avg_train_accuracy: 0.369
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0933
- 0.1338
- 0.1661
- 0.1874
- 0.2027
- 0.2152
- 0.2286
- 0.2349
- 0.245
- 0.2548
- 0.2612
- 0.2683
- 0.2746
- 0.2803
- 0.2881
- 0.296
- 0.2965
- 0.3057
- 0.304
- 0.3137
- 0.3245
- 0.324
- 0.3305
- 0.3349
- 0.3353
- 0.3451
- 0.3468
- 0.3482
- 0.3569
- 0.3532
- 0.3602
- 0.3616
- 0.3656
- 0.3657
- 0.3736
- 0.3722
- 0.3768
- 0.3737
- 0.3803
- 0.3781
- 0.3845
- 0.3896
- 0.3908
- 0.3905
- 0.3852
- 0.3983
- 0.383
- 0.3956
- 0.397
- 0.3983
- 0.4052
- 0.3929
- 0.4019
- 0.4003
- 0.4013
- 0.4022
- 0.4017
- 0.4094
- 0.4061
- 0.4111
- 0.4118
- 0.4096
- 0.4142
- 0.413
- 0.4206
- 0.4175
- 0.4131
- 0.4199
- 0.4166
- 0.4188
- 0.418
- 0.4189
- 0.42
- 0.4187
- 0.4186
- 0.4176
- 0.4171
- 0.4191
- 0.4228
- 0.4238
- 0.4227
- 0.4227
- 0.4229
- 0.4238
- 0.423
- 0.426
- 0.426
- 0.4302
- 0.4268
- 0.4253
- 0.4355
- 0.4294
- 0.4305
- 0.4236
- 0.4271
- 0.4291
- 0.4305
- 0.4312
- 0.431
- 0.4304
test_loss_list:
- 1.6463186073303222
- 1.5353303027153016
- 1.4657192540168762
- 1.416643979549408
- 1.3729383111000062
- 1.343018023967743
- 1.3115106010437012
- 1.286323549747467
- 1.2614010286331176
- 1.2343898177146913
- 1.2208085894584655
- 1.201388063430786
- 1.1834181022644044
- 1.1718212246894837
- 1.1600923395156861
- 1.139070520401001
- 1.1301909732818602
- 1.1172962617874145
- 1.1160915875434876
- 1.1017427802085877
- 1.0824378681182862
- 1.0798939990997314
- 1.0649252939224243
- 1.059509973526001
- 1.057511796951294
- 1.0408818650245666
- 1.0307443261146545
- 1.0268736171722412
- 1.0146377611160278
- 1.0191287589073181
- 1.0138976407051086
- 1.0037696886062621
- 0.9996599245071411
- 0.9949363994598389
- 0.9888799691200256
- 0.9878854775428771
- 0.980090172290802
- 0.9807779598236084
- 0.9778986048698425
- 0.9801973080635071
- 0.9673147773742676
- 0.970413978099823
- 0.9627320218086243
- 0.9623279070854187
- 0.9682615208625793
- 0.9469564986228943
- 0.9677867412567138
- 0.9434262132644653
- 0.9461848568916321
- 0.943326267004013
- 0.9422670543193817
- 0.9550081956386566
- 0.9431415402889252
- 0.9483587944507599
- 0.9397072231769562
- 0.9468494582176209
- 0.9425013780593872
- 0.9358342278003693
- 0.9350230765342712
- 0.931649626493454
- 0.9347600698471069
- 0.9310579705238342
- 0.9333461618423462
- 0.9304154944419861
- 0.9251558101177215
- 0.9264055895805359
- 0.9390803980827331
- 0.9228125214576721
- 0.9320701384544372
- 0.9287567043304443
- 0.9327334713935852
- 0.927826132774353
- 0.9343985390663146
- 0.9327491223812103
- 0.9306188011169434
- 0.929657906293869
- 0.928779890537262
- 0.9273137867450714
- 0.9242214083671569
- 0.927456214427948
- 0.9242830610275269
- 0.9274563872814179
- 0.9290162193775177
- 0.9353093123435974
- 0.9314578115940094
- 0.9263602387905121
- 0.9192827880382538
- 0.9235694205760956
- 0.9303436017036438
- 0.9297876584529877
- 0.9234099864959717
- 0.9265784299373627
- 0.9319199168682099
- 0.9470839679241181
- 0.9318708264827729
- 0.9350850093364715
- 0.9339283919334411
- 0.9366988754272461
- 0.9410674476623535
- 0.9395476520061493
train_accuracy:
- 0.114
- 0.117
- 0.115
- 0.182
- 0.167
- 0.163
- 0.203
- 0.214
- 0.218
- 0.202
- 0.245
- 0.264
- 0.269
- 0.256
- 0.259
- 0.293
- 0.292
- 0.25
- 0.276
- 0.27
- 0.298
- 0.269
- 0.284
- 0.298
- 0.297
- 0.322
- 0.304
- 0.297
- 0.339
- 0.312
- 0.335
- 0.337
- 0.33
- 0.332
- 0.355
- 0.343
- 0.337
- 0.349
- 0.345
- 0.344
- 0.345
- 0.348
- 0.345
- 0.338
- 0.345
- 0.356
- 0.36
- 0.368
- 0.353
- 0.359
- 0.361
- 0.36
- 0.358
- 0.366
- 0.365
- 0.355
- 0.367
- 0.373
- 0.381
- 0.373
- 0.357
- 0.367
- 0.387
- 0.4
- 0.389
- 0.369
- 0.379
- 0.384
- 0.39
- 0.358
- 0.4
- 0.366
- 0.403
- 0.396
- 0.373
- 0.386
- 0.382
- 0.399
- 0.399
- 0.365
- 0.391
- 0.398
- 0.389
- 0.402
- 0.38
- 0.392
- 0.405
- 0.411
- 0.408
- 0.384
- 0.368
- 0.413
- 0.405
- 0.404
- 0.403
- 0.385
- 0.4
- 0.412
- 0.387
- 0.369
train_loss:
- 4.216
- 3.744
- 3.481
- 3.303
- 3.187
- 2.995
- 2.974
- 2.83
- 2.858
- 2.802
- 2.593
- 2.586
- 2.552
- 2.432
- 2.372
- 2.467
- 2.31
- 2.203
- 2.115
- 2.099
- 2.145
- 2.048
- 1.971
- 1.833
- 1.754
- 1.952
- 1.89
- 1.688
- 1.76
- 1.624
- 1.69
- 1.69
- 1.493
- 1.588
- 1.513
- 1.424
- 1.394
- 1.43
- 1.4
- 1.278
- 1.46
- 1.366
- 1.184
- 1.347
- 1.202
- 1.276
- 1.178
- 1.083
- 1.003
- 1.126
- 1.09
- 0.951
- 0.863
- 0.763
- 0.996
- 0.952
- 0.894
- 0.945
- 0.845
- 0.927
- 0.783
- 0.89
- 0.734
- 0.811
- 0.776
- 0.685
- 0.622
- 0.795
- 0.594
- 0.717
- 0.66
- 0.636
- 0.584
- 0.582
- 0.484
- 0.597
- 0.515
- 0.63
- 0.545
- 0.543
- 0.478
- 0.481
- 0.387
- 0.427
- 0.531
- 0.49
- 0.461
- 0.444
- 0.425
- 0.402
- 0.462
- 0.337
- 0.356
- 0.368
- 0.328
- 0.332
- 0.369
- 0.329
- 0.29
- 0.333
unequal: 0
verbose: 1
