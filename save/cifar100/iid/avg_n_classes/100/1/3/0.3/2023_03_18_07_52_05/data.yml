avg_train_accuracy: 0.444
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0875
- 0.1355
- 0.156
- 0.1789
- 0.1988
- 0.2107
- 0.2283
- 0.2361
- 0.2469
- 0.257
- 0.267
- 0.2732
- 0.2763
- 0.2865
- 0.2901
- 0.3009
- 0.3053
- 0.3102
- 0.3211
- 0.3213
- 0.323
- 0.3343
- 0.3361
- 0.3444
- 0.3453
- 0.3447
- 0.3523
- 0.3611
- 0.3611
- 0.3649
- 0.3657
- 0.3683
- 0.3718
- 0.3708
- 0.3752
- 0.3767
- 0.3798
- 0.3882
- 0.387
- 0.3863
- 0.3854
- 0.3845
- 0.3951
- 0.3919
- 0.3981
- 0.3993
- 0.3939
- 0.4028
- 0.4006
- 0.4059
- 0.4017
- 0.4015
- 0.4084
- 0.4051
- 0.4067
- 0.411
- 0.4059
- 0.4155
- 0.4123
- 0.4103
- 0.417
- 0.4043
- 0.4142
- 0.4176
- 0.4182
- 0.4147
- 0.4186
- 0.4219
- 0.4245
- 0.4229
- 0.4185
- 0.4205
- 0.4215
- 0.4252
- 0.4241
- 0.4215
- 0.4304
- 0.4234
- 0.4263
- 0.4245
- 0.4356
- 0.4304
- 0.4267
- 0.4295
- 0.4259
- 0.4326
- 0.4266
- 0.4355
- 0.4294
- 0.4319
- 0.4334
- 0.4294
- 0.4363
- 0.4338
- 0.4364
- 0.4364
- 0.4333
- 0.4351
- 0.4326
- 0.4389
test_loss_list:
- 1.6522370672225952
- 1.5317776083946228
- 1.461581401824951
- 1.413730103969574
- 1.370603334903717
- 1.3436234521865844
- 1.311021454334259
- 1.2917247772216798
- 1.2640634155273438
- 1.2419273519515992
- 1.221631283760071
- 1.2014506912231446
- 1.1873255157470703
- 1.1708738422393798
- 1.1592228245735168
- 1.140032584667206
- 1.1284017872810364
- 1.1167696952819823
- 1.1035999178886413
- 1.0951475024223327
- 1.0894377732276916
- 1.068819887638092
- 1.0595029044151305
- 1.0504558658599854
- 1.0449091410636902
- 1.042851529121399
- 1.0318279600143432
- 1.0201317691802978
- 1.0189370584487916
- 1.0044083213806152
- 1.001861057281494
- 1.0057095503807068
- 0.9864176821708679
- 0.993375015258789
- 0.9859480476379394
- 0.980220935344696
- 0.977648332118988
- 0.9686342000961303
- 0.9685118079185486
- 0.9622086882591248
- 0.963704662322998
- 0.974353723526001
- 0.9550496339797974
- 0.9570214295387268
- 0.9443282890319824
- 0.9482926082611084
- 0.9487001848220825
- 0.9406932950019836
- 0.9436957359313964
- 0.9361280703544617
- 0.9420836758613587
- 0.9395791220664979
- 0.9396155405044556
- 0.9443654942512513
- 0.9332783269882202
- 0.9293312048912048
- 0.9386055612564087
- 0.9275330805778503
- 0.9285885787010193
- 0.9401256442070007
- 0.9359727907180786
- 0.9490549898147583
- 0.9300543165206909
- 0.9238279628753662
- 0.9236673951148987
- 0.9292229509353638
- 0.9230059170722962
- 0.9167129349708557
- 0.9193165612220764
- 0.9225073647499085
- 0.9252032232284546
- 0.9225235509872437
- 0.9249248480796814
- 0.9211163020133972
- 0.9263777232170105
- 0.9294655597209931
- 0.9201975560188294
- 0.9323769593238831
- 0.925210359096527
- 0.9244858407974244
- 0.9157445287704468
- 0.9176026940345764
- 0.9243257474899292
- 0.9203598070144653
- 0.9272140979766845
- 0.9163833403587341
- 0.926882085800171
- 0.9176783466339111
- 0.9289367723464966
- 0.9248009514808655
- 0.9213321805000305
- 0.9185076141357422
- 0.9254168915748596
- 0.9306352496147156
- 0.9282064652442932
- 0.9225246119499206
- 0.9238525605201722
- 0.92651291847229
- 0.927756667137146
- 0.9295336198806763
train_accuracy:
- 0.08
- 0.093
- 0.163
- 0.171
- 0.172
- 0.195
- 0.171
- 0.18
- 0.199
- 0.237
- 0.218
- 0.27
- 0.276
- 0.237
- 0.239
- 0.275
- 0.283
- 0.28
- 0.275
- 0.295
- 0.262
- 0.289
- 0.321
- 0.339
- 0.306
- 0.31
- 0.317
- 0.352
- 0.355
- 0.367
- 0.312
- 0.315
- 0.357
- 0.372
- 0.361
- 0.326
- 0.379
- 0.323
- 0.344
- 0.397
- 0.328
- 0.365
- 0.345
- 0.352
- 0.365
- 0.33
- 0.358
- 0.344
- 0.353
- 0.404
- 0.37
- 0.404
- 0.354
- 0.404
- 0.412
- 0.361
- 0.36
- 0.353
- 0.403
- 0.409
- 0.373
- 0.376
- 0.425
- 0.418
- 0.417
- 0.369
- 0.421
- 0.361
- 0.392
- 0.38
- 0.422
- 0.362
- 0.426
- 0.43
- 0.385
- 0.358
- 0.414
- 0.382
- 0.429
- 0.368
- 0.44
- 0.401
- 0.428
- 0.384
- 0.444
- 0.426
- 0.39
- 0.412
- 0.381
- 0.445
- 0.366
- 0.389
- 0.439
- 0.436
- 0.39
- 0.444
- 0.435
- 0.424
- 0.389
- 0.444
train_loss:
- 4.231
- 3.764
- 3.526
- 3.295
- 3.266
- 3.07
- 2.991
- 2.803
- 2.742
- 2.713
- 2.597
- 2.593
- 2.476
- 2.451
- 2.271
- 2.355
- 2.171
- 2.196
- 2.121
- 1.944
- 1.814
- 2.17
- 1.954
- 1.924
- 1.933
- 1.634
- 1.854
- 1.748
- 1.617
- 1.672
- 1.747
- 1.804
- 1.488
- 1.448
- 1.35
- 1.593
- 1.575
- 1.32
- 1.333
- 1.385
- 1.205
- 1.301
- 1.241
- 1.178
- 1.276
- 1.079
- 1.147
- 1.078
- 1.178
- 1.003
- 1.111
- 1.02
- 1.038
- 0.912
- 0.845
- 0.968
- 0.78
- 0.796
- 0.69
- 0.663
- 0.814
- 0.725
- 0.736
- 0.747
- 0.81
- 0.826
- 0.611
- 0.713
- 0.714
- 0.546
- 0.55
- 0.696
- 0.56
- 0.598
- 0.508
- 0.62
- 0.506
- 0.535
- 0.517
- 0.48
- 0.496
- 0.501
- 0.449
- 0.452
- 0.403
- 0.488
- 0.374
- 0.454
- 0.362
- 0.312
- 0.449
- 0.415
- 0.374
- 0.273
- 0.375
- 0.299
- 0.347
- 0.277
- 0.419
- 0.27
unequal: 0
verbose: 1
