avg_train_accuracy: 0.377
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0949
- 0.1347
- 0.1609
- 0.1866
- 0.2031
- 0.2198
- 0.2271
- 0.2429
- 0.2497
- 0.2616
- 0.2659
- 0.2733
- 0.2831
- 0.2875
- 0.2951
- 0.3035
- 0.3086
- 0.3129
- 0.3192
- 0.324
- 0.3236
- 0.3334
- 0.3351
- 0.3345
- 0.339
- 0.3467
- 0.352
- 0.3577
- 0.3584
- 0.3552
- 0.3667
- 0.3676
- 0.3694
- 0.3724
- 0.3671
- 0.3777
- 0.3834
- 0.3805
- 0.3804
- 0.3879
- 0.3838
- 0.3889
- 0.3918
- 0.3935
- 0.3952
- 0.3947
- 0.3957
- 0.397
- 0.4025
- 0.4014
- 0.3986
- 0.4027
- 0.4053
- 0.4073
- 0.3982
- 0.4083
- 0.4088
- 0.4044
- 0.4109
- 0.4106
- 0.4177
- 0.4125
- 0.4161
- 0.4196
- 0.4145
- 0.4179
- 0.4186
- 0.422
- 0.4237
- 0.4242
- 0.4249
- 0.4235
- 0.4265
- 0.4236
- 0.424
- 0.4237
- 0.4271
- 0.4228
- 0.4292
- 0.4251
- 0.4296
- 0.4275
- 0.4333
- 0.4282
- 0.4294
- 0.43
- 0.4222
- 0.4287
- 0.4321
- 0.4293
- 0.4307
- 0.437
- 0.4338
- 0.437
- 0.4353
- 0.4278
- 0.4323
- 0.434
- 0.4316
- 0.4333
test_loss_list:
- 1.6509159564971925
- 1.536225187778473
- 1.4602150964736937
- 1.4024209046363831
- 1.36116596698761
- 1.3296724009513854
- 1.304099633693695
- 1.2701596641540527
- 1.250196077823639
- 1.2293798995018006
- 1.2133700227737427
- 1.19637095451355
- 1.1759569072723388
- 1.1671845412254334
- 1.1491873455047608
- 1.132883689403534
- 1.1201791119575502
- 1.1104919338226318
- 1.0933978724479676
- 1.0851003670692443
- 1.0776342248916626
- 1.0635760998725892
- 1.0634344983100892
- 1.0617589497566222
- 1.0554120779037475
- 1.0353152632713318
- 1.0274243545532227
- 1.00990779876709
- 1.010489227771759
- 1.0125834918022156
- 0.9993499970436096
- 0.996139874458313
- 0.9837057495117187
- 0.9877153730392456
- 0.9868514919281006
- 0.981900041103363
- 0.9666074573993683
- 0.9652768635749817
- 0.9693145561218262
- 0.9542067313194275
- 0.9563705849647522
- 0.9554465210437775
- 0.9561971938610077
- 0.9499764597415924
- 0.9501847052574157
- 0.9450079119205474
- 0.9390947484970092
- 0.9419355988502502
- 0.9349965298175812
- 0.9394762301445008
- 0.9428975629806519
- 0.9328729045391083
- 0.9291969907283782
- 0.9341273558139801
- 0.9362909197807312
- 0.9219691979885102
- 0.9237942171096801
- 0.9253608250617981
- 0.9232176101207733
- 0.9249093317985535
- 0.9159191060066223
- 0.9190170466899872
- 0.9176938605308532
- 0.9200653672218323
- 0.9212563061714172
- 0.9117424476146698
- 0.9101179838180542
- 0.9156278192996978
- 0.9134162056446076
- 0.912056565284729
- 0.9171819138526917
- 0.9130089688301086
- 0.9136624562740326
- 0.92260369181633
- 0.9223656690120697
- 0.9226935756206512
- 0.9188869607448578
- 0.9225530111789704
- 0.9182169270515442
- 0.9189473843574524
- 0.912562882900238
- 0.9212734699249268
- 0.9201106011867524
- 0.9152004671096802
- 0.9187080073356628
- 0.9136249387264251
- 0.9256378793716431
- 0.9248532807826996
- 0.9147195494174958
- 0.9208008396625519
- 0.9175971102714539
- 0.9157242882251739
- 0.9230672240257263
- 0.9187765669822693
- 0.925150386095047
- 0.9248854863643646
- 0.9220312321186066
- 0.9218379807472229
- 0.9275777578353882
- 0.9285992205142974
train_accuracy:
- 0.092
- 0.129
- 0.167
- 0.137
- 0.19
- 0.209
- 0.167
- 0.226
- 0.236
- 0.247
- 0.248
- 0.258
- 0.272
- 0.258
- 0.278
- 0.301
- 0.287
- 0.299
- 0.263
- 0.293
- 0.29
- 0.33
- 0.301
- 0.267
- 0.307
- 0.356
- 0.322
- 0.296
- 0.315
- 0.344
- 0.36
- 0.35
- 0.346
- 0.341
- 0.363
- 0.312
- 0.317
- 0.387
- 0.379
- 0.321
- 0.348
- 0.367
- 0.376
- 0.348
- 0.334
- 0.345
- 0.374
- 0.332
- 0.404
- 0.403
- 0.356
- 0.352
- 0.347
- 0.377
- 0.408
- 0.408
- 0.361
- 0.39
- 0.424
- 0.405
- 0.379
- 0.369
- 0.395
- 0.402
- 0.358
- 0.423
- 0.392
- 0.377
- 0.366
- 0.365
- 0.354
- 0.377
- 0.436
- 0.361
- 0.388
- 0.382
- 0.406
- 0.43
- 0.406
- 0.422
- 0.392
- 0.377
- 0.434
- 0.401
- 0.376
- 0.418
- 0.386
- 0.432
- 0.381
- 0.42
- 0.425
- 0.375
- 0.38
- 0.439
- 0.427
- 0.407
- 0.442
- 0.398
- 0.405
- 0.377
train_loss:
- 4.224
- 3.686
- 3.544
- 3.361
- 3.175
- 3.021
- 2.934
- 2.945
- 2.684
- 2.689
- 2.629
- 2.535
- 2.543
- 2.347
- 2.345
- 2.255
- 2.256
- 2.228
- 2.103
- 1.923
- 1.952
- 1.94
- 1.77
- 1.722
- 1.59
- 2.111
- 2.053
- 1.622
- 1.668
- 1.636
- 1.653
- 1.564
- 1.558
- 1.36
- 1.397
- 1.594
- 1.44
- 1.452
- 1.203
- 1.386
- 1.197
- 1.274
- 1.218
- 1.103
- 1.14
- 1.405
- 1.171
- 0.935
- 1.072
- 0.939
- 0.882
- 1.139
- 0.932
- 0.965
- 0.911
- 1.12
- 0.769
- 0.91
- 0.774
- 0.941
- 0.74
- 0.814
- 0.819
- 0.725
- 0.683
- 0.895
- 0.674
- 0.647
- 0.685
- 0.607
- 0.522
- 0.705
- 0.528
- 0.439
- 0.495
- 0.491
- 0.503
- 0.545
- 0.57
- 0.593
- 0.46
- 0.407
- 0.392
- 0.507
- 0.432
- 0.497
- 0.472
- 0.468
- 0.413
- 0.426
- 0.421
- 0.365
- 0.385
- 0.359
- 0.295
- 0.405
- 0.343
- 0.373
- 0.291
- 0.345
unequal: 0
verbose: 1
