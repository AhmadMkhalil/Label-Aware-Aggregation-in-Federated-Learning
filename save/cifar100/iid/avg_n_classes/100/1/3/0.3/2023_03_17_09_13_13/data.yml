avg_train_accuracy: 0.427
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0976
- 0.138
- 0.164
- 0.1811
- 0.1982
- 0.2156
- 0.2259
- 0.2365
- 0.2491
- 0.2544
- 0.2602
- 0.2704
- 0.2755
- 0.2846
- 0.2962
- 0.2984
- 0.3065
- 0.309
- 0.3172
- 0.3213
- 0.3272
- 0.3312
- 0.3351
- 0.3387
- 0.3444
- 0.3504
- 0.3478
- 0.3551
- 0.3571
- 0.3601
- 0.3586
- 0.3591
- 0.3655
- 0.3665
- 0.3699
- 0.3739
- 0.3736
- 0.3728
- 0.3751
- 0.3805
- 0.3778
- 0.3865
- 0.3839
- 0.3896
- 0.3947
- 0.3921
- 0.3982
- 0.3976
- 0.3964
- 0.4
- 0.4037
- 0.4004
- 0.4064
- 0.4055
- 0.4065
- 0.4079
- 0.4102
- 0.4092
- 0.4097
- 0.4123
- 0.411
- 0.4118
- 0.4116
- 0.4158
- 0.4191
- 0.4127
- 0.4162
- 0.4162
- 0.4165
- 0.4185
- 0.4172
- 0.4211
- 0.4224
- 0.4211
- 0.4188
- 0.4268
- 0.4186
- 0.4184
- 0.4191
- 0.4238
- 0.4227
- 0.4212
- 0.4217
- 0.4277
- 0.4244
- 0.4227
- 0.4268
- 0.4247
- 0.4337
- 0.4291
- 0.4311
- 0.4281
- 0.4275
- 0.4316
- 0.4303
- 0.4313
- 0.4327
- 0.4285
- 0.4312
- 0.4349
test_loss_list:
- 1.6352002573013307
- 1.524219982624054
- 1.451452841758728
- 1.4087703800201417
- 1.3709511709213258
- 1.3333331775665282
- 1.3005370163917542
- 1.2783406448364258
- 1.2522635626792908
- 1.235132863521576
- 1.2141781091690063
- 1.1955425596237184
- 1.1835041522979737
- 1.1642226004600524
- 1.146794500350952
- 1.1387462663650512
- 1.1231737661361694
- 1.116020393371582
- 1.1024853897094726
- 1.0783912706375123
- 1.0744637608528138
- 1.068410210609436
- 1.0566987562179566
- 1.043394079208374
- 1.0394871616363526
- 1.0281897902488708
- 1.0254724097251893
- 1.013218047618866
- 1.01305424451828
- 1.0073753690719605
- 1.0178993082046508
- 1.0016402292251587
- 0.9945913314819336
- 0.991096715927124
- 0.9953138899803161
- 0.9841584205627442
- 0.984128623008728
- 0.9794801926612854
- 0.9749432325363159
- 0.9694881868362427
- 0.9727062964439392
- 0.9618444991111755
- 0.9690004801750183
- 0.9585258913040161
- 0.9531995701789856
- 0.9530833292007447
- 0.9462854671478271
- 0.9458939158916473
- 0.9564386630058288
- 0.9459327721595764
- 0.9405361127853393
- 0.9341862881183625
- 0.9331673812866211
- 0.9337381768226624
- 0.9311302101612091
- 0.9347497224807739
- 0.9323150181770324
- 0.934994889497757
- 0.936612389087677
- 0.9350343585014343
- 0.9291163802146911
- 0.9254223024845123
- 0.9330365014076233
- 0.929353814125061
- 0.9285397863388062
- 0.9340927672386169
- 0.932318651676178
- 0.93222247838974
- 0.9265966856479645
- 0.9234265708923339
- 0.932826063632965
- 0.9156755018234253
- 0.9206470263004303
- 0.9248382091522217
- 0.9264084005355835
- 0.9199374866485596
- 0.9297928190231324
- 0.9294098341464996
- 0.9257993483543396
- 0.9282244455814361
- 0.9205607974529266
- 0.9234461605548858
- 0.9305294501781464
- 0.9253295719623565
- 0.9334972357749939
- 0.9272723567485809
- 0.9366370213031768
- 0.9382095909118653
- 0.9250287175178528
- 0.9193423891067505
- 0.926160888671875
- 0.9407813358306885
- 0.9345300173759461
- 0.9230920517444611
- 0.9293125438690185
- 0.934880485534668
- 0.9302464509010315
- 0.9388667976856232
- 0.9379692220687866
- 0.9320223236083984
train_accuracy:
- 0.092
- 0.12
- 0.148
- 0.144
- 0.168
- 0.188
- 0.182
- 0.23
- 0.243
- 0.223
- 0.239
- 0.26
- 0.271
- 0.241
- 0.251
- 0.245
- 0.283
- 0.248
- 0.304
- 0.294
- 0.266
- 0.291
- 0.324
- 0.268
- 0.349
- 0.343
- 0.339
- 0.357
- 0.352
- 0.32
- 0.331
- 0.367
- 0.309
- 0.332
- 0.339
- 0.336
- 0.334
- 0.362
- 0.381
- 0.336
- 0.346
- 0.358
- 0.362
- 0.362
- 0.306
- 0.403
- 0.361
- 0.322
- 0.326
- 0.365
- 0.361
- 0.386
- 0.374
- 0.399
- 0.384
- 0.418
- 0.38
- 0.395
- 0.421
- 0.355
- 0.407
- 0.407
- 0.404
- 0.425
- 0.391
- 0.41
- 0.356
- 0.382
- 0.355
- 0.4
- 0.358
- 0.413
- 0.406
- 0.411
- 0.395
- 0.403
- 0.42
- 0.414
- 0.356
- 0.348
- 0.346
- 0.44
- 0.381
- 0.348
- 0.407
- 0.416
- 0.407
- 0.424
- 0.408
- 0.429
- 0.355
- 0.413
- 0.434
- 0.433
- 0.416
- 0.384
- 0.356
- 0.421
- 0.374
- 0.427
train_loss:
- 4.204
- 3.722
- 3.527
- 3.298
- 3.186
- 3.077
- 3.058
- 2.859
- 2.85
- 2.701
- 2.639
- 2.565
- 2.468
- 2.441
- 2.388
- 2.267
- 2.184
- 2.095
- 2.224
- 2.125
- 2.0
- 2.026
- 1.945
- 1.99
- 1.832
- 1.877
- 1.83
- 1.698
- 1.532
- 1.624
- 1.553
- 1.539
- 1.437
- 1.594
- 1.305
- 1.283
- 1.348
- 1.287
- 1.363
- 1.296
- 1.048
- 1.456
- 1.042
- 1.352
- 1.206
- 1.186
- 1.239
- 0.926
- 1.065
- 1.107
- 1.026
- 1.118
- 0.942
- 1.082
- 0.948
- 0.885
- 0.825
- 0.909
- 0.775
- 0.714
- 0.832
- 0.881
- 0.61
- 0.655
- 0.692
- 0.601
- 0.644
- 0.551
- 0.795
- 0.686
- 0.469
- 0.799
- 0.728
- 0.617
- 0.638
- 0.651
- 0.499
- 0.486
- 0.563
- 0.439
- 0.433
- 0.431
- 0.368
- 0.479
- 0.318
- 0.485
- 0.369
- 0.38
- 0.498
- 0.431
- 0.364
- 0.341
- 0.368
- 0.317
- 0.315
- 0.364
- 0.26
- 0.341
- 0.258
- 0.396
unequal: 0
verbose: 1
