avg_train_accuracy: 0.387
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.098
- 0.1455
- 0.1646
- 0.1857
- 0.1984
- 0.2143
- 0.2278
- 0.2375
- 0.2456
- 0.2557
- 0.2616
- 0.2692
- 0.2748
- 0.2836
- 0.2939
- 0.3006
- 0.3043
- 0.3094
- 0.3117
- 0.3169
- 0.3235
- 0.3254
- 0.332
- 0.3364
- 0.3408
- 0.3433
- 0.3534
- 0.3513
- 0.355
- 0.3581
- 0.3574
- 0.359
- 0.3605
- 0.3702
- 0.3691
- 0.3747
- 0.3738
- 0.3743
- 0.3815
- 0.3769
- 0.3825
- 0.3867
- 0.3826
- 0.3872
- 0.3844
- 0.3915
- 0.3975
- 0.392
- 0.3962
- 0.3973
- 0.3998
- 0.3978
- 0.3978
- 0.4033
- 0.4061
- 0.4029
- 0.4081
- 0.4088
- 0.4108
- 0.4101
- 0.4083
- 0.4096
- 0.4094
- 0.4145
- 0.4149
- 0.4193
- 0.4173
- 0.4099
- 0.4166
- 0.4151
- 0.4163
- 0.4148
- 0.4184
- 0.4241
- 0.4198
- 0.4186
- 0.4206
- 0.4238
- 0.4198
- 0.4255
- 0.4209
- 0.4227
- 0.4285
- 0.4252
- 0.4263
- 0.4293
- 0.4278
- 0.4309
- 0.43
- 0.4254
- 0.4263
- 0.4345
- 0.4303
- 0.4308
- 0.4297
- 0.4335
- 0.4306
- 0.4321
- 0.4334
- 0.4287
test_loss_list:
- 1.6354233360290527
- 1.5225479650497435
- 1.4580228066444396
- 1.410381407737732
- 1.3720483231544494
- 1.3365495443344115
- 1.3095876860618592
- 1.2826226210594178
- 1.2603178691864014
- 1.2423691105842591
- 1.2235970330238342
- 1.2060592341423035
- 1.1939267921447754
- 1.1715245008468629
- 1.1570522332191466
- 1.1429453206062317
- 1.1363431191444398
- 1.1227464413642883
- 1.1130322456359862
- 1.1056815075874329
- 1.0920373821258544
- 1.0892298221588135
- 1.0745551681518555
- 1.0641823172569276
- 1.055956084728241
- 1.0505892443656921
- 1.034143147468567
- 1.0387070107460021
- 1.0294600987434388
- 1.0255207490921021
- 1.023983302116394
- 1.0160941457748414
- 1.011765217781067
- 1.0061444449424743
- 1.0055278706550599
- 0.9919360280036926
- 0.9921147966384888
- 0.9896189618110657
- 0.9875603580474853
- 0.9879822278022766
- 0.9808286237716675
- 0.9701525139808654
- 0.9782147431373596
- 0.9656214308738709
- 0.9694953870773315
- 0.9599469518661499
- 0.9561208653450012
- 0.9607559323310852
- 0.9563595366477966
- 0.9553722953796386
- 0.9499760913848877
- 0.9514541125297546
- 0.9493629002571106
- 0.9442314410209656
- 0.9440962147712707
- 0.9580037665367126
- 0.952188982963562
- 0.9453672409057617
- 0.9443285298347474
- 0.9482501363754272
- 0.9443888926506042
- 0.935351026058197
- 0.940252251625061
- 0.9391137194633484
- 0.9360729169845581
- 0.9380319809913635
- 0.9417357182502747
- 0.9486600017547607
- 0.940968508720398
- 0.9385458397865295
- 0.9466172289848328
- 0.9485024642944336
- 0.9362925004959106
- 0.9361249899864197
- 0.9426932621002198
- 0.9401856207847595
- 0.9417691254615783
- 0.9437686395645142
- 0.9524969744682312
- 0.9402470922470093
- 0.9463349103927612
- 0.9517490577697754
- 0.9445004844665528
- 0.9451262283325196
- 0.9458805847167969
- 0.9392606854438782
- 0.9468721532821656
- 0.9509681057929993
- 0.949758141040802
- 0.9528083610534668
- 0.9475802731513977
- 0.9411280751228333
- 0.9504847764968872
- 0.9537725389003754
- 0.9554474711418152
- 0.9524803996086121
- 0.9540327143669128
- 0.9561394166946411
- 0.95572518825531
- 0.9522202134132385
train_accuracy:
- 0.091
- 0.104
- 0.152
- 0.168
- 0.171
- 0.192
- 0.223
- 0.21
- 0.23
- 0.241
- 0.249
- 0.241
- 0.241
- 0.277
- 0.26
- 0.251
- 0.277
- 0.292
- 0.311
- 0.281
- 0.293
- 0.299
- 0.327
- 0.289
- 0.289
- 0.297
- 0.343
- 0.335
- 0.324
- 0.316
- 0.346
- 0.367
- 0.328
- 0.353
- 0.331
- 0.349
- 0.348
- 0.371
- 0.337
- 0.333
- 0.341
- 0.387
- 0.362
- 0.359
- 0.361
- 0.39
- 0.388
- 0.367
- 0.344
- 0.38
- 0.362
- 0.371
- 0.367
- 0.389
- 0.397
- 0.388
- 0.38
- 0.4
- 0.36
- 0.374
- 0.35
- 0.4
- 0.37
- 0.387
- 0.382
- 0.41
- 0.366
- 0.366
- 0.369
- 0.399
- 0.424
- 0.399
- 0.403
- 0.41
- 0.419
- 0.386
- 0.433
- 0.391
- 0.364
- 0.404
- 0.426
- 0.397
- 0.371
- 0.37
- 0.37
- 0.373
- 0.43
- 0.431
- 0.417
- 0.415
- 0.371
- 0.386
- 0.397
- 0.36
- 0.403
- 0.42
- 0.439
- 0.402
- 0.396
- 0.387
train_loss:
- 4.178
- 3.732
- 3.445
- 3.284
- 3.188
- 3.043
- 2.957
- 2.803
- 2.833
- 2.582
- 2.582
- 2.604
- 2.504
- 2.475
- 2.354
- 2.317
- 2.252
- 2.147
- 2.161
- 2.048
- 2.023
- 1.976
- 1.829
- 1.991
- 1.958
- 1.834
- 1.755
- 1.623
- 1.709
- 1.638
- 1.553
- 1.378
- 1.492
- 1.51
- 1.337
- 1.666
- 1.394
- 1.278
- 1.221
- 1.471
- 1.394
- 1.365
- 1.196
- 1.246
- 1.072
- 1.15
- 1.18
- 1.024
- 1.197
- 0.91
- 1.175
- 0.905
- 0.94
- 0.992
- 0.83
- 0.811
- 0.782
- 0.859
- 0.973
- 0.712
- 0.785
- 0.851
- 0.723
- 0.8
- 0.714
- 0.76
- 0.694
- 0.642
- 0.609
- 0.58
- 0.684
- 0.611
- 0.654
- 0.535
- 0.507
- 0.459
- 0.512
- 0.475
- 0.388
- 0.548
- 0.502
- 0.47
- 0.407
- 0.549
- 0.454
- 0.522
- 0.398
- 0.383
- 0.401
- 0.313
- 0.37
- 0.483
- 0.336
- 0.366
- 0.307
- 0.323
- 0.275
- 0.357
- 0.378
- 0.344
unequal: 0
verbose: 1
