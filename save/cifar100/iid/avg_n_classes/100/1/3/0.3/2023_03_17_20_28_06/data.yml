avg_train_accuracy: 0.381
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0925
- 0.1363
- 0.1597
- 0.1803
- 0.1989
- 0.2143
- 0.2281
- 0.2398
- 0.2481
- 0.2597
- 0.2662
- 0.2765
- 0.28
- 0.2849
- 0.2909
- 0.3017
- 0.3044
- 0.314
- 0.3166
- 0.3217
- 0.3292
- 0.3382
- 0.3404
- 0.3439
- 0.3423
- 0.353
- 0.3484
- 0.3587
- 0.3556
- 0.3628
- 0.3675
- 0.3724
- 0.3752
- 0.373
- 0.379
- 0.3794
- 0.3827
- 0.3823
- 0.3911
- 0.3838
- 0.3923
- 0.3972
- 0.3923
- 0.3982
- 0.3992
- 0.4033
- 0.3966
- 0.3984
- 0.4025
- 0.4016
- 0.4057
- 0.4048
- 0.4075
- 0.4065
- 0.4052
- 0.4032
- 0.4117
- 0.4163
- 0.4151
- 0.4131
- 0.4114
- 0.41
- 0.4167
- 0.4131
- 0.4116
- 0.4178
- 0.4199
- 0.4233
- 0.4146
- 0.4192
- 0.4199
- 0.4194
- 0.4156
- 0.4252
- 0.4246
- 0.418
- 0.4231
- 0.4252
- 0.4193
- 0.4257
- 0.4248
- 0.4235
- 0.421
- 0.4272
- 0.4238
- 0.4269
- 0.4275
- 0.4298
- 0.4317
- 0.4278
- 0.4305
- 0.4311
- 0.4304
- 0.4252
- 0.4322
- 0.4299
- 0.4314
- 0.4364
- 0.4364
- 0.4312
test_loss_list:
- 1.6446713709831238
- 1.5278562545776366
- 1.4611748600006103
- 1.4065460658073425
- 1.3651182818412781
- 1.3331542706489563
- 1.3055806612968446
- 1.2795144820213318
- 1.2570235514640808
- 1.2352107381820678
- 1.2111781525611878
- 1.1939108777046203
- 1.178628509044647
- 1.1651388812065124
- 1.149597508907318
- 1.1251636123657227
- 1.1174611830711365
- 1.0993988728523254
- 1.0963683772087096
- 1.0849496126174927
- 1.0650348258018494
- 1.0546330618858337
- 1.0486914372444154
- 1.0437734270095824
- 1.0356441235542297
- 1.0258000254631043
- 1.0255184698104858
- 1.0102597332000733
- 1.0107874870300293
- 1.004803137779236
- 0.9958000159263611
- 0.9823721742630005
- 0.982226836681366
- 0.9789918565750122
- 0.9732580971717835
- 0.9707954287528991
- 0.9711186742782593
- 0.9699630975723267
- 0.9596306729316711
- 0.9555904626846313
- 0.9577898836135864
- 0.9423906803131104
- 0.9449439430236817
- 0.9473544049263001
- 0.9362624251842498
- 0.9348333859443665
- 0.9440631079673767
- 0.9394288945198059
- 0.9358058881759643
- 0.9331006610393524
- 0.9281940388679505
- 0.9321345508098602
- 0.9264465737342834
- 0.9280245852470398
- 0.9310162568092346
- 0.930761559009552
- 0.9262669646739959
- 0.9145149993896484
- 0.9179481029510498
- 0.9214041447639465
- 0.9273802852630615
- 0.932009539604187
- 0.9185377013683319
- 0.9264117538928985
- 0.928007402420044
- 0.9173134052753449
- 0.9161259996891021
- 0.9105976617336273
- 0.9279394280910492
- 0.9258128094673157
- 0.9162714314460755
- 0.9206696927547455
- 0.9249627006053924
- 0.9152709889411926
- 0.9202906429767609
- 0.9246724343299866
- 0.9160305058956146
- 0.9142018795013428
- 0.9207160890102386
- 0.9128313803672791
- 0.9170627570152283
- 0.9234642457962036
- 0.9280961978435517
- 0.9208938872814179
- 0.9241917729377747
- 0.9238554799556732
- 0.9215157020092011
- 0.9178769886493683
- 0.9210655713081359
- 0.927689002752304
- 0.9293918788433075
- 0.9232476472854614
- 0.927374176979065
- 0.927654629945755
- 0.9207479918003082
- 0.9235607552528381
- 0.9295768117904664
- 0.9238716447353363
- 0.9167047441005707
- 0.923050023317337
train_accuracy:
- 0.074
- 0.115
- 0.121
- 0.162
- 0.182
- 0.186
- 0.201
- 0.219
- 0.229
- 0.231
- 0.243
- 0.22
- 0.264
- 0.261
- 0.268
- 0.247
- 0.301
- 0.297
- 0.284
- 0.301
- 0.297
- 0.319
- 0.32
- 0.286
- 0.292
- 0.328
- 0.329
- 0.339
- 0.333
- 0.333
- 0.345
- 0.314
- 0.349
- 0.36
- 0.371
- 0.37
- 0.378
- 0.332
- 0.371
- 0.334
- 0.372
- 0.36
- 0.36
- 0.331
- 0.373
- 0.385
- 0.368
- 0.37
- 0.334
- 0.371
- 0.387
- 0.335
- 0.373
- 0.366
- 0.384
- 0.379
- 0.393
- 0.343
- 0.357
- 0.379
- 0.362
- 0.354
- 0.391
- 0.382
- 0.395
- 0.368
- 0.393
- 0.401
- 0.396
- 0.394
- 0.4
- 0.397
- 0.398
- 0.412
- 0.381
- 0.406
- 0.409
- 0.38
- 0.415
- 0.405
- 0.414
- 0.408
- 0.402
- 0.411
- 0.405
- 0.417
- 0.363
- 0.41
- 0.387
- 0.402
- 0.374
- 0.39
- 0.404
- 0.421
- 0.373
- 0.411
- 0.408
- 0.413
- 0.376
- 0.381
train_loss:
- 4.227
- 3.74
- 3.479
- 3.362
- 3.202
- 3.074
- 2.962
- 2.914
- 2.859
- 2.799
- 2.692
- 2.595
- 2.445
- 2.383
- 2.344
- 2.355
- 2.209
- 2.247
- 2.057
- 2.009
- 2.216
- 2.034
- 1.907
- 1.828
- 1.819
- 1.831
- 1.81
- 1.787
- 1.6
- 1.669
- 1.686
- 1.563
- 1.615
- 1.457
- 1.651
- 1.39
- 1.392
- 1.431
- 1.329
- 1.433
- 1.296
- 1.336
- 1.18
- 1.209
- 1.253
- 1.23
- 1.059
- 1.073
- 0.975
- 1.049
- 1.011
- 0.869
- 0.935
- 1.072
- 0.936
- 0.869
- 0.881
- 0.86
- 0.721
- 0.752
- 0.663
- 0.734
- 0.808
- 0.704
- 0.748
- 0.626
- 0.752
- 0.581
- 0.581
- 0.499
- 0.727
- 0.611
- 0.576
- 0.677
- 0.44
- 0.508
- 0.534
- 0.589
- 0.517
- 0.547
- 0.586
- 0.431
- 0.399
- 0.414
- 0.421
- 0.377
- 0.372
- 0.499
- 0.405
- 0.317
- 0.33
- 0.424
- 0.307
- 0.314
- 0.386
- 0.293
- 0.355
- 0.386
- 0.376
- 0.326
unequal: 0
verbose: 1
