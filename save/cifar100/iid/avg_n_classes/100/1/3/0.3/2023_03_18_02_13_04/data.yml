avg_train_accuracy: 0.412
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0941
- 0.1411
- 0.168
- 0.1828
- 0.197
- 0.2088
- 0.2191
- 0.2363
- 0.2439
- 0.2547
- 0.2616
- 0.2789
- 0.2862
- 0.2839
- 0.2983
- 0.3071
- 0.3159
- 0.3145
- 0.3263
- 0.3333
- 0.337
- 0.3364
- 0.3403
- 0.3439
- 0.3538
- 0.3587
- 0.359
- 0.3583
- 0.3645
- 0.3731
- 0.3683
- 0.371
- 0.3712
- 0.3835
- 0.3802
- 0.3784
- 0.3843
- 0.3826
- 0.3836
- 0.389
- 0.3942
- 0.3944
- 0.392
- 0.3912
- 0.4057
- 0.4044
- 0.3979
- 0.4041
- 0.4071
- 0.4087
- 0.4081
- 0.4113
- 0.4092
- 0.4087
- 0.4075
- 0.4103
- 0.4106
- 0.4178
- 0.4178
- 0.4228
- 0.4236
- 0.42
- 0.4174
- 0.4168
- 0.4178
- 0.4217
- 0.4236
- 0.4221
- 0.4219
- 0.426
- 0.4254
- 0.423
- 0.4192
- 0.4245
- 0.423
- 0.4274
- 0.4279
- 0.4272
- 0.4297
- 0.4301
- 0.4366
- 0.4329
- 0.4321
- 0.4368
- 0.435
- 0.4387
- 0.4355
- 0.4381
- 0.4363
- 0.4382
- 0.4414
- 0.4372
- 0.4377
- 0.444
- 0.4415
- 0.4406
- 0.4427
- 0.4437
- 0.4417
- 0.4407
test_loss_list:
- 1.632247703075409
- 1.5190923452377318
- 1.452761046886444
- 1.4020182251930238
- 1.3632155823707581
- 1.3352176499366761
- 1.3086889338493348
- 1.2768038058280944
- 1.2525363063812256
- 1.2312534618377686
- 1.2155292820930481
- 1.1936675548553466
- 1.1729947638511657
- 1.1619579815864562
- 1.136821060180664
- 1.1241961812973023
- 1.1026502275466918
- 1.0967571687698365
- 1.0830247449874877
- 1.0722954392433166
- 1.056597456932068
- 1.0540255188941956
- 1.0504685020446778
- 1.0428113746643066
- 1.0305730605125427
- 1.0135431504249572
- 1.0163110327720641
- 1.0109714436531068
- 1.0025843262672425
- 0.9954578638076782
- 0.9956930589675903
- 0.9882883763313294
- 0.984503448009491
- 0.969874210357666
- 0.9677110075950622
- 0.9745371782779694
- 0.9712892293930053
- 0.9664065480232239
- 0.962493325471878
- 0.9557682609558106
- 0.9486025810241699
- 0.9529129457473755
- 0.9541866445541382
- 0.9574542427062989
- 0.9342437827587128
- 0.9306385755538941
- 0.9391295337677001
- 0.9401798582077027
- 0.9336978054046631
- 0.9327764964103699
- 0.9293752121925354
- 0.9280237865447998
- 0.9362722051143646
- 0.9311658120155335
- 0.9330618143081665
- 0.9342977809906006
- 0.9305692148208619
- 0.9223880469799042
- 0.9200320720672608
- 0.916257667541504
- 0.9124387812614441
- 0.9203751468658448
- 0.922016909122467
- 0.9283592081069947
- 0.921377317905426
- 0.9177918767929077
- 0.9230439448356629
- 0.9225851082801819
- 0.9223265957832336
- 0.9245501112937927
- 0.9287846279144287
- 0.9206213402748108
- 0.93002685546875
- 0.9234691381454467
- 0.9265569710731506
- 0.9306955695152282
- 0.9202077603340149
- 0.9170288515090942
- 0.9136827182769776
- 0.9135892653465271
- 0.912761173248291
- 0.9161723053455353
- 0.9264413046836854
- 0.9135915327072144
- 0.9159101057052612
- 0.9178448438644409
- 0.9156402778625489
- 0.9155425775051117
- 0.9193446922302246
- 0.9184013366699219
- 0.9185406303405762
- 0.9216847515106201
- 0.9201525664329528
- 0.9185566568374633
- 0.9185442113876343
- 0.9165971648693084
- 0.9174949216842652
- 0.9232918643951415
- 0.9182199478149414
- 0.9206147003173828
train_accuracy:
- 0.09
- 0.133
- 0.157
- 0.173
- 0.174
- 0.202
- 0.223
- 0.225
- 0.249
- 0.24
- 0.226
- 0.268
- 0.261
- 0.272
- 0.261
- 0.279
- 0.301
- 0.296
- 0.292
- 0.299
- 0.307
- 0.297
- 0.32
- 0.31
- 0.322
- 0.319
- 0.319
- 0.329
- 0.34
- 0.321
- 0.348
- 0.338
- 0.319
- 0.351
- 0.352
- 0.36
- 0.352
- 0.37
- 0.38
- 0.352
- 0.373
- 0.36
- 0.343
- 0.355
- 0.37
- 0.388
- 0.365
- 0.379
- 0.371
- 0.37
- 0.378
- 0.377
- 0.371
- 0.375
- 0.395
- 0.386
- 0.397
- 0.391
- 0.369
- 0.41
- 0.383
- 0.379
- 0.396
- 0.4
- 0.412
- 0.397
- 0.419
- 0.404
- 0.381
- 0.419
- 0.373
- 0.402
- 0.382
- 0.418
- 0.396
- 0.394
- 0.404
- 0.392
- 0.391
- 0.419
- 0.402
- 0.395
- 0.396
- 0.434
- 0.435
- 0.413
- 0.424
- 0.403
- 0.431
- 0.415
- 0.418
- 0.394
- 0.425
- 0.428
- 0.419
- 0.427
- 0.401
- 0.417
- 0.407
- 0.412
train_loss:
- 4.194
- 3.756
- 3.484
- 3.332
- 3.214
- 3.018
- 2.953
- 2.939
- 2.828
- 2.681
- 2.551
- 2.617
- 2.502
- 2.306
- 2.47
- 2.319
- 2.333
- 2.172
- 2.116
- 2.067
- 2.192
- 1.946
- 1.921
- 1.788
- 1.875
- 1.921
- 1.786
- 1.622
- 1.652
- 1.72
- 1.472
- 1.633
- 1.6
- 1.558
- 1.461
- 1.339
- 1.352
- 1.31
- 1.391
- 1.339
- 1.366
- 1.183
- 1.141
- 1.14
- 1.319
- 1.252
- 1.059
- 1.035
- 0.986
- 1.014
- 0.995
- 0.886
- 0.806
- 0.925
- 0.88
- 0.859
- 0.893
- 0.829
- 1.013
- 0.775
- 0.775
- 0.727
- 0.732
- 0.611
- 0.687
- 0.684
- 0.585
- 0.621
- 0.573
- 0.499
- 0.497
- 0.567
- 0.442
- 0.53
- 0.475
- 0.44
- 0.767
- 0.598
- 0.508
- 0.661
- 0.548
- 0.547
- 0.405
- 0.491
- 0.476
- 0.442
- 0.371
- 0.496
- 0.398
- 0.388
- 0.401
- 0.467
- 0.39
- 0.313
- 0.336
- 0.302
- 0.335
- 0.362
- 0.254
- 0.349
unequal: 0
verbose: 1
