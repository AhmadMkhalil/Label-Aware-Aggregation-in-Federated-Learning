avg_train_accuracy: 0.393
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0922
- 0.1353
- 0.1502
- 0.1671
- 0.1768
- 0.1932
- 0.2047
- 0.2124
- 0.2228
- 0.2178
- 0.2331
- 0.237
- 0.2452
- 0.2596
- 0.2594
- 0.2625
- 0.2748
- 0.2697
- 0.2738
- 0.2804
- 0.2838
- 0.2944
- 0.2954
- 0.3006
- 0.3021
- 0.3045
- 0.3119
- 0.3126
- 0.3134
- 0.3172
- 0.3187
- 0.3253
- 0.3356
- 0.3384
- 0.3381
- 0.3453
- 0.3436
- 0.3482
- 0.3446
- 0.3462
- 0.3502
- 0.3409
- 0.3349
- 0.364
- 0.341
- 0.3584
- 0.3656
- 0.3641
- 0.3719
- 0.3693
- 0.3722
- 0.3746
- 0.3689
- 0.3605
- 0.3781
- 0.3688
- 0.3809
- 0.3741
- 0.3815
- 0.3863
- 0.3896
- 0.3821
- 0.3831
- 0.3866
- 0.3844
- 0.391
- 0.3845
- 0.3882
- 0.3939
- 0.3845
- 0.3922
- 0.3898
- 0.3935
- 0.3855
- 0.3976
- 0.4031
- 0.4009
- 0.3877
- 0.3948
- 0.3981
- 0.3966
- 0.3987
- 0.4068
- 0.4019
- 0.4022
- 0.3919
- 0.3912
- 0.409
- 0.404
- 0.394
- 0.4112
- 0.4053
- 0.4115
- 0.4147
- 0.4031
- 0.4085
- 0.4048
- 0.4004
- 0.4132
- 0.4061
test_loss_list:
- 1.6495180940628051
- 1.5443065857887268
- 1.4912780141830444
- 1.451324894428253
- 1.4271112036705018
- 1.38505380153656
- 1.350983190536499
- 1.332757968902588
- 1.3175538325309752
- 1.3249826264381408
- 1.2880639982223512
- 1.2860430097579956
- 1.2519935774803161
- 1.2319485831260681
- 1.2165766549110413
- 1.2211174774169922
- 1.188745174407959
- 1.1965051770210267
- 1.1785464954376221
- 1.17655415058136
- 1.1543189668655396
- 1.1404053974151611
- 1.145026731491089
- 1.123122673034668
- 1.1205768227577209
- 1.1166774177551269
- 1.0946738171577453
- 1.0935973262786864
- 1.0929425358772278
- 1.0866233229637146
- 1.091959240436554
- 1.0826880717277527
- 1.050863094329834
- 1.0533896732330321
- 1.0480951976776123
- 1.038449637889862
- 1.0450038671493531
- 1.040487949848175
- 1.0429858183860778
- 1.0422299885749817
- 1.0345848202705383
- 1.044657220840454
- 1.0571449279785157
- 1.0061656093597413
- 1.0456490373611451
- 1.013935351371765
- 1.0073776292800902
- 1.0060407400131226
- 0.9901754403114319
- 0.9956582283973694
- 0.9978017616271972
- 0.9850908350944519
- 0.9935784029960633
- 1.0166412663459778
- 0.9919571614265442
- 1.002756540775299
- 0.9810854005813598
- 1.0011881947517396
- 0.9861869788169861
- 0.9737313389778137
- 0.9727614259719849
- 0.9789672255516052
- 0.9762680816650391
- 0.97370436668396
- 0.9857151079177856
- 0.9677045369148254
- 0.9920843434333801
- 0.9804933738708496
- 0.9770840215682983
- 1.001852662563324
- 0.9687172508239746
- 0.9830282139778137
- 0.9761282467842102
- 0.9865967631340027
- 0.9669202828407287
- 0.9598278021812439
- 0.9624245643615723
- 0.9844263815879821
- 0.9681078791618347
- 0.9722110915184021
- 0.9760385894775391
- 0.9761069083213806
- 0.9583232688903809
- 0.9680745148658753
- 0.9688828921318055
- 0.9901310563087463
- 0.9859037470817565
- 0.9595519208908081
- 0.975211284160614
- 0.9957301425933838
- 0.9582099986076354
- 0.970105049610138
- 0.9621811604499817
- 0.9696915602684021
- 0.9720695233345031
- 0.978507866859436
- 0.9966480803489685
- 0.9823737525939942
- 0.9739605259895324
- 0.9795957183837891
train_accuracy:
- 0.074
- 0.12
- 0.13
- 0.147
- 0.155
- 0.199
- 0.18
- 0.19
- 0.194
- 0.2
- 0.216
- 0.218
- 0.227
- 0.218
- 0.227
- 0.227
- 0.258
- 0.251
- 0.253
- 0.257
- 0.246
- 0.282
- 0.263
- 0.278
- 0.289
- 0.292
- 0.279
- 0.286
- 0.308
- 0.283
- 0.314
- 0.32
- 0.307
- 0.301
- 0.321
- 0.312
- 0.314
- 0.308
- 0.335
- 0.312
- 0.315
- 0.309
- 0.301
- 0.337
- 0.289
- 0.331
- 0.332
- 0.344
- 0.364
- 0.329
- 0.342
- 0.356
- 0.309
- 0.304
- 0.362
- 0.343
- 0.378
- 0.328
- 0.363
- 0.346
- 0.33
- 0.347
- 0.37
- 0.376
- 0.368
- 0.352
- 0.344
- 0.371
- 0.378
- 0.375
- 0.379
- 0.369
- 0.345
- 0.341
- 0.332
- 0.393
- 0.383
- 0.329
- 0.35
- 0.37
- 0.343
- 0.357
- 0.395
- 0.377
- 0.378
- 0.368
- 0.363
- 0.378
- 0.372
- 0.384
- 0.355
- 0.399
- 0.391
- 0.39
- 0.381
- 0.378
- 0.383
- 0.376
- 0.397
- 0.393
train_loss:
- 4.226
- 3.737
- 3.529
- 3.2
- 3.071
- 3.249
- 3.069
- 3.099
- 2.672
- 2.288
- 2.677
- 2.24
- 2.849
- 2.845
- 2.852
- 2.152
- 2.476
- 2.023
- 2.414
- 1.816
- 2.609
- 2.377
- 1.893
- 2.355
- 2.001
- 1.928
- 2.354
- 2.164
- 1.745
- 1.754
- 2.033
- 1.944
- 2.234
- 1.932
- 1.66
- 1.549
- 1.544
- 1.566
- 1.867
- 1.247
- 1.629
- 2.14
- 1.543
- 1.616
- 1.349
- 1.502
- 1.306
- 1.665
- 1.629
- 1.581
- 1.388
- 1.357
- 1.344
- 0.86
- 1.209
- 1.223
- 1.334
- 0.872
- 1.153
- 1.155
- 0.699
- 1.147
- 1.342
- 0.96
- 0.581
- 1.307
- 0.768
- 0.606
- 1.002
- 0.598
- 1.117
- 1.076
- 0.986
- 0.555
- 0.738
- 0.617
- 1.3
- 0.545
- 0.577
- 0.888
- 0.438
- 0.433
- 0.895
- 0.695
- 1.003
- 0.54
- 0.915
- 0.594
- 0.499
- 0.941
- 0.501
- 0.618
- 0.431
- 0.242
- 0.664
- 0.888
- 0.431
- 0.473
- 0.578
- 0.432
unequal: 0
verbose: 1
