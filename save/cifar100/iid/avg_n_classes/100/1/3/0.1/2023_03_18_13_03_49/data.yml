avg_train_accuracy: 0.414
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0883
- 0.1264
- 0.1444
- 0.1664
- 0.1768
- 0.1892
- 0.2096
- 0.2191
- 0.2269
- 0.2359
- 0.2413
- 0.242
- 0.2574
- 0.2566
- 0.2729
- 0.2714
- 0.2817
- 0.2811
- 0.2902
- 0.2971
- 0.3008
- 0.3096
- 0.305
- 0.3187
- 0.32
- 0.3153
- 0.3181
- 0.3208
- 0.3246
- 0.3393
- 0.3437
- 0.3414
- 0.3452
- 0.3496
- 0.3494
- 0.3526
- 0.3537
- 0.3664
- 0.3494
- 0.3526
- 0.3372
- 0.3568
- 0.3555
- 0.3602
- 0.3747
- 0.3643
- 0.3725
- 0.3614
- 0.3677
- 0.3766
- 0.3854
- 0.3829
- 0.3793
- 0.3887
- 0.3871
- 0.3906
- 0.388
- 0.3893
- 0.3896
- 0.392
- 0.3908
- 0.3931
- 0.387
- 0.3944
- 0.3922
- 0.3981
- 0.3957
- 0.3944
- 0.3949
- 0.3909
- 0.3853
- 0.3899
- 0.3903
- 0.4074
- 0.405
- 0.4043
- 0.4067
- 0.4078
- 0.4137
- 0.4012
- 0.416
- 0.4087
- 0.4144
- 0.4121
- 0.4134
- 0.42
- 0.4122
- 0.422
- 0.4186
- 0.4166
- 0.4194
- 0.415
- 0.4157
- 0.3989
- 0.4268
- 0.4235
- 0.4173
- 0.4123
- 0.4036
- 0.4224
test_loss_list:
- 1.6571792078018188
- 1.5621665000915528
- 1.500711166858673
- 1.4449894976615907
- 1.41976016998291
- 1.3780621433258056
- 1.339294147491455
- 1.3177846026420594
- 1.2967375612258911
- 1.2851149225234986
- 1.260359721183777
- 1.2608916091918945
- 1.2361079907417298
- 1.2155263018608093
- 1.1923494696617127
- 1.1862391448020935
- 1.1755046796798707
- 1.1715725803375243
- 1.1425682592391968
- 1.142285990715027
- 1.1249190616607665
- 1.1156794428825378
- 1.1127178049087525
- 1.0916704201698304
- 1.0908742880821227
- 1.1053052568435668
- 1.0927761936187743
- 1.0833004641532897
- 1.077748556137085
- 1.053138291835785
- 1.0413246130943299
- 1.04717675447464
- 1.0359338903427124
- 1.0460201764106751
- 1.0387117385864257
- 1.0313052892684937
- 1.0334637808799743
- 1.0103101587295533
- 1.0261302661895753
- 1.0142005729675292
- 1.0580707907676696
- 1.022606885433197
- 1.0141668391227723
- 1.0162831687927245
- 0.9931209921836853
- 1.0060906100273133
- 0.989332115650177
- 1.0146887254714967
- 1.003462073802948
- 0.9767769050598144
- 0.9700393748283386
- 0.9753069591522217
- 0.9842814779281617
- 0.9693832325935364
- 0.9745552468299866
- 0.9636883974075318
- 0.9872641372680664
- 0.975968177318573
- 0.975197548866272
- 0.9650176525115967
- 0.9728228640556336
- 0.9658285403251647
- 0.976081166267395
- 0.9626568055152893
- 0.9819805455207825
- 0.9647805845737457
- 0.9784341549873352
- 0.9859724903106689
- 0.9724685025215148
- 0.9656652545928955
- 0.9864641213417054
- 0.9780509543418884
- 0.9818298482894897
- 0.9498633766174316
- 0.9509190058708191
- 0.9682987904548646
- 0.9595726418495178
- 0.9587971329689026
- 0.9418170714378357
- 0.965870475769043
- 0.9339632892608642
- 0.961008837223053
- 0.9503276419639587
- 0.9526024842262268
- 0.9515158987045288
- 0.9414939284324646
- 0.9512854766845703
- 0.9468302750587463
- 0.9529140138626099
- 0.9489904570579529
- 0.9456554698944092
- 0.9605739164352417
- 0.9534865880012512
- 1.00032155752182
- 0.9467279171943664
- 0.9435296368598938
- 0.9520490097999573
- 0.9572659611701966
- 0.9856288504600524
- 0.947419102191925
train_accuracy:
- 0.084
- 0.109
- 0.122
- 0.152
- 0.151
- 0.184
- 0.201
- 0.198
- 0.186
- 0.215
- 0.244
- 0.25
- 0.243
- 0.218
- 0.236
- 0.273
- 0.275
- 0.244
- 0.253
- 0.296
- 0.292
- 0.277
- 0.293
- 0.327
- 0.296
- 0.279
- 0.3
- 0.318
- 0.33
- 0.315
- 0.314
- 0.292
- 0.343
- 0.303
- 0.313
- 0.367
- 0.333
- 0.334
- 0.336
- 0.354
- 0.331
- 0.358
- 0.343
- 0.373
- 0.33
- 0.353
- 0.377
- 0.364
- 0.366
- 0.344
- 0.361
- 0.39
- 0.333
- 0.341
- 0.398
- 0.356
- 0.347
- 0.362
- 0.393
- 0.353
- 0.379
- 0.348
- 0.365
- 0.384
- 0.351
- 0.393
- 0.358
- 0.354
- 0.364
- 0.358
- 0.368
- 0.357
- 0.367
- 0.385
- 0.417
- 0.413
- 0.42
- 0.378
- 0.388
- 0.392
- 0.366
- 0.385
- 0.38
- 0.405
- 0.383
- 0.423
- 0.379
- 0.437
- 0.42
- 0.389
- 0.364
- 0.393
- 0.391
- 0.378
- 0.374
- 0.406
- 0.385
- 0.404
- 0.392
- 0.414
train_loss:
- 4.214
- 3.768
- 3.584
- 3.457
- 3.117
- 3.28
- 3.174
- 3.079
- 2.99
- 2.68
- 2.703
- 2.298
- 2.746
- 2.795
- 2.647
- 2.695
- 2.156
- 2.446
- 2.38
- 2.302
- 2.421
- 2.401
- 2.397
- 1.979
- 2.016
- 1.636
- 2.072
- 2.181
- 1.737
- 2.005
- 2.103
- 1.601
- 1.82
- 1.315
- 2.047
- 1.529
- 1.796
- 1.763
- 1.315
- 1.467
- 1.089
- 1.597
- 1.731
- 1.331
- 1.82
- 1.379
- 1.293
- 0.909
- 1.161
- 1.72
- 1.32
- 1.137
- 1.306
- 1.26
- 0.883
- 1.056
- 0.952
- 1.081
- 0.754
- 0.889
- 1.01
- 0.685
- 1.593
- 0.784
- 0.876
- 0.587
- 0.617
- 0.406
- 1.209
- 1.484
- 0.913
- 1.662
- 1.006
- 1.027
- 0.648
- 0.76
- 0.426
- 0.91
- 0.754
- 1.212
- 0.801
- 0.939
- 0.562
- 0.616
- 0.385
- 0.504
- 0.755
- 0.503
- 0.371
- 0.52
- 0.622
- 0.396
- 1.053
- 0.554
- 0.468
- 0.548
- 0.759
- 0.968
- 0.474
- 0.485
unequal: 0
verbose: 1
