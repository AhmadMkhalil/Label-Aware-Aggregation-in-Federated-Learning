avg_train_accuracy: 0.372
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0835
- 0.1179
- 0.1491
- 0.1677
- 0.1806
- 0.1928
- 0.205
- 0.2155
- 0.2271
- 0.232
- 0.2462
- 0.2398
- 0.2605
- 0.264
- 0.2653
- 0.2731
- 0.2803
- 0.2746
- 0.2867
- 0.2925
- 0.2927
- 0.2926
- 0.3021
- 0.3017
- 0.3102
- 0.3161
- 0.3256
- 0.3239
- 0.3218
- 0.3301
- 0.3336
- 0.3335
- 0.322
- 0.3406
- 0.3415
- 0.343
- 0.3441
- 0.3368
- 0.3377
- 0.345
- 0.3549
- 0.3536
- 0.3577
- 0.3546
- 0.3631
- 0.3682
- 0.3642
- 0.3711
- 0.3708
- 0.3606
- 0.3627
- 0.3633
- 0.3708
- 0.3855
- 0.3794
- 0.3732
- 0.3788
- 0.3783
- 0.3772
- 0.3867
- 0.391
- 0.3829
- 0.3854
- 0.3785
- 0.3879
- 0.3757
- 0.3847
- 0.3765
- 0.3816
- 0.387
- 0.3927
- 0.3863
- 0.3903
- 0.3921
- 0.3962
- 0.4024
- 0.3999
- 0.3939
- 0.3945
- 0.393
- 0.4035
- 0.3936
- 0.4011
- 0.4019
- 0.4059
- 0.4021
- 0.4135
- 0.4015
- 0.4157
- 0.4039
- 0.406
- 0.4009
- 0.4065
- 0.4024
- 0.4085
- 0.4052
- 0.4091
- 0.4131
- 0.4153
- 0.4055
test_loss_list:
- 1.6474826860427856
- 1.539506607055664
- 1.4875831007957458
- 1.4457243967056275
- 1.4096143341064453
- 1.3801630425453186
- 1.3538416123390198
- 1.3268077301979064
- 1.3018376326560974
- 1.2854709434509277
- 1.256977252960205
- 1.2669431734085084
- 1.2399525475502013
- 1.2203074288368225
- 1.2169883489608764
- 1.1884124350547791
- 1.1731631088256835
- 1.185496187210083
- 1.1643043446540833
- 1.138249444961548
- 1.1463593673706054
- 1.1349063992500306
- 1.1182098364830018
- 1.1161776328086852
- 1.1016928744316101
- 1.1021976971626282
- 1.0756035017967225
- 1.065741674900055
- 1.0959099507331849
- 1.0707101440429687
- 1.0557524132728577
- 1.0537895131111146
- 1.0732258653640747
- 1.0470558404922485
- 1.0454773330688476
- 1.0418320822715759
- 1.0320701217651367
- 1.0582826495170594
- 1.0622070336341858
- 1.0395943450927734
- 1.021331262588501
- 1.015904998779297
- 1.0137439203262328
- 1.0191557812690735
- 1.0126889419555665
- 0.9901585638523102
- 1.0054522061347961
- 1.0051463794708253
- 0.9926571917533874
- 1.0139481043815612
- 1.0179720067977904
- 1.0087042737007141
- 0.9875464606285095
- 0.9778706502914428
- 0.9814530181884765
- 0.9969401812553406
- 0.9900019431114196
- 0.9816094040870667
- 0.9946071839332581
- 0.9720884323120117
- 0.9594182205200196
- 0.9820286083221436
- 0.9666813254356384
- 0.9928070974349975
- 0.9873237991333008
- 1.0064355945587158
- 0.9931113457679749
- 1.0199116158485413
- 0.9976589798927307
- 0.9820136666297913
- 0.975316858291626
- 0.9823336100578308
- 0.9797725558280945
- 0.98036630153656
- 0.973538339138031
- 0.9640327310562133
- 0.9712774968147277
- 0.9903646612167358
- 0.9793689751625061
- 0.9880637884140014
- 0.9688814091682434
- 0.9937199592590332
- 0.9613923048973083
- 0.9686378014087677
- 0.9608554816246033
- 0.9559028148651123
- 0.9398815131187439
- 0.9798515820503235
- 0.9491548752784729
- 0.976072096824646
- 0.9734142684936523
- 0.9817768502235412
- 0.9647352290153504
- 0.9769246339797973
- 0.9656354689598083
- 0.9629428970813751
- 0.9684373450279236
- 0.9631979608535767
- 0.9597640204429626
- 0.9866944241523743
train_accuracy:
- 0.1
- 0.116
- 0.13
- 0.136
- 0.146
- 0.172
- 0.16
- 0.188
- 0.218
- 0.209
- 0.266
- 0.225
- 0.204
- 0.244
- 0.207
- 0.23
- 0.27
- 0.255
- 0.304
- 0.296
- 0.234
- 0.301
- 0.316
- 0.244
- 0.267
- 0.31
- 0.292
- 0.336
- 0.322
- 0.294
- 0.28
- 0.263
- 0.271
- 0.322
- 0.279
- 0.283
- 0.305
- 0.305
- 0.262
- 0.284
- 0.355
- 0.328
- 0.318
- 0.343
- 0.374
- 0.368
- 0.328
- 0.29
- 0.302
- 0.296
- 0.355
- 0.384
- 0.327
- 0.376
- 0.393
- 0.381
- 0.325
- 0.332
- 0.354
- 0.349
- 0.4
- 0.328
- 0.331
- 0.33
- 0.345
- 0.323
- 0.401
- 0.319
- 0.327
- 0.418
- 0.407
- 0.405
- 0.36
- 0.377
- 0.418
- 0.373
- 0.425
- 0.367
- 0.412
- 0.318
- 0.421
- 0.342
- 0.408
- 0.395
- 0.403
- 0.354
- 0.431
- 0.337
- 0.418
- 0.346
- 0.383
- 0.381
- 0.35
- 0.397
- 0.363
- 0.408
- 0.385
- 0.423
- 0.412
- 0.372
train_loss:
- 4.179
- 3.77
- 3.536
- 3.383
- 3.309
- 3.229
- 2.978
- 3.092
- 3.027
- 2.933
- 2.832
- 2.522
- 2.676
- 2.618
- 2.483
- 2.612
- 2.495
- 2.228
- 2.345
- 2.564
- 2.457
- 2.149
- 2.035
- 2.135
- 2.359
- 2.142
- 2.125
- 1.937
- 1.815
- 1.977
- 2.045
- 1.801
- 1.799
- 1.82
- 1.693
- 1.512
- 1.693
- 1.25
- 2.009
- 1.315
- 1.734
- 1.564
- 1.22
- 1.507
- 1.389
- 1.846
- 1.064
- 1.626
- 1.166
- 0.781
- 1.544
- 1.592
- 1.322
- 1.206
- 1.215
- 0.817
- 1.481
- 0.862
- 1.253
- 0.965
- 1.265
- 1.137
- 0.696
- 0.433
- 0.847
- 0.55
- 0.934
- 0.507
- 1.355
- 0.702
- 1.049
- 0.619
- 0.844
- 1.014
- 0.608
- 0.574
- 0.41
- 0.73
- 0.346
- 1.04
- 0.301
- 0.646
- 0.733
- 1.435
- 1.052
- 0.627
- 0.53
- 0.617
- 0.341
- 0.616
- 0.652
- 0.334
- 0.471
- 0.56
- 0.296
- 0.763
- 0.397
- 0.314
- 0.499
- 1.042
unequal: 0
verbose: 1
