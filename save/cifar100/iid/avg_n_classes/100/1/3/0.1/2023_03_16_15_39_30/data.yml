avg_train_accuracy: 0.359
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0935
- 0.1285
- 0.1486
- 0.169
- 0.1784
- 0.1938
- 0.2019
- 0.2173
- 0.2229
- 0.2334
- 0.2373
- 0.2341
- 0.2486
- 0.2492
- 0.2512
- 0.2628
- 0.2714
- 0.2819
- 0.282
- 0.2893
- 0.2976
- 0.3101
- 0.3018
- 0.3125
- 0.3112
- 0.3183
- 0.3119
- 0.3257
- 0.3329
- 0.3194
- 0.3277
- 0.324
- 0.3321
- 0.3239
- 0.3352
- 0.3396
- 0.3318
- 0.3417
- 0.3438
- 0.3367
- 0.3591
- 0.3435
- 0.3578
- 0.3661
- 0.3735
- 0.3588
- 0.3717
- 0.3701
- 0.3543
- 0.3766
- 0.3644
- 0.3807
- 0.3782
- 0.3755
- 0.3705
- 0.3769
- 0.3873
- 0.3874
- 0.3878
- 0.3836
- 0.3757
- 0.3911
- 0.3928
- 0.3808
- 0.3924
- 0.3956
- 0.3879
- 0.3954
- 0.3878
- 0.3943
- 0.3876
- 0.3918
- 0.3881
- 0.3878
- 0.3912
- 0.3961
- 0.3937
- 0.3906
- 0.3928
- 0.4022
- 0.3979
- 0.3964
- 0.4012
- 0.3889
- 0.4022
- 0.4024
- 0.4053
- 0.4019
- 0.4088
- 0.4041
- 0.4048
- 0.3939
- 0.4076
- 0.4029
- 0.4064
- 0.4132
- 0.4145
- 0.4087
- 0.4123
- 0.405
test_loss_list:
- 1.6348720121383666
- 1.5380769610404967
- 1.4828350949287414
- 1.4375910949707031
- 1.4103810358047486
- 1.380896565914154
- 1.347699475288391
- 1.3283839917182922
- 1.2974668979644775
- 1.2846737718582153
- 1.2638272833824158
- 1.2719392275810242
- 1.2504489088058472
- 1.229047315120697
- 1.2324608826637269
- 1.2049366903305054
- 1.179605827331543
- 1.1609234404563904
- 1.1712348818778993
- 1.1527606964111328
- 1.1443265461921692
- 1.1233145451545716
- 1.1349413108825683
- 1.1201951956748963
- 1.1085956001281738
- 1.1099787878990173
- 1.1206570386886596
- 1.0804640793800353
- 1.0721434116363526
- 1.0977905869483948
- 1.07092524766922
- 1.0935902333259582
- 1.0721835446357728
- 1.089365735054016
- 1.0617006349563598
- 1.064091215133667
- 1.0690165448188782
- 1.0427671670913696
- 1.0382001137733459
- 1.0622610926628113
- 1.0180487275123595
- 1.0468180179595947
- 1.0169562292099
- 1.0150276374816896
- 0.9972260737419129
- 1.0254822945594788
- 1.0047987341880797
- 1.0037393879890442
- 1.0295123600959777
- 0.9962194204330445
- 1.02400315284729
- 0.9908870267868042
- 0.9907530236244202
- 0.998117311000824
- 1.011736705303192
- 0.9899299240112305
- 0.9834387540817261
- 0.9790615034103394
- 0.9771120727062226
- 0.9897740650177002
- 1.0070598888397218
- 0.9756962561607361
- 0.9679358148574829
- 0.9860209512710572
- 0.9773332571983337
- 0.9755502319335938
- 0.9895606279373169
- 0.9752368354797363
- 0.9993155193328858
- 0.9803131151199341
- 0.985286157131195
- 0.9797608137130738
- 0.9934621977806092
- 1.0050178337097169
- 0.9897299957275391
- 0.9814327931404114
- 0.988972716331482
- 0.9968102526664734
- 0.993069703578949
- 0.9736712217330933
- 0.9846782755851745
- 0.9903875660896301
- 0.9758546113967895
- 1.0004325008392334
- 0.9800222826004028
- 0.9754351687431335
- 0.9769881653785706
- 0.9775033187866211
- 0.97730473279953
- 0.9853514814376831
- 0.9776252770423889
- 0.9866708159446717
- 0.9665956807136535
- 0.9709800577163696
- 0.9745742058753968
- 0.9729032230377197
- 0.9847727799415589
- 0.9799881696701049
- 0.9728508627414704
- 0.9787382435798645
train_accuracy:
- 0.103
- 0.126
- 0.163
- 0.168
- 0.196
- 0.159
- 0.201
- 0.173
- 0.192
- 0.208
- 0.249
- 0.252
- 0.221
- 0.259
- 0.255
- 0.241
- 0.278
- 0.273
- 0.253
- 0.276
- 0.263
- 0.288
- 0.284
- 0.28
- 0.278
- 0.276
- 0.268
- 0.319
- 0.268
- 0.26
- 0.314
- 0.259
- 0.3
- 0.292
- 0.339
- 0.291
- 0.318
- 0.337
- 0.359
- 0.36
- 0.344
- 0.332
- 0.342
- 0.305
- 0.357
- 0.345
- 0.363
- 0.325
- 0.348
- 0.355
- 0.318
- 0.362
- 0.376
- 0.346
- 0.35
- 0.375
- 0.328
- 0.359
- 0.376
- 0.376
- 0.383
- 0.335
- 0.364
- 0.374
- 0.346
- 0.371
- 0.385
- 0.349
- 0.342
- 0.359
- 0.327
- 0.355
- 0.35
- 0.346
- 0.379
- 0.359
- 0.362
- 0.384
- 0.376
- 0.366
- 0.396
- 0.354
- 0.361
- 0.381
- 0.349
- 0.363
- 0.366
- 0.405
- 0.369
- 0.37
- 0.414
- 0.392
- 0.405
- 0.404
- 0.412
- 0.38
- 0.365
- 0.4
- 0.386
- 0.359
train_loss:
- 4.201
- 3.727
- 3.553
- 3.18
- 3.097
- 3.263
- 3.128
- 3.001
- 3.02
- 2.984
- 2.67
- 2.259
- 2.602
- 2.738
- 2.271
- 2.742
- 2.539
- 2.424
- 2.317
- 2.503
- 2.217
- 2.349
- 2.108
- 1.97
- 2.059
- 1.912
- 1.488
- 2.118
- 2.198
- 1.707
- 2.014
- 1.511
- 1.784
- 1.324
- 1.949
- 1.863
- 2.293
- 1.703
- 1.624
- 1.183
- 1.797
- 1.253
- 1.555
- 1.476
- 1.81
- 1.282
- 1.228
- 1.356
- 1.59
- 0.997
- 1.052
- 1.626
- 1.267
- 0.856
- 0.939
- 1.687
- 1.271
- 1.307
- 0.855
- 1.317
- 1.248
- 1.395
- 1.305
- 0.794
- 1.028
- 1.096
- 0.739
- 0.745
- 0.469
- 0.834
- 1.11
- 0.867
- 0.485
- 0.347
- 0.833
- 0.715
- 0.724
- 0.404
- 1.008
- 0.611
- 0.398
- 0.389
- 0.859
- 1.071
- 0.585
- 0.648
- 0.383
- 0.649
- 0.288
- 0.504
- 0.908
- 1.313
- 0.546
- 0.783
- 0.369
- 0.334
- 0.173
- 0.46
- 0.519
- 0.583
unequal: 0
verbose: 1
