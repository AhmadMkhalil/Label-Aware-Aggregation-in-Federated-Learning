avg_train_accuracy: 0.433
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0854
- 0.1203
- 0.1488
- 0.1636
- 0.1696
- 0.1889
- 0.2095
- 0.2197
- 0.2189
- 0.2325
- 0.2323
- 0.2433
- 0.2518
- 0.2588
- 0.2657
- 0.2632
- 0.2748
- 0.2852
- 0.284
- 0.2794
- 0.2862
- 0.2996
- 0.2916
- 0.3032
- 0.3105
- 0.3106
- 0.311
- 0.3153
- 0.3208
- 0.3341
- 0.3222
- 0.3379
- 0.3507
- 0.3354
- 0.3537
- 0.34
- 0.3481
- 0.3559
- 0.3572
- 0.3614
- 0.3682
- 0.35
- 0.3527
- 0.3637
- 0.3722
- 0.3692
- 0.3728
- 0.357
- 0.3762
- 0.3629
- 0.3765
- 0.3648
- 0.3812
- 0.3846
- 0.3823
- 0.3816
- 0.3675
- 0.3872
- 0.393
- 0.3896
- 0.3954
- 0.3982
- 0.3975
- 0.406
- 0.3935
- 0.3996
- 0.3969
- 0.3985
- 0.3948
- 0.3886
- 0.4117
- 0.3975
- 0.4006
- 0.412
- 0.4033
- 0.4095
- 0.404
- 0.4065
- 0.4048
- 0.4035
- 0.3986
- 0.4049
- 0.398
- 0.4115
- 0.4036
- 0.4108
- 0.4068
- 0.4036
- 0.4043
- 0.4187
- 0.4149
- 0.4114
- 0.4133
- 0.4109
- 0.4185
- 0.4176
- 0.4222
- 0.4209
- 0.423
- 0.4232
test_loss_list:
- 1.655940124988556
- 1.557861762046814
- 1.485480499267578
- 1.4453407049179077
- 1.4179483580589294
- 1.3813217639923097
- 1.3476221942901612
- 1.3250718307495117
- 1.3008107924461365
- 1.2740888905525207
- 1.2693658447265626
- 1.254468162059784
- 1.2359284329414368
- 1.2125620174407958
- 1.211614010334015
- 1.2077902269363403
- 1.1841652989387512
- 1.168761019706726
- 1.1668960499763488
- 1.1676284980773926
- 1.1526558160781861
- 1.142397174835205
- 1.1457104587554932
- 1.124619150161743
- 1.1205407404899597
- 1.1035211706161498
- 1.1074386167526244
- 1.107855463027954
- 1.0870806550979615
- 1.0714360761642456
- 1.074081437587738
- 1.0566446566581726
- 1.0266318535804748
- 1.0674974250793456
- 1.0265857934951783
- 1.052482352256775
- 1.028174841403961
- 1.020322518348694
- 1.0195500612258912
- 1.0125522303581238
- 1.0095667409896851
- 1.0349417662620544
- 1.0344972491264344
- 1.0082298159599303
- 0.9855699872970581
- 0.9990620017051697
- 0.9919868659973144
- 1.019022455215454
- 1.002869222164154
- 1.0015739107131958
- 0.9814354586601257
- 1.0066434454917907
- 0.9779114627838135
- 0.9768840599060059
- 0.9787116622924805
- 0.9819636416435241
- 1.012491433620453
- 0.980297884941101
- 0.9706542730331421
- 0.9675643491744995
- 0.953724570274353
- 0.9561953210830688
- 0.9706310367584229
- 0.9479079151153564
- 0.9655749940872193
- 0.9561510491371155
- 0.9586225867271423
- 0.9632887434959412
- 0.9807386994361877
- 0.9805270290374756
- 0.9444385862350464
- 0.9644302535057068
- 0.9565695118904114
- 0.9494060182571411
- 0.9446677994728089
- 0.9485578680038452
- 0.9686427736282348
- 0.9726689696311951
- 0.972446722984314
- 0.9652409410476684
- 0.9783017992973327
- 0.9684913063049316
- 0.9732401180267334
- 0.9505098652839661
- 0.9696492719650268
- 0.956136965751648
- 0.9703624725341797
- 0.9829160118103027
- 0.9740253973007202
- 0.951922082901001
- 0.9620539903640747
- 0.9655932760238648
- 0.9584336447715759
- 0.973118588924408
- 0.9592448139190674
- 0.9531122922897339
- 0.9444651079177856
- 0.9312258911132812
- 0.9494296717643738
- 0.9550724148750305
train_accuracy:
- 0.091
- 0.104
- 0.114
- 0.154
- 0.165
- 0.151
- 0.177
- 0.221
- 0.183
- 0.226
- 0.214
- 0.208
- 0.211
- 0.248
- 0.282
- 0.242
- 0.243
- 0.28
- 0.298
- 0.258
- 0.246
- 0.316
- 0.249
- 0.267
- 0.282
- 0.277
- 0.264
- 0.277
- 0.285
- 0.284
- 0.302
- 0.293
- 0.341
- 0.278
- 0.308
- 0.322
- 0.34
- 0.314
- 0.314
- 0.323
- 0.36
- 0.321
- 0.327
- 0.338
- 0.378
- 0.344
- 0.324
- 0.316
- 0.337
- 0.345
- 0.378
- 0.318
- 0.358
- 0.373
- 0.347
- 0.341
- 0.331
- 0.38
- 0.352
- 0.347
- 0.391
- 0.37
- 0.34
- 0.396
- 0.351
- 0.374
- 0.388
- 0.377
- 0.37
- 0.341
- 0.424
- 0.356
- 0.403
- 0.422
- 0.351
- 0.429
- 0.354
- 0.342
- 0.369
- 0.351
- 0.348
- 0.366
- 0.38
- 0.382
- 0.361
- 0.395
- 0.374
- 0.374
- 0.377
- 0.394
- 0.387
- 0.405
- 0.354
- 0.421
- 0.429
- 0.398
- 0.375
- 0.376
- 0.379
- 0.433
train_loss:
- 4.197
- 3.794
- 3.577
- 3.481
- 3.31
- 3.208
- 3.033
- 3.075
- 3.126
- 2.884
- 2.741
- 2.685
- 2.735
- 2.51
- 2.568
- 2.364
- 2.697
- 2.211
- 2.206
- 2.053
- 2.247
- 1.903
- 1.91
- 2.417
- 1.897
- 2.301
- 1.697
- 1.783
- 2.261
- 2.148
- 1.947
- 2.24
- 1.894
- 1.805
- 1.792
- 1.886
- 1.678
- 1.534
- 1.483
- 2.018
- 1.627
- 1.571
- 1.164
- 1.493
- 1.609
- 1.605
- 1.492
- 1.007
- 1.268
- 1.216
- 1.289
- 1.602
- 0.974
- 1.0
- 1.212
- 1.075
- 1.28
- 1.335
- 1.302
- 1.055
- 1.585
- 1.31
- 1.006
- 1.045
- 0.89
- 1.127
- 0.903
- 0.785
- 0.504
- 0.712
- 0.98
- 1.011
- 0.871
- 0.697
- 0.902
- 0.494
- 0.887
- 0.496
- 0.767
- 0.684
- 0.629
- 0.798
- 0.56
- 1.014
- 0.501
- 0.652
- 0.352
- 0.25
- 0.633
- 0.488
- 0.297
- 1.242
- 0.449
- 0.737
- 0.791
- 0.795
- 0.642
- 0.632
- 0.366
- 0.573
unequal: 0
verbose: 1
