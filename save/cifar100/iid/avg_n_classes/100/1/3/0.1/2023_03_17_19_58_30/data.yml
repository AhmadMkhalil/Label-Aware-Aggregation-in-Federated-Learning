avg_train_accuracy: 0.391
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0813
- 0.1242
- 0.1421
- 0.1707
- 0.1841
- 0.1951
- 0.2056
- 0.2065
- 0.2248
- 0.2321
- 0.2457
- 0.2487
- 0.253
- 0.2563
- 0.2644
- 0.2638
- 0.2692
- 0.2738
- 0.2916
- 0.2961
- 0.2941
- 0.3025
- 0.311
- 0.3119
- 0.3182
- 0.3286
- 0.3259
- 0.3321
- 0.3354
- 0.339
- 0.3246
- 0.3331
- 0.339
- 0.3415
- 0.3493
- 0.3462
- 0.3409
- 0.3542
- 0.3561
- 0.36
- 0.3489
- 0.3668
- 0.3605
- 0.3622
- 0.3766
- 0.3719
- 0.3787
- 0.3771
- 0.3765
- 0.37
- 0.384
- 0.377
- 0.3776
- 0.3778
- 0.371
- 0.3755
- 0.3822
- 0.3881
- 0.3891
- 0.3848
- 0.3895
- 0.3869
- 0.3989
- 0.3919
- 0.3882
- 0.392
- 0.3877
- 0.3877
- 0.4015
- 0.3909
- 0.3899
- 0.4
- 0.3948
- 0.3944
- 0.3873
- 0.3968
- 0.3881
- 0.4048
- 0.411
- 0.4136
- 0.4166
- 0.4147
- 0.4092
- 0.4039
- 0.4207
- 0.406
- 0.4142
- 0.4092
- 0.414
- 0.4127
- 0.4159
- 0.411
- 0.4103
- 0.4163
- 0.4303
- 0.4212
- 0.4182
- 0.4167
- 0.4186
- 0.4321
test_loss_list:
- 1.6781776332855225
- 1.5593029499053954
- 1.5043454265594483
- 1.4439156579971313
- 1.409411895275116
- 1.3775330400466919
- 1.35803697347641
- 1.3498038148880005
- 1.3111258840560913
- 1.2870364904403686
- 1.2620467495918275
- 1.260145468711853
- 1.2376080441474915
- 1.2371717977523804
- 1.2139073491096497
- 1.2211496448516845
- 1.1882530665397644
- 1.1948986744880676
- 1.1551276636123657
- 1.1415750312805175
- 1.1560646510124206
- 1.1206517314910889
- 1.1044033670425415
- 1.102873182296753
- 1.0881173968315125
- 1.07408527135849
- 1.0899904203414916
- 1.0697382664680481
- 1.0609149551391601
- 1.0528323793411254
- 1.0883408570289612
- 1.0764900946617126
- 1.0568996286392212
- 1.0457304310798645
- 1.040908501148224
- 1.046940371990204
- 1.0488877177238465
- 1.0157760047912598
- 1.0184902262687683
- 1.0210226392745971
- 1.0354392528533936
- 0.990273904800415
- 1.00573264837265
- 0.9961046814918518
- 0.9854907011985778
- 0.9914987778663635
- 0.9879961442947388
- 0.9862883806228637
- 0.9856376409530639
- 0.9939579463005066
- 0.9772868824005126
- 0.9916943597793579
- 0.9925268459320068
- 0.9947061491012573
- 1.0154928874969482
- 1.002129259109497
- 0.9911433053016663
- 0.9807341301441193
- 0.9744848179817199
- 0.9915044867992401
- 0.9749948477745056
- 0.988557505607605
- 0.9576952314376831
- 0.9777843546867371
- 0.9856427073478699
- 0.9681334257125854
- 0.9872630667686463
- 0.9905505585670471
- 0.9758046984672546
- 0.9904747676849365
- 0.9979215312004089
- 0.9720362257957459
- 0.9836848378181458
- 0.982013463973999
- 0.9867436957359313
- 0.9717944931983947
- 0.9960590481758118
- 0.9612604475021362
- 0.9476111769676209
- 0.9499510645866394
- 0.9422675299644471
- 0.9574182057380676
- 0.9648168420791626
- 0.9731173896789551
- 0.9498370313644409
- 0.965723512172699
- 0.9574747860431672
- 0.963472511768341
- 0.9561112999916077
- 0.9685986876487732
- 0.9619471287727356
- 0.9638772082328796
- 0.9645212984085083
- 0.9578369879722595
- 0.9396250557899475
- 0.9460990190505981
- 0.9618979835510254
- 0.9654462027549744
- 0.9543550157546997
- 0.9449330115318298
train_accuracy:
- 0.078
- 0.123
- 0.145
- 0.13
- 0.155
- 0.161
- 0.175
- 0.181
- 0.221
- 0.179
- 0.207
- 0.216
- 0.254
- 0.25
- 0.242
- 0.261
- 0.247
- 0.272
- 0.287
- 0.266
- 0.244
- 0.269
- 0.29
- 0.285
- 0.294
- 0.294
- 0.295
- 0.292
- 0.302
- 0.314
- 0.281
- 0.308
- 0.304
- 0.309
- 0.316
- 0.315
- 0.331
- 0.354
- 0.32
- 0.347
- 0.336
- 0.338
- 0.352
- 0.316
- 0.348
- 0.345
- 0.35
- 0.386
- 0.348
- 0.327
- 0.346
- 0.383
- 0.34
- 0.338
- 0.342
- 0.346
- 0.358
- 0.345
- 0.356
- 0.348
- 0.367
- 0.376
- 0.373
- 0.347
- 0.361
- 0.377
- 0.376
- 0.366
- 0.392
- 0.382
- 0.357
- 0.364
- 0.37
- 0.388
- 0.384
- 0.38
- 0.373
- 0.367
- 0.383
- 0.396
- 0.381
- 0.369
- 0.386
- 0.388
- 0.362
- 0.382
- 0.369
- 0.405
- 0.392
- 0.394
- 0.379
- 0.393
- 0.424
- 0.385
- 0.373
- 0.404
- 0.39
- 0.407
- 0.393
- 0.391
train_loss:
- 4.227
- 3.778
- 3.284
- 3.459
- 3.317
- 3.239
- 2.9
- 2.553
- 3.037
- 3.013
- 2.766
- 2.34
- 2.593
- 2.141
- 2.142
- 1.943
- 2.65
- 1.718
- 2.443
- 2.546
- 2.424
- 2.439
- 1.927
- 2.119
- 2.168
- 2.34
- 1.823
- 2.088
- 1.833
- 1.822
- 1.389
- 1.673
- 1.204
- 1.998
- 1.77
- 1.144
- 1.958
- 2.17
- 1.004
- 1.849
- 1.61
- 1.623
- 1.796
- 1.756
- 0.945
- 1.603
- 1.498
- 1.543
- 0.772
- 1.406
- 1.328
- 1.218
- 1.0
- 0.692
- 1.377
- 0.882
- 1.283
- 0.751
- 0.728
- 0.562
- 1.367
- 1.431
- 0.531
- 0.327
- 1.294
- 0.967
- 0.564
- 0.948
- 1.051
- 0.606
- 0.734
- 0.484
- 0.502
- 1.466
- 0.839
- 1.153
- 0.651
- 1.241
- 0.733
- 0.693
- 0.433
- 0.234
- 0.54
- 0.873
- 0.28
- 0.873
- 0.24
- 1.118
- 0.635
- 0.485
- 0.664
- 0.786
- 1.074
- 0.761
- 0.272
- 0.452
- 0.588
- 0.575
- 0.407
- 0.228
unequal: 0
verbose: 1
