avg_train_accuracy: 0.418
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0814
- 0.1261
- 0.1556
- 0.1612
- 0.183
- 0.1912
- 0.1919
- 0.2138
- 0.2243
- 0.2294
- 0.229
- 0.2434
- 0.2581
- 0.2609
- 0.2645
- 0.2706
- 0.2794
- 0.2819
- 0.2915
- 0.291
- 0.2958
- 0.2954
- 0.3115
- 0.3105
- 0.3235
- 0.3202
- 0.3216
- 0.3237
- 0.3308
- 0.325
- 0.3355
- 0.3348
- 0.334
- 0.3475
- 0.3477
- 0.3393
- 0.3506
- 0.3367
- 0.3415
- 0.351
- 0.3561
- 0.3588
- 0.3623
- 0.3525
- 0.3636
- 0.3601
- 0.3715
- 0.3716
- 0.3779
- 0.3736
- 0.3791
- 0.3733
- 0.3797
- 0.3851
- 0.3832
- 0.3829
- 0.3856
- 0.3859
- 0.3834
- 0.388
- 0.3876
- 0.3967
- 0.3968
- 0.3973
- 0.3921
- 0.3891
- 0.4028
- 0.4026
- 0.4027
- 0.4005
- 0.4119
- 0.412
- 0.4032
- 0.4092
- 0.4003
- 0.3985
- 0.4019
- 0.4002
- 0.4074
- 0.4068
- 0.4101
- 0.4182
- 0.4164
- 0.4229
- 0.4159
- 0.4174
- 0.4212
- 0.3943
- 0.4146
- 0.4124
- 0.4199
- 0.4157
- 0.4133
- 0.4162
- 0.422
- 0.4142
- 0.4254
- 0.4219
- 0.4194
- 0.4193
test_loss_list:
- 1.6772039604187012
- 1.5554657983779907
- 1.4893081998825073
- 1.4552958130836486
- 1.4111290287971496
- 1.3861679387092591
- 1.374855043888092
- 1.3277760219573975
- 1.312578523159027
- 1.3085765767097473
- 1.289443278312683
- 1.2509637403488159
- 1.230626518726349
- 1.2244750690460204
- 1.2115607357025147
- 1.189598252773285
- 1.1758474063873292
- 1.1712115931510925
- 1.1521106386184692
- 1.1430674695968628
- 1.142573914527893
- 1.1289673304557801
- 1.1028541541099548
- 1.1023459839820862
- 1.0820352125167847
- 1.090523703098297
- 1.090416271686554
- 1.0897308230400085
- 1.090046889781952
- 1.0826163601875305
- 1.0808937406539918
- 1.069917583465576
- 1.059352250099182
- 1.0462395071983337
- 1.0458972907066346
- 1.0576833963394165
- 1.044383099079132
- 1.065314483642578
- 1.0423237371444702
- 1.0344436478614807
- 1.0227526664733886
- 1.01174821972847
- 1.0094274806976318
- 1.0322439360618592
- 1.0034103631973266
- 1.0260260772705079
- 0.9977612948417663
- 0.9964349031448364
- 0.9797579216957092
- 0.9785241889953613
- 0.9745905017852783
- 0.9823850345611572
- 0.9728113508224487
- 0.97023104429245
- 0.9757338047027588
- 0.9656938314437866
- 0.967687726020813
- 0.9728591465950012
- 0.9761121916770935
- 0.9591299366950988
- 0.9718955481052398
- 0.9517599034309387
- 0.9521046710014344
- 0.9681476616859436
- 0.9777395629882812
- 0.9801685237884521
- 0.9539083981513977
- 0.9496533989906311
- 0.9460304284095764
- 0.9537041354179382
- 0.9408251571655274
- 0.9416107034683228
- 0.9534036564826965
- 0.9534178161621094
- 0.9758150291442871
- 0.9722499394416809
- 0.96263103723526
- 0.9655752539634704
- 0.9497359251976013
- 0.9402642858028412
- 0.94946932554245
- 0.9402191710472106
- 0.9435651898384094
- 0.9404961490631103
- 0.9329930877685547
- 0.9388532698154449
- 0.9332153582572937
- 0.9716710638999939
- 0.9356829559803009
- 0.9433871746063233
- 0.9375043892860413
- 0.947069730758667
- 0.9504630374908447
- 0.9501272821426392
- 0.9407207250595093
- 0.9519169902801514
- 0.9437417364120484
- 0.941819498538971
- 0.9339547204971314
- 0.9372249329090119
train_accuracy:
- 0.078
- 0.11
- 0.175
- 0.162
- 0.158
- 0.206
- 0.209
- 0.205
- 0.193
- 0.192
- 0.227
- 0.2
- 0.248
- 0.208
- 0.253
- 0.265
- 0.255
- 0.273
- 0.244
- 0.285
- 0.254
- 0.28
- 0.327
- 0.301
- 0.316
- 0.268
- 0.32
- 0.275
- 0.281
- 0.308
- 0.269
- 0.313
- 0.327
- 0.306
- 0.302
- 0.326
- 0.329
- 0.322
- 0.28
- 0.339
- 0.344
- 0.306
- 0.344
- 0.343
- 0.364
- 0.331
- 0.33
- 0.354
- 0.352
- 0.393
- 0.361
- 0.348
- 0.387
- 0.373
- 0.344
- 0.329
- 0.372
- 0.328
- 0.362
- 0.374
- 0.381
- 0.402
- 0.377
- 0.366
- 0.359
- 0.374
- 0.341
- 0.37
- 0.364
- 0.341
- 0.394
- 0.375
- 0.376
- 0.361
- 0.371
- 0.337
- 0.392
- 0.372
- 0.397
- 0.417
- 0.343
- 0.395
- 0.383
- 0.373
- 0.406
- 0.416
- 0.395
- 0.426
- 0.4
- 0.39
- 0.417
- 0.428
- 0.436
- 0.398
- 0.41
- 0.395
- 0.376
- 0.397
- 0.449
- 0.418
train_loss:
- 4.228
- 3.766
- 3.612
- 3.281
- 3.134
- 3.07
- 2.67
- 3.105
- 2.713
- 2.313
- 2.942
- 2.892
- 2.901
- 2.149
- 2.566
- 2.606
- 2.5
- 2.202
- 2.671
- 2.434
- 2.238
- 2.378
- 2.208
- 1.925
- 2.036
- 1.963
- 1.63
- 1.642
- 1.856
- 1.407
- 1.481
- 1.98
- 2.23
- 1.307
- 1.543
- 1.846
- 1.323
- 0.924
- 2.093
- 1.917
- 1.592
- 1.661
- 1.673
- 1.173
- 1.745
- 1.034
- 1.385
- 1.338
- 1.867
- 1.752
- 1.566
- 1.43
- 1.35
- 1.211
- 1.07
- 1.456
- 1.044
- 1.05
- 0.815
- 1.24
- 1.366
- 1.197
- 1.047
- 0.643
- 0.471
- 0.899
- 1.187
- 1.162
- 1.042
- 0.998
- 0.604
- 0.876
- 0.777
- 0.607
- 0.384
- 0.811
- 1.099
- 0.937
- 0.725
- 1.04
- 0.645
- 0.555
- 0.741
- 0.524
- 1.159
- 0.697
- 0.448
- 0.748
- 0.804
- 0.748
- 0.533
- 0.555
- 0.303
- 0.76
- 0.641
- 0.552
- 0.488
- 0.35
- 0.385
- 0.448
unequal: 0
verbose: 1
