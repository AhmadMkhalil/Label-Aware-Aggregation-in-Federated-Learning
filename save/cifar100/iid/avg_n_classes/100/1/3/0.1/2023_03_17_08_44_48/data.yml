avg_train_accuracy: 0.425
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0833
- 0.1198
- 0.1449
- 0.1534
- 0.1775
- 0.182
- 0.1811
- 0.2019
- 0.2182
- 0.221
- 0.2274
- 0.2353
- 0.2375
- 0.2481
- 0.2668
- 0.2582
- 0.2592
- 0.2705
- 0.2821
- 0.2819
- 0.2864
- 0.2928
- 0.3002
- 0.3129
- 0.3091
- 0.3098
- 0.3171
- 0.3107
- 0.3258
- 0.3231
- 0.3251
- 0.3268
- 0.3294
- 0.3426
- 0.3425
- 0.3527
- 0.3492
- 0.3474
- 0.3524
- 0.3381
- 0.352
- 0.3503
- 0.3635
- 0.3634
- 0.3591
- 0.3612
- 0.3608
- 0.3676
- 0.363
- 0.3596
- 0.3727
- 0.3685
- 0.3632
- 0.3767
- 0.3756
- 0.3865
- 0.3862
- 0.3736
- 0.3807
- 0.378
- 0.3689
- 0.3867
- 0.3905
- 0.3914
- 0.3836
- 0.3915
- 0.3901
- 0.3936
- 0.3988
- 0.3933
- 0.3907
- 0.3986
- 0.3896
- 0.3952
- 0.3964
- 0.396
- 0.3957
- 0.3942
- 0.4028
- 0.4063
- 0.4039
- 0.3973
- 0.4088
- 0.392
- 0.407
- 0.4087
- 0.4119
- 0.4094
- 0.41
- 0.4152
- 0.4058
- 0.4092
- 0.404
- 0.4148
- 0.4169
- 0.4144
- 0.4161
- 0.418
- 0.4059
- 0.4214
test_loss_list:
- 1.674155321121216
- 1.5596868777275086
- 1.4923013162612915
- 1.4696454358100892
- 1.4160494017601013
- 1.401466143131256
- 1.3937874841690063
- 1.3544658350944518
- 1.3102185702323914
- 1.3110714888572692
- 1.2840496921539306
- 1.2704929614067078
- 1.2726056718826293
- 1.2409534764289856
- 1.2133779501914979
- 1.219131932258606
- 1.2246417498588562
- 1.1955415081977845
- 1.1727338576316833
- 1.1676402473449707
- 1.1484157299995423
- 1.1453867888450622
- 1.1364483761787414
- 1.104574408531189
- 1.0975159740447997
- 1.1033334016799927
- 1.0916593408584594
- 1.098815722465515
- 1.0785520315170287
- 1.0768192028999328
- 1.0786420512199402
- 1.071580548286438
- 1.0715201544761657
- 1.048411920070648
- 1.048701696395874
- 1.032209951877594
- 1.030308620929718
- 1.0249163484573365
- 1.0208949637413025
- 1.0532222747802735
- 1.0223119735717774
- 1.0265535831451416
- 1.0053947710990905
- 1.010545427799225
- 1.018355610370636
- 1.011621870994568
- 1.0110988402366639
- 0.9996529769897461
- 1.005457808971405
- 1.0194077920913696
- 0.994380750656128
- 0.9968916463851929
- 1.0063078486919403
- 0.9836597192287445
- 0.9915976786613464
- 0.9707384610176086
- 0.9771592140197753
- 0.9993299984931946
- 0.9883260631561279
- 0.9741253399848938
- 1.0249707460403443
- 0.9783714175224304
- 0.968430962562561
- 0.9729919898509979
- 0.9907830214500427
- 0.9683796381950378
- 0.9583494126796722
- 0.9602658605575561
- 0.9600575017929077
- 0.9760792064666748
- 0.9691540884971619
- 0.9629092741012574
- 0.9737136042118073
- 0.9783621883392334
- 0.9651229298114776
- 0.9707727551460266
- 0.9756419146060944
- 0.97609290599823
- 0.9626696455478668
- 0.9583608543872834
- 0.9629423487186431
- 0.9659228336811065
- 0.9451297545433044
- 0.9848044049739838
- 0.9600118899345398
- 0.9564421772956848
- 0.9467933356761933
- 0.9651009106636047
- 0.9688343858718872
- 0.9475146257877349
- 0.9651826608181
- 0.9617533898353576
- 0.9609550631046295
- 0.9484677743911744
- 0.9538743793964386
- 0.9480727851390839
- 0.959768283367157
- 0.9500618314743042
- 0.9743536007404328
- 0.9537345743179322
train_accuracy:
- 0.102
- 0.09
- 0.114
- 0.123
- 0.182
- 0.164
- 0.162
- 0.19
- 0.181
- 0.201
- 0.23
- 0.223
- 0.239
- 0.249
- 0.257
- 0.259
- 0.252
- 0.277
- 0.243
- 0.282
- 0.244
- 0.301
- 0.296
- 0.273
- 0.266
- 0.305
- 0.308
- 0.265
- 0.323
- 0.328
- 0.272
- 0.27
- 0.329
- 0.324
- 0.337
- 0.306
- 0.348
- 0.317
- 0.316
- 0.289
- 0.348
- 0.345
- 0.317
- 0.376
- 0.36
- 0.358
- 0.311
- 0.363
- 0.322
- 0.334
- 0.369
- 0.383
- 0.319
- 0.33
- 0.325
- 0.346
- 0.386
- 0.374
- 0.391
- 0.373
- 0.364
- 0.379
- 0.346
- 0.353
- 0.381
- 0.39
- 0.326
- 0.352
- 0.404
- 0.39
- 0.366
- 0.401
- 0.396
- 0.376
- 0.397
- 0.378
- 0.36
- 0.389
- 0.333
- 0.365
- 0.363
- 0.391
- 0.367
- 0.383
- 0.411
- 0.393
- 0.37
- 0.416
- 0.411
- 0.353
- 0.4
- 0.403
- 0.414
- 0.382
- 0.372
- 0.355
- 0.373
- 0.381
- 0.401
- 0.425
train_loss:
- 4.248
- 3.773
- 3.581
- 3.132
- 3.38
- 2.834
- 2.489
- 3.189
- 3.114
- 2.326
- 2.914
- 2.691
- 2.253
- 2.498
- 2.668
- 2.119
- 1.77
- 2.632
- 2.088
- 2.187
- 2.523
- 2.522
- 1.897
- 2.417
- 2.119
- 2.027
- 1.705
- 1.817
- 2.124
- 1.695
- 1.549
- 2.185
- 2.062
- 2.003
- 1.697
- 1.712
- 1.773
- 1.396
- 1.793
- 1.319
- 1.486
- 1.719
- 1.44
- 1.168
- 1.381
- 1.479
- 1.21
- 0.983
- 1.652
- 1.49
- 1.416
- 1.201
- 1.321
- 1.233
- 1.034
- 1.312
- 0.911
- 1.231
- 0.652
- 1.883
- 1.212
- 0.597
- 0.845
- 1.017
- 0.88
- 1.004
- 1.102
- 0.682
- 0.534
- 1.184
- 1.123
- 0.443
- 0.757
- 1.023
- 0.821
- 0.835
- 0.486
- 0.763
- 0.899
- 0.86
- 0.533
- 1.491
- 0.678
- 0.939
- 0.5
- 0.957
- 0.495
- 0.334
- 0.193
- 0.704
- 0.84
- 0.709
- 0.697
- 0.417
- 0.698
- 0.537
- 0.426
- 0.328
- 0.679
- 0.303
unequal: 0
verbose: 1
