avg_train_accuracy: 0.401
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0869
- 0.1221
- 0.1436
- 0.1661
- 0.1767
- 0.1938
- 0.2039
- 0.2227
- 0.226
- 0.2367
- 0.2415
- 0.2445
- 0.2553
- 0.2592
- 0.2625
- 0.2628
- 0.2784
- 0.2877
- 0.2826
- 0.2821
- 0.2734
- 0.2973
- 0.3011
- 0.2854
- 0.3031
- 0.3088
- 0.3197
- 0.3232
- 0.3159
- 0.3305
- 0.3207
- 0.3382
- 0.3321
- 0.337
- 0.3409
- 0.3223
- 0.3476
- 0.3462
- 0.3454
- 0.3376
- 0.3512
- 0.3565
- 0.3643
- 0.3613
- 0.3638
- 0.3684
- 0.378
- 0.3721
- 0.3548
- 0.3609
- 0.3697
- 0.3745
- 0.3786
- 0.3655
- 0.378
- 0.3838
- 0.378
- 0.3798
- 0.3837
- 0.3888
- 0.389
- 0.3859
- 0.3935
- 0.3821
- 0.3919
- 0.3991
- 0.3866
- 0.3811
- 0.3903
- 0.3863
- 0.3954
- 0.4034
- 0.401
- 0.3947
- 0.3993
- 0.4055
- 0.3865
- 0.3986
- 0.4038
- 0.3985
- 0.4052
- 0.4042
- 0.3946
- 0.4057
- 0.4009
- 0.397
- 0.4083
- 0.4066
- 0.4175
- 0.4067
- 0.4129
- 0.4138
- 0.4088
- 0.4105
- 0.4178
- 0.4193
- 0.4054
- 0.4199
- 0.4152
- 0.4095
test_loss_list:
- 1.6671706342697143
- 1.5538577723503113
- 1.4972918963432311
- 1.4412275743484497
- 1.4221721720695495
- 1.3882293152809142
- 1.3510749888420106
- 1.317814428806305
- 1.3153466153144837
- 1.2798520231246948
- 1.2729862332344055
- 1.2566913318634034
- 1.2338505864143372
- 1.2252226185798645
- 1.2132233953475953
- 1.219638729095459
- 1.1846199345588684
- 1.1595373582839965
- 1.1717122268676758
- 1.1629200172424317
- 1.1894093942642212
- 1.1369135618209838
- 1.12158029794693
- 1.1574374556541442
- 1.116659529209137
- 1.1080373191833497
- 1.0829374766349793
- 1.074370355606079
- 1.1065145277976989
- 1.0605711317062378
- 1.0842066049575805
- 1.049345815181732
- 1.0685908913612365
- 1.0548304724693298
- 1.0514809155464173
- 1.0895464658737182
- 1.0354191994667052
- 1.0417045450210571
- 1.047540509700775
- 1.065176749229431
- 1.0284721064567566
- 1.015926146507263
- 1.0066550135612489
- 1.021734175682068
- 1.0059144806861877
- 0.9969307160377503
- 0.9826551151275634
- 0.9868813705444336
- 1.021389365196228
- 1.0194356846809387
- 1.0017078948020934
- 0.9896659445762634
- 0.9883431220054626
- 1.0148992776870727
- 0.9889915204048156
- 0.9913933444023132
- 0.9993153142929078
- 0.9854814839363099
- 0.9900811505317688
- 0.9697804379463196
- 0.9777165341377259
- 0.9864186930656433
- 0.9656896781921387
- 0.9801308989524842
- 0.9719978451728821
- 0.9629671478271484
- 0.9995389318466187
- 1.0040582370758058
- 0.9715649580955505
- 0.9913791179656982
- 0.971974983215332
- 0.957383725643158
- 0.9592509841918946
- 0.9852551865577698
- 0.9649049520492554
- 0.9547986137866974
- 0.9966877007484436
- 0.9732949662208558
- 0.9700556945800781
- 0.9872015833854675
- 0.9722396469116211
- 0.9676040887832642
- 0.9890848445892334
- 0.9772247457504273
- 0.9798654961585999
- 0.9906497001647949
- 0.9740896725654602
- 0.9657219099998474
- 0.9506741225719452
- 0.9739633893966675
- 0.9611116933822632
- 0.9636757302284241
- 0.9747422528266907
- 0.9648394894599914
- 0.9504786348342895
- 0.9539861273765564
- 0.9620437860488892
- 0.9460804510116577
- 0.9542913341522217
- 0.9727813100814819
train_accuracy:
- 0.079
- 0.114
- 0.135
- 0.183
- 0.179
- 0.174
- 0.209
- 0.226
- 0.221
- 0.196
- 0.237
- 0.228
- 0.233
- 0.255
- 0.257
- 0.247
- 0.244
- 0.278
- 0.256
- 0.258
- 0.247
- 0.281
- 0.292
- 0.265
- 0.295
- 0.308
- 0.317
- 0.306
- 0.283
- 0.312
- 0.293
- 0.312
- 0.308
- 0.32
- 0.322
- 0.323
- 0.328
- 0.32
- 0.326
- 0.331
- 0.334
- 0.344
- 0.36
- 0.353
- 0.337
- 0.339
- 0.377
- 0.344
- 0.318
- 0.337
- 0.361
- 0.351
- 0.381
- 0.35
- 0.363
- 0.364
- 0.366
- 0.361
- 0.375
- 0.376
- 0.389
- 0.386
- 0.38
- 0.344
- 0.388
- 0.384
- 0.365
- 0.371
- 0.367
- 0.378
- 0.386
- 0.388
- 0.383
- 0.385
- 0.39
- 0.376
- 0.358
- 0.4
- 0.375
- 0.358
- 0.39
- 0.417
- 0.389
- 0.402
- 0.387
- 0.39
- 0.383
- 0.404
- 0.375
- 0.408
- 0.391
- 0.377
- 0.412
- 0.409
- 0.417
- 0.405
- 0.382
- 0.379
- 0.432
- 0.401
train_loss:
- 4.239
- 3.787
- 3.584
- 3.46
- 3.03
- 3.242
- 3.17
- 3.088
- 2.655
- 2.945
- 2.38
- 2.796
- 2.532
- 2.131
- 2.678
- 2.402
- 2.598
- 2.493
- 2.022
- 2.208
- 1.79
- 2.38
- 2.165
- 1.98
- 1.779
- 2.412
- 2.28
- 1.974
- 2.042
- 1.892
- 1.647
- 1.734
- 1.379
- 1.577
- 1.785
- 1.921
- 1.58
- 1.291
- 1.333
- 1.464
- 1.538
- 1.979
- 1.599
- 1.23
- 1.639
- 1.344
- 2.05
- 1.625
- 1.324
- 0.901
- 1.137
- 1.218
- 0.813
- 0.558
- 1.135
- 0.951
- 1.649
- 1.377
- 0.886
- 1.356
- 1.639
- 1.069
- 1.298
- 1.193
- 0.934
- 1.107
- 0.728
- 0.47
- 1.083
- 1.269
- 0.925
- 0.808
- 0.873
- 0.923
- 0.899
- 0.786
- 0.456
- 0.764
- 0.41
- 0.26
- 0.744
- 0.741
- 0.41
- 0.705
- 0.366
- 1.31
- 0.764
- 0.608
- 0.403
- 0.377
- 0.472
- 0.606
- 0.778
- 0.966
- 0.492
- 0.429
- 0.9
- 0.402
- 0.387
- 0.586
unequal: 0
verbose: 1
