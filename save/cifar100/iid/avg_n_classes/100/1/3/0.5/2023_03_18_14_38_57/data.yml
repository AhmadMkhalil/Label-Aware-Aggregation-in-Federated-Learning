avg_train_accuracy: 0.39
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.096
- 0.1369
- 0.1677
- 0.1859
- 0.2002
- 0.2202
- 0.2327
- 0.2442
- 0.2556
- 0.2673
- 0.2741
- 0.2836
- 0.2882
- 0.2956
- 0.306
- 0.3094
- 0.3155
- 0.3254
- 0.3255
- 0.3353
- 0.3372
- 0.3409
- 0.3467
- 0.3485
- 0.3551
- 0.3556
- 0.3542
- 0.3673
- 0.3682
- 0.3689
- 0.372
- 0.3721
- 0.3754
- 0.3776
- 0.3805
- 0.3839
- 0.3763
- 0.3885
- 0.3923
- 0.3873
- 0.3919
- 0.3973
- 0.3964
- 0.3955
- 0.4023
- 0.402
- 0.4067
- 0.4071
- 0.4061
- 0.4068
- 0.4073
- 0.4067
- 0.4099
- 0.4125
- 0.4129
- 0.4136
- 0.4171
- 0.4164
- 0.4175
- 0.4156
- 0.4194
- 0.4231
- 0.4215
- 0.4219
- 0.4197
- 0.4234
- 0.4233
- 0.4243
- 0.4274
- 0.4215
- 0.4244
- 0.4254
- 0.4247
- 0.4296
- 0.4252
- 0.4314
- 0.4287
- 0.4244
- 0.4303
- 0.4282
- 0.4274
- 0.4294
- 0.4293
- 0.4296
- 0.429
- 0.4351
- 0.4318
- 0.4346
- 0.4314
- 0.4315
- 0.4355
- 0.4327
- 0.4329
- 0.4346
- 0.4324
- 0.4321
- 0.4369
- 0.4384
- 0.4363
- 0.435
test_loss_list:
- 1.640235457420349
- 1.5251373291015624
- 1.451804096698761
- 1.4001820302009582
- 1.3593861317634583
- 1.326814179420471
- 1.2964223313331604
- 1.270568585395813
- 1.246157774925232
- 1.2240180945396424
- 1.2048214054107667
- 1.184745454788208
- 1.1704044151306152
- 1.1537527441978455
- 1.138475091457367
- 1.1244481801986694
- 1.1106018233299255
- 1.094429955482483
- 1.083931565284729
- 1.0746520853042603
- 1.0646213364601136
- 1.0583965706825256
- 1.0437778210639954
- 1.0384935092926026
- 1.0276825833320617
- 1.0217084860801697
- 1.0225445342063904
- 1.00811527967453
- 1.0020605373382567
- 0.9962748336791992
- 0.9954965925216674
- 0.9885485887527465
- 0.9830463457107544
- 0.9845909261703492
- 0.9766123700141907
- 0.9723143053054809
- 0.9727836108207703
- 0.9637972784042358
- 0.956259949207306
- 0.9589031720161438
- 0.9617477869987487
- 0.9496486973762512
- 0.9433724212646485
- 0.9432104420661926
- 0.9405669498443604
- 0.9383734893798829
- 0.9363434529304504
- 0.9366491913795472
- 0.9350072360038757
- 0.9341538310050964
- 0.9317411732673645
- 0.9313047218322754
- 0.9286468815803528
- 0.9291870188713074
- 0.9275056171417236
- 0.9341775155067444
- 0.9211906170845032
- 0.9199684548377991
- 0.9256165432929992
- 0.9242692542076111
- 0.9210037732124329
- 0.9186904239654541
- 0.9223777580261231
- 0.9227397012710571
- 0.9198342490196229
- 0.9197714948654174
- 0.9196026420593262
- 0.9212872195243835
- 0.9211029815673828
- 0.9223886466026306
- 0.9237554812431336
- 0.9223093819618225
- 0.9189249420166016
- 0.916531548500061
- 0.9198492789268493
- 0.9159894394874573
- 0.9189440512657165
- 0.9219672727584839
- 0.9225277376174926
- 0.9231714057922363
- 0.9206974792480469
- 0.9192687749862671
- 0.9230729794502258
- 0.9308130526542664
- 0.9291801357269287
- 0.9205908393859863
- 0.9259804201126098
- 0.9263499450683593
- 0.9254209160804748
- 0.9288154363632202
- 0.9278999209403992
- 0.9265262937545776
- 0.9248591947555542
- 0.9271139693260193
- 0.9299883127212525
- 0.9305564379692077
- 0.9322616887092591
- 0.9317791795730591
- 0.9292225027084351
- 0.9342201328277588
train_accuracy:
- 0.096
- 0.118
- 0.149
- 0.171
- 0.192
- 0.205
- 0.213
- 0.2
- 0.233
- 0.241
- 0.246
- 0.269
- 0.254
- 0.278
- 0.277
- 0.267
- 0.286
- 0.289
- 0.3
- 0.285
- 0.299
- 0.302
- 0.314
- 0.319
- 0.31
- 0.331
- 0.317
- 0.338
- 0.378
- 0.323
- 0.328
- 0.344
- 0.364
- 0.348
- 0.335
- 0.337
- 0.362
- 0.36
- 0.375
- 0.363
- 0.367
- 0.375
- 0.406
- 0.369
- 0.375
- 0.347
- 0.379
- 0.389
- 0.346
- 0.37
- 0.382
- 0.415
- 0.359
- 0.388
- 0.377
- 0.387
- 0.38
- 0.425
- 0.424
- 0.366
- 0.411
- 0.394
- 0.367
- 0.403
- 0.387
- 0.393
- 0.376
- 0.435
- 0.4
- 0.39
- 0.395
- 0.383
- 0.395
- 0.405
- 0.394
- 0.428
- 0.389
- 0.398
- 0.392
- 0.399
- 0.414
- 0.39
- 0.399
- 0.408
- 0.409
- 0.391
- 0.39
- 0.393
- 0.435
- 0.389
- 0.406
- 0.406
- 0.387
- 0.414
- 0.407
- 0.399
- 0.407
- 0.379
- 0.394
- 0.39
train_loss:
- 4.218
- 3.727
- 3.485
- 3.338
- 3.191
- 3.043
- 2.978
- 2.846
- 2.796
- 2.706
- 2.619
- 2.539
- 2.436
- 2.388
- 2.306
- 2.273
- 2.23
- 2.173
- 2.16
- 2.013
- 1.985
- 1.893
- 1.981
- 1.962
- 1.788
- 1.743
- 1.696
- 1.764
- 1.693
- 1.643
- 1.543
- 1.522
- 1.469
- 1.419
- 1.527
- 1.412
- 1.393
- 1.348
- 1.343
- 1.218
- 1.227
- 1.248
- 1.203
- 1.174
- 1.184
- 1.155
- 1.093
- 1.081
- 1.0
- 0.998
- 0.959
- 0.92
- 0.955
- 0.903
- 0.869
- 0.822
- 0.908
- 0.786
- 0.79
- 0.819
- 0.752
- 0.737
- 0.695
- 0.639
- 0.673
- 0.67
- 0.641
- 0.578
- 0.609
- 0.568
- 0.566
- 0.588
- 0.565
- 0.566
- 0.534
- 0.536
- 0.504
- 0.49
- 0.484
- 0.469
- 0.455
- 0.468
- 0.41
- 0.417
- 0.376
- 0.403
- 0.406
- 0.382
- 0.367
- 0.371
- 0.344
- 0.343
- 0.338
- 0.333
- 0.337
- 0.301
- 0.314
- 0.316
- 0.281
- 0.285
unequal: 0
verbose: 1
