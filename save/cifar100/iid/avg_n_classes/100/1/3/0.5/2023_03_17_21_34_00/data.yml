avg_train_accuracy: 0.427
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0949
- 0.1396
- 0.1636
- 0.1856
- 0.2015
- 0.2151
- 0.2259
- 0.2408
- 0.2505
- 0.2586
- 0.2664
- 0.2791
- 0.2797
- 0.2888
- 0.2977
- 0.2975
- 0.306
- 0.3108
- 0.3175
- 0.3205
- 0.3308
- 0.3295
- 0.337
- 0.3442
- 0.3499
- 0.3471
- 0.3505
- 0.3563
- 0.3549
- 0.3582
- 0.3665
- 0.3651
- 0.3724
- 0.376
- 0.3769
- 0.3794
- 0.3832
- 0.3817
- 0.3875
- 0.3877
- 0.3897
- 0.3938
- 0.3888
- 0.3949
- 0.3955
- 0.3975
- 0.402
- 0.3978
- 0.4026
- 0.4001
- 0.401
- 0.4007
- 0.4074
- 0.4068
- 0.4115
- 0.4095
- 0.4098
- 0.4101
- 0.4132
- 0.4151
- 0.4121
- 0.4156
- 0.4155
- 0.4157
- 0.416
- 0.4157
- 0.4186
- 0.4208
- 0.4231
- 0.4186
- 0.4185
- 0.4217
- 0.4213
- 0.422
- 0.4242
- 0.4251
- 0.4234
- 0.4251
- 0.4264
- 0.4249
- 0.4254
- 0.4278
- 0.4292
- 0.4278
- 0.4293
- 0.4276
- 0.4286
- 0.4293
- 0.4305
- 0.429
- 0.4291
- 0.4286
- 0.4337
- 0.4348
- 0.4323
- 0.4303
- 0.4314
- 0.4331
- 0.4344
- 0.4344
test_loss_list:
- 1.6424189710617065
- 1.5206631231307983
- 1.4487388157844543
- 1.3962725472450257
- 1.354174017906189
- 1.3225818657875061
- 1.2947690796852112
- 1.2678174734115601
- 1.242486596107483
- 1.2225278902053833
- 1.2039622068405151
- 1.182200870513916
- 1.1709529113769532
- 1.1548575496673583
- 1.135725758075714
- 1.1228088092803956
- 1.1134294748306275
- 1.1010787606239318
- 1.0881480431556703
- 1.0754080867767335
- 1.0630655670166016
- 1.054679992198944
- 1.0488004827499389
- 1.0370960068702697
- 1.0269248723983764
- 1.0201083898544312
- 1.0205787587165833
- 1.0093109011650085
- 1.00512859582901
- 1.0015493202209473
- 0.9870681524276733
- 0.989925594329834
- 0.9780613517761231
- 0.9713009548187256
- 0.9676818358898163
- 0.9671384572982789
- 0.9590414690971375
- 0.9625143194198609
- 0.9549031257629395
- 0.9512561368942261
- 0.9507496094703675
- 0.9484780859947205
- 0.9436439967155457
- 0.9388276743888855
- 0.9351945757865906
- 0.9335737812519074
- 0.9310955488681794
- 0.9320963799953461
- 0.9260672104358673
- 0.9284258198738098
- 0.9276316249370575
- 0.9281336104869843
- 0.9212032985687256
- 0.9227107405662537
- 0.9186431276798248
- 0.9177748477458954
- 0.9195735633373261
- 0.9174484598636627
- 0.920729695558548
- 0.9174605429172515
- 0.9179562938213348
- 0.913681617975235
- 0.914547609090805
- 0.9220097732543945
- 0.916057391166687
- 0.9143486261367798
- 0.9169567573070526
- 0.9147550284862518
- 0.919145872592926
- 0.913126392364502
- 0.91602534532547
- 0.9163751304149628
- 0.9185521912574768
- 0.9161183071136475
- 0.914142599105835
- 0.9129323339462281
- 0.9175137948989868
- 0.9179105854034424
- 0.9182864880561828
- 0.920458905696869
- 0.9256301522254944
- 0.9232879090309143
- 0.9197768712043762
- 0.9252844762802124
- 0.914675931930542
- 0.9209415638446807
- 0.9217541861534119
- 0.9220521676540375
- 0.923910459280014
- 0.9213451492786408
- 0.9248749852180481
- 0.9271746134757995
- 0.92347247838974
- 0.9222990965843201
- 0.9194837844371796
- 0.9293695962429047
- 0.9303791785240173
- 0.9254582619667053
- 0.9271774744987488
- 0.9290240049362183
train_accuracy:
- 0.081
- 0.117
- 0.168
- 0.149
- 0.209
- 0.207
- 0.174
- 0.245
- 0.212
- 0.215
- 0.217
- 0.215
- 0.225
- 0.283
- 0.305
- 0.236
- 0.235
- 0.27
- 0.293
- 0.317
- 0.266
- 0.311
- 0.27
- 0.274
- 0.349
- 0.338
- 0.32
- 0.297
- 0.311
- 0.292
- 0.345
- 0.308
- 0.315
- 0.327
- 0.357
- 0.344
- 0.327
- 0.323
- 0.331
- 0.413
- 0.365
- 0.32
- 0.344
- 0.36
- 0.348
- 0.342
- 0.368
- 0.347
- 0.355
- 0.367
- 0.366
- 0.423
- 0.388
- 0.348
- 0.373
- 0.392
- 0.357
- 0.396
- 0.4
- 0.345
- 0.425
- 0.42
- 0.397
- 0.365
- 0.371
- 0.383
- 0.414
- 0.41
- 0.438
- 0.362
- 0.434
- 0.358
- 0.389
- 0.37
- 0.411
- 0.416
- 0.39
- 0.384
- 0.372
- 0.405
- 0.375
- 0.381
- 0.378
- 0.409
- 0.416
- 0.422
- 0.366
- 0.415
- 0.386
- 0.384
- 0.457
- 0.383
- 0.383
- 0.397
- 0.375
- 0.38
- 0.451
- 0.454
- 0.358
- 0.427
train_loss:
- 4.251
- 3.756
- 3.493
- 3.314
- 3.211
- 3.071
- 2.962
- 2.851
- 2.8
- 2.754
- 2.625
- 2.568
- 2.477
- 2.44
- 2.431
- 2.293
- 2.207
- 2.168
- 2.119
- 2.076
- 2.073
- 2.005
- 1.93
- 1.902
- 1.899
- 1.84
- 1.756
- 1.681
- 1.673
- 1.576
- 1.626
- 1.577
- 1.523
- 1.559
- 1.45
- 1.467
- 1.412
- 1.324
- 1.331
- 1.326
- 1.287
- 1.217
- 1.181
- 1.199
- 1.202
- 1.16
- 1.105
- 1.102
- 1.037
- 1.011
- 0.966
- 0.935
- 0.955
- 0.938
- 0.932
- 0.839
- 0.804
- 0.831
- 0.788
- 0.799
- 0.807
- 0.743
- 0.73
- 0.648
- 0.709
- 0.692
- 0.617
- 0.65
- 0.607
- 0.612
- 0.631
- 0.596
- 0.55
- 0.529
- 0.528
- 0.521
- 0.477
- 0.49
- 0.455
- 0.415
- 0.395
- 0.42
- 0.459
- 0.387
- 0.465
- 0.408
- 0.395
- 0.419
- 0.35
- 0.364
- 0.364
- 0.352
- 0.337
- 0.355
- 0.345
- 0.337
- 0.291
- 0.322
- 0.328
- 0.278
unequal: 0
verbose: 1
