avg_train_accuracy: 0.42
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0935
- 0.1374
- 0.1629
- 0.1821
- 0.204
- 0.2128
- 0.2284
- 0.2435
- 0.2505
- 0.2598
- 0.2687
- 0.2793
- 0.2853
- 0.2948
- 0.3013
- 0.3081
- 0.308
- 0.3166
- 0.3213
- 0.3284
- 0.3336
- 0.3369
- 0.3431
- 0.3435
- 0.3479
- 0.3522
- 0.3606
- 0.3617
- 0.3703
- 0.3741
- 0.3722
- 0.3746
- 0.3765
- 0.3801
- 0.383
- 0.3846
- 0.3886
- 0.3956
- 0.3933
- 0.396
- 0.3994
- 0.3951
- 0.4029
- 0.4025
- 0.4
- 0.4073
- 0.4048
- 0.4055
- 0.4106
- 0.413
- 0.4107
- 0.4134
- 0.4124
- 0.4161
- 0.4173
- 0.4213
- 0.4203
- 0.4197
- 0.4154
- 0.4226
- 0.4254
- 0.4242
- 0.4254
- 0.4248
- 0.4302
- 0.4281
- 0.4286
- 0.4309
- 0.4287
- 0.4337
- 0.4285
- 0.4319
- 0.4292
- 0.4307
- 0.4296
- 0.4283
- 0.4369
- 0.4331
- 0.4326
- 0.4322
- 0.4312
- 0.4335
- 0.4326
- 0.4353
- 0.4347
- 0.4368
- 0.434
- 0.4359
- 0.4352
- 0.434
- 0.4356
- 0.4322
- 0.4381
- 0.4378
- 0.4368
- 0.438
- 0.4388
- 0.4358
- 0.4379
- 0.4377
test_loss_list:
- 1.6519977045059204
- 1.5296102833747864
- 1.4558754420280458
- 1.4043617129325867
- 1.3603535652160645
- 1.3285985922813415
- 1.2987021970748902
- 1.269871678352356
- 1.2467898535728454
- 1.2227727890014648
- 1.2037649512290955
- 1.1872876858711243
- 1.1662277579307556
- 1.1502643394470216
- 1.1360560584068298
- 1.1205465149879457
- 1.1114450001716614
- 1.097045238018036
- 1.0881597661972047
- 1.0730993819236756
- 1.0618982195854187
- 1.0516669321060181
- 1.0420812153816223
- 1.033919186592102
- 1.0302550029754638
- 1.0246204113960267
- 1.0107025575637818
- 1.004051308631897
- 0.9911504197120666
- 0.9903650760650635
- 0.9881856632232666
- 0.9836731147766113
- 0.976741771697998
- 0.9770591068267822
- 0.9674339461326599
- 0.9612398791313171
- 0.9595200347900391
- 0.9525666737556457
- 0.9540895938873291
- 0.9452240085601806
- 0.944243586063385
- 0.9542356157302856
- 0.9362908625602722
- 0.9403048920631408
- 0.9479461359977722
- 0.9371837615966797
- 0.9353632640838623
- 0.9322214508056641
- 0.9265183091163636
- 0.9221745765209198
- 0.9250697326660157
- 0.9203078937530518
- 0.9228618657588958
- 0.9182315957546234
- 0.9176394510269165
- 0.9127475523948669
- 0.9159996831417083
- 0.9147024309635162
- 0.9231817615032196
- 0.9125827038288117
- 0.9085877633094788
- 0.9083214592933655
- 0.9127731585502624
- 0.9109212994575501
- 0.9073311829566956
- 0.9093731451034546
- 0.9085283243656158
- 0.907056313753128
- 0.912114498615265
- 0.9073336863517761
- 0.9135941815376282
- 0.9105754113197326
- 0.9127473199367523
- 0.9108068251609802
- 0.9108071768283844
- 0.9146578168869018
- 0.9090892457962036
- 0.9139277386665344
- 0.9134721493721009
- 0.9132961630821228
- 0.915231556892395
- 0.9171267080307007
- 0.9171040678024291
- 0.9133109188079834
- 0.9184323859214782
- 0.9168636870384216
- 0.9211619758605957
- 0.9140216732025146
- 0.913977792263031
- 0.9221814870834351
- 0.9182145857810974
- 0.9179693174362182
- 0.9187443137168885
- 0.9192926979064941
- 0.9191287863254547
- 0.915028989315033
- 0.9194823908805847
- 0.9210983681678772
- 0.9227780127525329
- 0.9227790713310242
train_accuracy:
- 0.096
- 0.113
- 0.16
- 0.178
- 0.197
- 0.16
- 0.199
- 0.192
- 0.211
- 0.237
- 0.225
- 0.247
- 0.256
- 0.276
- 0.266
- 0.253
- 0.264
- 0.318
- 0.284
- 0.271
- 0.317
- 0.314
- 0.341
- 0.317
- 0.32
- 0.302
- 0.33
- 0.346
- 0.326
- 0.331
- 0.322
- 0.342
- 0.358
- 0.35
- 0.356
- 0.332
- 0.341
- 0.368
- 0.364
- 0.339
- 0.361
- 0.387
- 0.351
- 0.368
- 0.388
- 0.343
- 0.356
- 0.371
- 0.379
- 0.4
- 0.39
- 0.352
- 0.397
- 0.394
- 0.358
- 0.373
- 0.393
- 0.412
- 0.367
- 0.352
- 0.361
- 0.409
- 0.416
- 0.393
- 0.369
- 0.419
- 0.402
- 0.374
- 0.395
- 0.376
- 0.376
- 0.383
- 0.399
- 0.404
- 0.409
- 0.397
- 0.388
- 0.417
- 0.362
- 0.374
- 0.374
- 0.403
- 0.376
- 0.378
- 0.43
- 0.426
- 0.423
- 0.378
- 0.386
- 0.386
- 0.39
- 0.388
- 0.411
- 0.399
- 0.423
- 0.382
- 0.419
- 0.391
- 0.421
- 0.42
train_loss:
- 4.271
- 3.771
- 3.521
- 3.357
- 3.191
- 3.069
- 2.969
- 2.883
- 2.792
- 2.75
- 2.627
- 2.51
- 2.528
- 2.477
- 2.332
- 2.315
- 2.232
- 2.165
- 2.172
- 2.11
- 2.029
- 1.973
- 1.967
- 1.861
- 1.876
- 1.78
- 1.764
- 1.671
- 1.74
- 1.641
- 1.644
- 1.532
- 1.493
- 1.425
- 1.472
- 1.496
- 1.38
- 1.395
- 1.294
- 1.333
- 1.22
- 1.205
- 1.203
- 1.105
- 1.101
- 1.067
- 1.059
- 1.098
- 1.039
- 1.078
- 1.026
- 0.957
- 0.976
- 0.953
- 0.94
- 0.902
- 0.835
- 0.801
- 0.807
- 0.794
- 0.818
- 0.764
- 0.7
- 0.683
- 0.737
- 0.648
- 0.632
- 0.635
- 0.597
- 0.625
- 0.569
- 0.583
- 0.567
- 0.556
- 0.536
- 0.503
- 0.535
- 0.502
- 0.472
- 0.448
- 0.433
- 0.407
- 0.429
- 0.439
- 0.406
- 0.4
- 0.377
- 0.405
- 0.376
- 0.351
- 0.336
- 0.362
- 0.35
- 0.324
- 0.351
- 0.34
- 0.303
- 0.296
- 0.294
- 0.316
unequal: 0
verbose: 1
