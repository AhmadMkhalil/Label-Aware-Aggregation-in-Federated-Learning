avg_train_accuracy: 0.389
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1035
- 0.1372
- 0.1654
- 0.1831
- 0.1975
- 0.2139
- 0.2282
- 0.2409
- 0.2507
- 0.2624
- 0.2735
- 0.2812
- 0.2881
- 0.2948
- 0.305
- 0.3127
- 0.3192
- 0.3209
- 0.3315
- 0.3334
- 0.3383
- 0.3416
- 0.3503
- 0.3548
- 0.3532
- 0.3606
- 0.364
- 0.3652
- 0.3708
- 0.3733
- 0.3759
- 0.3784
- 0.3822
- 0.3826
- 0.3868
- 0.3874
- 0.3888
- 0.39
- 0.3927
- 0.3971
- 0.3987
- 0.4035
- 0.4015
- 0.4022
- 0.402
- 0.4072
- 0.4097
- 0.4084
- 0.4099
- 0.4071
- 0.4128
- 0.413
- 0.4148
- 0.4122
- 0.417
- 0.4175
- 0.4182
- 0.4171
- 0.4202
- 0.4197
- 0.4242
- 0.4258
- 0.4234
- 0.4271
- 0.4283
- 0.427
- 0.4289
- 0.4259
- 0.4314
- 0.4323
- 0.4318
- 0.4343
- 0.4322
- 0.4279
- 0.4315
- 0.4328
- 0.4294
- 0.4313
- 0.4328
- 0.4294
- 0.4342
- 0.43
- 0.4358
- 0.4349
- 0.434
- 0.4378
- 0.435
- 0.4356
- 0.4369
- 0.4385
- 0.4334
- 0.4431
- 0.4374
- 0.4404
- 0.4375
- 0.4396
- 0.4395
- 0.4399
- 0.4365
- 0.4407
test_loss_list:
- 1.6282307934761047
- 1.5127967643737792
- 1.4451353025436402
- 1.3982857584953308
- 1.3604739904403687
- 1.3271833205223083
- 1.297322678565979
- 1.2684646034240723
- 1.2468309497833252
- 1.2238269686698913
- 1.2034986543655395
- 1.184465138912201
- 1.1652029728889466
- 1.1503720331192016
- 1.1338111114501954
- 1.1162242937088012
- 1.1005787301063537
- 1.0932496905326843
- 1.0749369287490844
- 1.068125913143158
- 1.0589393854141236
- 1.0499070501327514
- 1.0431837368011474
- 1.0289182806015014
- 1.0253860688209533
- 1.0138231110572815
- 1.009690110683441
- 1.005753755569458
- 0.9931240034103394
- 0.9913807368278503
- 0.9879208636283875
- 0.979036636352539
- 0.9718957924842835
- 0.9695757007598877
- 0.9638329267501831
- 0.9587218284606933
- 0.9576202630996704
- 0.955684061050415
- 0.9524429869651795
- 0.9486658239364624
- 0.9419629049301147
- 0.9387494087219238
- 0.938748254776001
- 0.9416170477867126
- 0.9370128750801087
- 0.9314455676078797
- 0.9255472254753113
- 0.9270416116714477
- 0.9288823795318604
- 0.9292100191116333
- 0.9219181251525879
- 0.9228701257705688
- 0.9208847546577453
- 0.9244371509552002
- 0.9195995879173279
- 0.919985966682434
- 0.9194833064079284
- 0.9201846385002136
- 0.913807864189148
- 0.9142302012443543
- 0.9133725762367249
- 0.908026180267334
- 0.9111664962768554
- 0.9126962089538574
- 0.9096372997760773
- 0.9098541760444641
- 0.9050269198417663
- 0.909424922466278
- 0.9038593816757202
- 0.9105017745494842
- 0.9100681757926941
- 0.9083122754096985
- 0.906936342716217
- 0.909552081823349
- 0.9083313298225403
- 0.9091084694862366
- 0.9202911496162415
- 0.9109028577804565
- 0.9107525300979614
- 0.9169059991836548
- 0.9166957020759583
- 0.9147814500331879
- 0.9127595674991608
- 0.9150126004219055
- 0.9180965328216553
- 0.9159475469589233
- 0.9210106587409973
- 0.9193165445327759
- 0.9201883101463317
- 0.9172045111656189
- 0.9192546486854554
- 0.9168736863136292
- 0.919205014705658
- 0.9169316053390503
- 0.9173444342613221
- 0.9188133239746094
- 0.9187674856185913
- 0.9200904476642608
- 0.9271500086784363
- 0.9183088159561157
train_accuracy:
- 0.093
- 0.143
- 0.169
- 0.177
- 0.181
- 0.221
- 0.198
- 0.217
- 0.23
- 0.247
- 0.278
- 0.268
- 0.261
- 0.275
- 0.276
- 0.279
- 0.293
- 0.312
- 0.312
- 0.309
- 0.314
- 0.31
- 0.327
- 0.344
- 0.336
- 0.324
- 0.352
- 0.319
- 0.34
- 0.389
- 0.388
- 0.362
- 0.346
- 0.394
- 0.339
- 0.389
- 0.414
- 0.391
- 0.371
- 0.376
- 0.424
- 0.373
- 0.399
- 0.362
- 0.381
- 0.392
- 0.396
- 0.39
- 0.385
- 0.383
- 0.399
- 0.403
- 0.396
- 0.367
- 0.43
- 0.446
- 0.388
- 0.413
- 0.374
- 0.382
- 0.392
- 0.391
- 0.418
- 0.38
- 0.42
- 0.397
- 0.468
- 0.406
- 0.412
- 0.424
- 0.471
- 0.438
- 0.406
- 0.431
- 0.428
- 0.405
- 0.455
- 0.395
- 0.442
- 0.386
- 0.469
- 0.443
- 0.385
- 0.408
- 0.383
- 0.421
- 0.439
- 0.38
- 0.426
- 0.477
- 0.412
- 0.429
- 0.394
- 0.391
- 0.446
- 0.396
- 0.475
- 0.408
- 0.41
- 0.389
train_loss:
- 4.188
- 3.714
- 3.477
- 3.338
- 3.187
- 3.089
- 2.982
- 2.887
- 2.779
- 2.706
- 2.635
- 2.586
- 2.477
- 2.388
- 2.355
- 2.286
- 2.263
- 2.163
- 2.179
- 2.07
- 1.985
- 1.992
- 1.987
- 1.952
- 1.827
- 1.828
- 1.733
- 1.696
- 1.709
- 1.645
- 1.536
- 1.549
- 1.562
- 1.534
- 1.403
- 1.459
- 1.39
- 1.31
- 1.278
- 1.287
- 1.322
- 1.223
- 1.203
- 1.112
- 1.172
- 1.185
- 1.097
- 1.029
- 0.98
- 0.989
- 0.94
- 0.935
- 0.872
- 0.836
- 0.821
- 0.903
- 0.869
- 0.806
- 0.853
- 0.83
- 0.737
- 0.783
- 0.696
- 0.771
- 0.712
- 0.684
- 0.633
- 0.665
- 0.598
- 0.59
- 0.623
- 0.533
- 0.548
- 0.577
- 0.524
- 0.482
- 0.473
- 0.512
- 0.491
- 0.476
- 0.424
- 0.476
- 0.394
- 0.41
- 0.381
- 0.392
- 0.384
- 0.369
- 0.344
- 0.367
- 0.357
- 0.324
- 0.369
- 0.357
- 0.319
- 0.31
- 0.342
- 0.303
- 0.326
- 0.28
unequal: 0
verbose: 1
