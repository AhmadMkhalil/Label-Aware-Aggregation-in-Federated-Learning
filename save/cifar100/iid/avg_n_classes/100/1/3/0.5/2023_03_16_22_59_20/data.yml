avg_train_accuracy: 0.423
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0987
- 0.1398
- 0.1733
- 0.1899
- 0.2061
- 0.222
- 0.2385
- 0.2451
- 0.2546
- 0.2602
- 0.2699
- 0.2775
- 0.2856
- 0.294
- 0.2992
- 0.3079
- 0.3101
- 0.3196
- 0.3214
- 0.3288
- 0.3318
- 0.3399
- 0.3388
- 0.3454
- 0.3491
- 0.3513
- 0.3556
- 0.3586
- 0.3583
- 0.3659
- 0.3684
- 0.3738
- 0.3726
- 0.3799
- 0.3809
- 0.3813
- 0.3836
- 0.385
- 0.3874
- 0.3926
- 0.3962
- 0.3914
- 0.3986
- 0.3963
- 0.3971
- 0.4031
- 0.4031
- 0.4024
- 0.4043
- 0.4063
- 0.4075
- 0.4057
- 0.4081
- 0.4104
- 0.4085
- 0.4102
- 0.4146
- 0.414
- 0.4149
- 0.4135
- 0.4151
- 0.4167
- 0.4194
- 0.4201
- 0.4186
- 0.4213
- 0.4229
- 0.4229
- 0.423
- 0.4222
- 0.4236
- 0.4242
- 0.4236
- 0.4224
- 0.4271
- 0.4267
- 0.426
- 0.4289
- 0.4259
- 0.4297
- 0.4301
- 0.4286
- 0.4285
- 0.4304
- 0.4273
- 0.4313
- 0.4306
- 0.4309
- 0.432
- 0.431
- 0.4322
- 0.4311
- 0.4345
- 0.4332
- 0.4328
- 0.4321
- 0.4297
- 0.4319
- 0.4332
- 0.4347
test_loss_list:
- 1.634036464691162
- 1.5197836327552796
- 1.444460985660553
- 1.3977590131759643
- 1.3583336687088012
- 1.3295757699012756
- 1.295623242855072
- 1.2730106353759765
- 1.2481901502609254
- 1.228124716281891
- 1.2086072087287902
- 1.1913999676704408
- 1.1748258137702943
- 1.1570841836929322
- 1.1436142301559449
- 1.1293199491500854
- 1.1185425734519958
- 1.1044183468818665
- 1.0961638021469116
- 1.083034815788269
- 1.0690374922752381
- 1.062149202823639
- 1.0546073818206787
- 1.0380905699729919
- 1.0335686254501342
- 1.0262432479858399
- 1.0178991198539733
- 1.012397165298462
- 1.0032883810997009
- 0.9974444365501404
- 0.9949319529533386
- 0.9816474676132202
- 0.9798762798309326
- 0.9773124241828919
- 0.9689074850082398
- 0.9688454055786133
- 0.9656196188926697
- 0.9661909556388855
- 0.9630510473251342
- 0.9574846267700196
- 0.9521651649475098
- 0.9538113355636597
- 0.9427310729026794
- 0.9454484224319458
- 0.9418695044517517
- 0.9363415026664734
- 0.938103187084198
- 0.9374606966972351
- 0.9339851415157319
- 0.9328786516189576
- 0.9293387711048127
- 0.9253166103363037
- 0.9251223921775817
- 0.9257750964164734
- 0.9235035586357117
- 0.920725359916687
- 0.9191055381298066
- 0.9150441932678223
- 0.9179767298698426
- 0.917297774553299
- 0.9181995248794556
- 0.9200370788574219
- 0.9150267779827118
- 0.916939207315445
- 0.9149764156341553
- 0.9172833883762359
- 0.9156979155540467
- 0.9175828051567078
- 0.9169277453422546
- 0.9169473195075989
- 0.9155737328529358
- 0.9181284570693969
- 0.9145417380332946
- 0.9231652617454529
- 0.9164651799201965
- 0.9230337882041931
- 0.9174866533279419
- 0.9207660961151123
- 0.9204035592079163
- 0.9201814603805542
- 0.9212246012687683
- 0.924148051738739
- 0.922020628452301
- 0.9202387452125549
- 0.9197250890731812
- 0.9228911375999451
- 0.9278129029273987
- 0.9197038805484772
- 0.9213765251636505
- 0.9239459013938904
- 0.9287355053424835
- 0.9279771018028259
- 0.9254107141494751
- 0.9287074053287506
- 0.9283109593391419
- 0.9314004135131836
- 0.9307337427139282
- 0.9309038186073303
- 0.9332639050483703
- 0.9297318708896637
train_accuracy:
- 0.094
- 0.126
- 0.173
- 0.167
- 0.194
- 0.171
- 0.216
- 0.239
- 0.261
- 0.231
- 0.238
- 0.238
- 0.252
- 0.251
- 0.256
- 0.29
- 0.268
- 0.268
- 0.312
- 0.31
- 0.276
- 0.298
- 0.288
- 0.352
- 0.335
- 0.313
- 0.337
- 0.339
- 0.321
- 0.356
- 0.331
- 0.373
- 0.378
- 0.315
- 0.341
- 0.348
- 0.351
- 0.344
- 0.344
- 0.377
- 0.346
- 0.378
- 0.394
- 0.395
- 0.4
- 0.361
- 0.371
- 0.39
- 0.37
- 0.402
- 0.367
- 0.389
- 0.371
- 0.379
- 0.368
- 0.374
- 0.372
- 0.408
- 0.406
- 0.382
- 0.391
- 0.394
- 0.396
- 0.386
- 0.379
- 0.406
- 0.404
- 0.393
- 0.393
- 0.392
- 0.416
- 0.401
- 0.409
- 0.4
- 0.398
- 0.402
- 0.414
- 0.391
- 0.404
- 0.388
- 0.414
- 0.419
- 0.404
- 0.422
- 0.425
- 0.427
- 0.391
- 0.433
- 0.421
- 0.415
- 0.392
- 0.412
- 0.408
- 0.396
- 0.402
- 0.393
- 0.428
- 0.427
- 0.425
- 0.423
train_loss:
- 4.213
- 3.72
- 3.502
- 3.314
- 3.191
- 3.061
- 2.992
- 2.861
- 2.765
- 2.703
- 2.594
- 2.53
- 2.536
- 2.437
- 2.328
- 2.302
- 2.18
- 2.236
- 2.088
- 2.094
- 2.031
- 1.982
- 1.911
- 1.936
- 1.816
- 1.788
- 1.747
- 1.748
- 1.652
- 1.599
- 1.616
- 1.62
- 1.515
- 1.502
- 1.486
- 1.356
- 1.324
- 1.286
- 1.292
- 1.287
- 1.229
- 1.195
- 1.287
- 1.164
- 1.093
- 1.078
- 1.124
- 0.967
- 1.036
- 0.944
- 0.978
- 0.963
- 0.926
- 0.87
- 0.892
- 0.87
- 0.857
- 0.891
- 0.799
- 0.8
- 0.755
- 0.697
- 0.765
- 0.702
- 0.67
- 0.663
- 0.663
- 0.609
- 0.587
- 0.586
- 0.589
- 0.577
- 0.567
- 0.538
- 0.506
- 0.485
- 0.484
- 0.494
- 0.45
- 0.44
- 0.449
- 0.434
- 0.426
- 0.45
- 0.429
- 0.385
- 0.361
- 0.382
- 0.367
- 0.336
- 0.342
- 0.32
- 0.336
- 0.301
- 0.315
- 0.294
- 0.322
- 0.283
- 0.28
- 0.295
unequal: 0
verbose: 1
