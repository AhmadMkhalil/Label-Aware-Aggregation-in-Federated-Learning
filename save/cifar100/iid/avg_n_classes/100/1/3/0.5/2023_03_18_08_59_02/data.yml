avg_train_accuracy: 0.437
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.096
- 0.142
- 0.17
- 0.1935
- 0.2117
- 0.2238
- 0.2341
- 0.2433
- 0.2515
- 0.2641
- 0.2695
- 0.2793
- 0.2874
- 0.295
- 0.3023
- 0.3036
- 0.3104
- 0.3195
- 0.325
- 0.3325
- 0.3399
- 0.3412
- 0.3447
- 0.3501
- 0.3577
- 0.359
- 0.3613
- 0.3592
- 0.3651
- 0.3736
- 0.3749
- 0.3733
- 0.3767
- 0.3748
- 0.3815
- 0.3854
- 0.385
- 0.3844
- 0.3909
- 0.3935
- 0.3967
- 0.4009
- 0.3998
- 0.4022
- 0.4015
- 0.4074
- 0.4091
- 0.4094
- 0.4119
- 0.4077
- 0.4157
- 0.4122
- 0.419
- 0.4198
- 0.4198
- 0.4173
- 0.4193
- 0.4192
- 0.4287
- 0.4227
- 0.4254
- 0.43
- 0.4255
- 0.4288
- 0.429
- 0.4304
- 0.4303
- 0.43
- 0.4308
- 0.4299
- 0.4319
- 0.4314
- 0.4297
- 0.4324
- 0.429
- 0.435
- 0.4321
- 0.4377
- 0.4366
- 0.4366
- 0.4334
- 0.4354
- 0.4363
- 0.4358
- 0.4329
- 0.4329
- 0.4391
- 0.4358
- 0.4435
- 0.4414
- 0.4404
- 0.4398
- 0.4407
- 0.4406
- 0.4427
- 0.4418
- 0.4388
- 0.4393
- 0.4434
- 0.4449
test_loss_list:
- 1.6412949752807617
- 1.5168234133720397
- 1.4495880675315858
- 1.3944975352287292
- 1.3563144707679748
- 1.324569320678711
- 1.2950160789489746
- 1.2697957921028138
- 1.246993591785431
- 1.224816632270813
- 1.2038323044776917
- 1.1870434546470643
- 1.167914435863495
- 1.1514510202407837
- 1.1384629917144775
- 1.1251742887496947
- 1.1074972772598266
- 1.0961091136932373
- 1.083898057937622
- 1.0739275693893433
- 1.0606748795509338
- 1.0533566236495973
- 1.045461642742157
- 1.0291678619384765
- 1.023840048313141
- 1.018028392791748
- 1.0080756878852843
- 1.0059485530853272
- 0.9976119756698608
- 0.985324854850769
- 0.979792720079422
- 0.9791291928291321
- 0.9716788256168365
- 0.9701856827735901
- 0.9646839928627015
- 0.9596948194503784
- 0.9558696031570435
- 0.952569887638092
- 0.9479691791534424
- 0.9383792507648469
- 0.9355257642269135
- 0.9349508595466614
- 0.9307868719100952
- 0.934446359872818
- 0.9299006426334381
- 0.9215786814689636
- 0.9208879852294922
- 0.9204742538928986
- 0.916739627122879
- 0.914260767698288
- 0.912743729352951
- 0.9138376998901367
- 0.9101377475261688
- 0.9115417385101319
- 0.9057914066314697
- 0.9074777281284332
- 0.9081385564804078
- 0.9096481871604919
- 0.9025483751296997
- 0.9007450413703918
- 0.9042015516757965
- 0.900504754781723
- 0.9001684141159058
- 0.8976005685329437
- 0.900323692560196
- 0.8996048152446747
- 0.8968051743507385
- 0.8952738201618194
- 0.8981019103527069
- 0.9019596767425537
- 0.8947202098369599
- 0.8948098814487457
- 0.897475700378418
- 0.8978107416629791
- 0.9036207890510559
- 0.8952236199378967
- 0.897582323551178
- 0.8985393798351288
- 0.8980193066596985
- 0.9001096093654632
- 0.9026469039916992
- 0.9013013422489167
- 0.9022643589973449
- 0.9014320492744445
- 0.9029386818408967
- 0.9084478235244751
- 0.9018834185600281
- 0.9020843505859375
- 0.9028257322311402
- 0.9033215475082398
- 0.9050693130493164
- 0.9059193921089173
- 0.9017831027507782
- 0.9075979685783386
- 0.9077384161949158
- 0.9088665390014649
- 0.9083152139186859
- 0.9052865600585938
- 0.9072628390789031
- 0.9076498007774353
train_accuracy:
- 0.094
- 0.133
- 0.133
- 0.171
- 0.217
- 0.207
- 0.236
- 0.219
- 0.207
- 0.265
- 0.267
- 0.275
- 0.282
- 0.277
- 0.292
- 0.262
- 0.298
- 0.303
- 0.315
- 0.307
- 0.314
- 0.31
- 0.313
- 0.331
- 0.342
- 0.329
- 0.333
- 0.339
- 0.343
- 0.355
- 0.355
- 0.348
- 0.33
- 0.368
- 0.38
- 0.35
- 0.37
- 0.374
- 0.378
- 0.331
- 0.338
- 0.382
- 0.388
- 0.377
- 0.356
- 0.366
- 0.377
- 0.351
- 0.394
- 0.364
- 0.389
- 0.392
- 0.404
- 0.38
- 0.381
- 0.364
- 0.396
- 0.364
- 0.396
- 0.418
- 0.406
- 0.408
- 0.393
- 0.417
- 0.388
- 0.378
- 0.396
- 0.386
- 0.408
- 0.417
- 0.415
- 0.401
- 0.396
- 0.42
- 0.429
- 0.412
- 0.4
- 0.401
- 0.397
- 0.425
- 0.415
- 0.399
- 0.415
- 0.392
- 0.401
- 0.427
- 0.423
- 0.395
- 0.404
- 0.424
- 0.423
- 0.394
- 0.424
- 0.434
- 0.399
- 0.432
- 0.404
- 0.401
- 0.428
- 0.437
train_loss:
- 4.228
- 3.725
- 3.477
- 3.354
- 3.165
- 3.045
- 2.952
- 2.868
- 2.737
- 2.697
- 2.615
- 2.51
- 2.536
- 2.418
- 2.342
- 2.289
- 2.27
- 2.164
- 2.109
- 2.102
- 2.014
- 1.987
- 1.91
- 1.929
- 1.822
- 1.751
- 1.757
- 1.669
- 1.725
- 1.668
- 1.607
- 1.533
- 1.509
- 1.435
- 1.432
- 1.426
- 1.369
- 1.352
- 1.292
- 1.366
- 1.31
- 1.215
- 1.231
- 1.131
- 1.127
- 1.117
- 1.059
- 1.08
- 1.02
- 1.033
- 0.929
- 0.974
- 0.926
- 0.913
- 0.854
- 0.848
- 0.809
- 0.789
- 0.786
- 0.815
- 0.702
- 0.742
- 0.739
- 0.699
- 0.656
- 0.658
- 0.698
- 0.613
- 0.621
- 0.563
- 0.66
- 0.576
- 0.541
- 0.545
- 0.509
- 0.555
- 0.497
- 0.473
- 0.507
- 0.44
- 0.446
- 0.425
- 0.431
- 0.407
- 0.397
- 0.395
- 0.38
- 0.375
- 0.401
- 0.344
- 0.337
- 0.315
- 0.354
- 0.342
- 0.352
- 0.305
- 0.31
- 0.289
- 0.319
- 0.281
unequal: 0
verbose: 1
