avg_train_accuracy: 0.428
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0897
- 0.1325
- 0.1642
- 0.186
- 0.2026
- 0.2166
- 0.2297
- 0.2399
- 0.2509
- 0.2595
- 0.2667
- 0.2781
- 0.2841
- 0.2888
- 0.2937
- 0.3032
- 0.3035
- 0.3096
- 0.316
- 0.3252
- 0.3249
- 0.3328
- 0.3323
- 0.3398
- 0.3425
- 0.3478
- 0.3537
- 0.3517
- 0.358
- 0.36
- 0.3642
- 0.367
- 0.3683
- 0.3712
- 0.3735
- 0.3733
- 0.3731
- 0.3755
- 0.3806
- 0.3798
- 0.3807
- 0.3854
- 0.3864
- 0.385
- 0.3859
- 0.3894
- 0.39
- 0.3948
- 0.3926
- 0.3971
- 0.3956
- 0.3994
- 0.3989
- 0.4022
- 0.399
- 0.3978
- 0.4007
- 0.4049
- 0.4027
- 0.4046
- 0.4048
- 0.4073
- 0.4071
- 0.406
- 0.4076
- 0.4068
- 0.4083
- 0.4124
- 0.4135
- 0.415
- 0.4127
- 0.4115
- 0.4151
- 0.4142
- 0.4127
- 0.4119
- 0.4175
- 0.4187
- 0.4179
- 0.4151
- 0.4158
- 0.4155
- 0.4205
- 0.42
- 0.4179
- 0.4193
- 0.4205
- 0.4189
- 0.4214
- 0.4197
- 0.4205
- 0.4171
- 0.4263
- 0.4225
- 0.4206
- 0.4203
- 0.423
- 0.4252
- 0.4255
- 0.4227
test_loss_list:
- 1.643020713329315
- 1.523615574836731
- 1.4501697301864624
- 1.3979306936264038
- 1.361219766139984
- 1.3278119707107543
- 1.3021747398376464
- 1.2790667295455933
- 1.2543573951721192
- 1.233779056072235
- 1.214443438053131
- 1.194376049041748
- 1.1763021397590636
- 1.1651862978935241
- 1.1536533379554748
- 1.1326672887802125
- 1.1250526547431945
- 1.1128746366500855
- 1.1028808093070983
- 1.0879136180877687
- 1.0774288630485536
- 1.071841893196106
- 1.0615848231315612
- 1.0494876074790955
- 1.0457663750648498
- 1.0338458395004273
- 1.0278016090393067
- 1.0220630264282227
- 1.0176609349250794
- 1.0153699016571045
- 1.0081101441383362
- 1.004831438064575
- 1.0001371312141418
- 0.9960669016838074
- 0.990782024860382
- 0.9924132657051087
- 0.9869402909278869
- 0.9848772048950195
- 0.9772616744041442
- 0.980612325668335
- 0.9751903581619262
- 0.9756625270843506
- 0.9744097518920899
- 0.9659911513328552
- 0.9658503556251525
- 0.9625213360786438
- 0.9642025208473206
- 0.9571319961547852
- 0.9593582439422608
- 0.9554662942886353
- 0.9581921410560608
- 0.9502911281585693
- 0.9529024171829223
- 0.9508412885665893
- 0.9530730724334717
- 0.9543020462989807
- 0.9531716346740723
- 0.948249704837799
- 0.950867326259613
- 0.9495649242401123
- 0.9510826182365417
- 0.9481300330162048
- 0.9520179939270019
- 0.9513680458068847
- 0.9479898047447205
- 0.9474367880821228
- 0.9484280729293824
- 0.9486906480789185
- 0.9467854475975037
- 0.9456831836700439
- 0.9424269938468933
- 0.9474487733840943
- 0.946387345790863
- 0.9464770412445068
- 0.947500445842743
- 0.948401300907135
- 0.9497540116310119
- 0.9475668573379517
- 0.9495224952697754
- 0.9535451626777649
- 0.9524144625663757
- 0.9505701017379761
- 0.9496040177345276
- 0.9483722901344299
- 0.9524481582641602
- 0.9512726449966431
- 0.9528983736038208
- 0.95607412815094
- 0.9538414716720581
- 0.955324342250824
- 0.9580601072311401
- 0.9628337812423706
- 0.9565027093887329
- 0.9582535791397094
- 0.9570485115051269
- 0.9558381628990174
- 0.957923812866211
- 0.9588403367996216
- 0.9618999791145325
- 0.9605382561683655
train_accuracy:
- 0.081
- 0.127
- 0.139
- 0.152
- 0.181
- 0.204
- 0.208
- 0.226
- 0.222
- 0.225
- 0.241
- 0.247
- 0.254
- 0.263
- 0.256
- 0.268
- 0.3
- 0.281
- 0.288
- 0.3
- 0.29
- 0.294
- 0.311
- 0.319
- 0.314
- 0.349
- 0.32
- 0.314
- 0.316
- 0.368
- 0.326
- 0.329
- 0.315
- 0.339
- 0.333
- 0.336
- 0.374
- 0.36
- 0.331
- 0.377
- 0.37
- 0.355
- 0.347
- 0.39
- 0.347
- 0.356
- 0.35
- 0.363
- 0.356
- 0.366
- 0.359
- 0.392
- 0.356
- 0.387
- 0.365
- 0.401
- 0.417
- 0.368
- 0.399
- 0.372
- 0.403
- 0.413
- 0.378
- 0.42
- 0.367
- 0.402
- 0.365
- 0.37
- 0.382
- 0.414
- 0.368
- 0.376
- 0.373
- 0.376
- 0.369
- 0.376
- 0.388
- 0.38
- 0.387
- 0.388
- 0.417
- 0.428
- 0.38
- 0.383
- 0.424
- 0.435
- 0.375
- 0.378
- 0.418
- 0.431
- 0.371
- 0.418
- 0.386
- 0.39
- 0.375
- 0.374
- 0.372
- 0.443
- 0.426
- 0.428
train_loss:
- 4.196
- 3.734
- 3.469
- 3.345
- 3.157
- 3.063
- 2.942
- 2.824
- 2.793
- 2.712
- 2.605
- 2.581
- 2.535
- 2.424
- 2.319
- 2.32
- 2.21
- 2.186
- 2.138
- 2.093
- 2.035
- 1.985
- 1.906
- 1.935
- 1.818
- 1.834
- 1.791
- 1.744
- 1.693
- 1.633
- 1.603
- 1.546
- 1.497
- 1.468
- 1.516
- 1.389
- 1.347
- 1.338
- 1.333
- 1.312
- 1.227
- 1.195
- 1.134
- 1.231
- 1.158
- 1.125
- 1.103
- 1.073
- 1.022
- 0.985
- 0.941
- 0.959
- 0.935
- 0.895
- 0.851
- 0.855
- 0.78
- 0.866
- 0.8
- 0.728
- 0.742
- 0.744
- 0.638
- 0.696
- 0.685
- 0.644
- 0.678
- 0.633
- 0.627
- 0.579
- 0.649
- 0.543
- 0.495
- 0.583
- 0.552
- 0.546
- 0.508
- 0.473
- 0.497
- 0.441
- 0.426
- 0.452
- 0.413
- 0.408
- 0.454
- 0.394
- 0.4
- 0.372
- 0.344
- 0.386
- 0.328
- 0.338
- 0.331
- 0.345
- 0.29
- 0.32
- 0.329
- 0.269
- 0.261
- 0.292
unequal: 0
verbose: 1
