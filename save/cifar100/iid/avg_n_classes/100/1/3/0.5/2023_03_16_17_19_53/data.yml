avg_train_accuracy: 0.415
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1036
- 0.142
- 0.1699
- 0.1904
- 0.2038
- 0.2145
- 0.227
- 0.239
- 0.2495
- 0.2571
- 0.2689
- 0.2752
- 0.2831
- 0.2878
- 0.2966
- 0.2997
- 0.3021
- 0.3073
- 0.3142
- 0.3184
- 0.3198
- 0.3305
- 0.3351
- 0.3379
- 0.3417
- 0.3444
- 0.3456
- 0.3546
- 0.3607
- 0.3597
- 0.3647
- 0.3651
- 0.3681
- 0.3733
- 0.3705
- 0.3798
- 0.3836
- 0.3816
- 0.3824
- 0.3849
- 0.3902
- 0.389
- 0.394
- 0.3975
- 0.3916
- 0.3944
- 0.3963
- 0.3987
- 0.4026
- 0.406
- 0.4047
- 0.4091
- 0.4023
- 0.4095
- 0.4096
- 0.4086
- 0.4111
- 0.4078
- 0.4112
- 0.4093
- 0.4148
- 0.414
- 0.4147
- 0.4112
- 0.4173
- 0.4188
- 0.4167
- 0.4239
- 0.4202
- 0.42
- 0.423
- 0.4201
- 0.4224
- 0.4248
- 0.4265
- 0.4203
- 0.4214
- 0.4273
- 0.4223
- 0.4283
- 0.4242
- 0.4267
- 0.4262
- 0.425
- 0.4274
- 0.4314
- 0.4287
- 0.4261
- 0.4309
- 0.4277
- 0.4295
- 0.4327
- 0.4262
- 0.4273
- 0.4318
- 0.4302
- 0.4309
- 0.4315
- 0.4338
- 0.4337
test_loss_list:
- 1.642135124206543
- 1.5277592706680299
- 1.4572188782691955
- 1.4050073623657227
- 1.368431556224823
- 1.3409268879890441
- 1.3088454365730287
- 1.283572313785553
- 1.2557437777519227
- 1.2392381072044372
- 1.2197789239883423
- 1.2031058502197265
- 1.1824944233894348
- 1.171311628818512
- 1.1545029616355895
- 1.1383006620407103
- 1.1263080787658692
- 1.1158194947242737
- 1.099993667602539
- 1.0903609132766723
- 1.0804079461097718
- 1.0672706794738769
- 1.058887128829956
- 1.0504033136367799
- 1.0407695078849792
- 1.0365136551856995
- 1.0325145316123963
- 1.0233021783828735
- 1.013814353942871
- 1.0126693296432494
- 1.0041678547859192
- 1.0032741808891297
- 0.9981794667243957
- 0.9923876798152924
- 0.9912266206741333
- 0.9815520691871643
- 0.9734404516220093
- 0.9741399312019348
- 0.9742830324172974
- 0.9648167109489441
- 0.960768256187439
- 0.9568579804897308
- 0.9534162712097168
- 0.9548604893684387
- 0.9543444061279297
- 0.9538714075088501
- 0.9482598257064819
- 0.9494955480098725
- 0.9348817384243011
- 0.9375006937980652
- 0.9376457786560058
- 0.9362591922283172
- 0.9434948217868805
- 0.9400585329532624
- 0.9366338539123535
- 0.9369187831878663
- 0.9348650240898132
- 0.9380342745780945
- 0.9358779621124268
- 0.9401322269439697
- 0.9299870765209198
- 0.9335304617881774
- 0.9316278219223022
- 0.9306989741325379
- 0.9244805335998535
- 0.92616020321846
- 0.9277898812294006
- 0.9187603080272675
- 0.9278119039535523
- 0.9251164042949677
- 0.9225431668758393
- 0.9258682823181152
- 0.9254264962673188
- 0.9212282693386078
- 0.9249307942390442
- 0.9259353268146515
- 0.9261165070533752
- 0.9228147602081299
- 0.925807089805603
- 0.9230021131038666
- 0.9253254091739654
- 0.925544296503067
- 0.9242504286766052
- 0.931156644821167
- 0.9278577518463135
- 0.9263512301445007
- 0.9255883646011352
- 0.933612996339798
- 0.9276779818534852
- 0.9294756019115448
- 0.9260066854953766
- 0.9306236517429352
- 0.931200544834137
- 0.930434318780899
- 0.9319701933860779
- 0.9326401960849762
- 0.930906331539154
- 0.9310272824764252
- 0.9307969522476196
- 0.934596871137619
train_accuracy:
- 0.09
- 0.14
- 0.18
- 0.15
- 0.155
- 0.199
- 0.21
- 0.204
- 0.245
- 0.251
- 0.258
- 0.224
- 0.269
- 0.267
- 0.288
- 0.268
- 0.273
- 0.295
- 0.318
- 0.278
- 0.298
- 0.336
- 0.328
- 0.336
- 0.305
- 0.321
- 0.308
- 0.316
- 0.368
- 0.334
- 0.337
- 0.32
- 0.352
- 0.368
- 0.35
- 0.352
- 0.352
- 0.342
- 0.343
- 0.375
- 0.388
- 0.35
- 0.356
- 0.344
- 0.375
- 0.372
- 0.383
- 0.346
- 0.387
- 0.399
- 0.391
- 0.416
- 0.386
- 0.372
- 0.383
- 0.372
- 0.371
- 0.378
- 0.383
- 0.408
- 0.389
- 0.37
- 0.415
- 0.398
- 0.396
- 0.385
- 0.403
- 0.412
- 0.389
- 0.416
- 0.417
- 0.418
- 0.376
- 0.403
- 0.399
- 0.403
- 0.392
- 0.39
- 0.403
- 0.408
- 0.409
- 0.43
- 0.418
- 0.435
- 0.382
- 0.411
- 0.389
- 0.429
- 0.402
- 0.4
- 0.408
- 0.433
- 0.387
- 0.433
- 0.439
- 0.403
- 0.411
- 0.414
- 0.423
- 0.415
train_loss:
- 4.218
- 3.754
- 3.499
- 3.345
- 3.206
- 3.074
- 2.977
- 2.897
- 2.84
- 2.722
- 2.672
- 2.61
- 2.551
- 2.434
- 2.375
- 2.346
- 2.249
- 2.172
- 2.166
- 2.104
- 2.04
- 2.009
- 1.98
- 1.986
- 1.851
- 1.8
- 1.756
- 1.724
- 1.696
- 1.66
- 1.622
- 1.488
- 1.489
- 1.46
- 1.497
- 1.405
- 1.475
- 1.343
- 1.321
- 1.389
- 1.287
- 1.291
- 1.238
- 1.15
- 1.125
- 1.052
- 1.154
- 1.033
- 1.16
- 1.039
- 1.064
- 0.973
- 0.875
- 0.907
- 0.943
- 0.826
- 0.804
- 0.761
- 0.763
- 0.723
- 0.844
- 0.691
- 0.685
- 0.739
- 0.787
- 0.692
- 0.693
- 0.724
- 0.615
- 0.612
- 0.651
- 0.556
- 0.59
- 0.576
- 0.528
- 0.521
- 0.525
- 0.512
- 0.503
- 0.475
- 0.45
- 0.456
- 0.436
- 0.426
- 0.408
- 0.411
- 0.39
- 0.356
- 0.411
- 0.393
- 0.392
- 0.369
- 0.335
- 0.35
- 0.354
- 0.31
- 0.304
- 0.307
- 0.304
- 0.287
unequal: 0
verbose: 1
