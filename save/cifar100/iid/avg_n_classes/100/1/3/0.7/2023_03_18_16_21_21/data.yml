avg_train_accuracy: 0.379
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0974
- 0.139
- 0.1622
- 0.1821
- 0.2006
- 0.2142
- 0.2306
- 0.2402
- 0.2526
- 0.2603
- 0.2722
- 0.281
- 0.2864
- 0.2935
- 0.2999
- 0.3062
- 0.3126
- 0.32
- 0.3241
- 0.3306
- 0.3354
- 0.3381
- 0.3458
- 0.3463
- 0.3545
- 0.3567
- 0.3586
- 0.3624
- 0.3674
- 0.3725
- 0.3743
- 0.3759
- 0.3754
- 0.383
- 0.3847
- 0.3842
- 0.3911
- 0.3912
- 0.3913
- 0.3952
- 0.399
- 0.4004
- 0.4023
- 0.4
- 0.4047
- 0.4054
- 0.4076
- 0.4084
- 0.4042
- 0.4093
- 0.4122
- 0.4142
- 0.4148
- 0.4183
- 0.4176
- 0.4171
- 0.4225
- 0.4202
- 0.4201
- 0.42
- 0.4252
- 0.4251
- 0.4242
- 0.4267
- 0.4276
- 0.4266
- 0.4288
- 0.4282
- 0.4304
- 0.4303
- 0.4309
- 0.4268
- 0.4293
- 0.4275
- 0.4275
- 0.4324
- 0.4318
- 0.4343
- 0.4344
- 0.4365
- 0.4366
- 0.4351
- 0.4319
- 0.4371
- 0.4352
- 0.4366
- 0.4363
- 0.434
- 0.4369
- 0.4374
- 0.4357
- 0.4348
- 0.4355
- 0.4343
- 0.4341
- 0.4349
- 0.4364
- 0.4395
- 0.4365
- 0.4396
test_loss_list:
- 1.647030177116394
- 1.5311796140670777
- 1.4620284509658814
- 1.4097439527511597
- 1.3668273377418518
- 1.332789659500122
- 1.3004656195640565
- 1.27099951505661
- 1.2450135612487794
- 1.222621464729309
- 1.2027320885658264
- 1.184686758518219
- 1.1678053975105285
- 1.1513026094436645
- 1.1365276312828063
- 1.123761751651764
- 1.1098877739906312
- 1.0959084057807922
- 1.0860754132270813
- 1.0732440114021302
- 1.0632427978515624
- 1.0533881187438965
- 1.042731649875641
- 1.0346285057067872
- 1.0249193263053895
- 1.017308840751648
- 1.0107864570617675
- 1.0034947729110717
- 0.9978030443191528
- 0.9892148804664612
- 0.9833383011817932
- 0.9800633025169373
- 0.9788242244720459
- 0.969419801235199
- 0.966529951095581
- 0.9620311069488525
- 0.9539753437042237
- 0.9499431657791138
- 0.9542762637138367
- 0.9478778338432312
- 0.9409200489521027
- 0.938966474533081
- 0.9369980907440185
- 0.9374221098423005
- 0.9342694067955017
- 0.9309488415718079
- 0.9268003797531128
- 0.9247250032424926
- 0.9250129306316376
- 0.9223448634147644
- 0.9222483563423157
- 0.9171817278862
- 0.9170596265792846
- 0.9162261092662811
- 0.9152053320407867
- 0.9144298911094666
- 0.9087793707847596
- 0.9093866550922394
- 0.9089052271842957
- 0.9075181055068969
- 0.9060878956317902
- 0.9058453345298767
- 0.9081109392642975
- 0.9063644766807556
- 0.9048032796382904
- 0.9071369147300721
- 0.9053786242008209
- 0.906297664642334
- 0.9029526102542877
- 0.9041262233257293
- 0.9037462961673737
- 0.906225780248642
- 0.9050124037265778
- 0.9073442268371582
- 0.9056128478050232
- 0.9044332051277161
- 0.9063682198524475
- 0.9051522827148437
- 0.9061144888401031
- 0.9042708444595337
- 0.9043025529384613
- 0.906110053062439
- 0.9056033790111542
- 0.90616504073143
- 0.9068081378936768
- 0.9085853147506714
- 0.9069898867607117
- 0.9111350798606872
- 0.9113744592666626
- 0.907754340171814
- 0.9077921736240387
- 0.9106616914272309
- 0.9121399605274201
- 0.9132091355323791
- 0.9140202033519745
- 0.9128629124164581
- 0.9144856524467468
- 0.9118903303146362
- 0.9160437154769897
- 0.9161626410484314
train_accuracy:
- 0.072
- 0.155
- 0.138
- 0.198
- 0.188
- 0.196
- 0.221
- 0.198
- 0.211
- 0.215
- 0.241
- 0.265
- 0.276
- 0.269
- 0.292
- 0.275
- 0.287
- 0.275
- 0.31
- 0.289
- 0.3
- 0.31
- 0.326
- 0.299
- 0.312
- 0.315
- 0.315
- 0.356
- 0.327
- 0.321
- 0.323
- 0.325
- 0.318
- 0.36
- 0.328
- 0.371
- 0.328
- 0.364
- 0.368
- 0.353
- 0.331
- 0.373
- 0.392
- 0.365
- 0.37
- 0.4
- 0.39
- 0.36
- 0.397
- 0.358
- 0.398
- 0.376
- 0.396
- 0.38
- 0.4
- 0.35
- 0.4
- 0.362
- 0.393
- 0.402
- 0.393
- 0.368
- 0.411
- 0.38
- 0.357
- 0.404
- 0.364
- 0.358
- 0.419
- 0.422
- 0.413
- 0.42
- 0.392
- 0.417
- 0.361
- 0.388
- 0.409
- 0.429
- 0.369
- 0.41
- 0.43
- 0.419
- 0.41
- 0.397
- 0.374
- 0.381
- 0.388
- 0.367
- 0.422
- 0.434
- 0.405
- 0.433
- 0.424
- 0.418
- 0.414
- 0.397
- 0.378
- 0.403
- 0.418
- 0.379
train_loss:
- 4.227
- 3.752
- 3.507
- 3.325
- 3.218
- 3.082
- 2.96
- 2.868
- 2.772
- 2.689
- 2.628
- 2.521
- 2.477
- 2.442
- 2.344
- 2.277
- 2.245
- 2.187
- 2.117
- 2.049
- 2.035
- 1.947
- 1.939
- 1.855
- 1.834
- 1.776
- 1.728
- 1.705
- 1.67
- 1.632
- 1.589
- 1.506
- 1.476
- 1.513
- 1.444
- 1.389
- 1.398
- 1.312
- 1.311
- 1.248
- 1.273
- 1.231
- 1.215
- 1.144
- 1.113
- 1.116
- 1.032
- 1.055
- 1.039
- 0.993
- 1.0
- 0.937
- 0.916
- 0.902
- 0.873
- 0.854
- 0.827
- 0.824
- 0.788
- 0.755
- 0.773
- 0.708
- 0.724
- 0.692
- 0.659
- 0.628
- 0.624
- 0.599
- 0.628
- 0.589
- 0.574
- 0.561
- 0.535
- 0.522
- 0.508
- 0.507
- 0.497
- 0.457
- 0.445
- 0.471
- 0.446
- 0.445
- 0.421
- 0.417
- 0.39
- 0.389
- 0.372
- 0.372
- 0.367
- 0.365
- 0.341
- 0.334
- 0.332
- 0.318
- 0.3
- 0.323
- 0.298
- 0.3
- 0.285
- 0.283
unequal: 0
verbose: 1
