avg_train_accuracy: 0.418
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0988
- 0.1404
- 0.1673
- 0.1886
- 0.2012
- 0.2199
- 0.2327
- 0.2436
- 0.2557
- 0.2675
- 0.2743
- 0.2803
- 0.2894
- 0.2916
- 0.3016
- 0.3126
- 0.3113
- 0.3204
- 0.3234
- 0.3304
- 0.3351
- 0.3359
- 0.3428
- 0.3448
- 0.3488
- 0.3568
- 0.3593
- 0.3631
- 0.367
- 0.3684
- 0.3682
- 0.3746
- 0.3741
- 0.381
- 0.3789
- 0.3787
- 0.3841
- 0.3888
- 0.3839
- 0.3876
- 0.3914
- 0.3917
- 0.3928
- 0.3929
- 0.3959
- 0.398
- 0.3986
- 0.3999
- 0.397
- 0.403
- 0.4082
- 0.4027
- 0.4018
- 0.4082
- 0.4071
- 0.4101
- 0.41
- 0.4097
- 0.4113
- 0.416
- 0.4133
- 0.416
- 0.4157
- 0.4169
- 0.4202
- 0.4143
- 0.42
- 0.417
- 0.4206
- 0.4177
- 0.4189
- 0.4231
- 0.4214
- 0.4207
- 0.4222
- 0.4237
- 0.424
- 0.4241
- 0.4253
- 0.4248
- 0.4241
- 0.4268
- 0.4232
- 0.4256
- 0.4272
- 0.4278
- 0.425
- 0.4255
- 0.4285
- 0.4275
- 0.4282
- 0.4271
- 0.4291
- 0.4294
- 0.4288
- 0.4295
- 0.4292
- 0.4292
- 0.4302
- 0.4295
test_loss_list:
- 1.6440936088562013
- 1.5253886771202088
- 1.4533180689811707
- 1.400745096206665
- 1.360924756526947
- 1.3276419258117675
- 1.2971620869636535
- 1.2709574007987976
- 1.2449100017547607
- 1.2239943313598634
- 1.2035422539710998
- 1.1861122345924378
- 1.1679233980178834
- 1.153752281665802
- 1.1379960083961487
- 1.1213113689422607
- 1.1104530096054077
- 1.0946306300163269
- 1.0849151039123535
- 1.0744222140312194
- 1.066611409187317
- 1.0586874270439148
- 1.044101288318634
- 1.0419689893722535
- 1.032111120223999
- 1.0231288623809816
- 1.0141454243659973
- 1.0057724118232727
- 1.0030227565765382
- 0.9990036916732788
- 0.9930284929275512
- 0.9862984609603882
- 0.9786875414848327
- 0.974052083492279
- 0.9730518126487732
- 0.9673980331420898
- 0.9645675039291381
- 0.9606075429916382
- 0.9600642585754394
- 0.9535893702507019
- 0.9523582530021667
- 0.9490804481506347
- 0.9477515769004822
- 0.9459832978248596
- 0.9435500597953796
- 0.9432858419418335
- 0.9405571031570434
- 0.9414104032516479
- 0.9393263816833496
- 0.9344640350341797
- 0.9297408699989319
- 0.9355397534370422
- 0.9328613662719727
- 0.9310801196098327
- 0.9313317680358887
- 0.9264603519439697
- 0.9247303855419159
- 0.926070647239685
- 0.9255134701728821
- 0.9233777475357056
- 0.9227838516235352
- 0.9203134036064148
- 0.922854037284851
- 0.9211125755310059
- 0.9227159905433655
- 0.921946873664856
- 0.9209546995162964
- 0.9217182767391204
- 0.921874132156372
- 0.9295405578613282
- 0.9290525412559509
- 0.9253806447982789
- 0.9261920988559723
- 0.9271056842803955
- 0.9249503970146179
- 0.9259782147407531
- 0.9237610816955566
- 0.9241136181354522
- 0.9265637040138245
- 0.9251948654651642
- 0.9255181908607483
- 0.9276115894317627
- 0.929012520313263
- 0.9294500803947449
- 0.9285950446128846
- 0.93183340549469
- 0.9306794011592865
- 0.931652479171753
- 0.9309149527549744
- 0.9312612473964691
- 0.9366594505310059
- 0.9368689024448394
- 0.9354852771759034
- 0.934395968914032
- 0.9359559905529022
- 0.9350077366828918
- 0.9368743288516999
- 0.9390803587436676
- 0.9388433742523193
- 0.938368753194809
train_accuracy:
- 0.091
- 0.122
- 0.164
- 0.179
- 0.153
- 0.182
- 0.227
- 0.237
- 0.206
- 0.251
- 0.228
- 0.281
- 0.267
- 0.289
- 0.245
- 0.3
- 0.308
- 0.316
- 0.279
- 0.296
- 0.305
- 0.29
- 0.295
- 0.322
- 0.343
- 0.322
- 0.332
- 0.355
- 0.36
- 0.343
- 0.373
- 0.362
- 0.326
- 0.32
- 0.368
- 0.339
- 0.349
- 0.379
- 0.353
- 0.322
- 0.352
- 0.37
- 0.357
- 0.396
- 0.379
- 0.411
- 0.385
- 0.393
- 0.392
- 0.405
- 0.347
- 0.394
- 0.392
- 0.37
- 0.398
- 0.42
- 0.421
- 0.398
- 0.415
- 0.39
- 0.374
- 0.4
- 0.408
- 0.382
- 0.371
- 0.405
- 0.397
- 0.424
- 0.351
- 0.402
- 0.402
- 0.357
- 0.401
- 0.401
- 0.396
- 0.442
- 0.426
- 0.407
- 0.417
- 0.406
- 0.435
- 0.404
- 0.351
- 0.4
- 0.39
- 0.392
- 0.436
- 0.448
- 0.42
- 0.431
- 0.394
- 0.416
- 0.441
- 0.431
- 0.4
- 0.416
- 0.399
- 0.393
- 0.426
- 0.418
train_loss:
- 4.196
- 3.739
- 3.505
- 3.315
- 3.176
- 3.056
- 2.965
- 2.861
- 2.779
- 2.689
- 2.643
- 2.547
- 2.493
- 2.404
- 2.346
- 2.266
- 2.216
- 2.183
- 2.104
- 2.049
- 2.0
- 1.973
- 1.915
- 1.86
- 1.795
- 1.772
- 1.711
- 1.679
- 1.608
- 1.609
- 1.614
- 1.551
- 1.507
- 1.454
- 1.429
- 1.419
- 1.344
- 1.318
- 1.256
- 1.257
- 1.261
- 1.222
- 1.157
- 1.121
- 1.134
- 1.063
- 1.018
- 0.986
- 0.988
- 0.936
- 0.943
- 0.893
- 0.884
- 0.88
- 0.879
- 0.841
- 0.839
- 0.795
- 0.759
- 0.726
- 0.718
- 0.727
- 0.677
- 0.653
- 0.666
- 0.621
- 0.638
- 0.588
- 0.591
- 0.546
- 0.557
- 0.533
- 0.508
- 0.509
- 0.508
- 0.472
- 0.475
- 0.47
- 0.431
- 0.455
- 0.429
- 0.416
- 0.406
- 0.38
- 0.379
- 0.365
- 0.372
- 0.36
- 0.352
- 0.338
- 0.316
- 0.314
- 0.328
- 0.305
- 0.327
- 0.299
- 0.301
- 0.286
- 0.283
- 0.271
unequal: 0
verbose: 1
