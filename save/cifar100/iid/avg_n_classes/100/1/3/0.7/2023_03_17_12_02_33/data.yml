avg_train_accuracy: 0.425
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.098
- 0.1363
- 0.1662
- 0.1822
- 0.2003
- 0.2138
- 0.2248
- 0.2381
- 0.2452
- 0.256
- 0.265
- 0.2726
- 0.2822
- 0.2864
- 0.2916
- 0.2969
- 0.3035
- 0.3072
- 0.3128
- 0.3194
- 0.3228
- 0.33
- 0.3324
- 0.3365
- 0.3405
- 0.3435
- 0.35
- 0.3528
- 0.3552
- 0.3608
- 0.362
- 0.3635
- 0.3662
- 0.3745
- 0.3735
- 0.378
- 0.3819
- 0.3829
- 0.3851
- 0.3871
- 0.3897
- 0.394
- 0.3925
- 0.3931
- 0.394
- 0.3964
- 0.3958
- 0.4012
- 0.4011
- 0.4015
- 0.4045
- 0.4072
- 0.4059
- 0.4085
- 0.4097
- 0.4075
- 0.4134
- 0.4114
- 0.4146
- 0.4125
- 0.4151
- 0.4124
- 0.4181
- 0.4155
- 0.4151
- 0.4152
- 0.4188
- 0.4182
- 0.4174
- 0.4199
- 0.4206
- 0.4176
- 0.4183
- 0.4208
- 0.4196
- 0.4183
- 0.4207
- 0.4233
- 0.4203
- 0.4228
- 0.4246
- 0.424
- 0.4239
- 0.4243
- 0.4257
- 0.4254
- 0.4274
- 0.4258
- 0.4274
- 0.4273
- 0.4269
- 0.4285
- 0.4293
- 0.4276
- 0.4276
- 0.4288
- 0.4289
- 0.4288
- 0.4302
- 0.4277
test_loss_list:
- 1.6448598432540893
- 1.525788357257843
- 1.4527533316612244
- 1.4016029405593873
- 1.3604465413093567
- 1.3262291836738587
- 1.2989417791366578
- 1.272683093547821
- 1.2503810977935792
- 1.230948715209961
- 1.2100820755958557
- 1.1920724892616272
- 1.177112855911255
- 1.1621746635437011
- 1.1476912021636962
- 1.1345908761024475
- 1.1222319793701172
- 1.1100338363647462
- 1.0982273364067077
- 1.0868634104728698
- 1.0770352983474731
- 1.0680109429359437
- 1.0585024189949035
- 1.048825306892395
- 1.0403599905967713
- 1.0360778021812438
- 1.0242966401576996
- 1.0207199823856354
- 1.0142916440963745
- 1.005552259683609
- 0.9986716663837433
- 0.9967299747467041
- 0.9932405376434326
- 0.9842566859722137
- 0.9823529648780823
- 0.974182962179184
- 0.9710746705532074
- 0.966597181558609
- 0.9634873592853546
- 0.9586325371265412
- 0.9560023438930512
- 0.9518340587615967
- 0.9503506863117218
- 0.9485440480709076
- 0.9428984308242798
- 0.9423426699638366
- 0.9389256668090821
- 0.9374870550632477
- 0.932803407907486
- 0.9342452025413513
- 0.9324148917198181
- 0.9303693354129792
- 0.9311036157608032
- 0.9252044606208801
- 0.9264199686050415
- 0.926016297340393
- 0.9237887465953827
- 0.9242640399932861
- 0.922492402791977
- 0.9216801130771637
- 0.9230231750011444
- 0.9219415295124054
- 0.920425500869751
- 0.918537573814392
- 0.9185757374763489
- 0.9224928891658783
- 0.919283299446106
- 0.9193417000770568
- 0.9169670772552491
- 0.9183153665065765
- 0.9222765636444091
- 0.9180556607246398
- 0.9203773963451386
- 0.9197596728801727
- 0.9194362008571625
- 0.9221678185462951
- 0.9221236884593964
- 0.9202337682247161
- 0.924433913230896
- 0.9217650675773621
- 0.9185574877262116
- 0.9208838880062103
- 0.9214454078674317
- 0.9219226527214051
- 0.9195017039775848
- 0.9228460359573364
- 0.9199904799461365
- 0.9234518992900849
- 0.9246477091312408
- 0.9214217853546143
- 0.9253920996189118
- 0.9227048146724701
- 0.9262662994861602
- 0.9245409297943116
- 0.9271807432174682
- 0.9288245797157287
- 0.9293653810024262
- 0.9266793751716613
- 0.929754022359848
- 0.9322343742847443
train_accuracy:
- 0.098
- 0.147
- 0.145
- 0.168
- 0.189
- 0.21
- 0.222
- 0.198
- 0.213
- 0.204
- 0.236
- 0.246
- 0.24
- 0.242
- 0.262
- 0.282
- 0.263
- 0.294
- 0.289
- 0.291
- 0.276
- 0.312
- 0.313
- 0.277
- 0.315
- 0.327
- 0.323
- 0.333
- 0.332
- 0.317
- 0.35
- 0.349
- 0.305
- 0.341
- 0.349
- 0.339
- 0.348
- 0.37
- 0.37
- 0.34
- 0.357
- 0.374
- 0.37
- 0.327
- 0.361
- 0.37
- 0.364
- 0.368
- 0.384
- 0.379
- 0.4
- 0.381
- 0.372
- 0.345
- 0.365
- 0.339
- 0.39
- 0.403
- 0.403
- 0.384
- 0.396
- 0.402
- 0.381
- 0.382
- 0.401
- 0.391
- 0.379
- 0.387
- 0.398
- 0.416
- 0.41
- 0.401
- 0.406
- 0.391
- 0.389
- 0.407
- 0.404
- 0.392
- 0.419
- 0.402
- 0.418
- 0.392
- 0.401
- 0.42
- 0.387
- 0.401
- 0.412
- 0.402
- 0.406
- 0.391
- 0.4
- 0.401
- 0.424
- 0.418
- 0.408
- 0.394
- 0.405
- 0.408
- 0.424
- 0.425
train_loss:
- 4.219
- 3.746
- 3.5
- 3.304
- 3.182
- 3.066
- 2.986
- 2.862
- 2.776
- 2.723
- 2.631
- 2.557
- 2.494
- 2.438
- 2.377
- 2.293
- 2.237
- 2.183
- 2.177
- 2.07
- 2.037
- 1.99
- 1.951
- 1.898
- 1.829
- 1.811
- 1.802
- 1.715
- 1.648
- 1.651
- 1.607
- 1.553
- 1.543
- 1.533
- 1.435
- 1.425
- 1.364
- 1.391
- 1.294
- 1.313
- 1.267
- 1.233
- 1.19
- 1.152
- 1.16
- 1.106
- 1.094
- 1.05
- 1.011
- 0.993
- 1.002
- 0.947
- 0.948
- 0.913
- 0.872
- 0.827
- 0.859
- 0.792
- 0.786
- 0.784
- 0.737
- 0.733
- 0.724
- 0.709
- 0.671
- 0.655
- 0.65
- 0.61
- 0.619
- 0.602
- 0.566
- 0.57
- 0.526
- 0.523
- 0.505
- 0.497
- 0.493
- 0.487
- 0.459
- 0.453
- 0.423
- 0.452
- 0.423
- 0.402
- 0.396
- 0.371
- 0.393
- 0.377
- 0.349
- 0.37
- 0.357
- 0.33
- 0.335
- 0.336
- 0.326
- 0.309
- 0.293
- 0.306
- 0.276
- 0.285
unequal: 0
verbose: 1
