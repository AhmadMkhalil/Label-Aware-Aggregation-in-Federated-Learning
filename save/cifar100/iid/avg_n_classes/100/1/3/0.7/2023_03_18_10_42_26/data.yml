avg_train_accuracy: 0.388
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0955
- 0.1387
- 0.1669
- 0.1921
- 0.2057
- 0.2222
- 0.2343
- 0.2483
- 0.2611
- 0.2669
- 0.2802
- 0.2879
- 0.2944
- 0.2982
- 0.3069
- 0.3118
- 0.3147
- 0.3224
- 0.3246
- 0.3319
- 0.3369
- 0.3383
- 0.3443
- 0.3494
- 0.3504
- 0.3553
- 0.3594
- 0.3658
- 0.364
- 0.373
- 0.376
- 0.3734
- 0.3769
- 0.3824
- 0.385
- 0.3855
- 0.3884
- 0.3924
- 0.3932
- 0.3965
- 0.4012
- 0.4009
- 0.4016
- 0.4071
- 0.4059
- 0.4085
- 0.408
- 0.4098
- 0.4103
- 0.4134
- 0.4099
- 0.4113
- 0.4192
- 0.4168
- 0.4172
- 0.4195
- 0.4226
- 0.4207
- 0.4217
- 0.4202
- 0.4191
- 0.4242
- 0.4217
- 0.4237
- 0.4267
- 0.4251
- 0.4259
- 0.4258
- 0.429
- 0.4295
- 0.4286
- 0.4272
- 0.4307
- 0.428
- 0.4271
- 0.4282
- 0.4268
- 0.4319
- 0.4292
- 0.4327
- 0.4324
- 0.435
- 0.4329
- 0.4327
- 0.4335
- 0.4362
- 0.435
- 0.4316
- 0.4314
- 0.4363
- 0.4363
- 0.432
- 0.4361
- 0.4331
- 0.4357
- 0.4349
- 0.4394
- 0.4376
- 0.438
- 0.435
test_loss_list:
- 1.6556588506698608
- 1.52413950920105
- 1.4510593128204345
- 1.3970216417312622
- 1.3571091413497924
- 1.3234841108322144
- 1.2905752658843994
- 1.2657594776153565
- 1.2410387897491455
- 1.2195922660827636
- 1.2000279116630554
- 1.1827775740623474
- 1.1655675268173218
- 1.1496300148963927
- 1.1349122285842896
- 1.1218285870552063
- 1.1096715450286865
- 1.09911673784256
- 1.087374927997589
- 1.0737294721603394
- 1.061544246673584
- 1.0564443111419677
- 1.0422532367706299
- 1.03490802526474
- 1.0315474820137025
- 1.0159230875968932
- 1.0123574686050416
- 1.003220317363739
- 1.0008723092079164
- 0.9911550760269165
- 0.986526427268982
- 0.9854843735694885
- 0.9745249891281128
- 0.9709941601753235
- 0.9667142391204834
- 0.9653444480895996
- 0.9564349055290222
- 0.9525075840950012
- 0.9509419417381286
- 0.9471200919151306
- 0.9423360514640808
- 0.942571473121643
- 0.9384063625335693
- 0.9329395890235901
- 0.9335240411758423
- 0.9321728777885437
- 0.9269329357147217
- 0.9281290626525879
- 0.9259341645240784
- 0.9213406324386597
- 0.9226625108718872
- 0.9194502520561219
- 0.9173954796791076
- 0.9206460213661194
- 0.9184402513504029
- 0.9145317983627319
- 0.9145200061798096
- 0.9136203122138977
- 0.9152382969856262
- 0.9108417367935181
- 0.917473201751709
- 0.910002145767212
- 0.9150365042686462
- 0.9122916102409363
- 0.9092680382728576
- 0.9124687743186951
- 0.9116721534729004
- 0.9121380639076233
- 0.9118380475044251
- 0.9118183302879334
- 0.9100365364551544
- 0.9130215620994568
- 0.9127292275428772
- 0.9118449831008911
- 0.9137175917625427
- 0.9118263459205628
- 0.9161344695091248
- 0.9140901970863342
- 0.9138586008548737
- 0.9113898944854736
- 0.9126299035549164
- 0.9125245213508606
- 0.9143527317047119
- 0.9182222652435302
- 0.9137329983711243
- 0.9119435095787048
- 0.9153777444362641
- 0.9219449520111084
- 0.917701131105423
- 0.9192559218406677
- 0.9211897945404053
- 0.9230741381645202
- 0.9226415038108826
- 0.922151825428009
- 0.9223077034950257
- 0.9226749563217163
- 0.9227074527740479
- 0.9266545128822327
- 0.9302727055549621
- 0.9259363484382629
train_accuracy:
- 0.096
- 0.121
- 0.134
- 0.175
- 0.207
- 0.177
- 0.218
- 0.235
- 0.224
- 0.252
- 0.262
- 0.24
- 0.247
- 0.301
- 0.293
- 0.303
- 0.287
- 0.27
- 0.309
- 0.309
- 0.354
- 0.326
- 0.359
- 0.327
- 0.291
- 0.334
- 0.342
- 0.34
- 0.341
- 0.305
- 0.307
- 0.347
- 0.37
- 0.355
- 0.378
- 0.381
- 0.375
- 0.365
- 0.368
- 0.332
- 0.388
- 0.371
- 0.392
- 0.407
- 0.388
- 0.395
- 0.385
- 0.355
- 0.35
- 0.417
- 0.37
- 0.411
- 0.415
- 0.4
- 0.385
- 0.403
- 0.419
- 0.384
- 0.392
- 0.409
- 0.423
- 0.393
- 0.401
- 0.385
- 0.392
- 0.4
- 0.382
- 0.398
- 0.423
- 0.383
- 0.428
- 0.398
- 0.421
- 0.418
- 0.403
- 0.404
- 0.409
- 0.405
- 0.417
- 0.406
- 0.4
- 0.446
- 0.397
- 0.434
- 0.438
- 0.451
- 0.388
- 0.43
- 0.433
- 0.438
- 0.449
- 0.408
- 0.428
- 0.431
- 0.427
- 0.431
- 0.438
- 0.43
- 0.422
- 0.388
train_loss:
- 4.243
- 3.757
- 3.488
- 3.289
- 3.154
- 3.029
- 2.972
- 2.851
- 2.782
- 2.692
- 2.6
- 2.542
- 2.482
- 2.426
- 2.358
- 2.278
- 2.23
- 2.154
- 2.099
- 2.089
- 2.029
- 1.98
- 1.911
- 1.862
- 1.829
- 1.786
- 1.75
- 1.697
- 1.653
- 1.603
- 1.549
- 1.547
- 1.519
- 1.448
- 1.441
- 1.384
- 1.357
- 1.308
- 1.275
- 1.273
- 1.215
- 1.181
- 1.167
- 1.143
- 1.111
- 1.074
- 1.042
- 0.995
- 1.033
- 0.989
- 0.943
- 0.962
- 0.908
- 0.875
- 0.87
- 0.837
- 0.793
- 0.795
- 0.765
- 0.742
- 0.727
- 0.692
- 0.679
- 0.679
- 0.671
- 0.647
- 0.623
- 0.617
- 0.577
- 0.597
- 0.56
- 0.541
- 0.531
- 0.515
- 0.502
- 0.48
- 0.471
- 0.459
- 0.462
- 0.448
- 0.432
- 0.427
- 0.399
- 0.401
- 0.407
- 0.389
- 0.363
- 0.353
- 0.354
- 0.346
- 0.338
- 0.34
- 0.317
- 0.307
- 0.297
- 0.306
- 0.276
- 0.272
- 0.266
- 0.29
unequal: 0
verbose: 1
