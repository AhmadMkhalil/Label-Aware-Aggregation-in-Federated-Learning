avg_train_accuracy: 0.431
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0927
- 0.1298
- 0.1565
- 0.1829
- 0.2028
- 0.2157
- 0.229
- 0.2415
- 0.2512
- 0.2599
- 0.2705
- 0.2774
- 0.2844
- 0.2909
- 0.2969
- 0.3054
- 0.312
- 0.3205
- 0.3208
- 0.3282
- 0.3344
- 0.3361
- 0.3406
- 0.3492
- 0.3508
- 0.3546
- 0.3565
- 0.3601
- 0.3641
- 0.3672
- 0.3707
- 0.3735
- 0.3775
- 0.3776
- 0.3836
- 0.3824
- 0.3844
- 0.3883
- 0.3875
- 0.3923
- 0.3899
- 0.3961
- 0.3979
- 0.3974
- 0.4009
- 0.4035
- 0.4041
- 0.4019
- 0.4051
- 0.4069
- 0.4077
- 0.4084
- 0.412
- 0.4138
- 0.4103
- 0.4128
- 0.4183
- 0.418
- 0.4179
- 0.4201
- 0.4153
- 0.4185
- 0.4232
- 0.4229
- 0.4208
- 0.4229
- 0.4225
- 0.4243
- 0.4255
- 0.4256
- 0.4239
- 0.4278
- 0.4264
- 0.423
- 0.4281
- 0.4302
- 0.4278
- 0.4312
- 0.4287
- 0.4295
- 0.4288
- 0.4336
- 0.4311
- 0.4327
- 0.4338
- 0.4307
- 0.4366
- 0.4323
- 0.4307
- 0.4344
- 0.4353
- 0.4338
- 0.438
- 0.4379
- 0.4364
- 0.437
- 0.438
- 0.4394
- 0.4371
- 0.4364
test_loss_list:
- 1.64343181848526
- 1.52912978887558
- 1.4549337387084962
- 1.402936577796936
- 1.3606618714332581
- 1.3269473552703857
- 1.296918077468872
- 1.2713920402526855
- 1.2474609518051147
- 1.225373854637146
- 1.2048236966133117
- 1.1862588095664979
- 1.1690333604812622
- 1.1538726997375488
- 1.1389573788642884
- 1.1250177025794983
- 1.112577657699585
- 1.1014833879470824
- 1.0860550594329834
- 1.0764302611351013
- 1.0647741198539733
- 1.057349135875702
- 1.0452274441719056
- 1.0354653787612915
- 1.0268440437316895
- 1.0198709177970886
- 1.011894600391388
- 1.0066284561157226
- 0.9965039229393006
- 0.9924547100067138
- 0.9828771138191223
- 0.9788659834861755
- 0.9782743012905121
- 0.9742887985706329
- 0.9665339088439941
- 0.9627768421173095
- 0.9584185481071472
- 0.9565322971343995
- 0.9511828708648682
- 0.9504319167137146
- 0.9443294417858124
- 0.9403964519500733
- 0.9380813038349152
- 0.9361046659946441
- 0.93408132314682
- 0.9292136061191559
- 0.9301116871833801
- 0.9310123336315155
- 0.9252842772006988
- 0.9228575658798218
- 0.9216320061683655
- 0.9195499396324158
- 0.9190385901927948
- 0.9192866563796998
- 0.9197372913360595
- 0.9208535027503967
- 0.914619128704071
- 0.9121422934532165
- 0.9137540829181671
- 0.9132726943492889
- 0.9176087057590485
- 0.9167876136302948
- 0.9105305278301239
- 0.9088526213169098
- 0.9113729989528656
- 0.9124911499023437
- 0.9127836108207703
- 0.912323706150055
- 0.9096630489826203
- 0.907163747549057
- 0.9113924038410187
- 0.9080949950218201
- 0.9110820662975311
- 0.9106297326087952
- 0.9073179340362549
- 0.9077588963508606
- 0.9099364483356476
- 0.9080621206760406
- 0.9103599727153778
- 0.9162877249717712
- 0.9111073708534241
- 0.9101107716560364
- 0.9111179554462433
- 0.9132278490066529
- 0.9120272123813629
- 0.9145163774490357
- 0.9147163832187652
- 0.9130741560459137
- 0.9136972665786743
- 0.9152043724060058
- 0.9151555800437927
- 0.9167632865905762
- 0.9154495847225189
- 0.9182495045661926
- 0.9183346629142761
- 0.9181713902950287
- 0.9188801670074462
- 0.9172707188129425
- 0.9214790451526642
- 0.9212556564807892
train_accuracy:
- 0.09
- 0.102
- 0.144
- 0.164
- 0.166
- 0.174
- 0.227
- 0.206
- 0.224
- 0.232
- 0.263
- 0.263
- 0.267
- 0.266
- 0.258
- 0.303
- 0.312
- 0.277
- 0.315
- 0.302
- 0.295
- 0.303
- 0.295
- 0.322
- 0.341
- 0.321
- 0.32
- 0.354
- 0.328
- 0.342
- 0.332
- 0.35
- 0.376
- 0.363
- 0.356
- 0.338
- 0.36
- 0.384
- 0.364
- 0.37
- 0.352
- 0.352
- 0.388
- 0.373
- 0.392
- 0.385
- 0.363
- 0.395
- 0.394
- 0.382
- 0.368
- 0.391
- 0.354
- 0.348
- 0.337
- 0.364
- 0.353
- 0.406
- 0.401
- 0.408
- 0.374
- 0.398
- 0.406
- 0.409
- 0.416
- 0.42
- 0.351
- 0.355
- 0.418
- 0.392
- 0.409
- 0.413
- 0.425
- 0.384
- 0.414
- 0.424
- 0.409
- 0.413
- 0.397
- 0.417
- 0.426
- 0.402
- 0.393
- 0.36
- 0.429
- 0.419
- 0.395
- 0.414
- 0.417
- 0.412
- 0.395
- 0.436
- 0.399
- 0.426
- 0.442
- 0.44
- 0.428
- 0.373
- 0.438
- 0.431
train_loss:
- 4.255
- 3.749
- 3.518
- 3.344
- 3.214
- 3.087
- 2.977
- 2.871
- 2.805
- 2.722
- 2.618
- 2.569
- 2.511
- 2.424
- 2.358
- 2.294
- 2.246
- 2.19
- 2.137
- 2.082
- 2.022
- 1.959
- 1.932
- 1.884
- 1.846
- 1.777
- 1.733
- 1.711
- 1.644
- 1.6
- 1.59
- 1.548
- 1.518
- 1.465
- 1.425
- 1.377
- 1.357
- 1.339
- 1.317
- 1.245
- 1.241
- 1.222
- 1.183
- 1.139
- 1.125
- 1.084
- 1.064
- 1.012
- 1.017
- 0.99
- 0.944
- 0.92
- 0.908
- 0.873
- 0.857
- 0.814
- 0.825
- 0.798
- 0.768
- 0.765
- 0.736
- 0.704
- 0.708
- 0.673
- 0.647
- 0.639
- 0.612
- 0.601
- 0.587
- 0.588
- 0.545
- 0.553
- 0.532
- 0.536
- 0.505
- 0.486
- 0.462
- 0.454
- 0.443
- 0.447
- 0.436
- 0.432
- 0.423
- 0.398
- 0.394
- 0.387
- 0.37
- 0.365
- 0.352
- 0.345
- 0.349
- 0.332
- 0.331
- 0.309
- 0.313
- 0.303
- 0.294
- 0.293
- 0.279
- 0.275
unequal: 0
verbose: 1
