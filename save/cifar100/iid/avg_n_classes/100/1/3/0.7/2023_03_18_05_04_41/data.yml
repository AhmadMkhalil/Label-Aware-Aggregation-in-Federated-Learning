avg_train_accuracy: 0.429
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0961
- 0.138
- 0.17
- 0.193
- 0.2091
- 0.2204
- 0.2306
- 0.245
- 0.251
- 0.2652
- 0.2714
- 0.2794
- 0.2875
- 0.2995
- 0.3045
- 0.3113
- 0.3157
- 0.3213
- 0.3255
- 0.332
- 0.3378
- 0.3437
- 0.3472
- 0.3535
- 0.3594
- 0.3574
- 0.3645
- 0.367
- 0.37
- 0.3731
- 0.3781
- 0.3777
- 0.3787
- 0.3837
- 0.3858
- 0.3848
- 0.386
- 0.3918
- 0.3923
- 0.3956
- 0.3968
- 0.3989
- 0.4005
- 0.4035
- 0.4029
- 0.4027
- 0.4018
- 0.4035
- 0.4034
- 0.4093
- 0.4102
- 0.4108
- 0.4118
- 0.4104
- 0.4164
- 0.4156
- 0.4173
- 0.4165
- 0.4171
- 0.4164
- 0.4196
- 0.4202
- 0.4208
- 0.4205
- 0.418
- 0.4193
- 0.4236
- 0.4204
- 0.4212
- 0.4255
- 0.4228
- 0.4234
- 0.4271
- 0.4223
- 0.424
- 0.4272
- 0.4271
- 0.428
- 0.4271
- 0.4296
- 0.4273
- 0.4308
- 0.4326
- 0.4311
- 0.4315
- 0.4292
- 0.4327
- 0.4338
- 0.4315
- 0.4329
- 0.4332
- 0.4346
- 0.4337
- 0.4332
- 0.4334
- 0.43
- 0.4358
- 0.4342
- 0.4339
- 0.4346
test_loss_list:
- 1.637941780090332
- 1.525428009033203
- 1.450340552330017
- 1.3976834678649903
- 1.3569383668899535
- 1.3243617868423463
- 1.2950597596168518
- 1.2677276921272278
- 1.245290582180023
- 1.2212376976013184
- 1.2025276470184325
- 1.1852077388763427
- 1.1683514547348022
- 1.1524923825263977
- 1.1342434072494507
- 1.1206526803970336
- 1.1087406396865844
- 1.095243182182312
- 1.0825658655166626
- 1.0700124955177308
- 1.0601298999786377
- 1.0484691524505616
- 1.0412583017349244
- 1.033951051235199
- 1.0234515714645385
- 1.0224331879615784
- 1.0116394305229186
- 1.0041046237945557
- 0.9991424942016601
- 0.9942375469207764
- 0.9864622759819031
- 0.9840838646888733
- 0.9813657116889953
- 0.9769752764701843
- 0.9690970396995544
- 0.9689164471626281
- 0.9662264466285706
- 0.9563492572307587
- 0.9555925786495209
- 0.9551134896278382
- 0.9497420787811279
- 0.9499610137939453
- 0.9439108920097351
- 0.9418361127376557
- 0.9424220883846283
- 0.9436616897583008
- 0.9398989474773407
- 0.9363998389244079
- 0.9352691972255707
- 0.9304361736774445
- 0.9289219355583191
- 0.9292132830619813
- 0.9257826769351959
- 0.926930832862854
- 0.9217340695858002
- 0.9273692727088928
- 0.9239785897731781
- 0.9230057299137115
- 0.9235879838466644
- 0.923391330242157
- 0.9197107458114624
- 0.9218360662460328
- 0.9178121054172516
- 0.917985029220581
- 0.9200838768482208
- 0.9202398312091827
- 0.9184817695617675
- 0.917011548280716
- 0.9190960705280304
- 0.9151750707626343
- 0.9188931727409363
- 0.9188119542598724
- 0.9175319373607635
- 0.9201749563217163
- 0.9203244221210479
- 0.9228085386753082
- 0.921721694469452
- 0.9213990414142609
- 0.9246481120586395
- 0.919654757976532
- 0.9199284625053405
- 0.9222462749481202
- 0.9254242372512818
- 0.922575911283493
- 0.9223683965206146
- 0.923313993215561
- 0.9235946404933929
- 0.9230350065231323
- 0.9230731797218322
- 0.9247182929515838
- 0.9241642081737518
- 0.9243674945831298
- 0.9245932304859161
- 0.9270656144618988
- 0.9293794572353363
- 0.9339109790325165
- 0.9324095225334168
- 0.9284045422077178
- 0.9268052363395691
- 0.9303875398635865
train_accuracy:
- 0.101
- 0.151
- 0.152
- 0.186
- 0.197
- 0.186
- 0.187
- 0.219
- 0.244
- 0.253
- 0.247
- 0.251
- 0.256
- 0.242
- 0.294
- 0.287
- 0.308
- 0.286
- 0.28
- 0.302
- 0.317
- 0.319
- 0.303
- 0.333
- 0.336
- 0.309
- 0.329
- 0.333
- 0.333
- 0.308
- 0.344
- 0.345
- 0.349
- 0.362
- 0.361
- 0.337
- 0.337
- 0.37
- 0.365
- 0.359
- 0.366
- 0.343
- 0.368
- 0.378
- 0.365
- 0.374
- 0.392
- 0.369
- 0.392
- 0.364
- 0.367
- 0.372
- 0.386
- 0.389
- 0.423
- 0.375
- 0.384
- 0.411
- 0.419
- 0.392
- 0.39
- 0.421
- 0.407
- 0.425
- 0.377
- 0.401
- 0.374
- 0.386
- 0.388
- 0.412
- 0.406
- 0.374
- 0.386
- 0.397
- 0.398
- 0.388
- 0.394
- 0.409
- 0.383
- 0.379
- 0.412
- 0.407
- 0.394
- 0.396
- 0.386
- 0.402
- 0.448
- 0.405
- 0.406
- 0.426
- 0.437
- 0.425
- 0.431
- 0.402
- 0.432
- 0.387
- 0.391
- 0.428
- 0.419
- 0.429
train_loss:
- 4.19
- 3.728
- 3.466
- 3.302
- 3.172
- 3.049
- 2.962
- 2.855
- 2.764
- 2.708
- 2.616
- 2.525
- 2.471
- 2.395
- 2.36
- 2.267
- 2.214
- 2.182
- 2.137
- 2.05
- 2.0
- 1.946
- 1.911
- 1.861
- 1.813
- 1.761
- 1.73
- 1.68
- 1.646
- 1.603
- 1.579
- 1.515
- 1.479
- 1.453
- 1.461
- 1.386
- 1.358
- 1.327
- 1.265
- 1.245
- 1.211
- 1.184
- 1.152
- 1.126
- 1.149
- 1.056
- 1.065
- 0.992
- 1.005
- 0.994
- 0.946
- 0.952
- 0.901
- 0.871
- 0.852
- 0.83
- 0.787
- 0.778
- 0.76
- 0.741
- 0.713
- 0.687
- 0.705
- 0.647
- 0.651
- 0.651
- 0.611
- 0.595
- 0.589
- 0.589
- 0.559
- 0.533
- 0.529
- 0.511
- 0.485
- 0.486
- 0.481
- 0.449
- 0.45
- 0.433
- 0.43
- 0.424
- 0.391
- 0.404
- 0.398
- 0.366
- 0.376
- 0.358
- 0.353
- 0.35
- 0.337
- 0.336
- 0.322
- 0.307
- 0.297
- 0.296
- 0.283
- 0.293
- 0.289
- 0.278
unequal: 0
verbose: 1
