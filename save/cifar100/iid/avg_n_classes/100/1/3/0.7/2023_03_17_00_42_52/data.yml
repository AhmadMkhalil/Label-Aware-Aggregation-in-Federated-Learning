avg_train_accuracy: 0.406
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0989
- 0.1459
- 0.1735
- 0.192
- 0.2065
- 0.2226
- 0.2338
- 0.244
- 0.2538
- 0.2651
- 0.2707
- 0.2797
- 0.2878
- 0.2954
- 0.3026
- 0.3084
- 0.3133
- 0.3214
- 0.3287
- 0.334
- 0.3393
- 0.3399
- 0.3461
- 0.3479
- 0.3536
- 0.3576
- 0.3584
- 0.3643
- 0.3645
- 0.3694
- 0.3668
- 0.377
- 0.3776
- 0.3775
- 0.3774
- 0.3801
- 0.3833
- 0.3863
- 0.3891
- 0.3897
- 0.3938
- 0.3929
- 0.3922
- 0.3963
- 0.3964
- 0.3988
- 0.401
- 0.3996
- 0.3987
- 0.4042
- 0.4021
- 0.4055
- 0.4055
- 0.4067
- 0.4083
- 0.4118
- 0.41
- 0.4109
- 0.4117
- 0.4145
- 0.4141
- 0.4156
- 0.4162
- 0.4161
- 0.4175
- 0.4193
- 0.419
- 0.4174
- 0.4219
- 0.4196
- 0.419
- 0.4191
- 0.4217
- 0.4226
- 0.4223
- 0.4236
- 0.4237
- 0.4234
- 0.4235
- 0.4252
- 0.4252
- 0.4245
- 0.4239
- 0.4242
- 0.4266
- 0.4251
- 0.426
- 0.425
- 0.4253
- 0.4284
- 0.4295
- 0.4265
- 0.4269
- 0.4267
- 0.4273
- 0.4278
- 0.4299
- 0.4293
- 0.4301
- 0.4285
test_loss_list:
- 1.6421504187583924
- 1.5199302792549134
- 1.4441284537315369
- 1.3959185671806336
- 1.35456839799881
- 1.3211860346794129
- 1.2920720291137695
- 1.2642709255218505
- 1.241251232624054
- 1.2199524784088134
- 1.2008180665969848
- 1.1834607434272766
- 1.1671220207214354
- 1.1530141043663025
- 1.1353886318206787
- 1.122686095237732
- 1.1080437016487121
- 1.0936025595664978
- 1.0783647227287292
- 1.0680316638946534
- 1.0582306838035584
- 1.051042456626892
- 1.037682077884674
- 1.0323976922035216
- 1.022576777935028
- 1.016929385662079
- 1.00912832736969
- 1.0043886089324952
- 0.99632310628891
- 0.9908866715431214
- 0.990377562046051
- 0.9806258463859558
- 0.975307469367981
- 0.9729111361503601
- 0.9675373435020447
- 0.9618882989883423
- 0.958126676082611
- 0.953672536611557
- 0.9509271717071534
- 0.9450852799415589
- 0.9413623487949372
- 0.9406373167037964
- 0.9394114017486572
- 0.9343239045143128
- 0.9346408343315125
- 0.9325164365768432
- 0.932277934551239
- 0.9280398082733154
- 0.9281039071083069
- 0.9224701309204102
- 0.9207345461845398
- 0.9181734538078308
- 0.9212042117118835
- 0.9161077272891999
- 0.9153567826747895
- 0.9129382038116455
- 0.9145168030261993
- 0.9120383846759796
- 0.9142940175533295
- 0.9105183744430542
- 0.9139195954799653
- 0.9103357398509979
- 0.9106227600574494
- 0.9091359305381775
- 0.9080128169059754
- 0.9074554681777954
- 0.9064998757839203
- 0.9083165264129639
- 0.908034393787384
- 0.909370801448822
- 0.9089552676677704
- 0.912683492898941
- 0.908482483625412
- 0.9063992786407471
- 0.9083031606674195
- 0.9088009440898895
- 0.9102083289623261
- 0.9093003404140473
- 0.912442809343338
- 0.9100546360015869
- 0.9139699828624726
- 0.9098234832286834
- 0.9145461618900299
- 0.9124119901657104
- 0.9120863318443299
- 0.9156708991527558
- 0.9150369834899902
- 0.9165427947044372
- 0.9166297686100006
- 0.9164864349365235
- 0.9149448192119598
- 0.9157399094104767
- 0.9145688188076019
- 0.9158555269241333
- 0.9193825936317443
- 0.9222362911701203
- 0.9219360125064849
- 0.9218567621707916
- 0.9205180704593658
- 0.9206065917015076
train_accuracy:
- 0.091
- 0.131
- 0.146
- 0.162
- 0.186
- 0.205
- 0.202
- 0.233
- 0.216
- 0.239
- 0.233
- 0.275
- 0.295
- 0.284
- 0.259
- 0.293
- 0.268
- 0.286
- 0.293
- 0.295
- 0.304
- 0.322
- 0.299
- 0.305
- 0.37
- 0.339
- 0.326
- 0.312
- 0.342
- 0.372
- 0.327
- 0.332
- 0.331
- 0.342
- 0.346
- 0.375
- 0.396
- 0.386
- 0.373
- 0.378
- 0.375
- 0.358
- 0.363
- 0.354
- 0.398
- 0.386
- 0.399
- 0.382
- 0.413
- 0.377
- 0.364
- 0.369
- 0.382
- 0.411
- 0.366
- 0.376
- 0.401
- 0.395
- 0.391
- 0.395
- 0.402
- 0.408
- 0.401
- 0.4
- 0.399
- 0.416
- 0.385
- 0.404
- 0.423
- 0.374
- 0.424
- 0.386
- 0.383
- 0.412
- 0.378
- 0.401
- 0.4
- 0.414
- 0.407
- 0.397
- 0.411
- 0.395
- 0.415
- 0.412
- 0.395
- 0.388
- 0.414
- 0.388
- 0.402
- 0.397
- 0.39
- 0.403
- 0.399
- 0.413
- 0.429
- 0.393
- 0.419
- 0.402
- 0.43
- 0.406
train_loss:
- 4.227
- 3.739
- 3.485
- 3.298
- 3.176
- 3.051
- 2.939
- 2.899
- 2.776
- 2.69
- 2.61
- 2.549
- 2.474
- 2.373
- 2.322
- 2.24
- 2.259
- 2.151
- 2.123
- 2.043
- 2.027
- 1.929
- 1.913
- 1.842
- 1.805
- 1.718
- 1.741
- 1.691
- 1.649
- 1.656
- 1.566
- 1.554
- 1.519
- 1.423
- 1.419
- 1.407
- 1.367
- 1.369
- 1.315
- 1.258
- 1.258
- 1.224
- 1.159
- 1.168
- 1.123
- 1.063
- 1.06
- 1.002
- 1.0
- 0.991
- 0.985
- 0.96
- 0.889
- 0.892
- 0.886
- 0.844
- 0.823
- 0.824
- 0.75
- 0.784
- 0.747
- 0.715
- 0.709
- 0.675
- 0.668
- 0.667
- 0.635
- 0.61
- 0.593
- 0.584
- 0.549
- 0.548
- 0.532
- 0.531
- 0.51
- 0.487
- 0.486
- 0.481
- 0.471
- 0.443
- 0.434
- 0.434
- 0.404
- 0.403
- 0.402
- 0.375
- 0.372
- 0.352
- 0.355
- 0.341
- 0.353
- 0.336
- 0.32
- 0.323
- 0.311
- 0.305
- 0.29
- 0.286
- 0.284
- 0.277
unequal: 0
verbose: 1
