avg_train_accuracy: 0.402
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1015
- 0.141
- 0.1655
- 0.1889
- 0.2078
- 0.2216
- 0.2362
- 0.2454
- 0.2579
- 0.2656
- 0.276
- 0.2816
- 0.2887
- 0.2964
- 0.3032
- 0.3083
- 0.3147
- 0.3177
- 0.3254
- 0.3325
- 0.3366
- 0.3391
- 0.3476
- 0.352
- 0.3538
- 0.3551
- 0.3586
- 0.3644
- 0.3691
- 0.3714
- 0.3746
- 0.3768
- 0.3762
- 0.3836
- 0.387
- 0.3874
- 0.3912
- 0.3933
- 0.3978
- 0.3967
- 0.4004
- 0.4015
- 0.4049
- 0.4084
- 0.406
- 0.4087
- 0.4098
- 0.4102
- 0.4149
- 0.4137
- 0.416
- 0.4155
- 0.4174
- 0.4181
- 0.4199
- 0.4204
- 0.4215
- 0.4222
- 0.4217
- 0.4243
- 0.424
- 0.4264
- 0.4265
- 0.4277
- 0.4247
- 0.4282
- 0.428
- 0.4277
- 0.4298
- 0.4294
- 0.4302
- 0.4274
- 0.4314
- 0.4337
- 0.4314
- 0.4315
- 0.4347
- 0.432
- 0.4333
- 0.4357
- 0.4334
- 0.4352
- 0.4362
- 0.4372
- 0.4351
- 0.4345
- 0.4368
- 0.4359
- 0.436
- 0.4394
- 0.4389
- 0.4386
- 0.4372
- 0.4396
- 0.4378
- 0.4387
- 0.4402
- 0.4406
- 0.4413
- 0.437
test_loss_list:
- 1.6318509578704834
- 1.5144140648841857
- 1.4450964903831482
- 1.3908482027053832
- 1.352546808719635
- 1.3208839201927185
- 1.2900916671752929
- 1.2640214896202087
- 1.242801880836487
- 1.2232232213020324
- 1.2034609246253967
- 1.1846219897270203
- 1.1719533395767212
- 1.1557832264900207
- 1.13751238822937
- 1.1247651433944703
- 1.112187955379486
- 1.099813425540924
- 1.0858476281166076
- 1.0761687183380126
- 1.0674691152572633
- 1.0570909214019775
- 1.0434617400169373
- 1.0365726661682129
- 1.0283486533164978
- 1.0181694984436036
- 1.0166641855239869
- 1.0043138933181763
- 0.9971755123138428
- 0.9909572625160217
- 0.9882226657867431
- 0.9873523020744324
- 0.979593460559845
- 0.9729907703399658
- 0.9686908936500549
- 0.9630849409103394
- 0.9603377199172973
- 0.9551782214641571
- 0.9555565428733825
- 0.9515130686759948
- 0.9469631218910217
- 0.9430931115150452
- 0.9408379375934601
- 0.9378720295429229
- 0.939690957069397
- 0.9350892889499665
- 0.9312353122234345
- 0.9305987203121185
- 0.930911694765091
- 0.9284705948829651
- 0.9242428123950959
- 0.9236194205284118
- 0.9219398140907288
- 0.9225174403190612
- 0.9208071744441986
- 0.9162992691993713
- 0.9172499001026153
- 0.9172947955131531
- 0.9168533122539521
- 0.915712696313858
- 0.9189535522460938
- 0.916414498090744
- 0.9143541955947876
- 0.9111836683750153
- 0.9132594549655915
- 0.9143809282779694
- 0.912426278591156
- 0.9154289090633392
- 0.913092405796051
- 0.9155318188667297
- 0.917403199672699
- 0.913394821882248
- 0.9132450330257416
- 0.9126629996299743
- 0.9153428399562835
- 0.915028156042099
- 0.9109819138050079
- 0.9122956395149231
- 0.9129455935955048
- 0.9125640940666199
- 0.9168449580669403
- 0.916265572309494
- 0.9175502002239228
- 0.9165258550643921
- 0.9172034132480621
- 0.9190163266658783
- 0.9163148057460785
- 0.9168409383296967
- 0.919443792104721
- 0.9176937210559845
- 0.9178796637058259
- 0.9176786613464355
- 0.9220575618743897
- 0.9221289312839508
- 0.9229354989528656
- 0.924081815481186
- 0.9238162207603454
- 0.9246793699264526
- 0.9239121425151825
- 0.9270837736129761
train_accuracy:
- 0.103
- 0.147
- 0.179
- 0.172
- 0.201
- 0.195
- 0.192
- 0.237
- 0.256
- 0.259
- 0.259
- 0.283
- 0.253
- 0.275
- 0.295
- 0.281
- 0.311
- 0.309
- 0.31
- 0.316
- 0.329
- 0.311
- 0.341
- 0.307
- 0.339
- 0.348
- 0.305
- 0.347
- 0.346
- 0.354
- 0.327
- 0.362
- 0.323
- 0.362
- 0.372
- 0.372
- 0.363
- 0.368
- 0.352
- 0.374
- 0.384
- 0.383
- 0.367
- 0.35
- 0.376
- 0.385
- 0.368
- 0.397
- 0.391
- 0.373
- 0.395
- 0.387
- 0.375
- 0.379
- 0.388
- 0.407
- 0.386
- 0.371
- 0.393
- 0.381
- 0.377
- 0.396
- 0.395
- 0.414
- 0.376
- 0.423
- 0.417
- 0.387
- 0.42
- 0.407
- 0.406
- 0.385
- 0.391
- 0.428
- 0.395
- 0.39
- 0.422
- 0.414
- 0.393
- 0.418
- 0.412
- 0.418
- 0.398
- 0.411
- 0.419
- 0.421
- 0.392
- 0.426
- 0.422
- 0.415
- 0.41
- 0.425
- 0.425
- 0.39
- 0.409
- 0.392
- 0.409
- 0.423
- 0.397
- 0.402
train_loss:
- 4.205
- 3.742
- 3.494
- 3.326
- 3.186
- 3.076
- 2.98
- 2.888
- 2.793
- 2.713
- 2.636
- 2.561
- 2.471
- 2.421
- 2.374
- 2.316
- 2.269
- 2.188
- 2.148
- 2.074
- 2.01
- 1.971
- 1.96
- 1.89
- 1.82
- 1.824
- 1.749
- 1.739
- 1.672
- 1.639
- 1.564
- 1.556
- 1.528
- 1.508
- 1.446
- 1.414
- 1.346
- 1.359
- 1.306
- 1.271
- 1.222
- 1.21
- 1.211
- 1.141
- 1.12
- 1.104
- 1.069
- 1.049
- 1.007
- 0.989
- 0.954
- 0.937
- 0.901
- 0.896
- 0.865
- 0.842
- 0.817
- 0.794
- 0.783
- 0.747
- 0.718
- 0.698
- 0.726
- 0.684
- 0.67
- 0.643
- 0.634
- 0.595
- 0.588
- 0.583
- 0.546
- 0.557
- 0.524
- 0.522
- 0.519
- 0.485
- 0.491
- 0.478
- 0.463
- 0.456
- 0.434
- 0.416
- 0.418
- 0.397
- 0.393
- 0.388
- 0.382
- 0.377
- 0.351
- 0.346
- 0.341
- 0.34
- 0.325
- 0.316
- 0.303
- 0.308
- 0.307
- 0.29
- 0.287
- 0.277
unequal: 0
verbose: 1
