avg_train_accuracy: 0.392
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0892
- 0.1297
- 0.1592
- 0.177
- 0.1977
- 0.2066
- 0.2219
- 0.2295
- 0.2364
- 0.2483
- 0.2611
- 0.2679
- 0.2711
- 0.2796
- 0.2857
- 0.2915
- 0.2971
- 0.2996
- 0.3164
- 0.3132
- 0.3195
- 0.3269
- 0.3364
- 0.3337
- 0.3315
- 0.3407
- 0.3467
- 0.3539
- 0.3497
- 0.3609
- 0.359
- 0.3598
- 0.3581
- 0.3611
- 0.3679
- 0.371
- 0.3675
- 0.3746
- 0.3726
- 0.3821
- 0.384
- 0.3829
- 0.388
- 0.3895
- 0.3868
- 0.3928
- 0.3873
- 0.3939
- 0.3997
- 0.3989
- 0.3956
- 0.3999
- 0.4017
- 0.4003
- 0.4027
- 0.4082
- 0.4076
- 0.407
- 0.4057
- 0.4091
- 0.4096
- 0.4124
- 0.4133
- 0.4151
- 0.4138
- 0.415
- 0.4132
- 0.4151
- 0.4176
- 0.4151
- 0.4166
- 0.4193
- 0.4169
- 0.4176
- 0.42
- 0.4238
- 0.4223
- 0.4197
- 0.4236
- 0.4279
- 0.4221
- 0.4229
- 0.4259
- 0.4217
- 0.4281
- 0.4252
- 0.425
- 0.4306
- 0.4288
- 0.4299
- 0.4278
- 0.4301
- 0.4299
- 0.4284
- 0.4285
- 0.4303
- 0.4294
- 0.4338
- 0.4289
- 0.43
test_loss_list:
- 1.6466424989700317
- 1.5360100865364075
- 1.459965147972107
- 1.4174344897270204
- 1.3770514273643493
- 1.3463258123397828
- 1.318740837574005
- 1.2932007026672363
- 1.2694293713569642
- 1.2404262804985047
- 1.2257429337501526
- 1.2022934913635255
- 1.1869714498519897
- 1.1733387637138366
- 1.16337064743042
- 1.1505775904655458
- 1.1363390612602233
- 1.1238195323944091
- 1.1029736399650574
- 1.0988290882110596
- 1.0853196668624878
- 1.0737683010101318
- 1.0584661722183228
- 1.0533713459968568
- 1.055315110683441
- 1.0455105137825011
- 1.0312355327606202
- 1.0182570219039917
- 1.0213200163841247
- 1.0092644238471984
- 1.0109365224838256
- 1.0054847621917724
- 1.0137393593788147
- 1.0044960618019103
- 0.9929151487350464
- 0.9844970607757568
- 0.9876854372024536
- 0.9781017255783081
- 0.9827009558677673
- 0.9715841937065125
- 0.9625298452377319
- 0.9748579120635986
- 0.9527189946174621
- 0.9555216288566589
- 0.9577092719078064
- 0.9457853722572327
- 0.9534789407253266
- 0.9413014364242553
- 0.9421688222885132
- 0.9398142147064209
- 0.9372546672821045
- 0.9432455325126647
- 0.935064148902893
- 0.9323667263984681
- 0.9367869925498963
- 0.9320103883743286
- 0.9272743153572083
- 0.9271677374839783
- 0.9267279040813446
- 0.9260696601867676
- 0.9266430389881134
- 0.9295755243301391
- 0.9193118858337402
- 0.9207219517230988
- 0.918996250629425
- 0.9255095207691193
- 0.923726214170456
- 0.9201724052429199
- 0.9256807780265808
- 0.9237437438964844
- 0.9261412477493286
- 0.9216243374347687
- 0.9243982613086701
- 0.9259288167953491
- 0.925242166519165
- 0.923758875131607
- 0.9240257740020752
- 0.9208764588832855
- 0.9283912670612335
- 0.9224421346187591
- 0.9223783540725708
- 0.9253283286094666
- 0.9238656532764434
- 0.930882660150528
- 0.9226502633094787
- 0.9267405033111572
- 0.9244607508182525
- 0.9249660730361938
- 0.9254582405090332
- 0.9257937121391296
- 0.924435328245163
- 0.9244628536701203
- 0.9258674311637879
- 0.9284923839569091
- 0.9336855125427246
- 0.9277626979351044
- 0.9367831742763519
- 0.9287336647510529
- 0.9340559113025665
- 0.9357445788383484
train_accuracy:
- 0.09
- 0.114
- 0.136
- 0.172
- 0.174
- 0.186
- 0.172
- 0.208
- 0.221
- 0.247
- 0.221
- 0.243
- 0.24
- 0.247
- 0.247
- 0.262
- 0.272
- 0.275
- 0.278
- 0.282
- 0.282
- 0.294
- 0.318
- 0.298
- 0.299
- 0.325
- 0.317
- 0.304
- 0.319
- 0.33
- 0.323
- 0.308
- 0.318
- 0.337
- 0.35
- 0.352
- 0.344
- 0.352
- 0.347
- 0.356
- 0.345
- 0.336
- 0.366
- 0.34
- 0.348
- 0.367
- 0.373
- 0.373
- 0.368
- 0.341
- 0.354
- 0.393
- 0.37
- 0.378
- 0.372
- 0.365
- 0.408
- 0.378
- 0.37
- 0.387
- 0.396
- 0.388
- 0.4
- 0.382
- 0.377
- 0.392
- 0.375
- 0.392
- 0.384
- 0.391
- 0.398
- 0.394
- 0.38
- 0.398
- 0.386
- 0.378
- 0.4
- 0.384
- 0.404
- 0.396
- 0.41
- 0.38
- 0.389
- 0.386
- 0.417
- 0.387
- 0.41
- 0.414
- 0.414
- 0.422
- 0.399
- 0.39
- 0.404
- 0.415
- 0.388
- 0.399
- 0.399
- 0.406
- 0.394
- 0.392
train_loss:
- 4.225
- 3.76
- 3.561
- 3.351
- 3.226
- 3.089
- 2.95
- 2.913
- 2.758
- 2.812
- 2.605
- 2.62
- 2.577
- 2.414
- 2.299
- 2.352
- 2.252
- 2.218
- 2.302
- 2.129
- 2.166
- 2.046
- 2.167
- 1.916
- 1.78
- 1.779
- 1.828
- 1.905
- 1.668
- 1.79
- 1.545
- 1.486
- 1.464
- 1.467
- 1.569
- 1.636
- 1.317
- 1.294
- 1.139
- 1.623
- 1.345
- 1.124
- 1.451
- 1.243
- 1.196
- 1.18
- 0.946
- 1.285
- 1.212
- 1.11
- 0.958
- 1.021
- 1.138
- 1.003
- 0.847
- 0.967
- 0.89
- 0.816
- 0.893
- 0.996
- 0.68
- 0.809
- 0.754
- 0.87
- 0.715
- 0.643
- 0.651
- 0.772
- 0.711
- 0.601
- 0.578
- 0.594
- 0.597
- 0.484
- 0.589
- 0.501
- 0.589
- 0.495
- 0.586
- 0.56
- 0.563
- 0.439
- 0.459
- 0.373
- 0.48
- 0.362
- 0.404
- 0.454
- 0.404
- 0.435
- 0.394
- 0.39
- 0.359
- 0.329
- 0.305
- 0.34
- 0.278
- 0.325
- 0.292
- 0.26
unequal: 0
verbose: 1
