avg_train_accuracy: 0.379
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0826
- 0.126
- 0.1578
- 0.1763
- 0.1956
- 0.2087
- 0.2219
- 0.2357
- 0.2421
- 0.2532
- 0.2604
- 0.2646
- 0.2775
- 0.279
- 0.2843
- 0.285
- 0.2921
- 0.3057
- 0.3129
- 0.3188
- 0.3186
- 0.3209
- 0.3297
- 0.3334
- 0.3341
- 0.3351
- 0.3327
- 0.3435
- 0.3463
- 0.3489
- 0.3564
- 0.3597
- 0.3621
- 0.3653
- 0.367
- 0.3695
- 0.3769
- 0.3779
- 0.3742
- 0.3795
- 0.3829
- 0.379
- 0.3872
- 0.3857
- 0.3852
- 0.3874
- 0.3942
- 0.3895
- 0.3882
- 0.3898
- 0.3909
- 0.3948
- 0.3994
- 0.3915
- 0.3968
- 0.3988
- 0.4008
- 0.4021
- 0.4064
- 0.4047
- 0.4101
- 0.4118
- 0.4094
- 0.4074
- 0.4072
- 0.4092
- 0.4109
- 0.4111
- 0.4107
- 0.4115
- 0.4086
- 0.413
- 0.4106
- 0.4144
- 0.4101
- 0.4139
- 0.4167
- 0.4127
- 0.416
- 0.4121
- 0.4137
- 0.4215
- 0.4222
- 0.4218
- 0.4237
- 0.4243
- 0.4196
- 0.4272
- 0.4192
- 0.4216
- 0.4206
- 0.4256
- 0.4184
- 0.4268
- 0.4232
- 0.4241
- 0.4253
- 0.423
- 0.426
- 0.4216
test_loss_list:
- 1.666341791152954
- 1.5419968557357788
- 1.470370831489563
- 1.4177904391288758
- 1.377887465953827
- 1.3449212503433228
- 1.3167555356025695
- 1.2874577593803407
- 1.2638648915290833
- 1.2468934392929076
- 1.234571280479431
- 1.2142071342468261
- 1.1899736857414245
- 1.1838175892829894
- 1.1793210196495056
- 1.1734226059913635
- 1.1508332538604735
- 1.1253368186950683
- 1.1154617667198181
- 1.1048462390899658
- 1.0914949178695679
- 1.0799128127098083
- 1.0647779369354249
- 1.0626972198486329
- 1.055741150379181
- 1.0528757691383361
- 1.0646893572807312
- 1.0400490760803223
- 1.0362380361557006
- 1.020992510318756
- 1.0148889446258544
- 1.0028836798667908
- 1.0019690799713135
- 0.9969211852550507
- 0.9933161473274231
- 0.9846864247322082
- 0.9736023879051209
- 0.9767982733249664
- 0.9772203636169433
- 0.973201013803482
- 0.9661910164356232
- 0.9674963295459748
- 0.9594506168365479
- 0.9609797787666321
- 0.959482626914978
- 0.9636270117759704
- 0.9588997507095337
- 0.9711639261245728
- 0.9605627739429474
- 0.9475986671447754
- 0.9569904422760009
- 0.9506115651130677
- 0.9491937303543091
- 0.9489866745471954
- 0.9468035757541656
- 0.9404503512382507
- 0.9475530028343201
- 0.942060821056366
- 0.9453255343437195
- 0.957309467792511
- 0.9422230744361877
- 0.9432707440853119
- 0.9438866639137268
- 0.9370226967334747
- 0.9407782006263733
- 0.9426761531829834
- 0.9364583265781402
- 0.938053686618805
- 0.9375727295875549
- 0.9408372569084168
- 0.9411706447601318
- 0.942361261844635
- 0.9413048470020294
- 0.934838080406189
- 0.9430444431304932
- 0.9317483961582184
- 0.931357433795929
- 0.9431686890125275
- 0.9418467664718628
- 0.9421076679229736
- 0.9396005916595459
- 0.9341683769226075
- 0.9406356489658356
- 0.9463329839706421
- 0.9335953736305237
- 0.9355588352680206
- 0.9397422182559967
- 0.9370616960525513
- 0.94360844373703
- 0.9391429114341736
- 0.9476152575016021
- 0.9368527138233185
- 0.9494635927677154
- 0.9467695236206055
- 0.9448928117752076
- 0.9483518385887146
- 0.9494677603244781
- 0.950672413110733
- 0.9398968255519867
- 0.9505396318435669
train_accuracy:
- 0.083
- 0.123
- 0.151
- 0.145
- 0.176
- 0.182
- 0.197
- 0.223
- 0.208
- 0.246
- 0.218
- 0.219
- 0.254
- 0.235
- 0.24
- 0.238
- 0.289
- 0.27
- 0.307
- 0.292
- 0.303
- 0.261
- 0.307
- 0.296
- 0.311
- 0.312
- 0.326
- 0.295
- 0.33
- 0.317
- 0.338
- 0.319
- 0.328
- 0.345
- 0.315
- 0.324
- 0.34
- 0.346
- 0.382
- 0.354
- 0.368
- 0.367
- 0.361
- 0.353
- 0.344
- 0.385
- 0.392
- 0.346
- 0.377
- 0.362
- 0.343
- 0.362
- 0.387
- 0.342
- 0.366
- 0.38
- 0.367
- 0.387
- 0.385
- 0.364
- 0.388
- 0.361
- 0.377
- 0.369
- 0.384
- 0.388
- 0.397
- 0.389
- 0.386
- 0.376
- 0.342
- 0.378
- 0.38
- 0.396
- 0.387
- 0.398
- 0.339
- 0.378
- 0.358
- 0.398
- 0.413
- 0.396
- 0.381
- 0.383
- 0.381
- 0.421
- 0.394
- 0.386
- 0.401
- 0.391
- 0.363
- 0.435
- 0.405
- 0.417
- 0.42
- 0.419
- 0.398
- 0.388
- 0.387
- 0.379
train_loss:
- 4.248
- 3.808
- 3.532
- 3.341
- 3.242
- 3.04
- 2.92
- 2.944
- 2.76
- 2.629
- 2.461
- 2.6
- 2.518
- 2.322
- 2.205
- 2.113
- 2.285
- 2.366
- 2.29
- 2.193
- 2.133
- 2.207
- 1.999
- 1.861
- 1.872
- 1.798
- 1.838
- 1.666
- 1.792
- 1.785
- 1.683
- 1.696
- 1.563
- 1.569
- 1.609
- 1.586
- 1.421
- 1.383
- 1.46
- 1.379
- 1.335
- 1.363
- 1.268
- 1.2
- 1.05
- 1.24
- 1.124
- 1.173
- 1.033
- 1.117
- 0.94
- 0.922
- 0.871
- 1.039
- 0.789
- 0.957
- 0.813
- 0.923
- 0.798
- 0.824
- 0.745
- 0.717
- 0.665
- 0.894
- 0.642
- 0.551
- 0.733
- 0.81
- 0.703
- 0.588
- 0.589
- 0.614
- 0.665
- 0.523
- 0.558
- 0.66
- 0.537
- 0.476
- 0.49
- 0.414
- 0.582
- 0.545
- 0.535
- 0.424
- 0.457
- 0.442
- 0.357
- 0.428
- 0.338
- 0.47
- 0.401
- 0.446
- 0.351
- 0.32
- 0.282
- 0.319
- 0.346
- 0.301
- 0.431
- 0.304
unequal: 0
verbose: 1
