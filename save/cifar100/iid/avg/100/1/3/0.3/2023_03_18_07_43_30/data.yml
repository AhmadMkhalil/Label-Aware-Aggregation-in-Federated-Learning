avg_train_accuracy: 0.429
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0872
- 0.1355
- 0.1584
- 0.1854
- 0.1968
- 0.2144
- 0.2288
- 0.2357
- 0.2527
- 0.2627
- 0.2729
- 0.278
- 0.2847
- 0.2909
- 0.2984
- 0.309
- 0.3099
- 0.3177
- 0.3143
- 0.3196
- 0.3257
- 0.3346
- 0.3363
- 0.3403
- 0.3407
- 0.3481
- 0.3535
- 0.3565
- 0.3616
- 0.3664
- 0.3625
- 0.3659
- 0.3744
- 0.3689
- 0.3745
- 0.3834
- 0.3779
- 0.3793
- 0.3867
- 0.3879
- 0.3862
- 0.3858
- 0.3917
- 0.3951
- 0.3947
- 0.3992
- 0.3981
- 0.3989
- 0.3995
- 0.4007
- 0.4035
- 0.4
- 0.3982
- 0.4005
- 0.404
- 0.4068
- 0.408
- 0.406
- 0.4098
- 0.4089
- 0.4106
- 0.4129
- 0.4131
- 0.4156
- 0.4132
- 0.4159
- 0.4211
- 0.4164
- 0.422
- 0.4184
- 0.4234
- 0.4201
- 0.4222
- 0.418
- 0.4194
- 0.4226
- 0.4232
- 0.4224
- 0.4256
- 0.421
- 0.4207
- 0.4203
- 0.4238
- 0.4264
- 0.4305
- 0.4292
- 0.433
- 0.4279
- 0.427
- 0.4276
- 0.4275
- 0.4228
- 0.4307
- 0.424
- 0.4281
- 0.427
- 0.4321
- 0.4323
- 0.4326
- 0.4304
test_loss_list:
- 1.6499530291557312
- 1.5358074235916137
- 1.4647545528411865
- 1.4097968387603759
- 1.371065514087677
- 1.335536847114563
- 1.3026313781738281
- 1.2804124855995178
- 1.256419975757599
- 1.2301254296302795
- 1.205742561817169
- 1.1899473190307617
- 1.1754485225677491
- 1.1513061213493347
- 1.1382085371017456
- 1.1233268570899964
- 1.1092905068397523
- 1.092251591682434
- 1.0888975739479065
- 1.083823938369751
- 1.0716913056373596
- 1.0609258532524108
- 1.0565760564804076
- 1.046411657333374
- 1.0475255823135377
- 1.0291351580619812
- 1.020445704460144
- 1.0160142803192138
- 1.001333920955658
- 1.0041162443161011
- 0.9995081543922424
- 0.9924387216567994
- 0.9815831542015075
- 0.9801847219467164
- 0.9820375108718872
- 0.9695381736755371
- 0.9711980080604553
- 0.9660906338691712
- 0.9633296465873719
- 0.956722023487091
- 0.9623975944519043
- 0.9654334354400634
- 0.948364679813385
- 0.9436523628234863
- 0.9408303129673005
- 0.9405606138706207
- 0.9418761849403381
- 0.9404321002960205
- 0.9391028678417206
- 0.9355927348136902
- 0.9312262094020843
- 0.9351460433006287
- 0.9384106802940368
- 0.9397220480442047
- 0.9326397895812988
- 0.9281939959526062
- 0.9262061965465546
- 0.9359084069728851
- 0.9256769430637359
- 0.9282232606410981
- 0.9296723568439483
- 0.9233415460586548
- 0.9198123049736023
- 0.9230103373527527
- 0.933176827430725
- 0.9265960848331452
- 0.9182703721523285
- 0.9239246320724487
- 0.9227092730998993
- 0.9287174797058105
- 0.9281875133514405
- 0.9252099049091339
- 0.9235733246803284
- 0.9294924414157868
- 0.9323467063903809
- 0.9269235932826996
- 0.9228027141094208
- 0.9282548630237579
- 0.9237425518035889
- 0.9312910199165344
- 0.9358448934555054
- 0.9307982897758484
- 0.9213275456428528
- 0.9298428785800934
- 0.9227953124046325
- 0.9197697198390961
- 0.9202731764316558
- 0.9274601805210113
- 0.9304864072799682
- 0.9274076855182648
- 0.930984479188919
- 0.9375911402702332
- 0.9347905206680298
- 0.9462849998474121
- 0.9307282614707947
- 0.9285750412940978
- 0.9324201035499573
- 0.9245518386363983
- 0.9325800681114197
- 0.935583268404007
train_accuracy:
- 0.086
- 0.118
- 0.133
- 0.168
- 0.181
- 0.207
- 0.204
- 0.204
- 0.2
- 0.224
- 0.263
- 0.279
- 0.269
- 0.289
- 0.293
- 0.301
- 0.313
- 0.293
- 0.33
- 0.268
- 0.287
- 0.294
- 0.296
- 0.295
- 0.29
- 0.354
- 0.335
- 0.34
- 0.342
- 0.345
- 0.294
- 0.346
- 0.369
- 0.305
- 0.366
- 0.368
- 0.34
- 0.386
- 0.375
- 0.382
- 0.369
- 0.377
- 0.371
- 0.387
- 0.373
- 0.363
- 0.392
- 0.393
- 0.366
- 0.374
- 0.376
- 0.415
- 0.38
- 0.373
- 0.386
- 0.403
- 0.373
- 0.383
- 0.378
- 0.412
- 0.407
- 0.388
- 0.374
- 0.391
- 0.435
- 0.381
- 0.404
- 0.356
- 0.36
- 0.362
- 0.401
- 0.39
- 0.415
- 0.399
- 0.402
- 0.404
- 0.436
- 0.441
- 0.384
- 0.412
- 0.402
- 0.404
- 0.388
- 0.419
- 0.4
- 0.457
- 0.399
- 0.38
- 0.403
- 0.413
- 0.389
- 0.379
- 0.376
- 0.423
- 0.393
- 0.401
- 0.415
- 0.405
- 0.416
- 0.429
train_loss:
- 4.212
- 3.762
- 3.514
- 3.364
- 3.181
- 3.122
- 3.024
- 2.854
- 2.788
- 2.787
- 2.713
- 2.518
- 2.529
- 2.464
- 2.359
- 2.332
- 2.245
- 2.306
- 2.121
- 2.03
- 2.13
- 2.017
- 1.896
- 1.914
- 1.726
- 1.872
- 1.972
- 1.688
- 1.833
- 1.655
- 1.612
- 1.617
- 1.619
- 1.482
- 1.344
- 1.505
- 1.312
- 1.395
- 1.391
- 1.342
- 1.318
- 1.294
- 1.341
- 1.268
- 1.16
- 1.174
- 1.175
- 1.153
- 1.157
- 1.076
- 1.019
- 0.944
- 0.854
- 0.947
- 0.942
- 1.08
- 0.86
- 0.814
- 0.909
- 0.762
- 0.847
- 0.821
- 0.786
- 0.766
- 0.758
- 0.723
- 0.734
- 0.622
- 0.623
- 0.522
- 0.597
- 0.548
- 0.559
- 0.5
- 0.45
- 0.731
- 0.655
- 0.518
- 0.466
- 0.56
- 0.389
- 0.476
- 0.441
- 0.544
- 0.482
- 0.532
- 0.435
- 0.368
- 0.369
- 0.371
- 0.349
- 0.345
- 0.308
- 0.264
- 0.361
- 0.436
- 0.332
- 0.441
- 0.274
- 0.284
unequal: 0
verbose: 1
