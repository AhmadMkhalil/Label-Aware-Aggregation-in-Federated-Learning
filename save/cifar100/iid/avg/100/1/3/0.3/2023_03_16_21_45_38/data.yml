avg_train_accuracy: 0.421
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0998
- 0.1375
- 0.1657
- 0.1852
- 0.2023
- 0.2151
- 0.2262
- 0.2374
- 0.2476
- 0.2556
- 0.2616
- 0.2749
- 0.2761
- 0.2846
- 0.2949
- 0.2957
- 0.3016
- 0.3037
- 0.3082
- 0.3185
- 0.3156
- 0.3193
- 0.3254
- 0.3307
- 0.3285
- 0.3441
- 0.3471
- 0.3497
- 0.3493
- 0.3597
- 0.3593
- 0.352
- 0.3665
- 0.3654
- 0.3656
- 0.3738
- 0.3663
- 0.3762
- 0.3722
- 0.3768
- 0.3805
- 0.3835
- 0.3896
- 0.3834
- 0.3859
- 0.3895
- 0.3935
- 0.3919
- 0.3917
- 0.3895
- 0.3955
- 0.3952
- 0.3987
- 0.3942
- 0.3971
- 0.3949
- 0.3944
- 0.4064
- 0.402
- 0.4006
- 0.4017
- 0.4094
- 0.4064
- 0.4091
- 0.411
- 0.4129
- 0.4049
- 0.4074
- 0.4137
- 0.4024
- 0.4157
- 0.4107
- 0.411
- 0.4119
- 0.4149
- 0.4139
- 0.4125
- 0.4164
- 0.4129
- 0.4118
- 0.4173
- 0.4213
- 0.4217
- 0.4216
- 0.4213
- 0.4227
- 0.4243
- 0.4236
- 0.427
- 0.4194
- 0.4227
- 0.4229
- 0.4232
- 0.4185
- 0.4237
- 0.427
- 0.4244
- 0.4277
- 0.429
- 0.429
test_loss_list:
- 1.6336700558662414
- 1.5241606974601745
- 1.455048875808716
- 1.404853286743164
- 1.3667819595336914
- 1.3380862879753113
- 1.3091114377975464
- 1.2813766717910766
- 1.2605288219451904
- 1.2385550880432128
- 1.227482147216797
- 1.2088917446136476
- 1.1912969613075257
- 1.1752911043167114
- 1.1563503861427307
- 1.146991002559662
- 1.132574019432068
- 1.1299108910560607
- 1.1157047533988953
- 1.1058260083198548
- 1.1041612148284912
- 1.0899984002113343
- 1.078125808238983
- 1.0675918650627136
- 1.0689706420898437
- 1.044414873123169
- 1.040978877544403
- 1.0335458707809448
- 1.0277058696746826
- 1.0135587096214294
- 1.0095018649101257
- 1.019946002960205
- 1.0017450881004333
- 0.9997194933891297
- 0.9945051991939544
- 0.9821575331687927
- 0.9949899792671204
- 0.9847576665878296
- 0.9806140100955963
- 0.978974483013153
- 0.9715342783927917
- 0.9665589714050293
- 0.9573134517669678
- 0.9621516716480255
- 0.9669380831718445
- 0.956266051530838
- 0.9529687619209289
- 0.9550263977050781
- 0.9474182176589966
- 0.9515072321891784
- 0.9400447380542755
- 0.953525767326355
- 0.9410253918170929
- 0.9502178335189819
- 0.9468439304828644
- 0.9532168567180633
- 0.949758540391922
- 0.9337705278396606
- 0.9399277412891388
- 0.9466183090209961
- 0.9371175289154052
- 0.9335432553291321
- 0.9357528972625733
- 0.9288738167285919
- 0.9318069648742676
- 0.9293271946907044
- 0.9388539457321167
- 0.9411320614814759
- 0.9237758779525757
- 0.9478159463405609
- 0.9279825747013092
- 0.9407754981517792
- 0.9380274999141693
- 0.9498845636844635
- 0.9350589346885682
- 0.9296226632595063
- 0.9406058371067048
- 0.935504652261734
- 0.9442832481861114
- 0.9440860676765442
- 0.9282463848590851
- 0.9279123687744141
- 0.9323909187316894
- 0.9338073217868805
- 0.9328467988967896
- 0.926560605764389
- 0.934487271308899
- 0.9333107137680053
- 0.9333358013629913
- 0.9363081014156341
- 0.9381255221366882
- 0.9387359750270844
- 0.9421634459495545
- 0.9427286875247955
- 0.9356268262863159
- 0.9326456916332245
- 0.9405642199516296
- 0.9368835973739624
- 0.9407175636291504
- 0.9361231756210328
train_accuracy:
- 0.107
- 0.112
- 0.16
- 0.156
- 0.173
- 0.194
- 0.189
- 0.214
- 0.22
- 0.213
- 0.216
- 0.262
- 0.25
- 0.281
- 0.26
- 0.282
- 0.285
- 0.301
- 0.301
- 0.282
- 0.29
- 0.311
- 0.287
- 0.307
- 0.321
- 0.321
- 0.318
- 0.301
- 0.316
- 0.341
- 0.328
- 0.317
- 0.35
- 0.341
- 0.344
- 0.358
- 0.352
- 0.329
- 0.342
- 0.356
- 0.346
- 0.354
- 0.363
- 0.354
- 0.381
- 0.38
- 0.345
- 0.411
- 0.361
- 0.375
- 0.37
- 0.359
- 0.37
- 0.387
- 0.372
- 0.37
- 0.368
- 0.383
- 0.366
- 0.387
- 0.374
- 0.394
- 0.377
- 0.386
- 0.371
- 0.392
- 0.401
- 0.401
- 0.396
- 0.381
- 0.401
- 0.377
- 0.407
- 0.379
- 0.386
- 0.403
- 0.437
- 0.417
- 0.398
- 0.391
- 0.432
- 0.435
- 0.434
- 0.394
- 0.365
- 0.401
- 0.376
- 0.402
- 0.445
- 0.407
- 0.382
- 0.43
- 0.428
- 0.396
- 0.407
- 0.417
- 0.434
- 0.41
- 0.392
- 0.421
train_loss:
- 4.215
- 3.713
- 3.494
- 3.34
- 3.23
- 3.056
- 3.051
- 2.921
- 2.87
- 2.729
- 2.557
- 2.597
- 2.554
- 2.488
- 2.465
- 2.331
- 2.243
- 2.169
- 2.163
- 2.111
- 1.974
- 1.99
- 1.897
- 2.002
- 1.843
- 1.961
- 1.8
- 1.72
- 1.882
- 1.789
- 1.707
- 1.603
- 1.623
- 1.571
- 1.578
- 1.519
- 1.382
- 1.314
- 1.393
- 1.389
- 1.302
- 1.463
- 1.272
- 1.167
- 1.209
- 1.305
- 1.139
- 1.149
- 1.075
- 1.145
- 0.984
- 0.986
- 0.982
- 1.03
- 0.85
- 0.862
- 0.839
- 0.909
- 0.84
- 0.882
- 0.801
- 0.714
- 0.669
- 0.823
- 0.601
- 0.696
- 0.653
- 0.608
- 0.678
- 0.724
- 0.498
- 0.544
- 0.529
- 0.6
- 0.565
- 0.749
- 0.534
- 0.549
- 0.434
- 0.581
- 0.521
- 0.477
- 0.408
- 0.423
- 0.465
- 0.475
- 0.372
- 0.471
- 0.373
- 0.373
- 0.493
- 0.36
- 0.342
- 0.336
- 0.444
- 0.327
- 0.301
- 0.294
- 0.291
- 0.384
unequal: 0
verbose: 1
