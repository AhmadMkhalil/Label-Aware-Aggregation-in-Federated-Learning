avg_train_accuracy: 0.409
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0858
- 0.1337
- 0.1612
- 0.1806
- 0.2012
- 0.2133
- 0.2236
- 0.2362
- 0.2424
- 0.2504
- 0.2635
- 0.2732
- 0.2863
- 0.2934
- 0.295
- 0.2983
- 0.3037
- 0.3148
- 0.314
- 0.3163
- 0.3301
- 0.3295
- 0.3346
- 0.3385
- 0.3428
- 0.3455
- 0.3518
- 0.3543
- 0.3592
- 0.3612
- 0.3646
- 0.3635
- 0.3716
- 0.3708
- 0.3726
- 0.3687
- 0.3754
- 0.3797
- 0.3797
- 0.3902
- 0.3796
- 0.3966
- 0.3926
- 0.3916
- 0.3895
- 0.395
- 0.3953
- 0.3985
- 0.4056
- 0.3994
- 0.4064
- 0.4091
- 0.4071
- 0.4054
- 0.4058
- 0.4106
- 0.414
- 0.4137
- 0.4152
- 0.4116
- 0.4164
- 0.4182
- 0.4193
- 0.4151
- 0.4173
- 0.4194
- 0.4175
- 0.4193
- 0.4276
- 0.421
- 0.4224
- 0.4232
- 0.4273
- 0.4229
- 0.4202
- 0.4242
- 0.4287
- 0.4288
- 0.4276
- 0.4255
- 0.4307
- 0.4306
- 0.4336
- 0.4346
- 0.4367
- 0.4297
- 0.4306
- 0.4281
- 0.4343
- 0.4311
- 0.4289
- 0.4331
- 0.4363
- 0.4381
- 0.4379
- 0.4371
- 0.4316
- 0.4363
- 0.4327
- 0.4425
test_loss_list:
- 1.6555240964889526
- 1.527948362827301
- 1.455816593170166
- 1.4069584941864013
- 1.3675286841392518
- 1.3368368339538574
- 1.3093280982971192
- 1.2781387758255005
- 1.260730230808258
- 1.2391432976722718
- 1.2177442836761474
- 1.2039178347587585
- 1.1755667972564696
- 1.1609785556793213
- 1.1512491941452025
- 1.1344134163856507
- 1.1273135948181152
- 1.1140606689453125
- 1.1018984961509704
- 1.0877981758117676
- 1.0727640771865845
- 1.0689305114746093
- 1.0617273807525636
- 1.053970377445221
- 1.0500874400138855
- 1.0447057056427003
- 1.024453239440918
- 1.0163632774353026
- 1.0124347305297852
- 1.0068474984169007
- 1.0005560827255249
- 0.9976598024368286
- 0.9880508255958557
- 0.9833940410614014
- 0.9888682079315185
- 0.9885311794281005
- 0.9770962929725647
- 0.9643792438507081
- 0.9679720258712768
- 0.9568083238601685
- 0.966678261756897
- 0.9487374997138978
- 0.9533426856994629
- 0.9465614748001099
- 0.9495040822029114
- 0.9373024189472199
- 0.9396476507186889
- 0.9440454077720642
- 0.9349371528625489
- 0.9400043177604676
- 0.9302866530418396
- 0.9226410245895386
- 0.9267443346977234
- 0.9271809935569764
- 0.9279362869262695
- 0.9256699419021607
- 0.918084797859192
- 0.9197316789627075
- 0.9189807081222534
- 0.9249569725990295
- 0.915514748096466
- 0.9156330478191376
- 0.9141093921661377
- 0.9197887563705445
- 0.9100475680828094
- 0.9173785066604614
- 0.9191653418540955
- 0.9124198758602142
- 0.9111037635803223
- 0.9155597102642059
- 0.9142920780181885
- 0.9146158277988434
- 0.9141131269931794
- 0.9173762226104736
- 0.9185175323486328
- 0.9185638225078583
- 0.9172193884849549
- 0.9156497168540955
- 0.9162088048458099
- 0.9171830177307129
- 0.9127531480789185
- 0.912252938747406
- 0.9139826261997223
- 0.9096634936332703
- 0.9116995310783387
- 0.9138732361793518
- 0.920176067352295
- 0.9224163210391998
- 0.9129951989650726
- 0.9185507678985596
- 0.918878083229065
- 0.9204268288612366
- 0.9183375430107117
- 0.9162251281738282
- 0.9163264322280884
- 0.9204947304725647
- 0.91748943567276
- 0.9234990835189819
- 0.9231327629089355
- 0.9197033286094666
train_accuracy:
- 0.089
- 0.127
- 0.157
- 0.184
- 0.176
- 0.189
- 0.159
- 0.174
- 0.177
- 0.17
- 0.236
- 0.236
- 0.258
- 0.247
- 0.212
- 0.27
- 0.282
- 0.293
- 0.303
- 0.296
- 0.297
- 0.3
- 0.325
- 0.32
- 0.306
- 0.304
- 0.279
- 0.311
- 0.303
- 0.354
- 0.349
- 0.335
- 0.309
- 0.373
- 0.356
- 0.325
- 0.35
- 0.391
- 0.336
- 0.368
- 0.354
- 0.343
- 0.337
- 0.394
- 0.345
- 0.386
- 0.379
- 0.347
- 0.39
- 0.332
- 0.37
- 0.409
- 0.353
- 0.359
- 0.394
- 0.417
- 0.364
- 0.422
- 0.401
- 0.4
- 0.411
- 0.408
- 0.415
- 0.365
- 0.424
- 0.401
- 0.385
- 0.37
- 0.388
- 0.404
- 0.417
- 0.361
- 0.396
- 0.359
- 0.388
- 0.39
- 0.384
- 0.394
- 0.402
- 0.398
- 0.405
- 0.378
- 0.4
- 0.384
- 0.394
- 0.387
- 0.413
- 0.397
- 0.412
- 0.437
- 0.398
- 0.415
- 0.432
- 0.379
- 0.414
- 0.411
- 0.438
- 0.404
- 0.369
- 0.409
train_loss:
- 4.249
- 3.765
- 3.477
- 3.307
- 3.201
- 3.076
- 2.944
- 2.929
- 2.716
- 2.727
- 2.688
- 2.507
- 2.625
- 2.436
- 2.355
- 2.392
- 2.235
- 2.176
- 2.13
- 2.181
- 2.074
- 2.011
- 1.941
- 1.815
- 1.953
- 1.938
- 1.823
- 1.744
- 1.698
- 1.665
- 1.642
- 1.485
- 1.549
- 1.476
- 1.371
- 1.323
- 1.492
- 1.475
- 1.26
- 1.447
- 1.314
- 1.356
- 1.225
- 1.231
- 1.201
- 1.254
- 1.091
- 1.047
- 1.104
- 0.984
- 1.026
- 1.109
- 0.936
- 0.918
- 1.043
- 1.0
- 0.797
- 0.876
- 0.795
- 0.69
- 0.913
- 0.757
- 0.782
- 0.779
- 0.786
- 0.604
- 0.599
- 0.754
- 0.655
- 0.653
- 0.494
- 0.701
- 0.603
- 0.586
- 0.544
- 0.45
- 0.61
- 0.553
- 0.515
- 0.478
- 0.462
- 0.504
- 0.437
- 0.518
- 0.418
- 0.453
- 0.378
- 0.343
- 0.451
- 0.442
- 0.347
- 0.388
- 0.4
- 0.349
- 0.354
- 0.28
- 0.318
- 0.342
- 0.294
- 0.335
unequal: 0
verbose: 1
