avg_train_accuracy: 0.379
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0887
- 0.1296
- 0.1598
- 0.1777
- 0.1962
- 0.2093
- 0.2198
- 0.2307
- 0.2459
- 0.2578
- 0.2631
- 0.2708
- 0.2772
- 0.287
- 0.295
- 0.2992
- 0.3051
- 0.3126
- 0.3149
- 0.3171
- 0.3281
- 0.3267
- 0.3318
- 0.3418
- 0.3468
- 0.3469
- 0.3572
- 0.3554
- 0.3592
- 0.3602
- 0.3612
- 0.3636
- 0.3717
- 0.3739
- 0.375
- 0.3784
- 0.3821
- 0.3848
- 0.3884
- 0.3836
- 0.3877
- 0.3907
- 0.391
- 0.3955
- 0.3995
- 0.3943
- 0.3948
- 0.3959
- 0.3978
- 0.3979
- 0.396
- 0.4063
- 0.4073
- 0.4059
- 0.4047
- 0.4034
- 0.4135
- 0.4188
- 0.4137
- 0.4115
- 0.4129
- 0.4097
- 0.415
- 0.4166
- 0.4157
- 0.419
- 0.4121
- 0.4195
- 0.4218
- 0.425
- 0.4222
- 0.421
- 0.4227
- 0.4209
- 0.4226
- 0.4206
- 0.4218
- 0.4202
- 0.4247
- 0.4225
- 0.4208
- 0.425
- 0.4284
- 0.4243
- 0.4293
- 0.4292
- 0.4247
- 0.4256
- 0.4282
- 0.4291
- 0.429
- 0.4291
- 0.4272
- 0.428
- 0.4232
- 0.4305
- 0.4289
- 0.4311
- 0.4362
- 0.4347
test_loss_list:
- 1.6490067768096923
- 1.5374108934402466
- 1.4662849140167236
- 1.412830035686493
- 1.3740325093269348
- 1.3388271403312684
- 1.3089976906776428
- 1.2876591563224793
- 1.2656763768196106
- 1.238233335018158
- 1.2166947650909423
- 1.197253062725067
- 1.1749774527549743
- 1.1595474696159362
- 1.1440194702148438
- 1.1324738812446595
- 1.1162923026084899
- 1.1021451354026794
- 1.0965201354026795
- 1.0899278354644775
- 1.072102153301239
- 1.0623320817947388
- 1.0534278273582458
- 1.0406194496154786
- 1.0324334466457368
- 1.0309986448287964
- 1.018321943283081
- 1.0109188055992127
- 1.003759217262268
- 1.0028008341789245
- 0.9965303838253021
- 0.9946357214450836
- 0.9920483040809631
- 0.9786198604106903
- 0.9769874167442322
- 0.9751222789287567
- 0.9702962100505829
- 0.9597023689746856
- 0.9567917311191558
- 0.9572106266021728
- 0.9551538586616516
- 0.9584855508804321
- 0.9515603804588317
- 0.9450069284439087
- 0.9441927635669708
- 0.9475673568248749
- 0.9481104445457459
- 0.9445229470729828
- 0.944276579618454
- 0.9364317154884338
- 0.9531460165977478
- 0.9255157327651977
- 0.9326229512691497
- 0.935404258966446
- 0.9341780853271484
- 0.935498183965683
- 0.9174524593353272
- 0.9189839792251587
- 0.9272025167942047
- 0.9306930518150329
- 0.9253075551986695
- 0.9288704442977905
- 0.929355013370514
- 0.9250358891487122
- 0.9141674768924714
- 0.9142682242393494
- 0.9246723234653473
- 0.9104236829280853
- 0.9197699058055878
- 0.913354263305664
- 0.9205280947685242
- 0.9172280991077423
- 0.9161678004264832
- 0.9227162039279938
- 0.9111445689201355
- 0.9218883907794952
- 0.919625415802002
- 0.9305189073085784
- 0.9221910166740418
- 0.9288782715797425
- 0.9233813834190369
- 0.9210389018058777
- 0.9218885314464569
- 0.9221139752864838
- 0.9225380659103394
- 0.9232701146602631
- 0.9255407404899597
- 0.9319557404518127
- 0.9239952158927918
- 0.9285574007034302
- 0.9274359631538391
- 0.9289488518238067
- 0.9328741490840912
- 0.9281402087211609
- 0.9339473009109497
- 0.9258375084400177
- 0.9376115560531616
- 0.9290200924873352
- 0.9230919992923736
- 0.9312549996376037
train_accuracy:
- 0.08
- 0.119
- 0.168
- 0.166
- 0.172
- 0.2
- 0.192
- 0.202
- 0.222
- 0.229
- 0.255
- 0.256
- 0.245
- 0.26
- 0.282
- 0.272
- 0.304
- 0.276
- 0.289
- 0.265
- 0.295
- 0.316
- 0.335
- 0.3
- 0.348
- 0.331
- 0.301
- 0.336
- 0.327
- 0.341
- 0.365
- 0.345
- 0.341
- 0.358
- 0.34
- 0.349
- 0.335
- 0.351
- 0.34
- 0.347
- 0.361
- 0.366
- 0.364
- 0.389
- 0.384
- 0.372
- 0.359
- 0.37
- 0.379
- 0.382
- 0.388
- 0.358
- 0.405
- 0.418
- 0.39
- 0.344
- 0.36
- 0.378
- 0.383
- 0.378
- 0.355
- 0.403
- 0.373
- 0.364
- 0.407
- 0.387
- 0.381
- 0.41
- 0.384
- 0.375
- 0.371
- 0.421
- 0.392
- 0.412
- 0.384
- 0.396
- 0.394
- 0.4
- 0.378
- 0.418
- 0.376
- 0.375
- 0.391
- 0.404
- 0.421
- 0.4
- 0.387
- 0.403
- 0.396
- 0.392
- 0.414
- 0.392
- 0.377
- 0.431
- 0.41
- 0.388
- 0.421
- 0.41
- 0.38
- 0.379
train_loss:
- 4.219
- 3.722
- 3.455
- 3.306
- 3.186
- 3.073
- 3.058
- 2.889
- 2.744
- 2.652
- 2.676
- 2.611
- 2.618
- 2.433
- 2.341
- 2.396
- 2.367
- 2.273
- 2.114
- 2.134
- 2.133
- 2.055
- 1.979
- 1.991
- 1.94
- 1.77
- 1.853
- 1.74
- 1.818
- 1.633
- 1.681
- 1.541
- 1.531
- 1.703
- 1.461
- 1.377
- 1.504
- 1.434
- 1.394
- 1.345
- 1.32
- 1.231
- 1.239
- 1.285
- 1.168
- 1.141
- 1.155
- 1.048
- 1.028
- 1.124
- 0.978
- 1.037
- 0.984
- 0.953
- 0.913
- 0.855
- 1.026
- 0.95
- 0.841
- 0.807
- 0.815
- 0.812
- 0.737
- 0.736
- 0.799
- 0.766
- 0.64
- 0.694
- 0.695
- 0.644
- 0.611
- 0.606
- 0.588
- 0.542
- 0.627
- 0.565
- 0.503
- 0.448
- 0.526
- 0.433
- 0.445
- 0.488
- 0.479
- 0.449
- 0.371
- 0.498
- 0.365
- 0.3
- 0.497
- 0.385
- 0.389
- 0.31
- 0.364
- 0.332
- 0.331
- 0.3
- 0.345
- 0.336
- 0.355
- 0.293
unequal: 0
verbose: 1
