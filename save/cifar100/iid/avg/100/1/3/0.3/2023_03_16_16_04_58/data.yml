avg_train_accuracy: 0.424
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0897
- 0.1318
- 0.1642
- 0.1843
- 0.198
- 0.2178
- 0.2248
- 0.2397
- 0.2478
- 0.2553
- 0.2625
- 0.2727
- 0.2799
- 0.2864
- 0.2935
- 0.3008
- 0.3042
- 0.3052
- 0.3136
- 0.3203
- 0.3218
- 0.3267
- 0.3318
- 0.3353
- 0.339
- 0.3435
- 0.342
- 0.3501
- 0.3498
- 0.3565
- 0.3617
- 0.3605
- 0.3616
- 0.3621
- 0.3738
- 0.3765
- 0.3827
- 0.3806
- 0.3824
- 0.3831
- 0.3873
- 0.3883
- 0.39
- 0.3893
- 0.3949
- 0.3935
- 0.3954
- 0.3936
- 0.3965
- 0.3988
- 0.398
- 0.4024
- 0.4022
- 0.4056
- 0.4059
- 0.4038
- 0.4035
- 0.4023
- 0.4093
- 0.4133
- 0.4162
- 0.4142
- 0.4118
- 0.4116
- 0.4082
- 0.4163
- 0.4182
- 0.416
- 0.4153
- 0.4164
- 0.4201
- 0.4192
- 0.4178
- 0.4187
- 0.4182
- 0.4232
- 0.4201
- 0.4245
- 0.4179
- 0.4223
- 0.422
- 0.4217
- 0.4232
- 0.4264
- 0.4272
- 0.4244
- 0.4279
- 0.4262
- 0.4267
- 0.43
- 0.4282
- 0.4288
- 0.4337
- 0.4277
- 0.4322
- 0.4323
- 0.433
- 0.4336
- 0.43
- 0.4293
test_loss_list:
- 1.646832573413849
- 1.5317158269882203
- 1.4559676265716552
- 1.4095508098602294
- 1.374390687942505
- 1.3405568289756775
- 1.313743760585785
- 1.2842012763023376
- 1.2597852635383606
- 1.2443539094924927
- 1.2174046397209168
- 1.199021487236023
- 1.1848256635665892
- 1.1698170280456544
- 1.1555551528930663
- 1.142010009288788
- 1.131570236682892
- 1.1222640728950501
- 1.1134205198287963
- 1.096714403629303
- 1.0923403453826905
- 1.0781501483917237
- 1.074302098751068
- 1.0634373927116394
- 1.0564625906944274
- 1.0474192261695863
- 1.0465056848526002
- 1.0296914982795715
- 1.032645492553711
- 1.0236157608032226
- 1.0120708656311035
- 1.0094854068756103
- 1.0044640755653382
- 1.0019858169555664
- 0.988675172328949
- 0.9862775731086731
- 0.9741464638710022
- 0.9760047483444214
- 0.9673638463020324
- 0.9702904295921325
- 0.9645253944396973
- 0.9645485305786132
- 0.9567823743820191
- 0.9572707176208496
- 0.9473386240005494
- 0.9510497784614563
- 0.9459753274917603
- 0.9554717254638672
- 0.9501341581344604
- 0.9479935836791992
- 0.9500290179252624
- 0.9383098745346069
- 0.9387098002433777
- 0.9432228636741639
- 0.9365130305290222
- 0.9397384262084961
- 0.9442543578147888
- 0.9398267245292664
- 0.9345193457603455
- 0.9316176080703735
- 0.9305080127716064
- 0.9387378191947937
- 0.9418318080902099
- 0.9323637008666992
- 0.9401501417160034
- 0.9270550847053528
- 0.9287590384483337
- 0.9347957968711853
- 0.9335055947303772
- 0.9323230195045471
- 0.925524296760559
- 0.9346238517761231
- 0.9347005963325501
- 0.933672399520874
- 0.9374437713623047
- 0.9273427391052246
- 0.9333788561820984
- 0.9334669232368469
- 0.937433397769928
- 0.9340538191795349
- 0.9426021981239319
- 0.9408181166648865
- 0.9410006833076477
- 0.9273254585266113
- 0.9323404836654663
- 0.9393029475212097
- 0.9318773722648621
- 0.9368006110191345
- 0.9370698738098144
- 0.9263255667686462
- 0.935570411682129
- 0.9308466291427613
- 0.9336927080154419
- 0.9367390632629394
- 0.9340753102302551
- 0.9336097121238709
- 0.9341550898551941
- 0.9307703709602356
- 0.9356209444999695
- 0.942384102344513
train_accuracy:
- 0.092
- 0.107
- 0.146
- 0.167
- 0.177
- 0.19
- 0.168
- 0.204
- 0.204
- 0.225
- 0.242
- 0.248
- 0.281
- 0.291
- 0.296
- 0.262
- 0.309
- 0.299
- 0.312
- 0.293
- 0.295
- 0.295
- 0.308
- 0.296
- 0.306
- 0.35
- 0.342
- 0.335
- 0.346
- 0.327
- 0.341
- 0.373
- 0.325
- 0.338
- 0.314
- 0.322
- 0.317
- 0.356
- 0.357
- 0.395
- 0.38
- 0.374
- 0.399
- 0.329
- 0.366
- 0.38
- 0.365
- 0.372
- 0.344
- 0.415
- 0.334
- 0.341
- 0.407
- 0.371
- 0.369
- 0.37
- 0.372
- 0.389
- 0.387
- 0.385
- 0.421
- 0.423
- 0.399
- 0.397
- 0.395
- 0.353
- 0.361
- 0.388
- 0.383
- 0.429
- 0.408
- 0.369
- 0.407
- 0.364
- 0.406
- 0.429
- 0.421
- 0.421
- 0.407
- 0.376
- 0.377
- 0.416
- 0.388
- 0.382
- 0.371
- 0.404
- 0.395
- 0.417
- 0.422
- 0.378
- 0.39
- 0.416
- 0.434
- 0.439
- 0.434
- 0.425
- 0.417
- 0.421
- 0.45
- 0.424
train_loss:
- 4.214
- 3.714
- 3.55
- 3.289
- 3.157
- 3.004
- 2.946
- 2.865
- 2.836
- 2.647
- 2.774
- 2.662
- 2.553
- 2.418
- 2.465
- 2.439
- 2.256
- 2.157
- 2.15
- 2.159
- 1.989
- 2.108
- 2.03
- 1.871
- 1.794
- 1.775
- 1.63
- 1.85
- 1.587
- 1.703
- 1.652
- 1.65
- 1.587
- 1.393
- 1.808
- 1.496
- 1.612
- 1.512
- 1.373
- 1.407
- 1.235
- 1.293
- 1.324
- 1.24
- 1.296
- 1.196
- 1.042
- 1.101
- 1.068
- 1.035
- 0.957
- 1.078
- 0.993
- 1.021
- 0.877
- 0.828
- 0.721
- 0.765
- 0.942
- 0.883
- 0.821
- 0.664
- 0.647
- 0.775
- 0.531
- 0.838
- 0.713
- 0.65
- 0.5
- 0.746
- 0.686
- 0.545
- 0.474
- 0.586
- 0.622
- 0.623
- 0.449
- 0.607
- 0.49
- 0.424
- 0.359
- 0.372
- 0.363
- 0.615
- 0.438
- 0.306
- 0.468
- 0.349
- 0.43
- 0.515
- 0.335
- 0.413
- 0.393
- 0.411
- 0.431
- 0.349
- 0.342
- 0.332
- 0.344
- 0.268
unequal: 0
verbose: 1
