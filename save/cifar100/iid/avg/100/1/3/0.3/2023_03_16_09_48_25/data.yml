avg_train_accuracy: 0.425
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0992
- 0.1393
- 0.1661
- 0.187
- 0.1995
- 0.2207
- 0.2326
- 0.2421
- 0.2497
- 0.2591
- 0.2624
- 0.2777
- 0.2832
- 0.2822
- 0.2956
- 0.2974
- 0.3069
- 0.3132
- 0.3107
- 0.3205
- 0.3274
- 0.3352
- 0.3377
- 0.3427
- 0.3413
- 0.3459
- 0.3461
- 0.3491
- 0.3574
- 0.3643
- 0.3693
- 0.3716
- 0.3778
- 0.3757
- 0.3785
- 0.3811
- 0.3761
- 0.3862
- 0.3874
- 0.3899
- 0.3933
- 0.3911
- 0.3982
- 0.395
- 0.3961
- 0.3976
- 0.3985
- 0.401
- 0.3977
- 0.4022
- 0.4077
- 0.4076
- 0.4066
- 0.4063
- 0.4094
- 0.4174
- 0.4121
- 0.411
- 0.4133
- 0.4127
- 0.4159
- 0.4136
- 0.4162
- 0.4175
- 0.4237
- 0.4184
- 0.4229
- 0.4211
- 0.4244
- 0.4229
- 0.4213
- 0.426
- 0.4263
- 0.4236
- 0.4223
- 0.4236
- 0.4243
- 0.4232
- 0.427
- 0.429
- 0.4321
- 0.4275
- 0.43
- 0.4301
- 0.4278
- 0.4334
- 0.4307
- 0.4279
- 0.4287
- 0.4301
- 0.4346
- 0.4329
- 0.4362
- 0.437
- 0.4382
- 0.4344
- 0.433
- 0.4289
- 0.436
- 0.4374
test_loss_list:
- 1.6266145849227904
- 1.5103413915634156
- 1.4435724759101867
- 1.3962234497070312
- 1.3564695835113525
- 1.3219030785560608
- 1.293435709476471
- 1.266896538734436
- 1.2426834154129027
- 1.2222253775596619
- 1.2031405591964721
- 1.183919746875763
- 1.1673805952072143
- 1.1615447735786437
- 1.1418378853797913
- 1.1313803958892823
- 1.122516691684723
- 1.1123976802825928
- 1.108917863368988
- 1.0959225392341614
- 1.0853962540626525
- 1.0675579762458802
- 1.062656331062317
- 1.0519365048408509
- 1.0464042186737061
- 1.0408301591873168
- 1.035942623615265
- 1.0287201952934266
- 1.0158132266998292
- 1.0059807777404786
- 0.9984755063056946
- 0.9894464254379273
- 0.9851512610912323
- 0.9836945462226868
- 0.9779545092582702
- 0.9728440833091736
- 0.9775948345661163
- 0.9615982210636139
- 0.9624242174625397
- 0.9562599802017212
- 0.950712444782257
- 0.9560612595081329
- 0.9428861677646637
- 0.9504564988613129
- 0.9550247120857239
- 0.940044664144516
- 0.9415674042701722
- 0.9376269197463989
- 0.9347481572628021
- 0.9321226561069489
- 0.935401941537857
- 0.9331720209121704
- 0.9296340668201446
- 0.9321471309661865
- 0.9294567131996154
- 0.9194416058063507
- 0.924872682094574
- 0.9269877457618714
- 0.9269262886047364
- 0.927636649608612
- 0.9261686825752258
- 0.9255834674835205
- 0.92133842587471
- 0.9191079723834992
- 0.9168858850002288
- 0.9146144914627076
- 0.9106531512737274
- 0.9191163527965546
- 0.9126998412609101
- 0.9139410209655762
- 0.9148549294471741
- 0.9185184371471405
- 0.9188027703762054
- 0.9143970441818238
- 0.9167483568191528
- 0.9155951321125031
- 0.9232578146457672
- 0.9234400796890259
- 0.9233117651939392
- 0.9207333195209503
- 0.9159518694877624
- 0.9148339664936066
- 0.9167484891414642
- 0.9131791234016419
- 0.9158416295051575
- 0.9150862753391266
- 0.9258439838886261
- 0.923636076450348
- 0.9232446479797364
- 0.9216218984127045
- 0.9183405983448029
- 0.9223952198028564
- 0.9208586537837982
- 0.9236534559726715
- 0.9238238489627838
- 0.928398962020874
- 0.9249735391139984
- 0.9244171631336212
- 0.929595240354538
- 0.9220058012008667
train_accuracy:
- 0.087
- 0.119
- 0.153
- 0.175
- 0.191
- 0.199
- 0.2
- 0.227
- 0.22
- 0.258
- 0.241
- 0.266
- 0.278
- 0.237
- 0.28
- 0.293
- 0.304
- 0.298
- 0.278
- 0.276
- 0.317
- 0.267
- 0.276
- 0.308
- 0.317
- 0.332
- 0.34
- 0.334
- 0.338
- 0.313
- 0.342
- 0.363
- 0.376
- 0.336
- 0.346
- 0.336
- 0.368
- 0.368
- 0.372
- 0.343
- 0.384
- 0.35
- 0.392
- 0.393
- 0.368
- 0.354
- 0.383
- 0.389
- 0.381
- 0.383
- 0.37
- 0.339
- 0.408
- 0.368
- 0.334
- 0.395
- 0.368
- 0.387
- 0.392
- 0.377
- 0.393
- 0.387
- 0.393
- 0.398
- 0.409
- 0.391
- 0.347
- 0.417
- 0.406
- 0.382
- 0.357
- 0.394
- 0.407
- 0.42
- 0.413
- 0.36
- 0.428
- 0.403
- 0.395
- 0.388
- 0.398
- 0.406
- 0.422
- 0.36
- 0.413
- 0.429
- 0.397
- 0.418
- 0.384
- 0.424
- 0.401
- 0.411
- 0.365
- 0.369
- 0.402
- 0.423
- 0.4
- 0.37
- 0.411
- 0.425
train_loss:
- 4.196
- 3.734
- 3.494
- 3.332
- 3.166
- 3.113
- 2.965
- 2.85
- 2.816
- 2.745
- 2.646
- 2.549
- 2.521
- 2.33
- 2.361
- 2.298
- 2.122
- 2.173
- 2.113
- 2.128
- 1.955
- 2.177
- 1.992
- 1.904
- 1.844
- 1.688
- 1.699
- 1.896
- 1.714
- 1.863
- 1.632
- 1.534
- 1.599
- 1.476
- 1.473
- 1.468
- 1.416
- 1.469
- 1.384
- 1.469
- 1.226
- 1.218
- 1.315
- 1.065
- 1.105
- 1.267
- 1.094
- 1.101
- 1.08
- 1.068
- 0.995
- 0.967
- 1.028
- 0.943
- 0.894
- 0.981
- 0.923
- 0.932
- 0.774
- 0.759
- 0.689
- 0.847
- 0.847
- 0.716
- 0.714
- 0.737
- 0.678
- 0.638
- 0.637
- 0.659
- 0.583
- 0.554
- 0.589
- 0.531
- 0.628
- 0.631
- 0.51
- 0.463
- 0.4
- 0.527
- 0.559
- 0.481
- 0.46
- 0.419
- 0.514
- 0.388
- 0.358
- 0.42
- 0.353
- 0.443
- 0.425
- 0.343
- 0.376
- 0.298
- 0.383
- 0.358
- 0.355
- 0.348
- 0.292
- 0.347
unequal: 0
verbose: 1
