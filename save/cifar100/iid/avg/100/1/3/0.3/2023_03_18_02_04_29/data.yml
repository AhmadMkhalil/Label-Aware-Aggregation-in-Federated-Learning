avg_train_accuracy: 0.402
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0934
- 0.1308
- 0.1648
- 0.1791
- 0.1957
- 0.2085
- 0.2211
- 0.2309
- 0.2441
- 0.2479
- 0.2621
- 0.274
- 0.2788
- 0.2885
- 0.2893
- 0.2993
- 0.3076
- 0.3132
- 0.3114
- 0.3245
- 0.326
- 0.3266
- 0.3324
- 0.3431
- 0.3499
- 0.3473
- 0.3538
- 0.3575
- 0.3536
- 0.3648
- 0.367
- 0.3663
- 0.3669
- 0.3783
- 0.3732
- 0.3774
- 0.3781
- 0.3842
- 0.3853
- 0.3837
- 0.3861
- 0.392
- 0.3917
- 0.386
- 0.3952
- 0.3944
- 0.4026
- 0.4005
- 0.3998
- 0.3957
- 0.4057
- 0.4046
- 0.4022
- 0.4072
- 0.4108
- 0.4059
- 0.4065
- 0.414
- 0.4138
- 0.413
- 0.4162
- 0.4142
- 0.4111
- 0.4132
- 0.4141
- 0.4177
- 0.4197
- 0.4181
- 0.4182
- 0.4209
- 0.4211
- 0.4195
- 0.4154
- 0.4185
- 0.4148
- 0.4196
- 0.4194
- 0.4258
- 0.424
- 0.4205
- 0.4162
- 0.4279
- 0.4253
- 0.4251
- 0.424
- 0.4283
- 0.4267
- 0.4243
- 0.4307
- 0.4291
- 0.4256
- 0.4339
- 0.427
- 0.4308
- 0.4239
- 0.4289
- 0.4306
- 0.4265
- 0.4317
- 0.4346
test_loss_list:
- 1.6350069618225098
- 1.5263322019577026
- 1.4516877675056457
- 1.4098652052879332
- 1.369417471885681
- 1.338768594264984
- 1.309208207130432
- 1.2881931376457214
- 1.263667221069336
- 1.245003204345703
- 1.219791328907013
- 1.199167468547821
- 1.1825330901145934
- 1.1644697666168213
- 1.152558560371399
- 1.1357694911956786
- 1.1252475261688233
- 1.1142330861091614
- 1.0990892887115478
- 1.0870110297203064
- 1.079589035511017
- 1.0738531017303468
- 1.0644255137443543
- 1.040752727985382
- 1.0300939679145813
- 1.0259702134132385
- 1.0205666661262511
- 1.019448516368866
- 1.0271410584449767
- 1.0042261624336242
- 0.9972693586349487
- 0.9897204422950745
- 0.9939539837837219
- 0.9791872668266296
- 0.9898255562782288
- 0.9875990200042725
- 0.974258508682251
- 0.975341489315033
- 0.9613641834259034
- 0.9705180191993713
- 0.9609797811508178
- 0.9559039378166199
- 0.9563666892051697
- 0.9633274698257446
- 0.9445755636692047
- 0.9463290750980378
- 0.9399363994598389
- 0.9393887162208557
- 0.9421407890319824
- 0.9473986101150512
- 0.9307709670066834
- 0.9373096251487731
- 0.9398357915878296
- 0.9320993423461914
- 0.9289947962760925
- 0.9356291341781616
- 0.9290157222747802
- 0.923669912815094
- 0.9260340738296509
- 0.9227474427223206
- 0.922492687702179
- 0.9252668857574463
- 0.9319358229637146
- 0.927184374332428
- 0.9271798157691955
- 0.9254491066932679
- 0.9217138826847077
- 0.9232363295555115
- 0.9262975358963013
- 0.9240094542503356
- 0.9302830910682678
- 0.933837947845459
- 0.9323148059844971
- 0.9317192673683167
- 0.9273641562461853
- 0.9283491110801697
- 0.9273335361480712
- 0.9179493284225464
- 0.9206201291084289
- 0.9286140966415405
- 0.9390724492073059
- 0.921497151851654
- 0.9275415587425232
- 0.9352168083190918
- 0.9284450483322143
- 0.9275200152397156
- 0.9318155550956726
- 0.9293592214584351
- 0.9193221628665924
- 0.9306057488918305
- 0.933734564781189
- 0.9244148993492126
- 0.931361094713211
- 0.9259567534923554
- 0.9306336283683777
- 0.9304451513290405
- 0.9308185195922851
- 0.9388322186470032
- 0.934347186088562
- 0.9278726840019226
train_accuracy:
- 0.089
- 0.125
- 0.146
- 0.212
- 0.181
- 0.192
- 0.208
- 0.198
- 0.262
- 0.232
- 0.217
- 0.233
- 0.25
- 0.266
- 0.267
- 0.251
- 0.275
- 0.296
- 0.267
- 0.319
- 0.29
- 0.304
- 0.359
- 0.325
- 0.296
- 0.293
- 0.387
- 0.322
- 0.332
- 0.325
- 0.314
- 0.416
- 0.34
- 0.36
- 0.368
- 0.358
- 0.342
- 0.333
- 0.371
- 0.382
- 0.424
- 0.348
- 0.33
- 0.419
- 0.345
- 0.392
- 0.395
- 0.346
- 0.342
- 0.338
- 0.372
- 0.437
- 0.428
- 0.438
- 0.402
- 0.363
- 0.378
- 0.41
- 0.411
- 0.446
- 0.409
- 0.384
- 0.368
- 0.371
- 0.404
- 0.372
- 0.392
- 0.367
- 0.41
- 0.408
- 0.388
- 0.413
- 0.369
- 0.415
- 0.415
- 0.364
- 0.377
- 0.398
- 0.386
- 0.365
- 0.428
- 0.428
- 0.387
- 0.402
- 0.396
- 0.373
- 0.378
- 0.37
- 0.425
- 0.426
- 0.374
- 0.436
- 0.472
- 0.466
- 0.464
- 0.381
- 0.389
- 0.4
- 0.4
- 0.402
train_loss:
- 4.21
- 3.73
- 3.515
- 3.303
- 3.234
- 3.052
- 2.947
- 2.873
- 2.798
- 2.588
- 2.654
- 2.701
- 2.574
- 2.556
- 2.36
- 2.406
- 2.263
- 2.19
- 2.224
- 2.042
- 1.968
- 1.92
- 2.061
- 2.013
- 1.957
- 1.877
- 1.824
- 1.693
- 1.774
- 1.729
- 1.613
- 1.763
- 1.563
- 1.541
- 1.462
- 1.352
- 1.476
- 1.238
- 1.399
- 1.328
- 1.233
- 1.334
- 1.276
- 1.215
- 1.301
- 1.227
- 1.213
- 1.019
- 0.927
- 0.941
- 1.288
- 0.968
- 0.956
- 0.949
- 1.083
- 0.934
- 0.938
- 0.994
- 0.825
- 0.83
- 0.718
- 0.727
- 0.649
- 0.689
- 0.781
- 0.704
- 0.787
- 0.624
- 0.586
- 0.593
- 0.535
- 0.564
- 0.537
- 0.604
- 0.732
- 0.494
- 0.585
- 0.598
- 0.54
- 0.482
- 0.492
- 0.624
- 0.473
- 0.4
- 0.375
- 0.37
- 0.316
- 0.548
- 0.496
- 0.364
- 0.408
- 0.409
- 0.326
- 0.393
- 0.363
- 0.328
- 0.296
- 0.288
- 0.385
- 0.344
unequal: 0
verbose: 1
