avg_train_accuracy: 0.397
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0924
- 0.1281
- 0.1503
- 0.1637
- 0.1819
- 0.1943
- 0.2079
- 0.2132
- 0.2179
- 0.2358
- 0.2446
- 0.2539
- 0.2581
- 0.2698
- 0.2718
- 0.2755
- 0.2765
- 0.2801
- 0.2884
- 0.2829
- 0.2965
- 0.2914
- 0.2997
- 0.3014
- 0.3008
- 0.2992
- 0.3103
- 0.3047
- 0.316
- 0.3215
- 0.3065
- 0.3316
- 0.3426
- 0.3389
- 0.3291
- 0.3402
- 0.3448
- 0.343
- 0.3469
- 0.348
- 0.3518
- 0.359
- 0.3659
- 0.3593
- 0.3614
- 0.3606
- 0.3624
- 0.3643
- 0.3573
- 0.3651
- 0.3643
- 0.3639
- 0.3775
- 0.3779
- 0.3772
- 0.3699
- 0.3746
- 0.3721
- 0.3736
- 0.3758
- 0.3794
- 0.3762
- 0.3857
- 0.3845
- 0.3924
- 0.3838
- 0.3777
- 0.388
- 0.3834
- 0.3825
- 0.3842
- 0.384
- 0.3823
- 0.3846
- 0.3902
- 0.3915
- 0.3835
- 0.3897
- 0.3999
- 0.3977
- 0.4005
- 0.398
- 0.3943
- 0.3993
- 0.4
- 0.3968
- 0.3987
- 0.3993
- 0.3913
- 0.399
- 0.3993
- 0.4064
- 0.4004
- 0.3988
- 0.4043
- 0.402
- 0.398
- 0.4085
- 0.411
- 0.4102
test_loss_list:
- 1.649349241256714
- 1.542062883377075
- 1.4949145030975342
- 1.4411976838111877
- 1.406350495815277
- 1.3686388373374938
- 1.3473655652999879
- 1.3117085218429565
- 1.302345643043518
- 1.2721687245368958
- 1.2561842489242554
- 1.2369778633117676
- 1.224754912853241
- 1.207591826915741
- 1.1922279262542725
- 1.1913954401016236
- 1.1771923565864564
- 1.1689370059967041
- 1.1648846673965454
- 1.176967260837555
- 1.1452298617362977
- 1.1523263430595398
- 1.1446357202529907
- 1.1175563168525695
- 1.1385574340820312
- 1.1294855952262879
- 1.1246213102340699
- 1.1277889657020568
- 1.096661801338196
- 1.0954455876350402
- 1.130359447002411
- 1.059300594329834
- 1.0631633949279786
- 1.0629015851020813
- 1.0816985940933228
- 1.0539099979400635
- 1.0475824403762817
- 1.0482289910316467
- 1.0344148135185243
- 1.0306624150276185
- 1.0349468660354615
- 1.0117156159877778
- 1.0090404987335204
- 1.0119916009902954
- 1.0012987112998963
- 1.0209156608581542
- 1.0049846601486205
- 1.0021080446243287
- 1.0337335062026978
- 1.0072610902786254
- 1.003083529472351
- 1.0019134020805358
- 0.9930065727233887
- 0.983192732334137
- 0.9911088943481445
- 1.0085668826103211
- 0.9885770010948182
- 0.9987691140174866
- 1.0132245326042175
- 1.00291020154953
- 0.9940648317337036
- 0.9927542018890381
- 0.983775520324707
- 0.9928061628341674
- 0.9761038339138031
- 1.0010186338424683
- 1.0003961992263795
- 0.9927307271957397
- 1.0084073758125305
- 0.99534095287323
- 1.0117496418952943
- 1.003623218536377
- 1.0141813731193543
- 0.9961678671836853
- 0.9870359134674073
- 1.0019176387786866
- 1.0083301782608032
- 0.9953094434738159
- 0.9777610588073731
- 0.9811188626289368
- 0.984582028388977
- 0.9808220553398133
- 0.9923990058898926
- 0.9911150288581848
- 0.9827397656440735
- 0.9918902325630188
- 0.9960443472862244
- 0.9882792854309081
- 1.0041727304458619
- 0.9882284379005433
- 0.9918698406219483
- 0.9839364242553711
- 0.9905052351951599
- 0.9961941647529602
- 0.9655083656311035
- 0.9846970677375794
- 0.9964985036849976
- 0.9769619870185852
- 0.9810919451713562
- 0.9838737106323242
train_accuracy:
- 0.103
- 0.123
- 0.137
- 0.15
- 0.16
- 0.178
- 0.184
- 0.203
- 0.167
- 0.211
- 0.235
- 0.265
- 0.206
- 0.254
- 0.236
- 0.268
- 0.268
- 0.208
- 0.263
- 0.277
- 0.282
- 0.286
- 0.274
- 0.276
- 0.277
- 0.284
- 0.3
- 0.298
- 0.302
- 0.288
- 0.309
- 0.291
- 0.324
- 0.3
- 0.317
- 0.308
- 0.328
- 0.31
- 0.349
- 0.301
- 0.338
- 0.347
- 0.308
- 0.351
- 0.347
- 0.343
- 0.328
- 0.335
- 0.328
- 0.356
- 0.326
- 0.358
- 0.373
- 0.337
- 0.365
- 0.353
- 0.363
- 0.351
- 0.358
- 0.376
- 0.33
- 0.362
- 0.339
- 0.381
- 0.341
- 0.334
- 0.367
- 0.341
- 0.339
- 0.337
- 0.341
- 0.376
- 0.376
- 0.377
- 0.395
- 0.374
- 0.377
- 0.371
- 0.369
- 0.388
- 0.405
- 0.353
- 0.387
- 0.391
- 0.348
- 0.346
- 0.392
- 0.367
- 0.391
- 0.406
- 0.385
- 0.367
- 0.356
- 0.398
- 0.372
- 0.409
- 0.356
- 0.382
- 0.387
- 0.397
train_loss:
- 4.2
- 3.704
- 3.211
- 3.407
- 3.318
- 3.233
- 2.783
- 3.086
- 3.006
- 2.993
- 2.785
- 2.927
- 2.594
- 2.373
- 2.557
- 2.503
- 2.554
- 2.258
- 2.15
- 1.762
- 2.519
- 1.591
- 2.086
- 2.355
- 1.762
- 1.397
- 1.486
- 1.288
- 2.28
- 1.991
- 2.296
- 2.056
- 1.353
- 1.636
- 1.92
- 1.634
- 1.521
- 1.356
- 1.874
- 1.48
- 1.349
- 1.832
- 1.821
- 1.944
- 1.22
- 0.803
- 1.376
- 1.151
- 0.737
- 1.593
- 1.477
- 1.838
- 1.233
- 1.164
- 0.762
- 0.485
- 1.457
- 0.484
- 0.929
- 1.093
- 0.968
- 1.506
- 0.704
- 0.78
- 1.227
- 0.734
- 1.173
- 0.656
- 0.417
- 0.688
- 0.41
- 0.681
- 0.379
- 1.312
- 0.587
- 0.302
- 0.877
- 0.99
- 0.502
- 0.361
- 0.445
- 0.56
- 0.72
- 0.303
- 0.403
- 0.228
- 0.239
- 0.427
- 0.946
- 0.597
- 0.588
- 0.341
- 0.187
- 0.253
- 1.168
- 0.5
- 0.703
- 0.282
- 0.233
- 0.443
unequal: 0
verbose: 1
