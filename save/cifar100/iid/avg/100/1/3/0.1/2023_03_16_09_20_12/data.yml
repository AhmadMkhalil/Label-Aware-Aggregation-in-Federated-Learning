avg_train_accuracy: 0.399
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0797
- 0.1162
- 0.1402
- 0.1589
- 0.1723
- 0.1798
- 0.1964
- 0.2189
- 0.2195
- 0.231
- 0.2361
- 0.243
- 0.2514
- 0.2521
- 0.2564
- 0.2712
- 0.2671
- 0.2805
- 0.2834
- 0.277
- 0.29
- 0.2864
- 0.3051
- 0.3079
- 0.3063
- 0.3077
- 0.2955
- 0.3183
- 0.3153
- 0.3116
- 0.3148
- 0.326
- 0.3244
- 0.3264
- 0.3312
- 0.3328
- 0.3449
- 0.3279
- 0.3322
- 0.3452
- 0.3321
- 0.3443
- 0.3448
- 0.3603
- 0.3524
- 0.3569
- 0.3585
- 0.3697
- 0.3668
- 0.3641
- 0.373
- 0.362
- 0.3692
- 0.3709
- 0.3704
- 0.3664
- 0.366
- 0.3772
- 0.39
- 0.3807
- 0.3837
- 0.3726
- 0.3879
- 0.3869
- 0.3855
- 0.388
- 0.3923
- 0.3943
- 0.3909
- 0.3886
- 0.3967
- 0.3909
- 0.375
- 0.3805
- 0.3984
- 0.3859
- 0.3892
- 0.381
- 0.3911
- 0.3877
- 0.4009
- 0.401
- 0.3947
- 0.3981
- 0.3996
- 0.3915
- 0.4036
- 0.3985
- 0.4024
- 0.4061
- 0.4017
- 0.4015
- 0.4019
- 0.4034
- 0.4109
- 0.4095
- 0.4073
- 0.4063
- 0.4075
- 0.4146
test_loss_list:
- 1.6633545780181884
- 1.563622694015503
- 1.5126639008522034
- 1.4505400943756104
- 1.4197250080108643
- 1.3920035505294799
- 1.3710442662239075
- 1.3378278732299804
- 1.3125723552703858
- 1.2969112610816955
- 1.2860075807571412
- 1.2636289501190185
- 1.249679741859436
- 1.2377679562568664
- 1.223774824142456
- 1.2069495487213135
- 1.2014844346046447
- 1.1847929072380066
- 1.1779338860511779
- 1.1816190838813783
- 1.1731052947044374
- 1.1547823214530946
- 1.12699049949646
- 1.1284393024444581
- 1.1306941056251525
- 1.121179428100586
- 1.1381065034866333
- 1.1145012640953065
- 1.1139360904693603
- 1.126140456199646
- 1.1219713687896729
- 1.0898644423484802
- 1.0941096544265747
- 1.0890677452087403
- 1.0695582437515259
- 1.0750233793258668
- 1.0531403493881226
- 1.0915379810333252
- 1.0816003918647765
- 1.051694803237915
- 1.0739814090728759
- 1.0643184757232667
- 1.0484000897407533
- 1.039784722328186
- 1.0539669108390808
- 1.0283470726013184
- 1.0251328134536744
- 1.0071106004714965
- 1.015659637451172
- 1.0083306312561036
- 1.0074426531791687
- 1.0297238183021546
- 1.0148096680641174
- 1.022739918231964
- 1.021094992160797
- 1.0229920625686646
- 1.0326982402801514
- 0.9980817508697509
- 0.9761194157600402
- 0.9997609853744507
- 0.9932142996788025
- 1.008109486103058
- 0.9867917978763581
- 0.9874381685256958
- 0.9916114068031311
- 0.9802553105354309
- 0.9772497868537903
- 0.9776806259155273
- 0.9960891580581666
- 0.997462192773819
- 0.9781794428825379
- 0.9798349213600158
- 1.0144983148574829
- 1.0151261806488037
- 0.9767034602165222
- 1.0012815642356871
- 0.997372899055481
- 1.0093843030929566
- 1.0025741863250732
- 0.9882816290855407
- 0.9774642872810364
- 0.9790177750587463
- 0.983995234966278
- 0.9927682030200958
- 0.9972848200798035
- 1.0042126274108887
- 0.9780431914329529
- 0.98049320936203
- 0.9779259836673737
- 0.9828978455066681
- 0.981940780878067
- 0.9943076622486114
- 0.9957236266136169
- 1.0026608681678773
- 0.9749768209457398
- 0.9915615582466125
- 0.9843839108943939
- 0.9906982123851776
- 0.9891665136814117
- 0.9822911286354065
train_accuracy:
- 0.079
- 0.099
- 0.137
- 0.177
- 0.142
- 0.166
- 0.164
- 0.191
- 0.21
- 0.204
- 0.214
- 0.26
- 0.227
- 0.245
- 0.228
- 0.258
- 0.25
- 0.27
- 0.255
- 0.268
- 0.26
- 0.282
- 0.289
- 0.275
- 0.296
- 0.276
- 0.275
- 0.292
- 0.306
- 0.274
- 0.283
- 0.303
- 0.281
- 0.305
- 0.322
- 0.332
- 0.342
- 0.305
- 0.302
- 0.317
- 0.321
- 0.317
- 0.341
- 0.33
- 0.308
- 0.325
- 0.322
- 0.347
- 0.347
- 0.344
- 0.321
- 0.31
- 0.347
- 0.34
- 0.345
- 0.329
- 0.33
- 0.36
- 0.389
- 0.375
- 0.341
- 0.356
- 0.37
- 0.37
- 0.339
- 0.383
- 0.345
- 0.394
- 0.358
- 0.364
- 0.353
- 0.386
- 0.373
- 0.356
- 0.399
- 0.363
- 0.391
- 0.358
- 0.377
- 0.377
- 0.399
- 0.383
- 0.373
- 0.396
- 0.396
- 0.371
- 0.399
- 0.387
- 0.374
- 0.374
- 0.383
- 0.387
- 0.39
- 0.374
- 0.396
- 0.365
- 0.387
- 0.391
- 0.395
- 0.399
train_loss:
- 4.2
- 3.81
- 3.382
- 3.451
- 3.353
- 3.212
- 2.924
- 3.174
- 3.09
- 2.946
- 2.594
- 2.782
- 2.702
- 2.799
- 2.551
- 2.562
- 2.35
- 2.707
- 2.526
- 2.282
- 2.15
- 2.393
- 2.531
- 2.094
- 2.142
- 2.047
- 1.598
- 1.895
- 1.91
- 1.49
- 1.608
- 2.05
- 1.298
- 1.829
- 2.105
- 1.57
- 1.722
- 1.454
- 1.014
- 1.967
- 1.931
- 1.499
- 1.568
- 1.036
- 1.217
- 2.039
- 1.377
- 1.56
- 1.879
- 1.623
- 1.076
- 0.683
- 1.315
- 1.511
- 1.007
- 0.688
- 1.58
- 1.641
- 1.299
- 1.248
- 0.652
- 1.323
- 1.393
- 1.117
- 1.179
- 1.033
- 0.583
- 0.72
- 0.821
- 1.262
- 0.466
- 0.872
- 0.525
- 0.956
- 0.724
- 0.675
- 0.503
- 0.571
- 0.536
- 1.333
- 0.48
- 0.705
- 0.902
- 1.158
- 0.614
- 0.704
- 0.446
- 0.544
- 0.513
- 0.555
- 0.377
- 0.64
- 0.444
- 0.413
- 0.367
- 0.48
- 0.398
- 0.494
- 0.274
- 0.294
unequal: 0
verbose: 1
