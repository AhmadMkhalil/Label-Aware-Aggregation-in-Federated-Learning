avg_train_accuracy: 0.428
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.083
- 0.1242
- 0.1439
- 0.1705
- 0.1857
- 0.1965
- 0.2035
- 0.2082
- 0.223
- 0.2287
- 0.2417
- 0.2477
- 0.2533
- 0.2627
- 0.267
- 0.2743
- 0.2724
- 0.2742
- 0.2772
- 0.2754
- 0.2756
- 0.2887
- 0.2945
- 0.3084
- 0.313
- 0.3123
- 0.3164
- 0.3211
- 0.3236
- 0.3146
- 0.3114
- 0.3287
- 0.3245
- 0.3334
- 0.3339
- 0.3463
- 0.3531
- 0.3486
- 0.3428
- 0.3505
- 0.3569
- 0.347
- 0.3612
- 0.3588
- 0.3612
- 0.3578
- 0.3561
- 0.3717
- 0.3689
- 0.3814
- 0.3694
- 0.3787
- 0.3799
- 0.3734
- 0.3833
- 0.3938
- 0.3788
- 0.388
- 0.3858
- 0.3908
- 0.3952
- 0.3998
- 0.3918
- 0.4039
- 0.3964
- 0.4053
- 0.3951
- 0.411
- 0.4061
- 0.3967
- 0.4056
- 0.4016
- 0.4036
- 0.4163
- 0.3957
- 0.409
- 0.4102
- 0.4102
- 0.4119
- 0.4106
- 0.4049
- 0.4112
- 0.4033
- 0.4148
- 0.417
- 0.4141
- 0.4128
- 0.4138
- 0.417
- 0.4122
- 0.4119
- 0.4149
- 0.4152
- 0.4244
- 0.4186
- 0.4151
- 0.4319
- 0.4311
- 0.4244
- 0.4358
test_loss_list:
- 1.6647429275512695
- 1.556221625804901
- 1.490521059036255
- 1.448029441833496
- 1.4057856106758118
- 1.3716305828094482
- 1.3538876104354858
- 1.329445219039917
- 1.300075945854187
- 1.2838343477249146
- 1.2697746443748474
- 1.247065155506134
- 1.2319748735427856
- 1.2131898856163026
- 1.2031075549125672
- 1.1872501635551453
- 1.1868419003486634
- 1.1879649114608766
- 1.1731706523895264
- 1.16717351436615
- 1.1751674675941468
- 1.1561880826950073
- 1.1330512475967407
- 1.1140658140182496
- 1.1063926672935487
- 1.1075910711288453
- 1.095710244178772
- 1.0946129846572876
- 1.1003072714805604
- 1.1236109018325806
- 1.1364669704437256
- 1.0789482522010803
- 1.0913043427467346
- 1.058273093700409
- 1.0700026869773864
- 1.0301821279525756
- 1.0347598505020141
- 1.0431060123443603
- 1.0350040948390962
- 1.0364257907867431
- 1.0320670795440674
- 1.0430545783042908
- 1.0289570379257202
- 1.0252678298950195
- 1.0213085794448853
- 0.9991940259933472
- 1.0136063313484192
- 0.9903367376327514
- 0.9997092986106872
- 0.9719844079017639
- 0.9901120066642761
- 0.9872299909591675
- 0.9834673142433167
- 0.9885085475444794
- 0.9747069692611694
- 0.9605749130249024
- 0.9736088919639587
- 0.9664708065986634
- 0.9578744435310363
- 0.957479614019394
- 0.9630635690689087
- 0.9604911661148071
- 0.9853895020484924
- 0.9505238819122315
- 0.9596079766750336
- 0.9511198830604554
- 0.9677065539360047
- 0.9560711252689361
- 0.9564656209945679
- 0.9548039245605469
- 0.9429482913017273
- 0.9465776801109314
- 0.9344108736515045
- 0.9369807827472687
- 0.9776627922058105
- 0.9490974986553192
- 0.9493549466133118
- 0.9401094555854798
- 0.9538223338127136
- 0.9591337287425995
- 0.9687694036960601
- 0.9540437245368958
- 0.9782960891723633
- 0.9518347358703614
- 0.9528360271453857
- 0.9549397456645966
- 0.9558162891864777
- 0.9516625082492829
- 0.9631897401809693
- 0.9592360138893128
- 0.963404141664505
- 0.951851702928543
- 0.9475499653816223
- 0.9378362131118775
- 0.951492817401886
- 0.9440593051910401
- 0.9319451642036438
- 0.9437727773189545
- 0.9393378436565399
- 0.928039927482605
train_accuracy:
- 0.083
- 0.129
- 0.126
- 0.166
- 0.194
- 0.194
- 0.179
- 0.196
- 0.185
- 0.225
- 0.203
- 0.235
- 0.212
- 0.262
- 0.26
- 0.269
- 0.28
- 0.29
- 0.246
- 0.237
- 0.255
- 0.295
- 0.251
- 0.295
- 0.265
- 0.322
- 0.317
- 0.264
- 0.253
- 0.247
- 0.244
- 0.31
- 0.318
- 0.326
- 0.318
- 0.326
- 0.366
- 0.299
- 0.332
- 0.341
- 0.34
- 0.333
- 0.294
- 0.332
- 0.371
- 0.348
- 0.361
- 0.364
- 0.355
- 0.328
- 0.327
- 0.306
- 0.358
- 0.375
- 0.323
- 0.383
- 0.386
- 0.372
- 0.387
- 0.385
- 0.378
- 0.329
- 0.325
- 0.397
- 0.398
- 0.402
- 0.384
- 0.405
- 0.38
- 0.409
- 0.394
- 0.343
- 0.405
- 0.387
- 0.379
- 0.358
- 0.392
- 0.421
- 0.343
- 0.359
- 0.362
- 0.404
- 0.396
- 0.344
- 0.411
- 0.398
- 0.428
- 0.363
- 0.358
- 0.405
- 0.428
- 0.401
- 0.392
- 0.414
- 0.411
- 0.434
- 0.401
- 0.36
- 0.423
- 0.428
train_loss:
- 4.288
- 3.816
- 3.61
- 3.402
- 3.342
- 3.206
- 3.128
- 2.998
- 2.933
- 3.011
- 2.681
- 2.857
- 2.549
- 2.691
- 2.563
- 2.68
- 2.345
- 1.946
- 2.238
- 1.809
- 1.525
- 1.847
- 2.503
- 2.308
- 2.188
- 1.608
- 2.225
- 1.828
- 1.415
- 1.165
- 0.975
- 1.959
- 1.438
- 2.093
- 1.559
- 2.003
- 1.493
- 1.111
- 1.504
- 1.359
- 1.81
- 1.274
- 0.986
- 1.226
- 1.213
- 1.928
- 1.328
- 1.542
- 2.013
- 1.88
- 1.295
- 0.976
- 1.279
- 1.614
- 1.238
- 1.603
- 1.232
- 1.129
- 1.319
- 1.063
- 0.94
- 0.799
- 0.459
- 1.198
- 1.04
- 0.809
- 0.88
- 0.626
- 0.899
- 1.09
- 1.33
- 1.094
- 0.778
- 0.707
- 0.906
- 0.838
- 0.534
- 0.633
- 0.603
- 0.641
- 0.356
- 0.699
- 0.712
- 0.439
- 0.422
- 1.088
- 0.548
- 0.474
- 0.244
- 0.713
- 0.425
- 1.174
- 0.815
- 0.351
- 0.456
- 0.632
- 0.483
- 0.396
- 0.806
- 0.327
unequal: 0
verbose: 1
