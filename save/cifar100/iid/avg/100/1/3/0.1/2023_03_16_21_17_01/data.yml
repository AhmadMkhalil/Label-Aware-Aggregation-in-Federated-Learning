avg_train_accuracy: 0.378
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0833
- 0.1232
- 0.1518
- 0.1684
- 0.1887
- 0.1974
- 0.2044
- 0.2192
- 0.2259
- 0.2356
- 0.2437
- 0.244
- 0.2488
- 0.2679
- 0.2743
- 0.2877
- 0.2913
- 0.2977
- 0.2942
- 0.3022
- 0.3065
- 0.3136
- 0.3191
- 0.313
- 0.323
- 0.3162
- 0.3286
- 0.335
- 0.3224
- 0.3284
- 0.3495
- 0.3504
- 0.3337
- 0.3337
- 0.3386
- 0.3604
- 0.3569
- 0.3585
- 0.3603
- 0.3612
- 0.3677
- 0.3629
- 0.363
- 0.3724
- 0.3759
- 0.3824
- 0.3649
- 0.3842
- 0.3871
- 0.3781
- 0.3848
- 0.3916
- 0.3835
- 0.3867
- 0.3915
- 0.3939
- 0.3997
- 0.4048
- 0.4066
- 0.408
- 0.383
- 0.3871
- 0.4058
- 0.3961
- 0.394
- 0.4108
- 0.4133
- 0.4111
- 0.405
- 0.4006
- 0.4178
- 0.4183
- 0.4155
- 0.4202
- 0.4063
- 0.4144
- 0.4135
- 0.4225
- 0.4148
- 0.4152
- 0.4204
- 0.4067
- 0.4248
- 0.4231
- 0.4279
- 0.4201
- 0.4245
- 0.4236
- 0.419
- 0.4226
- 0.4157
- 0.4049
- 0.4315
- 0.4304
- 0.4291
- 0.4365
- 0.4282
- 0.4393
- 0.4317
- 0.4369
test_loss_list:
- 1.673356399536133
- 1.5494890737533569
- 1.4824803495407104
- 1.4368865203857422
- 1.3933376145362855
- 1.3631446146965027
- 1.3507690930366516
- 1.3175210022926331
- 1.3004817652702332
- 1.2646649622917174
- 1.251803081035614
- 1.2529281854629517
- 1.2284211897850037
- 1.2041609334945678
- 1.1848432588577271
- 1.1626862239837648
- 1.1517745995521544
- 1.1457476663589476
- 1.1353669738769532
- 1.1222991466522216
- 1.1239434504508972
- 1.1064883971214294
- 1.0911020016670228
- 1.0958671259880066
- 1.090472204685211
- 1.110980920791626
- 1.0780831503868102
- 1.0573572826385498
- 1.090405251979828
- 1.0812112975120545
- 1.0388850831985474
- 1.0371845984458923
- 1.0847818064689636
- 1.0767473602294921
- 1.0724142050743104
- 1.0177307057380676
- 1.0366741466522216
- 1.0279951858520509
- 1.019320204257965
- 1.019415647983551
- 0.9887158012390137
- 1.0312511944770812
- 1.021362931728363
- 0.9897508549690247
- 0.9961702728271484
- 0.9745953297615051
- 1.006056616306305
- 0.9692895984649659
- 0.9618001008033752
- 0.9921744394302369
- 0.9847792863845826
- 0.9742898988723755
- 0.9708982396125794
- 0.9660993647575379
- 0.9642669975757598
- 0.9692493593692779
- 0.9414179134368896
- 0.9401303267478943
- 0.9422788906097412
- 0.9422145986557007
- 0.9922205567359924
- 0.976582533121109
- 0.9459040939807892
- 0.9548912739753723
- 0.9629983162879944
- 0.9311062777042389
- 0.9238256359100342
- 0.9307702600955963
- 0.9525967359542846
- 0.9680123949050903
- 0.9298858499526977
- 0.9268472838401794
- 0.9370655155181885
- 0.9279403305053711
- 0.9600306081771851
- 0.933695707321167
- 0.9419227123260498
- 0.9284549963474273
- 0.940040271282196
- 0.9389512538909912
- 0.9428120255470276
- 0.9564157402515412
- 0.9296905732154847
- 0.9362530100345612
- 0.9338904011249543
- 0.9452055370807648
- 0.9291758227348328
- 0.9379524302482605
- 0.9432193231582642
- 0.9436014914512634
- 0.948934406042099
- 0.9777537429332733
- 0.9187789678573608
- 0.936193106174469
- 0.9259741342067719
- 0.9141036665439606
- 0.9320354402065277
- 0.9150040209293365
- 0.93166255235672
- 0.9200156211853028
train_accuracy:
- 0.085
- 0.109
- 0.144
- 0.131
- 0.161
- 0.189
- 0.168
- 0.162
- 0.207
- 0.2
- 0.188
- 0.181
- 0.211
- 0.255
- 0.238
- 0.281
- 0.274
- 0.282
- 0.259
- 0.282
- 0.265
- 0.277
- 0.293
- 0.268
- 0.291
- 0.278
- 0.33
- 0.325
- 0.305
- 0.288
- 0.336
- 0.325
- 0.312
- 0.314
- 0.297
- 0.296
- 0.33
- 0.332
- 0.363
- 0.32
- 0.296
- 0.328
- 0.304
- 0.329
- 0.345
- 0.374
- 0.304
- 0.354
- 0.363
- 0.342
- 0.341
- 0.347
- 0.36
- 0.36
- 0.357
- 0.371
- 0.34
- 0.38
- 0.379
- 0.351
- 0.35
- 0.318
- 0.379
- 0.353
- 0.355
- 0.399
- 0.352
- 0.404
- 0.378
- 0.359
- 0.377
- 0.367
- 0.382
- 0.385
- 0.329
- 0.39
- 0.352
- 0.406
- 0.39
- 0.396
- 0.384
- 0.396
- 0.401
- 0.395
- 0.394
- 0.381
- 0.374
- 0.362
- 0.414
- 0.362
- 0.388
- 0.377
- 0.384
- 0.401
- 0.406
- 0.368
- 0.431
- 0.386
- 0.404
- 0.378
train_loss:
- 4.281
- 3.833
- 3.592
- 3.452
- 3.322
- 3.242
- 2.968
- 3.141
- 2.95
- 2.974
- 2.726
- 2.343
- 2.787
- 2.708
- 2.712
- 2.578
- 2.441
- 2.202
- 2.433
- 2.28
- 2.263
- 1.918
- 2.066
- 2.234
- 1.71
- 1.341
- 1.952
- 2.247
- 1.749
- 1.954
- 1.63
- 1.957
- 1.499
- 1.635
- 1.217
- 1.891
- 1.426
- 1.639
- 1.433
- 2.077
- 1.901
- 1.276
- 1.635
- 1.575
- 1.407
- 1.216
- 1.525
- 1.912
- 1.408
- 1.454
- 1.18
- 1.136
- 1.643
- 1.107
- 0.947
- 1.267
- 1.332
- 1.157
- 0.775
- 1.285
- 0.833
- 1.075
- 0.965
- 1.404
- 0.908
- 1.083
- 0.858
- 0.729
- 1.33
- 0.781
- 0.995
- 0.938
- 0.769
- 0.787
- 0.72
- 0.786
- 0.512
- 0.699
- 0.581
- 0.769
- 0.63
- 1.123
- 0.461
- 0.58
- 0.483
- 0.396
- 0.523
- 0.782
- 0.587
- 0.506
- 0.872
- 0.695
- 0.893
- 0.528
- 0.6
- 0.455
- 1.0
- 0.322
- 0.443
- 0.233
unequal: 0
verbose: 1
