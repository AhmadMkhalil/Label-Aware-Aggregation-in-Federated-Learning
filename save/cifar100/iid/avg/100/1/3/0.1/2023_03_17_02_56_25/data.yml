avg_train_accuracy: 0.361
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0849
- 0.1179
- 0.1404
- 0.157
- 0.1754
- 0.1836
- 0.1871
- 0.2092
- 0.2119
- 0.2299
- 0.2268
- 0.2417
- 0.2439
- 0.2441
- 0.2637
- 0.2728
- 0.2706
- 0.2796
- 0.2766
- 0.2713
- 0.296
- 0.2956
- 0.2984
- 0.3052
- 0.3137
- 0.3113
- 0.308
- 0.3217
- 0.3256
- 0.3282
- 0.3271
- 0.3316
- 0.3435
- 0.3437
- 0.3369
- 0.3333
- 0.3392
- 0.341
- 0.3419
- 0.3543
- 0.3478
- 0.3488
- 0.3386
- 0.3562
- 0.3435
- 0.3697
- 0.3641
- 0.371
- 0.3738
- 0.3768
- 0.3796
- 0.3691
- 0.3737
- 0.3658
- 0.3715
- 0.3675
- 0.3683
- 0.3808
- 0.3788
- 0.3835
- 0.3907
- 0.3816
- 0.383
- 0.3859
- 0.3807
- 0.3895
- 0.3868
- 0.3943
- 0.386
- 0.3972
- 0.3889
- 0.3864
- 0.3979
- 0.398
- 0.3925
- 0.3984
- 0.3953
- 0.3987
- 0.4013
- 0.4084
- 0.3973
- 0.404
- 0.4078
- 0.4098
- 0.4215
- 0.4213
- 0.4135
- 0.4137
- 0.4007
- 0.4125
- 0.4239
- 0.4143
- 0.4142
- 0.4104
- 0.4149
- 0.4255
- 0.4203
- 0.4195
- 0.4168
- 0.4097
test_loss_list:
- 1.6665563583374023
- 1.5591363763809205
- 1.510366461277008
- 1.4769646859169006
- 1.423283531665802
- 1.4075432372093202
- 1.4048490118980408
- 1.3495121955871583
- 1.3295699644088745
- 1.2925421214103698
- 1.2956905364990234
- 1.266732075214386
- 1.2692677283287048
- 1.2421537399291993
- 1.215913851261139
- 1.1954048299789428
- 1.1885307836532593
- 1.1740063285827638
- 1.1754733228683472
- 1.1857078981399536
- 1.1424166297912597
- 1.1330744552612304
- 1.1334651184082032
- 1.1239176559448243
- 1.105546736717224
- 1.103834114074707
- 1.1145749831199645
- 1.0852947974205016
- 1.080427620410919
- 1.069452974796295
- 1.073796648979187
- 1.0741812086105347
- 1.0428359389305115
- 1.0437126779556274
- 1.063933825492859
- 1.0686026263236998
- 1.0528839683532716
- 1.0601679873466492
- 1.0446439814567565
- 1.022207624912262
- 1.0404239106178284
- 1.0336448907852174
- 1.063184094429016
- 1.0342731189727783
- 1.053966703414917
- 0.9970055723190308
- 1.0135539364814758
- 1.0024162459373473
- 0.992947678565979
- 0.9986831378936768
- 0.997385790348053
- 1.0021561336517335
- 0.9990186953544616
- 1.013694589138031
- 1.0006340146064758
- 1.0073148202896118
- 1.012197163105011
- 0.9925016975402832
- 0.9973545598983765
- 0.9932943272590637
- 0.9682649397850036
- 0.9943359088897705
- 0.9902032232284546
- 0.988412573337555
- 0.9911633110046387
- 0.9778743433952332
- 0.9930918097496033
- 0.9727583062648774
- 0.9710192799568176
- 0.9682897329330444
- 0.970915699005127
- 1.0024903178215028
- 0.9801696252822876
- 0.9731311798095703
- 0.9769079470634461
- 0.9659446096420288
- 0.9682135498523712
- 0.9793862676620484
- 0.973559741973877
- 0.9623068714141846
- 0.9823838877677917
- 0.9752780628204346
- 0.964189088344574
- 0.9574866557121277
- 0.9342166709899903
- 0.9430804491043091
- 0.954315299987793
- 0.9527129626274109
- 0.9703520083427429
- 0.9652793955802917
- 0.9431655573844909
- 0.962717866897583
- 0.9588057947158813
- 0.9739848399162292
- 0.9592510223388672
- 0.9478928887844086
- 0.9590645956993104
- 0.9610717320442199
- 0.968968596458435
- 0.9696919822692871
train_accuracy:
- 0.067
- 0.086
- 0.114
- 0.131
- 0.159
- 0.163
- 0.16
- 0.206
- 0.184
- 0.214
- 0.217
- 0.206
- 0.203
- 0.219
- 0.257
- 0.213
- 0.251
- 0.268
- 0.23
- 0.235
- 0.292
- 0.285
- 0.252
- 0.294
- 0.312
- 0.298
- 0.299
- 0.298
- 0.271
- 0.334
- 0.305
- 0.265
- 0.341
- 0.322
- 0.326
- 0.336
- 0.326
- 0.299
- 0.315
- 0.29
- 0.349
- 0.32
- 0.314
- 0.341
- 0.318
- 0.308
- 0.309
- 0.333
- 0.356
- 0.385
- 0.356
- 0.321
- 0.354
- 0.321
- 0.349
- 0.32
- 0.343
- 0.37
- 0.348
- 0.358
- 0.326
- 0.356
- 0.411
- 0.328
- 0.359
- 0.384
- 0.387
- 0.34
- 0.375
- 0.368
- 0.357
- 0.341
- 0.398
- 0.38
- 0.373
- 0.341
- 0.395
- 0.371
- 0.388
- 0.391
- 0.366
- 0.421
- 0.381
- 0.343
- 0.376
- 0.382
- 0.387
- 0.387
- 0.388
- 0.365
- 0.397
- 0.382
- 0.395
- 0.394
- 0.373
- 0.365
- 0.377
- 0.395
- 0.437
- 0.361
train_loss:
- 4.228
- 3.796
- 3.324
- 2.981
- 3.324
- 2.714
- 2.379
- 3.132
- 3.094
- 2.79
- 2.205
- 2.751
- 2.286
- 2.638
- 2.584
- 2.779
- 2.238
- 2.649
- 2.518
- 2.037
- 2.299
- 1.965
- 2.524
- 1.962
- 2.194
- 1.668
- 1.85
- 1.914
- 2.22
- 2.087
- 1.456
- 1.851
- 2.188
- 1.688
- 1.237
- 1.676
- 1.259
- 2.054
- 1.016
- 1.84
- 1.421
- 1.675
- 1.212
- 1.282
- 1.697
- 1.529
- 1.069
- 1.574
- 1.372
- 1.253
- 1.043
- 1.518
- 0.855
- 1.084
- 1.046
- 0.845
- 0.741
- 1.265
- 0.824
- 1.052
- 1.113
- 0.657
- 1.019
- 0.825
- 1.253
- 0.74
- 0.795
- 0.685
- 1.613
- 1.092
- 0.917
- 0.505
- 0.695
- 0.841
- 0.606
- 0.599
- 1.232
- 0.471
- 0.632
- 0.637
- 1.016
- 0.599
- 0.824
- 1.518
- 0.605
- 0.513
- 0.574
- 0.749
- 0.449
- 1.096
- 0.449
- 0.553
- 0.342
- 0.576
- 0.639
- 0.469
- 0.458
- 0.523
- 0.507
- 0.868
unequal: 0
verbose: 1
