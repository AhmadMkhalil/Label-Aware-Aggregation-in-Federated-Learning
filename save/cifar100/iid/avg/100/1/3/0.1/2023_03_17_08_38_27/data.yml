avg_train_accuracy: 0.415
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0856
- 0.127
- 0.1464
- 0.1693
- 0.1804
- 0.1861
- 0.202
- 0.2154
- 0.2199
- 0.2304
- 0.2357
- 0.2507
- 0.2568
- 0.2612
- 0.2541
- 0.2679
- 0.2841
- 0.2814
- 0.2883
- 0.3025
- 0.3009
- 0.2989
- 0.2944
- 0.2903
- 0.2918
- 0.302
- 0.3166
- 0.3169
- 0.3298
- 0.3257
- 0.329
- 0.3272
- 0.3294
- 0.3404
- 0.3473
- 0.3468
- 0.3219
- 0.3437
- 0.3531
- 0.3566
- 0.3464
- 0.3598
- 0.359
- 0.367
- 0.3589
- 0.3615
- 0.3632
- 0.3571
- 0.3618
- 0.3738
- 0.3728
- 0.3672
- 0.375
- 0.3839
- 0.3822
- 0.3861
- 0.3847
- 0.3917
- 0.3919
- 0.3875
- 0.3928
- 0.3988
- 0.3938
- 0.4021
- 0.3893
- 0.3996
- 0.3948
- 0.4041
- 0.4031
- 0.3974
- 0.4027
- 0.3951
- 0.4083
- 0.3898
- 0.3941
- 0.3952
- 0.4036
- 0.4018
- 0.4063
- 0.409
- 0.3993
- 0.4085
- 0.4107
- 0.4052
- 0.4055
- 0.4119
- 0.4161
- 0.4223
- 0.4082
- 0.4182
- 0.4225
- 0.422
- 0.4133
- 0.407
- 0.419
- 0.4206
- 0.4157
- 0.4206
- 0.4271
- 0.4229
test_loss_list:
- 1.650888683795929
- 1.5489674401283264
- 1.48857971906662
- 1.4461675930023192
- 1.4119979810714722
- 1.3950960993766786
- 1.3578852939605712
- 1.3358609008789062
- 1.3090230584144593
- 1.2929068851470946
- 1.2748800826072693
- 1.2618933606147766
- 1.2404240036010743
- 1.2222726583480834
- 1.234238829612732
- 1.209156424999237
- 1.180209951400757
- 1.1739728903770448
- 1.1496126127243043
- 1.13897451877594
- 1.1231929183006286
- 1.13504234790802
- 1.1489714145660401
- 1.1607178521156312
- 1.1635814332962036
- 1.1295944118499757
- 1.1081836700439454
- 1.0964644718170167
- 1.0751293420791626
- 1.0744955372810363
- 1.0846096754074097
- 1.0851785635948181
- 1.0771865034103394
- 1.0758180236816406
- 1.0390105247497559
- 1.0487147450447083
- 1.0933922815322876
- 1.0536729049682618
- 1.0305991315841674
- 1.0366474032402038
- 1.0438617634773255
- 1.0200349593162537
- 1.0204122567176819
- 1.0213057208061218
- 1.0308238220214845
- 1.0242542076110839
- 1.01486412525177
- 1.0221731162071228
- 1.0156694912910462
- 0.9958078527450561
- 0.9983870792388916
- 1.0141059041023255
- 0.9916724514961243
- 0.9915863752365113
- 0.999472303390503
- 0.9886441349983215
- 0.9850231122970581
- 0.9740364503860474
- 0.9760112404823303
- 0.9700738787651062
- 0.9723651146888733
- 0.9666116452217102
- 0.9621084570884705
- 0.9564869356155395
- 0.9837080550193786
- 0.9744816374778748
- 0.9744803285598755
- 0.9675349259376526
- 0.9510958015918731
- 0.9716345310211182
- 0.9597297239303589
- 0.978552770614624
- 0.9655624198913574
- 0.9892925643920898
- 0.9713848376274109
- 0.9806955575942993
- 0.9653827261924743
- 0.9599893999099731
- 0.9668208265304565
- 0.9586600089073181
- 0.9690028142929077
- 0.9661800980567932
- 0.95784423828125
- 0.9732671904563904
- 0.9726199769973755
- 0.9579151582717895
- 0.9398039627075195
- 0.9588310551643372
- 0.9720559000968934
- 0.9543091821670532
- 0.947189177274704
- 0.9491133642196655
- 0.9660602021217346
- 0.9727752208709717
- 0.9555307984352112
- 0.9528008604049683
- 0.9599917531013489
- 0.9550108182430267
- 0.9436775279045105
- 0.9462547993659973
train_accuracy:
- 0.088
- 0.097
- 0.152
- 0.165
- 0.176
- 0.188
- 0.166
- 0.216
- 0.218
- 0.221
- 0.192
- 0.231
- 0.238
- 0.261
- 0.246
- 0.266
- 0.23
- 0.282
- 0.252
- 0.285
- 0.275
- 0.288
- 0.279
- 0.291
- 0.287
- 0.281
- 0.29
- 0.267
- 0.31
- 0.297
- 0.325
- 0.294
- 0.342
- 0.308
- 0.286
- 0.347
- 0.328
- 0.309
- 0.315
- 0.356
- 0.347
- 0.352
- 0.338
- 0.362
- 0.325
- 0.362
- 0.318
- 0.354
- 0.366
- 0.375
- 0.309
- 0.378
- 0.343
- 0.386
- 0.351
- 0.387
- 0.366
- 0.396
- 0.356
- 0.388
- 0.392
- 0.37
- 0.369
- 0.391
- 0.369
- 0.401
- 0.378
- 0.403
- 0.405
- 0.371
- 0.395
- 0.375
- 0.376
- 0.35
- 0.405
- 0.394
- 0.385
- 0.387
- 0.377
- 0.409
- 0.399
- 0.41
- 0.409
- 0.418
- 0.412
- 0.369
- 0.413
- 0.422
- 0.344
- 0.366
- 0.425
- 0.426
- 0.362
- 0.387
- 0.407
- 0.432
- 0.37
- 0.374
- 0.397
- 0.415
train_loss:
- 4.218
- 3.712
- 3.588
- 3.403
- 3.357
- 2.939
- 3.008
- 2.992
- 3.011
- 2.817
- 2.946
- 2.458
- 2.801
- 2.769
- 2.328
- 2.518
- 2.516
- 2.458
- 2.64
- 2.174
- 2.495
- 1.821
- 1.479
- 1.259
- 1.078
- 2.264
- 2.242
- 2.116
- 2.039
- 1.863
- 1.182
- 1.522
- 2.026
- 1.851
- 1.781
- 1.053
- 1.674
- 1.399
- 1.962
- 0.92
- 1.981
- 1.923
- 1.217
- 0.768
- 0.912
- 1.423
- 1.483
- 1.628
- 1.113
- 1.612
- 1.219
- 1.002
- 1.61
- 0.782
- 1.491
- 0.565
- 1.614
- 1.318
- 1.166
- 0.977
- 1.225
- 0.902
- 1.791
- 0.62
- 1.231
- 0.457
- 0.949
- 1.088
- 0.812
- 0.698
- 1.104
- 0.529
- 0.852
- 1.048
- 0.992
- 0.562
- 0.503
- 1.283
- 0.383
- 0.681
- 0.914
- 0.616
- 0.905
- 0.425
- 0.261
- 1.269
- 0.575
- 0.642
- 0.83
- 0.869
- 0.385
- 0.494
- 0.589
- 1.034
- 0.819
- 0.486
- 0.622
- 0.518
- 0.453
- 0.546
unequal: 0
verbose: 1
