avg_train_accuracy: 0.39
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0911
- 0.1241
- 0.1432
- 0.1527
- 0.1769
- 0.1826
- 0.2054
- 0.2122
- 0.2189
- 0.2309
- 0.2368
- 0.2385
- 0.252
- 0.2568
- 0.2564
- 0.273
- 0.2663
- 0.2789
- 0.2845
- 0.2816
- 0.2873
- 0.3035
- 0.303
- 0.308
- 0.304
- 0.3091
- 0.3177
- 0.3181
- 0.3108
- 0.329
- 0.3363
- 0.3331
- 0.3412
- 0.3412
- 0.3296
- 0.3482
- 0.346
- 0.3383
- 0.3499
- 0.343
- 0.3509
- 0.36
- 0.3548
- 0.3613
- 0.3567
- 0.3603
- 0.3573
- 0.3664
- 0.361
- 0.3662
- 0.3619
- 0.3582
- 0.3684
- 0.3571
- 0.367
- 0.3784
- 0.371
- 0.382
- 0.3729
- 0.3717
- 0.3822
- 0.3855
- 0.3849
- 0.3939
- 0.3831
- 0.3839
- 0.3925
- 0.3907
- 0.3856
- 0.3949
- 0.3916
- 0.3805
- 0.3972
- 0.3892
- 0.3968
- 0.4048
- 0.3907
- 0.4064
- 0.4096
- 0.4112
- 0.3958
- 0.4091
- 0.404
- 0.4121
- 0.4017
- 0.4089
- 0.4041
- 0.405
- 0.4108
- 0.4194
- 0.4066
- 0.4118
- 0.407
- 0.4131
- 0.4204
- 0.4148
- 0.419
- 0.4094
- 0.4118
- 0.4133
test_loss_list:
- 1.6543088340759278
- 1.5573206806182862
- 1.4927356362342834
- 1.4646099519729614
- 1.4134437823295594
- 1.4023647999763489
- 1.3488733625411988
- 1.3304535937309265
- 1.3104776334762573
- 1.2845581555366516
- 1.2624592566490174
- 1.2541042256355286
- 1.2416120648384095
- 1.2268583917617797
- 1.2223677277565002
- 1.1997034811973573
- 1.1888145542144775
- 1.1821647238731385
- 1.1641137027740478
- 1.178738570213318
- 1.1568473982810974
- 1.1228965139389038
- 1.132941393852234
- 1.115507128238678
- 1.133161985874176
- 1.116095678806305
- 1.1022337007522582
- 1.0949551558494568
- 1.1133612728118896
- 1.0734151577949524
- 1.0556747126579284
- 1.0698417162895202
- 1.0541161394119263
- 1.0416536927223206
- 1.07471519947052
- 1.0388707280158997
- 1.0365152621269227
- 1.0643233203887938
- 1.0400295090675353
- 1.0449376726150512
- 1.0372704458236695
- 1.0124466276168824
- 1.0248899483680725
- 1.0233373188972472
- 1.0323891019821168
- 1.0337952089309692
- 1.0343544697761535
- 1.014752869606018
- 1.0265256905555724
- 1.0184949326515198
- 1.0257004523277282
- 1.0275955390930176
- 0.9988201820850372
- 1.028374561071396
- 1.0095594644546508
- 0.9792867302894592
- 1.012397747039795
- 0.9837611222267151
- 1.0047026872634888
- 1.0015823793411256
- 0.9799715483188629
- 0.9734502613544465
- 0.9733417248725891
- 0.9687605905532837
- 0.9768471729755401
- 0.9796167540550232
- 0.9701376509666443
- 0.9818255281448365
- 0.9813499331474305
- 0.9745465254783631
- 0.9804767942428589
- 0.9953302359580993
- 0.9762494850158692
- 0.991986916065216
- 0.9712866497039795
- 0.9567368972301483
- 0.9772954511642457
- 0.9510756695270538
- 0.945182591676712
- 0.9542827653884888
- 0.9761297845840454
- 0.9577322053909302
- 0.9679621005058289
- 0.95933513879776
- 0.9660454392433167
- 0.9542809987068176
- 0.9698373997211456
- 0.9663608574867248
- 0.9549971508979798
- 0.9472556161880493
- 0.9720669770240784
- 0.961702516078949
- 0.957076016664505
- 0.9556233525276184
- 0.9511166870594024
- 0.9615638792514801
- 0.9510570287704467
- 0.9792913627624512
- 0.9664897537231445
- 0.9697561943531037
train_accuracy:
- 0.088
- 0.12
- 0.151
- 0.147
- 0.162
- 0.161
- 0.179
- 0.17
- 0.198
- 0.217
- 0.225
- 0.23
- 0.239
- 0.241
- 0.239
- 0.256
- 0.254
- 0.248
- 0.259
- 0.264
- 0.227
- 0.291
- 0.278
- 0.274
- 0.288
- 0.303
- 0.291
- 0.29
- 0.296
- 0.314
- 0.338
- 0.296
- 0.319
- 0.309
- 0.343
- 0.342
- 0.257
- 0.305
- 0.31
- 0.278
- 0.317
- 0.373
- 0.328
- 0.339
- 0.329
- 0.343
- 0.339
- 0.332
- 0.344
- 0.281
- 0.342
- 0.333
- 0.342
- 0.337
- 0.338
- 0.372
- 0.349
- 0.39
- 0.343
- 0.337
- 0.297
- 0.355
- 0.379
- 0.309
- 0.374
- 0.359
- 0.394
- 0.317
- 0.361
- 0.382
- 0.37
- 0.383
- 0.392
- 0.382
- 0.384
- 0.374
- 0.371
- 0.326
- 0.429
- 0.41
- 0.375
- 0.386
- 0.405
- 0.409
- 0.375
- 0.328
- 0.394
- 0.379
- 0.423
- 0.428
- 0.373
- 0.391
- 0.393
- 0.402
- 0.389
- 0.382
- 0.425
- 0.417
- 0.38
- 0.39
train_loss:
- 4.258
- 3.783
- 3.589
- 3.138
- 3.261
- 2.832
- 3.182
- 3.139
- 2.99
- 2.88
- 2.873
- 2.641
- 2.52
- 2.464
- 2.285
- 2.69
- 2.672
- 2.249
- 2.25
- 1.813
- 2.461
- 2.406
- 1.684
- 2.25
- 1.442
- 2.263
- 2.073
- 1.899
- 1.885
- 2.187
- 2.016
- 1.623
- 1.935
- 2.254
- 1.728
- 1.645
- 1.973
- 1.436
- 1.039
- 1.612
- 1.438
- 1.483
- 1.59
- 1.053
- 0.713
- 1.398
- 0.963
- 1.765
- 0.858
- 1.431
- 1.63
- 1.839
- 1.253
- 0.923
- 1.317
- 1.362
- 0.862
- 1.311
- 1.665
- 1.066
- 1.262
- 1.335
- 0.932
- 0.888
- 1.083
- 1.024
- 0.698
- 0.735
- 0.758
- 0.943
- 1.017
- 1.418
- 0.629
- 0.922
- 0.908
- 0.736
- 1.119
- 0.713
- 1.016
- 0.53
- 0.792
- 0.56
- 0.682
- 0.397
- 0.907
- 0.571
- 0.892
- 0.765
- 0.824
- 0.372
- 0.635
- 0.489
- 0.868
- 0.701
- 0.381
- 0.206
- 0.609
- 0.322
- 0.244
- 0.615
unequal: 0
verbose: 1
