avg_train_accuracy: 0.407
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0928
- 0.1258
- 0.1527
- 0.1596
- 0.1795
- 0.1918
- 0.2078
- 0.2113
- 0.2215
- 0.2279
- 0.2313
- 0.2389
- 0.2453
- 0.2527
- 0.2505
- 0.2668
- 0.2722
- 0.2729
- 0.2705
- 0.2795
- 0.2803
- 0.2835
- 0.2804
- 0.2825
- 0.2984
- 0.3055
- 0.3126
- 0.2958
- 0.3109
- 0.3104
- 0.3217
- 0.3179
- 0.326
- 0.3149
- 0.3142
- 0.312
- 0.3153
- 0.3183
- 0.3351
- 0.3393
- 0.3394
- 0.3446
- 0.3392
- 0.3502
- 0.3549
- 0.3564
- 0.3536
- 0.345
- 0.3472
- 0.3525
- 0.3487
- 0.3502
- 0.353
- 0.3344
- 0.3635
- 0.3593
- 0.3609
- 0.3656
- 0.3645
- 0.369
- 0.3682
- 0.3732
- 0.3749
- 0.3731
- 0.3692
- 0.3795
- 0.3812
- 0.3851
- 0.3878
- 0.3836
- 0.3884
- 0.3828
- 0.3893
- 0.3815
- 0.3941
- 0.3886
- 0.3909
- 0.389
- 0.3946
- 0.3887
- 0.3826
- 0.3979
- 0.3937
- 0.3835
- 0.3886
- 0.3975
- 0.3934
- 0.3997
- 0.3906
- 0.3975
- 0.3874
- 0.4078
- 0.404
- 0.4005
- 0.4037
- 0.3986
- 0.4063
- 0.402
- 0.4027
- 0.403
test_loss_list:
- 1.641773180961609
- 1.5554614973068237
- 1.4910996890068053
- 1.4659191942214966
- 1.4110222578048706
- 1.3787599873542786
- 1.3481103324890136
- 1.3351247692108155
- 1.3179475331306458
- 1.2904749202728272
- 1.2839537906646727
- 1.2618180179595948
- 1.2590653610229492
- 1.2315551829338074
- 1.2418117022514343
- 1.2169396471977234
- 1.1976503396034242
- 1.1918773937225342
- 1.197497615814209
- 1.1781229734420777
- 1.1796624851226807
- 1.1777994084358214
- 1.182678906917572
- 1.1804699778556824
- 1.144122622013092
- 1.126029407978058
- 1.1100004482269288
- 1.1440566349029542
- 1.110390067100525
- 1.113693084716797
- 1.0879289960861207
- 1.1003313207626342
- 1.0784977066516876
- 1.1023274374008178
- 1.1116575407981872
- 1.122457526922226
- 1.0971270632743835
- 1.0946287024021149
- 1.060776376724243
- 1.0489069199562073
- 1.0548593258857728
- 1.0469779539108277
- 1.058486384153366
- 1.0410699439048767
- 1.0331125438213349
- 1.029054763317108
- 1.0395592641830445
- 1.0533845043182373
- 1.0520385026931762
- 1.0390791559219361
- 1.0600829362869262
- 1.0477335584163665
- 1.041022365093231
- 1.0911337327957153
- 1.0321391224861145
- 1.0441757977008819
- 1.0256869435310363
- 1.0162242186069488
- 1.0251834082603455
- 1.0155548858642578
- 1.022598501443863
- 1.0019076597690582
- 1.004006427526474
- 1.0190320992469788
- 1.0025564289093019
- 0.9941920495033264
- 0.990357836484909
- 0.9881952476501464
- 0.9879000329971314
- 0.9882632899284363
- 0.9870642113685608
- 1.0021636581420899
- 0.984092276096344
- 0.9888997030258179
- 0.9784042263031005
- 0.9885667753219605
- 0.9933589112758636
- 1.0005107140541076
- 0.9860337352752686
- 0.9979242706298828
- 0.9877681052684784
- 0.9842271792888642
- 0.9979903721809387
- 1.0068692970275879
- 0.9994164824485778
- 0.9928573393821716
- 0.9913873863220215
- 0.9782416081428528
- 1.0028834986686705
- 0.985395770072937
- 0.9967062079906464
- 0.9753422021865845
- 0.9776331496238708
- 0.991975588798523
- 0.989789047241211
- 0.9882107043266296
- 0.9848329615592957
- 0.9742926478385925
- 0.9807640814781189
- 0.9797109985351562
train_accuracy:
- 0.087
- 0.107
- 0.142
- 0.163
- 0.153
- 0.179
- 0.2
- 0.187
- 0.208
- 0.206
- 0.235
- 0.234
- 0.239
- 0.216
- 0.204
- 0.242
- 0.241
- 0.245
- 0.245
- 0.224
- 0.261
- 0.228
- 0.251
- 0.246
- 0.257
- 0.288
- 0.309
- 0.297
- 0.273
- 0.282
- 0.314
- 0.307
- 0.32
- 0.307
- 0.294
- 0.311
- 0.283
- 0.298
- 0.309
- 0.283
- 0.28
- 0.332
- 0.316
- 0.328
- 0.345
- 0.318
- 0.336
- 0.302
- 0.34
- 0.342
- 0.334
- 0.336
- 0.326
- 0.3
- 0.354
- 0.337
- 0.326
- 0.353
- 0.335
- 0.344
- 0.352
- 0.369
- 0.371
- 0.342
- 0.374
- 0.316
- 0.359
- 0.359
- 0.372
- 0.378
- 0.354
- 0.351
- 0.387
- 0.32
- 0.379
- 0.354
- 0.388
- 0.389
- 0.38
- 0.386
- 0.372
- 0.403
- 0.388
- 0.347
- 0.362
- 0.363
- 0.362
- 0.392
- 0.37
- 0.371
- 0.396
- 0.405
- 0.375
- 0.398
- 0.369
- 0.405
- 0.378
- 0.411
- 0.356
- 0.407
train_loss:
- 4.195
- 3.482
- 3.579
- 3.102
- 3.346
- 3.262
- 3.13
- 2.83
- 2.744
- 3.001
- 2.374
- 2.907
- 2.09
- 2.66
- 2.201
- 2.572
- 2.46
- 2.165
- 1.787
- 2.074
- 1.915
- 1.711
- 1.699
- 1.307
- 2.528
- 2.358
- 2.455
- 2.327
- 1.352
- 1.653
- 2.058
- 1.918
- 1.656
- 1.27
- 1.025
- 0.846
- 2.073
- 1.99
- 2.113
- 1.645
- 1.122
- 1.029
- 1.574
- 1.88
- 1.443
- 1.204
- 1.043
- 0.876
- 0.828
- 0.913
- 0.689
- 1.331
- 2.004
- 1.314
- 0.732
- 0.413
- 1.665
- 0.809
- 1.266
- 1.572
- 0.96
- 1.571
- 0.601
- 0.865
- 1.638
- 1.166
- 1.12
- 0.693
- 0.459
- 1.128
- 1.297
- 0.746
- 1.066
- 0.943
- 0.572
- 0.708
- 0.443
- 0.753
- 0.421
- 0.495
- 1.279
- 0.399
- 0.93
- 0.648
- 0.345
- 0.768
- 1.149
- 0.435
- 0.665
- 0.893
- 0.998
- 0.359
- 0.554
- 0.625
- 0.641
- 0.775
- 0.598
- 0.518
- 0.743
- 0.356
unequal: 0
verbose: 1
