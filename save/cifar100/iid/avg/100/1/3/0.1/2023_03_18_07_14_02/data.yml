avg_train_accuracy: 0.431
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0851
- 0.1262
- 0.1459
- 0.1579
- 0.1674
- 0.1721
- 0.1807
- 0.2005
- 0.215
- 0.2222
- 0.2413
- 0.2496
- 0.2569
- 0.2618
- 0.2675
- 0.2671
- 0.2726
- 0.2776
- 0.2845
- 0.2912
- 0.2936
- 0.3022
- 0.3133
- 0.3068
- 0.3158
- 0.3206
- 0.3213
- 0.3261
- 0.3277
- 0.3242
- 0.3233
- 0.3314
- 0.3408
- 0.3456
- 0.3539
- 0.3412
- 0.3358
- 0.3478
- 0.3525
- 0.3571
- 0.3554
- 0.3591
- 0.3576
- 0.3662
- 0.3567
- 0.3639
- 0.3646
- 0.3603
- 0.3618
- 0.3591
- 0.3668
- 0.3706
- 0.3824
- 0.3783
- 0.382
- 0.3698
- 0.3795
- 0.3749
- 0.3842
- 0.3763
- 0.3728
- 0.3871
- 0.3867
- 0.3876
- 0.3767
- 0.3901
- 0.3807
- 0.3981
- 0.3923
- 0.3899
- 0.3979
- 0.3848
- 0.394
- 0.3925
- 0.3851
- 0.3942
- 0.399
- 0.3933
- 0.3894
- 0.3941
- 0.3963
- 0.3998
- 0.3909
- 0.4032
- 0.3903
- 0.4103
- 0.3968
- 0.4072
- 0.411
- 0.4058
- 0.4024
- 0.4131
- 0.407
- 0.4054
- 0.4064
- 0.4027
- 0.4128
- 0.4023
- 0.416
- 0.4195
test_loss_list:
- 1.6618683671951293
- 1.5514776253700255
- 1.4910345911979674
- 1.4579713201522828
- 1.4425311803817749
- 1.428071255683899
- 1.4182535266876222
- 1.3647303867340088
- 1.3222385740280151
- 1.3093116331100463
- 1.2785478377342223
- 1.2608337378501893
- 1.2353469681739808
- 1.2199686455726624
- 1.2078115558624267
- 1.210861804485321
- 1.1989589405059815
- 1.1712342977523804
- 1.1526945400238038
- 1.1383842015266419
- 1.1506517696380616
- 1.1269229602813722
- 1.1036685466766358
- 1.1216476249694824
- 1.0885304737091064
- 1.0777296924591064
- 1.0875517654418945
- 1.0783201360702515
- 1.0791653823852538
- 1.0824630165100098
- 1.0736526846885681
- 1.062022864818573
- 1.0491718363761902
- 1.0345188093185425
- 1.025947895050049
- 1.053616282939911
- 1.0571560645103455
- 1.039673192501068
- 1.0358513188362122
- 1.017918014526367
- 1.0169386506080627
- 1.0070762825012207
- 1.0103631711006165
- 1.0091848349571229
- 1.0249680972099304
- 1.0144588589668273
- 1.0110731673240663
- 1.0227350330352782
- 1.0271773409843445
- 1.0203702163696289
- 0.9998771357536316
- 0.9910470914840698
- 0.9905762767791748
- 0.9944290447235108
- 0.9997394609451294
- 1.0109146213531495
- 0.9917887008190155
- 1.0015078949928284
- 0.9984674406051636
- 1.0102151536941528
- 1.0101036643981933
- 0.9821042370796204
- 0.9898181962966919
- 0.9857974290847779
- 1.0079977452754973
- 0.9721314322948456
- 0.9894067001342773
- 0.9667976117134094
- 0.9768825435638427
- 0.9798374652862549
- 0.9768251371383667
- 0.992067312002182
- 0.9754248571395874
- 0.99072709441185
- 0.9945045673847198
- 0.9837913978099823
- 0.9719160580635071
- 0.9881645560264587
- 0.9927541661262512
- 0.9849597048759461
- 0.9935704982280731
- 0.9845703256130218
- 1.011137020587921
- 0.9884220135211944
- 1.0076332211494445
- 0.9743991971015931
- 0.9930851936340332
- 0.9820419788360596
- 0.971422884464264
- 0.9842224109172821
- 0.9857420361042023
- 0.9627914452552795
- 0.982761698961258
- 0.988591194152832
- 0.9866819548606872
- 1.001854965686798
- 0.9805902886390686
- 0.9868121576309205
- 0.9603945899009705
- 0.954207227230072
train_accuracy:
- 0.088
- 0.124
- 0.132
- 0.155
- 0.155
- 0.168
- 0.166
- 0.172
- 0.218
- 0.189
- 0.224
- 0.221
- 0.216
- 0.227
- 0.262
- 0.263
- 0.238
- 0.256
- 0.289
- 0.315
- 0.301
- 0.271
- 0.288
- 0.275
- 0.309
- 0.3
- 0.319
- 0.294
- 0.305
- 0.297
- 0.338
- 0.3
- 0.287
- 0.317
- 0.37
- 0.295
- 0.3
- 0.331
- 0.305
- 0.35
- 0.36
- 0.351
- 0.338
- 0.354
- 0.353
- 0.333
- 0.368
- 0.321
- 0.325
- 0.333
- 0.379
- 0.346
- 0.328
- 0.38
- 0.329
- 0.366
- 0.382
- 0.387
- 0.329
- 0.38
- 0.331
- 0.389
- 0.352
- 0.393
- 0.346
- 0.393
- 0.352
- 0.391
- 0.358
- 0.396
- 0.405
- 0.381
- 0.407
- 0.343
- 0.387
- 0.361
- 0.415
- 0.342
- 0.406
- 0.355
- 0.413
- 0.408
- 0.411
- 0.395
- 0.363
- 0.409
- 0.377
- 0.37
- 0.416
- 0.373
- 0.401
- 0.421
- 0.415
- 0.378
- 0.382
- 0.378
- 0.382
- 0.382
- 0.427
- 0.431
train_loss:
- 4.237
- 3.724
- 3.342
- 2.934
- 2.61
- 2.336
- 2.084
- 3.155
- 3.026
- 2.648
- 2.996
- 2.896
- 2.78
- 2.347
- 2.754
- 2.251
- 2.038
- 2.649
- 2.469
- 2.556
- 2.016
- 2.363
- 2.246
- 1.772
- 2.266
- 2.008
- 1.822
- 1.737
- 1.668
- 1.378
- 1.983
- 2.184
- 2.088
- 1.948
- 1.839
- 1.26
- 0.875
- 1.649
- 1.745
- 1.498
- 1.624
- 1.342
- 1.795
- 1.054
- 0.749
- 1.84
- 1.376
- 0.996
- 0.625
- 1.565
- 1.119
- 1.61
- 1.468
- 0.9
- 1.056
- 0.705
- 0.913
- 0.555
- 0.872
- 1.502
- 0.763
- 0.725
- 1.431
- 0.591
- 1.269
- 0.451
- 1.281
- 0.619
- 0.604
- 0.398
- 0.437
- 0.92
- 0.345
- 0.462
- 1.212
- 0.362
- 0.318
- 0.26
- 1.133
- 0.259
- 0.694
- 0.504
- 0.503
- 0.33
- 1.149
- 0.281
- 0.815
- 0.303
- 0.226
- 0.756
- 0.945
- 0.24
- 0.543
- 0.596
- 0.639
- 0.316
- 0.293
- 1.355
- 0.411
- 0.234
unequal: 0
verbose: 1
