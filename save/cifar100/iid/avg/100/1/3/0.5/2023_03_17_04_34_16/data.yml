avg_train_accuracy: 0.404
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1072
- 0.1479
- 0.1691
- 0.1909
- 0.2088
- 0.2218
- 0.2388
- 0.245
- 0.2594
- 0.2675
- 0.2745
- 0.2816
- 0.2911
- 0.2988
- 0.3023
- 0.3073
- 0.3194
- 0.3231
- 0.3267
- 0.3285
- 0.3339
- 0.3414
- 0.3462
- 0.3528
- 0.3531
- 0.36
- 0.365
- 0.3625
- 0.3689
- 0.373
- 0.3743
- 0.3764
- 0.3806
- 0.3801
- 0.3856
- 0.3909
- 0.3915
- 0.3937
- 0.3925
- 0.3951
- 0.3972
- 0.3987
- 0.3994
- 0.4058
- 0.4082
- 0.4081
- 0.4058
- 0.4102
- 0.4128
- 0.41
- 0.4149
- 0.408
- 0.4149
- 0.414
- 0.4173
- 0.4176
- 0.4204
- 0.4205
- 0.4221
- 0.4218
- 0.423
- 0.4258
- 0.4257
- 0.4215
- 0.4269
- 0.4256
- 0.4309
- 0.4307
- 0.4326
- 0.429
- 0.4297
- 0.4331
- 0.4298
- 0.429
- 0.4293
- 0.4316
- 0.4373
- 0.4314
- 0.4329
- 0.4356
- 0.4363
- 0.4351
- 0.4356
- 0.4324
- 0.436
- 0.4354
- 0.4367
- 0.4364
- 0.4353
- 0.439
- 0.4362
- 0.4398
- 0.4377
- 0.44
- 0.4405
- 0.4381
- 0.4408
- 0.4424
- 0.442
- 0.4389
test_loss_list:
- 1.6239493346214295
- 1.5049538016319275
- 1.4381140422821046
- 1.392042260169983
- 1.354170753955841
- 1.3244259834289551
- 1.2916751670837403
- 1.267217106819153
- 1.2416304063796997
- 1.2201610708236694
- 1.2024369525909424
- 1.1822662901878358
- 1.1654633593559265
- 1.1491946601867675
- 1.135347125530243
- 1.1208971738815308
- 1.1014090704917907
- 1.0883524537086486
- 1.0815483045578003
- 1.0693341279029847
- 1.0581053519248962
- 1.0447135138511658
- 1.0391647601127625
- 1.0282157373428344
- 1.0254504251480103
- 1.013342125415802
- 1.0078025317192079
- 1.009407994747162
- 0.9957524967193604
- 0.9861645817756652
- 0.9854782772064209
- 0.9859492897987365
- 0.97625821352005
- 0.976524555683136
- 0.9669914412498474
- 0.9613860845565796
- 0.9585488486289978
- 0.9528828644752503
- 0.9545143103599548
- 0.9529843831062317
- 0.9497902345657349
- 0.9460539984703064
- 0.9473298025131226
- 0.9360483884811401
- 0.9377497386932373
- 0.9375588798522949
- 0.9353036236763
- 0.9319941711425781
- 0.931085216999054
- 0.9317279982566834
- 0.927447144985199
- 0.9341142201423644
- 0.9281007027626038
- 0.9254887294769287
- 0.9239191079139709
- 0.9245891237258911
- 0.9225599265098572
- 0.9184805512428283
- 0.9180502080917359
- 0.919641239643097
- 0.9172650599479675
- 0.9200743627548218
- 0.9146979677677155
- 0.9259872102737426
- 0.913819237947464
- 0.9185298991203308
- 0.9131849837303162
- 0.9139165687561035
- 0.9139826655387878
- 0.9160111594200134
- 0.91761510014534
- 0.9168278014659882
- 0.9205774307250977
- 0.9176049375534058
- 0.9176379632949829
- 0.915009298324585
- 0.913141303062439
- 0.9267102289199829
- 0.9158834981918335
- 0.9141607987880707
- 0.9156827855110169
- 0.9167907047271728
- 0.9182958161830902
- 0.9196140551567078
- 0.9214928007125854
- 0.9199706315994263
- 0.9205562710762024
- 0.9213734292984008
- 0.9284249520301819
- 0.920166825056076
- 0.9231695783138275
- 0.9248077845573426
- 0.927426563501358
- 0.9250711989402771
- 0.923501718044281
- 0.9266742897033692
- 0.925865204334259
- 0.9260260879993438
- 0.9250669610500336
- 0.9292803287506104
train_accuracy:
- 0.087
- 0.136
- 0.142
- 0.18
- 0.188
- 0.205
- 0.228
- 0.24
- 0.214
- 0.244
- 0.255
- 0.247
- 0.253
- 0.28
- 0.283
- 0.273
- 0.28
- 0.301
- 0.321
- 0.316
- 0.315
- 0.318
- 0.305
- 0.311
- 0.295
- 0.336
- 0.352
- 0.316
- 0.341
- 0.342
- 0.346
- 0.355
- 0.353
- 0.35
- 0.353
- 0.367
- 0.341
- 0.367
- 0.37
- 0.358
- 0.373
- 0.335
- 0.375
- 0.373
- 0.382
- 0.356
- 0.386
- 0.391
- 0.388
- 0.389
- 0.384
- 0.385
- 0.405
- 0.376
- 0.384
- 0.386
- 0.381
- 0.398
- 0.406
- 0.4
- 0.405
- 0.386
- 0.404
- 0.369
- 0.397
- 0.37
- 0.4
- 0.399
- 0.408
- 0.41
- 0.421
- 0.401
- 0.408
- 0.409
- 0.404
- 0.41
- 0.387
- 0.399
- 0.422
- 0.383
- 0.416
- 0.411
- 0.418
- 0.42
- 0.386
- 0.429
- 0.403
- 0.413
- 0.421
- 0.417
- 0.444
- 0.432
- 0.434
- 0.384
- 0.413
- 0.416
- 0.41
- 0.408
- 0.426
- 0.404
train_loss:
- 4.193
- 3.696
- 3.445
- 3.298
- 3.158
- 3.059
- 2.957
- 2.855
- 2.765
- 2.717
- 2.609
- 2.57
- 2.45
- 2.423
- 2.342
- 2.282
- 2.297
- 2.147
- 2.117
- 2.007
- 1.984
- 2.006
- 1.918
- 1.839
- 1.786
- 1.824
- 1.699
- 1.693
- 1.645
- 1.625
- 1.525
- 1.561
- 1.502
- 1.434
- 1.47
- 1.375
- 1.336
- 1.281
- 1.246
- 1.232
- 1.151
- 1.209
- 1.076
- 1.264
- 1.135
- 1.132
- 0.997
- 1.051
- 0.944
- 0.907
- 0.929
- 0.935
- 0.819
- 0.932
- 0.948
- 0.831
- 0.861
- 0.822
- 0.86
- 0.781
- 0.736
- 0.709
- 0.721
- 0.662
- 0.718
- 0.705
- 0.664
- 0.626
- 0.596
- 0.54
- 0.579
- 0.514
- 0.557
- 0.489
- 0.568
- 0.458
- 0.545
- 0.481
- 0.463
- 0.484
- 0.473
- 0.419
- 0.436
- 0.404
- 0.378
- 0.398
- 0.417
- 0.392
- 0.347
- 0.364
- 0.333
- 0.317
- 0.303
- 0.33
- 0.361
- 0.309
- 0.324
- 0.29
- 0.298
- 0.282
unequal: 0
verbose: 1
