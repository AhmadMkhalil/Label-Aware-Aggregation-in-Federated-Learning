avg_train_accuracy: 0.389
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0961
- 0.1367
- 0.1616
- 0.185
- 0.2041
- 0.2183
- 0.2291
- 0.2423
- 0.2496
- 0.2586
- 0.2666
- 0.2784
- 0.2823
- 0.2912
- 0.296
- 0.303
- 0.31
- 0.3146
- 0.3163
- 0.327
- 0.3296
- 0.3324
- 0.3349
- 0.3389
- 0.3432
- 0.35
- 0.3521
- 0.352
- 0.362
- 0.3598
- 0.3638
- 0.3666
- 0.3677
- 0.371
- 0.3765
- 0.38
- 0.3767
- 0.3823
- 0.3846
- 0.3877
- 0.3874
- 0.3877
- 0.392
- 0.3892
- 0.3925
- 0.3959
- 0.3935
- 0.3974
- 0.3952
- 0.3994
- 0.3995
- 0.4032
- 0.406
- 0.4036
- 0.4073
- 0.4094
- 0.4079
- 0.41
- 0.4089
- 0.4131
- 0.4088
- 0.4158
- 0.4137
- 0.4112
- 0.4135
- 0.4209
- 0.4191
- 0.4148
- 0.417
- 0.423
- 0.4211
- 0.4203
- 0.4224
- 0.4207
- 0.4213
- 0.4171
- 0.4205
- 0.4237
- 0.4238
- 0.4239
- 0.4257
- 0.4225
- 0.425
- 0.4249
- 0.4242
- 0.4266
- 0.4292
- 0.4282
- 0.4291
- 0.427
- 0.4269
- 0.4303
- 0.4292
- 0.4315
- 0.4308
- 0.4323
- 0.4313
- 0.4298
- 0.4324
- 0.4311
test_loss_list:
- 1.6425304746627807
- 1.5247001957893371
- 1.4551323199272155
- 1.4052111053466796
- 1.364878454208374
- 1.32907114982605
- 1.3024825406074525
- 1.2752718329429626
- 1.2524173951148987
- 1.232454309463501
- 1.2126847791671753
- 1.1940034747123718
- 1.1797755646705628
- 1.1650129652023316
- 1.1502130722999573
- 1.1353593206405639
- 1.1223217415809632
- 1.1135907554626465
- 1.1030873894691466
- 1.0874199104309081
- 1.0835755014419555
- 1.0724172925949096
- 1.0597667789459229
- 1.0602070379257202
- 1.0444757103919984
- 1.0364702725410462
- 1.0291772699356079
- 1.027876877784729
- 1.0208031153678894
- 1.0158395195007324
- 1.0084621930122375
- 1.0028010392189026
- 0.9975167918205261
- 0.9904689455032348
- 0.9831630682945252
- 0.9820455265045166
- 0.9852342224121093
- 0.975656909942627
- 0.9716274881362915
- 0.9708316016197205
- 0.9685717630386352
- 0.9676946520805358
- 0.9655354738235473
- 0.9600315189361572
- 0.9579108500480652
- 0.9500066733360291
- 0.9543067169189453
- 0.9509528970718384
- 0.9576977849006653
- 0.949762942790985
- 0.9512729716300964
- 0.943669273853302
- 0.9414047646522522
- 0.9432335591316223
- 0.9387154006958007
- 0.9356104683876038
- 0.9407963681221009
- 0.9436482739448547
- 0.9391929316520691
- 0.9330279684066772
- 0.9383803129196167
- 0.9275951385498047
- 0.9328333902359008
- 0.9344261145591736
- 0.9355791807174683
- 0.9353996920585632
- 0.9293170213699341
- 0.9352325963973999
- 0.9321397280693055
- 0.9289588809013367
- 0.9317427563667298
- 0.9325158071517944
- 0.9308580446243286
- 0.9320381021499634
- 0.9339207994937897
- 0.9384169435501098
- 0.9323530328273774
- 0.933488347530365
- 0.9314051032066345
- 0.9362926483154297
- 0.9372049760818482
- 0.9403012883663178
- 0.9440715980529785
- 0.9420041370391846
- 0.9409379720687866
- 0.9337486386299133
- 0.9428595733642579
- 0.9418180537223816
- 0.9430587530136109
- 0.9348384988307953
- 0.9439158105850219
- 0.9404680609703064
- 0.9445535778999329
- 0.9429230189323425
- 0.9419705080986023
- 0.9453149318695069
- 0.9493132972717285
- 0.9491170310974121
- 0.9452992749214172
- 0.9517312455177307
train_accuracy:
- 0.084
- 0.113
- 0.129
- 0.149
- 0.184
- 0.192
- 0.192
- 0.205
- 0.207
- 0.27
- 0.239
- 0.273
- 0.233
- 0.297
- 0.272
- 0.28
- 0.271
- 0.275
- 0.296
- 0.339
- 0.29
- 0.302
- 0.323
- 0.309
- 0.308
- 0.318
- 0.319
- 0.305
- 0.29
- 0.337
- 0.309
- 0.348
- 0.325
- 0.339
- 0.327
- 0.399
- 0.304
- 0.348
- 0.399
- 0.342
- 0.329
- 0.32
- 0.362
- 0.332
- 0.376
- 0.319
- 0.356
- 0.363
- 0.342
- 0.359
- 0.326
- 0.386
- 0.356
- 0.391
- 0.369
- 0.362
- 0.365
- 0.332
- 0.396
- 0.382
- 0.368
- 0.379
- 0.381
- 0.382
- 0.352
- 0.404
- 0.394
- 0.391
- 0.354
- 0.386
- 0.394
- 0.4
- 0.388
- 0.385
- 0.376
- 0.37
- 0.362
- 0.349
- 0.389
- 0.379
- 0.39
- 0.387
- 0.347
- 0.388
- 0.391
- 0.4
- 0.378
- 0.347
- 0.337
- 0.369
- 0.421
- 0.349
- 0.408
- 0.401
- 0.381
- 0.356
- 0.402
- 0.402
- 0.393
- 0.389
train_loss:
- 4.231
- 3.748
- 3.486
- 3.337
- 3.203
- 3.095
- 2.966
- 2.909
- 2.807
- 2.759
- 2.646
- 2.603
- 2.504
- 2.429
- 2.387
- 2.372
- 2.247
- 2.193
- 2.159
- 2.116
- 2.044
- 2.036
- 1.961
- 1.922
- 1.9
- 1.786
- 1.745
- 1.689
- 1.703
- 1.633
- 1.678
- 1.572
- 1.58
- 1.512
- 1.475
- 1.46
- 1.408
- 1.381
- 1.315
- 1.27
- 1.205
- 1.229
- 1.137
- 1.277
- 1.16
- 1.145
- 1.046
- 1.104
- 0.995
- 1.028
- 0.976
- 0.939
- 0.991
- 0.889
- 0.906
- 0.923
- 0.899
- 0.875
- 0.798
- 0.855
- 0.76
- 0.771
- 0.706
- 0.755
- 0.696
- 0.678
- 0.662
- 0.633
- 0.611
- 0.631
- 0.584
- 0.586
- 0.569
- 0.518
- 0.51
- 0.55
- 0.468
- 0.506
- 0.475
- 0.444
- 0.438
- 0.384
- 0.387
- 0.442
- 0.415
- 0.469
- 0.356
- 0.361
- 0.381
- 0.406
- 0.352
- 0.357
- 0.342
- 0.335
- 0.354
- 0.316
- 0.287
- 0.294
- 0.366
- 0.328
unequal: 0
verbose: 1
