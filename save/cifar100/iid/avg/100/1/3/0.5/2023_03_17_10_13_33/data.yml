avg_train_accuracy: 0.411
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0976
- 0.1342
- 0.1591
- 0.1814
- 0.1966
- 0.2119
- 0.2266
- 0.2344
- 0.2446
- 0.2585
- 0.262
- 0.2723
- 0.2785
- 0.2833
- 0.2947
- 0.3006
- 0.3038
- 0.3108
- 0.3122
- 0.3213
- 0.3278
- 0.3301
- 0.3373
- 0.3415
- 0.3409
- 0.3431
- 0.3463
- 0.3499
- 0.3565
- 0.3582
- 0.3625
- 0.3615
- 0.367
- 0.3723
- 0.3717
- 0.3718
- 0.3792
- 0.3808
- 0.3775
- 0.3809
- 0.3789
- 0.3806
- 0.3873
- 0.3864
- 0.3865
- 0.3918
- 0.3887
- 0.3871
- 0.389
- 0.391
- 0.3955
- 0.3971
- 0.3975
- 0.4002
- 0.4026
- 0.3997
- 0.4072
- 0.4021
- 0.4098
- 0.406
- 0.4073
- 0.4067
- 0.4066
- 0.4109
- 0.4089
- 0.4134
- 0.4084
- 0.41
- 0.4099
- 0.4116
- 0.4152
- 0.4107
- 0.4124
- 0.4187
- 0.4161
- 0.4116
- 0.4184
- 0.4199
- 0.4181
- 0.4166
- 0.418
- 0.4194
- 0.421
- 0.4198
- 0.4169
- 0.4166
- 0.4169
- 0.4212
- 0.4217
- 0.4184
- 0.4199
- 0.4193
- 0.423
- 0.4245
- 0.42
- 0.422
- 0.4198
- 0.422
- 0.422
- 0.4233
test_loss_list:
- 1.6447141647338868
- 1.5283063101768493
- 1.4600256037712098
- 1.4090142464637756
- 1.3710003542900084
- 1.3348771715164185
- 1.3038590836524964
- 1.2774464464187623
- 1.2550015711784364
- 1.2336370134353638
- 1.2137472081184386
- 1.1935626339912415
- 1.1792439126968384
- 1.1637658715248107
- 1.148843138217926
- 1.1336438822746278
- 1.1242924547195434
- 1.1104350233078002
- 1.0987910509109498
- 1.0863395524024964
- 1.0758528923988342
- 1.0686092925071717
- 1.0583416199684144
- 1.0504531359672546
- 1.0483773827552796
- 1.0433721375465392
- 1.0335814118385316
- 1.026129584312439
- 1.019374544620514
- 1.013544430732727
- 1.0065001559257507
- 1.0052971816062928
- 0.9997965121269226
- 0.9968010711669922
- 0.9864455318450928
- 0.9839591073989868
- 0.979735610485077
- 0.9774555897712708
- 0.9745545387268066
- 0.9718237948417664
- 0.9721041202545166
- 0.971274664402008
- 0.9632372999191284
- 0.9599626612663269
- 0.9552768325805664
- 0.9507049334049225
- 0.9552613306045532
- 0.9529329037666321
- 0.9540802359580993
- 0.9513198518753052
- 0.9450126695632934
- 0.9453249597549438
- 0.9439134132862091
- 0.9417228841781616
- 0.9384200251102448
- 0.9401484453678131
- 0.9359951901435852
- 0.9385325515270233
- 0.9336143863201142
- 0.9355521631240845
- 0.9371438026428223
- 0.9310365235805511
- 0.9381929016113282
- 0.9325644564628601
- 0.936030068397522
- 0.9341582906246185
- 0.932688661813736
- 0.9341861009597778
- 0.9350131630897522
- 0.9331527543067932
- 0.9316771876811981
- 0.9336919569969178
- 0.9336690878868104
- 0.9310692381858826
- 0.933567042350769
- 0.9364075601100922
- 0.9294024443626404
- 0.9380295836925506
- 0.9307589840888977
- 0.936895227432251
- 0.9362580382823944
- 0.9352577877044678
- 0.939243882894516
- 0.9394559645652771
- 0.9393972992897034
- 0.9384076309204101
- 0.9395999765396118
- 0.9400591421127319
- 0.9416649234294892
- 0.9428061759471893
- 0.9455187201499939
- 0.9434092807769775
- 0.943503452539444
- 0.941213880777359
- 0.9447181415557862
- 0.9457626461982727
- 0.9497466504573822
- 0.9487643027305603
- 0.9472472000122071
- 0.9411134088039398
train_accuracy:
- 0.106
- 0.119
- 0.135
- 0.191
- 0.168
- 0.172
- 0.176
- 0.218
- 0.22
- 0.253
- 0.258
- 0.25
- 0.241
- 0.258
- 0.278
- 0.244
- 0.323
- 0.259
- 0.306
- 0.319
- 0.32
- 0.299
- 0.299
- 0.338
- 0.317
- 0.326
- 0.338
- 0.318
- 0.345
- 0.349
- 0.354
- 0.355
- 0.357
- 0.327
- 0.373
- 0.374
- 0.339
- 0.338
- 0.361
- 0.334
- 0.374
- 0.355
- 0.353
- 0.407
- 0.366
- 0.383
- 0.405
- 0.354
- 0.374
- 0.35
- 0.353
- 0.388
- 0.378
- 0.386
- 0.373
- 0.376
- 0.419
- 0.397
- 0.402
- 0.38
- 0.378
- 0.41
- 0.384
- 0.387
- 0.401
- 0.376
- 0.411
- 0.384
- 0.386
- 0.377
- 0.409
- 0.412
- 0.394
- 0.4
- 0.378
- 0.393
- 0.389
- 0.413
- 0.382
- 0.419
- 0.384
- 0.384
- 0.411
- 0.405
- 0.381
- 0.377
- 0.395
- 0.412
- 0.4
- 0.414
- 0.42
- 0.398
- 0.415
- 0.414
- 0.413
- 0.39
- 0.419
- 0.388
- 0.45
- 0.411
train_loss:
- 4.248
- 3.727
- 3.487
- 3.323
- 3.176
- 3.064
- 3.008
- 2.887
- 2.79
- 2.737
- 2.664
- 2.587
- 2.467
- 2.453
- 2.397
- 2.327
- 2.218
- 2.183
- 2.164
- 2.145
- 2.086
- 1.978
- 1.932
- 1.91
- 1.835
- 1.8
- 1.69
- 1.741
- 1.652
- 1.634
- 1.685
- 1.524
- 1.484
- 1.472
- 1.546
- 1.471
- 1.367
- 1.348
- 1.322
- 1.371
- 1.261
- 1.198
- 1.234
- 1.251
- 1.189
- 1.168
- 1.07
- 1.033
- 1.001
- 0.977
- 1.031
- 1.0
- 0.934
- 0.902
- 0.917
- 0.941
- 0.835
- 0.779
- 0.825
- 0.804
- 0.817
- 0.786
- 0.744
- 0.677
- 0.692
- 0.654
- 0.697
- 0.641
- 0.581
- 0.583
- 0.615
- 0.553
- 0.552
- 0.578
- 0.531
- 0.518
- 0.541
- 0.458
- 0.487
- 0.469
- 0.429
- 0.439
- 0.412
- 0.437
- 0.418
- 0.423
- 0.39
- 0.383
- 0.352
- 0.354
- 0.347
- 0.349
- 0.306
- 0.33
- 0.337
- 0.323
- 0.3
- 0.274
- 0.305
- 0.332
unequal: 0
verbose: 1
