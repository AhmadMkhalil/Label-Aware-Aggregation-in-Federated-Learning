avg_train_accuracy: 0.41
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1
- 0.1402
- 0.1626
- 0.1821
- 0.2
- 0.2153
- 0.2312
- 0.2409
- 0.2516
- 0.2662
- 0.2716
- 0.277
- 0.2863
- 0.2914
- 0.301
- 0.3055
- 0.3158
- 0.3209
- 0.3279
- 0.3319
- 0.3361
- 0.3381
- 0.3437
- 0.3487
- 0.3499
- 0.3556
- 0.3601
- 0.3646
- 0.3701
- 0.3676
- 0.3747
- 0.3773
- 0.3751
- 0.3757
- 0.3838
- 0.3889
- 0.3921
- 0.3907
- 0.3901
- 0.396
- 0.3951
- 0.3991
- 0.3903
- 0.4015
- 0.4054
- 0.4032
- 0.405
- 0.4013
- 0.4087
- 0.4084
- 0.4134
- 0.4109
- 0.4124
- 0.4179
- 0.4172
- 0.4129
- 0.4166
- 0.4156
- 0.4182
- 0.4226
- 0.4181
- 0.4239
- 0.4214
- 0.4229
- 0.4226
- 0.4259
- 0.4274
- 0.4249
- 0.4258
- 0.4305
- 0.428
- 0.4282
- 0.4329
- 0.4305
- 0.4349
- 0.4301
- 0.4343
- 0.4337
- 0.435
- 0.4311
- 0.433
- 0.4354
- 0.4334
- 0.4336
- 0.4401
- 0.4385
- 0.4357
- 0.4332
- 0.4337
- 0.4359
- 0.4359
- 0.439
- 0.4377
- 0.4387
- 0.4385
- 0.4397
- 0.4377
- 0.4399
- 0.4407
- 0.442
test_loss_list:
- 1.6470781660079956
- 1.526343080997467
- 1.455103919506073
- 1.4060878825187684
- 1.3662775707244874
- 1.3294353151321412
- 1.2992195868492127
- 1.2706675791740418
- 1.2503385949134826
- 1.2212519788742064
- 1.2016551661491395
- 1.186179642677307
- 1.1684669375419616
- 1.153152256011963
- 1.1389146828651429
- 1.1263190412521362
- 1.109460048675537
- 1.0940204191207885
- 1.081227662563324
- 1.0708027482032776
- 1.0614081740379333
- 1.05537118434906
- 1.0456509900093078
- 1.0325831222534179
- 1.0279108667373658
- 1.0193283534049988
- 1.0127490663528442
- 1.0041830945014953
- 0.9988063693046569
- 0.99584965467453
- 0.9839970183372497
- 0.9821998023986817
- 0.9841905450820922
- 0.9794919800758362
- 0.9675239753723145
- 0.9608029270172119
- 0.9586128163337707
- 0.9597872066497802
- 0.9543664169311523
- 0.9498829007148742
- 0.947326717376709
- 0.9454797196388245
- 0.9507575917243958
- 0.9410509061813355
- 0.9369334673881531
- 0.9358780217170716
- 0.9344069266319275
- 0.9349696087837219
- 0.9301655125617981
- 0.9275451111793518
- 0.9239216995239258
- 0.9238642287254334
- 0.9269514274597168
- 0.9196512854099274
- 0.9213980460166931
- 0.9209516859054565
- 0.9190423178672791
- 0.9182892036437988
- 0.9139420104026794
- 0.9168545985221863
- 0.9187144184112549
- 0.9154999017715454
- 0.9152247703075409
- 0.9154579210281372
- 0.9178985476493835
- 0.9134272062778472
- 0.9134486603736878
- 0.9155409622192383
- 0.9122855734825134
- 0.9075608634948731
- 0.9128879570960998
- 0.9132678365707397
- 0.9067531871795654
- 0.9064501094818115
- 0.908072338104248
- 0.9124173641204834
- 0.9088926005363465
- 0.9083196425437927
- 0.9086647653579711
- 0.9160230422019958
- 0.9131591451168061
- 0.9120117056369782
- 0.9092773711681366
- 0.9198386073112488
- 0.9121866106987
- 0.9119427716732025
- 0.9134642970561981
- 0.9179012727737427
- 0.918286325931549
- 0.9171330857276917
- 0.9102552270889283
- 0.9125706124305725
- 0.9150838422775268
- 0.919329354763031
- 0.9170178604125977
- 0.9137625885009766
- 0.9198960614204407
- 0.9156946194171905
- 0.9167628002166748
- 0.9156336450576782
train_accuracy:
- 0.086
- 0.13
- 0.146
- 0.166
- 0.177
- 0.175
- 0.217
- 0.222
- 0.213
- 0.269
- 0.243
- 0.246
- 0.262
- 0.306
- 0.268
- 0.293
- 0.286
- 0.317
- 0.341
- 0.35
- 0.312
- 0.318
- 0.308
- 0.317
- 0.342
- 0.331
- 0.328
- 0.381
- 0.348
- 0.325
- 0.388
- 0.336
- 0.337
- 0.349
- 0.38
- 0.403
- 0.368
- 0.358
- 0.353
- 0.383
- 0.36
- 0.36
- 0.412
- 0.362
- 0.393
- 0.417
- 0.384
- 0.385
- 0.37
- 0.379
- 0.372
- 0.427
- 0.387
- 0.381
- 0.386
- 0.368
- 0.382
- 0.384
- 0.392
- 0.39
- 0.386
- 0.377
- 0.385
- 0.399
- 0.386
- 0.405
- 0.386
- 0.417
- 0.388
- 0.393
- 0.403
- 0.443
- 0.402
- 0.391
- 0.395
- 0.398
- 0.403
- 0.397
- 0.408
- 0.402
- 0.4
- 0.418
- 0.412
- 0.394
- 0.408
- 0.444
- 0.41
- 0.415
- 0.404
- 0.404
- 0.398
- 0.41
- 0.416
- 0.398
- 0.411
- 0.409
- 0.42
- 0.452
- 0.408
- 0.41
train_loss:
- 4.233
- 3.744
- 3.491
- 3.297
- 3.202
- 3.095
- 2.976
- 2.877
- 2.734
- 2.765
- 2.628
- 2.522
- 2.453
- 2.399
- 2.318
- 2.289
- 2.283
- 2.218
- 2.167
- 2.048
- 1.997
- 1.908
- 1.864
- 1.885
- 1.838
- 1.784
- 1.728
- 1.692
- 1.653
- 1.576
- 1.694
- 1.497
- 1.43
- 1.478
- 1.529
- 1.416
- 1.356
- 1.29
- 1.232
- 1.343
- 1.314
- 1.142
- 1.232
- 1.166
- 1.136
- 1.099
- 1.054
- 1.102
- 0.958
- 0.989
- 1.002
- 0.949
- 0.899
- 0.934
- 0.819
- 0.863
- 0.843
- 0.8
- 0.842
- 0.76
- 0.658
- 0.727
- 0.705
- 0.683
- 0.587
- 0.659
- 0.62
- 0.655
- 0.605
- 0.667
- 0.536
- 0.596
- 0.601
- 0.57
- 0.532
- 0.495
- 0.552
- 0.491
- 0.494
- 0.429
- 0.46
- 0.433
- 0.462
- 0.405
- 0.427
- 0.373
- 0.345
- 0.37
- 0.341
- 0.35
- 0.408
- 0.37
- 0.333
- 0.349
- 0.318
- 0.349
- 0.29
- 0.291
- 0.317
- 0.301
unequal: 0
verbose: 1
