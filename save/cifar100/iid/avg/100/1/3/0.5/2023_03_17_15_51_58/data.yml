avg_train_accuracy: 0.413
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.093
- 0.1356
- 0.1635
- 0.1869
- 0.2055
- 0.2222
- 0.2297
- 0.2446
- 0.2544
- 0.2625
- 0.2702
- 0.2844
- 0.2897
- 0.2993
- 0.3079
- 0.3083
- 0.3184
- 0.3252
- 0.3258
- 0.3336
- 0.3401
- 0.3468
- 0.3492
- 0.3501
- 0.3547
- 0.3584
- 0.3593
- 0.3634
- 0.3617
- 0.3699
- 0.3767
- 0.3753
- 0.3799
- 0.3799
- 0.3817
- 0.3865
- 0.3835
- 0.3868
- 0.3934
- 0.3958
- 0.3953
- 0.3976
- 0.3986
- 0.4038
- 0.4046
- 0.4042
- 0.4061
- 0.408
- 0.4082
- 0.4117
- 0.4111
- 0.4111
- 0.4134
- 0.4138
- 0.4146
- 0.416
- 0.4133
- 0.416
- 0.4171
- 0.4164
- 0.4242
- 0.4204
- 0.4233
- 0.4209
- 0.4214
- 0.4258
- 0.4244
- 0.422
- 0.4257
- 0.4269
- 0.4308
- 0.4281
- 0.4266
- 0.4296
- 0.4294
- 0.4266
- 0.4325
- 0.4339
- 0.4359
- 0.4322
- 0.4303
- 0.4344
- 0.4349
- 0.4337
- 0.4332
- 0.4359
- 0.4334
- 0.4382
- 0.4377
- 0.4354
- 0.4362
- 0.438
- 0.4387
- 0.4391
- 0.4344
- 0.4356
- 0.4382
- 0.4366
- 0.4393
- 0.4381
test_loss_list:
- 1.6585139989852906
- 1.5352868437767029
- 1.4575289630889892
- 1.4061121129989624
- 1.3653038215637208
- 1.3297530317306518
- 1.301760036945343
- 1.2707950806617736
- 1.2459289026260376
- 1.2246707582473755
- 1.2063471055030823
- 1.1821529269218445
- 1.167127788066864
- 1.1486652207374572
- 1.1310155081748963
- 1.1178183603286742
- 1.1039104628562928
- 1.0899832367897033
- 1.079327211380005
- 1.0673916125297547
- 1.0546450424194336
- 1.0448983120918274
- 1.0356871962547303
- 1.0335080122947693
- 1.01789644241333
- 1.0113357973098756
- 1.0067793917655945
- 1.0021415209770204
- 1.0016662788391113
- 0.9881118845939636
- 0.980863139629364
- 0.977106819152832
- 0.9689704489707947
- 0.9660796618461609
- 0.9591330015659332
- 0.9548451888561249
- 0.955489432811737
- 0.9522611141204834
- 0.946302181482315
- 0.941586207151413
- 0.9391987597942353
- 0.9356258678436279
- 0.9336716687679291
- 0.9298402833938598
- 0.9295133566856384
- 0.9271768474578858
- 0.9262457394599914
- 0.9237560606002808
- 0.922561411857605
- 0.916059387922287
- 0.9166526889801025
- 0.9160609829425812
- 0.9133229672908783
- 0.9106250119209289
- 0.9109799885749816
- 0.9141128969192505
- 0.9157903945446014
- 0.9107590019702911
- 0.9085562014579773
- 0.9106072449684143
- 0.9045959758758545
- 0.9083393609523773
- 0.9053657281398774
- 0.9066685950756073
- 0.9064286077022552
- 0.903719253540039
- 0.9046659624576568
- 0.9066990792751313
- 0.9006431639194489
- 0.9014128005504608
- 0.904018703699112
- 0.9061155140399932
- 0.9077600157260894
- 0.9033980238437652
- 0.9056949007511139
- 0.9056769561767578
- 0.905155040025711
- 0.9040492498874664
- 0.905380266904831
- 0.9062975931167603
- 0.9129503083229065
- 0.9078723573684693
- 0.9076523661613465
- 0.9075560748577118
- 0.9095460510253907
- 0.9099070334434509
- 0.9080857062339782
- 0.9077969348430633
- 0.9108262264728546
- 0.9129162168502808
- 0.9100837051868439
- 0.9117639446258545
- 0.9133360326290131
- 0.9135863196849823
- 0.9202182924747467
- 0.9170024073123932
- 0.9199831461906434
- 0.9148630392551422
- 0.9170671355724335
- 0.9159406208992005
train_accuracy:
- 0.073
- 0.123
- 0.141
- 0.167
- 0.154
- 0.19
- 0.197
- 0.211
- 0.229
- 0.22
- 0.229
- 0.258
- 0.225
- 0.253
- 0.268
- 0.272
- 0.291
- 0.279
- 0.271
- 0.272
- 0.304
- 0.277
- 0.331
- 0.333
- 0.325
- 0.299
- 0.339
- 0.348
- 0.347
- 0.356
- 0.315
- 0.346
- 0.372
- 0.35
- 0.351
- 0.352
- 0.348
- 0.337
- 0.355
- 0.339
- 0.367
- 0.381
- 0.364
- 0.387
- 0.39
- 0.361
- 0.337
- 0.38
- 0.379
- 0.401
- 0.399
- 0.362
- 0.387
- 0.369
- 0.387
- 0.399
- 0.378
- 0.383
- 0.408
- 0.374
- 0.393
- 0.396
- 0.405
- 0.364
- 0.395
- 0.4
- 0.399
- 0.379
- 0.403
- 0.419
- 0.377
- 0.398
- 0.382
- 0.43
- 0.381
- 0.377
- 0.386
- 0.428
- 0.417
- 0.39
- 0.405
- 0.394
- 0.425
- 0.404
- 0.422
- 0.438
- 0.428
- 0.392
- 0.428
- 0.406
- 0.384
- 0.433
- 0.427
- 0.418
- 0.4
- 0.419
- 0.414
- 0.41
- 0.437
- 0.413
train_loss:
- 4.249
- 3.761
- 3.499
- 3.292
- 3.167
- 3.076
- 2.934
- 2.879
- 2.818
- 2.705
- 2.619
- 2.545
- 2.473
- 2.406
- 2.353
- 2.296
- 2.258
- 2.201
- 2.122
- 2.011
- 2.04
- 1.957
- 1.935
- 1.812
- 1.871
- 1.798
- 1.72
- 1.618
- 1.685
- 1.631
- 1.613
- 1.565
- 1.523
- 1.472
- 1.431
- 1.401
- 1.347
- 1.305
- 1.285
- 1.273
- 1.297
- 1.231
- 1.182
- 1.175
- 1.126
- 1.06
- 1.124
- 1.038
- 0.985
- 1.034
- 0.954
- 0.921
- 0.97
- 0.874
- 0.845
- 0.815
- 0.758
- 0.857
- 0.777
- 0.764
- 0.736
- 0.699
- 0.73
- 0.697
- 0.638
- 0.681
- 0.621
- 0.606
- 0.596
- 0.558
- 0.606
- 0.541
- 0.521
- 0.507
- 0.462
- 0.498
- 0.526
- 0.479
- 0.435
- 0.425
- 0.434
- 0.415
- 0.396
- 0.422
- 0.412
- 0.423
- 0.381
- 0.329
- 0.373
- 0.333
- 0.357
- 0.324
- 0.318
- 0.289
- 0.287
- 0.285
- 0.337
- 0.326
- 0.278
- 0.294
unequal: 0
verbose: 1
