avg_train_accuracy: 0.398
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0907
- 0.1393
- 0.1673
- 0.1844
- 0.2036
- 0.2207
- 0.2327
- 0.2388
- 0.2484
- 0.2619
- 0.272
- 0.2801
- 0.2868
- 0.2934
- 0.3005
- 0.3057
- 0.3129
- 0.3192
- 0.3205
- 0.3295
- 0.3342
- 0.3341
- 0.3405
- 0.343
- 0.3469
- 0.3545
- 0.3606
- 0.3644
- 0.364
- 0.3642
- 0.3643
- 0.3686
- 0.3716
- 0.3763
- 0.3745
- 0.3712
- 0.3787
- 0.3809
- 0.3811
- 0.3879
- 0.3923
- 0.3896
- 0.3896
- 0.3885
- 0.3913
- 0.3926
- 0.3952
- 0.3971
- 0.4002
- 0.4005
- 0.4027
- 0.4033
- 0.4038
- 0.4065
- 0.4058
- 0.4063
- 0.4098
- 0.4121
- 0.4102
- 0.4112
- 0.4145
- 0.4139
- 0.4117
- 0.4121
- 0.4124
- 0.4185
- 0.4162
- 0.415
- 0.4181
- 0.4199
- 0.4173
- 0.4204
- 0.4223
- 0.4182
- 0.4195
- 0.4186
- 0.419
- 0.4202
- 0.4222
- 0.4217
- 0.4225
- 0.4256
- 0.4253
- 0.4262
- 0.4237
- 0.4255
- 0.4264
- 0.4261
- 0.4257
- 0.4287
- 0.428
- 0.4298
- 0.4289
- 0.431
- 0.4283
- 0.4269
- 0.4256
- 0.4301
- 0.4277
- 0.427
test_loss_list:
- 1.6432226943969725
- 1.52255610704422
- 1.4532095575332642
- 1.4027754282951355
- 1.3625750875473022
- 1.3251132464408875
- 1.2971654653549194
- 1.2735705089569092
- 1.2521262121200563
- 1.2269297337532044
- 1.2084568643569946
- 1.191404619216919
- 1.1767888116836547
- 1.1587468409538269
- 1.1438267397880555
- 1.1339366102218629
- 1.1196633553504944
- 1.1060526847839356
- 1.092660596370697
- 1.079560594558716
- 1.0709445762634278
- 1.0660494327545167
- 1.057688148021698
- 1.0497814512252808
- 1.0404178929328918
- 1.0296545481681825
- 1.0184375977516174
- 1.0141995787620544
- 1.0062426686286927
- 1.003455171585083
- 1.0025937128067017
- 0.9998450112342835
- 0.9920293545722961
- 0.9871929728984833
- 0.9819494390487671
- 0.9902132940292359
- 0.9752829873561859
- 0.9736275374889374
- 0.9690654003620147
- 0.9609520363807679
- 0.9549082434177398
- 0.9579570531845093
- 0.9566692769527435
- 0.954639060497284
- 0.9510865926742553
- 0.9496006178855896
- 0.943984351158142
- 0.9429783928394317
- 0.9433176636695861
- 0.9397665035724639
- 0.943744410276413
- 0.9365601468086243
- 0.9367999362945557
- 0.9338122820854187
- 0.9333443999290466
- 0.9348705458641052
- 0.9262411308288574
- 0.9274020481109619
- 0.9331767523288726
- 0.9295477879047394
- 0.9278486657142639
- 0.9298656260967255
- 0.9296934497356415
- 0.9300600457191467
- 0.9305741024017334
- 0.9285902142524719
- 0.9351160490512848
- 0.9312825846672058
- 0.9276608145236969
- 0.9279930746555328
- 0.9288418233394623
- 0.9274488997459411
- 0.9225309753417968
- 0.9312779712677002
- 0.9242853891849517
- 0.9297518360614777
- 0.9276381123065949
- 0.932296530008316
- 0.9307036757469177
- 0.9292373144626618
- 0.9296920204162598
- 0.9284160530567169
- 0.9308029747009278
- 0.9302030229568481
- 0.9346868503093719
- 0.9319793057441711
- 0.9346764242649078
- 0.9336321759223938
- 0.9347368049621582
- 0.9342684364318847
- 0.9313527810573577
- 0.9316013586521149
- 0.9332536458969116
- 0.9342009782791137
- 0.9357151353359222
- 0.9375382089614868
- 0.9394277095794678
- 0.9408711755275726
- 0.9376134908199311
- 0.9429234719276428
train_accuracy:
- 0.08
- 0.13
- 0.146
- 0.18
- 0.169
- 0.15
- 0.201
- 0.233
- 0.216
- 0.237
- 0.244
- 0.244
- 0.288
- 0.287
- 0.259
- 0.304
- 0.242
- 0.291
- 0.268
- 0.258
- 0.274
- 0.295
- 0.271
- 0.35
- 0.356
- 0.307
- 0.313
- 0.362
- 0.322
- 0.368
- 0.361
- 0.332
- 0.344
- 0.318
- 0.352
- 0.348
- 0.394
- 0.36
- 0.315
- 0.324
- 0.351
- 0.353
- 0.321
- 0.37
- 0.384
- 0.394
- 0.35
- 0.416
- 0.386
- 0.388
- 0.385
- 0.369
- 0.367
- 0.358
- 0.362
- 0.33
- 0.378
- 0.384
- 0.412
- 0.388
- 0.384
- 0.369
- 0.39
- 0.346
- 0.343
- 0.383
- 0.375
- 0.419
- 0.429
- 0.421
- 0.411
- 0.389
- 0.356
- 0.353
- 0.413
- 0.354
- 0.36
- 0.394
- 0.394
- 0.389
- 0.402
- 0.384
- 0.388
- 0.41
- 0.416
- 0.37
- 0.422
- 0.44
- 0.427
- 0.425
- 0.406
- 0.398
- 0.411
- 0.395
- 0.385
- 0.394
- 0.432
- 0.397
- 0.426
- 0.398
train_loss:
- 4.218
- 3.738
- 3.483
- 3.295
- 3.178
- 3.078
- 2.93
- 2.86
- 2.742
- 2.724
- 2.63
- 2.522
- 2.441
- 2.436
- 2.306
- 2.262
- 2.223
- 2.219
- 2.14
- 2.137
- 1.999
- 1.897
- 1.899
- 1.909
- 1.929
- 1.811
- 1.782
- 1.749
- 1.684
- 1.648
- 1.559
- 1.589
- 1.502
- 1.491
- 1.405
- 1.386
- 1.316
- 1.462
- 1.331
- 1.336
- 1.291
- 1.205
- 1.283
- 1.128
- 1.102
- 1.151
- 1.073
- 1.108
- 1.012
- 1.035
- 0.957
- 0.927
- 0.98
- 0.874
- 0.923
- 0.823
- 0.863
- 0.859
- 0.764
- 0.757
- 0.782
- 0.735
- 0.72
- 0.681
- 0.686
- 0.628
- 0.615
- 0.617
- 0.649
- 0.577
- 0.585
- 0.585
- 0.606
- 0.534
- 0.58
- 0.478
- 0.521
- 0.466
- 0.475
- 0.464
- 0.457
- 0.454
- 0.429
- 0.434
- 0.419
- 0.383
- 0.373
- 0.399
- 0.365
- 0.403
- 0.357
- 0.389
- 0.333
- 0.332
- 0.314
- 0.3
- 0.319
- 0.336
- 0.295
- 0.304
unequal: 0
verbose: 1
