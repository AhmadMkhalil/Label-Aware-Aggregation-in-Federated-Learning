avg_train_accuracy: 0.373
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0968
- 0.1366
- 0.164
- 0.1873
- 0.2076
- 0.2199
- 0.2349
- 0.2427
- 0.2538
- 0.2665
- 0.2726
- 0.2814
- 0.287
- 0.2937
- 0.3008
- 0.3067
- 0.3139
- 0.3187
- 0.3256
- 0.3284
- 0.3371
- 0.341
- 0.3431
- 0.3491
- 0.3486
- 0.3581
- 0.3588
- 0.3644
- 0.3637
- 0.367
- 0.3715
- 0.3772
- 0.3778
- 0.3799
- 0.3806
- 0.3883
- 0.3899
- 0.3932
- 0.3888
- 0.3948
- 0.3956
- 0.3961
- 0.4021
- 0.4008
- 0.3951
- 0.3978
- 0.4032
- 0.4043
- 0.4022
- 0.4036
- 0.4054
- 0.4084
- 0.4076
- 0.4104
- 0.4089
- 0.4099
- 0.4162
- 0.412
- 0.4134
- 0.415
- 0.414
- 0.4201
- 0.4177
- 0.4177
- 0.4211
- 0.4205
- 0.4187
- 0.4164
- 0.4224
- 0.4192
- 0.4288
- 0.4245
- 0.4257
- 0.4287
- 0.4273
- 0.4269
- 0.4249
- 0.4265
- 0.4253
- 0.427
- 0.4284
- 0.4273
- 0.4263
- 0.4252
- 0.4274
- 0.4325
- 0.4281
- 0.4298
- 0.426
- 0.4325
- 0.4285
- 0.4322
- 0.4334
- 0.4314
- 0.4314
- 0.4356
- 0.4353
- 0.4372
- 0.4336
- 0.4337
test_loss_list:
- 1.6322902178764342
- 1.5242782926559448
- 1.4517114901542663
- 1.4008499932289125
- 1.3591091275215148
- 1.3260434460639954
- 1.2970972442626953
- 1.2724061632156372
- 1.2469994950294494
- 1.2241815733909607
- 1.2049032258987427
- 1.1848748874664308
- 1.1702670407295228
- 1.1551133680343628
- 1.140933210849762
- 1.1320880150794983
- 1.1173704934120179
- 1.1038273549079896
- 1.0896379232406617
- 1.078326244354248
- 1.0676260590553284
- 1.0611450457572937
- 1.0522956585884093
- 1.0398173689842225
- 1.0411725616455079
- 1.0261190056800842
- 1.020282645225525
- 1.0119070076942445
- 1.0073526740074157
- 1.0034837961196899
- 0.9986825966835022
- 0.9902258133888244
- 0.9837189745903016
- 0.9805225896835327
- 0.9813875079154968
- 0.9709484052658081
- 0.9679032135009765
- 0.9610009074211121
- 0.9627048397064208
- 0.9552092123031616
- 0.9572114872932435
- 0.9524518918991088
- 0.9462354516983033
- 0.9465935373306275
- 0.9516572380065917
- 0.9427151513099671
- 0.9426584863662719
- 0.9405501937866211
- 0.9484114575386048
- 0.9431779861450196
- 0.936547908782959
- 0.9366651844978332
- 0.9385365462303161
- 0.9355980324745178
- 0.9338192844390869
- 0.9357039165496827
- 0.9276048254966736
- 0.9283546566963196
- 0.9292021656036377
- 0.9276378130912781
- 0.9281221103668212
- 0.9207880711555481
- 0.9244716715812683
- 0.9275962138175964
- 0.9209065866470337
- 0.9244924521446228
- 0.9256004500389099
- 0.9295296001434327
- 0.9236437368392945
- 0.9227535533905029
- 0.9215637803077698
- 0.923636474609375
- 0.9202028036117553
- 0.9222098875045777
- 0.9251519823074341
- 0.9295229506492615
- 0.9249695539474487
- 0.9276683235168457
- 0.9280165076255799
- 0.9280113339424133
- 0.9280667352676392
- 0.9289554667472839
- 0.932226357460022
- 0.9315145373344421
- 0.9293821144104004
- 0.925697808265686
- 0.9301433420181274
- 0.9311195468902588
- 0.9288059425354004
- 0.9335511159896851
- 0.9318473243713379
- 0.9303631973266602
- 0.9305481505393982
- 0.92897376537323
- 0.9339464211463928
- 0.9295843315124511
- 0.9309559392929078
- 0.9296217250823975
- 0.9384152340888977
- 0.9423834896087646
train_accuracy:
- 0.088
- 0.129
- 0.158
- 0.178
- 0.192
- 0.2
- 0.195
- 0.232
- 0.251
- 0.237
- 0.267
- 0.26
- 0.262
- 0.287
- 0.288
- 0.285
- 0.299
- 0.286
- 0.31
- 0.288
- 0.334
- 0.323
- 0.303
- 0.315
- 0.331
- 0.313
- 0.32
- 0.353
- 0.357
- 0.361
- 0.351
- 0.32
- 0.371
- 0.345
- 0.347
- 0.341
- 0.371
- 0.358
- 0.367
- 0.343
- 0.378
- 0.367
- 0.341
- 0.378
- 0.34
- 0.406
- 0.367
- 0.395
- 0.34
- 0.379
- 0.372
- 0.388
- 0.362
- 0.355
- 0.381
- 0.379
- 0.38
- 0.376
- 0.371
- 0.428
- 0.38
- 0.363
- 0.384
- 0.379
- 0.386
- 0.4
- 0.389
- 0.403
- 0.361
- 0.408
- 0.395
- 0.376
- 0.355
- 0.373
- 0.397
- 0.391
- 0.382
- 0.411
- 0.396
- 0.379
- 0.411
- 0.387
- 0.355
- 0.402
- 0.402
- 0.412
- 0.367
- 0.404
- 0.399
- 0.456
- 0.443
- 0.42
- 0.411
- 0.408
- 0.382
- 0.455
- 0.372
- 0.416
- 0.45
- 0.373
train_loss:
- 4.221
- 3.711
- 3.49
- 3.318
- 3.177
- 3.07
- 2.972
- 2.861
- 2.75
- 2.711
- 2.636
- 2.524
- 2.485
- 2.431
- 2.298
- 2.274
- 2.198
- 2.203
- 2.13
- 2.092
- 1.998
- 1.889
- 1.966
- 1.881
- 1.837
- 1.737
- 1.753
- 1.748
- 1.596
- 1.578
- 1.598
- 1.572
- 1.566
- 1.464
- 1.356
- 1.391
- 1.434
- 1.304
- 1.272
- 1.294
- 1.236
- 1.218
- 1.21
- 1.102
- 1.118
- 1.098
- 0.973
- 0.988
- 0.962
- 0.886
- 1.031
- 0.922
- 0.825
- 0.89
- 0.917
- 0.809
- 0.885
- 0.842
- 0.761
- 0.789
- 0.725
- 0.781
- 0.695
- 0.71
- 0.724
- 0.609
- 0.605
- 0.638
- 0.617
- 0.606
- 0.575
- 0.553
- 0.538
- 0.532
- 0.489
- 0.454
- 0.528
- 0.461
- 0.45
- 0.444
- 0.422
- 0.39
- 0.366
- 0.447
- 0.427
- 0.401
- 0.347
- 0.378
- 0.35
- 0.36
- 0.364
- 0.329
- 0.353
- 0.322
- 0.3
- 0.337
- 0.315
- 0.32
- 0.291
- 0.28
unequal: 0
verbose: 1
