avg_train_accuracy: 0.411
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1124
- 0.1457
- 0.1737
- 0.1948
- 0.2102
- 0.2225
- 0.2341
- 0.2441
- 0.255
- 0.2627
- 0.2757
- 0.2811
- 0.2906
- 0.2966
- 0.3078
- 0.3122
- 0.3191
- 0.3262
- 0.3278
- 0.3373
- 0.3401
- 0.3433
- 0.3481
- 0.3542
- 0.3617
- 0.3629
- 0.3661
- 0.3651
- 0.3721
- 0.3727
- 0.3788
- 0.3826
- 0.3851
- 0.3876
- 0.3839
- 0.385
- 0.3915
- 0.3937
- 0.3976
- 0.3998
- 0.3985
- 0.4041
- 0.4035
- 0.4034
- 0.409
- 0.4082
- 0.4097
- 0.4124
- 0.4117
- 0.4127
- 0.4168
- 0.4198
- 0.4157
- 0.4194
- 0.4185
- 0.4191
- 0.4202
- 0.4227
- 0.4234
- 0.4247
- 0.4221
- 0.4217
- 0.428
- 0.4235
- 0.4248
- 0.428
- 0.4295
- 0.4272
- 0.4266
- 0.4313
- 0.4279
- 0.4337
- 0.4304
- 0.4315
- 0.4305
- 0.4342
- 0.4336
- 0.4299
- 0.4327
- 0.4327
- 0.431
- 0.4335
- 0.4365
- 0.4355
- 0.4353
- 0.4353
- 0.4364
- 0.4367
- 0.4334
- 0.4348
- 0.4362
- 0.4346
- 0.4395
- 0.4368
- 0.4359
- 0.4393
- 0.4393
- 0.4358
- 0.4403
- 0.4373
test_loss_list:
- 1.6197925591468811
- 1.503408899307251
- 1.4354093527793885
- 1.3878632402420044
- 1.3534786319732666
- 1.3218215703964233
- 1.2899103903770446
- 1.2635326504707336
- 1.2410086250305177
- 1.219274697303772
- 1.1957257175445557
- 1.176841983795166
- 1.161342329978943
- 1.1431008458137513
- 1.1269101524353027
- 1.1139582300186157
- 1.097994055747986
- 1.0877650475502014
- 1.0785341882705688
- 1.063361451625824
- 1.0573160696029662
- 1.0448885130882264
- 1.0395880913734437
- 1.026830472946167
- 1.0160751581192016
- 1.0149645495414734
- 1.006145384311676
- 0.9961035037040711
- 0.9940742611885071
- 0.9917815804481507
- 0.9807314729690552
- 0.9730591261386872
- 0.9714446759223938
- 0.9698422861099243
- 0.966552517414093
- 0.9597760212421417
- 0.9554873251914978
- 0.9533190536499023
- 0.9485195517539978
- 0.9482845282554626
- 0.9419925010204315
- 0.9336924088001252
- 0.9323553907871246
- 0.9366132938861846
- 0.9241139936447144
- 0.9277680540084838
- 0.9209981775283813
- 0.9233952450752259
- 0.92245077252388
- 0.9186378335952758
- 0.9182183420658112
- 0.9124435925483704
- 0.9193892562389374
- 0.9075226640701294
- 0.9116127359867096
- 0.9131898498535156
- 0.9145823729038238
- 0.9055970907211304
- 0.9042572927474976
- 0.9065652823448181
- 0.9065130317211151
- 0.9104581332206726
- 0.9040658438205719
- 0.9025624680519104
- 0.9022025394439698
- 0.9030183506011963
- 0.9005129623413086
- 0.9079985749721527
- 0.9028003680706024
- 0.9010420501232147
- 0.9022816860675812
- 0.9021443116664887
- 0.9032476091384888
- 0.9046320927143097
- 0.90363028049469
- 0.9058190298080444
- 0.9024593603610992
- 0.9032714390754699
- 0.907630226612091
- 0.9028020596504212
- 0.904253009557724
- 0.9038210868835449
- 0.9051555931568146
- 0.9032359743118286
- 0.9027916264533996
- 0.9091989922523499
- 0.911221559047699
- 0.9099769580364228
- 0.911705915927887
- 0.9116954827308654
- 0.9147616505622864
- 0.9179724717140197
- 0.9112199664115905
- 0.9179878401756286
- 0.9164126741886139
- 0.9124072742462158
- 0.9165346682071686
- 0.9213581764698029
- 0.9099253726005554
- 0.9210754764080048
train_accuracy:
- 0.092
- 0.173
- 0.154
- 0.158
- 0.178
- 0.206
- 0.219
- 0.229
- 0.28
- 0.238
- 0.285
- 0.285
- 0.263
- 0.301
- 0.292
- 0.281
- 0.304
- 0.265
- 0.293
- 0.287
- 0.346
- 0.305
- 0.304
- 0.326
- 0.307
- 0.313
- 0.366
- 0.332
- 0.349
- 0.359
- 0.333
- 0.344
- 0.376
- 0.371
- 0.367
- 0.353
- 0.361
- 0.35
- 0.351
- 0.366
- 0.4
- 0.357
- 0.385
- 0.346
- 0.368
- 0.372
- 0.388
- 0.41
- 0.374
- 0.394
- 0.387
- 0.385
- 0.417
- 0.366
- 0.381
- 0.38
- 0.388
- 0.428
- 0.405
- 0.419
- 0.377
- 0.403
- 0.391
- 0.398
- 0.391
- 0.393
- 0.437
- 0.439
- 0.394
- 0.428
- 0.397
- 0.417
- 0.41
- 0.442
- 0.41
- 0.398
- 0.406
- 0.447
- 0.402
- 0.416
- 0.404
- 0.413
- 0.446
- 0.396
- 0.424
- 0.413
- 0.431
- 0.413
- 0.414
- 0.419
- 0.402
- 0.409
- 0.408
- 0.418
- 0.433
- 0.416
- 0.427
- 0.418
- 0.434
- 0.411
train_loss:
- 4.176
- 3.69
- 3.45
- 3.276
- 3.148
- 3.024
- 2.94
- 2.837
- 2.718
- 2.669
- 2.607
- 2.538
- 2.437
- 2.41
- 2.323
- 2.327
- 2.18
- 2.132
- 2.096
- 2.058
- 2.058
- 1.944
- 1.825
- 1.822
- 1.849
- 1.725
- 1.78
- 1.709
- 1.687
- 1.55
- 1.608
- 1.586
- 1.542
- 1.439
- 1.409
- 1.405
- 1.341
- 1.373
- 1.274
- 1.25
- 1.263
- 1.261
- 1.158
- 1.154
- 1.119
- 1.06
- 1.097
- 1.033
- 1.025
- 1.035
- 0.927
- 0.973
- 0.913
- 0.912
- 0.864
- 0.85
- 0.802
- 0.816
- 0.755
- 0.726
- 0.752
- 0.709
- 0.731
- 0.692
- 0.623
- 0.65
- 0.688
- 0.638
- 0.616
- 0.588
- 0.582
- 0.562
- 0.509
- 0.555
- 0.524
- 0.473
- 0.505
- 0.472
- 0.445
- 0.46
- 0.428
- 0.445
- 0.436
- 0.39
- 0.391
- 0.398
- 0.394
- 0.36
- 0.342
- 0.351
- 0.325
- 0.327
- 0.358
- 0.334
- 0.29
- 0.323
- 0.287
- 0.286
- 0.308
- 0.267
unequal: 0
verbose: 1
