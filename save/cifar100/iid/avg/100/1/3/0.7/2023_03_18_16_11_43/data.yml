avg_train_accuracy: 0.453
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0934
- 0.142
- 0.1677
- 0.1882
- 0.2048
- 0.2228
- 0.2327
- 0.2456
- 0.2561
- 0.2666
- 0.2768
- 0.2833
- 0.2911
- 0.2999
- 0.3001
- 0.3084
- 0.3157
- 0.3223
- 0.3236
- 0.331
- 0.3354
- 0.3398
- 0.3452
- 0.3487
- 0.3516
- 0.3561
- 0.3614
- 0.3673
- 0.3712
- 0.3719
- 0.3746
- 0.3793
- 0.3836
- 0.3816
- 0.3835
- 0.3863
- 0.3856
- 0.3877
- 0.3904
- 0.3974
- 0.3999
- 0.3969
- 0.3971
- 0.3992
- 0.4045
- 0.4041
- 0.4066
- 0.4056
- 0.4081
- 0.4077
- 0.4091
- 0.4098
- 0.4114
- 0.4156
- 0.4138
- 0.4141
- 0.4156
- 0.4175
- 0.4186
- 0.4154
- 0.4208
- 0.4182
- 0.4231
- 0.422
- 0.4242
- 0.4266
- 0.4255
- 0.4222
- 0.4229
- 0.4265
- 0.4258
- 0.428
- 0.4277
- 0.4298
- 0.4277
- 0.4281
- 0.4293
- 0.4326
- 0.4302
- 0.4289
- 0.431
- 0.434
- 0.4331
- 0.4333
- 0.4345
- 0.4317
- 0.4336
- 0.4342
- 0.4343
- 0.4348
- 0.4368
- 0.4362
- 0.4337
- 0.4364
- 0.4354
- 0.4351
- 0.4368
- 0.4353
- 0.435
- 0.4376
test_loss_list:
- 1.6433698058128356
- 1.5221050786972046
- 1.4465216660499574
- 1.3962038207054137
- 1.3575812911987304
- 1.323519377708435
- 1.2925990796089173
- 1.2636640691757202
- 1.2396248030662536
- 1.2173787999153136
- 1.1960373973846437
- 1.176769983768463
- 1.1594499444961548
- 1.1442797899246215
- 1.1264711952209472
- 1.1125857520103455
- 1.0986239147186279
- 1.0842855477333069
- 1.0782329225540161
- 1.0641851782798768
- 1.050779674053192
- 1.0429082942008971
- 1.0313691186904907
- 1.0233097338676453
- 1.013462393283844
- 1.0100629568099975
- 1.0008983516693115
- 0.996441045999527
- 0.9873743462562561
- 0.9803699183464051
- 0.9772573828697204
- 0.9708649718761444
- 0.9659456419944763
- 0.9671496307849884
- 0.9578991162776948
- 0.9542561972141266
- 0.9516770851612091
- 0.9475214016437531
- 0.950234682559967
- 0.9378531289100647
- 0.9347530436515809
- 0.9372772431373596
- 0.9321215677261353
- 0.9347399425506592
- 0.9271465158462524
- 0.9259901189804077
- 0.9215117776393891
- 0.9247451031208038
- 0.9178994965553283
- 0.9187651133537292
- 0.9194815540313721
- 0.9155649805068969
- 0.9153088045120239
- 0.9145215737819672
- 0.9166270542144775
- 0.9132048964500428
- 0.9107563352584839
- 0.9115048384666443
- 0.906781234741211
- 0.9066688728332519
- 0.9056552934646607
- 0.9086673533916474
- 0.9064855766296387
- 0.9092922830581665
- 0.9074076974391937
- 0.9041356265544891
- 0.9034103965759277
- 0.905822182893753
- 0.9090977585315705
- 0.906225118637085
- 0.9061749231815338
- 0.9084462630748749
- 0.9064103019237518
- 0.9074954962730408
- 0.9062903046607971
- 0.9073947715759277
- 0.907516850233078
- 0.9079260110855103
- 0.9086997199058533
- 0.9082827484607696
- 0.9089252769947052
- 0.9086921620368957
- 0.9141007781028747
- 0.9138226199150086
- 0.9131117463111877
- 0.9127053093910217
- 0.9153217160701752
- 0.9160709512233735
- 0.9158256125450134
- 0.9143153738975525
- 0.9153647541999816
- 0.9167203378677368
- 0.9171767795085907
- 0.9174038243293762
- 0.9216380095481873
- 0.9197403538227081
- 0.9209819984436035
- 0.9210415673255921
- 0.9246496939659119
- 0.9228560304641724
train_accuracy:
- 0.091
- 0.137
- 0.167
- 0.158
- 0.188
- 0.185
- 0.213
- 0.197
- 0.256
- 0.265
- 0.249
- 0.293
- 0.268
- 0.244
- 0.272
- 0.273
- 0.285
- 0.288
- 0.329
- 0.286
- 0.302
- 0.296
- 0.292
- 0.323
- 0.366
- 0.313
- 0.334
- 0.299
- 0.305
- 0.345
- 0.342
- 0.394
- 0.34
- 0.379
- 0.337
- 0.353
- 0.395
- 0.364
- 0.342
- 0.376
- 0.36
- 0.354
- 0.381
- 0.362
- 0.37
- 0.375
- 0.421
- 0.35
- 0.368
- 0.338
- 0.386
- 0.38
- 0.381
- 0.377
- 0.379
- 0.376
- 0.377
- 0.411
- 0.433
- 0.405
- 0.388
- 0.391
- 0.394
- 0.391
- 0.445
- 0.407
- 0.389
- 0.401
- 0.392
- 0.378
- 0.444
- 0.392
- 0.397
- 0.404
- 0.399
- 0.394
- 0.396
- 0.397
- 0.404
- 0.416
- 0.389
- 0.423
- 0.424
- 0.395
- 0.431
- 0.407
- 0.402
- 0.408
- 0.401
- 0.376
- 0.391
- 0.397
- 0.406
- 0.407
- 0.412
- 0.412
- 0.408
- 0.444
- 0.415
- 0.453
train_loss:
- 4.241
- 3.742
- 3.511
- 3.326
- 3.194
- 3.084
- 2.97
- 2.887
- 2.787
- 2.693
- 2.623
- 2.573
- 2.479
- 2.425
- 2.352
- 2.285
- 2.234
- 2.177
- 2.138
- 2.049
- 2.006
- 1.954
- 1.912
- 1.854
- 1.836
- 1.769
- 1.707
- 1.685
- 1.657
- 1.616
- 1.567
- 1.528
- 1.497
- 1.44
- 1.41
- 1.382
- 1.397
- 1.29
- 1.319
- 1.268
- 1.228
- 1.194
- 1.178
- 1.12
- 1.135
- 1.083
- 1.081
- 1.039
- 1.004
- 0.976
- 0.97
- 0.931
- 0.894
- 0.848
- 0.844
- 0.853
- 0.829
- 0.795
- 0.778
- 0.759
- 0.73
- 0.74
- 0.703
- 0.674
- 0.656
- 0.638
- 0.618
- 0.633
- 0.586
- 0.557
- 0.556
- 0.53
- 0.536
- 0.525
- 0.49
- 0.497
- 0.491
- 0.459
- 0.45
- 0.452
- 0.432
- 0.418
- 0.401
- 0.392
- 0.399
- 0.391
- 0.37
- 0.352
- 0.361
- 0.348
- 0.345
- 0.319
- 0.33
- 0.308
- 0.305
- 0.297
- 0.292
- 0.278
- 0.267
- 0.291
unequal: 0
verbose: 1
