avg_train_accuracy: 0.389
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1009
- 0.1457
- 0.165
- 0.188
- 0.2083
- 0.2195
- 0.2307
- 0.2406
- 0.2544
- 0.2625
- 0.2733
- 0.2813
- 0.2869
- 0.2897
- 0.2975
- 0.3026
- 0.3077
- 0.3154
- 0.3222
- 0.3264
- 0.3328
- 0.3383
- 0.3424
- 0.3454
- 0.3503
- 0.3508
- 0.3569
- 0.3611
- 0.3625
- 0.3637
- 0.3676
- 0.3697
- 0.3714
- 0.3744
- 0.3757
- 0.382
- 0.3794
- 0.3826
- 0.386
- 0.3888
- 0.3868
- 0.3915
- 0.3927
- 0.3924
- 0.3952
- 0.3979
- 0.3975
- 0.3981
- 0.4016
- 0.4023
- 0.4033
- 0.403
- 0.4068
- 0.4059
- 0.409
- 0.4127
- 0.4089
- 0.4107
- 0.4125
- 0.4134
- 0.4164
- 0.4151
- 0.4185
- 0.4178
- 0.4194
- 0.417
- 0.4211
- 0.4213
- 0.4195
- 0.4212
- 0.4208
- 0.423
- 0.4245
- 0.4232
- 0.4277
- 0.428
- 0.4244
- 0.4274
- 0.4248
- 0.4261
- 0.4291
- 0.4288
- 0.4275
- 0.4265
- 0.4276
- 0.4313
- 0.4312
- 0.4304
- 0.4343
- 0.4324
- 0.4308
- 0.4319
- 0.432
- 0.4336
- 0.4334
- 0.4355
- 0.4332
- 0.4339
- 0.4339
- 0.4346
test_loss_list:
- 1.6282543540000916
- 1.5102469038963318
- 1.443764684200287
- 1.394762465953827
- 1.3566145563125611
- 1.3243760514259337
- 1.2972558784484862
- 1.2714587903022767
- 1.2474165678024292
- 1.2250446677207947
- 1.2072094249725343
- 1.189279842376709
- 1.1736120247840882
- 1.1604078793525696
- 1.1463750314712524
- 1.133661789894104
- 1.1197376704216004
- 1.1090472888946534
- 1.0957449722290038
- 1.0842583298683166
- 1.0716140007972716
- 1.0643404459953307
- 1.0560500383377076
- 1.0445331144332886
- 1.0377600550651551
- 1.0301863169670105
- 1.0232690930366517
- 1.0164239025115966
- 1.0096052861213685
- 1.006632695198059
- 0.9987221050262451
- 0.9956453680992127
- 0.9893505096435546
- 0.9852117013931274
- 0.9816753268241882
- 0.9744278454780578
- 0.9704673099517822
- 0.969349570274353
- 0.9633984756469727
- 0.9593957686424255
- 0.9580433416366577
- 0.9538544607162476
- 0.956514117717743
- 0.9514109802246093
- 0.9466493701934815
- 0.9443301033973693
- 0.9441225934028625
- 0.9424416542053222
- 0.9414512419700622
- 0.9377231240272522
- 0.938602066040039
- 0.9365811014175415
- 0.9354712533950805
- 0.9329885268211364
- 0.9312509202957153
- 0.9311924624443054
- 0.9321326541900635
- 0.9329311990737915
- 0.9316723656654358
- 0.9312092566490173
- 0.9273781228065491
- 0.9259929633140564
- 0.9257618737220764
- 0.9280450391769409
- 0.9289423227310181
- 0.9279600667953491
- 0.9268535828590393
- 0.9285178565979004
- 0.9288006377220154
- 0.9282323741912841
- 0.9274003386497498
- 0.9282858681678772
- 0.926811797618866
- 0.9303128385543823
- 0.9305877423286438
- 0.9323165416717529
- 0.9295866680145264
- 0.9301566076278687
- 0.931780366897583
- 0.9304269766807556
- 0.9297295928001403
- 0.9311191248893738
- 0.9319816708564759
- 0.9353157138824463
- 0.9303649401664734
- 0.9349782371520996
- 0.9307918739318848
- 0.9349934339523316
- 0.9342541718482971
- 0.9339570283889771
- 0.9381653332710266
- 0.9370128178596496
- 0.9365697312355041
- 0.9364937829971314
- 0.9375187158584595
- 0.9375238204002381
- 0.9418651652336121
- 0.9434600114822388
- 0.9435629343986511
- 0.9428515148162842
train_accuracy:
- 0.085
- 0.136
- 0.162
- 0.175
- 0.163
- 0.21
- 0.2
- 0.226
- 0.199
- 0.243
- 0.261
- 0.271
- 0.298
- 0.288
- 0.298
- 0.239
- 0.276
- 0.311
- 0.289
- 0.269
- 0.289
- 0.316
- 0.29
- 0.285
- 0.264
- 0.352
- 0.354
- 0.301
- 0.342
- 0.313
- 0.374
- 0.323
- 0.386
- 0.338
- 0.318
- 0.386
- 0.359
- 0.393
- 0.395
- 0.397
- 0.318
- 0.349
- 0.408
- 0.347
- 0.406
- 0.368
- 0.34
- 0.355
- 0.398
- 0.37
- 0.429
- 0.377
- 0.421
- 0.382
- 0.427
- 0.373
- 0.352
- 0.377
- 0.361
- 0.375
- 0.377
- 0.398
- 0.431
- 0.386
- 0.437
- 0.387
- 0.392
- 0.381
- 0.378
- 0.443
- 0.408
- 0.439
- 0.386
- 0.394
- 0.389
- 0.44
- 0.37
- 0.399
- 0.364
- 0.442
- 0.434
- 0.36
- 0.371
- 0.362
- 0.375
- 0.439
- 0.37
- 0.382
- 0.446
- 0.418
- 0.446
- 0.379
- 0.372
- 0.419
- 0.401
- 0.379
- 0.417
- 0.443
- 0.371
- 0.389
train_loss:
- 4.206
- 3.707
- 3.463
- 3.313
- 3.167
- 3.045
- 2.941
- 2.878
- 2.776
- 2.716
- 2.627
- 2.539
- 2.475
- 2.419
- 2.378
- 2.315
- 2.24
- 2.159
- 2.127
- 2.093
- 2.069
- 1.965
- 1.92
- 1.868
- 1.804
- 1.812
- 1.788
- 1.712
- 1.688
- 1.607
- 1.615
- 1.549
- 1.509
- 1.489
- 1.466
- 1.431
- 1.379
- 1.337
- 1.335
- 1.298
- 1.253
- 1.211
- 1.208
- 1.156
- 1.136
- 1.102
- 1.079
- 1.06
- 1.014
- 0.993
- 0.967
- 0.948
- 0.908
- 0.887
- 0.858
- 0.849
- 0.835
- 0.797
- 0.8
- 0.753
- 0.727
- 0.739
- 0.7
- 0.687
- 0.679
- 0.656
- 0.654
- 0.605
- 0.594
- 0.599
- 0.562
- 0.559
- 0.531
- 0.533
- 0.502
- 0.509
- 0.491
- 0.479
- 0.449
- 0.429
- 0.45
- 0.413
- 0.425
- 0.403
- 0.413
- 0.381
- 0.386
- 0.379
- 0.36
- 0.343
- 0.341
- 0.338
- 0.33
- 0.331
- 0.31
- 0.307
- 0.301
- 0.282
- 0.302
- 0.273
unequal: 0
verbose: 1
