avg_train_accuracy: 0.387
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0872
- 0.1281
- 0.1579
- 0.1838
- 0.2029
- 0.2187
- 0.2337
- 0.2467
- 0.2548
- 0.2626
- 0.2726
- 0.2801
- 0.2886
- 0.2931
- 0.298
- 0.3038
- 0.3077
- 0.3128
- 0.3205
- 0.3231
- 0.3287
- 0.3348
- 0.3393
- 0.3457
- 0.3457
- 0.3503
- 0.3571
- 0.3587
- 0.3616
- 0.3646
- 0.3676
- 0.3709
- 0.3734
- 0.3743
- 0.3787
- 0.3816
- 0.3837
- 0.3832
- 0.3881
- 0.388
- 0.3912
- 0.3929
- 0.3934
- 0.3966
- 0.3913
- 0.3948
- 0.4004
- 0.4002
- 0.4
- 0.4024
- 0.4028
- 0.4038
- 0.4061
- 0.4062
- 0.4086
- 0.4109
- 0.41
- 0.4122
- 0.413
- 0.4144
- 0.4149
- 0.4157
- 0.4141
- 0.4162
- 0.4147
- 0.4183
- 0.4182
- 0.4168
- 0.4194
- 0.4216
- 0.4186
- 0.4247
- 0.4195
- 0.4238
- 0.4229
- 0.4244
- 0.4224
- 0.4242
- 0.4247
- 0.4265
- 0.425
- 0.4227
- 0.4272
- 0.4268
- 0.4261
- 0.4273
- 0.4244
- 0.4277
- 0.4274
- 0.4231
- 0.4284
- 0.4269
- 0.4302
- 0.4287
- 0.4287
- 0.4275
- 0.4308
- 0.4271
- 0.4322
- 0.4298
test_loss_list:
- 1.6506476759910584
- 1.5314741158485412
- 1.4554587650299071
- 1.4006934309005736
- 1.3583923983573913
- 1.3238917756080628
- 1.2926500153541565
- 1.2664363956451417
- 1.2425539207458496
- 1.2212577080726623
- 1.2033316707611084
- 1.1842174983024598
- 1.1679419159889222
- 1.1535206723213196
- 1.1397930788993835
- 1.127276237010956
- 1.1162025332450867
- 1.1032539129257202
- 1.0922955799102783
- 1.0798191404342652
- 1.0692568802833557
- 1.0603747153282166
- 1.0505703854560853
- 1.0405462312698364
- 1.0338904094696044
- 1.0261696314811706
- 1.0200681948661805
- 1.0120104908943177
- 1.0059848868846892
- 1.0002693009376527
- 0.9924938189983368
- 0.9898927819728851
- 0.9833718609809875
- 0.9800815594196319
- 0.9746456325054169
- 0.9700278711318969
- 0.9690389585494995
- 0.9622328746318817
- 0.9599087774753571
- 0.9569009137153626
- 0.9520915472507476
- 0.9510176622867584
- 0.9476423716545105
- 0.943261387348175
- 0.9422041726112366
- 0.9402470874786377
- 0.9395896875858307
- 0.9387413108348847
- 0.9371882963180542
- 0.9326487123966217
- 0.9326873993873597
- 0.9281569039821624
- 0.9298257756233216
- 0.9274239754676818
- 0.9279196667671203
- 0.9255858397483826
- 0.9282757294178009
- 0.9225243246555328
- 0.9243788254261017
- 0.9230235993862153
- 0.9197539818286896
- 0.9198393487930298
- 0.9203695333003998
- 0.9209034693241119
- 0.9203149509429932
- 0.9191914081573487
- 0.9196519327163696
- 0.9234784412384033
- 0.9210408163070679
- 0.9245904159545898
- 0.9196816194057464
- 0.922278743982315
- 0.9199048018455506
- 0.9207713723182678
- 0.9195893442630768
- 0.9214222121238709
- 0.9195313358306885
- 0.9214609467983246
- 0.9204623305797577
- 0.9201464748382568
- 0.9228322267532348
- 0.9265266335010529
- 0.920936131477356
- 0.9246718716621399
- 0.9246888756752014
- 0.9253546750545502
- 0.9290113854408264
- 0.9253108894824982
- 0.9280947458744049
- 0.9320683670043945
- 0.9307934510707855
- 0.9296877038478851
- 0.9295741748809815
- 0.9300043594837188
- 0.9316238236427307
- 0.933295978307724
- 0.9302165305614472
- 0.9352378404140472
- 0.9332479274272919
- 0.93457310795784
train_accuracy:
- 0.082
- 0.13
- 0.146
- 0.184
- 0.175
- 0.2
- 0.188
- 0.213
- 0.21
- 0.229
- 0.25
- 0.234
- 0.251
- 0.263
- 0.305
- 0.283
- 0.275
- 0.249
- 0.3
- 0.303
- 0.31
- 0.341
- 0.325
- 0.275
- 0.329
- 0.297
- 0.318
- 0.327
- 0.305
- 0.303
- 0.355
- 0.364
- 0.32
- 0.315
- 0.313
- 0.331
- 0.345
- 0.349
- 0.356
- 0.377
- 0.396
- 0.351
- 0.352
- 0.352
- 0.341
- 0.335
- 0.339
- 0.36
- 0.36
- 0.368
- 0.375
- 0.345
- 0.4
- 0.354
- 0.356
- 0.415
- 0.418
- 0.361
- 0.391
- 0.376
- 0.411
- 0.368
- 0.415
- 0.363
- 0.375
- 0.387
- 0.386
- 0.397
- 0.378
- 0.392
- 0.366
- 0.392
- 0.365
- 0.383
- 0.392
- 0.438
- 0.38
- 0.381
- 0.394
- 0.385
- 0.402
- 0.394
- 0.409
- 0.429
- 0.384
- 0.389
- 0.391
- 0.422
- 0.411
- 0.39
- 0.405
- 0.439
- 0.393
- 0.386
- 0.418
- 0.411
- 0.44
- 0.403
- 0.387
- 0.387
train_loss:
- 4.23
- 3.758
- 3.503
- 3.327
- 3.19
- 3.087
- 2.968
- 2.885
- 2.783
- 2.687
- 2.602
- 2.558
- 2.476
- 2.439
- 2.361
- 2.287
- 2.228
- 2.181
- 2.134
- 2.065
- 2.023
- 1.986
- 1.939
- 1.885
- 1.82
- 1.775
- 1.75
- 1.678
- 1.659
- 1.625
- 1.568
- 1.518
- 1.471
- 1.443
- 1.448
- 1.412
- 1.381
- 1.31
- 1.28
- 1.261
- 1.238
- 1.212
- 1.182
- 1.134
- 1.139
- 1.065
- 1.039
- 1.019
- 1.009
- 0.974
- 0.924
- 0.939
- 0.879
- 0.879
- 0.856
- 0.822
- 0.804
- 0.808
- 0.789
- 0.733
- 0.751
- 0.696
- 0.707
- 0.678
- 0.642
- 0.641
- 0.595
- 0.612
- 0.577
- 0.589
- 0.57
- 0.54
- 0.524
- 0.516
- 0.52
- 0.486
- 0.474
- 0.474
- 0.453
- 0.436
- 0.435
- 0.409
- 0.418
- 0.412
- 0.399
- 0.381
- 0.371
- 0.363
- 0.347
- 0.347
- 0.327
- 0.328
- 0.316
- 0.316
- 0.321
- 0.303
- 0.295
- 0.283
- 0.28
- 0.275
unequal: 0
verbose: 1
