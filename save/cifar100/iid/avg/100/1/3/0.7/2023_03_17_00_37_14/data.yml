avg_train_accuracy: 0.428
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0983
- 0.1412
- 0.166
- 0.1883
- 0.2057
- 0.2172
- 0.2327
- 0.2444
- 0.2539
- 0.2624
- 0.271
- 0.2735
- 0.2863
- 0.2916
- 0.2955
- 0.3035
- 0.3074
- 0.313
- 0.3194
- 0.3244
- 0.3278
- 0.3348
- 0.3364
- 0.3416
- 0.3449
- 0.3462
- 0.3506
- 0.3565
- 0.3582
- 0.3608
- 0.3589
- 0.3666
- 0.3688
- 0.3703
- 0.3703
- 0.3751
- 0.3758
- 0.3801
- 0.383
- 0.3852
- 0.3863
- 0.3902
- 0.3886
- 0.3888
- 0.395
- 0.395
- 0.3971
- 0.397
- 0.3982
- 0.4005
- 0.4016
- 0.4056
- 0.4083
- 0.4044
- 0.4054
- 0.4067
- 0.4139
- 0.4129
- 0.4122
- 0.4151
- 0.4169
- 0.4162
- 0.4178
- 0.4189
- 0.4152
- 0.4184
- 0.4226
- 0.4207
- 0.4201
- 0.4203
- 0.4226
- 0.4234
- 0.4223
- 0.4253
- 0.427
- 0.4235
- 0.4252
- 0.4251
- 0.4279
- 0.428
- 0.4288
- 0.4264
- 0.4288
- 0.4284
- 0.4304
- 0.4297
- 0.4296
- 0.4269
- 0.432
- 0.4307
- 0.4279
- 0.4317
- 0.4307
- 0.4326
- 0.4342
- 0.4313
- 0.4311
- 0.4317
- 0.4353
- 0.4346
test_loss_list:
- 1.65021710395813
- 1.5256314706802367
- 1.4523870706558228
- 1.3992020344734193
- 1.3612338209152222
- 1.3285821723937987
- 1.2998222780227662
- 1.271428301334381
- 1.2466679215431213
- 1.2277342104911804
- 1.20763986825943
- 1.190491530895233
- 1.175536985397339
- 1.1598726296424866
- 1.1464015126228333
- 1.1325065636634826
- 1.1214977812767029
- 1.1110390257835387
- 1.1013110423088073
- 1.0880215978622436
- 1.0777258157730103
- 1.0674015474319458
- 1.0592071533203125
- 1.0494971370697022
- 1.0420024251937867
- 1.0332753014564515
- 1.028217294216156
- 1.0188681173324585
- 1.0113357853889466
- 1.0056144738197326
- 1.0010367465019225
- 0.994855363368988
- 0.9888349437713623
- 0.9854480671882629
- 0.9814840400218964
- 0.9757374501228333
- 0.9707945966720581
- 0.9693108415603637
- 0.9634110641479492
- 0.9609137499332427
- 0.9594111263751983
- 0.957468581199646
- 0.9531187498569489
- 0.9533957827091217
- 0.9512333440780639
- 0.9471334505081177
- 0.9440760219097137
- 0.9423721027374268
- 0.9451173317432403
- 0.9408787250518799
- 0.9360703206062317
- 0.932762622833252
- 0.9331794321537018
- 0.933550580739975
- 0.9312739288806915
- 0.9303653860092163
- 0.9271187567710877
- 0.9303874063491822
- 0.9274744808673858
- 0.9268548429012299
- 0.9253999507427215
- 0.9264109778404236
- 0.9250765776634217
- 0.924605518579483
- 0.9259610652923584
- 0.926117285490036
- 0.923316798210144
- 0.9260002171993256
- 0.9244618797302246
- 0.9251374864578247
- 0.9244765317440033
- 0.9226164579391479
- 0.9251316368579865
- 0.9254011654853821
- 0.9253743278980255
- 0.9275590133666992
- 0.9256599450111389
- 0.9301173734664917
- 0.9298849260807037
- 0.9267768347263337
- 0.9264004337787628
- 0.9298445010185241
- 0.9297259187698365
- 0.9261349928379059
- 0.9292898726463318
- 0.9304802942276001
- 0.9321786165237427
- 0.931299661397934
- 0.932469596862793
- 0.9354246008396149
- 0.9361553752422332
- 0.9343554139137268
- 0.9391266429424285
- 0.9382470691204071
- 0.9376912629604339
- 0.9402628755569458
- 0.9387767887115479
- 0.9400794458389282
- 0.9400263547897338
- 0.9383692348003387
train_accuracy:
- 0.086
- 0.141
- 0.148
- 0.183
- 0.192
- 0.184
- 0.214
- 0.208
- 0.218
- 0.244
- 0.229
- 0.25
- 0.256
- 0.256
- 0.248
- 0.267
- 0.257
- 0.281
- 0.289
- 0.288
- 0.281
- 0.314
- 0.294
- 0.304
- 0.312
- 0.305
- 0.342
- 0.337
- 0.331
- 0.337
- 0.348
- 0.333
- 0.33
- 0.352
- 0.346
- 0.343
- 0.354
- 0.336
- 0.359
- 0.358
- 0.347
- 0.347
- 0.344
- 0.386
- 0.351
- 0.364
- 0.352
- 0.384
- 0.353
- 0.362
- 0.379
- 0.363
- 0.366
- 0.408
- 0.416
- 0.371
- 0.414
- 0.391
- 0.409
- 0.383
- 0.375
- 0.383
- 0.397
- 0.389
- 0.406
- 0.381
- 0.402
- 0.394
- 0.405
- 0.369
- 0.388
- 0.414
- 0.43
- 0.413
- 0.432
- 0.368
- 0.38
- 0.408
- 0.404
- 0.397
- 0.398
- 0.398
- 0.407
- 0.393
- 0.424
- 0.38
- 0.379
- 0.41
- 0.384
- 0.416
- 0.413
- 0.407
- 0.382
- 0.406
- 0.403
- 0.406
- 0.407
- 0.436
- 0.379
- 0.428
train_loss:
- 4.258
- 3.761
- 3.502
- 3.34
- 3.193
- 3.088
- 2.976
- 2.9
- 2.816
- 2.722
- 2.646
- 2.587
- 2.508
- 2.454
- 2.374
- 2.343
- 2.262
- 2.231
- 2.151
- 2.131
- 2.053
- 2.011
- 1.967
- 1.91
- 1.886
- 1.844
- 1.775
- 1.75
- 1.683
- 1.67
- 1.618
- 1.582
- 1.56
- 1.516
- 1.481
- 1.418
- 1.406
- 1.364
- 1.338
- 1.289
- 1.285
- 1.236
- 1.219
- 1.184
- 1.146
- 1.127
- 1.084
- 1.068
- 1.035
- 1.01
- 0.988
- 0.948
- 0.946
- 0.896
- 0.89
- 0.859
- 0.855
- 0.831
- 0.787
- 0.782
- 0.764
- 0.749
- 0.719
- 0.705
- 0.681
- 0.646
- 0.659
- 0.625
- 0.619
- 0.597
- 0.586
- 0.55
- 0.569
- 0.532
- 0.525
- 0.501
- 0.492
- 0.482
- 0.485
- 0.458
- 0.453
- 0.441
- 0.416
- 0.425
- 0.411
- 0.382
- 0.392
- 0.365
- 0.376
- 0.354
- 0.347
- 0.345
- 0.344
- 0.316
- 0.306
- 0.316
- 0.288
- 0.298
- 0.298
- 0.299
unequal: 0
verbose: 1
