avg_train_accuracy: 0.408
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0942
- 0.1394
- 0.1647
- 0.1828
- 0.2009
- 0.2185
- 0.2331
- 0.2436
- 0.2551
- 0.2631
- 0.2735
- 0.2795
- 0.2859
- 0.2972
- 0.3013
- 0.3099
- 0.3149
- 0.3193
- 0.3256
- 0.3309
- 0.336
- 0.3382
- 0.345
- 0.3457
- 0.3541
- 0.3583
- 0.3571
- 0.3624
- 0.3616
- 0.3659
- 0.3716
- 0.3739
- 0.3745
- 0.3799
- 0.3828
- 0.3866
- 0.3889
- 0.3845
- 0.3909
- 0.3926
- 0.3972
- 0.4002
- 0.3991
- 0.3993
- 0.4004
- 0.4032
- 0.4044
- 0.4063
- 0.4079
- 0.407
- 0.4097
- 0.4098
- 0.4114
- 0.4129
- 0.4131
- 0.4162
- 0.4139
- 0.414
- 0.419
- 0.4178
- 0.4196
- 0.4225
- 0.4215
- 0.4244
- 0.4243
- 0.4225
- 0.426
- 0.4255
- 0.4259
- 0.4268
- 0.4262
- 0.4286
- 0.4256
- 0.4289
- 0.43
- 0.4301
- 0.4295
- 0.4294
- 0.4312
- 0.4336
- 0.4308
- 0.432
- 0.4334
- 0.4311
- 0.4327
- 0.432
- 0.4324
- 0.4332
- 0.4388
- 0.4342
- 0.4355
- 0.4371
- 0.4367
- 0.4386
- 0.4391
- 0.4374
- 0.4379
- 0.4368
- 0.4386
- 0.438
test_loss_list:
- 1.6443965435028076
- 1.525593340396881
- 1.454446451663971
- 1.4048436403274536
- 1.3626110672950744
- 1.3289698910713197
- 1.2993356823921203
- 1.2731619095802307
- 1.247112855911255
- 1.2236246132850648
- 1.203872973918915
- 1.1857830882072449
- 1.1682353901863098
- 1.1542634463310242
- 1.1385225701332091
- 1.123586871623993
- 1.1104144358634949
- 1.0963906693458556
- 1.0855078387260437
- 1.0725915431976318
- 1.0607727813720702
- 1.057103726863861
- 1.0410918021202087
- 1.0356981110572816
- 1.0251071310043336
- 1.0189329648017884
- 1.0116695022583009
- 1.0040742373466491
- 1.0013446450233459
- 0.9911948490142822
- 0.9864955925941468
- 0.9804682207107543
- 0.9798055124282837
- 0.9683205032348633
- 0.9674827194213867
- 0.9600607895851135
- 0.9582187867164612
- 0.9568468642234802
- 0.9509227657318116
- 0.9481830143928528
- 0.9437508749961853
- 0.9404846239089966
- 0.939101779460907
- 0.9385210847854615
- 0.9373895764350891
- 0.9306297969818115
- 0.930023980140686
- 0.9306368756294251
- 0.9246951198577881
- 0.926507031917572
- 0.9222479152679444
- 0.9233589243888854
- 0.9212185525894165
- 0.9208238339424133
- 0.9179897308349609
- 0.9197513508796692
- 0.9202957224845886
- 0.9178583264350891
- 0.9144270205497742
- 0.9157195901870727
- 0.9141578769683838
- 0.9105995571613312
- 0.9139003658294678
- 0.9126419305801392
- 0.9138690519332886
- 0.9113806247711181
- 0.9112805724143982
- 0.9111915040016174
- 0.911332961320877
- 0.9094673788547516
- 0.9145026516914367
- 0.9124561131000519
- 0.9170071363449097
- 0.9100136256217957
- 0.9096697127819061
- 0.9116267585754394
- 0.9125219905376434
- 0.9163802111148834
- 0.9138876056671142
- 0.9124620628356933
- 0.9135174643993378
- 0.9153207063674926
- 0.9138440501689911
- 0.9174968206882477
- 0.9158884680271149
- 0.9174720060825348
- 0.9172358393669129
- 0.9161826527118683
- 0.912534841299057
- 0.9205435538291931
- 0.9191967129707337
- 0.9183323848247528
- 0.9183921194076539
- 0.9209150898456574
- 0.9179723906517029
- 0.9212608873844147
- 0.9217139208316802
- 0.9220148336887359
- 0.9227512800693511
- 0.9233917617797851
train_accuracy:
- 0.084
- 0.128
- 0.136
- 0.168
- 0.197
- 0.207
- 0.191
- 0.241
- 0.21
- 0.233
- 0.243
- 0.288
- 0.279
- 0.269
- 0.291
- 0.297
- 0.3
- 0.292
- 0.322
- 0.301
- 0.287
- 0.289
- 0.324
- 0.348
- 0.357
- 0.333
- 0.319
- 0.345
- 0.361
- 0.345
- 0.324
- 0.33
- 0.371
- 0.356
- 0.357
- 0.365
- 0.377
- 0.376
- 0.387
- 0.377
- 0.395
- 0.381
- 0.372
- 0.4
- 0.352
- 0.394
- 0.406
- 0.355
- 0.378
- 0.357
- 0.364
- 0.394
- 0.406
- 0.379
- 0.427
- 0.386
- 0.4
- 0.42
- 0.389
- 0.414
- 0.403
- 0.401
- 0.425
- 0.433
- 0.372
- 0.419
- 0.432
- 0.427
- 0.428
- 0.433
- 0.405
- 0.363
- 0.432
- 0.442
- 0.411
- 0.382
- 0.427
- 0.43
- 0.396
- 0.434
- 0.375
- 0.422
- 0.414
- 0.409
- 0.402
- 0.437
- 0.446
- 0.428
- 0.411
- 0.432
- 0.434
- 0.389
- 0.443
- 0.442
- 0.392
- 0.448
- 0.414
- 0.452
- 0.432
- 0.408
train_loss:
- 4.233
- 3.74
- 3.494
- 3.32
- 3.19
- 3.083
- 2.971
- 2.896
- 2.798
- 2.713
- 2.634
- 2.552
- 2.495
- 2.428
- 2.361
- 2.306
- 2.241
- 2.207
- 2.1
- 2.088
- 2.006
- 1.962
- 1.94
- 1.867
- 1.82
- 1.772
- 1.723
- 1.701
- 1.635
- 1.593
- 1.609
- 1.523
- 1.527
- 1.489
- 1.455
- 1.407
- 1.34
- 1.34
- 1.299
- 1.278
- 1.227
- 1.188
- 1.148
- 1.16
- 1.132
- 1.093
- 1.069
- 1.031
- 0.978
- 0.998
- 0.933
- 0.939
- 0.888
- 0.858
- 0.865
- 0.838
- 0.822
- 0.787
- 0.743
- 0.732
- 0.766
- 0.717
- 0.7
- 0.664
- 0.656
- 0.641
- 0.625
- 0.618
- 0.588
- 0.557
- 0.581
- 0.54
- 0.549
- 0.527
- 0.489
- 0.477
- 0.471
- 0.452
- 0.45
- 0.446
- 0.436
- 0.432
- 0.424
- 0.412
- 0.405
- 0.386
- 0.379
- 0.363
- 0.344
- 0.359
- 0.345
- 0.325
- 0.334
- 0.315
- 0.307
- 0.305
- 0.303
- 0.297
- 0.277
- 0.289
unequal: 0
verbose: 1
