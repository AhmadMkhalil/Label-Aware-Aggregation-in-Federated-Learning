avg_train_accuracy: 0.394
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0962
- 0.1371
- 0.1674
- 0.1876
- 0.2015
- 0.22
- 0.2325
- 0.2418
- 0.2551
- 0.2594
- 0.2722
- 0.2791
- 0.2847
- 0.2929
- 0.3019
- 0.3061
- 0.3129
- 0.3177
- 0.3239
- 0.3269
- 0.3325
- 0.338
- 0.3417
- 0.3462
- 0.3538
- 0.3509
- 0.3613
- 0.3629
- 0.368
- 0.3717
- 0.3752
- 0.3748
- 0.3791
- 0.3834
- 0.3858
- 0.3868
- 0.3895
- 0.3928
- 0.3913
- 0.397
- 0.3978
- 0.4
- 0.3995
- 0.4028
- 0.4033
- 0.404
- 0.4077
- 0.4081
- 0.4102
- 0.4118
- 0.4172
- 0.4133
- 0.4143
- 0.4127
- 0.4155
- 0.42
- 0.4183
- 0.419
- 0.4187
- 0.4207
- 0.4223
- 0.4237
- 0.4269
- 0.424
- 0.4244
- 0.4272
- 0.4256
- 0.4265
- 0.4267
- 0.4284
- 0.4282
- 0.4321
- 0.4325
- 0.4341
- 0.4304
- 0.4294
- 0.4344
- 0.4342
- 0.437
- 0.4298
- 0.4325
- 0.4355
- 0.4358
- 0.4364
- 0.4348
- 0.4384
- 0.4402
- 0.439
- 0.4399
- 0.4345
- 0.4366
- 0.4367
- 0.4385
- 0.4383
- 0.4384
- 0.4408
- 0.4407
- 0.441
- 0.4419
- 0.4428
test_loss_list:
- 1.6499134588241577
- 1.5302263140678405
- 1.4547516131401061
- 1.4025480699539186
- 1.3618365001678467
- 1.3267077970504761
- 1.2976872730255127
- 1.2729605913162232
- 1.249924988746643
- 1.228066644668579
- 1.2063302516937255
- 1.1885421991348266
- 1.17231098651886
- 1.1564780616760253
- 1.1408057355880736
- 1.1286423516273498
- 1.1129213237762452
- 1.100505886077881
- 1.0879745936393739
- 1.0773620748519896
- 1.0646256303787232
- 1.0539493989944457
- 1.0442690539360047
- 1.035031054019928
- 1.0258238554000854
- 1.0237279319763184
- 1.0093073105812074
- 1.0026937556266784
- 0.9950331306457519
- 0.9921052289009095
- 0.9841010451316834
- 0.9825471806526184
- 0.9751550912857055
- 0.9684489488601684
- 0.9691577339172364
- 0.96071359872818
- 0.9564004039764404
- 0.9539492130279541
- 0.9551576042175293
- 0.9465538930892944
- 0.9425828051567078
- 0.9387656021118164
- 0.9375088429450988
- 0.9350083231925964
- 0.9321058249473572
- 0.9291150999069214
- 0.9275780487060546
- 0.9263508868217468
- 0.9257409548759461
- 0.9206976103782654
- 0.9201049733161927
- 0.9194989395141602
- 0.9167184400558471
- 0.91853475689888
- 0.9168662989139557
- 0.9145289576053619
- 0.9131475389003754
- 0.913696037530899
- 0.9128580713272094
- 0.9125653409957886
- 0.9130190813541412
- 0.9106287670135498
- 0.9086436128616333
- 0.9060158956050873
- 0.91041570186615
- 0.9059619319438934
- 0.9115838718414306
- 0.9058976006507874
- 0.9061358785629272
- 0.9062658298015595
- 0.9086380112171173
- 0.9086275851726532
- 0.9074956965446472
- 0.9062216889858246
- 0.9111558902263641
- 0.9092321848869324
- 0.9074301064014435
- 0.9083718597888947
- 0.9078690421581268
- 0.9102821409702301
- 0.9103971099853516
- 0.9098873114585877
- 0.9098280227184296
- 0.9104966223239899
- 0.911854019165039
- 0.9131492459774018
- 0.9115737509727478
- 0.9114299190044403
- 0.9118247866630554
- 0.9161149406433106
- 0.9158678340911866
- 0.915919280052185
- 0.9134283185005188
- 0.9156268429756165
- 0.9179496049880982
- 0.9165743362903594
- 0.9160252666473389
- 0.9193013930320739
- 0.9199036598205567
- 0.9187199020385742
train_accuracy:
- 0.091
- 0.117
- 0.153
- 0.151
- 0.192
- 0.185
- 0.216
- 0.206
- 0.219
- 0.223
- 0.244
- 0.264
- 0.256
- 0.267
- 0.247
- 0.272
- 0.275
- 0.303
- 0.289
- 0.31
- 0.312
- 0.3
- 0.329
- 0.344
- 0.343
- 0.327
- 0.276
- 0.339
- 0.309
- 0.346
- 0.344
- 0.355
- 0.315
- 0.354
- 0.348
- 0.317
- 0.357
- 0.365
- 0.369
- 0.373
- 0.315
- 0.338
- 0.328
- 0.365
- 0.376
- 0.375
- 0.364
- 0.379
- 0.372
- 0.38
- 0.409
- 0.338
- 0.356
- 0.376
- 0.358
- 0.382
- 0.386
- 0.346
- 0.372
- 0.389
- 0.398
- 0.398
- 0.379
- 0.353
- 0.408
- 0.386
- 0.426
- 0.393
- 0.389
- 0.384
- 0.391
- 0.38
- 0.382
- 0.365
- 0.421
- 0.419
- 0.4
- 0.398
- 0.388
- 0.385
- 0.399
- 0.399
- 0.369
- 0.39
- 0.401
- 0.39
- 0.425
- 0.42
- 0.416
- 0.405
- 0.392
- 0.397
- 0.432
- 0.398
- 0.427
- 0.367
- 0.408
- 0.423
- 0.435
- 0.394
train_loss:
- 4.238
- 3.752
- 3.508
- 3.347
- 3.185
- 3.078
- 2.988
- 2.877
- 2.786
- 2.73
- 2.642
- 2.574
- 2.485
- 2.448
- 2.402
- 2.301
- 2.235
- 2.219
- 2.149
- 2.091
- 2.047
- 1.991
- 1.938
- 1.896
- 1.868
- 1.789
- 1.771
- 1.715
- 1.701
- 1.642
- 1.602
- 1.545
- 1.543
- 1.477
- 1.424
- 1.431
- 1.378
- 1.338
- 1.319
- 1.298
- 1.286
- 1.228
- 1.184
- 1.157
- 1.141
- 1.119
- 1.073
- 1.06
- 1.047
- 1.017
- 0.978
- 0.941
- 0.946
- 0.907
- 0.884
- 0.862
- 0.84
- 0.8
- 0.772
- 0.765
- 0.753
- 0.748
- 0.729
- 0.7
- 0.679
- 0.661
- 0.648
- 0.621
- 0.605
- 0.604
- 0.561
- 0.558
- 0.561
- 0.543
- 0.514
- 0.497
- 0.501
- 0.484
- 0.455
- 0.441
- 0.426
- 0.441
- 0.424
- 0.414
- 0.406
- 0.401
- 0.377
- 0.372
- 0.389
- 0.359
- 0.339
- 0.333
- 0.345
- 0.325
- 0.317
- 0.317
- 0.304
- 0.298
- 0.287
- 0.281
unequal: 0
verbose: 1
