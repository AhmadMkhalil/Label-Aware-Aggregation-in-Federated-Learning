avg_train_accuracy: 0.379
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0951
- 0.1394
- 0.1663
- 0.1867
- 0.2025
- 0.2194
- 0.2318
- 0.2406
- 0.2507
- 0.2628
- 0.2724
- 0.2794
- 0.2854
- 0.2927
- 0.3013
- 0.3051
- 0.3127
- 0.3203
- 0.3224
- 0.3287
- 0.3332
- 0.3427
- 0.3438
- 0.3469
- 0.3508
- 0.3514
- 0.3606
- 0.3646
- 0.3653
- 0.3713
- 0.3719
- 0.3779
- 0.3807
- 0.3821
- 0.3879
- 0.3902
- 0.3934
- 0.3917
- 0.3945
- 0.3981
- 0.3975
- 0.4031
- 0.4017
- 0.4005
- 0.4042
- 0.4066
- 0.4092
- 0.4055
- 0.4076
- 0.4061
- 0.4055
- 0.4108
- 0.4124
- 0.4158
- 0.4138
- 0.4169
- 0.4188
- 0.4174
- 0.4194
- 0.4205
- 0.4212
- 0.4202
- 0.4218
- 0.4214
- 0.4206
- 0.4217
- 0.4254
- 0.423
- 0.4225
- 0.4232
- 0.4248
- 0.4266
- 0.4244
- 0.4243
- 0.4268
- 0.4257
- 0.4273
- 0.4275
- 0.4256
- 0.4284
- 0.4301
- 0.426
- 0.4271
- 0.4305
- 0.432
- 0.4299
- 0.4326
- 0.4295
- 0.4298
- 0.4327
- 0.432
- 0.4315
- 0.4289
- 0.4288
- 0.4306
- 0.4323
- 0.4337
- 0.4329
- 0.4321
- 0.4336
test_loss_list:
- 1.648187608718872
- 1.530521194934845
- 1.4574623823165893
- 1.4055864882469178
- 1.3661505126953124
- 1.3304691123962402
- 1.3016267275810243
- 1.2751032710075378
- 1.2513185930252075
- 1.2296431279182434
- 1.2077250027656554
- 1.1894870901107788
- 1.1739755463600159
- 1.1556933116912842
- 1.1401118016242981
- 1.1277458548545838
- 1.1131049799919128
- 1.099468038082123
- 1.0895032501220703
- 1.077983386516571
- 1.064801652431488
- 1.0542825055122376
- 1.0469737005233766
- 1.0403396391868591
- 1.0310066652297973
- 1.0233873176574706
- 1.0159216332435608
- 1.0045130920410157
- 1.0008926057815553
- 0.9940105986595154
- 0.9894405221939087
- 0.981967899799347
- 0.9811035847663879
- 0.9745473456382752
- 0.9685912585258484
- 0.9653017807006836
- 0.9617760896682739
- 0.9603732681274414
- 0.9552379560470581
- 0.9493115437030792
- 0.9498353695869446
- 0.9455511140823364
- 0.9424498224258423
- 0.9392587041854858
- 0.939150652885437
- 0.9371974349021912
- 0.9317264032363891
- 0.9358670496940613
- 0.9317618155479431
- 0.9316736769676208
- 0.9319546258449555
- 0.9270528435707093
- 0.9263694763183594
- 0.9231162428855896
- 0.9243374228477478
- 0.9212287175655365
- 0.9243223154544831
- 0.9233867144584655
- 0.9240635001659393
- 0.9214215052127838
- 0.9189034688472748
- 0.9180537974834442
- 0.9180591404438019
- 0.9207953035831451
- 0.9173566102981567
- 0.9185338056087494
- 0.9199080610275269
- 0.9164583718776703
- 0.9179645645618438
- 0.9203995954990387
- 0.9185044193267822
- 0.9194368541240692
- 0.9198031044006347
- 0.9176651632785797
- 0.9197361373901367
- 0.9187810564041138
- 0.922893625497818
- 0.9188480579853058
- 0.9232518792152404
- 0.9219565641880035
- 0.9227559220790863
- 0.9231120252609253
- 0.9237121319770814
- 0.9216964793205261
- 0.9224214088916779
- 0.9242433309555054
- 0.9254930758476257
- 0.9239597189426422
- 0.928334231376648
- 0.9268161702156067
- 0.9281546747684479
- 0.9278960466384888
- 0.9305266690254211
- 0.9298311269283295
- 0.9293036580085754
- 0.933365877866745
- 0.9335882925987243
- 0.9321144723892212
- 0.9344946587085724
- 0.9348673176765442
train_accuracy:
- 0.09
- 0.116
- 0.151
- 0.18
- 0.186
- 0.194
- 0.219
- 0.195
- 0.269
- 0.227
- 0.241
- 0.241
- 0.249
- 0.27
- 0.264
- 0.268
- 0.321
- 0.281
- 0.27
- 0.317
- 0.287
- 0.296
- 0.307
- 0.292
- 0.297
- 0.322
- 0.34
- 0.337
- 0.374
- 0.351
- 0.354
- 0.345
- 0.319
- 0.352
- 0.334
- 0.345
- 0.39
- 0.391
- 0.356
- 0.368
- 0.338
- 0.357
- 0.411
- 0.342
- 0.376
- 0.381
- 0.379
- 0.409
- 0.394
- 0.38
- 0.385
- 0.384
- 0.394
- 0.399
- 0.39
- 0.395
- 0.395
- 0.391
- 0.401
- 0.424
- 0.423
- 0.406
- 0.4
- 0.4
- 0.431
- 0.412
- 0.393
- 0.403
- 0.365
- 0.414
- 0.378
- 0.412
- 0.407
- 0.393
- 0.413
- 0.395
- 0.402
- 0.361
- 0.406
- 0.374
- 0.412
- 0.366
- 0.413
- 0.408
- 0.38
- 0.412
- 0.421
- 0.428
- 0.433
- 0.378
- 0.423
- 0.416
- 0.408
- 0.372
- 0.43
- 0.376
- 0.441
- 0.383
- 0.418
- 0.379
train_loss:
- 4.238
- 3.771
- 3.527
- 3.346
- 3.209
- 3.098
- 2.981
- 2.906
- 2.797
- 2.726
- 2.657
- 2.577
- 2.493
- 2.492
- 2.407
- 2.325
- 2.265
- 2.192
- 2.117
- 2.085
- 2.037
- 2.002
- 1.958
- 1.9
- 1.847
- 1.796
- 1.774
- 1.745
- 1.656
- 1.652
- 1.562
- 1.595
- 1.567
- 1.482
- 1.462
- 1.434
- 1.374
- 1.367
- 1.305
- 1.31
- 1.241
- 1.218
- 1.191
- 1.19
- 1.116
- 1.071
- 1.089
- 1.054
- 1.029
- 1.015
- 0.969
- 0.937
- 0.897
- 0.888
- 0.848
- 0.863
- 0.809
- 0.807
- 0.774
- 0.76
- 0.765
- 0.775
- 0.701
- 0.7
- 0.678
- 0.663
- 0.649
- 0.613
- 0.599
- 0.571
- 0.598
- 0.543
- 0.549
- 0.55
- 0.516
- 0.507
- 0.477
- 0.506
- 0.463
- 0.44
- 0.444
- 0.443
- 0.42
- 0.401
- 0.396
- 0.394
- 0.388
- 0.378
- 0.367
- 0.355
- 0.341
- 0.336
- 0.341
- 0.322
- 0.326
- 0.306
- 0.298
- 0.303
- 0.277
- 0.28
unequal: 0
verbose: 1
