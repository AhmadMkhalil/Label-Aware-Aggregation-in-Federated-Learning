avg_train_accuracy: 0.4
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1092
- 0.1506
- 0.1752
- 0.1925
- 0.2093
- 0.2249
- 0.2404
- 0.2502
- 0.2599
- 0.2694
- 0.2768
- 0.2865
- 0.2938
- 0.2986
- 0.3041
- 0.3141
- 0.3204
- 0.3262
- 0.3285
- 0.331
- 0.341
- 0.3425
- 0.3481
- 0.3515
- 0.3544
- 0.3611
- 0.3617
- 0.3605
- 0.368
- 0.3704
- 0.3744
- 0.3811
- 0.3809
- 0.3806
- 0.3827
- 0.3851
- 0.3869
- 0.3883
- 0.3904
- 0.3937
- 0.396
- 0.3981
- 0.399
- 0.4013
- 0.4052
- 0.4039
- 0.4068
- 0.4095
- 0.4108
- 0.4096
- 0.4094
- 0.4094
- 0.4124
- 0.4149
- 0.4139
- 0.4159
- 0.4163
- 0.4201
- 0.4185
- 0.4175
- 0.4209
- 0.4214
- 0.4216
- 0.4231
- 0.4241
- 0.4247
- 0.4252
- 0.4253
- 0.4238
- 0.4284
- 0.4303
- 0.4234
- 0.4275
- 0.4291
- 0.427
- 0.4296
- 0.4302
- 0.4282
- 0.4313
- 0.4317
- 0.4314
- 0.4333
- 0.4332
- 0.4339
- 0.4317
- 0.4317
- 0.4331
- 0.4335
- 0.4334
- 0.4366
- 0.4345
- 0.4386
- 0.4368
- 0.4328
- 0.4367
- 0.4348
- 0.4374
- 0.4379
- 0.436
- 0.4362
test_loss_list:
- 1.623399384021759
- 1.5038411903381348
- 1.439177324771881
- 1.3892032933235168
- 1.3511118030548095
- 1.3161676931381225
- 1.2885162615776062
- 1.264114797115326
- 1.2397471785545349
- 1.2183680391311646
- 1.1973180103302001
- 1.1785853099822998
- 1.1615105319023131
- 1.1484324502944947
- 1.1315831422805787
- 1.11748610496521
- 1.1043481492996217
- 1.091905312538147
- 1.0811903500556945
- 1.071498634815216
- 1.0591946601867677
- 1.0502219033241271
- 1.0385768747329711
- 1.031121335029602
- 1.0259389829635621
- 1.0142396807670593
- 1.0100158524513245
- 1.0081896376609802
- 1.0004422163963318
- 0.9941593980789185
- 0.9838828706741333
- 0.9798294544219971
- 0.9732700252532959
- 0.9719961524009705
- 0.9675450658798218
- 0.9658637285232544
- 0.9622915506362915
- 0.9580428886413574
- 0.9550419116020202
- 0.9491182684898376
- 0.947607421875
- 0.9445816922187805
- 0.9445261979103088
- 0.9416209125518799
- 0.9362511539459228
- 0.9366703605651856
- 0.9344152355194092
- 0.9312425303459168
- 0.9277202010154724
- 0.9281809258460999
- 0.9302235698699951
- 0.9246801924705506
- 0.9226541495323182
- 0.9227572894096374
- 0.9205932068824768
- 0.9182960700988769
- 0.9220606207847595
- 0.9185536623001098
- 0.9152909040451049
- 0.9204099369049072
- 0.9186646294593811
- 0.9169125008583069
- 0.9191621685028076
- 0.9198407983779907
- 0.9176995205879211
- 0.9143985724449157
- 0.9152081751823425
- 0.916509165763855
- 0.9148087215423584
- 0.9131077480316162
- 0.914382381439209
- 0.9216232752799988
- 0.9158469080924988
- 0.9197382616996765
- 0.9155267763137818
- 0.9200262451171874
- 0.9208596110343933
- 0.9207869577407837
- 0.9188408470153808
- 0.918441071510315
- 0.9194024586677552
- 0.9198625946044922
- 0.9190041899681092
- 0.919577271938324
- 0.9226951265335083
- 0.9239550518989563
- 0.926140513420105
- 0.9223610639572144
- 0.9267209076881409
- 0.9201742684841157
- 0.9254850602149963
- 0.925920238494873
- 0.925700557231903
- 0.9284189772605896
- 0.9278089499473572
- 0.9324989461898804
- 0.9292520213127137
- 0.9311775922775268
- 0.9295468163490296
- 0.9305005049705506
train_accuracy:
- 0.092
- 0.119
- 0.17
- 0.175
- 0.202
- 0.215
- 0.195
- 0.189
- 0.267
- 0.205
- 0.25
- 0.234
- 0.215
- 0.297
- 0.241
- 0.274
- 0.277
- 0.273
- 0.28
- 0.275
- 0.322
- 0.298
- 0.326
- 0.33
- 0.309
- 0.339
- 0.32
- 0.288
- 0.344
- 0.295
- 0.288
- 0.31
- 0.339
- 0.319
- 0.321
- 0.348
- 0.34
- 0.339
- 0.357
- 0.362
- 0.359
- 0.358
- 0.409
- 0.373
- 0.41
- 0.36
- 0.414
- 0.385
- 0.379
- 0.365
- 0.422
- 0.357
- 0.343
- 0.367
- 0.369
- 0.384
- 0.393
- 0.372
- 0.379
- 0.391
- 0.428
- 0.391
- 0.388
- 0.435
- 0.378
- 0.38
- 0.351
- 0.421
- 0.402
- 0.402
- 0.397
- 0.376
- 0.403
- 0.391
- 0.398
- 0.364
- 0.408
- 0.374
- 0.398
- 0.405
- 0.379
- 0.398
- 0.379
- 0.39
- 0.379
- 0.383
- 0.403
- 0.404
- 0.425
- 0.408
- 0.439
- 0.393
- 0.368
- 0.395
- 0.406
- 0.416
- 0.414
- 0.372
- 0.402
- 0.4
train_loss:
- 4.175
- 3.695
- 3.456
- 3.293
- 3.155
- 3.035
- 2.924
- 2.841
- 2.752
- 2.664
- 2.617
- 2.508
- 2.459
- 2.359
- 2.316
- 2.29
- 2.221
- 2.158
- 2.088
- 2.057
- 1.978
- 1.952
- 1.901
- 1.831
- 1.804
- 1.759
- 1.687
- 1.669
- 1.63
- 1.584
- 1.565
- 1.518
- 1.495
- 1.426
- 1.387
- 1.382
- 1.333
- 1.317
- 1.268
- 1.232
- 1.205
- 1.184
- 1.117
- 1.119
- 1.083
- 1.054
- 1.034
- 1.02
- 0.99
- 0.948
- 0.917
- 0.903
- 0.872
- 0.858
- 0.834
- 0.811
- 0.794
- 0.784
- 0.75
- 0.728
- 0.725
- 0.684
- 0.665
- 0.63
- 0.618
- 0.645
- 0.612
- 0.57
- 0.581
- 0.548
- 0.544
- 0.506
- 0.526
- 0.502
- 0.488
- 0.465
- 0.459
- 0.437
- 0.452
- 0.432
- 0.412
- 0.399
- 0.409
- 0.376
- 0.357
- 0.338
- 0.357
- 0.349
- 0.343
- 0.354
- 0.327
- 0.333
- 0.31
- 0.299
- 0.312
- 0.283
- 0.294
- 0.287
- 0.266
- 0.282
unequal: 0
verbose: 1
