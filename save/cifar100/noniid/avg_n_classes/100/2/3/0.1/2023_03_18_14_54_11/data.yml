avg_train_accuracy: 0.224
avg_train_loss: 0.014
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0434
- 0.0853
- 0.1043
- 0.1212
- 0.1227
- 0.1404
- 0.1508
- 0.0174
- 0.1409
- 0.155
- 0.0183
- 0.0186
- 0.1626
- 0.0146
- 0.1616
- 0.1694
- 0.1873
- 0.1873
- 0.0193
- 0.1863
- 0.1941
- 0.2003
- 0.2026
- 0.018
- 0.2065
- 0.2122
- 0.2145
- 0.2183
- 0.2111
- 0.0184
- 0.2213
- 0.2202
- 0.2279
- 0.0187
- 0.2303
- 0.2226
- 0.0149
- 0.2274
- 0.2325
- 0.2348
- 0.0151
- 0.0192
- 0.014
- 0.2284
- 0.2333
- 0.0161
- 0.0153
- 0.2306
- 0.0191
- 0.0185
- 0.0188
- 0.2386
- 0.2392
- 0.0144
- 0.238
- 0.2437
- 0.2401
- 0.2477
- 0.2443
- 0.0194
- 0.0193
- 0.2535
- 0.2576
- 0.016
- 0.2534
- 0.2581
- 0.0189
- 0.2544
- 0.2564
- 0.2673
- 0.0152
- 0.2571
- 0.0201
- 0.257
- 0.264
- 0.0156
- 0.2692
- 0.2624
- 0.0195
- 0.2617
- 0.2635
- 0.0202
- 0.0196
- 0.2686
- 0.2681
- 0.268
- 0.0166
- 0.0195
- 0.016
- 0.266
- 0.2675
- 0.2677
- 0.2699
- 0.2707
- 0.2692
- 0.2671
- 0.0206
- 0.0183
- 0.0165
- 0.2772
test_loss_list:
- 1.7982422494888306
- 1.712957396507263
- 1.6678822255134582
- 1.6307675409317017
- 1.627584195137024
- 1.603684184551239
- 1.5824538350105286
- 4.620693807601929
- 1.592969958782196
- 1.5665405917167663
- 4.5296656513214115
- 4.514675207138062
- 1.5287511944770813
- 4.762363138198853
- 1.5318249940872193
- 1.5082854843139648
- 1.488346517086029
- 1.4902408957481383
- 4.52007266998291
- 1.4705404210090638
- 1.4639441204071044
- 1.4631313395500183
- 1.4553835606575012
- 4.48927604675293
- 1.4553215432167053
- 1.440495684146881
- 1.4318985509872437
- 1.442457525730133
- 1.4545460224151612
- 4.419177598953247
- 1.4207443237304687
- 1.4132495427131653
- 1.4149043035507203
- 4.322104606628418
- 1.4263714289665221
- 1.4156436276435853
- 4.4947622203826905
- 1.4179597854614259
- 1.3997732138633727
- 1.414702754020691
- 4.431884813308716
- 4.3520785999298095
- 4.467742166519165
- 1.3781038737297058
- 1.378957233428955
- 4.2859452438354495
- 4.421039848327637
- 1.3870874524116517
- 4.17139536857605
- 4.277944889068603
- 4.313341207504273
- 1.354146707057953
- 1.355457944869995
- 4.492081661224365
- 1.362917227745056
- 1.370674090385437
- 1.3687212657928467
- 1.3465023756027221
- 1.3637623119354247
- 4.169279375076294
- 4.400234794616699
- 1.3367671632766724
- 1.3353263521194458
- 4.206536083221436
- 1.3294929265975952
- 1.3296568274497986
- 4.026387891769409
- 1.3298119950294494
- 1.325493631362915
- 1.3305820274353026
- 4.360400009155273
- 1.3392262148857117
- 4.136935119628906
- 1.332689208984375
- 1.323204562664032
- 4.271531400680542
- 1.3116121649742127
- 1.3326105403900146
- 4.014703493118287
- 1.3262718749046325
- 1.328513309955597
- 3.888562068939209
- 3.9692060279846193
- 1.3158287334442138
- 1.3264394354820253
- 1.3239102053642273
- 4.195818634033203
- 4.282947645187378
- 4.481774253845215
- 1.3175059723854066
- 1.3229948735237123
- 1.3312450766563415
- 1.3309346890449525
- 1.3300160765647888
- 1.326681089401245
- 1.3365729761123657
- 3.9979551315307615
- 4.020597133636475
- 4.279453964233398
- 1.288670687675476
train_accuracy:
- 0.04
- 0.083
- 0.091
- 0.111
- 0.106
- 0.139
- 0.146
- 0.887
- 0.146
- 0.103
- 0.916
- 0.894
- 0.129
- 0.809
- 0.115
- 0.149
- 0.166
- 0.158
- 0.93
- 0.16
- 0.185
- 0.164
- 0.184
- 0.725
- 0.141
- 0.196
- 0.156
- 0.216
- 0.18
- 0.878
- 0.195
- 0.225
- 0.15
- 0.859
- 0.163
- 0.197
- 0.562
- 0.142
- 0.238
- 0.167
- 0.525
- 0.925
- 0.451
- 0.194
- 0.223
- 0.79
- 0.659
- 0.221
- 0.933
- 0.856
- 0.871
- 0.246
- 0.262
- 0.54
- 0.251
- 0.18
- 0.199
- 0.267
- 0.203
- 0.893
- 0.954
- 0.234
- 0.273
- 0.744
- 0.194
- 0.254
- 0.865
- 0.214
- 0.204
- 0.274
- 0.576
- 0.208
- 0.963
- 0.286
- 0.26
- 0.668
- 0.199
- 0.235
- 0.945
- 0.223
- 0.277
- 0.956
- 0.955
- 0.289
- 0.279
- 0.206
- 0.736
- 0.963
- 0.69
- 0.279
- 0.271
- 0.275
- 0.204
- 0.293
- 0.236
- 0.24
- 0.956
- 0.81
- 0.664
- 0.224
train_loss:
- 4.267
- 3.528
- 3.665
- 3.535
- 3.161
- 3.124
- 3.022
- 0.645
- 2.913
- 3.181
- 0.541
- 0.856
- 3.474
- 0.891
- 2.979
- 3.127
- 3.103
- 2.623
- 0.442
- 3.029
- 2.711
- 2.318
- 2.669
- 0.486
- 2.963
- 2.249
- 2.421
- 1.918
- 2.041
- 0.455
- 2.642
- 2.293
- 2.31
- 0.4
- 2.051
- 1.894
- 0.833
- 1.916
- 1.877
- 1.412
- 0.674
- 0.703
- 0.849
- 1.897
- 2.057
- 0.57
- 0.193
- 1.81
- 0.333
- 0.65
- 0.061
- 1.937
- 2.051
- 0.506
- 1.54
- 1.404
- 2.2
- 1.687
- 1.689
- 0.342
- 0.593
- 2.357
- 1.285
- 0.537
- 1.69
- 1.552
- 0.322
- 1.931
- 1.258
- 1.099
- 0.444
- 1.728
- 0.353
- 1.035
- 1.301
- 0.41
- 1.377
- 1.011
- 0.268
- 1.72
- 1.493
- 0.242
- 0.012
- 1.026
- 1.078
- 1.307
- 0.41
- 0.495
- 0.596
- 0.939
- 0.917
- 0.521
- 0.992
- 0.981
- 1.292
- 0.841
- 0.258
- 0.611
- 0.634
- 1.363
unequal: 0
verbose: 1
