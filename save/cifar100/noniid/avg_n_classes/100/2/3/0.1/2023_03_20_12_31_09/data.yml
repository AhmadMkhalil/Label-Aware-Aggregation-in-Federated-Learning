avg_train_accuracy: 0.293
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.034
- 0.0184
- 0.0147
- 0.0832
- 0.0191
- 0.0997
- 0.1181
- 0.114
- 0.0189
- 0.1215
- 0.138
- 0.1359
- 0.1502
- 0.1651
- 0.1602
- 0.1704
- 0.1717
- 0.0197
- 0.1773
- 0.0184
- 0.1815
- 0.182
- 0.1853
- 0.0192
- 0.1848
- 0.1828
- 0.0162
- 0.0158
- 0.1967
- 0.0192
- 0.1943
- 0.192
- 0.0193
- 0.2061
- 0.2094
- 0.0159
- 0.2119
- 0.2167
- 0.2213
- 0.2189
- 0.2226
- 0.2248
- 0.2201
- 0.0173
- 0.2216
- 0.2335
- 0.2326
- 0.0179
- 0.2375
- 0.2467
- 0.0194
- 0.2419
- 0.2442
- 0.248
- 0.2442
- 0.245
- 0.2425
- 0.2435
- 0.2568
- 0.2575
- 0.0176
- 0.0196
- 0.261
- 0.2593
- 0.2564
- 0.0197
- 0.2522
- 0.263
- 0.256
- 0.2618
- 0.0195
- 0.2559
- 0.2654
- 0.2597
- 0.0186
- 0.2573
- 0.2674
- 0.262
- 0.2661
- 0.0183
- 0.02
- 0.2763
- 0.0202
- 0.0198
- 0.2699
- 0.2755
- 0.0215
- 0.272
- 0.0201
- 0.2744
- 0.0212
- 0.2784
- 0.268
- 0.2703
- 0.274
- 0.2718
- 0.2675
- 0.273
- 0.2708
- 0.2714
test_loss_list:
- 1.816347041130066
- 4.577615594863891
- 4.568639421463013
- 1.7133652019500731
- 4.325399112701416
- 1.6780593156814576
- 1.6304149293899537
- 1.6316405892372132
- 4.462036018371582
- 1.61552752494812
- 1.5853358125686645
- 1.5697162055969238
- 1.5633059215545655
- 1.5363605737686157
- 1.552013223171234
- 1.5357981491088868
- 1.5155840039253234
- 4.62873291015625
- 1.5112069487571715
- 4.428103742599487
- 1.4894164991378784
- 1.4778060436248779
- 1.4919738745689393
- 4.415143384933471
- 1.4829521822929381
- 1.4981020855903626
- 4.353580217361451
- 4.531218776702881
- 1.457291603088379
- 4.302771844863892
- 1.4719708251953125
- 1.4864797019958496
- 4.361124277114868
- 1.4449240899085998
- 1.432172772884369
- 4.445158233642578
- 1.4164018368721008
- 1.415775966644287
- 1.409969584941864
- 1.420728464126587
- 1.4165039944648743
- 1.4118310141563415
- 1.424875829219818
- 4.296461000442505
- 1.400993993282318
- 1.3876429915428161
- 1.3943624210357666
- 4.4154043292999265
- 1.3929563307762145
- 1.3681331253051758
- 4.197268037796021
- 1.3689188170433044
- 1.3632811999320984
- 1.3612016463279724
- 1.362328338623047
- 1.3597347474098205
- 1.370184998512268
- 1.3775128793716431
- 1.35662424325943
- 1.3480912971496581
- 4.2313711547851565
- 4.31673906326294
- 1.3172983360290527
- 1.320743637084961
- 1.328748972415924
- 4.07527714729309
- 1.3225501132011415
- 1.3150502276420593
- 1.3343594455718994
- 1.3351055765151978
- 4.156685085296631
- 1.3379458642005921
- 1.320583825111389
- 1.3368130540847778
- 4.155265846252441
- 1.3229486918449402
- 1.3111884307861328
- 1.3343593192100525
- 1.3201805996894835
- 4.21552698135376
- 4.399286632537842
- 1.297928078174591
- 3.9783449077606203
- 4.405307035446167
- 1.2871033477783203
- 1.2942068982124328
- 3.7960076236724856
- 1.2914334869384765
- 4.02803331375122
- 1.2709154200553894
- 3.754603214263916
- 1.2756116580963135
- 1.3095235228538513
- 1.3182327437400818
- 1.3131006598472594
- 1.3141300940513612
- 1.3372569680213928
- 1.3145824623107911
- 1.3151723384857177
- 1.3284006190299988
train_accuracy:
- 0.039
- 0.865
- 0.838
- 0.104
- 0.898
- 0.071
- 0.133
- 0.124
- 0.929
- 0.114
- 0.138
- 0.148
- 0.148
- 0.153
- 0.15
- 0.171
- 0.165
- 0.965
- 0.166
- 0.845
- 0.166
- 0.193
- 0.186
- 0.936
- 0.177
- 0.182
- 0.702
- 0.666
- 0.208
- 0.946
- 0.205
- 0.212
- 0.953
- 0.209
- 0.221
- 0.626
- 0.223
- 0.223
- 0.225
- 0.227
- 0.219
- 0.219
- 0.238
- 0.754
- 0.234
- 0.245
- 0.241
- 0.833
- 0.239
- 0.292
- 0.947
- 0.233
- 0.263
- 0.25
- 0.271
- 0.254
- 0.241
- 0.267
- 0.278
- 0.281
- 0.869
- 0.955
- 0.25
- 0.271
- 0.316
- 0.879
- 0.271
- 0.289
- 0.283
- 0.304
- 0.935
- 0.262
- 0.267
- 0.286
- 0.898
- 0.265
- 0.285
- 0.279
- 0.259
- 0.746
- 0.993
- 0.332
- 0.948
- 0.988
- 0.312
- 0.278
- 0.951
- 0.274
- 0.984
- 0.284
- 0.972
- 0.275
- 0.274
- 0.264
- 0.273
- 0.279
- 0.264
- 0.259
- 0.285
- 0.293
train_loss:
- 4.306
- 0.528
- 1.105
- 4.257
- 0.5
- 4.086
- 3.568
- 3.517
- 0.512
- 3.364
- 3.109
- 3.327
- 3.198
- 2.804
- 2.33
- 3.112
- 2.913
- 0.488
- 2.52
- 0.506
- 3.262
- 2.782
- 2.27
- 0.443
- 2.83
- 2.138
- 0.771
- 0.285
- 2.458
- 0.386
- 2.015
- 1.451
- 0.36
- 2.375
- 2.622
- 0.631
- 2.831
- 2.134
- 2.176
- 1.541
- 1.866
- 1.826
- 1.337
- 0.54
- 2.766
- 1.737
- 2.16
- 0.453
- 1.908
- 2.507
- 0.4
- 2.387
- 1.389
- 1.509
- 1.773
- 1.794
- 1.818
- 1.456
- 2.172
- 1.345
- 0.465
- 0.738
- 1.608
- 1.307
- 1.715
- 0.38
- 1.307
- 1.12
- 0.844
- 1.416
- 0.338
- 0.989
- 1.529
- 0.639
- 0.419
- 0.687
- 0.991
- 0.633
- 1.311
- 0.351
- 0.649
- 1.566
- 0.305
- 0.542
- 0.951
- 1.171
- 0.255
- 1.832
- 0.259
- 1.553
- 0.254
- 1.256
- 0.69
- 0.484
- 1.042
- 1.291
- 0.828
- 0.649
- 0.757
- 0.779
unequal: 0
verbose: 1
