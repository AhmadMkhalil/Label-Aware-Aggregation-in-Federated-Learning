avg_train_accuracy: 0.29
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0467
- 0.0875
- 0.0177
- 0.0186
- 0.0196
- 0.0187
- 0.019
- 0.1057
- 0.1132
- 0.0196
- 0.0188
- 0.0196
- 0.0193
- 0.1156
- 0.0192
- 0.1286
- 0.0193
- 0.1433
- 0.1491
- 0.1443
- 0.158
- 0.0189
- 0.1576
- 0.158
- 0.1626
- 0.1712
- 0.1858
- 0.1882
- 0.1843
- 0.1911
- 0.1879
- 0.1936
- 0.2041
- 0.0198
- 0.0197
- 0.1955
- 0.2059
- 0.2014
- 0.0168
- 0.2068
- 0.2203
- 0.2239
- 0.0191
- 0.2222
- 0.2316
- 0.2249
- 0.2286
- 0.2271
- 0.0198
- 0.02
- 0.0183
- 0.019
- 0.2325
- 0.2311
- 0.2469
- 0.2396
- 0.0199
- 0.2424
- 0.0199
- 0.0198
- 0.2439
- 0.2509
- 0.2522
- 0.251
- 0.2567
- 0.2564
- 0.0198
- 0.2569
- 0.0187
- 0.0182
- 0.0189
- 0.019
- 0.2534
- 0.0185
- 0.0184
- 0.0186
- 0.2564
- 0.2569
- 0.0188
- 0.2608
- 0.0192
- 0.2519
- 0.2545
- 0.2527
- 0.02
- 0.2642
- 0.2625
- 0.0195
- 0.019
- 0.2626
- 0.2772
- 0.2701
- 0.2731
- 0.2762
- 0.0214
- 0.2777
- 0.2709
- 0.2701
- 0.2712
- 0.2742
test_loss_list:
- 1.7992814588546753
- 1.719402461051941
- 4.808858766555786
- 4.533646926879883
- 4.472577123641968
- 4.506491527557373
- 4.706701068878174
- 1.6564758968353273
- 1.6457713294029235
- 4.532443857192993
- 4.2297755718231205
- 4.43782301902771
- 4.351606693267822
- 1.5968026471138002
- 4.0409486293792725
- 1.5791399598121643
- 4.007109994888306
- 1.547663264274597
- 1.5488942074775696
- 1.5689789962768554
- 1.5432136392593383
- 4.031772356033326
- 1.545024435520172
- 1.5653059339523316
- 1.5285978293418885
- 1.5097401309013367
- 1.4808474969863892
- 1.476997594833374
- 1.4920141458511353
- 1.487700216770172
- 1.4863664436340331
- 1.4929134917259217
- 1.4650656819343566
- 4.476730823516846
- 4.566812763214111
- 1.4760651636123656
- 1.4568392777442931
- 1.4699103665351867
- 4.463257341384888
- 1.4407960724830629
- 1.4184047603607177
- 1.3989870047569275
- 3.9987394046783447
- 1.400597972869873
- 1.3865307879447937
- 1.401155333518982
- 1.3991582798957825
- 1.4197504377365113
- 4.51694953918457
- 4.564947357177735
- 4.256266031265259
- 3.954635009765625
- 1.3608166980743408
- 1.3775446486473084
- 1.3444116187095643
- 1.355057475566864
- 4.220353727340698
- 1.351249134540558
- 4.187906570434571
- 4.103152513504028
- 1.3408376622200011
- 1.332791645526886
- 1.3299024033546447
- 1.3436728715896606
- 1.347570035457611
- 1.3341064167022705
- 4.142504205703736
- 1.339731216430664
- 4.155794820785522
- 4.219501209259033
- 3.9672695064544676
- 3.9909528064727784
- 1.3379937076568604
- 4.070905714035034
- 4.135080232620239
- 4.178372964859009
- 1.3215786576271058
- 1.3154468607902527
- 4.012527837753296
- 1.3254416155815125
- 3.8278378677368163
- 1.3327839589118957
- 1.325610637664795
- 1.3356272888183593
- 3.9870590114593507
- 1.3008085989952087
- 1.3040986800193786
- 4.033154621124267
- 4.033844327926635
- 1.2910650372505188
- 1.2659388160705567
- 1.3008606791496278
- 1.2971036887168885
- 1.2927933859825134
- 3.7868882179260255
- 1.2742727494239807
- 1.3015766906738282
- 1.3029980492591857
- 1.319177303314209
- 1.3106959867477417
train_accuracy:
- 0.057
- 0.087
- 0.794
- 0.941
- 0.959
- 0.847
- 0.942
- 0.106
- 0.11
- 0.993
- 0.841
- 0.982
- 0.956
- 0.115
- 0.889
- 0.132
- 0.925
- 0.114
- 0.156
- 0.165
- 0.128
- 0.901
- 0.164
- 0.173
- 0.157
- 0.167
- 0.205
- 0.166
- 0.163
- 0.208
- 0.173
- 0.202
- 0.15
- 0.98
- 0.982
- 0.209
- 0.232
- 0.213
- 0.646
- 0.235
- 0.212
- 0.246
- 0.878
- 0.196
- 0.255
- 0.224
- 0.261
- 0.232
- 0.988
- 0.992
- 0.831
- 0.936
- 0.264
- 0.229
- 0.204
- 0.205
- 0.986
- 0.251
- 0.993
- 0.988
- 0.261
- 0.282
- 0.216
- 0.245
- 0.281
- 0.247
- 0.99
- 0.304
- 0.941
- 0.867
- 0.946
- 0.956
- 0.293
- 0.87
- 0.891
- 0.878
- 0.252
- 0.305
- 0.896
- 0.262
- 0.941
- 0.263
- 0.234
- 0.26
- 0.989
- 0.228
- 0.267
- 0.945
- 0.96
- 0.251
- 0.307
- 0.32
- 0.3
- 0.311
- 0.985
- 0.268
- 0.255
- 0.287
- 0.266
- 0.29
train_loss:
- 4.295
- 3.557
- 0.622
- 0.872
- 0.775
- 0.707
- 0.144
- 4.105
- 3.584
- 0.394
- 0.726
- 0.569
- 0.579
- 3.774
- 0.366
- 3.688
- 0.363
- 3.473
- 2.997
- 2.628
- 2.89
- 0.396
- 2.646
- 2.082
- 3.134
- 2.814
- 2.963
- 2.791
- 2.227
- 2.085
- 2.062
- 1.755
- 2.47
- 0.418
- 0.05
- 1.809
- 2.627
- 2.064
- 0.662
- 1.753
- 2.486
- 2.44
- 0.433
- 2.289
- 1.997
- 1.733
- 1.659
- 1.395
- 0.371
- 0.032
- 0.81
- 0.653
- 1.743
- 1.599
- 2.104
- 1.874
- 0.319
- 1.632
- 0.274
- 0.025
- 2.411
- 1.373
- 1.761
- 1.233
- 1.912
- 1.257
- 0.29
- 1.688
- 0.525
- 0.103
- 0.648
- 0.046
- 1.347
- 0.371
- 0.067
- 0.06
- 1.326
- 1.813
- 0.336
- 1.049
- 0.303
- 0.768
- 1.143
- 0.721
- 0.277
- 1.813
- 1.454
- 0.339
- 0.524
- 1.819
- 1.294
- 1.236
- 1.179
- 0.993
- 0.293
- 1.468
- 0.755
- 0.948
- 0.874
- 0.55
unequal: 0
verbose: 1
