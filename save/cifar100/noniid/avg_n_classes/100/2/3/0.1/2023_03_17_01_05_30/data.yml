avg_train_accuracy: 0.26
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0182
- 0.0553
- 0.0828
- 0.0988
- 0.0185
- 0.1071
- 0.1241
- 0.1325
- 0.0186
- 0.133
- 0.0189
- 0.1546
- 0.1563
- 0.159
- 0.0186
- 0.1641
- 0.0189
- 0.1677
- 0.1708
- 0.1762
- 0.1733
- 0.1806
- 0.1876
- 0.1935
- 0.1918
- 0.0187
- 0.1973
- 0.0193
- 0.21
- 0.2054
- 0.202
- 0.2194
- 0.0191
- 0.0181
- 0.0192
- 0.2023
- 0.2096
- 0.2185
- 0.221
- 0.225
- 0.2162
- 0.2278
- 0.0188
- 0.0191
- 0.2184
- 0.2326
- 0.2388
- 0.2323
- 0.2322
- 0.0188
- 0.2367
- 0.2352
- 0.2303
- 0.2284
- 0.0192
- 0.24
- 0.0194
- 0.2289
- 0.0186
- 0.0191
- 0.0194
- 0.2418
- 0.0189
- 0.2496
- 0.2469
- 0.2465
- 0.2537
- 0.0211
- 0.2489
- 0.2507
- 0.2525
- 0.2485
- 0.2627
- 0.263
- 0.2637
- 0.2612
- 0.0196
- 0.2602
- 0.0199
- 0.2645
- 0.02
- 0.0194
- 0.2688
- 0.0201
- 0.0194
- 0.2716
- 0.0208
- 0.2699
- 0.0222
- 0.271
- 0.2676
- 0.2682
- 0.2759
- 0.0219
- 0.0197
- 0.2696
- 0.2687
- 0.2742
- 0.0228
- 0.2702
test_loss_list:
- 3.409322671890259
- 1.786546130180359
- 1.7346883487701417
- 1.6837303352355957
- 4.474809360504151
- 1.6640812826156617
- 1.6233672738075255
- 1.610242040157318
- 4.502304925918579
- 1.5774544882774353
- 4.359666357040405
- 1.5540645432472229
- 1.5454638934135436
- 1.5548636484146119
- 4.340446615219117
- 1.5372098636627198
- 4.250185947418213
- 1.5321465229988098
- 1.51209885597229
- 1.523628315925598
- 1.5046215796470641
- 1.502015254497528
- 1.5036193609237671
- 1.4868493628501893
- 1.4853062772750854
- 4.384048948287964
- 1.4642819786071777
- 4.342566175460815
- 1.438886785507202
- 1.4507276725769043
- 1.4517892122268676
- 1.4350724172592164
- 4.306815958023071
- 4.610930500030517
- 4.478511056900024
- 1.4049278163909913
- 1.3998110127449035
- 1.406371178627014
- 1.4028808689117431
- 1.4008023381233214
- 1.4166783428192138
- 1.4003578662872314
- 4.446909046173095
- 4.365088148117065
- 1.38451664686203
- 1.380037133693695
- 1.3775993394851684
- 1.4015343904495239
- 1.3945244908332826
- 4.405830793380737
- 1.3997592639923095
- 1.3821237730979918
- 1.3982720398902893
- 1.4091291618347168
- 4.252256746292114
- 1.370519862174988
- 4.206171998977661
- 1.3859255194664002
- 4.238115425109863
- 4.222826251983642
- 4.334656267166138
- 1.363988597393036
- 3.994557361602783
- 1.3361785125732422
- 1.3634621047973632
- 1.3494896650314332
- 1.346389560699463
- 4.002344732284546
- 1.3667055225372315
- 1.3673856115341188
- 1.3398300671577454
- 1.357927758693695
- 1.3457466244697571
- 1.327384614944458
- 1.3417767953872681
- 1.3528563833236695
- 4.220023469924927
- 1.3327496337890625
- 3.9781381988525393
- 1.336969358921051
- 3.9513634204864503
- 4.148538932800293
- 1.3020694947242737
- 3.9827060222625734
- 4.31439468383789
- 1.283801429271698
- 3.8716415691375734
- 1.2904781651496888
- 3.712092866897583
- 1.2985877394676208
- 1.3223934054374695
- 1.3200655102729797
- 1.2967110323905944
- 3.7641742706298826
- 4.206511116027832
- 1.3014204382896424
- 1.3033318662643432
- 1.3154762268066407
- 3.754463243484497
- 1.3004087972640992
train_accuracy:
- 0.828
- 0.062
- 0.082
- 0.096
- 0.874
- 0.116
- 0.111
- 0.136
- 0.869
- 0.135
- 0.94
- 0.145
- 0.152
- 0.153
- 0.814
- 0.166
- 0.865
- 0.173
- 0.16
- 0.183
- 0.164
- 0.193
- 0.183
- 0.196
- 0.21
- 0.87
- 0.235
- 0.944
- 0.213
- 0.209
- 0.187
- 0.206
- 0.916
- 0.85
- 0.969
- 0.212
- 0.204
- 0.238
- 0.254
- 0.272
- 0.255
- 0.245
- 0.911
- 0.942
- 0.228
- 0.245
- 0.251
- 0.241
- 0.25
- 0.865
- 0.243
- 0.236
- 0.225
- 0.221
- 0.882
- 0.261
- 0.888
- 0.222
- 0.963
- 0.878
- 0.94
- 0.263
- 0.914
- 0.288
- 0.279
- 0.259
- 0.264
- 0.889
- 0.251
- 0.225
- 0.289
- 0.291
- 0.249
- 0.315
- 0.257
- 0.331
- 0.946
- 0.297
- 0.929
- 0.338
- 0.948
- 0.823
- 0.26
- 0.868
- 0.961
- 0.263
- 0.921
- 0.299
- 0.905
- 0.33
- 0.341
- 0.271
- 0.281
- 0.925
- 0.94
- 0.26
- 0.268
- 0.295
- 0.918
- 0.26
train_loss:
- 0.466
- 4.611
- 3.881
- 3.778
- 0.622
- 3.658
- 3.521
- 3.248
- 0.518
- 3.621
- 0.541
- 3.361
- 3.1
- 2.649
- 0.466
- 3.16
- 0.432
- 2.749
- 2.711
- 2.294
- 3.033
- 2.121
- 2.291
- 2.685
- 1.936
- 0.442
- 3.055
- 0.446
- 2.751
- 2.041
- 2.552
- 2.09
- 0.38
- 0.934
- 0.606
- 2.872
- 2.206
- 1.848
- 1.851
- 2.329
- 1.77
- 1.61
- 0.529
- 0.6
- 2.478
- 1.348
- 1.876
- 1.351
- 1.195
- 0.482
- 1.528
- 1.934
- 1.422
- 1.12
- 0.493
- 2.207
- 0.347
- 1.327
- 0.473
- 0.1
- 0.593
- 1.978
- 0.367
- 1.412
- 0.84
- 1.034
- 1.217
- 0.319
- 1.066
- 2.073
- 1.645
- 1.102
- 0.907
- 1.724
- 0.711
- 1.254
- 0.309
- 1.335
- 0.341
- 1.236
- 0.248
- 0.636
- 1.971
- 0.37
- 0.488
- 1.359
- 0.283
- 1.622
- 0.247
- 1.155
- 0.605
- 1.353
- 0.792
- 0.253
- 0.589
- 1.139
- 0.506
- 1.134
- 0.253
- 0.701
unequal: 0
verbose: 1
