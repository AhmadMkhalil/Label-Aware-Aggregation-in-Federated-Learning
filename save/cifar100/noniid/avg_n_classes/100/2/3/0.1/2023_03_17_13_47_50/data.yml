avg_train_accuracy: 0.275
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0433
- 0.0799
- 0.0108
- 0.0977
- 0.1091
- 0.0185
- 0.0144
- 0.1194
- 0.1257
- 0.1435
- 0.1426
- 0.151
- 0.1622
- 0.1644
- 0.1661
- 0.1699
- 0.1863
- 0.1859
- 0.0144
- 0.0148
- 0.0189
- 0.0191
- 0.0161
- 0.0178
- 0.1846
- 0.0192
- 0.1953
- 0.018
- 0.0191
- 0.0191
- 0.1931
- 0.2059
- 0.2012
- 0.0179
- 0.0191
- 0.2127
- 0.0159
- 0.2101
- 0.2139
- 0.0182
- 0.2113
- 0.218
- 0.0187
- 0.2217
- 0.2169
- 0.2124
- 0.2276
- 0.0154
- 0.2199
- 0.0187
- 0.0189
- 0.0158
- 0.2282
- 0.2252
- 0.0193
- 0.235
- 0.241
- 0.2329
- 0.241
- 0.2463
- 0.015
- 0.0193
- 0.0192
- 0.2422
- 0.0198
- 0.2461
- 0.2474
- 0.2434
- 0.245
- 0.2435
- 0.258
- 0.2482
- 0.2526
- 0.2585
- 0.2585
- 0.2538
- 0.2602
- 0.0186
- 0.0167
- 0.2572
- 0.2713
- 0.0166
- 0.2742
- 0.02
- 0.2681
- 0.2658
- 0.2649
- 0.2747
- 0.0159
- 0.2781
- 0.2727
- 0.2801
- 0.2802
- 0.0206
- 0.2745
- 0.284
- 0.2782
- 0.2841
- 0.2767
- 0.2756
test_loss_list:
- 1.804875602722168
- 1.7115876770019531
- 5.011792831420898
- 1.6814185237884522
- 1.6470530605316163
- 4.590602111816406
- 4.596882467269897
- 1.6047562170028686
- 1.6137938046455382
- 1.5830931568145752
- 1.589085683822632
- 1.563061728477478
- 1.5416689276695252
- 1.5471802377700805
- 1.5217737078666687
- 1.5306931304931641
- 1.5031180167198182
- 1.5216897702217103
- 4.807668256759643
- 4.921796646118164
- 4.491801748275757
- 4.628578691482544
- 4.648010339736938
- 4.5416787815093995
- 1.458282835483551
- 4.10771523475647
- 1.4554689979553224
- 4.254614572525025
- 4.140984182357788
- 4.34199896812439
- 1.4397280502319336
- 1.4398979616165162
- 1.4370579075813295
- 4.250072641372681
- 4.178365802764892
- 1.4079990005493164
- 4.531036128997803
- 1.401171417236328
- 1.4071452140808105
- 4.146342287063598
- 1.4182007384300233
- 1.4138070917129517
- 4.167373170852661
- 1.3944556879997254
- 1.412468490600586
- 1.444114830493927
- 1.3975314402580261
- 4.422695407867431
- 1.4139899253845214
- 4.140754299163818
- 4.254605674743653
- 4.458658084869385
- 1.3687801432609559
- 1.3812782859802246
- 4.0338222026824955
- 1.357688057422638
- 1.3565528655052186
- 1.3722646069526672
- 1.3626717233657837
- 1.3626017737388612
- 4.381428289413452
- 4.106828241348267
- 4.245011539459228
- 1.3564186549186708
- 3.835772466659546
- 1.3425114727020264
- 1.3465935134887694
- 1.367339689731598
- 1.36389568567276
- 1.3638928389549256
- 1.3282366156578065
- 1.356588773727417
- 1.3619459509849547
- 1.347686161994934
- 1.3506851029396056
- 1.3627235651016236
- 1.3498927664756775
- 4.092184400558471
- 4.223524160385132
- 1.3178964972496032
- 1.2995080637931824
- 4.180711288452148
- 1.289031584262848
- 3.8744559478759766
- 1.3045501279830933
- 1.3155001831054687
- 1.3170347809791565
- 1.2927370619773866
- 4.157903671264648
- 1.2949462628364563
- 1.3142302179336547
- 1.3016147994995118
- 1.298484275341034
- 3.8447924613952638
- 1.295140917301178
- 1.2809452843666076
- 1.291643648147583
- 1.2740570044517516
- 1.2991293525695802
- 1.3058646368980407
train_accuracy:
- 0.024
- 0.096
- 0.107
- 0.1
- 0.095
- 0.968
- 0.866
- 0.093
- 0.103
- 0.135
- 0.12
- 0.111
- 0.16
- 0.158
- 0.189
- 0.191
- 0.165
- 0.16
- 0.502
- 0.466
- 0.895
- 0.94
- 0.871
- 0.85
- 0.179
- 0.93
- 0.16
- 0.852
- 0.92
- 0.965
- 0.168
- 0.17
- 0.175
- 0.878
- 0.933
- 0.179
- 0.831
- 0.233
- 0.183
- 0.891
- 0.217
- 0.198
- 0.884
- 0.24
- 0.245
- 0.204
- 0.204
- 0.896
- 0.208
- 0.895
- 0.893
- 0.71
- 0.206
- 0.22
- 0.964
- 0.227
- 0.218
- 0.214
- 0.255
- 0.231
- 0.497
- 0.945
- 0.964
- 0.233
- 0.958
- 0.237
- 0.227
- 0.226
- 0.227
- 0.234
- 0.234
- 0.209
- 0.222
- 0.259
- 0.244
- 0.27
- 0.242
- 0.89
- 0.799
- 0.23
- 0.264
- 0.739
- 0.245
- 0.889
- 0.215
- 0.25
- 0.261
- 0.26
- 0.607
- 0.239
- 0.26
- 0.274
- 0.237
- 0.962
- 0.237
- 0.275
- 0.263
- 0.257
- 0.265
- 0.275
train_loss:
- 4.284
- 3.861
- 0.897
- 4.058
- 3.552
- 0.559
- 1.141
- 3.568
- 2.889
- 3.35
- 2.849
- 3.236
- 3.039
- 2.629
- 3.077
- 2.59
- 2.807
- 2.36
- 0.817
- 0.352
- 0.733
- 0.074
- 0.84
- 0.873
- 3.121
- 0.312
- 2.838
- 0.479
- 0.584
- 0.047
- 3.052
- 2.302
- 2.358
- 0.39
- 0.559
- 3.014
- 0.596
- 2.637
- 2.057
- 0.371
- 2.557
- 1.747
- 0.342
- 2.337
- 1.581
- 1.354
- 2.201
- 0.606
- 1.536
- 0.363
- 0.051
- 0.745
- 2.622
- 1.806
- 0.359
- 1.959
- 1.998
- 1.69
- 1.322
- 1.645
- 0.507
- 0.549
- 0.021
- 1.487
- 0.233
- 2.05
- 1.331
- 1.06
- 1.243
- 1.575
- 1.946
- 1.385
- 1.319
- 1.228
- 1.275
- 0.924
- 1.486
- 0.387
- 0.779
- 2.389
- 1.211
- 0.442
- 1.45
- 0.307
- 1.018
- 0.914
- 0.877
- 1.734
- 0.426
- 1.477
- 1.207
- 1.258
- 0.897
- 0.334
- 0.769
- 0.847
- 1.482
- 0.6
- 1.092
- 1.057
unequal: 0
verbose: 1
