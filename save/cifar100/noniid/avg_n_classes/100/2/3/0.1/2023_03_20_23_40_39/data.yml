avg_train_accuracy: 0.902
avg_train_loss: 0.0
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0352
- 0.0856
- 0.0938
- 0.1099
- 0.1213
- 0.13
- 0.1363
- 0.143
- 0.0174
- 0.0196
- 0.0196
- 0.1376
- 0.1574
- 0.1721
- 0.1741
- 0.1744
- 0.1799
- 0.1767
- 0.1872
- 0.1944
- 0.1954
- 0.0184
- 0.0181
- 0.1972
- 0.1974
- 0.0196
- 0.0181
- 0.2056
- 0.2069
- 0.2118
- 0.2097
- 0.2171
- 0.2076
- 0.221
- 0.0197
- 0.2213
- 0.2318
- 0.2338
- 0.2284
- 0.2355
- 0.0187
- 0.2373
- 0.2377
- 0.0185
- 0.2409
- 0.0197
- 0.2321
- 0.2424
- 0.2406
- 0.2457
- 0.2557
- 0.0198
- 0.2507
- 0.0199
- 0.2546
- 0.2644
- 0.2587
- 0.2614
- 0.2611
- 0.2599
- 0.261
- 0.2567
- 0.0185
- 0.2606
- 0.26
- 0.27
- 0.0185
- 0.2626
- 0.2662
- 0.0192
- 0.0185
- 0.2634
- 0.2757
- 0.0188
- 0.2726
- 0.2717
- 0.019
- 0.2795
- 0.0189
- 0.2772
- 0.2719
- 0.2746
- 0.2693
- 0.0207
- 0.2723
- 0.276
- 0.0208
- 0.0209
- 0.286
- 0.2813
- 0.2864
- 0.2824
- 0.2788
- 0.0199
- 0.2881
- 0.2881
- 0.2857
- 0.2789
- 0.0199
- 0.0192
test_loss_list:
- 1.8075829601287843
- 1.7144091320037842
- 1.6866870951652526
- 1.650131938457489
- 1.6287834095954894
- 1.6046402168273926
- 1.600702896118164
- 1.5873439288139344
- 4.589575233459473
- 4.800127525329589
- 4.8579238986969
- 1.5599845123291016
- 1.5341865181922913
- 1.522449276447296
- 1.5136662936210632
- 1.4990085434913636
- 1.491203682422638
- 1.512244498729706
- 1.5060809540748596
- 1.4835360884666442
- 1.4808728313446045
- 4.619318180084228
- 4.5955008697509765
- 1.4644999814033508
- 1.4544840526580811
- 4.636785345077515
- 4.520306749343872
- 1.4214929938316345
- 1.4309147000312805
- 1.426576735973358
- 1.434927635192871
- 1.4165413331985475
- 1.4589268112182616
- 1.429090805053711
- 4.51203125
- 1.4078662776947022
- 1.3866772532463074
- 1.374796769618988
- 1.395377414226532
- 1.3841478323936462
- 4.451870365142822
- 1.3795129013061525
- 1.3695473313331603
- 4.484846315383911
- 1.368155391216278
- 4.212238311767578
- 1.3773094844818115
- 1.3590125393867494
- 1.3634328103065492
- 1.3624826335906983
- 1.3514349961280823
- 4.3334215259552
- 1.3421568202972411
- 4.038771991729736
- 1.3182216215133666
- 1.3160257267951965
- 1.3267607522010803
- 1.331085937023163
- 1.3271994495391846
- 1.3317011308670044
- 1.3272601342201233
- 1.3506645560264587
- 4.490987815856934
- 1.3294712018966675
- 1.3358070874214172
- 1.3256314373016358
- 4.367280321121216
- 1.303317711353302
- 1.3108061790466308
- 4.244773960113525
- 4.304592847824097
- 1.292279531955719
- 1.2814378690719606
- 4.231080780029297
- 1.300564386844635
- 1.288698332309723
- 4.081712293624878
- 1.291004066467285
- 3.9545200634002686
- 1.2949362325668334
- 1.312164216041565
- 1.298269681930542
- 1.3206383752822877
- 4.251399412155151
- 1.2955264711380006
- 1.2920688438415526
- 3.852664670944214
- 3.8675735855102538
- 1.2636481499671937
- 1.2870500540733338
- 1.2773318433761596
- 1.2826452040672303
- 1.302510302066803
- 4.17696533203125
- 1.2821315336227417
- 1.2683796072006226
- 1.2804238510131836
- 1.2969805812835693
- 4.143401851654053
- 4.1915921878814695
train_accuracy:
- 0.046
- 0.091
- 0.117
- 0.115
- 0.108
- 0.167
- 0.14
- 0.134
- 0.709
- 0.976
- 0.954
- 0.192
- 0.138
- 0.149
- 0.187
- 0.174
- 0.219
- 0.227
- 0.173
- 0.194
- 0.175
- 0.832
- 0.846
- 0.163
- 0.215
- 0.98
- 0.854
- 0.228
- 0.211
- 0.223
- 0.193
- 0.242
- 0.245
- 0.209
- 0.984
- 0.214
- 0.228
- 0.207
- 0.21
- 0.243
- 0.934
- 0.24
- 0.265
- 0.849
- 0.235
- 0.984
- 0.252
- 0.268
- 0.245
- 0.261
- 0.237
- 0.987
- 0.268
- 0.992
- 0.305
- 0.264
- 0.245
- 0.273
- 0.297
- 0.261
- 0.314
- 0.313
- 0.832
- 0.258
- 0.254
- 0.277
- 0.855
- 0.265
- 0.281
- 0.92
- 0.893
- 0.265
- 0.291
- 0.916
- 0.269
- 0.295
- 0.912
- 0.268
- 0.917
- 0.269
- 0.271
- 0.282
- 0.293
- 0.994
- 0.317
- 0.297
- 0.986
- 0.978
- 0.281
- 0.287
- 0.281
- 0.343
- 0.27
- 0.942
- 0.283
- 0.359
- 0.301
- 0.299
- 0.957
- 0.902
train_loss:
- 4.334
- 3.851
- 3.405
- 3.632
- 3.446
- 3.274
- 2.948
- 3.114
- 0.623
- 0.779
- 0.087
- 3.306
- 3.199
- 3.142
- 2.978
- 2.767
- 2.545
- 2.131
- 2.751
- 2.588
- 2.675
- 0.688
- 0.784
- 2.538
- 2.189
- 0.445
- 0.729
- 2.841
- 1.886
- 2.09
- 2.395
- 1.812
- 1.466
- 2.034
- 0.376
- 2.393
- 2.369
- 2.428
- 1.845
- 1.858
- 0.554
- 2.103
- 1.564
- 0.423
- 1.997
- 0.365
- 1.535
- 1.611
- 1.812
- 1.214
- 1.465
- 0.31
- 2.236
- 0.282
- 2.209
- 1.663
- 1.619
- 1.425
- 1.571
- 1.407
- 1.225
- 0.92
- 0.465
- 1.717
- 1.157
- 1.372
- 0.494
- 1.443
- 0.965
- 0.377
- 0.622
- 1.195
- 1.413
- 0.345
- 1.457
- 0.827
- 0.309
- 1.108
- 0.267
- 1.398
- 0.772
- 0.729
- 0.459
- 0.35
- 1.35
- 1.193
- 0.243
- 0.015
- 1.379
- 0.88
- 0.901
- 0.879
- 0.633
- 0.383
- 0.655
- 0.68
- 0.597
- 0.366
- 0.318
- 0.036
unequal: 0
verbose: 1
