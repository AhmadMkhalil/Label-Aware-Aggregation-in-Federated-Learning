avg_train_accuracy: 0.298
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0425
- 0.0845
- 0.1051
- 0.1257
- 0.1378
- 0.1484
- 0.1516
- 0.1722
- 0.1671
- 0.1788
- 0.1703
- 0.1865
- 0.1971
- 0.2021
- 0.202
- 0.2096
- 0.2087
- 0.1968
- 0.22
- 0.2228
- 0.2246
- 0.2115
- 0.2087
- 0.232
- 0.2329
- 0.2405
- 0.232
- 0.2408
- 0.227
- 0.2402
- 0.224
- 0.2511
- 0.2527
- 0.2517
- 0.2613
- 0.2608
- 0.2362
- 0.2459
- 0.255
- 0.255
- 0.2563
- 0.2679
- 0.2662
- 0.2635
- 0.2676
- 0.2729
- 0.2645
- 0.2689
- 0.264
- 0.2712
- 0.2751
- 0.2766
- 0.2713
- 0.2809
- 0.2753
- 0.2829
- 0.2763
- 0.2757
- 0.2526
- 0.2731
- 0.2798
- 0.2807
- 0.2859
- 0.282
- 0.268
- 0.2843
- 0.2777
- 0.2821
- 0.2697
- 0.2884
- 0.2844
- 0.2862
- 0.2866
- 0.2917
- 0.2907
- 0.2922
- 0.2759
- 0.2858
- 0.294
- 0.2939
- 0.2907
- 0.2753
- 0.286
- 0.2934
- 0.2959
- 0.2721
- 0.291
- 0.2806
- 0.2891
- 0.2812
- 0.2959
- 0.2983
- 0.2943
- 0.2824
- 0.284
- 0.3003
- 0.3028
- 0.299
- 0.3001
- 0.3022
test_loss_list:
- 1.794105930328369
- 1.6810467338562012
- 1.6427456665039062
- 1.5981495785713196
- 1.5734948515892029
- 1.5533688616752626
- 1.549770073890686
- 1.5123515248298645
- 1.5190544152259826
- 1.488533456325531
- 1.512765543460846
- 1.4766959977149963
- 1.4601488637924194
- 1.4537782382965088
- 1.4495763540267945
- 1.4366497707366943
- 1.435994210243225
- 1.4448210668563843
- 1.4097785782814025
- 1.4081055426597595
- 1.406224045753479
- 1.4396664381027222
- 1.4371930146217347
- 1.3838051795959472
- 1.3764867973327637
- 1.3710833168029786
- 1.385432689189911
- 1.3726241993904114
- 1.3984506726264954
- 1.3597020030021667
- 1.4028926944732667
- 1.3409644842147828
- 1.3491299748420715
- 1.3439747548103333
- 1.3431667685508728
- 1.3279241180419923
- 1.3802960157394408
- 1.3556302738189698
- 1.3425130343437195
- 1.3517752361297608
- 1.3367636847496032
- 1.3259215807914735
- 1.333169825077057
- 1.3402135181427002
- 1.3296573066711426
- 1.3156698226928711
- 1.3312435793876647
- 1.320522677898407
- 1.3230020356178285
- 1.3101724648475648
- 1.3145563793182373
- 1.306785418987274
- 1.3206964588165284
- 1.3052731680870056
- 1.318264148235321
- 1.2989883041381836
- 1.3131128144264221
- 1.3201132774353028
- 1.3651557183265686
- 1.3182532048225404
- 1.3138665103912353
- 1.2956578969955443
- 1.2951505494117737
- 1.301860134601593
- 1.3516897678375244
- 1.2968623399734498
- 1.3134585189819337
- 1.3025246524810792
- 1.3397571325302124
- 1.2927302670478822
- 1.3169476079940796
- 1.30597083568573
- 1.2955954337120057
- 1.3065847420692445
- 1.2853703427314758
- 1.2994612526893616
- 1.3465631890296936
- 1.3054518246650695
- 1.2968023824691772
- 1.3072937655448913
- 1.3000470852851869
- 1.3411926865577697
- 1.3015379428863525
- 1.2903957414627074
- 1.2949626111984254
- 1.3388910484313965
- 1.2990992259979248
- 1.3317712616920472
- 1.2974440026283265
- 1.3339321088790894
- 1.2885525846481323
- 1.2954177117347718
- 1.2964102697372437
- 1.327743718624115
- 1.3301332330703735
- 1.2876696753501893
- 1.2896322703361511
- 1.3017051577568055
- 1.2902505278587342
- 1.287945466041565
train_accuracy:
- 0.027
- 0.111
- 0.095
- 0.13
- 0.0
- 0.125
- 0.13
- 0.175
- 0.154
- 0.155
- 0.183
- 0.179
- 0.172
- 0.0
- 0.218
- 0.172
- 0.168
- 0.185
- 0.0
- 0.0
- 0.225
- 0.245
- 0.0
- 0.19
- 0.198
- 0.301
- 0.0
- 0.0
- 0.0
- 0.232
- 0.0
- 0.206
- 0.21
- 0.0
- 0.258
- 0.221
- 0.223
- 0.0
- 0.259
- 0.0
- 0.216
- 0.271
- 0.0
- 0.281
- 0.257
- 0.312
- 0.309
- 0.0
- 0.0
- 0.305
- 0.322
- 0.0
- 0.0
- 0.239
- 0.322
- 0.248
- 0.246
- 0.0
- 0.239
- 0.219
- 0.0
- 0.0
- 0.272
- 0.0
- 0.0
- 0.261
- 0.28
- 0.0
- 0.295
- 0.288
- 0.305
- 0.0
- 0.326
- 0.249
- 0.304
- 0.343
- 0.0
- 0.301
- 0.318
- 0.277
- 0.252
- 0.0
- 0.0
- 0.32
- 0.32
- 0.0
- 0.296
- 0.0
- 0.307
- 0.271
- 0.291
- 0.255
- 0.287
- 0.0
- 0.0
- 0.291
- 0.277
- 0.0
- 0.313
- 0.298
train_loss:
- 3.094
- 2.788
- 2.583
- 2.574
- 2.475
- 3.134
- 2.149
- 3.07
- 2.123
- 2.169
- 1.246
- 1.989
- 2.589
- 2.062
- 1.77
- 1.786
- 1.717
- 1.272
- 1.747
- 1.644
- 1.519
- 0.957
- 1.083
- 2.015
- 1.513
- 1.79
- 1.286
- 1.288
- 1.081
- 1.597
- 0.827
- 1.834
- 1.201
- 1.38
- 1.469
- 1.615
- 0.763
- 0.927
- 1.202
- 0.922
- 1.073
- 1.282
- 1.034
- 0.869
- 1.278
- 1.06
- 0.74
- 1.098
- 0.78
- 1.14
- 0.871
- 0.967
- 0.757
- 1.114
- 0.706
- 1.013
- 0.795
- 0.709
- 0.563
- 0.748
- 0.579
- 0.746
- 0.815
- 0.678
- 0.454
- 0.662
- 0.575
- 0.594
- 0.477
- 0.692
- 0.527
- 0.546
- 0.576
- 0.539
- 0.589
- 0.405
- 0.501
- 0.499
- 0.457
- 0.513
- 0.599
- 0.426
- 0.499
- 0.433
- 0.433
- 0.463
- 0.426
- 0.337
- 0.519
- 0.433
- 0.384
- 0.437
- 0.306
- 0.444
- 0.4
- 0.385
- 0.355
- 0.414
- 0.344
- 0.319
unequal: 0
verbose: 1
