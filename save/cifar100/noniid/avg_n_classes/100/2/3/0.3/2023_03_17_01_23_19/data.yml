avg_train_accuracy: 0.312
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0436
- 0.0907
- 0.116
- 0.1356
- 0.1472
- 0.1422
- 0.1655
- 0.178
- 0.1827
- 0.1729
- 0.1956
- 0.1952
- 0.2001
- 0.2074
- 0.2091
- 0.2144
- 0.2228
- 0.221
- 0.2032
- 0.2341
- 0.2295
- 0.2279
- 0.2298
- 0.2386
- 0.2293
- 0.2442
- 0.2479
- 0.2554
- 0.2317
- 0.2577
- 0.2508
- 0.2566
- 0.2531
- 0.2471
- 0.2549
- 0.2665
- 0.2451
- 0.2542
- 0.2622
- 0.2516
- 0.2469
- 0.263
- 0.2657
- 0.2785
- 0.2759
- 0.2726
- 0.2775
- 0.2503
- 0.2627
- 0.2724
- 0.2758
- 0.2758
- 0.2612
- 0.2663
- 0.2811
- 0.2799
- 0.279
- 0.2898
- 0.2859
- 0.2733
- 0.2913
- 0.2881
- 0.2886
- 0.2873
- 0.2893
- 0.2942
- 0.2728
- 0.2919
- 0.2718
- 0.2727
- 0.2922
- 0.296
- 0.2937
- 0.2943
- 0.2966
- 0.2924
- 0.2956
- 0.2937
- 0.293
- 0.2971
- 0.3023
- 0.293
- 0.2852
- 0.2961
- 0.2934
- 0.3049
- 0.3021
- 0.3016
- 0.2946
- 0.301
- 0.3033
- 0.3041
- 0.2969
- 0.2988
- 0.3112
- 0.3088
- 0.3027
- 0.303
- 0.2875
- 0.3061
test_loss_list:
- 1.8012601375579833
- 1.6844111156463624
- 1.6359304785728455
- 1.5958036136627198
- 1.5668754005432128
- 1.580767147541046
- 1.528693473339081
- 1.510480432510376
- 1.5019788718223572
- 1.5225582027435303
- 1.4710119652748108
- 1.4742149877548218
- 1.453628122806549
- 1.4419097352027892
- 1.4358559131622315
- 1.432425410747528
- 1.4148354077339171
- 1.41623633146286
- 1.4623535513877868
- 1.3878779625892639
- 1.4076492714881896
- 1.398546772003174
- 1.4037329173088073
- 1.3787218618392945
- 1.4171158957481385
- 1.3607282972335815
- 1.3506855058670044
- 1.3473240518569947
- 1.397859525680542
- 1.3324342823028565
- 1.3509594154357911
- 1.3414439678192138
- 1.3376611399650573
- 1.365634400844574
- 1.3388755059242248
- 1.3263284254074097
- 1.3636872911453246
- 1.3505030989646911
- 1.3321307826042175
- 1.3650793099403382
- 1.3595478677749633
- 1.3223870587348938
- 1.3148027563095093
- 1.2913157057762146
- 1.3034498000144958
- 1.3142945957183838
- 1.3041610074043275
- 1.3805050325393677
- 1.3325722217559814
- 1.3147418951988221
- 1.308537757396698
- 1.3062490177154542
- 1.3507846331596374
- 1.3219113874435424
- 1.291287145614624
- 1.289469051361084
- 1.2909937167167664
- 1.2825849008560182
- 1.286921353340149
- 1.340128653049469
- 1.2908704853057862
- 1.2937690949440002
- 1.2865221691131592
- 1.2889706349372865
- 1.287763671875
- 1.2844622945785522
- 1.318220589160919
- 1.2862467384338379
- 1.348294837474823
- 1.323611807823181
- 1.280437445640564
- 1.2790016508102418
- 1.2755077576637268
- 1.2746203875541686
- 1.2784020686149598
- 1.2824724125862121
- 1.2878442478179932
- 1.2841422080993652
- 1.2792224955558777
- 1.2817686223983764
- 1.2750074934959412
- 1.2885814094543457
- 1.3281805658340453
- 1.2775645327568055
- 1.2916629528999328
- 1.2805638885498047
- 1.287628800868988
- 1.290614025592804
- 1.3098465514183044
- 1.2958894348144532
- 1.2877338695526124
- 1.2853990387916565
- 1.3008739233016968
- 1.2891238236427307
- 1.26967711687088
- 1.2807538986206055
- 1.276807768344879
- 1.2871861696243285
- 1.319220564365387
- 1.283746211528778
train_accuracy:
- 0.055
- 0.135
- 0.099
- 0.107
- 0.132
- 0.0
- 0.0
- 0.202
- 0.165
- 0.0
- 0.153
- 0.234
- 0.183
- 0.183
- 0.182
- 0.0
- 0.199
- 0.216
- 0.0
- 0.267
- 0.217
- 0.245
- 0.204
- 0.267
- 0.0
- 0.198
- 0.208
- 0.224
- 0.0
- 0.229
- 0.0
- 0.274
- 0.257
- 0.215
- 0.0
- 0.225
- 0.0
- 0.0
- 0.231
- 0.281
- 0.23
- 0.251
- 0.221
- 0.241
- 0.327
- 0.316
- 0.267
- 0.229
- 0.277
- 0.236
- 0.257
- 0.279
- 0.0
- 0.0
- 0.247
- 0.0
- 0.289
- 0.272
- 0.271
- 0.233
- 0.275
- 0.0
- 0.326
- 0.0
- 0.336
- 0.248
- 0.252
- 0.0
- 0.0
- 0.0
- 0.281
- 0.3
- 0.273
- 0.273
- 0.0
- 0.0
- 0.273
- 0.316
- 0.272
- 0.268
- 0.0
- 0.279
- 0.0
- 0.32
- 0.274
- 0.287
- 0.263
- 0.268
- 0.359
- 0.0
- 0.306
- 0.307
- 0.307
- 0.358
- 0.307
- 0.34
- 0.277
- 0.324
- 0.0
- 0.312
train_loss:
- 4.309
- 2.769
- 2.585
- 3.459
- 3.256
- 1.482
- 2.267
- 2.832
- 2.78
- 1.502
- 2.648
- 1.886
- 1.99
- 2.597
- 1.807
- 1.943
- 2.273
- 1.656
- 1.174
- 2.284
- 1.604
- 1.532
- 1.38
- 1.481
- 1.015
- 1.676
- 1.572
- 1.801
- 1.062
- 1.864
- 1.306
- 1.314
- 1.357
- 0.917
- 1.131
- 1.3
- 0.989
- 1.078
- 0.895
- 0.799
- 1.043
- 1.092
- 0.98
- 1.134
- 1.047
- 0.931
- 0.875
- 0.66
- 0.951
- 0.842
- 0.952
- 0.754
- 0.639
- 0.755
- 0.905
- 0.834
- 0.822
- 0.762
- 0.814
- 0.649
- 0.741
- 0.633
- 0.775
- 0.617
- 0.692
- 0.618
- 0.638
- 0.658
- 0.651
- 0.595
- 0.58
- 0.581
- 0.572
- 0.54
- 0.511
- 0.428
- 0.445
- 0.579
- 0.511
- 0.436
- 0.491
- 0.472
- 0.495
- 0.515
- 0.396
- 0.455
- 0.381
- 0.336
- 0.446
- 0.462
- 0.434
- 0.367
- 0.356
- 0.383
- 0.337
- 0.307
- 0.326
- 0.438
- 0.368
- 0.332
unequal: 0
verbose: 1
