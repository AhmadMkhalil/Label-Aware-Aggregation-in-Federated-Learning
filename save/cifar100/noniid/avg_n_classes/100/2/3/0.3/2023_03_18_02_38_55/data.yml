avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0376
- 0.0709
- 0.1035
- 0.1204
- 0.1263
- 0.1408
- 0.138
- 0.1459
- 0.1743
- 0.162
- 0.1765
- 0.1678
- 0.1932
- 0.2028
- 0.2066
- 0.2116
- 0.213
- 0.2182
- 0.2252
- 0.2294
- 0.2254
- 0.2286
- 0.2356
- 0.237
- 0.2331
- 0.2252
- 0.2254
- 0.2504
- 0.2394
- 0.2471
- 0.2508
- 0.2585
- 0.2635
- 0.2646
- 0.2418
- 0.2619
- 0.2678
- 0.2627
- 0.2671
- 0.24
- 0.2632
- 0.2675
- 0.2595
- 0.2696
- 0.2765
- 0.2686
- 0.2608
- 0.2645
- 0.2852
- 0.2672
- 0.281
- 0.2861
- 0.2855
- 0.2904
- 0.2683
- 0.2924
- 0.2731
- 0.296
- 0.2954
- 0.2862
- 0.2894
- 0.2873
- 0.289
- 0.2999
- 0.294
- 0.291
- 0.2929
- 0.2955
- 0.2984
- 0.2998
- 0.2954
- 0.3006
- 0.2994
- 0.2943
- 0.2855
- 0.293
- 0.2826
- 0.2922
- 0.2925
- 0.2964
- 0.299
- 0.2996
- 0.2958
- 0.2935
- 0.2995
- 0.2812
- 0.297
- 0.2978
- 0.3032
- 0.2982
- 0.2908
- 0.3072
- 0.2978
- 0.2978
- 0.2983
- 0.3026
- 0.3109
- 0.2948
- 0.3029
- 0.3019
test_loss_list:
- 1.8089250087738038
- 1.7380268955230713
- 1.6478447818756103
- 1.6092273426055907
- 1.5959237599372864
- 1.5599704885482788
- 1.5646507883071898
- 1.54824946641922
- 1.497328667640686
- 1.5299398112297058
- 1.4870546531677247
- 1.504272859096527
- 1.463845627307892
- 1.4409060406684875
- 1.4416726398468018
- 1.4201353240013121
- 1.4258356285095215
- 1.4116546058654784
- 1.4052468729019165
- 1.39425155878067
- 1.409445927143097
- 1.3994180870056152
- 1.3858896231651305
- 1.390611617565155
- 1.3863311362266542
- 1.4168832445144652
- 1.4065147924423218
- 1.3501501774787903
- 1.3644664001464843
- 1.3547387766838073
- 1.3550156569480896
- 1.3357023191452027
- 1.3226911401748658
- 1.338475456237793
- 1.3819756698608399
- 1.3365474247932434
- 1.3211018872261047
- 1.3170047044754027
- 1.3251562356948852
- 1.3910952758789064
- 1.3288876962661744
- 1.3230322265625
- 1.3595612359046936
- 1.319577329158783
- 1.3158487725257872
- 1.3271585249900817
- 1.3589794516563416
- 1.3448749852180482
- 1.2860005497932434
- 1.3461511516571045
- 1.314349102973938
- 1.299114396572113
- 1.2990899610519409
- 1.295352897644043
- 1.3417591381072997
- 1.2840126943588257
- 1.3246774244308472
- 1.2836839056015015
- 1.2922528195381164
- 1.303278820514679
- 1.2971450233459472
- 1.3046417498588563
- 1.3037885928153992
- 1.293746657371521
- 1.2974808406829834
- 1.3062298941612243
- 1.3106035828590392
- 1.281388282775879
- 1.2913266372680665
- 1.290725338459015
- 1.3033637595176697
- 1.2836099886894226
- 1.2946063160896302
- 1.2921474170684815
- 1.3128247618675233
- 1.3119638848304749
- 1.3431338524818421
- 1.3079041075706481
- 1.3087944459915162
- 1.2989026713371277
- 1.2948430466651917
- 1.288445897102356
- 1.297434332370758
- 1.3092089247703553
- 1.3063693404197694
- 1.3441303324699403
- 1.3013451886177063
- 1.3008422684669494
- 1.2879554581642152
- 1.304824287891388
- 1.3368571257591249
- 1.2850217723846435
- 1.3089383888244628
- 1.2984178376197815
- 1.298759422302246
- 1.300640549659729
- 1.2867849040031434
- 1.329715223312378
- 1.3001107263565064
- 1.301186306476593
train_accuracy:
- 0.0
- 0.0
- 0.115
- 0.0
- 0.158
- 0.139
- 0.0
- 0.0
- 0.22
- 0.0
- 0.0
- 0.0
- 0.216
- 0.191
- 0.193
- 0.193
- 0.0
- 0.0
- 0.197
- 0.269
- 0.182
- 0.211
- 0.197
- 0.272
- 0.214
- 0.258
- 0.0
- 0.267
- 0.0
- 0.218
- 0.0
- 0.285
- 0.253
- 0.263
- 0.0
- 0.295
- 0.226
- 0.253
- 0.267
- 0.0
- 0.0
- 0.249
- 0.0
- 0.264
- 0.23
- 0.0
- 0.0
- 0.292
- 0.278
- 0.0
- 0.0
- 0.0
- 0.27
- 0.322
- 0.0
- 0.291
- 0.0
- 0.277
- 0.322
- 0.252
- 0.287
- 0.291
- 0.0
- 0.359
- 0.321
- 0.0
- 0.274
- 0.292
- 0.265
- 0.349
- 0.0
- 0.29
- 0.293
- 0.293
- 0.296
- 0.0
- 0.261
- 0.255
- 0.257
- 0.296
- 0.295
- 0.269
- 0.0
- 0.316
- 0.0
- 0.257
- 0.259
- 0.26
- 0.346
- 0.279
- 0.262
- 0.302
- 0.0
- 0.314
- 0.298
- 0.261
- 0.369
- 0.32
- 0.0
- 0.0
train_loss:
- 1.783
- 1.572
- 3.536
- 2.506
- 1.541
- 2.276
- 1.433
- 1.504
- 2.854
- 1.34
- 2.051
- 1.229
- 2.393
- 2.693
- 1.797
- 2.615
- 1.65
- 1.847
- 2.212
- 2.156
- 1.506
- 1.512
- 1.866
- 1.353
- 1.562
- 0.835
- 1.012
- 1.951
- 1.368
- 1.278
- 1.125
- 1.43
- 1.547
- 1.077
- 0.809
- 1.243
- 1.557
- 1.456
- 1.157
- 0.774
- 1.078
- 1.099
- 0.8
- 1.148
- 0.868
- 0.83
- 0.755
- 0.695
- 1.177
- 0.643
- 0.706
- 0.694
- 0.815
- 0.819
- 0.633
- 0.95
- 0.663
- 0.779
- 0.646
- 0.67
- 0.696
- 0.577
- 0.524
- 0.651
- 0.606
- 0.488
- 0.476
- 0.599
- 0.653
- 0.498
- 0.45
- 0.657
- 0.491
- 0.545
- 0.476
- 0.444
- 0.458
- 0.513
- 0.445
- 0.482
- 0.456
- 0.402
- 0.482
- 0.386
- 0.435
- 0.404
- 0.428
- 0.337
- 0.401
- 0.372
- 0.376
- 0.321
- 0.305
- 0.381
- 0.436
- 0.303
- 0.368
- 0.379
- 0.342
- 0.274
unequal: 0
verbose: 1
