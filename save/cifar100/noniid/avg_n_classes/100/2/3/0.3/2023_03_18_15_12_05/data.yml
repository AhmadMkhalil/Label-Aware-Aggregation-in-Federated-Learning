avg_train_accuracy: 0.251
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0374
- 0.0766
- 0.1091
- 0.1254
- 0.1395
- 0.1517
- 0.154
- 0.1587
- 0.1764
- 0.1756
- 0.1689
- 0.1889
- 0.2042
- 0.2106
- 0.1719
- 0.2137
- 0.2165
- 0.2167
- 0.2262
- 0.22
- 0.2193
- 0.2284
- 0.236
- 0.2349
- 0.2404
- 0.2464
- 0.243
- 0.2542
- 0.2485
- 0.2501
- 0.2511
- 0.2568
- 0.2537
- 0.2645
- 0.2584
- 0.2677
- 0.2702
- 0.269
- 0.2718
- 0.2622
- 0.256
- 0.2658
- 0.2657
- 0.2513
- 0.2706
- 0.2793
- 0.2774
- 0.2825
- 0.2733
- 0.2738
- 0.2694
- 0.2863
- 0.2761
- 0.2838
- 0.2837
- 0.2633
- 0.2902
- 0.2885
- 0.2889
- 0.2687
- 0.271
- 0.2838
- 0.2931
- 0.2763
- 0.2931
- 0.2888
- 0.2919
- 0.2927
- 0.2962
- 0.2974
- 0.2753
- 0.2909
- 0.297
- 0.2695
- 0.3001
- 0.2929
- 0.2942
- 0.2972
- 0.2949
- 0.2971
- 0.3002
- 0.3007
- 0.2929
- 0.2962
- 0.2951
- 0.3052
- 0.2977
- 0.2993
- 0.296
- 0.2965
- 0.2965
- 0.2799
- 0.2996
- 0.2998
- 0.2984
- 0.3067
- 0.2858
- 0.2891
- 0.2899
- 0.2796
test_loss_list:
- 1.8065468454360962
- 1.7091302347183228
- 1.6356291627883912
- 1.6043186402320861
- 1.5782261776924134
- 1.5410996723175048
- 1.534269461631775
- 1.524625496864319
- 1.4959542655944824
- 1.489857633113861
- 1.508470606803894
- 1.4729789757728577
- 1.4461615777015686
- 1.436336462497711
- 1.432410066127777
- 1.3646534657478333
- 1.3729148244857787
- 1.384057776927948
- 1.3672728729248047
- 1.3750244736671449
- 1.3823599004745484
- 1.3740606260299684
- 1.3588341784477234
- 1.3578049778938293
- 1.3572422456741333
- 1.346971082687378
- 1.3564549565315247
- 1.337566969394684
- 1.3448867869377137
- 1.3287446045875548
- 1.3352312302589417
- 1.3178858613967896
- 1.3227468967437743
- 1.3138830304145812
- 1.3267082738876343
- 1.3096703362464905
- 1.3004053187370301
- 1.3119167733192443
- 1.3125987935066223
- 1.3272164869308472
- 1.3424616980552673
- 1.3160116863250733
- 1.3145374059677124
- 1.354619686603546
- 1.3101845955848694
- 1.2877302980422973
- 1.303949339389801
- 1.2900836086273193
- 1.3105062079429626
- 1.2986287784576416
- 1.310566782951355
- 1.284031991958618
- 1.300432381629944
- 1.2890184593200684
- 1.291204285621643
- 1.3372609329223633
- 1.2817527890205382
- 1.278511824607849
- 1.2849174284934997
- 1.3262513756752015
- 1.315307309627533
- 1.2945607566833497
- 1.2754542756080627
- 1.3065401101112366
- 1.2721091151237487
- 1.2787029790878295
- 1.277170102596283
- 1.2785426092147827
- 1.2799593019485473
- 1.2711742115020752
- 1.329256911277771
- 1.27772891998291
- 1.2732253909111022
- 1.3333573985099791
- 1.2719267773628236
- 1.2845263433456422
- 1.2813989090919495
- 1.2711153602600098
- 1.2882316637039184
- 1.2861462616920472
- 1.2765761613845825
- 1.274006006717682
- 1.291074595451355
- 1.282465362548828
- 1.2835007548332213
- 1.2851088428497315
- 1.2894963598251343
- 1.2728083562850951
- 1.2843585848808288
- 1.2884396600723267
- 1.293530740737915
- 1.323346996307373
- 1.2865502977371215
- 1.2864831757545472
- 1.300383780002594
- 1.2753907322883606
- 1.3222795033454895
- 1.3237014293670655
- 1.2996166729927063
- 1.3439236211776733
train_accuracy:
- 0.031
- 0.0
- 0.0
- 0.147
- 0.085
- 0.137
- 0.146
- 0.143
- 0.0
- 0.137
- 0.163
- 0.0
- 0.182
- 0.206
- 0.1
- 0.21
- 0.216
- 0.158
- 0.227
- 0.165
- 0.0
- 0.192
- 0.174
- 0.241
- 0.187
- 0.258
- 0.252
- 0.219
- 0.0
- 0.254
- 0.0
- 0.289
- 0.231
- 0.218
- 0.0
- 0.273
- 0.283
- 0.242
- 0.23
- 0.233
- 0.0
- 0.268
- 0.213
- 0.234
- 0.0
- 0.286
- 0.0
- 0.309
- 0.0
- 0.0
- 0.0
- 0.263
- 0.0
- 0.284
- 0.31
- 0.0
- 0.261
- 0.329
- 0.0
- 0.275
- 0.0
- 0.0
- 0.346
- 0.314
- 0.293
- 0.318
- 0.324
- 0.0
- 0.332
- 0.325
- 0.305
- 0.0
- 0.31
- 0.0
- 0.249
- 0.311
- 0.256
- 0.298
- 0.0
- 0.33
- 0.289
- 0.309
- 0.328
- 0.29
- 0.283
- 0.273
- 0.0
- 0.322
- 0.331
- 0.326
- 0.253
- 0.0
- 0.313
- 0.272
- 0.297
- 0.271
- 0.0
- 0.0
- 0.276
- 0.251
train_loss:
- 2.989
- 1.683
- 2.63
- 2.521
- 2.411
- 3.276
- 2.321
- 2.106
- 2.196
- 2.116
- 1.274
- 2.059
- 2.712
- 2.476
- 0.57
- 2.627
- 2.473
- 1.645
- 2.372
- 1.669
- 1.658
- 1.448
- 2.014
- 1.612
- 1.468
- 1.826
- 1.446
- 1.833
- 1.277
- 1.491
- 1.361
- 1.726
- 1.24
- 1.628
- 1.151
- 1.206
- 1.541
- 1.118
- 1.313
- 0.971
- 0.762
- 0.921
- 0.99
- 0.678
- 0.851
- 1.077
- 0.83
- 1.132
- 0.713
- 0.856
- 0.608
- 0.996
- 0.628
- 0.893
- 0.797
- 0.502
- 0.885
- 0.925
- 0.837
- 0.504
- 0.526
- 0.654
- 0.759
- 0.61
- 0.751
- 0.601
- 0.642
- 0.648
- 0.501
- 0.516
- 0.422
- 0.696
- 0.599
- 0.42
- 0.627
- 0.509
- 0.431
- 0.54
- 0.407
- 0.471
- 0.491
- 0.472
- 0.42
- 0.332
- 0.45
- 0.423
- 0.392
- 0.511
- 0.364
- 0.284
- 0.377
- 0.367
- 0.313
- 0.265
- 0.358
- 0.381
- 0.366
- 0.354
- 0.46
- 0.36
unequal: 0
verbose: 1
