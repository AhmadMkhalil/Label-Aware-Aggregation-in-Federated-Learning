avg_train_accuracy: 0.339
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0962
- 0.1164
- 0.1163
- 0.1388
- 0.1555
- 0.1584
- 0.1712
- 0.1762
- 0.1785
- 0.1928
- 0.2019
- 0.1986
- 0.2194
- 0.2141
- 0.2231
- 0.2198
- 0.2346
- 0.2341
- 0.24
- 0.2369
- 0.2411
- 0.2419
- 0.2535
- 0.2473
- 0.2466
- 0.2615
- 0.2299
- 0.2384
- 0.2568
- 0.2549
- 0.2553
- 0.2608
- 0.2669
- 0.2688
- 0.2629
- 0.2562
- 0.2699
- 0.2782
- 0.2878
- 0.2787
- 0.2842
- 0.2685
- 0.2794
- 0.2783
- 0.2806
- 0.2806
- 0.2847
- 0.2878
- 0.2721
- 0.293
- 0.2874
- 0.2877
- 0.293
- 0.2938
- 0.2937
- 0.2821
- 0.2922
- 0.2816
- 0.2785
- 0.2944
- 0.3018
- 0.3038
- 0.3016
- 0.3035
- 0.2989
- 0.2894
- 0.3084
- 0.2923
- 0.3074
- 0.2803
- 0.2938
- 0.3011
- 0.2833
- 0.306
- 0.3065
- 0.3032
- 0.3118
- 0.3066
- 0.3107
- 0.3062
- 0.3137
- 0.3121
- 0.3104
- 0.2963
- 0.3053
- 0.3116
- 0.3163
- 0.3135
- 0.3135
- 0.3017
- 0.3008
- 0.3175
- 0.319
- 0.3101
- 0.3133
- 0.3117
- 0.3146
- 0.2966
- 0.317
test_loss_list:
- 1.8181070137023925
- 1.683085196018219
- 1.6329747200012208
- 1.6273963785171508
- 1.582923333644867
- 1.546268301010132
- 1.5355547261238098
- 1.5144833421707153
- 1.5052458834648133
- 1.5003048753738404
- 1.4684091329574585
- 1.4630556869506837
- 1.467068750858307
- 1.4340191769599915
- 1.4328156566619874
- 1.4187596869468688
- 1.4262107849121093
- 1.405974678993225
- 1.3984551620483399
- 1.3954826188087464
- 1.4040254521369935
- 1.3898947763442993
- 1.3927811431884765
- 1.376436779499054
- 1.3820786023139953
- 1.3748898959159852
- 1.3600684142112731
- 1.4162840938568115
- 1.4025730633735656
- 1.3582437682151793
- 1.353914361000061
- 1.3493952894210814
- 1.3548085117340087
- 1.3315523743629456
- 1.3418066167831422
- 1.342420175075531
- 1.3580765056610107
- 1.3256768774986267
- 1.309310829639435
- 1.296309700012207
- 1.3063070464134217
- 1.3047837281227113
- 1.3425480890274049
- 1.3234699416160582
- 1.3145479297637939
- 1.3173969626426696
- 1.3110441017150878
- 1.2970346546173095
- 1.3056766748428346
- 1.3357123374938964
- 1.2809078693389893
- 1.3067475533485413
- 1.2928645277023316
- 1.2845304083824158
- 1.2860669231414794
- 1.2781359887123107
- 1.3099019384384156
- 1.2875952458381652
- 1.3208338022232056
- 1.3152473282814026
- 1.274305419921875
- 1.2691377472877503
- 1.2648915314674378
- 1.2658551359176635
- 1.2609981322288513
- 1.2722373628616332
- 1.3048115134239198
- 1.2566616654396057
- 1.323284981250763
- 1.2707830667495728
- 1.3365776586532592
- 1.2970365905761718
- 1.2639333319664001
- 1.3088915824890137
- 1.262064552307129
- 1.2700227880477906
- 1.2618344259262084
- 1.252144467830658
- 1.2598805594444276
- 1.2509921216964721
- 1.2690610933303832
- 1.253410267829895
- 1.2636723136901855
- 1.2663668918609619
- 1.29051730632782
- 1.26513840675354
- 1.2718255782127381
- 1.2609439754486085
- 1.2596514225006104
- 1.2608312225341798
- 1.2939201378822327
- 1.2787843561172485
- 1.259514992237091
- 1.2530004048347474
- 1.2689281845092772
- 1.2625601315498352
- 1.2706938409805297
- 1.257684726715088
- 1.3158880257606507
- 1.2607643127441406
train_accuracy:
- 0.048
- 0.098
- 0.136
- 0.107
- 0.128
- 0.123
- 0.0
- 0.183
- 0.192
- 0.186
- 0.147
- 0.0
- 0.218
- 0.237
- 0.0
- 0.221
- 0.235
- 0.247
- 0.253
- 0.219
- 0.0
- 0.261
- 0.279
- 0.0
- 0.267
- 0.0
- 0.283
- 0.0
- 0.243
- 0.287
- 0.261
- 0.275
- 0.0
- 0.0
- 0.266
- 0.268
- 0.0
- 0.0
- 0.221
- 0.272
- 0.298
- 0.266
- 0.277
- 0.286
- 0.308
- 0.0
- 0.0
- 0.0
- 0.289
- 0.0
- 0.299
- 0.278
- 0.0
- 0.0
- 0.0
- 0.316
- 0.0
- 0.278
- 0.0
- 0.0
- 0.0
- 0.317
- 0.0
- 0.264
- 0.271
- 0.0
- 0.0
- 0.316
- 0.0
- 0.322
- 0.283
- 0.0
- 0.275
- 0.0
- 0.335
- 0.0
- 0.285
- 0.0
- 0.322
- 0.309
- 0.343
- 0.352
- 0.343
- 0.346
- 0.0
- 0.276
- 0.319
- 0.34
- 0.328
- 0.275
- 0.0
- 0.324
- 0.335
- 0.363
- 0.0
- 0.344
- 0.331
- 0.307
- 0.0
- 0.339
train_loss:
- 1.843
- 3.938
- 3.633
- 1.556
- 2.411
- 2.381
- 2.258
- 2.23
- 2.164
- 2.079
- 2.844
- 1.984
- 1.792
- 2.717
- 1.882
- 2.419
- 1.697
- 2.338
- 2.274
- 2.123
- 1.6
- 2.085
- 1.414
- 1.633
- 1.431
- 1.455
- 1.744
- 0.921
- 0.938
- 1.399
- 1.248
- 1.184
- 0.965
- 1.316
- 0.904
- 0.925
- 0.881
- 1.134
- 1.386
- 1.445
- 1.154
- 1.203
- 0.679
- 0.838
- 0.884
- 0.744
- 0.778
- 1.025
- 0.678
- 0.559
- 1.104
- 0.552
- 1.074
- 0.674
- 1.107
- 1.036
- 0.562
- 0.589
- 0.479
- 0.549
- 0.987
- 0.685
- 0.756
- 0.853
- 0.625
- 0.591
- 0.601
- 0.708
- 0.447
- 0.438
- 0.586
- 0.472
- 0.661
- 0.496
- 0.43
- 0.421
- 0.545
- 0.648
- 0.445
- 0.631
- 0.448
- 0.395
- 0.315
- 0.419
- 0.505
- 0.468
- 0.372
- 0.357
- 0.453
- 0.424
- 0.391
- 0.383
- 0.328
- 0.448
- 0.429
- 0.381
- 0.375
- 0.328
- 0.376
- 0.322
unequal: 0
verbose: 1
