avg_train_accuracy: 0.324
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0493
- 0.0877
- 0.1119
- 0.121
- 0.1389
- 0.1548
- 0.1604
- 0.1646
- 0.1774
- 0.1632
- 0.1822
- 0.1909
- 0.2051
- 0.2045
- 0.2111
- 0.2159
- 0.2167
- 0.2179
- 0.2182
- 0.2283
- 0.2081
- 0.2314
- 0.2151
- 0.2436
- 0.2298
- 0.2437
- 0.2528
- 0.2318
- 0.2485
- 0.256
- 0.248
- 0.2527
- 0.2395
- 0.2627
- 0.2695
- 0.2667
- 0.2748
- 0.2738
- 0.2707
- 0.2711
- 0.2772
- 0.2749
- 0.2746
- 0.2762
- 0.2785
- 0.2834
- 0.28
- 0.2767
- 0.277
- 0.2824
- 0.2782
- 0.2716
- 0.2788
- 0.291
- 0.2393
- 0.2863
- 0.2842
- 0.275
- 0.2904
- 0.29
- 0.2794
- 0.2869
- 0.2907
- 0.2919
- 0.2941
- 0.2872
- 0.2816
- 0.296
- 0.2859
- 0.2759
- 0.2918
- 0.2842
- 0.3015
- 0.2829
- 0.2995
- 0.2755
- 0.2997
- 0.2977
- 0.3051
- 0.3025
- 0.2988
- 0.3026
- 0.3021
- 0.3077
- 0.2951
- 0.3038
- 0.3081
- 0.3076
- 0.2863
- 0.31
- 0.3109
- 0.2916
- 0.307
- 0.3027
- 0.312
- 0.3038
- 0.3021
- 0.3061
- 0.3045
- 0.3046
test_loss_list:
- 1.8020906305313111
- 1.686297287940979
- 1.6383339858055115
- 1.6239687061309815
- 1.5820275521278382
- 1.545449938774109
- 1.5376701760292053
- 1.5231683039665223
- 1.5078181195259095
- 1.526998815536499
- 1.4900809931755066
- 1.470759286880493
- 1.4487705755233764
- 1.4387376189231873
- 1.4351687169075011
- 1.4213277387619019
- 1.4216476082801819
- 1.4213606524467468
- 1.430799925327301
- 1.3947185587882995
- 1.4581723046302795
- 1.3836597323417663
- 1.4239100813865662
- 1.3692428398132324
- 1.4153141927719117
- 1.3700939345359802
- 1.3563291430473328
- 1.4020696234703065
- 1.3526673555374145
- 1.3455830550193786
- 1.3530473232269287
- 1.3497239756584167
- 1.3833613419532775
- 1.328539490699768
- 1.3158009266853332
- 1.321524293422699
- 1.3143605399131775
- 1.3202886819839477
- 1.3236366748809814
- 1.331960129737854
- 1.3118276524543762
- 1.3159979367256165
- 1.3309456777572632
- 1.3233153796195984
- 1.317270131111145
- 1.2999189138412475
- 1.3116283345222473
- 1.324347858428955
- 1.327857291698456
- 1.3035197639465332
- 1.306980905532837
- 1.314261555671692
- 1.3023623752593994
- 1.2872394394874573
- 1.317223265171051
- 1.2289336943626403
- 1.2589767575263977
- 1.2808251810073852
- 1.2651006770133972
- 1.2647092604637147
- 1.28962744474411
- 1.2702235317230224
- 1.2737571144104003
- 1.2692695116996766
- 1.2730603289604188
- 1.276944532394409
- 1.3014323568344117
- 1.263850429058075
- 1.300536913871765
- 1.3238063192367553
- 1.2759943461418153
- 1.3034069633483887
- 1.2690640687942505
- 1.3189171481132507
- 1.2758892965316773
- 1.3199867606163025
- 1.2694724321365356
- 1.2820918226242066
- 1.2615877532958983
- 1.2713697147369385
- 1.2911304140090942
- 1.2738017797470094
- 1.27757954120636
- 1.2688019132614137
- 1.317231228351593
- 1.2778632616996766
- 1.278981969356537
- 1.2766498875617982
- 1.3204561638832093
- 1.2772481942176819
- 1.2773485040664674
- 1.325187602043152
- 1.2700318121910095
- 1.2811274385452271
- 1.2756545186042785
- 1.285053207874298
- 1.2973538827896118
- 1.29141206741333
- 1.288565707206726
- 1.300538077354431
train_accuracy:
- 0.0
- 0.088
- 0.0
- 0.085
- 0.0
- 0.151
- 0.21
- 0.119
- 0.142
- 0.15
- 0.174
- 0.0
- 0.142
- 0.195
- 0.209
- 0.0
- 0.256
- 0.0
- 0.208
- 0.218
- 0.182
- 0.249
- 0.204
- 0.271
- 0.214
- 0.225
- 0.194
- 0.0
- 0.273
- 0.203
- 0.29
- 0.271
- 0.251
- 0.0
- 0.264
- 0.279
- 0.275
- 0.297
- 0.301
- 0.0
- 0.303
- 0.215
- 0.0
- 0.295
- 0.24
- 0.289
- 0.0
- 0.284
- 0.306
- 0.245
- 0.246
- 0.353
- 0.31
- 0.294
- 0.173
- 0.266
- 0.0
- 0.0
- 0.285
- 0.309
- 0.0
- 0.334
- 0.308
- 0.334
- 0.314
- 0.0
- 0.0
- 0.313
- 0.0
- 0.0
- 0.324
- 0.0
- 0.262
- 0.0
- 0.308
- 0.0
- 0.363
- 0.0
- 0.0
- 0.263
- 0.334
- 0.313
- 0.261
- 0.288
- 0.0
- 0.365
- 0.0
- 0.311
- 0.249
- 0.27
- 0.283
- 0.279
- 0.264
- 0.339
- 0.273
- 0.0
- 0.302
- 0.0
- 0.0
- 0.324
train_loss:
- 1.849
- 2.874
- 2.672
- 1.592
- 2.487
- 3.125
- 2.929
- 2.222
- 2.744
- 1.299
- 1.968
- 1.968
- 2.2
- 1.841
- 1.86
- 1.929
- 1.882
- 1.815
- 1.183
- 2.115
- 1.086
- 1.595
- 1.03
- 1.964
- 0.86
- 1.525
- 1.422
- 0.914
- 1.716
- 1.769
- 1.302
- 1.106
- 0.975
- 1.369
- 1.582
- 1.543
- 1.401
- 1.281
- 0.975
- 0.866
- 1.363
- 1.354
- 0.965
- 0.989
- 0.913
- 1.008
- 0.919
- 0.903
- 0.859
- 0.807
- 0.922
- 0.955
- 0.78
- 0.971
- 0.495
- 0.91
- 0.616
- 0.495
- 0.763
- 0.608
- 0.53
- 0.736
- 0.608
- 0.667
- 0.61
- 0.524
- 0.496
- 0.631
- 0.549
- 0.508
- 0.513
- 0.477
- 0.75
- 0.382
- 0.444
- 0.462
- 0.553
- 0.462
- 0.565
- 0.494
- 0.41
- 0.435
- 0.442
- 0.485
- 0.39
- 0.496
- 0.385
- 0.35
- 0.403
- 0.42
- 0.352
- 0.39
- 0.4
- 0.36
- 0.333
- 0.369
- 0.321
- 0.336
- 0.322
- 0.272
unequal: 0
verbose: 1
