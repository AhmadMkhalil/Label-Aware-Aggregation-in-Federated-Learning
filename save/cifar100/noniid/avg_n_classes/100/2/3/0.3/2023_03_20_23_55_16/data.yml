avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0432
- 0.0795
- 0.0959
- 0.1225
- 0.1406
- 0.1367
- 0.1547
- 0.1506
- 0.1577
- 0.182
- 0.1775
- 0.191
- 0.1949
- 0.2051
- 0.1853
- 0.2109
- 0.2132
- 0.214
- 0.2235
- 0.2181
- 0.2137
- 0.1777
- 0.2307
- 0.2132
- 0.2359
- 0.2151
- 0.2427
- 0.2392
- 0.2381
- 0.2447
- 0.2483
- 0.2509
- 0.2283
- 0.2543
- 0.2481
- 0.2564
- 0.2586
- 0.2595
- 0.2659
- 0.2686
- 0.2652
- 0.2455
- 0.2661
- 0.2528
- 0.2506
- 0.2775
- 0.2761
- 0.2863
- 0.2751
- 0.2594
- 0.2789
- 0.2841
- 0.2824
- 0.2817
- 0.261
- 0.2804
- 0.2853
- 0.2847
- 0.2693
- 0.2838
- 0.2806
- 0.2658
- 0.2851
- 0.2869
- 0.2666
- 0.28
- 0.2864
- 0.2899
- 0.2646
- 0.289
- 0.2859
- 0.2662
- 0.2738
- 0.2839
- 0.2728
- 0.2912
- 0.295
- 0.2983
- 0.3018
- 0.2969
- 0.3022
- 0.2813
- 0.2923
- 0.291
- 0.3011
- 0.298
- 0.2977
- 0.3016
- 0.3069
- 0.3037
- 0.3022
- 0.2883
- 0.2976
- 0.303
- 0.3051
- 0.3116
- 0.3078
- 0.3078
- 0.3088
- 0.2907
test_loss_list:
- 1.8071847248077393
- 1.7141772866249085
- 1.6433559036254883
- 1.6010208582878114
- 1.568652901649475
- 1.5737107944488526
- 1.530357265472412
- 1.543725492954254
- 1.539674596786499
- 1.4842724514007568
- 1.4803377032279967
- 1.4670470237731934
- 1.453826355934143
- 1.4457913780212401
- 1.4669685792922973
- 1.4230915665626527
- 1.4125010418891906
- 1.4163804626464844
- 1.407205936908722
- 1.414830241203308
- 1.432146542072296
- 1.4235029697418213
- 1.3317621731758118
- 1.3619956350326539
- 1.33943510055542
- 1.3899587774276734
- 1.329896821975708
- 1.3338665604591369
- 1.3513949131965637
- 1.332368483543396
- 1.335729613304138
- 1.3367203760147095
- 1.376686656475067
- 1.3270924544334413
- 1.3418718934059144
- 1.3233107614517212
- 1.3273093724250793
- 1.332808916568756
- 1.3132815074920654
- 1.3153011870384217
- 1.317000765800476
- 1.3664014172554015
- 1.3267637705802917
- 1.3570990061759949
- 1.352798912525177
- 1.3018048882484436
- 1.3068085765838624
- 1.292355365753174
- 1.3093162870407105
- 1.346963016986847
- 1.3049483609199524
- 1.2964376091957093
- 1.300327389240265
- 1.3113937401771545
- 1.3561265277862549
- 1.307586076259613
- 1.3054788398742676
- 1.300475125312805
- 1.3325524759292602
- 1.2955937528610229
- 1.3106675219535828
- 1.337782392501831
- 1.2947699308395386
- 1.2895723915100097
- 1.3370980262756347
- 1.3102390336990357
- 1.2948892140388488
- 1.2960824179649353
- 1.3463728427886963
- 1.2899965405464173
- 1.2975342988967895
- 1.3351014542579651
- 1.3224891591072083
- 1.2929170966148376
- 1.323778052330017
- 1.2803406071662904
- 1.277264335155487
- 1.2738459205627441
- 1.2845107197761536
- 1.278270537853241
- 1.2744741773605346
- 1.3170931005477906
- 1.2865173244476318
- 1.291976809501648
- 1.2742866492271423
- 1.2902689170837403
- 1.2941079759597778
- 1.2829861879348754
- 1.2741692280769348
- 1.2844542169570923
- 1.2854688596725463
- 1.3235854530334472
- 1.3017843985557556
- 1.285299038887024
- 1.2851909184455872
- 1.2809296226501465
- 1.2845752716064454
- 1.2861703300476075
- 1.2908537578582764
- 1.3389416575431823
train_accuracy:
- 0.0
- 0.0
- 0.114
- 0.1
- 0.159
- 0.111
- 0.179
- 0.0
- 0.0
- 0.194
- 0.221
- 0.166
- 0.238
- 0.167
- 0.0
- 0.168
- 0.259
- 0.194
- 0.22
- 0.0
- 0.0
- 0.358
- 0.22
- 0.0
- 0.28
- 0.0
- 0.231
- 0.216
- 0.0
- 0.264
- 0.229
- 0.269
- 0.0
- 0.0
- 0.0
- 0.258
- 0.237
- 0.263
- 0.247
- 0.246
- 0.0
- 0.237
- 0.254
- 0.0
- 0.0
- 0.269
- 0.271
- 0.271
- 0.0
- 0.0
- 0.337
- 0.277
- 0.256
- 0.264
- 0.234
- 0.338
- 0.254
- 0.0
- 0.0
- 0.285
- 0.349
- 0.252
- 0.261
- 0.271
- 0.0
- 0.267
- 0.292
- 0.0
- 0.0
- 0.277
- 0.326
- 0.0
- 0.0
- 0.0
- 0.0
- 0.343
- 0.291
- 0.316
- 0.265
- 0.0
- 0.296
- 0.245
- 0.291
- 0.277
- 0.279
- 0.304
- 0.349
- 0.0
- 0.323
- 0.382
- 0.302
- 0.27
- 0.292
- 0.327
- 0.0
- 0.304
- 0.316
- 0.318
- 0.0
- 0.0
train_loss:
- 3.131
- 1.672
- 2.615
- 2.516
- 3.3
- 1.538
- 2.349
- 1.406
- 1.409
- 2.834
- 1.96
- 2.616
- 2.576
- 2.003
- 1.329
- 2.527
- 2.311
- 1.732
- 1.673
- 1.552
- 1.11
- 0.542
- 1.608
- 0.954
- 1.993
- 0.951
- 2.004
- 1.801
- 1.23
- 1.811
- 1.604
- 1.496
- 0.841
- 1.528
- 1.114
- 1.481
- 1.301
- 1.347
- 1.686
- 1.176
- 1.206
- 0.76
- 0.983
- 0.695
- 0.756
- 1.237
- 1.089
- 1.183
- 0.826
- 0.703
- 1.057
- 1.131
- 0.911
- 0.654
- 0.547
- 0.837
- 0.726
- 0.952
- 0.658
- 0.823
- 0.687
- 0.521
- 0.685
- 0.665
- 0.509
- 0.553
- 0.65
- 0.56
- 0.587
- 0.698
- 0.562
- 0.414
- 0.567
- 0.478
- 0.502
- 0.559
- 0.476
- 0.649
- 0.521
- 0.614
- 0.502
- 0.456
- 0.412
- 0.45
- 0.523
- 0.515
- 0.459
- 0.453
- 0.423
- 0.403
- 0.404
- 0.35
- 0.398
- 0.39
- 0.426
- 0.32
- 0.338
- 0.317
- 0.347
- 0.357
unequal: 0
verbose: 1
