avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0457
- 0.093
- 0.1111
- 0.1253
- 0.1318
- 0.1482
- 0.1572
- 0.1695
- 0.1828
- 0.182
- 0.1987
- 0.1977
- 0.2047
- 0.2039
- 0.2052
- 0.2137
- 0.2178
- 0.2216
- 0.2282
- 0.2235
- 0.2287
- 0.2126
- 0.2392
- 0.2369
- 0.239
- 0.2392
- 0.2383
- 0.2517
- 0.2529
- 0.2537
- 0.251
- 0.2528
- 0.2504
- 0.2569
- 0.2457
- 0.2598
- 0.2552
- 0.2562
- 0.2597
- 0.2679
- 0.2474
- 0.2547
- 0.2546
- 0.2698
- 0.2755
- 0.2804
- 0.2784
- 0.2744
- 0.2791
- 0.2751
- 0.2549
- 0.2757
- 0.2691
- 0.2615
- 0.252
- 0.2791
- 0.2824
- 0.2844
- 0.2866
- 0.2845
- 0.2914
- 0.2828
- 0.2851
- 0.2693
- 0.2667
- 0.2822
- 0.2791
- 0.2796
- 0.2881
- 0.293
- 0.2937
- 0.284
- 0.2863
- 0.2938
- 0.2921
- 0.2885
- 0.2893
- 0.2752
- 0.3012
- 0.2779
- 0.2906
- 0.2952
- 0.3009
- 0.2966
- 0.2921
- 0.294
- 0.2955
- 0.2912
- 0.2966
- 0.2972
- 0.3028
- 0.2998
- 0.3006
- 0.3066
- 0.2893
- 0.3027
- 0.2845
- 0.3015
- 0.2953
- 0.2874
test_loss_list:
- 1.7872047662734984
- 1.6846045875549316
- 1.6367356133461
- 1.611354398727417
- 1.5903810024261475
- 1.5624647068977355
- 1.5355446648597717
- 1.5164346241950988
- 1.4975142526626586
- 1.4903724098205566
- 1.461828088760376
- 1.465931634902954
- 1.4571915292739868
- 1.4567945790290833
- 1.4512096047401428
- 1.4340916085243225
- 1.4300358271598816
- 1.417424557209015
- 1.4128397870063782
- 1.4080235266685486
- 1.411680176258087
- 1.4316266989707946
- 1.3886610388755798
- 1.3874014592170716
- 1.3870689511299132
- 1.3845556426048278
- 1.3863183903694152
- 1.3665523147583007
- 1.3583527088165284
- 1.3633693552017212
- 1.3636757469177245
- 1.3564228701591492
- 1.3648404026031493
- 1.3573459768295288
- 1.3754076290130615
- 1.3490981936454773
- 1.3664728856086732
- 1.3581564927101135
- 1.3486505794525145
- 1.331279034614563
- 1.388239359855652
- 1.360567717552185
- 1.3619200158119202
- 1.3264836931228638
- 1.315046293735504
- 1.3111428999900818
- 1.3128538537025451
- 1.3166805624961853
- 1.3153703308105469
- 1.3226689410209655
- 1.3673888039588928
- 1.3132734203338623
- 1.3293588709831239
- 1.3650007390975951
- 1.3669037842750549
- 1.3060534358024598
- 1.3132224988937378
- 1.307118308544159
- 1.3035251092910767
- 1.3079303121566772
- 1.298501193523407
- 1.304647479057312
- 1.3114440989494325
- 1.3438559436798097
- 1.361337389945984
- 1.3198982691764831
- 1.3159219479560853
- 1.3284723591804504
- 1.294378845691681
- 1.29596182346344
- 1.2919987535476685
- 1.3115150022506714
- 1.314569342136383
- 1.298898868560791
- 1.3059351658821106
- 1.3014656472206116
- 1.2957235884666443
- 1.349761085510254
- 1.2900956606864928
- 1.3288557934761047
- 1.3045995759963989
- 1.2950083780288697
- 1.290755934715271
- 1.3122996664047242
- 1.3101154732704163
- 1.309548864364624
- 1.2963933801651002
- 1.3103367900848388
- 1.3024787068367005
- 1.303840925693512
- 1.2970622420310973
- 1.3104321098327636
- 1.3022172617912293
- 1.2952937293052673
- 1.3350978660583497
- 1.2947664880752563
- 1.3357881617546081
- 1.2940060305595398
- 1.312479729652405
- 1.3370142078399658
train_accuracy:
- 0.037
- 0.0
- 0.0
- 0.139
- 0.107
- 0.159
- 0.132
- 0.129
- 0.171
- 0.179
- 0.217
- 0.182
- 0.0
- 0.0
- 0.172
- 0.228
- 0.0
- 0.185
- 0.0
- 0.256
- 0.0
- 0.0
- 0.199
- 0.229
- 0.221
- 0.0
- 0.229
- 0.225
- 0.237
- 0.235
- 0.0
- 0.0
- 0.275
- 0.279
- 0.0
- 0.245
- 0.245
- 0.232
- 0.236
- 0.276
- 0.281
- 0.0
- 0.229
- 0.303
- 0.261
- 0.261
- 0.246
- 0.247
- 0.293
- 0.0
- 0.0
- 0.0
- 0.0
- 0.259
- 0.0
- 0.273
- 0.297
- 0.0
- 0.268
- 0.0
- 0.302
- 0.265
- 0.0
- 0.257
- 0.0
- 0.258
- 0.249
- 0.0
- 0.278
- 0.292
- 0.263
- 0.266
- 0.272
- 0.314
- 0.265
- 0.3
- 0.0
- 0.304
- 0.283
- 0.253
- 0.324
- 0.326
- 0.281
- 0.326
- 0.0
- 0.315
- 0.326
- 0.297
- 0.326
- 0.309
- 0.281
- 0.324
- 0.29
- 0.319
- 0.297
- 0.287
- 0.31
- 0.29
- 0.0
- 0.0
train_loss:
- 3.024
- 2.69
- 2.646
- 2.388
- 2.302
- 2.317
- 3.122
- 3.124
- 2.95
- 2.099
- 2.776
- 2.666
- 1.974
- 1.831
- 1.854
- 1.865
- 1.847
- 2.21
- 1.763
- 2.157
- 1.581
- 1.179
- 1.967
- 2.012
- 1.868
- 1.385
- 1.441
- 1.802
- 1.863
- 1.6
- 1.366
- 1.292
- 1.222
- 1.145
- 0.987
- 1.325
- 1.036
- 1.103
- 1.164
- 1.451
- 0.868
- 0.762
- 0.912
- 1.055
- 1.198
- 1.243
- 0.973
- 0.8
- 0.766
- 0.755
- 0.61
- 0.884
- 0.701
- 0.502
- 0.627
- 0.992
- 0.658
- 0.957
- 0.78
- 0.68
- 0.757
- 0.685
- 0.58
- 0.646
- 0.529
- 0.693
- 0.656
- 0.506
- 0.646
- 0.58
- 0.644
- 0.632
- 0.487
- 0.711
- 0.478
- 0.623
- 0.438
- 0.426
- 0.479
- 0.529
- 0.4
- 0.368
- 0.561
- 0.408
- 0.537
- 0.376
- 0.455
- 0.371
- 0.328
- 0.498
- 0.375
- 0.371
- 0.442
- 0.358
- 0.358
- 0.393
- 0.336
- 0.363
- 0.327
- 0.43
unequal: 0
verbose: 1
