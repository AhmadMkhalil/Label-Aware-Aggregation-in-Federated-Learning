avg_train_accuracy: 0.269
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037
- 0.0903
- 0.1116
- 0.1308
- 0.142
- 0.1513
- 0.1656
- 0.1774
- 0.1848
- 0.1894
- 0.1935
- 0.197
- 0.2047
- 0.2121
- 0.2172
- 0.2177
- 0.2281
- 0.2272
- 0.2368
- 0.2398
- 0.2457
- 0.2444
- 0.2517
- 0.2508
- 0.2562
- 0.2575
- 0.2575
- 0.2583
- 0.2571
- 0.2652
- 0.261
- 0.2593
- 0.2707
- 0.2716
- 0.2668
- 0.275
- 0.2768
- 0.2787
- 0.2745
- 0.2794
- 0.2864
- 0.287
- 0.2906
- 0.2881
- 0.293
- 0.2926
- 0.2899
- 0.2978
- 0.2968
- 0.2944
- 0.301
- 0.2985
- 0.2984
- 0.2982
- 0.2997
- 0.2996
- 0.3037
- 0.3049
- 0.2967
- 0.3063
- 0.2979
- 0.2979
- 0.3045
- 0.3034
- 0.3033
- 0.3091
- 0.3064
- 0.3043
- 0.3078
- 0.3092
- 0.3084
- 0.3081
- 0.3113
- 0.3119
- 0.3098
- 0.3074
- 0.3128
- 0.3094
- 0.3109
- 0.3158
- 0.3167
- 0.3131
- 0.3164
- 0.3143
- 0.3105
- 0.3134
- 0.3141
- 0.3134
- 0.3143
- 0.3157
- 0.3138
- 0.3133
- 0.3164
- 0.3109
- 0.3125
- 0.313
- 0.3158
- 0.3153
- 0.3165
- 0.3146
test_loss_list:
- 1.8196359395980835
- 1.6876359939575196
- 1.6368849897384643
- 1.5890186023712158
- 1.561120207309723
- 1.5393354082107544
- 1.5151922106742859
- 1.4979867458343505
- 1.4854790091514587
- 1.4711879658699036
- 1.4575769543647765
- 1.4462949061393737
- 1.433540530204773
- 1.4227407741546632
- 1.4120013523101806
- 1.4042324209213257
- 1.3848886370658875
- 1.3795451378822328
- 1.3644890832901
- 1.3654469847679138
- 1.356407768726349
- 1.3471790289878844
- 1.3391433691978454
- 1.3377547788619994
- 1.3335637640953064
- 1.321741325855255
- 1.315670964717865
- 1.3225596070289611
- 1.3140685153007508
- 1.3000299167633056
- 1.3113046884536743
- 1.3058171010017394
- 1.2855248427391053
- 1.2876434564590453
- 1.295239109992981
- 1.2772957110404968
- 1.276019446849823
- 1.277778398990631
- 1.28305358171463
- 1.2732308316230774
- 1.2584407973289489
- 1.2637189745903015
- 1.2555344676971436
- 1.2569337821006774
- 1.2488207483291627
- 1.24784752368927
- 1.2575253415107728
- 1.243887219429016
- 1.2514362168312072
- 1.2566748690605163
- 1.2481916666030883
- 1.2409624934196473
- 1.2460216498374939
- 1.2391523718833923
- 1.2441406083106994
- 1.2470536851882934
- 1.2362487292289734
- 1.234527461528778
- 1.2505302739143371
- 1.2371017932891846
- 1.2519996881484985
- 1.244451367855072
- 1.238382604122162
- 1.235620415210724
- 1.2437307929992676
- 1.2335662579536437
- 1.2349485993385314
- 1.2397505617141724
- 1.2300079488754272
- 1.2317767763137817
- 1.2330099487304687
- 1.2378754425048828
- 1.236603524684906
- 1.23183021068573
- 1.236812083721161
- 1.2411249208450317
- 1.2311737465858459
- 1.234884340763092
- 1.2411217236518859
- 1.227725338935852
- 1.230544080734253
- 1.2372134470939635
- 1.2288405060768128
- 1.2376624655723572
- 1.2382343673706055
- 1.2332947945594788
- 1.2399389791488646
- 1.2384070134162903
- 1.2394487357139587
- 1.2450881576538086
- 1.2365207934379578
- 1.2434589314460753
- 1.2392004108428956
- 1.2448277759552002
- 1.241407971382141
- 1.24642817735672
- 1.234252347946167
- 1.2346583676338196
- 1.236843535900116
- 1.24453693151474
train_accuracy:
- 0.024
- 0.074
- 0.13
- 0.105
- 0.114
- 0.162
- 0.148
- 0.2
- 0.165
- 0.209
- 0.225
- 0.0
- 0.207
- 0.0
- 0.254
- 0.0
- 0.23
- 0.193
- 0.241
- 0.169
- 0.24
- 0.0
- 0.0
- 0.247
- 0.265
- 0.0
- 0.312
- 0.304
- 0.0
- 0.316
- 0.0
- 0.0
- 0.274
- 0.309
- 0.235
- 0.0
- 0.232
- 0.305
- 0.0
- 0.235
- 0.24
- 0.0
- 0.0
- 0.0
- 0.0
- 0.248
- 0.307
- 0.306
- 0.263
- 0.288
- 0.334
- 0.253
- 0.336
- 0.0
- 0.26
- 0.261
- 0.0
- 0.323
- 0.243
- 0.0
- 0.316
- 0.0
- 0.259
- 0.251
- 0.333
- 0.0
- 0.311
- 0.0
- 0.0
- 0.325
- 0.343
- 0.263
- 0.334
- 0.307
- 0.316
- 0.0
- 0.342
- 0.309
- 0.326
- 0.238
- 0.338
- 0.352
- 0.0
- 0.344
- 0.329
- 0.335
- 0.248
- 0.258
- 0.324
- 0.282
- 0.0
- 0.0
- 0.0
- 0.25
- 0.0
- 0.34
- 0.0
- 0.323
- 0.264
- 0.269
train_loss:
- 3.634
- 3.291
- 2.997
- 2.353
- 3.266
- 2.129
- 3.081
- 2.974
- 2.406
- 2.699
- 1.942
- 1.876
- 2.183
- 2.161
- 2.082
- 1.748
- 1.631
- 1.612
- 1.828
- 1.503
- 2.028
- 1.475
- 1.696
- 1.709
- 1.381
- 1.626
- 1.439
- 1.252
- 1.226
- 1.263
- 0.978
- 1.063
- 1.272
- 1.225
- 0.911
- 1.33
- 1.154
- 1.023
- 0.81
- 1.003
- 1.049
- 0.953
- 1.065
- 0.873
- 0.866
- 1.034
- 0.772
- 1.008
- 0.81
- 0.859
- 0.783
- 0.755
- 0.727
- 0.702
- 0.713
- 0.737
- 0.702
- 0.664
- 0.677
- 0.699
- 0.645
- 0.568
- 0.585
- 0.632
- 0.558
- 0.591
- 0.613
- 0.604
- 0.5
- 0.542
- 0.521
- 0.518
- 0.478
- 0.496
- 0.493
- 0.487
- 0.485
- 0.47
- 0.426
- 0.46
- 0.405
- 0.475
- 0.4
- 0.364
- 0.389
- 0.395
- 0.364
- 0.325
- 0.408
- 0.352
- 0.366
- 0.353
- 0.33
- 0.395
- 0.359
- 0.359
- 0.327
- 0.279
- 0.365
- 0.359
unequal: 0
verbose: 1
