avg_train_accuracy: 0.368
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0418
- 0.0978
- 0.1138
- 0.1348
- 0.133
- 0.1572
- 0.1588
- 0.1642
- 0.1801
- 0.1813
- 0.1859
- 0.1939
- 0.2016
- 0.2027
- 0.2038
- 0.21
- 0.2151
- 0.2185
- 0.2211
- 0.2269
- 0.2256
- 0.2259
- 0.2317
- 0.2354
- 0.24
- 0.2428
- 0.2453
- 0.2549
- 0.2532
- 0.2525
- 0.2609
- 0.2577
- 0.2607
- 0.2607
- 0.2666
- 0.2717
- 0.2724
- 0.2732
- 0.2691
- 0.2741
- 0.2806
- 0.2805
- 0.2811
- 0.2795
- 0.2864
- 0.2828
- 0.2836
- 0.2824
- 0.2804
- 0.2898
- 0.2861
- 0.2852
- 0.2907
- 0.2847
- 0.2902
- 0.2938
- 0.2916
- 0.2966
- 0.2979
- 0.2971
- 0.2932
- 0.2944
- 0.2991
- 0.2996
- 0.2929
- 0.3001
- 0.3064
- 0.2996
- 0.3013
- 0.2965
- 0.3039
- 0.3055
- 0.3037
- 0.3036
- 0.3058
- 0.3076
- 0.3067
- 0.3068
- 0.3053
- 0.3072
- 0.3034
- 0.3011
- 0.298
- 0.3075
- 0.3104
- 0.3038
- 0.3096
- 0.3113
- 0.3085
- 0.3112
- 0.3122
- 0.3049
- 0.313
- 0.3117
- 0.3133
- 0.3158
- 0.3077
- 0.3072
- 0.304
- 0.3067
test_loss_list:
- 1.79119300365448
- 1.6710166764259338
- 1.6230504512786865
- 1.581074788570404
- 1.564304323196411
- 1.531219754219055
- 1.5218271613121033
- 1.50204021692276
- 1.4810583639144896
- 1.4702209043502807
- 1.462313551902771
- 1.449653789997101
- 1.43415931224823
- 1.4344283986091613
- 1.4182799696922301
- 1.4096894240379334
- 1.3996094131469727
- 1.3929279136657715
- 1.3934898686408996
- 1.3851944923400878
- 1.3798054218292237
- 1.3657801175117492
- 1.366415193080902
- 1.3542584824562072
- 1.3473210120201111
- 1.3378373169898987
- 1.3293126106262207
- 1.3208434748649598
- 1.321736490726471
- 1.3243237471580505
- 1.3143732595443725
- 1.3087351393699647
- 1.3068719935417175
- 1.3106134486198426
- 1.2994675278663634
- 1.2957116293907165
- 1.2892214417457581
- 1.2964520287513732
- 1.2889934253692628
- 1.288172917366028
- 1.2751191139221192
- 1.278544363975525
- 1.2710261702537538
- 1.2669612503051757
- 1.2644307374954225
- 1.264465742111206
- 1.267796459197998
- 1.2734375643730163
- 1.2731270742416383
- 1.2589462852478028
- 1.2619423246383668
- 1.256940631866455
- 1.2529820060729981
- 1.2686051273345946
- 1.2515147352218627
- 1.2518975281715392
- 1.2559462881088257
- 1.2482137274742127
- 1.2477347040176392
- 1.2476651501655578
- 1.256935110092163
- 1.2498515272140502
- 1.2481288981437684
- 1.2539333009719849
- 1.2692048168182373
- 1.24601726770401
- 1.240066168308258
- 1.2472806406021117
- 1.2445685005187987
- 1.2474243688583373
- 1.2418553590774537
- 1.2387882900238036
- 1.2383351731300354
- 1.2434187269210815
- 1.238913769721985
- 1.233716914653778
- 1.2416507172584534
- 1.2484826803207398
- 1.238286669254303
- 1.2418632793426514
- 1.244897985458374
- 1.245835738182068
- 1.2625223231315612
- 1.248364145755768
- 1.239068112373352
- 1.2513010430335998
- 1.243574001789093
- 1.2492173862457276
- 1.2356802392005921
- 1.235706765651703
- 1.2462364315986634
- 1.246435489654541
- 1.2336825609207154
- 1.2422021794319154
- 1.2414458179473877
- 1.241544930934906
- 1.2564253902435303
- 1.2436845731735229
- 1.257044644355774
- 1.249344437122345
train_accuracy:
- 0.045
- 0.0
- 0.124
- 0.101
- 0.0
- 0.158
- 0.0
- 0.0
- 0.16
- 0.19
- 0.0
- 0.169
- 0.186
- 0.249
- 0.264
- 0.185
- 0.0
- 0.215
- 0.29
- 0.0
- 0.221
- 0.242
- 0.218
- 0.218
- 0.225
- 0.0
- 0.0
- 0.245
- 0.238
- 0.212
- 0.235
- 0.235
- 0.0
- 0.0
- 0.276
- 0.0
- 0.0
- 0.249
- 0.0
- 0.253
- 0.0
- 0.255
- 0.0
- 0.0
- 0.256
- 0.246
- 0.0
- 0.255
- 0.269
- 0.259
- 0.0
- 0.244
- 0.289
- 0.0
- 0.0
- 0.247
- 0.266
- 0.295
- 0.263
- 0.323
- 0.246
- 0.244
- 0.292
- 0.267
- 0.0
- 0.297
- 0.364
- 0.0
- 0.0
- 0.0
- 0.377
- 0.373
- 0.261
- 0.0
- 0.0
- 0.374
- 0.307
- 0.274
- 0.276
- 0.267
- 0.281
- 0.0
- 0.0
- 0.0
- 0.275
- 0.0
- 0.377
- 0.27
- 0.0
- 0.299
- 0.376
- 0.303
- 0.292
- 0.0
- 0.27
- 0.275
- 0.0
- 0.267
- 0.0
- 0.368
train_loss:
- 4.32
- 2.531
- 2.4
- 3.441
- 1.675
- 2.184
- 2.071
- 1.568
- 2.447
- 2.34
- 1.434
- 2.188
- 2.189
- 1.709
- 1.669
- 1.972
- 1.619
- 1.979
- 1.455
- 1.417
- 1.381
- 1.478
- 1.466
- 1.273
- 1.156
- 1.221
- 1.378
- 1.501
- 1.426
- 1.23
- 1.423
- 1.437
- 1.289
- 0.85
- 1.231
- 1.11
- 1.183
- 1.01
- 1.022
- 0.927
- 1.122
- 0.997
- 0.943
- 0.869
- 1.005
- 0.964
- 0.804
- 0.775
- 0.641
- 0.844
- 0.714
- 0.716
- 0.708
- 0.621
- 0.634
- 0.654
- 0.653
- 0.701
- 0.757
- 0.692
- 0.577
- 0.569
- 0.59
- 0.56
- 0.429
- 0.624
- 0.637
- 0.473
- 0.539
- 0.482
- 0.559
- 0.545
- 0.442
- 0.463
- 0.437
- 0.504
- 0.476
- 0.431
- 0.45
- 0.402
- 0.406
- 0.381
- 0.394
- 0.367
- 0.378
- 0.363
- 0.38
- 0.362
- 0.388
- 0.33
- 0.319
- 0.322
- 0.334
- 0.357
- 0.289
- 0.312
- 0.326
- 0.34
- 0.301
- 0.282
unequal: 0
verbose: 1
