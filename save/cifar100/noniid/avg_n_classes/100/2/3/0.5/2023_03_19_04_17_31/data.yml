avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0478
- 0.0961
- 0.1166
- 0.1341
- 0.1486
- 0.1612
- 0.1691
- 0.1681
- 0.1782
- 0.181
- 0.1922
- 0.1965
- 0.2042
- 0.2133
- 0.2148
- 0.2183
- 0.229
- 0.2256
- 0.236
- 0.2377
- 0.2303
- 0.2391
- 0.2413
- 0.249
- 0.2429
- 0.2532
- 0.2503
- 0.2498
- 0.2631
- 0.2587
- 0.2601
- 0.2687
- 0.2699
- 0.2711
- 0.2726
- 0.2628
- 0.2724
- 0.2744
- 0.2834
- 0.2752
- 0.2824
- 0.2826
- 0.285
- 0.2831
- 0.2848
- 0.2837
- 0.2799
- 0.2928
- 0.2899
- 0.2906
- 0.2905
- 0.2952
- 0.2927
- 0.2913
- 0.2955
- 0.2881
- 0.296
- 0.3011
- 0.3005
- 0.2963
- 0.3005
- 0.2931
- 0.3002
- 0.2998
- 0.3008
- 0.2986
- 0.3053
- 0.3017
- 0.2967
- 0.3025
- 0.3028
- 0.3028
- 0.305
- 0.3052
- 0.3097
- 0.3081
- 0.3047
- 0.3064
- 0.2998
- 0.3029
- 0.3063
- 0.3048
- 0.3024
- 0.3101
- 0.3102
- 0.3075
- 0.3092
- 0.3082
- 0.3134
- 0.3112
- 0.3105
- 0.3107
- 0.3131
- 0.3153
- 0.311
- 0.3112
- 0.3158
- 0.3083
- 0.312
- 0.3117
test_loss_list:
- 1.7857291030883788
- 1.6645690679550171
- 1.6176370930671693
- 1.5820626783370972
- 1.5514480185508728
- 1.5242172479629517
- 1.5099699878692627
- 1.4993385148048402
- 1.4824922895431518
- 1.4707440900802613
- 1.4500409388542175
- 1.4410254311561586
- 1.4280038928985597
- 1.4122056126594544
- 1.4071555209159852
- 1.3972477436065673
- 1.3856747174263
- 1.382957763671875
- 1.3748348402976989
- 1.3661478281021118
- 1.3703191661834717
- 1.3577828574180604
- 1.345895173549652
- 1.3351895666122438
- 1.342142210006714
- 1.324351909160614
- 1.3297088623046875
- 1.3328955578804016
- 1.3146844387054444
- 1.3172413611412048
- 1.3088050961494446
- 1.2958320116996764
- 1.2993955183029176
- 1.2936871790885924
- 1.2957537627220155
- 1.3045048904418945
- 1.2891692519187927
- 1.287661738395691
- 1.2730717611312867
- 1.2764503002166747
- 1.2672536778450012
- 1.2732515478134154
- 1.2678496623039246
- 1.2712593960762024
- 1.2668083262443544
- 1.2617448806762694
- 1.2749310064315795
- 1.2554511904716492
- 1.2615434622764587
- 1.2639285278320314
- 1.2654878997802734
- 1.2608451986312865
- 1.2572885298728942
- 1.2493492722511292
- 1.2530991864204406
- 1.2640460467338561
- 1.2467982625961305
- 1.2472912454605103
- 1.2550045466423034
- 1.2604268264770508
- 1.2524379730224608
- 1.255784251689911
- 1.2521487164497376
- 1.2550653338432312
- 1.2580085825920104
- 1.255299232006073
- 1.2523541021347047
- 1.2531248784065248
- 1.2544625234603881
- 1.2502079367637635
- 1.25304044008255
- 1.2527119207382202
- 1.2525148963928223
- 1.252496588230133
- 1.2469440293312073
- 1.2542458415031432
- 1.2561935353279114
- 1.2540937852859497
- 1.2607330250740052
- 1.249992129802704
- 1.2520464658737183
- 1.253892502784729
- 1.2577811646461488
- 1.2479069805145264
- 1.2469195604324341
- 1.2500025987625123
- 1.2505867528915404
- 1.2533856439590454
- 1.2494527626037597
- 1.2553294110298157
- 1.2527472615242004
- 1.2532674622535707
- 1.253142762184143
- 1.2500057244300842
- 1.2572900772094726
- 1.2506864404678344
- 1.2481493496894835
- 1.2551598072052002
- 1.24789555311203
- 1.2601881265640258
train_accuracy:
- 0.058
- 0.103
- 0.0
- 0.118
- 0.136
- 0.14
- 0.151
- 0.146
- 0.154
- 0.161
- 0.177
- 0.0
- 0.221
- 0.16
- 0.199
- 0.196
- 0.0
- 0.207
- 0.208
- 0.206
- 0.273
- 0.267
- 0.0
- 0.0
- 0.0
- 0.221
- 0.217
- 0.207
- 0.223
- 0.218
- 0.226
- 0.246
- 0.0
- 0.262
- 0.229
- 0.229
- 0.259
- 0.249
- 0.262
- 0.264
- 0.0
- 0.257
- 0.0
- 0.257
- 0.0
- 0.256
- 0.0
- 0.264
- 0.279
- 0.314
- 0.278
- 0.245
- 0.0
- 0.302
- 0.271
- 0.249
- 0.0
- 0.334
- 0.326
- 0.0
- 0.276
- 0.264
- 0.338
- 0.288
- 0.246
- 0.292
- 0.306
- 0.306
- 0.281
- 0.301
- 0.0
- 0.0
- 0.293
- 0.283
- 0.311
- 0.291
- 0.0
- 0.287
- 0.326
- 0.285
- 0.287
- 0.336
- 0.273
- 0.291
- 0.32
- 0.298
- 0.34
- 0.297
- 0.292
- 0.346
- 0.361
- 0.302
- 0.323
- 0.326
- 0.305
- 0.0
- 0.31
- 0.0
- 0.342
- 0.0
train_loss:
- 2.794
- 2.495
- 2.363
- 2.31
- 2.179
- 2.674
- 2.064
- 1.969
- 1.908
- 1.872
- 2.339
- 1.808
- 2.528
- 2.12
- 1.665
- 1.646
- 1.882
- 1.849
- 2.065
- 1.846
- 1.131
- 1.413
- 1.481
- 1.64
- 1.274
- 1.803
- 1.214
- 0.982
- 1.373
- 1.109
- 1.114
- 1.585
- 1.29
- 1.277
- 0.975
- 0.747
- 1.18
- 0.959
- 1.127
- 0.969
- 0.92
- 0.931
- 0.875
- 0.794
- 0.781
- 0.829
- 0.615
- 0.861
- 0.783
- 0.787
- 0.726
- 0.902
- 0.763
- 0.746
- 0.718
- 0.592
- 0.797
- 0.78
- 0.725
- 0.577
- 0.678
- 0.581
- 0.602
- 0.624
- 0.493
- 0.521
- 0.551
- 0.488
- 0.561
- 0.515
- 0.484
- 0.455
- 0.48
- 0.423
- 0.454
- 0.473
- 0.462
- 0.396
- 0.415
- 0.402
- 0.418
- 0.373
- 0.364
- 0.358
- 0.402
- 0.342
- 0.368
- 0.364
- 0.346
- 0.326
- 0.336
- 0.355
- 0.334
- 0.315
- 0.328
- 0.318
- 0.289
- 0.295
- 0.315
- 0.286
unequal: 0
verbose: 1
