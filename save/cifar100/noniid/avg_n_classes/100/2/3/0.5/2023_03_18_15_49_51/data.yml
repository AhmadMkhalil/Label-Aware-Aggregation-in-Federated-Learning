avg_train_accuracy: 0.301
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041
- 0.0876
- 0.116
- 0.1358
- 0.1463
- 0.1582
- 0.1604
- 0.1697
- 0.1816
- 0.1867
- 0.1912
- 0.1976
- 0.2068
- 0.1972
- 0.2087
- 0.2163
- 0.2203
- 0.2285
- 0.2271
- 0.2251
- 0.2361
- 0.2332
- 0.2452
- 0.2465
- 0.2485
- 0.2488
- 0.2533
- 0.2565
- 0.2603
- 0.2608
- 0.268
- 0.2581
- 0.2698
- 0.2649
- 0.2724
- 0.2718
- 0.2694
- 0.2754
- 0.2733
- 0.274
- 0.2735
- 0.2789
- 0.2844
- 0.281
- 0.28
- 0.2821
- 0.2845
- 0.2803
- 0.2792
- 0.2887
- 0.2889
- 0.2891
- 0.2779
- 0.2838
- 0.2879
- 0.2855
- 0.2879
- 0.2817
- 0.2916
- 0.288
- 0.2949
- 0.2913
- 0.2981
- 0.2972
- 0.2982
- 0.2993
- 0.2984
- 0.2977
- 0.2984
- 0.2923
- 0.2979
- 0.294
- 0.3041
- 0.2982
- 0.3009
- 0.3034
- 0.3063
- 0.3038
- 0.2984
- 0.3054
- 0.3076
- 0.3053
- 0.302
- 0.3019
- 0.3025
- 0.3055
- 0.3056
- 0.3054
- 0.3039
- 0.3027
- 0.3001
- 0.3095
- 0.3086
- 0.3035
- 0.3089
- 0.3092
- 0.3099
- 0.3072
- 0.3107
- 0.3053
test_loss_list:
- 1.8038181018829347
- 1.6760246801376342
- 1.6211495471000672
- 1.5810780334472656
- 1.5522776818275452
- 1.5331591367721558
- 1.5186832284927367
- 1.4971887683868408
- 1.4781662344932556
- 1.4726730155944825
- 1.459563467502594
- 1.4444555711746216
- 1.4294508695602417
- 1.4360210514068603
- 1.4089861822128296
- 1.4033901762962342
- 1.4009195685386657
- 1.3859687113761903
- 1.378853008747101
- 1.3897927117347717
- 1.3659322476387024
- 1.3628737425804138
- 1.3507850670814514
- 1.3451849603652954
- 1.3393936491012572
- 1.3316191244125366
- 1.3278540587425232
- 1.3219884943962097
- 1.3138623118400574
- 1.3110546898841857
- 1.30248797416687
- 1.318599500656128
- 1.2985836696624755
- 1.295057873725891
- 1.292143359184265
- 1.2896756291389466
- 1.292761583328247
- 1.2853521490097046
- 1.29148540019989
- 1.2860342931747437
- 1.2828737139701842
- 1.274501509666443
- 1.2692557454109192
- 1.2703256177902222
- 1.2739448213577271
- 1.2690780401229858
- 1.269287371635437
- 1.2798811602592468
- 1.2842414021492004
- 1.2522220039367675
- 1.2636048889160156
- 1.2596610879898071
- 1.280424234867096
- 1.2680095434188843
- 1.2482933950424195
- 1.2575360035896301
- 1.2596342301368713
- 1.2580415201187134
- 1.2461236643791198
- 1.251799554824829
- 1.2477534651756286
- 1.2572279357910157
- 1.237727210521698
- 1.2468686962127686
- 1.246111617088318
- 1.251327564716339
- 1.241120047569275
- 1.241630928516388
- 1.2472548127174377
- 1.262892987728119
- 1.2490496969223022
- 1.2592387318611145
- 1.2404969716072083
- 1.2548194336891174
- 1.2496108746528625
- 1.2392940950393676
- 1.2431590509414674
- 1.2459109783172608
- 1.2480036759376525
- 1.243108720779419
- 1.2425612664222718
- 1.244486656188965
- 1.2492944741249083
- 1.2441019678115846
- 1.2451728892326355
- 1.251714415550232
- 1.2599079418182373
- 1.2430645060539245
- 1.2477256059646606
- 1.247824010848999
- 1.2528561234474183
- 1.241279299259186
- 1.2509139561653138
- 1.2513875007629394
- 1.2397388768196107
- 1.241285035610199
- 1.2483432960510255
- 1.2502698707580566
- 1.2486293244361877
- 1.2542934250831603
train_accuracy:
- 0.052
- 0.101
- 0.0
- 0.153
- 0.166
- 0.0
- 0.0
- 0.0
- 0.162
- 0.159
- 0.16
- 0.0
- 0.206
- 0.0
- 0.186
- 0.256
- 0.0
- 0.236
- 0.275
- 0.0
- 0.274
- 0.245
- 0.259
- 0.234
- 0.23
- 0.0
- 0.259
- 0.245
- 0.261
- 0.307
- 0.255
- 0.251
- 0.258
- 0.247
- 0.317
- 0.287
- 0.259
- 0.264
- 0.285
- 0.0
- 0.0
- 0.268
- 0.324
- 0.0
- 0.291
- 0.0
- 0.267
- 0.0
- 0.0
- 0.289
- 0.3
- 0.342
- 0.0
- 0.348
- 0.284
- 0.0
- 0.298
- 0.33
- 0.303
- 0.273
- 0.0
- 0.284
- 0.291
- 0.314
- 0.308
- 0.26
- 0.302
- 0.295
- 0.0
- 0.0
- 0.297
- 0.0
- 0.351
- 0.317
- 0.284
- 0.303
- 0.312
- 0.0
- 0.0
- 0.352
- 0.292
- 0.344
- 0.355
- 0.0
- 0.321
- 0.302
- 0.0
- 0.356
- 0.0
- 0.348
- 0.0
- 0.348
- 0.31
- 0.29
- 0.307
- 0.0
- 0.311
- 0.312
- 0.0
- 0.301
train_loss:
- 3.599
- 2.542
- 2.971
- 2.848
- 2.753
- 2.088
- 1.605
- 2.013
- 2.405
- 1.809
- 1.926
- 1.817
- 2.206
- 1.322
- 2.168
- 1.956
- 1.581
- 2.155
- 1.597
- 1.138
- 1.694
- 1.372
- 1.924
- 1.447
- 1.36
- 1.306
- 1.466
- 1.337
- 1.479
- 1.182
- 1.352
- 0.953
- 1.241
- 1.274
- 1.184
- 1.19
- 0.998
- 1.105
- 0.977
- 0.947
- 0.921
- 1.0
- 0.941
- 1.021
- 0.751
- 0.962
- 0.8
- 0.718
- 0.735
- 0.887
- 0.717
- 0.851
- 0.627
- 0.69
- 0.776
- 0.608
- 0.687
- 0.581
- 0.674
- 0.639
- 0.733
- 0.577
- 0.635
- 0.617
- 0.651
- 0.611
- 0.547
- 0.597
- 0.577
- 0.503
- 0.501
- 0.471
- 0.513
- 0.462
- 0.501
- 0.495
- 0.453
- 0.511
- 0.475
- 0.447
- 0.467
- 0.467
- 0.362
- 0.432
- 0.361
- 0.441
- 0.406
- 0.343
- 0.433
- 0.411
- 0.415
- 0.334
- 0.397
- 0.381
- 0.319
- 0.275
- 0.271
- 0.314
- 0.287
- 0.361
unequal: 0
verbose: 1
