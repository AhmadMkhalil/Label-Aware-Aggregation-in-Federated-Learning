avg_train_accuracy: 0.299
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0817
- 0.1035
- 0.1322
- 0.1391
- 0.1555
- 0.1617
- 0.1704
- 0.1798
- 0.1907
- 0.1894
- 0.2013
- 0.2083
- 0.2143
- 0.2127
- 0.2211
- 0.2226
- 0.2237
- 0.2254
- 0.2327
- 0.2361
- 0.2402
- 0.2367
- 0.2472
- 0.2346
- 0.2473
- 0.2492
- 0.2533
- 0.248
- 0.2549
- 0.2606
- 0.2629
- 0.2554
- 0.2586
- 0.2665
- 0.2708
- 0.2617
- 0.2755
- 0.2732
- 0.2713
- 0.274
- 0.2816
- 0.2788
- 0.2789
- 0.277
- 0.2781
- 0.2854
- 0.2802
- 0.2826
- 0.2804
- 0.2855
- 0.2762
- 0.2814
- 0.2892
- 0.2886
- 0.2886
- 0.2919
- 0.2888
- 0.2899
- 0.282
- 0.291
- 0.2902
- 0.2873
- 0.2955
- 0.2897
- 0.2946
- 0.2859
- 0.295
- 0.2952
- 0.2937
- 0.2942
- 0.2943
- 0.2975
- 0.2979
- 0.2971
- 0.295
- 0.2976
- 0.2953
- 0.2999
- 0.2992
- 0.2986
- 0.2998
- 0.3022
- 0.2924
- 0.3025
- 0.3064
- 0.3023
- 0.3028
- 0.3031
- 0.3035
- 0.3075
- 0.3046
- 0.3078
- 0.303
- 0.3096
- 0.3098
- 0.3052
- 0.3053
- 0.3037
- 0.3084
test_loss_list:
- 1.8020813798904418
- 1.6857388067245482
- 1.6356731462478638
- 1.5906554007530211
- 1.5730814528465271
- 1.5330953788757324
- 1.5154590177536011
- 1.5060357308387757
- 1.483962345123291
- 1.4657982683181763
- 1.4578296852111816
- 1.4365127992630005
- 1.4235650205612183
- 1.4138412714004516
- 1.3991529250144958
- 1.3912652373313903
- 1.3906776046752929
- 1.37795166015625
- 1.377392327785492
- 1.3690716123580933
- 1.3582696509361267
- 1.3524046969413757
- 1.3575095343589783
- 1.3414321184158324
- 1.3595336079597473
- 1.3363602018356324
- 1.3268905377388
- 1.3216677498817444
- 1.3312056016921998
- 1.307483789920807
- 1.304149215221405
- 1.3036446714401244
- 1.3184327507019042
- 1.305959577560425
- 1.2945697021484375
- 1.2840573239326476
- 1.2916579675674438
- 1.2788974475860595
- 1.28172691822052
- 1.292883861064911
- 1.2763150119781494
- 1.2713588500022888
- 1.2728339004516602
- 1.2761330819129943
- 1.2676283502578736
- 1.2713903069496155
- 1.2639912176132202
- 1.2740380144119263
- 1.2714343881607055
- 1.2689148378372193
- 1.2631909227371216
- 1.2798998689651488
- 1.26742573261261
- 1.2504467391967773
- 1.2568352913856506
- 1.2603683686256408
- 1.2478245306015014
- 1.2584163451194763
- 1.251471140384674
- 1.2673427629470826
- 1.2538573408126832
- 1.2509596514701844
- 1.257266459465027
- 1.2411453580856324
- 1.262548007965088
- 1.2533635330200195
- 1.2685064101219177
- 1.2482661056518554
- 1.245982973575592
- 1.2516549229621887
- 1.257067551612854
- 1.2501055431365966
- 1.246426486968994
- 1.2500368571281433
- 1.2494024324417115
- 1.254516658782959
- 1.248984818458557
- 1.2520774507522583
- 1.2489195656776428
- 1.2488735818862915
- 1.2568155360221862
- 1.2469341897964477
- 1.249231734275818
- 1.2613524222373962
- 1.2494187474250793
- 1.2486759734153747
- 1.255084481239319
- 1.258344566822052
- 1.2602301573753356
- 1.254889051914215
- 1.2509352254867554
- 1.2537784337997437
- 1.258832128047943
- 1.2642974853515625
- 1.2559717607498169
- 1.2581041884422302
- 1.2607998919487
- 1.2621038413047792
- 1.260958616733551
- 1.2542713928222655
train_accuracy:
- 0.056
- 0.0
- 0.132
- 0.129
- 0.121
- 0.0
- 0.176
- 0.0
- 0.0
- 0.176
- 0.168
- 0.0
- 0.16
- 0.17
- 0.178
- 0.179
- 0.169
- 0.0
- 0.0
- 0.0
- 0.204
- 0.256
- 0.0
- 0.259
- 0.182
- 0.0
- 0.0
- 0.285
- 0.229
- 0.249
- 0.263
- 0.254
- 0.0
- 0.24
- 0.0
- 0.0
- 0.0
- 0.259
- 0.232
- 0.0
- 0.0
- 0.266
- 0.318
- 0.26
- 0.0
- 0.0
- 0.284
- 0.271
- 0.0
- 0.245
- 0.28
- 0.0
- 0.259
- 0.258
- 0.27
- 0.0
- 0.302
- 0.28
- 0.28
- 0.0
- 0.0
- 0.274
- 0.264
- 0.329
- 0.327
- 0.331
- 0.0
- 0.332
- 0.274
- 0.271
- 0.0
- 0.278
- 0.262
- 0.0
- 0.0
- 0.281
- 0.0
- 0.269
- 0.291
- 0.283
- 0.0
- 0.0
- 0.306
- 0.0
- 0.295
- 0.342
- 0.301
- 0.287
- 0.315
- 0.0
- 0.294
- 0.292
- 0.269
- 0.287
- 0.285
- 0.0
- 0.0
- 0.31
- 0.305
- 0.299
train_loss:
- 3.604
- 2.577
- 3.038
- 3.435
- 1.745
- 2.739
- 2.57
- 1.959
- 2.401
- 2.011
- 1.493
- 1.908
- 2.17
- 2.146
- 1.76
- 1.973
- 1.612
- 2.057
- 1.603
- 1.532
- 1.725
- 1.757
- 1.44
- 1.622
- 1.077
- 1.34
- 1.378
- 1.251
- 1.02
- 1.421
- 1.388
- 1.142
- 0.896
- 1.127
- 1.12
- 1.304
- 0.93
- 1.304
- 1.215
- 0.828
- 0.93
- 1.03
- 0.909
- 0.833
- 1.038
- 0.879
- 0.87
- 0.759
- 0.785
- 0.807
- 0.792
- 0.609
- 0.819
- 0.805
- 0.8
- 0.675
- 0.788
- 0.623
- 0.686
- 0.531
- 0.624
- 0.564
- 0.557
- 0.661
- 0.482
- 0.492
- 0.463
- 0.561
- 0.557
- 0.555
- 0.441
- 0.553
- 0.508
- 0.468
- 0.501
- 0.424
- 0.565
- 0.428
- 0.478
- 0.456
- 0.464
- 0.4
- 0.44
- 0.424
- 0.451
- 0.384
- 0.34
- 0.327
- 0.33
- 0.473
- 0.399
- 0.346
- 0.314
- 0.375
- 0.345
- 0.304
- 0.333
- 0.388
- 0.305
- 0.291
unequal: 0
verbose: 1
