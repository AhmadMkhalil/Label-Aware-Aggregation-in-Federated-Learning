avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0442
- 0.1016
- 0.1188
- 0.1356
- 0.1491
- 0.1577
- 0.1615
- 0.179
- 0.1776
- 0.1872
- 0.1892
- 0.2003
- 0.2059
- 0.2176
- 0.2186
- 0.2214
- 0.2235
- 0.229
- 0.2323
- 0.2342
- 0.2333
- 0.2347
- 0.2454
- 0.2467
- 0.2445
- 0.2518
- 0.249
- 0.2568
- 0.2559
- 0.2572
- 0.2515
- 0.257
- 0.2649
- 0.2662
- 0.2702
- 0.2679
- 0.2675
- 0.2754
- 0.273
- 0.2739
- 0.2725
- 0.2781
- 0.2784
- 0.2779
- 0.2796
- 0.2847
- 0.2775
- 0.283
- 0.2809
- 0.283
- 0.2878
- 0.2883
- 0.2852
- 0.2855
- 0.2846
- 0.2935
- 0.2862
- 0.2869
- 0.2847
- 0.2879
- 0.2873
- 0.2924
- 0.2912
- 0.292
- 0.2916
- 0.2953
- 0.2951
- 0.2933
- 0.2926
- 0.2948
- 0.2923
- 0.2967
- 0.2918
- 0.2936
- 0.2935
- 0.2903
- 0.2978
- 0.2977
- 0.2961
- 0.2945
- 0.2993
- 0.2932
- 0.301
- 0.3002
- 0.2954
- 0.3025
- 0.2981
- 0.3043
- 0.3019
- 0.3021
- 0.3013
- 0.3013
- 0.2981
- 0.302
- 0.3029
- 0.3015
- 0.3031
- 0.3007
- 0.305
- 0.301
test_loss_list:
- 1.7779744338989258
- 1.6594765734672547
- 1.614757628440857
- 1.579332492351532
- 1.5553197431564332
- 1.5352140998840331
- 1.529174304008484
- 1.4967166042327882
- 1.491587200164795
- 1.462244951725006
- 1.4579877018928529
- 1.4361705374717713
- 1.4256531167030335
- 1.418069326877594
- 1.4071915936470032
- 1.3988488006591797
- 1.3920957374572753
- 1.3853495907783508
- 1.3768661165237426
- 1.3692726111412048
- 1.3736583113670349
- 1.3637828278541564
- 1.3530949997901915
- 1.3505105042457581
- 1.3524568200111389
- 1.3407948446273803
- 1.3457326149940492
- 1.3336780285835266
- 1.3296649169921875
- 1.3260864067077636
- 1.3237667298316955
- 1.3223823285102845
- 1.3137726426124572
- 1.3096744370460511
- 1.3025825309753418
- 1.3012526059150695
- 1.294433069229126
- 1.2900214719772338
- 1.2925337171554565
- 1.29297189950943
- 1.29313175201416
- 1.2922465467453004
- 1.287193636894226
- 1.282714478969574
- 1.2833912992477416
- 1.2769002962112426
- 1.2881443285942078
- 1.273185396194458
- 1.2791834688186645
- 1.2724799394607544
- 1.2706823348999023
- 1.2722866868972778
- 1.2758245301246642
- 1.2759141874313356
- 1.271833736896515
- 1.265455298423767
- 1.277318320274353
- 1.2671076464653015
- 1.264727339744568
- 1.2649242568016053
- 1.2604178380966187
- 1.264140350818634
- 1.2626644468307495
- 1.2619346833229066
- 1.2637819719314576
- 1.2582368326187134
- 1.2618219542503357
- 1.2653322005271912
- 1.2636379432678222
- 1.2570199275016785
- 1.2603330969810487
- 1.2554079818725585
- 1.2617173242568969
- 1.2575008940696717
- 1.259510853290558
- 1.2627071785926818
- 1.2517520928382873
- 1.2522422099113464
- 1.2580748033523559
- 1.2619184255599976
- 1.2534032702445983
- 1.2639042592048646
- 1.249113438129425
- 1.2478329253196716
- 1.253481833934784
- 1.2502439737319946
- 1.2564530062675476
- 1.2499561786651612
- 1.2581093621253967
- 1.2589744138717651
- 1.263404242992401
- 1.2576551222801209
- 1.2630103850364685
- 1.2603727436065675
- 1.254652853012085
- 1.2627196836471557
- 1.2577747917175293
- 1.2609667134284974
- 1.2592960047721862
- 1.2632310748100282
train_accuracy:
- 0.053
- 0.115
- 0.151
- 0.139
- 0.146
- 0.155
- 0.18
- 0.2
- 0.218
- 0.228
- 0.2
- 0.217
- 0.231
- 0.244
- 0.225
- 0.258
- 0.242
- 0.242
- 0.242
- 0.262
- 0.252
- 0.231
- 0.232
- 0.251
- 0.227
- 0.253
- 0.27
- 0.237
- 0.24
- 0.241
- 0.279
- 0.229
- 0.0
- 0.279
- 0.0
- 0.0
- 0.295
- 0.3
- 0.248
- 0.31
- 0.0
- 0.0
- 0.256
- 0.262
- 0.0
- 0.322
- 0.0
- 0.0
- 0.305
- 0.295
- 0.32
- 0.274
- 0.279
- 0.0
- 0.327
- 0.283
- 0.0
- 0.334
- 0.311
- 0.296
- 0.315
- 0.255
- 0.313
- 0.301
- 0.328
- 0.304
- 0.348
- 0.327
- 0.318
- 0.318
- 0.0
- 0.316
- 0.0
- 0.0
- 0.0
- 0.307
- 0.344
- 0.316
- 0.0
- 0.314
- 0.0
- 0.0
- 0.266
- 0.325
- 0.335
- 0.332
- 0.339
- 0.336
- 0.312
- 0.0
- 0.334
- 0.0
- 0.308
- 0.292
- 0.317
- 0.0
- 0.314
- 0.343
- 0.0
- 0.0
train_loss:
- 2.792
- 3.826
- 3.563
- 2.825
- 3.235
- 2.57
- 1.519
- 2.019
- 1.894
- 1.977
- 1.824
- 1.848
- 2.134
- 2.05
- 2.406
- 1.678
- 1.946
- 1.855
- 1.494
- 1.767
- 1.144
- 1.612
- 1.921
- 1.612
- 1.257
- 1.521
- 1.152
- 1.431
- 1.305
- 1.415
- 1.195
- 1.098
- 1.344
- 1.123
- 1.255
- 0.953
- 1.204
- 1.171
- 1.053
- 1.159
- 1.083
- 0.906
- 0.952
- 0.966
- 0.913
- 0.98
- 0.764
- 0.865
- 0.78
- 0.831
- 0.861
- 0.78
- 0.662
- 0.658
- 0.617
- 0.708
- 0.596
- 0.659
- 0.657
- 0.632
- 0.667
- 0.582
- 0.583
- 0.601
- 0.561
- 0.574
- 0.528
- 0.471
- 0.471
- 0.52
- 0.44
- 0.486
- 0.444
- 0.437
- 0.464
- 0.409
- 0.449
- 0.426
- 0.429
- 0.387
- 0.419
- 0.374
- 0.401
- 0.373
- 0.389
- 0.378
- 0.342
- 0.364
- 0.336
- 0.336
- 0.298
- 0.341
- 0.349
- 0.35
- 0.294
- 0.313
- 0.301
- 0.292
- 0.293
- 0.293
unequal: 0
verbose: 1
