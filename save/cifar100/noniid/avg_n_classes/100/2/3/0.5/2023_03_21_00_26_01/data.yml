avg_train_accuracy: 0.274
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0389
- 0.0943
- 0.1134
- 0.1359
- 0.147
- 0.1599
- 0.1708
- 0.1747
- 0.1792
- 0.1843
- 0.1967
- 0.1923
- 0.2047
- 0.2109
- 0.2148
- 0.2186
- 0.2276
- 0.2233
- 0.2315
- 0.2381
- 0.2387
- 0.244
- 0.2431
- 0.2507
- 0.2489
- 0.2471
- 0.253
- 0.2518
- 0.2531
- 0.2625
- 0.2642
- 0.266
- 0.2625
- 0.2625
- 0.2701
- 0.2717
- 0.2756
- 0.2763
- 0.273
- 0.2816
- 0.2762
- 0.2788
- 0.2762
- 0.2784
- 0.2829
- 0.2832
- 0.2818
- 0.2819
- 0.2857
- 0.2837
- 0.2869
- 0.2898
- 0.2919
- 0.2897
- 0.2925
- 0.2955
- 0.2964
- 0.2975
- 0.2845
- 0.291
- 0.2963
- 0.2936
- 0.2993
- 0.2957
- 0.3014
- 0.2992
- 0.2985
- 0.3036
- 0.2967
- 0.294
- 0.2982
- 0.2969
- 0.3015
- 0.298
- 0.2946
- 0.2999
- 0.3034
- 0.3044
- 0.3017
- 0.3024
- 0.3048
- 0.3046
- 0.3058
- 0.3055
- 0.3015
- 0.3096
- 0.308
- 0.3066
- 0.2949
- 0.3004
- 0.3013
- 0.3068
- 0.31
- 0.3058
- 0.3097
- 0.3052
- 0.3082
- 0.3041
- 0.31
- 0.3091
test_loss_list:
- 1.7999658727645873
- 1.6800528001785278
- 1.6200568652153016
- 1.5843640208244323
- 1.5548155736923217
- 1.5313970136642456
- 1.508113341331482
- 1.4941013169288635
- 1.4832403779029846
- 1.4717712640762328
- 1.448517737388611
- 1.4537230706214905
- 1.4301569223403932
- 1.4251144433021545
- 1.4165102648735046
- 1.4048246073722839
- 1.3906145548820497
- 1.3869007873535155
- 1.3711200523376466
- 1.3663061571121216
- 1.369572868347168
- 1.357992751598358
- 1.3502264738082885
- 1.3459432005882264
- 1.3408522629737853
- 1.3400081562995911
- 1.3348455595970155
- 1.3348182153701782
- 1.3283442807197572
- 1.3136227107048035
- 1.3130229330062866
- 1.3056690049171449
- 1.3148090171813964
- 1.3098743677139282
- 1.3008151483535766
- 1.2976679182052613
- 1.3006521606445312
- 1.2928407192230225
- 1.2959475922584534
- 1.2878103971481323
- 1.2865811228752135
- 1.2856218862533568
- 1.287609305381775
- 1.2840739464759827
- 1.2860894799232483
- 1.2790398263931275
- 1.2832572174072265
- 1.2825522756576537
- 1.2715292978286743
- 1.2803815412521362
- 1.2711546182632447
- 1.2736806750297547
- 1.2605476880073547
- 1.2649871325492859
- 1.2640173792839051
- 1.261240165233612
- 1.2662326335906982
- 1.2700890326499938
- 1.2827086687088012
- 1.2642292094230652
- 1.2560841608047486
- 1.263430905342102
- 1.2623412275314332
- 1.2603185200691223
- 1.254992377758026
- 1.2574434185028076
- 1.2532584071159363
- 1.2545725226402282
- 1.25792822599411
- 1.2657847094535828
- 1.246605272293091
- 1.2572515964508058
- 1.2478473973274231
- 1.259469404220581
- 1.2738022875785828
- 1.2486041617393493
- 1.2505203104019165
- 1.250208146572113
- 1.2466574144363403
- 1.251254997253418
- 1.2541525173187256
- 1.257977650165558
- 1.2629717206954956
- 1.2516303515434266
- 1.2580543160438538
- 1.2510340738296508
- 1.2495053720474243
- 1.2514288377761842
- 1.272766284942627
- 1.255710711479187
- 1.2541072845458985
- 1.2511768579483031
- 1.2466508412361146
- 1.2578324794769287
- 1.2541529297828675
- 1.2542731142044068
- 1.2545219206809997
- 1.2541554522514344
- 1.245925645828247
- 1.2494019961357117
train_accuracy:
- 0.054
- 0.107
- 0.118
- 0.105
- 0.171
- 0.0
- 0.177
- 0.0
- 0.146
- 0.184
- 0.0
- 0.0
- 0.178
- 0.0
- 0.212
- 0.198
- 0.223
- 0.192
- 0.214
- 0.251
- 0.251
- 0.0
- 0.23
- 0.0
- 0.221
- 0.0
- 0.253
- 0.234
- 0.211
- 0.21
- 0.0
- 0.253
- 0.198
- 0.241
- 0.0
- 0.257
- 0.29
- 0.0
- 0.253
- 0.267
- 0.242
- 0.269
- 0.23
- 0.26
- 0.277
- 0.258
- 0.0
- 0.307
- 0.0
- 0.22
- 0.274
- 0.0
- 0.277
- 0.274
- 0.284
- 0.256
- 0.272
- 0.255
- 0.252
- 0.0
- 0.257
- 0.0
- 0.0
- 0.252
- 0.259
- 0.237
- 0.253
- 0.317
- 0.0
- 0.313
- 0.263
- 0.278
- 0.27
- 0.267
- 0.227
- 0.271
- 0.278
- 0.324
- 0.29
- 0.285
- 0.294
- 0.264
- 0.0
- 0.279
- 0.276
- 0.291
- 0.266
- 0.279
- 0.0
- 0.0
- 0.276
- 0.0
- 0.294
- 0.0
- 0.293
- 0.304
- 0.244
- 0.0
- 0.322
- 0.274
train_loss:
- 2.843
- 2.499
- 3.027
- 2.344
- 2.774
- 2.116
- 2.642
- 2.472
- 1.992
- 1.971
- 1.992
- 1.412
- 2.582
- 2.102
- 2.106
- 1.72
- 1.677
- 1.584
- 1.97
- 1.84
- 1.474
- 1.696
- 1.711
- 1.649
- 1.729
- 1.377
- 1.576
- 1.266
- 1.291
- 1.491
- 1.183
- 1.388
- 1.095
- 1.049
- 1.057
- 1.147
- 1.233
- 1.209
- 1.127
- 1.225
- 0.938
- 1.029
- 0.887
- 0.984
- 0.915
- 0.966
- 0.81
- 0.911
- 0.998
- 0.754
- 0.825
- 0.81
- 0.791
- 0.849
- 0.787
- 0.779
- 0.799
- 0.793
- 0.596
- 0.582
- 0.672
- 0.559
- 0.618
- 0.632
- 0.633
- 0.607
- 0.598
- 0.569
- 0.478
- 0.444
- 0.56
- 0.45
- 0.517
- 0.519
- 0.461
- 0.469
- 0.439
- 0.444
- 0.431
- 0.462
- 0.445
- 0.411
- 0.372
- 0.419
- 0.39
- 0.389
- 0.392
- 0.364
- 0.38
- 0.369
- 0.364
- 0.339
- 0.342
- 0.318
- 0.325
- 0.309
- 0.328
- 0.339
- 0.31
- 0.254
unequal: 0
verbose: 1
