avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0421
- 0.0972
- 0.1165
- 0.1308
- 0.1382
- 0.1601
- 0.1544
- 0.1773
- 0.1818
- 0.1965
- 0.1951
- 0.2072
- 0.2045
- 0.2095
- 0.2037
- 0.2152
- 0.2188
- 0.2269
- 0.2292
- 0.2234
- 0.2361
- 0.2376
- 0.2438
- 0.2491
- 0.2467
- 0.2545
- 0.2554
- 0.2567
- 0.2586
- 0.2636
- 0.2664
- 0.2642
- 0.2683
- 0.2623
- 0.2705
- 0.2602
- 0.2676
- 0.2687
- 0.2794
- 0.2759
- 0.2751
- 0.2751
- 0.2777
- 0.2775
- 0.283
- 0.2863
- 0.2893
- 0.285
- 0.2876
- 0.2872
- 0.291
- 0.2913
- 0.2933
- 0.2929
- 0.292
- 0.2988
- 0.2969
- 0.3011
- 0.2964
- 0.2978
- 0.2931
- 0.3003
- 0.2977
- 0.3011
- 0.2925
- 0.2986
- 0.2996
- 0.3047
- 0.3059
- 0.2954
- 0.3042
- 0.3031
- 0.3038
- 0.303
- 0.2918
- 0.3061
- 0.3027
- 0.3013
- 0.309
- 0.3097
- 0.3052
- 0.3078
- 0.3069
- 0.3095
- 0.3091
- 0.3055
- 0.3089
- 0.3126
- 0.3056
- 0.3116
- 0.3069
- 0.307
- 0.3065
- 0.3086
- 0.3052
- 0.312
- 0.3084
- 0.3114
- 0.3148
- 0.3082
test_loss_list:
- 1.7903646850585937
- 1.6637203907966613
- 1.614846773147583
- 1.5860582542419435
- 1.555989089012146
- 1.5263570833206177
- 1.5243940448760986
- 1.4904194116592406
- 1.474822826385498
- 1.4562374305725099
- 1.4468489933013915
- 1.4314761900901793
- 1.4243022727966308
- 1.415215871334076
- 1.422829339504242
- 1.4006423211097718
- 1.3924760484695435
- 1.3740618681907655
- 1.3745601296424865
- 1.378909363746643
- 1.36176353931427
- 1.3585155701637268
- 1.3511421608924865
- 1.3482355952262879
- 1.3416286540031432
- 1.3309395051002502
- 1.3321758008003235
- 1.3254874563217163
- 1.3211825466156006
- 1.3113269186019898
- 1.3100124192237854
- 1.3126851224899292
- 1.3055379128456115
- 1.3097004103660583
- 1.2987351965904237
- 1.3174404430389404
- 1.308927845954895
- 1.2982773637771607
- 1.2885976910591126
- 1.287971556186676
- 1.2912160682678222
- 1.285732822418213
- 1.2775665760040282
- 1.2758960127830505
- 1.2742360186576844
- 1.2714694786071776
- 1.2639716482162475
- 1.2700602340698242
- 1.266127381324768
- 1.2644153022766114
- 1.2591472578048706
- 1.2622656846046447
- 1.2574173974990845
- 1.2583696675300597
- 1.2594537353515625
- 1.2539961981773375
- 1.253024160861969
- 1.2490856409072877
- 1.2507596278190614
- 1.2521572256088256
- 1.261400203704834
- 1.2494240474700928
- 1.2576209926605224
- 1.2544716334342956
- 1.2643836092948915
- 1.254665389060974
- 1.2488780546188354
- 1.2433004570007324
- 1.2458726620674134
- 1.2584200048446654
- 1.2497227311134338
- 1.2482719922065735
- 1.2467469668388367
- 1.2514212036132812
- 1.2738647890090942
- 1.244833195209503
- 1.252371997833252
- 1.2524774432182313
- 1.2451040959358215
- 1.247043273448944
- 1.2480573749542236
- 1.243389549255371
- 1.2464502382278442
- 1.2460163807868958
- 1.2438545227050781
- 1.2532337856292726
- 1.2454657554626465
- 1.2448539304733277
- 1.2576049661636353
- 1.2472394704818726
- 1.2475246334075927
- 1.251160182952881
- 1.2443938994407653
- 1.2459925389289856
- 1.2555242395401
- 1.2473194360733033
- 1.2507276344299316
- 1.2447675347328186
- 1.246316294670105
- 1.245293962955475
train_accuracy:
- 0.047
- 0.091
- 0.106
- 0.165
- 0.172
- 0.136
- 0.127
- 0.162
- 0.184
- 0.155
- 0.0
- 0.159
- 0.168
- 0.0
- 0.199
- 0.0
- 0.0
- 0.183
- 0.179
- 0.0
- 0.237
- 0.248
- 0.205
- 0.29
- 0.25
- 0.292
- 0.0
- 0.224
- 0.212
- 0.21
- 0.259
- 0.245
- 0.252
- 0.0
- 0.277
- 0.279
- 0.313
- 0.0
- 0.278
- 0.291
- 0.292
- 0.241
- 0.271
- 0.0
- 0.277
- 0.337
- 0.0
- 0.272
- 0.266
- 0.292
- 0.356
- 0.0
- 0.0
- 0.344
- 0.277
- 0.343
- 0.295
- 0.276
- 0.0
- 0.291
- 0.0
- 0.0
- 0.0
- 0.366
- 0.354
- 0.354
- 0.279
- 0.283
- 0.269
- 0.0
- 0.367
- 0.283
- 0.0
- 0.0
- 0.0
- 0.316
- 0.256
- 0.269
- 0.0
- 0.283
- 0.0
- 0.275
- 0.293
- 0.288
- 0.0
- 0.279
- 0.0
- 0.293
- 0.295
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.271
- 0.0
- 0.307
- 0.0
train_loss:
- 4.308
- 3.203
- 3.599
- 2.285
- 2.213
- 2.678
- 1.606
- 2.466
- 2.372
- 2.386
- 1.86
- 2.213
- 1.724
- 2.056
- 1.288
- 1.63
- 1.566
- 1.951
- 1.773
- 1.088
- 2.068
- 1.658
- 1.69
- 1.633
- 1.32
- 1.848
- 1.295
- 1.212
- 1.213
- 1.449
- 1.385
- 1.046
- 1.27
- 1.034
- 1.422
- 0.814
- 0.972
- 1.065
- 1.108
- 1.033
- 0.842
- 0.86
- 0.95
- 0.775
- 0.975
- 0.842
- 0.939
- 0.739
- 0.76
- 0.721
- 0.766
- 0.696
- 0.792
- 0.7
- 0.704
- 0.642
- 0.689
- 0.714
- 0.622
- 0.614
- 0.606
- 0.599
- 0.507
- 0.542
- 0.464
- 0.545
- 0.575
- 0.556
- 0.541
- 0.435
- 0.449
- 0.518
- 0.499
- 0.406
- 0.415
- 0.474
- 0.44
- 0.403
- 0.403
- 0.427
- 0.371
- 0.389
- 0.37
- 0.38
- 0.38
- 0.356
- 0.337
- 0.342
- 0.34
- 0.334
- 0.329
- 0.341
- 0.315
- 0.304
- 0.304
- 0.27
- 0.295
- 0.318
- 0.257
- 0.324
unequal: 0
verbose: 1
