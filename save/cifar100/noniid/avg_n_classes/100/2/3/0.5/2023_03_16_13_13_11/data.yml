avg_train_accuracy: 0.287
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0466
- 0.0981
- 0.1228
- 0.1362
- 0.153
- 0.16
- 0.1738
- 0.178
- 0.1841
- 0.1914
- 0.1946
- 0.2026
- 0.2103
- 0.2184
- 0.2104
- 0.2275
- 0.2272
- 0.2328
- 0.2353
- 0.2341
- 0.2344
- 0.2458
- 0.2455
- 0.2528
- 0.2508
- 0.2514
- 0.2508
- 0.2591
- 0.2599
- 0.265
- 0.2692
- 0.2658
- 0.2688
- 0.2711
- 0.2734
- 0.2728
- 0.2694
- 0.2707
- 0.2739
- 0.2692
- 0.277
- 0.2778
- 0.285
- 0.279
- 0.288
- 0.2862
- 0.286
- 0.2919
- 0.2902
- 0.2875
- 0.2938
- 0.2942
- 0.2902
- 0.2917
- 0.2919
- 0.2912
- 0.2865
- 0.2934
- 0.2975
- 0.2976
- 0.2914
- 0.3
- 0.3001
- 0.2975
- 0.2967
- 0.2989
- 0.3005
- 0.2982
- 0.3018
- 0.3038
- 0.2977
- 0.2993
- 0.3045
- 0.3079
- 0.3068
- 0.3022
- 0.3028
- 0.3041
- 0.3062
- 0.3011
- 0.3059
- 0.3077
- 0.3065
- 0.3014
- 0.3049
- 0.3077
- 0.3043
- 0.3075
- 0.3089
- 0.302
- 0.3072
- 0.3048
- 0.3127
- 0.3101
- 0.3098
- 0.3118
- 0.3077
- 0.3066
- 0.3142
- 0.3117
test_loss_list:
- 1.7836401987075805
- 1.6618989706039429
- 1.616012797355652
- 1.584134693145752
- 1.5519152212142944
- 1.5300065088272095
- 1.5131211638450623
- 1.4920245909690857
- 1.4798093557357788
- 1.4646375489234924
- 1.4585231733322144
- 1.4437586903572082
- 1.4290252757072448
- 1.4147573041915893
- 1.4230038022994995
- 1.39498291015625
- 1.394468402862549
- 1.3881344890594483
- 1.3791197919845581
- 1.3816695857048034
- 1.374311466217041
- 1.3599562621116639
- 1.360393671989441
- 1.3450828504562378
- 1.3464109420776367
- 1.343737382888794
- 1.3379631423950196
- 1.3309791421890258
- 1.3295356082916259
- 1.3198494338989257
- 1.3104001569747925
- 1.3170567727088929
- 1.3144287991523742
- 1.3101936721801757
- 1.3043012857437133
- 1.3056371760368348
- 1.3081534481048585
- 1.3088921618461609
- 1.2961328220367432
- 1.3090076732635498
- 1.2865359687805176
- 1.2884215593338013
- 1.2799211192131041
- 1.2962273740768433
- 1.277900288105011
- 1.2780753350257874
- 1.2782697892189026
- 1.2743669319152833
- 1.2763943982124328
- 1.270890119075775
- 1.267141399383545
- 1.2728142213821412
- 1.2707353711128235
- 1.2707498812675475
- 1.2696786880493165
- 1.2739217257499695
- 1.2838579821586609
- 1.258718695640564
- 1.2555508685112
- 1.2629532670974732
- 1.2764859342575072
- 1.2589153242111206
- 1.2550925278663636
- 1.257586328983307
- 1.2616327953338624
- 1.2567914867401122
- 1.2554607844352723
- 1.263334083557129
- 1.2521463751792907
- 1.2561461853981017
- 1.2628873372077942
- 1.250126302242279
- 1.2483250713348388
- 1.2522902035713195
- 1.2539283800125123
- 1.2646250057220458
- 1.2561260294914245
- 1.259655363559723
- 1.2565570235252381
- 1.265675127506256
- 1.2572179079055785
- 1.257373902797699
- 1.2591242122650146
- 1.266697416305542
- 1.2520528578758239
- 1.253976080417633
- 1.2566403841972351
- 1.251868829727173
- 1.2569363403320313
- 1.2653681349754333
- 1.2570832538604737
- 1.2564716386795043
- 1.255311028957367
- 1.257437436580658
- 1.2585078907012939
- 1.2610410046577454
- 1.2623310565948487
- 1.258180751800537
- 1.253737859725952
- 1.2585708165168763
train_accuracy:
- 0.0
- 0.106
- 0.0
- 0.141
- 0.131
- 0.132
- 0.0
- 0.141
- 0.0
- 0.171
- 0.0
- 0.0
- 0.213
- 0.0
- 0.0
- 0.25
- 0.0
- 0.205
- 0.204
- 0.237
- 0.0
- 0.227
- 0.253
- 0.22
- 0.241
- 0.235
- 0.0
- 0.0
- 0.0
- 0.216
- 0.235
- 0.0
- 0.266
- 0.325
- 0.237
- 0.0
- 0.239
- 0.0
- 0.342
- 0.0
- 0.287
- 0.0
- 0.268
- 0.0
- 0.284
- 0.291
- 0.256
- 0.267
- 0.273
- 0.313
- 0.255
- 0.352
- 0.308
- 0.307
- 0.0
- 0.317
- 0.302
- 0.263
- 0.0
- 0.327
- 0.311
- 0.309
- 0.273
- 0.0
- 0.27
- 0.341
- 0.303
- 0.0
- 0.263
- 0.0
- 0.0
- 0.0
- 0.31
- 0.342
- 0.37
- 0.294
- 0.0
- 0.321
- 0.303
- 0.0
- 0.0
- 0.304
- 0.0
- 0.0
- 0.0
- 0.36
- 0.0
- 0.299
- 0.293
- 0.0
- 0.302
- 0.331
- 0.303
- 0.29
- 0.0
- 0.349
- 0.35
- 0.356
- 0.3
- 0.287
train_loss:
- 3.485
- 2.476
- 2.358
- 2.254
- 2.664
- 2.55
- 2.043
- 2.509
- 1.915
- 2.346
- 1.787
- 1.804
- 1.72
- 1.699
- 1.243
- 2.382
- 1.855
- 1.496
- 1.802
- 1.434
- 1.396
- 2.062
- 1.321
- 1.679
- 1.329
- 1.285
- 1.266
- 1.42
- 1.142
- 1.342
- 1.402
- 1.084
- 1.223
- 1.21
- 1.4
- 1.21
- 0.91
- 0.849
- 0.922
- 0.729
- 1.082
- 0.838
- 1.017
- 0.712
- 1.037
- 0.983
- 0.775
- 0.955
- 0.78
- 0.844
- 0.882
- 0.763
- 0.746
- 0.752
- 0.704
- 0.736
- 0.545
- 0.655
- 0.719
- 0.638
- 0.547
- 0.636
- 0.575
- 0.522
- 0.545
- 0.536
- 0.556
- 0.445
- 0.524
- 0.489
- 0.433
- 0.495
- 0.474
- 0.485
- 0.486
- 0.413
- 0.419
- 0.408
- 0.393
- 0.383
- 0.412
- 0.374
- 0.369
- 0.351
- 0.381
- 0.365
- 0.346
- 0.37
- 0.321
- 0.348
- 0.338
- 0.354
- 0.282
- 0.297
- 0.356
- 0.304
- 0.314
- 0.319
- 0.314
- 0.295
unequal: 0
verbose: 1
