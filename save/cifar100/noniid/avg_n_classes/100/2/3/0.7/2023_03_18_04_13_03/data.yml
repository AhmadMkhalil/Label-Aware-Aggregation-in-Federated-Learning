avg_train_accuracy: 0.348
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0483
- 0.1015
- 0.1175
- 0.1365
- 0.1458
- 0.1574
- 0.163
- 0.1783
- 0.1886
- 0.1902
- 0.1947
- 0.2053
- 0.2114
- 0.2153
- 0.2105
- 0.2202
- 0.2221
- 0.2279
- 0.2357
- 0.2331
- 0.2402
- 0.2437
- 0.2418
- 0.2483
- 0.2525
- 0.2537
- 0.2527
- 0.2552
- 0.2586
- 0.2575
- 0.2598
- 0.2633
- 0.2626
- 0.2683
- 0.2648
- 0.2659
- 0.2686
- 0.2726
- 0.2734
- 0.2705
- 0.2775
- 0.2777
- 0.2744
- 0.2788
- 0.2829
- 0.2819
- 0.2803
- 0.2803
- 0.2852
- 0.286
- 0.2819
- 0.289
- 0.2857
- 0.286
- 0.2848
- 0.2908
- 0.2886
- 0.2911
- 0.293
- 0.2927
- 0.2969
- 0.293
- 0.2932
- 0.2944
- 0.2964
- 0.2964
- 0.2972
- 0.2996
- 0.2949
- 0.2986
- 0.297
- 0.298
- 0.3
- 0.2983
- 0.2968
- 0.2992
- 0.3009
- 0.302
- 0.3031
- 0.3063
- 0.3047
- 0.3023
- 0.3039
- 0.3006
- 0.2997
- 0.3024
- 0.3057
- 0.3035
- 0.3014
- 0.302
- 0.2999
- 0.3018
- 0.3029
- 0.3056
- 0.3041
- 0.3045
- 0.307
- 0.3046
- 0.3084
- 0.3077
test_loss_list:
- 1.7865163850784302
- 1.669894392490387
- 1.619965262413025
- 1.583589289188385
- 1.553028299808502
- 1.5276090598106384
- 1.5061895775794982
- 1.4866370487213134
- 1.4687869143486023
- 1.4560499095916748
- 1.4445488238334656
- 1.4299572587013245
- 1.4190317273139954
- 1.4108176136016846
- 1.4070757603645325
- 1.3931683111190796
- 1.3764139795303345
- 1.3678419160842896
- 1.3599628472328187
- 1.3545616698265075
- 1.3477344560623168
- 1.3435321879386901
- 1.3388210701942445
- 1.3308907270431518
- 1.3232963275909424
- 1.3202679944038391
- 1.3156282377243043
- 1.3090002751350402
- 1.3087985229492187
- 1.3065833926200867
- 1.3024342846870423
- 1.2934208488464356
- 1.2916276836395264
- 1.2903399753570557
- 1.2893889808654786
- 1.2866643834114075
- 1.2826117181777954
- 1.2727534437179566
- 1.2720421814918519
- 1.2718606209754943
- 1.265274291038513
- 1.2602043867111206
- 1.2637078094482421
- 1.260568675994873
- 1.2541699409484863
- 1.2537786698341369
- 1.2528339695930482
- 1.2486023354530333
- 1.2481861662864686
- 1.2476683521270753
- 1.2484346342086792
- 1.2408358573913574
- 1.2428965616226195
- 1.2388645815849304
- 1.2400302052497865
- 1.2349294781684876
- 1.240358865261078
- 1.2428554177284241
- 1.2387946224212647
- 1.2420649600028992
- 1.2352613759040834
- 1.2382297921180725
- 1.2409950113296508
- 1.2403769540786742
- 1.235575933456421
- 1.2355513858795166
- 1.237193956375122
- 1.2355573391914367
- 1.234757342338562
- 1.2332047986984254
- 1.2341117930412293
- 1.232508897781372
- 1.2312037396430968
- 1.2330206179618834
- 1.2341812443733216
- 1.2325096464157104
- 1.2356083297729492
- 1.2347400522232055
- 1.2294993829727172
- 1.2280941462516786
- 1.2344601368904113
- 1.2361774253845215
- 1.2358118939399718
- 1.2389110207557679
- 1.2392381501197816
- 1.2322129201889038
- 1.228885998725891
- 1.2336099743843079
- 1.235985565185547
- 1.235553846359253
- 1.2316781234741212
- 1.2344314432144166
- 1.2324363255500794
- 1.2351766276359557
- 1.2362622666358947
- 1.2321848249435425
- 1.2298260593414307
- 1.2297771024703978
- 1.2343191957473756
- 1.23395432472229
train_accuracy:
- 0.0
- 0.103
- 0.0
- 0.123
- 0.187
- 0.0
- 0.0
- 0.219
- 0.149
- 0.228
- 0.141
- 0.192
- 0.251
- 0.258
- 0.0
- 0.202
- 0.259
- 0.0
- 0.177
- 0.0
- 0.229
- 0.227
- 0.237
- 0.273
- 0.275
- 0.289
- 0.0
- 0.233
- 0.225
- 0.244
- 0.0
- 0.307
- 0.318
- 0.306
- 0.312
- 0.0
- 0.0
- 0.0
- 0.261
- 0.328
- 0.0
- 0.0
- 0.279
- 0.27
- 0.0
- 0.334
- 0.268
- 0.0
- 0.335
- 0.346
- 0.0
- 0.327
- 0.299
- 0.311
- 0.309
- 0.265
- 0.3
- 0.325
- 0.261
- 0.0
- 0.271
- 0.345
- 0.0
- 0.302
- 0.356
- 0.0
- 0.343
- 0.276
- 0.0
- 0.0
- 0.339
- 0.344
- 0.0
- 0.283
- 0.298
- 0.31
- 0.314
- 0.353
- 0.0
- 0.275
- 0.342
- 0.295
- 0.307
- 0.0
- 0.345
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.357
- 0.317
- 0.338
- 0.0
- 0.346
- 0.298
- 0.28
- 0.356
- 0.348
train_loss:
- 3.246
- 3.385
- 2.32
- 3.05
- 2.151
- 2.446
- 1.992
- 2.632
- 2.228
- 2.191
- 2.09
- 2.367
- 2.307
- 1.966
- 1.598
- 1.59
- 1.537
- 1.774
- 1.724
- 1.666
- 1.861
- 1.819
- 1.542
- 1.347
- 1.469
- 1.231
- 1.429
- 1.415
- 1.706
- 1.305
- 1.126
- 1.24
- 1.363
- 1.362
- 0.991
- 1.267
- 0.974
- 1.09
- 1.099
- 0.882
- 1.11
- 0.892
- 0.872
- 0.928
- 0.91
- 0.921
- 0.76
- 0.766
- 0.807
- 0.787
- 0.688
- 0.703
- 0.717
- 0.664
- 0.708
- 0.707
- 0.66
- 0.645
- 0.718
- 0.629
- 0.611
- 0.6
- 0.585
- 0.568
- 0.59
- 0.549
- 0.577
- 0.477
- 0.512
- 0.481
- 0.472
- 0.492
- 0.469
- 0.47
- 0.413
- 0.439
- 0.451
- 0.416
- 0.409
- 0.419
- 0.398
- 0.371
- 0.358
- 0.351
- 0.339
- 0.352
- 0.373
- 0.336
- 0.318
- 0.306
- 0.348
- 0.304
- 0.322
- 0.307
- 0.305
- 0.283
- 0.304
- 0.294
- 0.291
- 0.282
unequal: 0
verbose: 1
