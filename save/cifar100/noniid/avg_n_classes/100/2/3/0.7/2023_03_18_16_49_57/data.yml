avg_train_accuracy: 0.306
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0466
- 0.0981
- 0.1199
- 0.138
- 0.1474
- 0.1552
- 0.1669
- 0.1758
- 0.182
- 0.1883
- 0.1973
- 0.1989
- 0.2089
- 0.2183
- 0.2186
- 0.2219
- 0.2283
- 0.2334
- 0.2324
- 0.2415
- 0.2442
- 0.2455
- 0.2484
- 0.251
- 0.2506
- 0.2521
- 0.2596
- 0.2625
- 0.2644
- 0.2647
- 0.2643
- 0.2684
- 0.2764
- 0.2723
- 0.2754
- 0.2793
- 0.2827
- 0.279
- 0.2804
- 0.2824
- 0.2804
- 0.2796
- 0.282
- 0.2853
- 0.2863
- 0.2856
- 0.2876
- 0.2896
- 0.2916
- 0.2884
- 0.2917
- 0.2923
- 0.2907
- 0.2944
- 0.2929
- 0.2955
- 0.2967
- 0.2924
- 0.3019
- 0.299
- 0.2988
- 0.3007
- 0.2983
- 0.3035
- 0.3036
- 0.3016
- 0.2999
- 0.3024
- 0.3049
- 0.3002
- 0.3033
- 0.3006
- 0.3064
- 0.305
- 0.3049
- 0.304
- 0.3078
- 0.3058
- 0.3071
- 0.3053
- 0.31
- 0.3103
- 0.3069
- 0.3083
- 0.311
- 0.3071
- 0.3105
- 0.3062
- 0.3118
- 0.3103
- 0.3128
- 0.3124
- 0.3112
- 0.3126
- 0.308
- 0.3123
- 0.3058
- 0.3115
- 0.3086
- 0.3125
test_loss_list:
- 1.7809080362319947
- 1.659415054321289
- 1.609782407283783
- 1.5686456084251403
- 1.5410316228866576
- 1.5182739305496216
- 1.499758276939392
- 1.4810841107368469
- 1.463343677520752
- 1.4514087533950806
- 1.4356797456741333
- 1.4251194882392884
- 1.412373538017273
- 1.3998818325996398
- 1.3920874571800232
- 1.3828509092330932
- 1.3731287980079652
- 1.3663347935676575
- 1.3601829195022583
- 1.3466722655296326
- 1.338503201007843
- 1.335292341709137
- 1.33011221408844
- 1.32483567237854
- 1.322017683982849
- 1.3152622437477113
- 1.3033194613456727
- 1.3011059403419494
- 1.2964831757545472
- 1.298290777206421
- 1.2944834971427917
- 1.2875963616371155
- 1.2811565470695496
- 1.281023578643799
- 1.2759255528450013
- 1.2724784231185913
- 1.2674130749702455
- 1.2685030341148376
- 1.2702452063560485
- 1.2634144186973573
- 1.2617423796653748
- 1.2609639430046082
- 1.256034483909607
- 1.2514369869232178
- 1.2523606681823731
- 1.2484001207351685
- 1.2523355054855347
- 1.2525107979774475
- 1.2465109658241271
- 1.2481379508972168
- 1.2489647579193115
- 1.2457148385047914
- 1.245246617794037
- 1.2399437022209168
- 1.241603090763092
- 1.2421799397468567
- 1.2367467498779297
- 1.2378909254074097
- 1.2343114948272704
- 1.2370139503479003
- 1.2367919540405274
- 1.2363911628723145
- 1.2361254048347474
- 1.2326968121528625
- 1.2351346015930176
- 1.2352769327163697
- 1.2377907752990722
- 1.2332169151306152
- 1.2326713228225707
- 1.2361352157592773
- 1.2359784531593323
- 1.2397450590133667
- 1.2324280738830566
- 1.2345590853691102
- 1.236564772129059
- 1.2332265162467957
- 1.2333930921554566
- 1.2371760272979737
- 1.2421025109291077
- 1.2432455968856813
- 1.2308212852478027
- 1.236173164844513
- 1.2396341609954833
- 1.2395826554298401
- 1.2369985914230346
- 1.2418841075897218
- 1.2396700382232666
- 1.2386669063568114
- 1.2288819885253905
- 1.2313324546813964
- 1.237488567829132
- 1.2403706192970276
- 1.2366939997673034
- 1.2365152955055236
- 1.2379391479492188
- 1.2362546372413634
- 1.2394857215881347
- 1.2364860892295837
- 1.2376044940948487
- 1.2378164052963256
train_accuracy:
- 0.057
- 0.088
- 0.106
- 0.156
- 0.145
- 0.168
- 0.185
- 0.203
- 0.0
- 0.171
- 0.223
- 0.216
- 0.0
- 0.197
- 0.0
- 0.251
- 0.246
- 0.0
- 0.0
- 0.259
- 0.263
- 0.0
- 0.24
- 0.241
- 0.261
- 0.0
- 0.218
- 0.0
- 0.286
- 0.258
- 0.0
- 0.0
- 0.236
- 0.254
- 0.299
- 0.0
- 0.271
- 0.0
- 0.282
- 0.294
- 0.0
- 0.0
- 0.0
- 0.262
- 0.314
- 0.0
- 0.275
- 0.263
- 0.313
- 0.264
- 0.309
- 0.277
- 0.0
- 0.332
- 0.0
- 0.303
- 0.29
- 0.0
- 0.302
- 0.284
- 0.312
- 0.0
- 0.304
- 0.283
- 0.333
- 0.0
- 0.0
- 0.319
- 0.0
- 0.33
- 0.303
- 0.278
- 0.0
- 0.305
- 0.0
- 0.334
- 0.32
- 0.311
- 0.323
- 0.336
- 0.0
- 0.322
- 0.341
- 0.332
- 0.339
- 0.312
- 0.32
- 0.0
- 0.291
- 0.364
- 0.328
- 0.323
- 0.325
- 0.0
- 0.0
- 0.315
- 0.0
- 0.326
- 0.302
- 0.306
train_loss:
- 3.191
- 2.907
- 2.71
- 3.039
- 2.495
- 2.404
- 1.976
- 2.284
- 2.185
- 2.114
- 1.771
- 1.699
- 2.242
- 2.174
- 1.843
- 1.808
- 2.005
- 1.69
- 1.65
- 1.653
- 1.612
- 1.514
- 1.485
- 1.459
- 1.215
- 1.222
- 1.375
- 1.33
- 1.275
- 1.436
- 1.041
- 1.225
- 1.303
- 0.968
- 1.251
- 1.106
- 1.059
- 1.007
- 0.989
- 0.847
- 0.961
- 0.802
- 0.811
- 0.886
- 0.932
- 0.846
- 0.895
- 0.867
- 0.796
- 0.787
- 0.727
- 0.691
- 0.645
- 0.68
- 0.673
- 0.599
- 0.647
- 0.639
- 0.609
- 0.584
- 0.556
- 0.553
- 0.564
- 0.558
- 0.546
- 0.482
- 0.456
- 0.52
- 0.476
- 0.497
- 0.462
- 0.422
- 0.462
- 0.442
- 0.4
- 0.437
- 0.422
- 0.398
- 0.398
- 0.365
- 0.404
- 0.373
- 0.358
- 0.35
- 0.367
- 0.354
- 0.344
- 0.349
- 0.342
- 0.325
- 0.316
- 0.32
- 0.318
- 0.309
- 0.303
- 0.291
- 0.298
- 0.269
- 0.286
- 0.278
unequal: 0
verbose: 1
