avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0539
- 0.1032
- 0.1187
- 0.1333
- 0.1426
- 0.1566
- 0.1671
- 0.1768
- 0.1826
- 0.1882
- 0.1965
- 0.2017
- 0.2075
- 0.2124
- 0.2166
- 0.2225
- 0.2263
- 0.2311
- 0.2365
- 0.24
- 0.2393
- 0.242
- 0.2482
- 0.2498
- 0.2536
- 0.2507
- 0.2544
- 0.259
- 0.2598
- 0.2634
- 0.2637
- 0.2655
- 0.2662
- 0.2692
- 0.2727
- 0.2737
- 0.2731
- 0.2737
- 0.2767
- 0.2766
- 0.2809
- 0.2801
- 0.2809
- 0.2818
- 0.2831
- 0.2837
- 0.2863
- 0.2851
- 0.288
- 0.2869
- 0.2897
- 0.2907
- 0.2873
- 0.2904
- 0.2936
- 0.293
- 0.2891
- 0.2927
- 0.2946
- 0.294
- 0.2906
- 0.2983
- 0.2913
- 0.2955
- 0.2941
- 0.2979
- 0.3003
- 0.3021
- 0.2972
- 0.2983
- 0.2983
- 0.2959
- 0.2993
- 0.2979
- 0.2988
- 0.3008
- 0.3023
- 0.3005
- 0.3014
- 0.3033
- 0.301
- 0.3029
- 0.3023
- 0.3045
- 0.3066
- 0.3051
- 0.3049
- 0.3018
- 0.3037
- 0.3033
- 0.3057
- 0.3011
- 0.3054
- 0.3034
- 0.3025
- 0.3047
- 0.3049
- 0.3053
- 0.3068
- 0.3057
test_loss_list:
- 1.7788949394226075
- 1.6632963991165162
- 1.61782399892807
- 1.5821162247657776
- 1.5546336555480957
- 1.5282232213020324
- 1.5021024322509766
- 1.483646914958954
- 1.4691521310806275
- 1.4538788437843322
- 1.4389211797714234
- 1.4299678468704224
- 1.4205031156539918
- 1.4103703474998475
- 1.3999106216430663
- 1.3900082659721376
- 1.3808483910560607
- 1.3706283044815064
- 1.3606240773200988
- 1.3556546688079834
- 1.3510193347930908
- 1.3441573786735534
- 1.3331072402000428
- 1.328966519832611
- 1.3232050895690919
- 1.3195346522331237
- 1.3132654809951783
- 1.3068790745735168
- 1.2995742750167847
- 1.296945354938507
- 1.2904643607139588
- 1.2868288946151734
- 1.285089647769928
- 1.2804098892211915
- 1.2750287818908692
- 1.2767432355880737
- 1.271529908180237
- 1.2710303282737732
- 1.2694804883003235
- 1.2608697843551635
- 1.2537376070022583
- 1.2556722092628478
- 1.2544056463241577
- 1.2558827662467957
- 1.2506176567077636
- 1.247883586883545
- 1.2455567026138306
- 1.2480891942977905
- 1.2474571037292481
- 1.248330261707306
- 1.241852538585663
- 1.243722448348999
- 1.2428848338127136
- 1.2402115345001221
- 1.237502474784851
- 1.237457242012024
- 1.241088352203369
- 1.2390553259849548
- 1.2355649495124816
- 1.2343614292144776
- 1.2338079333305358
- 1.2347889399528504
- 1.236819474697113
- 1.233200833797455
- 1.2345418524742127
- 1.2295446252822877
- 1.226981248855591
- 1.22798264503479
- 1.2309004640579224
- 1.2285453128814696
- 1.2341231155395507
- 1.2327835297584533
- 1.230335705280304
- 1.233251326084137
- 1.2368686699867248
- 1.2333280730247498
- 1.2297220921516419
- 1.2307181000709533
- 1.232884750366211
- 1.2330521106719972
- 1.2351779699325562
- 1.2284598016738892
- 1.2309414219856263
- 1.2268719315528869
- 1.233283610343933
- 1.2317556190490722
- 1.2285547709465028
- 1.232365641593933
- 1.2333746123313905
- 1.2332672834396363
- 1.2305534029006957
- 1.2287614345550537
- 1.2329445815086364
- 1.233018069267273
- 1.234446039199829
- 1.2319779109954834
- 1.236145737171173
- 1.23129292011261
- 1.2300713801383971
- 1.2330728793144226
train_accuracy:
- 0.0
- 0.086
- 0.0
- 0.113
- 0.123
- 0.15
- 0.0
- 0.0
- 0.0
- 0.175
- 0.173
- 0.191
- 0.197
- 0.209
- 0.0
- 0.215
- 0.218
- 0.215
- 0.22
- 0.239
- 0.237
- 0.0
- 0.0
- 0.236
- 0.0
- 0.251
- 0.253
- 0.0
- 0.0
- 0.258
- 0.232
- 0.252
- 0.257
- 0.274
- 0.275
- 0.266
- 0.276
- 0.276
- 0.257
- 0.267
- 0.268
- 0.296
- 0.284
- 0.0
- 0.0
- 0.286
- 0.0
- 0.233
- 0.307
- 0.265
- 0.0
- 0.0
- 0.314
- 0.316
- 0.0
- 0.273
- 0.266
- 0.0
- 0.285
- 0.304
- 0.275
- 0.275
- 0.29
- 0.308
- 0.0
- 0.0
- 0.297
- 0.0
- 0.309
- 0.339
- 0.0
- 0.287
- 0.32
- 0.0
- 0.318
- 0.297
- 0.33
- 0.298
- 0.319
- 0.332
- 0.0
- 0.0
- 0.315
- 0.284
- 0.0
- 0.308
- 0.279
- 0.0
- 0.0
- 0.316
- 0.326
- 0.326
- 0.311
- 0.249
- 0.0
- 0.34
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 3.192
- 2.931
- 2.734
- 2.612
- 2.131
- 2.833
- 2.03
- 2.259
- 1.895
- 2.165
- 2.383
- 2.329
- 2.249
- 2.215
- 1.877
- 2.098
- 1.553
- 1.977
- 1.443
- 1.85
- 1.543
- 1.598
- 1.547
- 1.729
- 1.618
- 1.388
- 1.199
- 1.343
- 1.292
- 1.287
- 1.268
- 1.214
- 1.123
- 1.103
- 0.957
- 1.214
- 1.076
- 1.026
- 0.988
- 0.918
- 1.105
- 0.937
- 0.921
- 0.868
- 0.902
- 0.88
- 0.815
- 0.88
- 0.931
- 0.766
- 0.76
- 0.745
- 0.726
- 0.631
- 0.683
- 0.682
- 0.604
- 0.657
- 0.597
- 0.647
- 0.559
- 0.589
- 0.56
- 0.549
- 0.482
- 0.528
- 0.535
- 0.468
- 0.498
- 0.512
- 0.491
- 0.454
- 0.439
- 0.442
- 0.415
- 0.413
- 0.396
- 0.396
- 0.389
- 0.416
- 0.39
- 0.377
- 0.357
- 0.36
- 0.389
- 0.338
- 0.356
- 0.32
- 0.324
- 0.326
- 0.311
- 0.323
- 0.312
- 0.296
- 0.302
- 0.307
- 0.286
- 0.281
- 0.296
- 0.28
unequal: 0
verbose: 1
