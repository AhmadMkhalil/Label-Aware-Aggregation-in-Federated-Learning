avg_train_accuracy: 0.312
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0521
- 0.0997
- 0.1255
- 0.136
- 0.1519
- 0.1631
- 0.1704
- 0.1795
- 0.1841
- 0.1917
- 0.1987
- 0.2043
- 0.2121
- 0.2153
- 0.2253
- 0.2267
- 0.2267
- 0.2313
- 0.2338
- 0.2351
- 0.24
- 0.2445
- 0.2487
- 0.2497
- 0.2519
- 0.2535
- 0.2573
- 0.2577
- 0.2607
- 0.263
- 0.2655
- 0.2662
- 0.2679
- 0.2691
- 0.2678
- 0.2723
- 0.2781
- 0.2752
- 0.2786
- 0.2817
- 0.2772
- 0.2828
- 0.2807
- 0.2832
- 0.2837
- 0.2827
- 0.2818
- 0.2876
- 0.2858
- 0.293
- 0.291
- 0.2891
- 0.2932
- 0.297
- 0.2938
- 0.2947
- 0.2939
- 0.2927
- 0.2914
- 0.2976
- 0.2976
- 0.2982
- 0.2984
- 0.2992
- 0.2985
- 0.3019
- 0.2992
- 0.2997
- 0.3033
- 0.3045
- 0.3045
- 0.303
- 0.3088
- 0.3053
- 0.3101
- 0.3023
- 0.3046
- 0.3095
- 0.3067
- 0.3058
- 0.3071
- 0.306
- 0.3079
- 0.3083
- 0.3076
- 0.308
- 0.3096
- 0.3095
- 0.3091
- 0.308
- 0.3076
- 0.3089
- 0.307
- 0.3072
- 0.3099
- 0.3087
- 0.3072
- 0.3065
- 0.3112
- 0.3136
test_loss_list:
- 1.7886964750289918
- 1.6607595777511597
- 1.6096052622795105
- 1.569454174041748
- 1.5360249257087708
- 1.5125536394119263
- 1.4941878342628478
- 1.4763113951683045
- 1.460181930065155
- 1.4467324662208556
- 1.4359243083000184
- 1.4212825870513917
- 1.411378242969513
- 1.393143458366394
- 1.380942530632019
- 1.3723446106910706
- 1.3633786916732789
- 1.3570445418357848
- 1.3454078912734986
- 1.3415313053131104
- 1.3333149695396422
- 1.3215108609199524
- 1.3177607917785645
- 1.309769973754883
- 1.302107880115509
- 1.2967476511001588
- 1.2917806649208068
- 1.2890986323356628
- 1.2805580067634583
- 1.2795667338371277
- 1.2755907416343688
- 1.2750872731208802
- 1.2675903868675231
- 1.265667061805725
- 1.2635696125030518
- 1.2573022937774658
- 1.254656891822815
- 1.2545359325408936
- 1.2514723348617554
- 1.249814865589142
- 1.2515964961051942
- 1.2448213410377502
- 1.2442418026924134
- 1.2409258961677552
- 1.2392492127418517
- 1.2396424865722657
- 1.2371776986122132
- 1.2331048965454101
- 1.2351139616966247
- 1.2243644285202027
- 1.2267608428001404
- 1.231540274620056
- 1.225439066886902
- 1.2253685235977172
- 1.2258581876754762
- 1.2292957925796508
- 1.2243448209762573
- 1.2242397832870484
- 1.2273358726501464
- 1.2194792795181275
- 1.2210688543319703
- 1.222619309425354
- 1.2254719519615174
- 1.2244000983238221
- 1.22378751039505
- 1.2233667731285096
- 1.224788899421692
- 1.221339566707611
- 1.2225398015975952
- 1.2209410238265992
- 1.2218373584747315
- 1.223417842388153
- 1.2211526393890382
- 1.2272334957122804
- 1.2231788897514344
- 1.2309034943580628
- 1.224993007183075
- 1.2246065711975098
- 1.2252902793884277
- 1.2254660868644713
- 1.2220610809326171
- 1.2275639176368713
- 1.2205743598937988
- 1.2208595013618468
- 1.223903441429138
- 1.2293984842300416
- 1.2283225202560424
- 1.2266657662391662
- 1.2261352562904357
- 1.2281533193588257
- 1.2246804332733154
- 1.2224161124229431
- 1.219757673740387
- 1.2246152448654175
- 1.2233880972862243
- 1.2243110704421998
- 1.2259230995178223
- 1.2251665949821473
- 1.224794201850891
- 1.2308555412292481
train_accuracy:
- 0.0
- 0.0
- 0.129
- 0.0
- 0.143
- 0.0
- 0.154
- 0.204
- 0.0
- 0.225
- 0.165
- 0.181
- 0.0
- 0.174
- 0.176
- 0.237
- 0.0
- 0.202
- 0.266
- 0.222
- 0.225
- 0.22
- 0.0
- 0.216
- 0.0
- 0.24
- 0.246
- 0.0
- 0.281
- 0.0
- 0.236
- 0.283
- 0.293
- 0.255
- 0.307
- 0.245
- 0.288
- 0.239
- 0.267
- 0.257
- 0.0
- 0.251
- 0.305
- 0.257
- 0.307
- 0.259
- 0.0
- 0.309
- 0.261
- 0.0
- 0.276
- 0.0
- 0.27
- 0.279
- 0.284
- 0.308
- 0.303
- 0.243
- 0.0
- 0.283
- 0.0
- 0.308
- 0.0
- 0.285
- 0.31
- 0.33
- 0.265
- 0.313
- 0.0
- 0.307
- 0.324
- 0.33
- 0.333
- 0.315
- 0.279
- 0.332
- 0.292
- 0.0
- 0.25
- 0.0
- 0.31
- 0.331
- 0.312
- 0.0
- 0.307
- 0.259
- 0.314
- 0.345
- 0.0
- 0.267
- 0.0
- 0.3
- 0.299
- 0.345
- 0.282
- 0.0
- 0.28
- 0.311
- 0.284
- 0.312
train_loss:
- 3.241
- 2.891
- 2.738
- 2.191
- 2.947
- 2.436
- 2.364
- 2.587
- 2.25
- 2.479
- 2.037
- 2.007
- 1.67
- 1.671
- 2.12
- 1.769
- 1.778
- 1.917
- 1.72
- 1.46
- 1.383
- 1.576
- 1.462
- 1.311
- 1.272
- 1.257
- 1.374
- 1.159
- 1.275
- 1.205
- 1.23
- 1.106
- 1.171
- 1.151
- 1.056
- 1.11
- 1.19
- 1.031
- 1.023
- 1.081
- 0.893
- 1.042
- 0.796
- 0.931
- 0.834
- 0.761
- 0.728
- 0.826
- 0.706
- 0.845
- 0.731
- 0.661
- 0.828
- 0.726
- 0.629
- 0.697
- 0.69
- 0.571
- 0.581
- 0.689
- 0.604
- 0.606
- 0.563
- 0.534
- 0.564
- 0.508
- 0.526
- 0.537
- 0.52
- 0.498
- 0.548
- 0.495
- 0.516
- 0.496
- 0.458
- 0.42
- 0.423
- 0.414
- 0.401
- 0.396
- 0.43
- 0.401
- 0.392
- 0.4
- 0.352
- 0.382
- 0.334
- 0.361
- 0.351
- 0.333
- 0.317
- 0.341
- 0.335
- 0.326
- 0.349
- 0.311
- 0.313
- 0.309
- 0.275
- 0.266
unequal: 0
verbose: 1
