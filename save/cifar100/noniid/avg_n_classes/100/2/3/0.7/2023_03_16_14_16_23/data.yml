avg_train_accuracy: 0.301
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0392
- 0.0987
- 0.1131
- 0.1339
- 0.1461
- 0.1589
- 0.1684
- 0.1761
- 0.1794
- 0.1896
- 0.1947
- 0.1999
- 0.2082
- 0.2112
- 0.2152
- 0.2208
- 0.2233
- 0.2278
- 0.2285
- 0.2328
- 0.2391
- 0.2368
- 0.2455
- 0.25
- 0.2495
- 0.2501
- 0.2557
- 0.2551
- 0.2584
- 0.2594
- 0.2623
- 0.2602
- 0.2658
- 0.2664
- 0.2693
- 0.2709
- 0.2695
- 0.2738
- 0.277
- 0.2755
- 0.2767
- 0.2796
- 0.2845
- 0.286
- 0.2857
- 0.2876
- 0.2871
- 0.2867
- 0.2937
- 0.2922
- 0.2888
- 0.2951
- 0.2909
- 0.2933
- 0.2943
- 0.2972
- 0.2937
- 0.2955
- 0.292
- 0.2959
- 0.2919
- 0.2987
- 0.2958
- 0.2978
- 0.299
- 0.2998
- 0.3003
- 0.301
- 0.3001
- 0.2996
- 0.3036
- 0.3037
- 0.3035
- 0.304
- 0.2999
- 0.3021
- 0.3058
- 0.3028
- 0.3045
- 0.3016
- 0.3022
- 0.3049
- 0.3067
- 0.3032
- 0.3062
- 0.3043
- 0.2994
- 0.3048
- 0.3088
- 0.3076
- 0.3083
- 0.3049
- 0.3096
- 0.3071
- 0.306
- 0.3058
- 0.3071
- 0.3109
- 0.3115
- 0.3113
test_loss_list:
- 1.789580636024475
- 1.662019271850586
- 1.615162513256073
- 1.5770714282989502
- 1.551826934814453
- 1.524598205089569
- 1.5067071580886842
- 1.4911703538894654
- 1.4742374563217162
- 1.4613137125968934
- 1.449036636352539
- 1.4367883968353272
- 1.4241272258758544
- 1.4172388410568237
- 1.4029702186584472
- 1.396695885658264
- 1.3845097136497497
- 1.3742354822158813
- 1.3692415022850037
- 1.3628660535812378
- 1.3545839738845826
- 1.352195155620575
- 1.345518400669098
- 1.3365378379821777
- 1.332299416065216
- 1.3283549666404724
- 1.3251718831062318
- 1.3199900388717651
- 1.3185996556282042
- 1.3052914547920227
- 1.303115382194519
- 1.2999000859260559
- 1.2929160213470459
- 1.291095061302185
- 1.287684292793274
- 1.2808695197105409
- 1.2829903030395509
- 1.2783730936050415
- 1.2782099485397338
- 1.2748155164718629
- 1.2671777868270875
- 1.2689363193511962
- 1.2615945649147033
- 1.2609231567382813
- 1.263211224079132
- 1.2655927896499635
- 1.2617314672470092
- 1.2601973462104796
- 1.2563136911392212
- 1.2578843498229981
- 1.2555194115638733
- 1.250652551651001
- 1.251808784008026
- 1.246528434753418
- 1.2476064348220826
- 1.249461088180542
- 1.2504950785636901
- 1.250652494430542
- 1.2502985453605653
- 1.2483843421936036
- 1.2573068594932557
- 1.2423737478256225
- 1.2463288855552674
- 1.239202926158905
- 1.2429364347457885
- 1.2409339118003846
- 1.2384727716445922
- 1.244807949066162
- 1.2410854840278625
- 1.2447905087471007
- 1.2422507977485657
- 1.241367461681366
- 1.243201105594635
- 1.2418839406967164
- 1.245089898109436
- 1.245959119796753
- 1.2437452173233032
- 1.2418758416175841
- 1.2434828495979309
- 1.2483567237854003
- 1.2443935799598693
- 1.246475694179535
- 1.2493506050109864
- 1.2494410824775697
- 1.2419948887825012
- 1.2422965359687805
- 1.245122525691986
- 1.2445598554611206
- 1.2393940329551696
- 1.2436461114883424
- 1.2434976983070374
- 1.245601019859314
- 1.2428419041633605
- 1.2439932584762574
- 1.245126452445984
- 1.2490886640548706
- 1.2446496605873107
- 1.2436354351043701
- 1.241936502456665
- 1.244200851917267
train_accuracy:
- 0.028
- 0.092
- 0.119
- 0.131
- 0.0
- 0.0
- 0.0
- 0.179
- 0.199
- 0.0
- 0.176
- 0.194
- 0.196
- 0.195
- 0.201
- 0.21
- 0.0
- 0.223
- 0.216
- 0.217
- 0.0
- 0.0
- 0.251
- 0.26
- 0.281
- 0.288
- 0.26
- 0.254
- 0.23
- 0.0
- 0.253
- 0.0
- 0.0
- 0.253
- 0.0
- 0.265
- 0.237
- 0.0
- 0.26
- 0.235
- 0.0
- 0.335
- 0.258
- 0.334
- 0.0
- 0.306
- 0.277
- 0.0
- 0.311
- 0.276
- 0.332
- 0.271
- 0.0
- 0.318
- 0.264
- 0.296
- 0.346
- 0.275
- 0.0
- 0.28
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.332
- 0.357
- 0.0
- 0.318
- 0.321
- 0.266
- 0.355
- 0.0
- 0.307
- 0.29
- 0.325
- 0.0
- 0.0
- 0.285
- 0.273
- 0.279
- 0.283
- 0.314
- 0.35
- 0.362
- 0.341
- 0.0
- 0.0
- 0.309
- 0.301
- 0.275
- 0.0
- 0.27
- 0.277
- 0.0
- 0.0
- 0.358
- 0.266
- 0.301
train_loss:
- 2.719
- 2.929
- 2.728
- 2.989
- 2.473
- 2.417
- 2.323
- 2.24
- 2.203
- 2.162
- 2.359
- 1.739
- 2.245
- 1.915
- 2.162
- 1.844
- 1.811
- 1.736
- 1.718
- 1.639
- 1.832
- 1.39
- 1.742
- 1.504
- 1.303
- 1.409
- 1.578
- 1.502
- 1.169
- 1.125
- 1.242
- 1.105
- 1.19
- 1.165
- 1.007
- 1.118
- 0.935
- 1.167
- 1.138
- 0.889
- 0.998
- 0.878
- 1.026
- 0.9
- 0.877
- 0.852
- 0.869
- 0.727
- 0.802
- 0.781
- 0.7
- 0.782
- 0.654
- 0.722
- 0.664
- 0.634
- 0.608
- 0.615
- 0.588
- 0.588
- 0.552
- 0.611
- 0.594
- 0.574
- 0.574
- 0.49
- 0.529
- 0.469
- 0.523
- 0.449
- 0.502
- 0.483
- 0.46
- 0.464
- 0.461
- 0.442
- 0.41
- 0.391
- 0.406
- 0.374
- 0.404
- 0.376
- 0.378
- 0.365
- 0.367
- 0.348
- 0.329
- 0.317
- 0.353
- 0.342
- 0.336
- 0.326
- 0.334
- 0.31
- 0.297
- 0.288
- 0.326
- 0.267
- 0.284
- 0.288
unequal: 0
verbose: 1
