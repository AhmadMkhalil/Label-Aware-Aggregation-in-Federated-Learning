avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0486
- 0.101
- 0.1258
- 0.1405
- 0.1468
- 0.1642
- 0.1662
- 0.1774
- 0.1818
- 0.1973
- 0.2002
- 0.2047
- 0.2138
- 0.2168
- 0.2248
- 0.2279
- 0.2311
- 0.2339
- 0.2404
- 0.2433
- 0.2452
- 0.2522
- 0.2468
- 0.2529
- 0.2555
- 0.2597
- 0.2615
- 0.2608
- 0.2641
- 0.2667
- 0.2658
- 0.269
- 0.2732
- 0.2752
- 0.2762
- 0.2785
- 0.2792
- 0.2829
- 0.2807
- 0.2874
- 0.2853
- 0.2896
- 0.292
- 0.2897
- 0.2872
- 0.2906
- 0.2925
- 0.2933
- 0.2926
- 0.2947
- 0.2931
- 0.2967
- 0.2943
- 0.298
- 0.2966
- 0.297
- 0.2968
- 0.3006
- 0.3009
- 0.2998
- 0.2985
- 0.2996
- 0.3046
- 0.3049
- 0.3037
- 0.3031
- 0.3032
- 0.3043
- 0.3014
- 0.3053
- 0.2999
- 0.3036
- 0.305
- 0.3088
- 0.3046
- 0.3073
- 0.3055
- 0.3076
- 0.3085
- 0.3087
- 0.311
- 0.3098
- 0.3078
- 0.3092
- 0.3139
- 0.3121
- 0.3121
- 0.3117
- 0.3117
- 0.3136
- 0.3117
- 0.3128
- 0.3131
- 0.309
- 0.3129
- 0.3114
- 0.3121
- 0.3134
- 0.3111
- 0.3131
test_loss_list:
- 1.7881922674179078
- 1.6570505332946777
- 1.6016345310211182
- 1.5644206380844117
- 1.5404308557510376
- 1.5128794050216674
- 1.4948025488853454
- 1.4724298119544983
- 1.4594080567359924
- 1.4415727853775024
- 1.43211763381958
- 1.4204637479782105
- 1.4036267924308776
- 1.3958100390434265
- 1.381025562286377
- 1.370584101676941
- 1.3624278354644774
- 1.354762272834778
- 1.3464969301223755
- 1.3423930406570435
- 1.334426245689392
- 1.3278122115135194
- 1.3247360897064209
- 1.3160668230056762
- 1.313724822998047
- 1.300701575279236
- 1.2993022751808168
- 1.2964775657653809
- 1.2900941252708436
- 1.2847215366363525
- 1.2800084090232848
- 1.2769974732398988
- 1.2720338487625122
- 1.2716873073577881
- 1.2659504222869873
- 1.2627080082893372
- 1.2616629767417908
- 1.2552109599113463
- 1.2574073910713195
- 1.2488517832756043
- 1.2508274006843567
- 1.2432925486564637
- 1.2430016040802
- 1.249476327896118
- 1.246457166671753
- 1.2358780121803283
- 1.2370623016357423
- 1.2373053407669068
- 1.236684672832489
- 1.238664140701294
- 1.2362634253501892
- 1.2325131225585937
- 1.2354887914657593
- 1.232619013786316
- 1.2380610132217407
- 1.2333332633972167
- 1.2359807443618775
- 1.231396083831787
- 1.232226355075836
- 1.2313760709762573
- 1.2288257336616517
- 1.226638514995575
- 1.22202579498291
- 1.2238036584854126
- 1.2236472153663636
- 1.2199021077156067
- 1.2239186096191406
- 1.2201806473731995
- 1.2193034434318542
- 1.2181674146652222
- 1.2217132258415222
- 1.2244622755050658
- 1.2179519724845886
- 1.2176725482940673
- 1.2237937426567078
- 1.2220570302009583
- 1.220565745830536
- 1.221968400478363
- 1.2201840901374816
- 1.220018458366394
- 1.2226497435569763
- 1.2219681763648986
- 1.2216529226303101
- 1.2215415668487548
- 1.2234235048294066
- 1.2276300024986266
- 1.2248581671714782
- 1.2288203835487366
- 1.2314646816253663
- 1.2309550380706786
- 1.2277033996582032
- 1.2284930157661438
- 1.231266403198242
- 1.2350400161743165
- 1.2322846841812134
- 1.229789388179779
- 1.2240020084381102
- 1.2273410201072692
- 1.2311555647850037
- 1.234679708480835
train_accuracy:
- 0.056
- 0.132
- 0.131
- 0.114
- 0.0
- 0.191
- 0.141
- 0.162
- 0.0
- 0.169
- 0.209
- 0.0
- 0.262
- 0.251
- 0.233
- 0.202
- 0.218
- 0.237
- 0.254
- 0.265
- 0.0
- 0.263
- 0.25
- 0.284
- 0.0
- 0.0
- 0.0
- 0.301
- 0.0
- 0.313
- 0.284
- 0.0
- 0.0
- 0.0
- 0.0
- 0.292
- 0.3
- 0.321
- 0.313
- 0.283
- 0.287
- 0.294
- 0.291
- 0.322
- 0.282
- 0.0
- 0.339
- 0.277
- 0.361
- 0.344
- 0.0
- 0.0
- 0.345
- 0.309
- 0.0
- 0.305
- 0.0
- 0.0
- 0.308
- 0.367
- 0.304
- 0.0
- 0.0
- 0.35
- 0.0
- 0.296
- 0.359
- 0.32
- 0.335
- 0.368
- 0.362
- 0.0
- 0.379
- 0.301
- 0.348
- 0.366
- 0.0
- 0.372
- 0.35
- 0.0
- 0.375
- 0.287
- 0.386
- 0.344
- 0.323
- 0.298
- 0.0
- 0.3
- 0.0
- 0.307
- 0.319
- 0.345
- 0.0
- 0.353
- 0.332
- 0.329
- 0.0
- 0.328
- 0.34
- 0.0
train_loss:
- 2.646
- 3.333
- 2.274
- 2.978
- 2.076
- 2.362
- 1.973
- 1.899
- 1.835
- 2.399
- 1.74
- 1.672
- 1.943
- 1.891
- 1.564
- 1.778
- 1.978
- 1.463
- 1.893
- 1.83
- 1.327
- 1.739
- 1.293
- 1.438
- 1.187
- 1.414
- 1.365
- 1.115
- 1.07
- 1.069
- 1.225
- 1.194
- 1.153
- 1.067
- 0.985
- 0.916
- 1.045
- 1.003
- 0.87
- 1.097
- 0.857
- 0.94
- 0.883
- 0.872
- 0.861
- 0.767
- 0.801
- 0.705
- 0.767
- 0.659
- 0.783
- 0.714
- 0.701
- 0.607
- 0.651
- 0.63
- 0.599
- 0.57
- 0.609
- 0.548
- 0.515
- 0.559
- 0.557
- 0.551
- 0.51
- 0.503
- 0.505
- 0.46
- 0.436
- 0.443
- 0.41
- 0.445
- 0.453
- 0.445
- 0.384
- 0.392
- 0.37
- 0.369
- 0.383
- 0.389
- 0.359
- 0.366
- 0.357
- 0.354
- 0.355
- 0.328
- 0.319
- 0.319
- 0.308
- 0.301
- 0.329
- 0.313
- 0.293
- 0.295
- 0.287
- 0.293
- 0.291
- 0.272
- 0.285
- 0.254
unequal: 0
verbose: 1
