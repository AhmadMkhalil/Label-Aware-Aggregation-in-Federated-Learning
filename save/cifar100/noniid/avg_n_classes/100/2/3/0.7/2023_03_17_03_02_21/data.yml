avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0442
- 0.0868
- 0.1083
- 0.1282
- 0.148
- 0.1568
- 0.1643
- 0.1731
- 0.1815
- 0.1905
- 0.1936
- 0.1984
- 0.2045
- 0.2078
- 0.2099
- 0.2151
- 0.2178
- 0.2262
- 0.2259
- 0.2301
- 0.2344
- 0.2375
- 0.2425
- 0.2391
- 0.2431
- 0.2473
- 0.2469
- 0.2507
- 0.2494
- 0.2575
- 0.2561
- 0.2588
- 0.263
- 0.2616
- 0.262
- 0.2657
- 0.2667
- 0.2644
- 0.2644
- 0.2695
- 0.2716
- 0.2704
- 0.2745
- 0.276
- 0.2777
- 0.2808
- 0.2807
- 0.2834
- 0.2819
- 0.2823
- 0.2872
- 0.2813
- 0.2917
- 0.2889
- 0.2901
- 0.2887
- 0.2893
- 0.2893
- 0.2894
- 0.2902
- 0.2879
- 0.2929
- 0.29
- 0.2911
- 0.2945
- 0.2915
- 0.2967
- 0.2957
- 0.2996
- 0.2971
- 0.2977
- 0.2978
- 0.3005
- 0.2992
- 0.2983
- 0.2971
- 0.2963
- 0.3019
- 0.2959
- 0.2982
- 0.2997
- 0.3005
- 0.3013
- 0.3026
- 0.2981
- 0.2985
- 0.303
- 0.3029
- 0.3042
- 0.3028
- 0.3047
- 0.3019
- 0.3029
- 0.3046
- 0.3023
- 0.3017
- 0.3047
- 0.3019
- 0.3021
- 0.3023
test_loss_list:
- 1.7889434099197388
- 1.6696129179000854
- 1.618178517818451
- 1.5777744436264038
- 1.5430819845199586
- 1.5175310254096985
- 1.4969093012809753
- 1.478363769054413
- 1.4607591223716736
- 1.4444782853126525
- 1.4331472539901733
- 1.4221260166168213
- 1.4109577322006226
- 1.401807107925415
- 1.3931833982467652
- 1.3844852685928344
- 1.3742628192901611
- 1.3622419738769531
- 1.3611962437629699
- 1.3529327154159545
- 1.3432556223869323
- 1.3393055129051208
- 1.3332438921928407
- 1.3283374166488648
- 1.3214851593971253
- 1.314632318019867
- 1.3116316270828248
- 1.3069026613235473
- 1.3063169717788696
- 1.300767900943756
- 1.2978955817222595
- 1.2911065125465393
- 1.2893779540061951
- 1.28734459400177
- 1.2880213952064514
- 1.2817004013061524
- 1.2773544239997863
- 1.2779071521759033
- 1.2788442134857179
- 1.2675732922554017
- 1.2696187686920166
- 1.267833309173584
- 1.2624310541152954
- 1.2598807096481324
- 1.2583412551879882
- 1.2557426166534424
- 1.2592869091033936
- 1.2552656292915345
- 1.2557045602798462
- 1.2505865931510924
- 1.2469025230407715
- 1.2502934527397156
- 1.2447055029869079
- 1.2462692427635194
- 1.245623905658722
- 1.2461737561225892
- 1.2451715922355653
- 1.241558437347412
- 1.2420373702049254
- 1.2429819703102112
- 1.2394673085212708
- 1.240647611618042
- 1.2435901832580567
- 1.240736289024353
- 1.2364520120620728
- 1.2343838143348693
- 1.2326254153251648
- 1.2388929796218873
- 1.2331395769119262
- 1.2362445998191833
- 1.232705476284027
- 1.235182704925537
- 1.23285537481308
- 1.2338187766075135
- 1.2319363474845886
- 1.2345144391059875
- 1.232163791656494
- 1.2304226183891296
- 1.2349825525283813
- 1.2346086144447326
- 1.2345659613609314
- 1.2392675399780273
- 1.2352758073806762
- 1.237504186630249
- 1.2412990856170654
- 1.2380262684822083
- 1.2362354755401612
- 1.2347578811645508
- 1.2373976349830627
- 1.2382067918777466
- 1.2405384302139282
- 1.2477288031578064
- 1.2425280380249024
- 1.2429076719284058
- 1.2421162343025207
- 1.2449469065666199
- 1.2429980421066285
- 1.2459473943710326
- 1.2479732537269592
- 1.2450172996520996
train_accuracy:
- 0.047
- 0.081
- 0.082
- 0.121
- 0.0
- 0.137
- 0.145
- 0.168
- 0.145
- 0.168
- 0.0
- 0.0
- 0.215
- 0.0
- 0.17
- 0.176
- 0.208
- 0.221
- 0.223
- 0.216
- 0.223
- 0.257
- 0.24
- 0.218
- 0.225
- 0.23
- 0.259
- 0.232
- 0.217
- 0.238
- 0.237
- 0.265
- 0.254
- 0.294
- 0.0
- 0.254
- 0.0
- 0.0
- 0.239
- 0.247
- 0.0
- 0.251
- 0.266
- 0.0
- 0.0
- 0.241
- 0.294
- 0.0
- 0.261
- 0.295
- 0.281
- 0.0
- 0.252
- 0.275
- 0.283
- 0.0
- 0.0
- 0.305
- 0.0
- 0.322
- 0.253
- 0.28
- 0.0
- 0.0
- 0.258
- 0.297
- 0.272
- 0.0
- 0.0
- 0.292
- 0.0
- 0.0
- 0.3
- 0.0
- 0.0
- 0.263
- 0.318
- 0.0
- 0.0
- 0.261
- 0.0
- 0.268
- 0.265
- 0.266
- 0.326
- 0.27
- 0.0
- 0.289
- 0.316
- 0.0
- 0.256
- 0.332
- 0.306
- 0.0
- 0.0
- 0.263
- 0.301
- 0.287
- 0.31
- 0.0
train_loss:
- 3.807
- 2.49
- 2.771
- 2.698
- 2.563
- 2.485
- 2.378
- 2.294
- 1.916
- 2.174
- 1.812
- 2.052
- 2.013
- 1.67
- 1.637
- 1.821
- 1.614
- 1.775
- 1.443
- 1.701
- 1.697
- 1.613
- 1.593
- 1.293
- 1.519
- 1.422
- 1.423
- 1.444
- 1.395
- 1.369
- 1.106
- 1.259
- 1.371
- 1.216
- 1.106
- 1.386
- 1.121
- 1.103
- 1.089
- 1.079
- 1.065
- 0.901
- 1.009
- 0.915
- 0.901
- 0.99
- 0.95
- 0.877
- 0.749
- 0.838
- 0.85
- 0.737
- 0.803
- 0.791
- 0.743
- 0.725
- 0.664
- 0.66
- 0.661
- 0.637
- 0.6
- 0.573
- 0.568
- 0.559
- 0.558
- 0.572
- 0.561
- 0.527
- 0.532
- 0.539
- 0.541
- 0.483
- 0.463
- 0.521
- 0.468
- 0.45
- 0.486
- 0.465
- 0.449
- 0.458
- 0.394
- 0.407
- 0.411
- 0.381
- 0.404
- 0.399
- 0.383
- 0.375
- 0.362
- 0.367
- 0.341
- 0.324
- 0.32
- 0.376
- 0.345
- 0.328
- 0.325
- 0.322
- 0.339
- 0.31
unequal: 0
verbose: 1
