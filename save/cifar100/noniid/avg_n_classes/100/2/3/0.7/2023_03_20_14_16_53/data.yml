avg_train_accuracy: 0.292
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0445
- 0.0966
- 0.1174
- 0.1409
- 0.1502
- 0.1623
- 0.1746
- 0.1879
- 0.1932
- 0.1934
- 0.2027
- 0.2124
- 0.2155
- 0.2217
- 0.2212
- 0.2325
- 0.2295
- 0.2324
- 0.236
- 0.2443
- 0.2445
- 0.2464
- 0.2518
- 0.2544
- 0.2576
- 0.2568
- 0.2617
- 0.2618
- 0.2596
- 0.2629
- 0.2675
- 0.2682
- 0.2676
- 0.2719
- 0.2691
- 0.2727
- 0.2745
- 0.274
- 0.277
- 0.2785
- 0.2774
- 0.2847
- 0.2841
- 0.2816
- 0.2818
- 0.2872
- 0.2843
- 0.2888
- 0.288
- 0.2863
- 0.2895
- 0.2896
- 0.2894
- 0.2937
- 0.2896
- 0.2942
- 0.2947
- 0.2944
- 0.2912
- 0.2919
- 0.2945
- 0.2921
- 0.2945
- 0.296
- 0.2971
- 0.2971
- 0.2989
- 0.2955
- 0.3004
- 0.2995
- 0.2978
- 0.2979
- 0.2983
- 0.301
- 0.2977
- 0.3008
- 0.3011
- 0.3012
- 0.2999
- 0.3007
- 0.3024
- 0.3041
- 0.3009
- 0.3072
- 0.3039
- 0.3038
- 0.3051
- 0.3061
- 0.3038
- 0.3051
- 0.3003
- 0.3082
- 0.3067
- 0.3075
- 0.3061
- 0.3089
- 0.3086
- 0.3071
- 0.3085
- 0.3051
test_loss_list:
- 1.7956661415100097
- 1.6640588235855103
- 1.613923933506012
- 1.5741622757911682
- 1.5438922142982483
- 1.5193834209442139
- 1.4978170609474182
- 1.478818395137787
- 1.4658053135871887
- 1.4549373722076415
- 1.438911018371582
- 1.425414650440216
- 1.414526879787445
- 1.4037051916122436
- 1.395756344795227
- 1.382502019405365
- 1.377826247215271
- 1.369974296092987
- 1.359287316799164
- 1.350406847000122
- 1.3477206110954285
- 1.3404723048210143
- 1.3310424280166626
- 1.3270773911476135
- 1.319843270778656
- 1.3171786260604859
- 1.3108477544784547
- 1.3056664490699768
- 1.3068504738807678
- 1.3021752977371215
- 1.2978949069976806
- 1.2935912990570069
- 1.2914096069335939
- 1.2859331846237183
- 1.2783456349372864
- 1.2786844515800475
- 1.2752049207687377
- 1.2764235472679137
- 1.2725796222686767
- 1.2673624205589293
- 1.2675649785995484
- 1.264730007648468
- 1.2644801211357117
- 1.2691256213188171
- 1.2613848519325257
- 1.2590670037269591
- 1.2555595326423645
- 1.2512615203857422
- 1.2511155319213867
- 1.249448754787445
- 1.2506325030326844
- 1.2425088000297546
- 1.2436404085159303
- 1.2436200094223022
- 1.2405687165260315
- 1.23954594373703
- 1.242259862422943
- 1.2400031352043153
- 1.241085913181305
- 1.2423714399337769
- 1.2387480640411377
- 1.2424838709831239
- 1.239766983985901
- 1.2324984526634217
- 1.2402740550041198
- 1.2294312310218811
- 1.2383696961402892
- 1.2390630912780762
- 1.2379333591461181
- 1.2409104537963866
- 1.2371613907814025
- 1.2336577343940736
- 1.2392529726028443
- 1.239133861064911
- 1.2356280636787416
- 1.2331139302253724
- 1.236545262336731
- 1.2349032592773437
- 1.2377798819541932
- 1.2313869285583496
- 1.233068835735321
- 1.2307700991630555
- 1.2343427896499635
- 1.2356549072265626
- 1.2397595143318176
- 1.2345812177658082
- 1.2365596580505371
- 1.2406440901756286
- 1.235362687110901
- 1.2394575142860413
- 1.2400046873092652
- 1.2377425360679626
- 1.2420768904685975
- 1.23719703912735
- 1.2365617275238037
- 1.237704405784607
- 1.243944025039673
- 1.2446093726158143
- 1.2485763335227966
- 1.241680703163147
train_accuracy:
- 0.044
- 0.108
- 0.096
- 0.11
- 0.0
- 0.139
- 0.184
- 0.167
- 0.189
- 0.175
- 0.21
- 0.0
- 0.18
- 0.185
- 0.185
- 0.211
- 0.207
- 0.222
- 0.0
- 0.206
- 0.309
- 0.236
- 0.246
- 0.237
- 0.313
- 0.216
- 0.333
- 0.0
- 0.0
- 0.291
- 0.255
- 0.26
- 0.0
- 0.273
- 0.0
- 0.0
- 0.346
- 0.232
- 0.281
- 0.264
- 0.255
- 0.279
- 0.0
- 0.0
- 0.0
- 0.281
- 0.283
- 0.281
- 0.296
- 0.305
- 0.0
- 0.281
- 0.0
- 0.0
- 0.308
- 0.0
- 0.265
- 0.262
- 0.309
- 0.0
- 0.281
- 0.32
- 0.0
- 0.317
- 0.289
- 0.326
- 0.296
- 0.0
- 0.298
- 0.283
- 0.32
- 0.318
- 0.0
- 0.0
- 0.274
- 0.0
- 0.287
- 0.319
- 0.0
- 0.373
- 0.375
- 0.321
- 0.326
- 0.295
- 0.298
- 0.381
- 0.0
- 0.316
- 0.299
- 0.337
- 0.374
- 0.0
- 0.293
- 0.332
- 0.0
- 0.336
- 0.352
- 0.319
- 0.375
- 0.292
train_loss:
- 3.265
- 3.404
- 2.734
- 2.576
- 2.099
- 2.779
- 2.001
- 2.624
- 2.504
- 1.798
- 1.808
- 2.035
- 1.698
- 2.195
- 1.579
- 2.097
- 1.503
- 1.451
- 1.673
- 1.941
- 1.612
- 1.321
- 1.596
- 1.523
- 1.458
- 1.205
- 1.601
- 1.365
- 1.495
- 1.262
- 1.263
- 1.376
- 1.073
- 1.173
- 1.18
- 1.118
- 1.087
- 1.017
- 1.012
- 1.141
- 1.067
- 0.953
- 0.896
- 0.894
- 0.897
- 0.771
- 0.806
- 0.872
- 0.82
- 0.719
- 0.742
- 0.736
- 0.679
- 0.648
- 0.697
- 0.681
- 0.64
- 0.657
- 0.625
- 0.527
- 0.54
- 0.558
- 0.488
- 0.577
- 0.458
- 0.543
- 0.53
- 0.478
- 0.518
- 0.517
- 0.471
- 0.483
- 0.474
- 0.468
- 0.417
- 0.451
- 0.405
- 0.408
- 0.371
- 0.414
- 0.38
- 0.393
- 0.362
- 0.364
- 0.347
- 0.35
- 0.354
- 0.33
- 0.357
- 0.306
- 0.297
- 0.328
- 0.313
- 0.301
- 0.32
- 0.316
- 0.294
- 0.293
- 0.282
- 0.285
unequal: 0
verbose: 1
