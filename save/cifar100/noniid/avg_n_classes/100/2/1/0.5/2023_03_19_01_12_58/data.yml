avg_train_accuracy: 0.257
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0458
- 0.0964
- 0.1193
- 0.1327
- 0.1518
- 0.1636
- 0.1726
- 0.1821
- 0.1828
- 0.1959
- 0.2028
- 0.2118
- 0.2173
- 0.2204
- 0.2238
- 0.228
- 0.2377
- 0.2388
- 0.2418
- 0.2488
- 0.2527
- 0.2555
- 0.2553
- 0.2646
- 0.2618
- 0.2639
- 0.2688
- 0.2743
- 0.2732
- 0.2737
- 0.2745
- 0.2795
- 0.2803
- 0.2842
- 0.2834
- 0.2879
- 0.2926
- 0.2941
- 0.2956
- 0.2933
- 0.3004
- 0.3001
- 0.3017
- 0.2966
- 0.3039
- 0.3048
- 0.3014
- 0.3055
- 0.3052
- 0.3066
- 0.3067
- 0.3119
- 0.3132
- 0.3093
- 0.3129
- 0.3149
- 0.3065
- 0.3096
- 0.3123
- 0.3195
- 0.3156
- 0.3166
- 0.319
- 0.3177
- 0.3196
- 0.321
- 0.3214
- 0.3198
- 0.3212
- 0.324
- 0.3237
- 0.3242
- 0.3243
- 0.3244
- 0.3241
- 0.3241
- 0.3254
- 0.3253
- 0.3273
- 0.3269
- 0.3274
- 0.3264
- 0.3302
- 0.326
- 0.3258
- 0.3261
- 0.3278
- 0.3276
- 0.3304
- 0.3308
- 0.3344
- 0.3298
- 0.3283
- 0.3291
- 0.3295
- 0.3282
- 0.333
- 0.3301
- 0.3313
- 0.3286
test_loss_list:
- 1.780936279296875
- 1.6356598711013794
- 1.5791492581367492
- 1.5414445281028748
- 1.5050203776359559
- 1.4786629247665406
- 1.4598597526550292
- 1.4324298191070557
- 1.4200987672805787
- 1.4017996644973756
- 1.3877528285980225
- 1.3706792855262757
- 1.3614743757247925
- 1.3477685832977295
- 1.3396354246139526
- 1.3265605974197388
- 1.3141148233413695
- 1.308852789402008
- 1.2992857599258423
- 1.2892880177497863
- 1.2800311398506166
- 1.276194405555725
- 1.2723064851760864
- 1.2575525951385498
- 1.2593174839019776
- 1.2503262257575989
- 1.2427601790428162
- 1.240828754901886
- 1.2357456302642822
- 1.233416075706482
- 1.2272859811782837
- 1.2190976858139038
- 1.2171678066253662
- 1.2061330127716063
- 1.203158094882965
- 1.1968513965606689
- 1.195205855369568
- 1.1915180706977844
- 1.1889478826522828
- 1.1853090453147888
- 1.1851483154296876
- 1.1863342881202699
- 1.1808887314796448
- 1.179857633113861
- 1.181183795928955
- 1.1730052304267884
- 1.1760892510414123
- 1.170419373512268
- 1.172511510848999
- 1.1698653316497802
- 1.1711203265190124
- 1.1665515685081482
- 1.1659725284576417
- 1.1641775560379028
- 1.1601769065856933
- 1.1614887118339539
- 1.1751536107063294
- 1.1664771342277527
- 1.1618110251426697
- 1.1548925375938415
- 1.155860207080841
- 1.1586082243919373
- 1.1600951361656189
- 1.1538179302215577
- 1.1582274389266969
- 1.1542541646957398
- 1.152993996143341
- 1.152206883430481
- 1.1527135968208313
- 1.1461422204971314
- 1.1518454813957215
- 1.1502649664878846
- 1.148866183757782
- 1.1529607391357422
- 1.1498021006584167
- 1.150118489265442
- 1.1456374025344849
- 1.150344090461731
- 1.142438418865204
- 1.1424079537391663
- 1.147088496685028
- 1.1463140416145325
- 1.1457967710494996
- 1.1459536910057069
- 1.1482482624053956
- 1.147676751613617
- 1.1461027121543885
- 1.1529100584983825
- 1.1489651894569397
- 1.1486964440345764
- 1.1458454132080078
- 1.1493334102630615
- 1.1443390321731568
- 1.149954218864441
- 1.149726493358612
- 1.1530413627624512
- 1.1498877215385437
- 1.1508033466339112
- 1.1524113535881042
- 1.1572364974021911
train_accuracy:
- 0.03
- 0.103
- 0.079
- 0.125
- 0.132
- 0.16
- 0.144
- 0.164
- 0.2
- 0.195
- 0.232
- 0.18
- 0.152
- 0.231
- 0.225
- 0.236
- 0.22
- 0.192
- 0.269
- 0.192
- 0.201
- 0.198
- 0.0
- 0.237
- 0.261
- 0.221
- 0.216
- 0.271
- 0.242
- 0.25
- 0.244
- 0.0
- 0.0
- 0.286
- 0.298
- 0.274
- 0.311
- 0.267
- 0.289
- 0.235
- 0.281
- 0.291
- 0.229
- 0.297
- 0.328
- 0.306
- 0.249
- 0.266
- 0.265
- 0.256
- 0.297
- 0.308
- 0.342
- 0.281
- 0.258
- 0.26
- 0.246
- 0.279
- 0.273
- 0.302
- 0.37
- 0.275
- 0.278
- 0.292
- 0.261
- 0.325
- 0.299
- 0.281
- 0.277
- 0.284
- 0.311
- 0.0
- 0.31
- 0.289
- 0.271
- 0.314
- 0.288
- 0.277
- 0.324
- 0.334
- 0.271
- 0.355
- 0.3
- 0.35
- 0.285
- 0.276
- 0.371
- 0.324
- 0.289
- 0.335
- 0.273
- 0.282
- 0.363
- 0.299
- 0.328
- 0.269
- 0.317
- 0.283
- 0.256
- 0.257
train_loss:
- 3.568
- 3.885
- 3.645
- 2.858
- 3.379
- 3.221
- 3.094
- 3.056
- 2.444
- 2.43
- 2.807
- 2.35
- 2.647
- 2.158
- 2.084
- 2.094
- 2.432
- 2.354
- 1.934
- 2.25
- 1.876
- 2.083
- 1.741
- 2.13
- 1.921
- 1.712
- 1.945
- 1.818
- 1.88
- 1.527
- 1.529
- 1.493
- 1.426
- 1.392
- 1.364
- 1.352
- 1.446
- 1.451
- 1.246
- 1.488
- 1.411
- 1.363
- 1.364
- 1.277
- 1.098
- 1.288
- 1.034
- 1.13
- 1.196
- 0.948
- 0.899
- 1.051
- 1.076
- 1.0
- 0.998
- 1.046
- 0.833
- 0.918
- 0.906
- 0.887
- 0.833
- 0.866
- 0.71
- 0.848
- 0.709
- 0.697
- 0.772
- 0.694
- 0.633
- 0.727
- 0.685
- 0.575
- 0.7
- 0.64
- 0.594
- 0.575
- 0.525
- 0.603
- 0.538
- 0.524
- 0.539
- 0.544
- 0.505
- 0.482
- 0.473
- 0.502
- 0.485
- 0.457
- 0.48
- 0.433
- 0.423
- 0.416
- 0.405
- 0.407
- 0.428
- 0.387
- 0.374
- 0.364
- 0.36
- 0.336
unequal: 0
verbose: 1
