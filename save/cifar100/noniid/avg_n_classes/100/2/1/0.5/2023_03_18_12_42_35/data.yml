avg_train_accuracy: 0.386
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0498
- 0.1073
- 0.119
- 0.138
- 0.1465
- 0.1586
- 0.1692
- 0.1782
- 0.1869
- 0.1916
- 0.1997
- 0.207
- 0.2111
- 0.219
- 0.223
- 0.2316
- 0.2347
- 0.2341
- 0.238
- 0.2494
- 0.2463
- 0.2539
- 0.256
- 0.2637
- 0.2583
- 0.2636
- 0.2683
- 0.269
- 0.2729
- 0.2726
- 0.2726
- 0.2799
- 0.2758
- 0.2781
- 0.2834
- 0.2853
- 0.2832
- 0.2922
- 0.2923
- 0.2935
- 0.2907
- 0.2984
- 0.2973
- 0.2982
- 0.3036
- 0.2996
- 0.302
- 0.301
- 0.3027
- 0.3052
- 0.3101
- 0.3071
- 0.3055
- 0.312
- 0.3076
- 0.3093
- 0.3125
- 0.312
- 0.3153
- 0.3148
- 0.315
- 0.3166
- 0.3158
- 0.3121
- 0.3154
- 0.3158
- 0.3148
- 0.3175
- 0.3196
- 0.3194
- 0.3189
- 0.3177
- 0.3225
- 0.3226
- 0.3246
- 0.3215
- 0.3261
- 0.325
- 0.3223
- 0.3242
- 0.3194
- 0.323
- 0.3259
- 0.3266
- 0.3257
- 0.3245
- 0.325
- 0.3263
- 0.3267
- 0.3275
- 0.3282
- 0.3245
- 0.3263
- 0.3263
- 0.3254
- 0.3286
- 0.3279
- 0.3295
- 0.3265
- 0.331
test_loss_list:
- 1.7785790061950684
- 1.6389004945755006
- 1.5888434195518493
- 1.544019992351532
- 1.511540606021881
- 1.4800780034065246
- 1.4617499423027038
- 1.4429544043540954
- 1.4229900598526002
- 1.4101338410377502
- 1.3929301738739013
- 1.3810894393920898
- 1.3716380572319031
- 1.358306896686554
- 1.3499563241004944
- 1.3388501286506653
- 1.3278135561943054
- 1.3195010089874268
- 1.3150719237327575
- 1.3008355331420898
- 1.3012647247314453
- 1.2876730847358704
- 1.2833053493499755
- 1.269748477935791
- 1.2676664042472838
- 1.26041757106781
- 1.2530458521842958
- 1.2522847938537598
- 1.249390163421631
- 1.2420908164978028
- 1.2383454823493958
- 1.2282604551315308
- 1.2335221409797668
- 1.2268054008483886
- 1.2217300391197206
- 1.2198843193054199
- 1.2153952145576477
- 1.2058569812774658
- 1.2047635102272034
- 1.2009878730773926
- 1.1979732155799865
- 1.1927245211601258
- 1.1938086915016175
- 1.188655960559845
- 1.1850963163375854
- 1.1845236015319824
- 1.1827245497703551
- 1.184380578994751
- 1.1777306008338928
- 1.1727789258956909
- 1.1710135078430175
- 1.1758688926696776
- 1.1737783718109132
- 1.1722548818588256
- 1.1753214049339293
- 1.17714337348938
- 1.1655100679397583
- 1.1669368028640748
- 1.1646053814888
- 1.1664446187019348
- 1.1617211937904357
- 1.1596252489089967
- 1.1611577987670898
- 1.1654053139686584
- 1.1623512840270995
- 1.1600239419937133
- 1.1647023606300353
- 1.1651927089691163
- 1.1598989987373352
- 1.1595031881332398
- 1.1557696080207824
- 1.1587006449699402
- 1.1572474074363708
- 1.1567320871353148
- 1.1544594407081603
- 1.1592987823486327
- 1.1568252992630006
- 1.155137574672699
- 1.1602954459190369
- 1.1599612140655517
- 1.161604084968567
- 1.1619416236877442
- 1.161012945175171
- 1.1601476550102234
- 1.160666253566742
- 1.1555287194252015
- 1.1569780540466308
- 1.1584201455116272
- 1.1544666981697083
- 1.161246976852417
- 1.1584785628318786
- 1.1586839485168456
- 1.1571151566505433
- 1.1615686702728272
- 1.157965726852417
- 1.1604138565063478
- 1.1652885270118714
- 1.1607365369796754
- 1.1671347880363465
- 1.1670538949966431
train_accuracy:
- 0.038
- 0.086
- 0.128
- 0.132
- 0.14
- 0.172
- 0.154
- 0.186
- 0.16
- 0.193
- 0.174
- 0.157
- 0.232
- 0.185
- 0.251
- 0.25
- 0.178
- 0.237
- 0.237
- 0.282
- 0.254
- 0.202
- 0.211
- 0.306
- 0.218
- 0.311
- 0.253
- 0.0
- 0.261
- 0.263
- 0.243
- 0.287
- 0.263
- 0.266
- 0.249
- 0.234
- 0.244
- 0.243
- 0.245
- 0.232
- 0.235
- 0.256
- 0.241
- 0.256
- 0.249
- 0.249
- 0.274
- 0.264
- 0.284
- 0.303
- 0.273
- 0.357
- 0.291
- 0.3
- 0.263
- 0.271
- 0.305
- 0.32
- 0.0
- 0.241
- 0.316
- 0.315
- 0.0
- 0.0
- 0.304
- 0.286
- 0.0
- 0.272
- 0.319
- 0.338
- 0.349
- 0.271
- 0.0
- 0.281
- 0.279
- 0.319
- 0.322
- 0.376
- 0.275
- 0.282
- 0.282
- 0.337
- 0.0
- 0.368
- 0.279
- 0.312
- 0.273
- 0.275
- 0.275
- 0.327
- 0.272
- 0.323
- 0.0
- 0.295
- 0.0
- 0.314
- 0.332
- 0.36
- 0.276
- 0.386
train_loss:
- 4.364
- 3.218
- 3.0
- 2.934
- 3.345
- 3.246
- 3.156
- 3.078
- 2.964
- 2.437
- 2.82
- 2.744
- 2.671
- 2.625
- 2.489
- 2.444
- 2.424
- 1.984
- 2.343
- 2.279
- 1.852
- 2.22
- 1.81
- 2.093
- 1.734
- 1.952
- 1.925
- 1.625
- 1.882
- 1.503
- 1.446
- 1.523
- 1.383
- 1.384
- 1.371
- 1.285
- 1.274
- 1.312
- 1.412
- 1.472
- 1.271
- 1.384
- 1.158
- 1.106
- 1.241
- 1.131
- 1.166
- 0.974
- 1.054
- 1.016
- 1.083
- 0.991
- 1.075
- 1.029
- 0.849
- 0.874
- 1.028
- 0.862
- 0.836
- 0.78
- 0.793
- 0.9
- 0.71
- 0.7
- 0.678
- 0.685
- 0.642
- 0.583
- 0.774
- 0.634
- 0.657
- 0.666
- 0.556
- 0.608
- 0.581
- 0.56
- 0.586
- 0.583
- 0.531
- 0.564
- 0.531
- 0.511
- 0.466
- 0.458
- 0.454
- 0.475
- 0.459
- 0.465
- 0.45
- 0.462
- 0.401
- 0.418
- 0.417
- 0.366
- 0.409
- 0.421
- 0.367
- 0.39
- 0.356
- 0.333
unequal: 0
verbose: 1
