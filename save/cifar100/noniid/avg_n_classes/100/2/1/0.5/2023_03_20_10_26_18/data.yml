avg_train_accuracy: 0.319
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0441
- 0.0939
- 0.1176
- 0.1386
- 0.1493
- 0.1629
- 0.1719
- 0.1782
- 0.187
- 0.195
- 0.2005
- 0.2078
- 0.2155
- 0.2162
- 0.2236
- 0.231
- 0.2344
- 0.2391
- 0.2459
- 0.243
- 0.249
- 0.2512
- 0.256
- 0.259
- 0.2623
- 0.2632
- 0.2633
- 0.2623
- 0.2684
- 0.2684
- 0.2698
- 0.2785
- 0.273
- 0.277
- 0.2786
- 0.2859
- 0.2841
- 0.2826
- 0.2861
- 0.2828
- 0.2907
- 0.2876
- 0.2922
- 0.2945
- 0.2937
- 0.2908
- 0.2951
- 0.2964
- 0.2949
- 0.2989
- 0.2957
- 0.2987
- 0.302
- 0.3009
- 0.3018
- 0.3016
- 0.303
- 0.3025
- 0.3057
- 0.3095
- 0.3059
- 0.3121
- 0.3128
- 0.3118
- 0.3046
- 0.3092
- 0.3126
- 0.3118
- 0.3124
- 0.315
- 0.31
- 0.3122
- 0.3122
- 0.3122
- 0.3151
- 0.3135
- 0.3145
- 0.312
- 0.3165
- 0.3169
- 0.3185
- 0.32
- 0.317
- 0.3205
- 0.3193
- 0.319
- 0.3217
- 0.3166
- 0.3196
- 0.3207
- 0.3203
- 0.3232
- 0.3229
- 0.3213
- 0.3207
- 0.3224
- 0.3195
- 0.3252
- 0.3221
- 0.3237
test_loss_list:
- 1.7756328105926513
- 1.6406629920005797
- 1.5833426928520202
- 1.5373851656913757
- 1.5102592706680298
- 1.4791352891921996
- 1.454913969039917
- 1.4354281616210938
- 1.4204536151885987
- 1.40669997215271
- 1.39446133852005
- 1.3804019594192505
- 1.3653226232528686
- 1.359032497406006
- 1.3435589694976806
- 1.3329990410804748
- 1.3261538171768188
- 1.3146816658973695
- 1.3056152868270874
- 1.303974859714508
- 1.296199119091034
- 1.2817256236076355
- 1.275391516685486
- 1.2684435725212098
- 1.2646493077278138
- 1.2626947093009948
- 1.2544444990158081
- 1.2496723008155823
- 1.2485385966300964
- 1.2407130599021912
- 1.2410380411148072
- 1.2344769287109374
- 1.2349033045768738
- 1.2319461178779603
- 1.2182445001602173
- 1.213710572719574
- 1.209540557861328
- 1.212664132118225
- 1.2089159965515137
- 1.214423761367798
- 1.203012659549713
- 1.203759527206421
- 1.1996465516090393
- 1.194919786453247
- 1.1899999380111694
- 1.1911072158813476
- 1.1844973707199096
- 1.1837927055358888
- 1.1812676358222962
- 1.1811859798431397
- 1.1809286332130433
- 1.1840895485877991
- 1.177111976146698
- 1.1782143306732178
- 1.1785238242149354
- 1.179083971977234
- 1.1766802883148193
- 1.1802828264236451
- 1.17302818775177
- 1.168849036693573
- 1.1630505681037904
- 1.1652658581733704
- 1.1632506847381592
- 1.1621202683448792
- 1.1699593162536621
- 1.159392409324646
- 1.1609668278694152
- 1.161431577205658
- 1.1613052153587342
- 1.1607315015792847
- 1.1613772702217102
- 1.1635527062416076
- 1.1746317625045777
- 1.1669396328926087
- 1.1689614701271056
- 1.1708923816680907
- 1.16487890958786
- 1.1618604016304017
- 1.1593067669868469
- 1.1558887219429017
- 1.1584801054000855
- 1.1555524206161498
- 1.1643495869636535
- 1.1575079202651977
- 1.1618902683258057
- 1.1597431206703186
- 1.159338834285736
- 1.1597454524040223
- 1.16061692237854
- 1.159614953994751
- 1.1588683319091797
- 1.1584082436561585
- 1.164969174861908
- 1.1654799914360046
- 1.1659820938110352
- 1.1629823565483093
- 1.1655138111114502
- 1.1624018216133118
- 1.1576253938674927
- 1.1658706426620484
train_accuracy:
- 0.045
- 0.104
- 0.124
- 0.141
- 0.147
- 0.119
- 0.159
- 0.0
- 0.208
- 0.191
- 0.183
- 0.199
- 0.206
- 0.192
- 0.2
- 0.21
- 0.23
- 0.162
- 0.215
- 0.237
- 0.261
- 0.18
- 0.268
- 0.253
- 0.245
- 0.244
- 0.249
- 0.19
- 0.249
- 0.26
- 0.284
- 0.268
- 0.252
- 0.248
- 0.281
- 0.286
- 0.289
- 0.306
- 0.252
- 0.285
- 0.236
- 0.293
- 0.0
- 0.0
- 0.296
- 0.284
- 0.269
- 0.235
- 0.0
- 0.288
- 0.295
- 0.296
- 0.221
- 0.284
- 0.289
- 0.274
- 0.287
- 0.302
- 0.355
- 0.284
- 0.319
- 0.338
- 0.339
- 0.285
- 0.315
- 0.316
- 0.263
- 0.255
- 0.291
- 0.0
- 0.314
- 0.307
- 0.305
- 0.288
- 0.311
- 0.311
- 0.309
- 0.302
- 0.287
- 0.252
- 0.312
- 0.262
- 0.322
- 0.311
- 0.315
- 0.367
- 0.263
- 0.304
- 0.322
- 0.309
- 0.325
- 0.303
- 0.309
- 0.307
- 0.309
- 0.326
- 0.314
- 0.323
- 0.339
- 0.319
train_loss:
- 3.516
- 3.863
- 3.017
- 3.428
- 2.682
- 3.173
- 2.583
- 2.504
- 2.871
- 2.34
- 2.679
- 2.618
- 2.611
- 2.108
- 2.5
- 2.408
- 2.029
- 2.355
- 2.229
- 1.884
- 1.77
- 1.795
- 1.784
- 2.059
- 1.937
- 1.577
- 1.613
- 1.566
- 1.453
- 1.736
- 1.763
- 1.679
- 1.342
- 1.315
- 1.451
- 1.478
- 1.555
- 1.506
- 1.422
- 1.175
- 1.372
- 1.187
- 1.151
- 1.158
- 1.07
- 1.044
- 1.061
- 1.232
- 1.017
- 1.113
- 1.071
- 0.895
- 1.056
- 0.894
- 0.962
- 0.935
- 0.81
- 0.816
- 0.861
- 0.813
- 0.826
- 0.823
- 0.829
- 0.789
- 0.682
- 0.72
- 0.723
- 0.712
- 0.727
- 0.664
- 0.618
- 0.657
- 0.572
- 0.552
- 0.588
- 0.585
- 0.57
- 0.532
- 0.579
- 0.513
- 0.566
- 0.54
- 0.489
- 0.493
- 0.459
- 0.467
- 0.449
- 0.436
- 0.465
- 0.444
- 0.443
- 0.395
- 0.426
- 0.396
- 0.422
- 0.388
- 0.383
- 0.376
- 0.379
- 0.347
unequal: 0
verbose: 1
