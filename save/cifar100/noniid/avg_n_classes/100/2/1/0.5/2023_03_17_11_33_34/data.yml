avg_train_accuracy: 0.314
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0454
- 0.0923
- 0.1178
- 0.1362
- 0.1502
- 0.1657
- 0.1752
- 0.1837
- 0.1931
- 0.1982
- 0.2021
- 0.2036
- 0.2161
- 0.2205
- 0.2246
- 0.2317
- 0.236
- 0.239
- 0.24
- 0.246
- 0.2547
- 0.2541
- 0.2581
- 0.2567
- 0.2614
- 0.2653
- 0.2699
- 0.2728
- 0.2771
- 0.2748
- 0.2769
- 0.2792
- 0.2844
- 0.2845
- 0.2919
- 0.2892
- 0.292
- 0.2909
- 0.2913
- 0.2949
- 0.296
- 0.2911
- 0.2946
- 0.2983
- 0.2979
- 0.2996
- 0.3037
- 0.3044
- 0.305
- 0.3042
- 0.3073
- 0.3052
- 0.3074
- 0.3068
- 0.3071
- 0.3088
- 0.3081
- 0.3176
- 0.3084
- 0.3141
- 0.3185
- 0.3224
- 0.3201
- 0.3191
- 0.3209
- 0.3147
- 0.3192
- 0.3202
- 0.3208
- 0.3228
- 0.3186
- 0.3184
- 0.3219
- 0.3232
- 0.3253
- 0.3233
- 0.322
- 0.3269
- 0.3269
- 0.3239
- 0.3217
- 0.3206
- 0.3275
- 0.326
- 0.3241
- 0.3273
- 0.3249
- 0.3312
- 0.3266
- 0.3262
- 0.3347
- 0.3275
- 0.3285
- 0.3309
- 0.3246
- 0.3305
- 0.3312
- 0.3309
- 0.3322
- 0.3242
test_loss_list:
- 1.7784251737594605
- 1.6432706904411316
- 1.583294231891632
- 1.542568907737732
- 1.5083531737327576
- 1.4756126952171327
- 1.454544541835785
- 1.4380812549591064
- 1.4206003332138062
- 1.4027674055099488
- 1.389545862674713
- 1.3719142580032349
- 1.3625479078292846
- 1.3514334225654603
- 1.3369678568840027
- 1.3260742545127868
- 1.3181604194641112
- 1.308353178501129
- 1.305596537590027
- 1.2921838855743408
- 1.2812559914588928
- 1.277080307006836
- 1.2695948100090027
- 1.2674969506263734
- 1.2568863677978515
- 1.250536425113678
- 1.2442808389663695
- 1.2345783019065857
- 1.234579303264618
- 1.2318394589424133
- 1.2277806758880616
- 1.2195020484924317
- 1.2208486318588256
- 1.2172098660469055
- 1.2128158760070802
- 1.2092341876029968
- 1.2021657824516296
- 1.2054528427124023
- 1.1979195666313172
- 1.192908868789673
- 1.192339677810669
- 1.196480519771576
- 1.1886475014686584
- 1.1818733143806457
- 1.1770611023902893
- 1.175569272041321
- 1.1731502890586853
- 1.171237711906433
- 1.1744420170783996
- 1.1693260765075684
- 1.1608363318443298
- 1.159687032699585
- 1.1581816339492799
- 1.1581190299987794
- 1.1566537857055663
- 1.1593824076652526
- 1.1559186792373657
- 1.144086742401123
- 1.1575496220588684
- 1.1517241191864014
- 1.1486375260353088
- 1.1426682472229004
- 1.1431032419204712
- 1.1469455456733704
- 1.145396831035614
- 1.1505196046829225
- 1.1540048336982727
- 1.1500393414497376
- 1.1450845980644226
- 1.1460349035263062
- 1.144234640598297
- 1.147602310180664
- 1.1423624706268312
- 1.1473606204986573
- 1.140323736667633
- 1.146426818370819
- 1.1444963097572327
- 1.141129801273346
- 1.1408394145965577
- 1.1444110107421874
- 1.1502338147163391
- 1.1538039588928222
- 1.1421549606323242
- 1.1390446829795837
- 1.1450026249885559
- 1.1402251052856445
- 1.1466867733001709
- 1.137805917263031
- 1.1466762232780456
- 1.1419571232795716
- 1.1429844045639037
- 1.1467361330986023
- 1.146465826034546
- 1.1486092138290405
- 1.152928192615509
- 1.1488558220863343
- 1.1517796778678895
- 1.1467299461364746
- 1.151349377632141
- 1.1580935978889466
train_accuracy:
- 0.054
- 0.086
- 0.107
- 0.145
- 0.123
- 0.135
- 0.144
- 0.216
- 0.187
- 0.0
- 0.0
- 0.194
- 0.192
- 0.218
- 0.183
- 0.21
- 0.237
- 0.227
- 0.0
- 0.229
- 0.246
- 0.29
- 0.226
- 0.0
- 0.263
- 0.268
- 0.26
- 0.249
- 0.229
- 0.242
- 0.23
- 0.29
- 0.284
- 0.296
- 0.239
- 0.324
- 0.272
- 0.271
- 0.291
- 0.273
- 0.271
- 0.0
- 0.269
- 0.346
- 0.285
- 0.277
- 0.0
- 0.296
- 0.287
- 0.347
- 0.312
- 0.308
- 0.285
- 0.301
- 0.295
- 0.305
- 0.296
- 0.271
- 0.286
- 0.367
- 0.324
- 0.322
- 0.372
- 0.304
- 0.304
- 0.284
- 0.307
- 0.308
- 0.314
- 0.32
- 0.0
- 0.314
- 0.318
- 0.323
- 0.328
- 0.284
- 0.0
- 0.317
- 0.298
- 0.317
- 0.383
- 0.302
- 0.322
- 0.318
- 0.0
- 0.294
- 0.335
- 0.308
- 0.305
- 0.401
- 0.332
- 0.0
- 0.324
- 0.33
- 0.319
- 0.32
- 0.303
- 0.314
- 0.332
- 0.314
train_loss:
- 4.326
- 3.869
- 3.656
- 2.883
- 3.368
- 2.71
- 2.578
- 3.071
- 2.971
- 2.459
- 2.306
- 2.76
- 2.654
- 2.166
- 2.502
- 2.511
- 2.405
- 2.392
- 1.958
- 2.263
- 2.246
- 1.822
- 2.077
- 1.777
- 1.745
- 1.689
- 1.918
- 1.886
- 1.795
- 1.797
- 1.718
- 1.707
- 1.65
- 1.652
- 1.516
- 1.391
- 1.539
- 1.257
- 1.318
- 1.422
- 1.414
- 1.151
- 1.126
- 1.16
- 1.245
- 1.25
- 1.053
- 1.223
- 0.998
- 0.986
- 0.996
- 0.991
- 0.917
- 0.907
- 0.829
- 0.806
- 0.905
- 0.973
- 0.771
- 0.822
- 0.904
- 0.851
- 0.853
- 0.816
- 0.703
- 0.707
- 0.705
- 0.632
- 0.708
- 0.707
- 0.664
- 0.637
- 0.66
- 0.583
- 0.634
- 0.578
- 0.553
- 0.6
- 0.518
- 0.511
- 0.507
- 0.467
- 0.494
- 0.511
- 0.469
- 0.495
- 0.437
- 0.475
- 0.403
- 0.468
- 0.421
- 0.363
- 0.462
- 0.398
- 0.404
- 0.402
- 0.395
- 0.398
- 0.362
- 0.364
unequal: 0
verbose: 1
