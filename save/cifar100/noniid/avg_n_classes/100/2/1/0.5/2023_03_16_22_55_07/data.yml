avg_train_accuracy: 0.355
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0427
- 0.099
- 0.1157
- 0.1269
- 0.1477
- 0.146
- 0.1707
- 0.1756
- 0.1849
- 0.1872
- 0.1953
- 0.2027
- 0.2064
- 0.2109
- 0.2149
- 0.222
- 0.2232
- 0.2284
- 0.2304
- 0.2366
- 0.2411
- 0.2435
- 0.2467
- 0.25
- 0.2484
- 0.2531
- 0.2548
- 0.2596
- 0.2599
- 0.2648
- 0.2665
- 0.2699
- 0.2737
- 0.2734
- 0.2764
- 0.2742
- 0.2766
- 0.2848
- 0.284
- 0.2811
- 0.2868
- 0.2877
- 0.2865
- 0.294
- 0.2878
- 0.2926
- 0.2938
- 0.296
- 0.2942
- 0.2938
- 0.2988
- 0.2964
- 0.2997
- 0.3039
- 0.3042
- 0.299
- 0.3042
- 0.3047
- 0.3096
- 0.31
- 0.307
- 0.3032
- 0.3068
- 0.3101
- 0.3136
- 0.3103
- 0.3161
- 0.3114
- 0.312
- 0.3147
- 0.3131
- 0.3194
- 0.3123
- 0.3175
- 0.3182
- 0.3157
- 0.3203
- 0.3139
- 0.317
- 0.3195
- 0.3181
- 0.3213
- 0.3178
- 0.3208
- 0.3212
- 0.3229
- 0.3166
- 0.3243
- 0.3235
- 0.3267
- 0.3243
- 0.3201
- 0.3257
- 0.3229
- 0.3249
- 0.3258
- 0.3297
- 0.3294
- 0.3274
- 0.328
test_loss_list:
- 1.7831690645217895
- 1.6419976806640626
- 1.5911185717582703
- 1.5472581791877746
- 1.51011390209198
- 1.4867293047904968
- 1.4583948898315429
- 1.4382801175117492
- 1.4238962030410767
- 1.4092990446090699
- 1.3958625745773316
- 1.3800621104240418
- 1.3657451725006104
- 1.3557015991210937
- 1.3450792121887207
- 1.3339259815216065
- 1.324674437046051
- 1.313125765323639
- 1.3046751284599305
- 1.2968305659294128
- 1.2906463098526002
- 1.2846777105331422
- 1.2769210457801818
- 1.2695492959022523
- 1.2641736578941345
- 1.2637464165687562
- 1.2574104738235474
- 1.2467384696006776
- 1.2450824522972106
- 1.2379467129707336
- 1.2313798666000366
- 1.2310505318641662
- 1.2233021140098572
- 1.222284462451935
- 1.2093294954299927
- 1.2131990718841552
- 1.2076349878311157
- 1.198117368221283
- 1.2021981263160706
- 1.2069974064826965
- 1.1966493153572082
- 1.191236550807953
- 1.1921274328231812
- 1.1840347671508789
- 1.1813104462623596
- 1.1812407755851746
- 1.1819015455245971
- 1.180538568496704
- 1.176365613937378
- 1.1769769740104676
- 1.175804433822632
- 1.1739697122573853
- 1.1717155241966248
- 1.1641479134559631
- 1.1626963782310487
- 1.163391993045807
- 1.1631317043304443
- 1.1612602496147155
- 1.1589066410064697
- 1.156272053718567
- 1.1587780284881593
- 1.1685646891593933
- 1.1647941541671754
- 1.1587264680862426
- 1.1557394409179687
- 1.1558097863197327
- 1.1529440426826476
- 1.1535094738006593
- 1.1543298721313477
- 1.1506536436080932
- 1.1572247219085694
- 1.1465938663482667
- 1.1597134733200074
- 1.15936532497406
- 1.1540200400352478
- 1.1533013200759887
- 1.1517771530151366
- 1.1602327942848205
- 1.153188111782074
- 1.1471520972251892
- 1.152311406135559
- 1.1497891163825988
- 1.1558166241645813
- 1.1585194754600525
- 1.154274525642395
- 1.1551773619651795
- 1.1585892820358277
- 1.151566596031189
- 1.155106155872345
- 1.1543429517745971
- 1.1547026634216309
- 1.156144025325775
- 1.1524954724311829
- 1.1615989375114442
- 1.151764464378357
- 1.1559480333328247
- 1.15662495136261
- 1.1572608542442322
- 1.158233287334442
- 1.1657094287872314
train_accuracy:
- 0.059
- 0.12
- 0.11
- 0.098
- 0.0
- 0.151
- 0.175
- 0.153
- 0.211
- 0.158
- 0.16
- 0.181
- 0.183
- 0.203
- 0.196
- 0.0
- 0.206
- 0.22
- 0.229
- 0.219
- 0.267
- 0.234
- 0.219
- 0.24
- 0.23
- 0.221
- 0.0
- 0.231
- 0.214
- 0.0
- 0.259
- 0.0
- 0.293
- 0.238
- 0.283
- 0.279
- 0.282
- 0.247
- 0.267
- 0.317
- 0.27
- 0.0
- 0.307
- 0.293
- 0.251
- 0.293
- 0.292
- 0.0
- 0.285
- 0.289
- 0.3
- 0.295
- 0.303
- 0.3
- 0.297
- 0.327
- 0.31
- 0.261
- 0.284
- 0.332
- 0.312
- 0.303
- 0.306
- 0.0
- 0.322
- 0.0
- 0.316
- 0.283
- 0.329
- 0.286
- 0.258
- 0.264
- 0.264
- 0.354
- 0.362
- 0.318
- 0.318
- 0.0
- 0.273
- 0.277
- 0.317
- 0.366
- 0.254
- 0.34
- 0.298
- 0.32
- 0.314
- 0.305
- 0.288
- 0.341
- 0.326
- 0.31
- 0.352
- 0.365
- 0.301
- 0.297
- 0.308
- 0.37
- 0.342
- 0.355
train_loss:
- 4.309
- 3.863
- 2.994
- 2.898
- 2.812
- 2.719
- 3.174
- 3.089
- 2.485
- 2.891
- 2.837
- 2.803
- 2.258
- 2.611
- 2.57
- 2.093
- 2.083
- 2.023
- 2.32
- 2.267
- 2.255
- 2.176
- 2.124
- 1.814
- 1.693
- 1.957
- 1.659
- 1.582
- 1.895
- 1.508
- 1.783
- 1.451
- 1.442
- 1.345
- 1.739
- 1.372
- 1.368
- 1.487
- 1.482
- 1.221
- 1.183
- 1.186
- 1.286
- 1.191
- 1.335
- 1.256
- 1.19
- 1.054
- 1.151
- 1.196
- 1.013
- 0.911
- 0.934
- 1.055
- 0.959
- 0.898
- 0.826
- 0.833
- 0.813
- 0.792
- 0.837
- 0.732
- 0.792
- 0.766
- 0.712
- 0.702
- 0.774
- 0.702
- 0.606
- 0.637
- 0.671
- 0.743
- 0.599
- 0.581
- 0.563
- 0.604
- 0.62
- 0.538
- 0.571
- 0.604
- 0.533
- 0.506
- 0.512
- 0.492
- 0.504
- 0.546
- 0.514
- 0.488
- 0.435
- 0.453
- 0.43
- 0.45
- 0.441
- 0.402
- 0.415
- 0.419
- 0.38
- 0.403
- 0.37
- 0.367
unequal: 0
verbose: 1
