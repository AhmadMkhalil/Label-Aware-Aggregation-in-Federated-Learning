avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0467
- 0.0949
- 0.119
- 0.1316
- 0.1421
- 0.1589
- 0.1704
- 0.1886
- 0.1931
- 0.203
- 0.2006
- 0.2133
- 0.2231
- 0.2235
- 0.2297
- 0.23
- 0.2323
- 0.2351
- 0.2415
- 0.2472
- 0.2492
- 0.2502
- 0.2486
- 0.2535
- 0.2605
- 0.2642
- 0.2679
- 0.2685
- 0.2702
- 0.271
- 0.2732
- 0.2784
- 0.2737
- 0.2793
- 0.2829
- 0.2814
- 0.285
- 0.2855
- 0.2839
- 0.2846
- 0.2922
- 0.2883
- 0.2928
- 0.295
- 0.2956
- 0.2937
- 0.2977
- 0.2943
- 0.2959
- 0.2973
- 0.3012
- 0.3054
- 0.3026
- 0.3027
- 0.306
- 0.3036
- 0.3035
- 0.3063
- 0.3094
- 0.3106
- 0.3085
- 0.3099
- 0.312
- 0.3149
- 0.3086
- 0.3108
- 0.3159
- 0.3152
- 0.3097
- 0.3148
- 0.3117
- 0.3148
- 0.3148
- 0.3163
- 0.3123
- 0.3214
- 0.3209
- 0.3146
- 0.321
- 0.3225
- 0.3249
- 0.3164
- 0.3258
- 0.3234
- 0.3205
- 0.3271
- 0.3243
- 0.3231
- 0.3284
- 0.328
- 0.3283
- 0.3247
- 0.3224
- 0.3212
- 0.3287
- 0.3256
- 0.3245
- 0.3269
- 0.3304
- 0.3278
test_loss_list:
- 1.7812502574920654
- 1.6416786074638368
- 1.5869774150848388
- 1.5468257212638854
- 1.5153375911712645
- 1.4862540316581727
- 1.4625594520568848
- 1.4390023040771485
- 1.4214023399353026
- 1.4049260139465332
- 1.392462124824524
- 1.3735454559326172
- 1.3606054019927978
- 1.355111882686615
- 1.3452513217926025
- 1.3337130951881409
- 1.3283620357513428
- 1.3250580739974975
- 1.3166379094123841
- 1.3001960706710816
- 1.296258375644684
- 1.2926794075965882
- 1.2892434191703797
- 1.283004674911499
- 1.2684194684028625
- 1.261084451675415
- 1.2594206976890563
- 1.2486105895042419
- 1.243569073677063
- 1.2430266284942626
- 1.2408648347854614
- 1.2322152686119079
- 1.2311329340934754
- 1.2224318408966064
- 1.22107173204422
- 1.220538604259491
- 1.216175651550293
- 1.2193363690376282
- 1.2194703722000122
- 1.2145669078826904
- 1.205032343864441
- 1.203625521659851
- 1.2038711023330688
- 1.1987697029113769
- 1.1989302134513855
- 1.1934280824661254
- 1.199510040283203
- 1.196370186805725
- 1.1906145930290222
- 1.1936520671844482
- 1.1816721081733703
- 1.1793130016326905
- 1.18668790102005
- 1.1881340837478638
- 1.1830980157852173
- 1.1822188520431518
- 1.181452178955078
- 1.1822083544731141
- 1.1815032052993775
- 1.1755812406539916
- 1.1771589756011962
- 1.1734908628463745
- 1.1707023239135743
- 1.1708815431594848
- 1.1770824766159058
- 1.1724387454986571
- 1.1743047046661377
- 1.1781392288208008
- 1.1788563084602357
- 1.1693820333480835
- 1.180317347049713
- 1.1707538270950317
- 1.175535740852356
- 1.1712389421463012
- 1.1760193705558777
- 1.1683555221557618
- 1.170385603904724
- 1.1743414568901063
- 1.1729475474357605
- 1.1640645956993103
- 1.1642645764350892
- 1.1691685652732848
- 1.15882643699646
- 1.173471291065216
- 1.1687953805923461
- 1.1677293038368226
- 1.1710344123840333
- 1.1792551946640015
- 1.1700816082954406
- 1.1697789764404296
- 1.17084175825119
- 1.1666916847229003
- 1.1665568017959596
- 1.1748495411872864
- 1.167710576057434
- 1.1691199707984925
- 1.175289056301117
- 1.1611405634880065
- 1.172760741710663
- 1.1722199749946594
train_accuracy:
- 0.038
- 0.102
- 0.083
- 0.0
- 0.106
- 0.131
- 0.0
- 0.171
- 0.169
- 0.156
- 0.158
- 0.206
- 0.245
- 0.252
- 0.199
- 0.219
- 0.208
- 0.18
- 0.219
- 0.216
- 0.242
- 0.229
- 0.231
- 0.0
- 0.205
- 0.252
- 0.0
- 0.243
- 0.263
- 0.227
- 0.226
- 0.27
- 0.272
- 0.277
- 0.278
- 0.296
- 0.252
- 0.0
- 0.261
- 0.328
- 0.27
- 0.329
- 0.28
- 0.274
- 0.299
- 0.279
- 0.299
- 0.0
- 0.286
- 0.299
- 0.29
- 0.314
- 0.296
- 0.334
- 0.306
- 0.0
- 0.3
- 0.262
- 0.3
- 0.283
- 0.275
- 0.289
- 0.294
- 0.283
- 0.0
- 0.312
- 0.305
- 0.274
- 0.0
- 0.297
- 0.309
- 0.284
- 0.338
- 0.302
- 0.36
- 0.3
- 0.304
- 0.286
- 0.311
- 0.307
- 0.348
- 0.301
- 0.32
- 0.29
- 0.363
- 0.292
- 0.301
- 0.285
- 0.323
- 0.0
- 0.317
- 0.307
- 0.318
- 0.371
- 0.305
- 0.3
- 0.314
- 0.364
- 0.301
- 0.0
train_loss:
- 3.581
- 3.883
- 3.047
- 2.91
- 2.778
- 3.177
- 2.582
- 3.081
- 2.463
- 2.418
- 2.322
- 2.309
- 2.643
- 2.165
- 2.487
- 2.462
- 2.36
- 1.904
- 2.242
- 1.945
- 2.103
- 2.061
- 1.713
- 1.816
- 1.694
- 1.953
- 1.623
- 1.939
- 1.847
- 1.467
- 1.712
- 1.459
- 1.411
- 1.661
- 1.514
- 1.527
- 1.467
- 1.251
- 1.255
- 1.203
- 1.39
- 1.388
- 1.237
- 1.284
- 1.065
- 1.252
- 1.059
- 1.001
- 0.964
- 0.971
- 1.127
- 1.113
- 0.997
- 0.833
- 1.01
- 0.823
- 0.847
- 0.912
- 0.851
- 0.797
- 0.726
- 0.835
- 0.888
- 0.865
- 0.652
- 0.775
- 0.685
- 0.686
- 0.638
- 0.78
- 0.572
- 0.607
- 0.598
- 0.687
- 0.59
- 0.63
- 0.629
- 0.574
- 0.503
- 0.573
- 0.518
- 0.492
- 0.565
- 0.492
- 0.482
- 0.462
- 0.425
- 0.461
- 0.433
- 0.447
- 0.419
- 0.427
- 0.397
- 0.397
- 0.404
- 0.392
- 0.344
- 0.442
- 0.371
- 0.331
unequal: 0
verbose: 1
