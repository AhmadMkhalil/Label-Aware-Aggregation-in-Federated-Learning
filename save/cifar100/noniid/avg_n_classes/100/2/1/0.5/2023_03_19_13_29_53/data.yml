avg_train_accuracy: 0.318
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0335
- 0.1027
- 0.1232
- 0.1423
- 0.1561
- 0.1661
- 0.1735
- 0.1826
- 0.1897
- 0.2023
- 0.2049
- 0.2074
- 0.2169
- 0.2188
- 0.2289
- 0.2341
- 0.2369
- 0.2442
- 0.2445
- 0.2502
- 0.2555
- 0.2569
- 0.2599
- 0.2571
- 0.2636
- 0.2626
- 0.2676
- 0.2707
- 0.273
- 0.2789
- 0.2849
- 0.2845
- 0.2858
- 0.288
- 0.2911
- 0.2916
- 0.2939
- 0.2937
- 0.2917
- 0.2977
- 0.3006
- 0.301
- 0.3006
- 0.3027
- 0.3009
- 0.311
- 0.31
- 0.3095
- 0.3087
- 0.3109
- 0.3118
- 0.3125
- 0.3124
- 0.3119
- 0.3185
- 0.3166
- 0.3198
- 0.3149
- 0.3151
- 0.32
- 0.3171
- 0.3143
- 0.324
- 0.3233
- 0.3213
- 0.3196
- 0.3219
- 0.3224
- 0.3253
- 0.3263
- 0.3261
- 0.3281
- 0.3264
- 0.3251
- 0.329
- 0.3293
- 0.3265
- 0.3288
- 0.3306
- 0.331
- 0.3256
- 0.3282
- 0.3298
- 0.3271
- 0.3313
- 0.3327
- 0.3349
- 0.3321
- 0.3343
- 0.3327
- 0.3315
- 0.337
- 0.3351
- 0.3332
- 0.3377
- 0.3317
- 0.336
- 0.334
- 0.3365
- 0.3368
test_loss_list:
- 1.8020696687698363
- 1.6428508496284484
- 1.5823844265937805
- 1.5380115008354187
- 1.5067893028259278
- 1.4760704493522645
- 1.456231234073639
- 1.4361081719398499
- 1.4185850024223328
- 1.395308825969696
- 1.3836806035041809
- 1.373051085472107
- 1.3552483296394349
- 1.3449800133705139
- 1.3300115156173706
- 1.3194679117202759
- 1.3107729291915893
- 1.3004354619979859
- 1.2966699314117431
- 1.2902900886535644
- 1.2754323029518126
- 1.2653451657295227
- 1.2619597864151002
- 1.2598462772369385
- 1.252533586025238
- 1.254066858291626
- 1.2393705177307128
- 1.2385622024536134
- 1.2345700311660766
- 1.2226066565513611
- 1.217716417312622
- 1.2080764031410218
- 1.203826756477356
- 1.2053216195106506
- 1.1930635285377502
- 1.197112693786621
- 1.1891509008407593
- 1.1912774205207826
- 1.1916575002670289
- 1.1824273920059205
- 1.1806015729904176
- 1.1787366795539855
- 1.1754527807235717
- 1.1765361475944518
- 1.174213511943817
- 1.162774522304535
- 1.163684277534485
- 1.1611554431915283
- 1.167040376663208
- 1.1615689373016358
- 1.1578261208534242
- 1.1614918780326844
- 1.160084478855133
- 1.1576079773902892
- 1.1535129809379578
- 1.1505716061592102
- 1.1524124479293822
- 1.1543237161636353
- 1.1556267309188843
- 1.144008755683899
- 1.147586123943329
- 1.1467630028724671
- 1.1434085750579834
- 1.1410432744026184
- 1.1422535681724548
- 1.1457160210609436
- 1.1366850161552429
- 1.1392836666107178
- 1.1351797890663147
- 1.1377413225173951
- 1.1363680100440978
- 1.1337370371818543
- 1.1389610409736632
- 1.1409465670585632
- 1.1386474752426148
- 1.1371045875549317
- 1.1350386619567872
- 1.1308619809150695
- 1.1301179909706116
- 1.1314509296417237
- 1.1371666049957276
- 1.1372504043579101
- 1.1399392557144166
- 1.1474341416358949
- 1.1357420253753663
- 1.1381036734580994
- 1.1327532625198364
- 1.1384792447090148
- 1.1380842685699464
- 1.1360652112960816
- 1.1406983375549316
- 1.1392455625534057
- 1.143094253540039
- 1.1434495425224305
- 1.1385551929473876
- 1.1438668370246887
- 1.1432287406921386
- 1.145915491580963
- 1.142851583957672
- 1.1357846927642823
train_accuracy:
- 0.016
- 0.084
- 0.12
- 0.143
- 0.143
- 0.14
- 0.171
- 0.183
- 0.0
- 0.183
- 0.19
- 0.0
- 0.14
- 0.184
- 0.195
- 0.21
- 0.212
- 0.222
- 0.217
- 0.251
- 0.214
- 0.178
- 0.253
- 0.207
- 0.251
- 0.0
- 0.258
- 0.243
- 0.237
- 0.236
- 0.278
- 0.267
- 0.272
- 0.284
- 0.254
- 0.305
- 0.0
- 0.272
- 0.318
- 0.308
- 0.224
- 0.302
- 0.285
- 0.306
- 0.0
- 0.261
- 0.301
- 0.273
- 0.267
- 0.269
- 0.331
- 0.289
- 0.325
- 0.304
- 0.304
- 0.309
- 0.309
- 0.292
- 0.31
- 0.0
- 0.282
- 0.252
- 0.343
- 0.282
- 0.346
- 0.321
- 0.305
- 0.329
- 0.295
- 0.298
- 0.285
- 0.345
- 0.283
- 0.322
- 0.332
- 0.304
- 0.315
- 0.349
- 0.289
- 0.352
- 0.32
- 0.0
- 0.274
- 0.301
- 0.297
- 0.322
- 0.305
- 0.325
- 0.335
- 0.288
- 0.296
- 0.269
- 0.359
- 0.348
- 0.348
- 0.0
- 0.365
- 0.35
- 0.303
- 0.318
train_loss:
- 4.37
- 3.917
- 3.643
- 3.448
- 3.319
- 3.227
- 2.634
- 3.022
- 2.464
- 2.875
- 2.805
- 2.294
- 2.218
- 2.157
- 2.518
- 2.424
- 2.0
- 2.381
- 2.28
- 1.898
- 1.885
- 2.172
- 2.086
- 1.684
- 1.958
- 1.563
- 1.891
- 1.503
- 1.777
- 1.795
- 1.57
- 1.486
- 1.7
- 1.341
- 1.573
- 1.506
- 1.36
- 1.422
- 1.402
- 1.437
- 1.367
- 1.33
- 1.14
- 1.216
- 1.141
- 1.226
- 1.166
- 0.994
- 0.911
- 1.112
- 1.062
- 0.983
- 1.026
- 0.865
- 0.982
- 0.861
- 0.787
- 0.742
- 0.787
- 0.831
- 0.776
- 0.867
- 0.822
- 0.785
- 0.678
- 0.675
- 0.764
- 0.58
- 0.664
- 0.748
- 0.662
- 0.68
- 0.635
- 0.647
- 0.566
- 0.55
- 0.522
- 0.572
- 0.535
- 0.549
- 0.549
- 0.475
- 0.471
- 0.484
- 0.438
- 0.459
- 0.468
- 0.438
- 0.449
- 0.407
- 0.398
- 0.469
- 0.388
- 0.397
- 0.371
- 0.359
- 0.388
- 0.368
- 0.321
- 0.367
unequal: 0
verbose: 1
