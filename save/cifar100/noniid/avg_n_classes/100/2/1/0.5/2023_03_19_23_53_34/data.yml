avg_train_accuracy: 0.295
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0414
- 0.0994
- 0.1229
- 0.1387
- 0.1531
- 0.1604
- 0.1734
- 0.1798
- 0.1899
- 0.1953
- 0.2031
- 0.2134
- 0.2181
- 0.221
- 0.2209
- 0.2289
- 0.2345
- 0.2395
- 0.2444
- 0.2418
- 0.2529
- 0.2534
- 0.2551
- 0.2585
- 0.2605
- 0.2658
- 0.2662
- 0.2677
- 0.2706
- 0.274
- 0.2748
- 0.2825
- 0.2829
- 0.2904
- 0.2863
- 0.2874
- 0.2946
- 0.2936
- 0.2965
- 0.2956
- 0.2957
- 0.3004
- 0.3031
- 0.2995
- 0.3022
- 0.3068
- 0.3087
- 0.3053
- 0.3089
- 0.3045
- 0.3102
- 0.311
- 0.3136
- 0.3141
- 0.3131
- 0.3155
- 0.3166
- 0.3188
- 0.3244
- 0.3182
- 0.3198
- 0.3242
- 0.3288
- 0.3233
- 0.326
- 0.3228
- 0.3239
- 0.3319
- 0.3305
- 0.3265
- 0.3302
- 0.3339
- 0.3328
- 0.331
- 0.3341
- 0.3297
- 0.3312
- 0.3347
- 0.3343
- 0.3349
- 0.3313
- 0.3302
- 0.333
- 0.3337
- 0.3345
- 0.3351
- 0.3379
- 0.34
- 0.3381
- 0.3394
- 0.3353
- 0.3343
- 0.3371
- 0.3402
- 0.3379
- 0.3409
- 0.3431
- 0.3394
- 0.3368
- 0.3431
test_loss_list:
- 1.782973017692566
- 1.6473872661590576
- 1.5902687644958495
- 1.5487490892410278
- 1.5178267097473144
- 1.4860860013961792
- 1.4639702033996582
- 1.4387183094024658
- 1.4210783576965331
- 1.4047741389274597
- 1.3921149635314942
- 1.3748837804794312
- 1.3654792165756227
- 1.3546173548698426
- 1.3468020224571229
- 1.330102345943451
- 1.3190687608718872
- 1.3129174661636354
- 1.3017331218719483
- 1.2958237862586974
- 1.2850414848327636
- 1.278454384803772
- 1.2754977178573608
- 1.269932928085327
- 1.2604328751564027
- 1.2534152030944825
- 1.243245062828064
- 1.2432467007637025
- 1.2344132137298585
- 1.2284657955169678
- 1.224425609111786
- 1.2113695406913758
- 1.2074118900299071
- 1.2009868597984314
- 1.1996204543113709
- 1.1970966720581055
- 1.1896749901771546
- 1.1856180334091186
- 1.1842356872558595
- 1.1851811456680297
- 1.1752587270736694
- 1.1697734546661378
- 1.169629623889923
- 1.166721522808075
- 1.1629275560379029
- 1.1549351406097412
- 1.154693763256073
- 1.1509782004356384
- 1.1514358139038086
- 1.1558641266822816
- 1.1492455232143401
- 1.1476241636276245
- 1.1447815322875976
- 1.1442100322246551
- 1.1415471518039704
- 1.142578318119049
- 1.1369992685317993
- 1.1375670969486236
- 1.1387041902542114
- 1.1376560235023498
- 1.1384016060829163
- 1.1315663933753968
- 1.131569950580597
- 1.1354133081436157
- 1.1376352834701537
- 1.1349425172805787
- 1.136608488559723
- 1.1297212958335876
- 1.13201363325119
- 1.135609848499298
- 1.1317793798446656
- 1.1294282650947571
- 1.1311173164844512
- 1.135235879421234
- 1.1300185060501098
- 1.1341967189311981
- 1.134604845046997
- 1.1299700403213502
- 1.1338363909721374
- 1.1317525005340576
- 1.132897403240204
- 1.1358436059951782
- 1.131540733575821
- 1.1323695421218871
- 1.1304842710494996
- 1.1342359578609467
- 1.1324662172794342
- 1.131675136089325
- 1.1308864641189575
- 1.126617580652237
- 1.1354111862182616
- 1.138535817861557
- 1.1378778862953185
- 1.1308969283103942
- 1.133019847869873
- 1.1326659286022187
- 1.1269652736186981
- 1.1292621958255769
- 1.1324477326869964
- 1.1289484024047851
train_accuracy:
- 0.052
- 0.074
- 0.099
- 0.128
- 0.117
- 0.148
- 0.155
- 0.196
- 0.175
- 0.186
- 0.165
- 0.186
- 0.19
- 0.202
- 0.214
- 0.227
- 0.202
- 0.225
- 0.243
- 0.194
- 0.196
- 0.216
- 0.21
- 0.227
- 0.209
- 0.2
- 0.245
- 0.244
- 0.0
- 0.252
- 0.0
- 0.227
- 0.246
- 0.269
- 0.27
- 0.258
- 0.237
- 0.0
- 0.283
- 0.0
- 0.291
- 0.287
- 0.295
- 0.245
- 0.262
- 0.0
- 0.272
- 0.0
- 0.266
- 0.279
- 0.263
- 0.0
- 0.282
- 0.0
- 0.0
- 0.285
- 0.306
- 0.281
- 0.304
- 0.304
- 0.275
- 0.274
- 0.283
- 0.0
- 0.314
- 0.284
- 0.29
- 0.0
- 0.276
- 0.311
- 0.277
- 0.283
- 0.329
- 0.294
- 0.301
- 0.3
- 0.292
- 0.323
- 0.3
- 0.289
- 0.291
- 0.259
- 0.293
- 0.283
- 0.323
- 0.292
- 0.303
- 0.0
- 0.0
- 0.316
- 0.279
- 0.293
- 0.0
- 0.291
- 0.0
- 0.295
- 0.297
- 0.308
- 0.345
- 0.295
train_loss:
- 4.326
- 3.874
- 3.636
- 3.497
- 2.744
- 2.763
- 2.605
- 2.55
- 3.012
- 2.835
- 2.755
- 2.797
- 2.69
- 2.562
- 2.526
- 2.117
- 2.023
- 2.329
- 2.279
- 2.263
- 2.195
- 2.147
- 1.81
- 2.024
- 1.723
- 1.976
- 1.666
- 1.644
- 1.623
- 1.808
- 1.482
- 1.54
- 1.444
- 1.692
- 1.367
- 1.37
- 1.521
- 1.271
- 1.465
- 1.219
- 1.249
- 1.204
- 1.158
- 1.15
- 1.258
- 1.13
- 1.015
- 1.022
- 1.177
- 0.929
- 1.086
- 0.944
- 0.957
- 0.906
- 0.831
- 0.93
- 0.853
- 0.793
- 0.938
- 0.805
- 0.729
- 0.815
- 0.82
- 0.732
- 0.832
- 0.699
- 0.775
- 0.689
- 0.706
- 0.609
- 0.705
- 0.638
- 0.65
- 0.708
- 0.651
- 0.657
- 0.554
- 0.583
- 0.525
- 0.583
- 0.571
- 0.504
- 0.507
- 0.471
- 0.481
- 0.465
- 0.493
- 0.439
- 0.412
- 0.465
- 0.4
- 0.415
- 0.367
- 0.464
- 0.365
- 0.393
- 0.423
- 0.4
- 0.391
- 0.393
unequal: 0
verbose: 1
