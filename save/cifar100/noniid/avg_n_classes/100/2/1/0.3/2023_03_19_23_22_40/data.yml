avg_train_accuracy: 0.319
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0472
- 0.0948
- 0.1114
- 0.1269
- 0.1428
- 0.149
- 0.1679
- 0.1708
- 0.1806
- 0.1778
- 0.1911
- 0.1966
- 0.1944
- 0.2023
- 0.2098
- 0.2169
- 0.2203
- 0.2218
- 0.2351
- 0.2281
- 0.2358
- 0.2408
- 0.2485
- 0.2519
- 0.2454
- 0.257
- 0.2481
- 0.2534
- 0.2611
- 0.2672
- 0.269
- 0.2676
- 0.2715
- 0.2688
- 0.2722
- 0.2787
- 0.2786
- 0.2829
- 0.2862
- 0.2844
- 0.2828
- 0.2753
- 0.2819
- 0.2886
- 0.2924
- 0.2909
- 0.2933
- 0.2881
- 0.2865
- 0.3026
- 0.2994
- 0.2935
- 0.2938
- 0.2993
- 0.2956
- 0.3046
- 0.2945
- 0.3049
- 0.3013
- 0.2962
- 0.3047
- 0.3068
- 0.3034
- 0.312
- 0.3129
- 0.3096
- 0.3142
- 0.3162
- 0.3074
- 0.3179
- 0.3091
- 0.3157
- 0.3144
- 0.3117
- 0.3116
- 0.3194
- 0.3161
- 0.3184
- 0.3175
- 0.3221
- 0.3196
- 0.3201
- 0.3199
- 0.324
- 0.3233
- 0.3212
- 0.3144
- 0.3197
- 0.3143
- 0.3279
- 0.3251
- 0.3276
- 0.321
- 0.3284
- 0.3283
- 0.32
- 0.3217
- 0.3267
- 0.3272
- 0.3265
test_loss_list:
- 1.7869183349609374
- 1.648429045677185
- 1.598739778995514
- 1.551911885738373
- 1.5153114461898805
- 1.4923171830177306
- 1.4655659151077272
- 1.449876697063446
- 1.435877332687378
- 1.433969829082489
- 1.4082284259796143
- 1.4033965468406677
- 1.395741229057312
- 1.3777882027626038
- 1.3731703162193298
- 1.360728976726532
- 1.3437236332893372
- 1.337397005558014
- 1.3220969796180726
- 1.334935369491577
- 1.3134501123428344
- 1.2986732697486878
- 1.2822113609313965
- 1.2758750438690185
- 1.2869451880455016
- 1.2641058015823363
- 1.2823046803474427
- 1.2613957858085632
- 1.2533161783218383
- 1.2444233512878418
- 1.2508244037628173
- 1.238585033416748
- 1.2317881059646607
- 1.239949963092804
- 1.226007878780365
- 1.221740198135376
- 1.2259554839134217
- 1.2165241050720215
- 1.2107063555717468
- 1.2157100868225097
- 1.2140591168403625
- 1.2341284251213074
- 1.22045161485672
- 1.205303394794464
- 1.1981692051887511
- 1.199088523387909
- 1.1937634348869324
- 1.206898581981659
- 1.2072728443145753
- 1.181616289615631
- 1.1846955108642578
- 1.196592891216278
- 1.1829593467712403
- 1.1819695568084716
- 1.191743595600128
- 1.176481306552887
- 1.1975210213661194
- 1.1802488851547241
- 1.187306399345398
- 1.1988551926612854
- 1.1849316263198852
- 1.1806715297698975
- 1.1964704775810242
- 1.175271451473236
- 1.1678359532356262
- 1.1785456204414368
- 1.1690965795516968
- 1.1693150329589843
- 1.1848662304878235
- 1.1731231141090392
- 1.1865218043327332
- 1.1661769318580628
- 1.170481915473938
- 1.1834056329727174
- 1.1758537840843202
- 1.1692520689964294
- 1.16924072265625
- 1.1741679763793946
- 1.178661153316498
- 1.1737643671035767
- 1.1717807006835939
- 1.1751138520240785
- 1.1741903710365296
- 1.1699731540679932
- 1.1752391362190246
- 1.1700524187088013
- 1.194607105255127
- 1.1717881226539613
- 1.1791739106178283
- 1.1712652134895325
- 1.1716004085540772
- 1.1696634101867676
- 1.1754462814331055
- 1.169862060546875
- 1.1732590889930725
- 1.193246750831604
- 1.185304353237152
- 1.165417537689209
- 1.1786203384399414
- 1.17928861618042
train_accuracy:
- 0.05
- 0.084
- 0.081
- 0.144
- 0.128
- 0.12
- 0.185
- 0.144
- 0.159
- 0.0
- 0.165
- 0.212
- 0.0
- 0.191
- 0.0
- 0.169
- 0.2
- 0.228
- 0.172
- 0.0
- 0.245
- 0.227
- 0.208
- 0.264
- 0.282
- 0.253
- 0.247
- 0.251
- 0.274
- 0.244
- 0.265
- 0.268
- 0.282
- 0.266
- 0.258
- 0.271
- 0.279
- 0.28
- 0.285
- 0.287
- 0.289
- 0.254
- 0.27
- 0.29
- 0.306
- 0.0
- 0.296
- 0.0
- 0.307
- 0.29
- 0.26
- 0.302
- 0.283
- 0.307
- 0.293
- 0.292
- 0.0
- 0.297
- 0.305
- 0.274
- 0.282
- 0.318
- 0.29
- 0.313
- 0.304
- 0.323
- 0.277
- 0.308
- 0.329
- 0.344
- 0.316
- 0.33
- 0.319
- 0.344
- 0.309
- 0.328
- 0.33
- 0.317
- 0.335
- 0.322
- 0.342
- 0.315
- 0.0
- 0.332
- 0.347
- 0.335
- 0.0
- 0.348
- 0.303
- 0.317
- 0.348
- 0.327
- 0.306
- 0.307
- 0.362
- 0.31
- 0.323
- 0.332
- 0.335
- 0.319
train_loss:
- 4.345
- 3.956
- 3.707
- 3.521
- 3.365
- 3.285
- 3.155
- 3.127
- 2.91
- 2.117
- 2.868
- 2.632
- 1.952
- 2.751
- 1.85
- 1.896
- 1.899
- 1.758
- 2.359
- 1.574
- 1.868
- 2.235
- 2.307
- 2.054
- 1.569
- 2.007
- 1.498
- 1.517
- 1.953
- 1.9
- 1.419
- 1.817
- 1.721
- 1.284
- 1.745
- 1.655
- 1.534
- 1.595
- 1.503
- 1.291
- 1.443
- 1.068
- 1.084
- 1.36
- 1.355
- 1.22
- 1.259
- 0.994
- 1.332
- 1.227
- 1.139
- 0.953
- 1.136
- 1.112
- 0.765
- 1.116
- 0.826
- 0.873
- 0.928
- 0.764
- 0.805
- 0.765
- 0.81
- 0.888
- 0.84
- 0.894
- 0.731
- 0.807
- 0.6
- 0.705
- 0.637
- 0.765
- 0.653
- 0.537
- 0.785
- 0.733
- 0.641
- 0.628
- 0.691
- 0.563
- 0.585
- 0.569
- 0.509
- 0.575
- 0.498
- 0.552
- 0.451
- 0.502
- 0.461
- 0.555
- 0.484
- 0.432
- 0.473
- 0.464
- 0.388
- 0.442
- 0.429
- 0.436
- 0.415
- 0.381
unequal: 0
verbose: 1
