avg_train_accuracy: 0.338
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0382
- 0.0949
- 0.1179
- 0.1333
- 0.1401
- 0.1518
- 0.1728
- 0.1645
- 0.1712
- 0.1862
- 0.1965
- 0.2011
- 0.2067
- 0.2175
- 0.2207
- 0.2283
- 0.224
- 0.2279
- 0.2363
- 0.2367
- 0.2402
- 0.2445
- 0.2386
- 0.2504
- 0.2469
- 0.2539
- 0.2584
- 0.2671
- 0.2638
- 0.2701
- 0.2633
- 0.2682
- 0.2657
- 0.271
- 0.2773
- 0.2678
- 0.2697
- 0.2817
- 0.2831
- 0.2778
- 0.2886
- 0.2827
- 0.2844
- 0.2816
- 0.2817
- 0.2943
- 0.2969
- 0.2931
- 0.2971
- 0.2963
- 0.2949
- 0.2994
- 0.2869
- 0.298
- 0.2962
- 0.2971
- 0.2989
- 0.3011
- 0.3062
- 0.3104
- 0.3125
- 0.3098
- 0.3123
- 0.3121
- 0.3112
- 0.3037
- 0.3126
- 0.322
- 0.3176
- 0.3168
- 0.3191
- 0.3169
- 0.3178
- 0.3112
- 0.3153
- 0.3155
- 0.3225
- 0.3154
- 0.3172
- 0.3134
- 0.3199
- 0.3224
- 0.33
- 0.3118
- 0.3215
- 0.3162
- 0.3228
- 0.3248
- 0.3235
- 0.3191
- 0.3264
- 0.3264
- 0.3244
- 0.3295
- 0.3233
- 0.3269
- 0.3296
- 0.325
- 0.3237
- 0.323
test_loss_list:
- 1.7923100996017456
- 1.646566858291626
- 1.5866283679008484
- 1.5510685968399047
- 1.5225262284278869
- 1.5004830861091614
- 1.4683298659324646
- 1.4743506813049316
- 1.448238582611084
- 1.4215331149101258
- 1.4120875930786132
- 1.3910689091682433
- 1.3794472336769104
- 1.3645154762268066
- 1.3527027702331542
- 1.3374022150039673
- 1.3431885743141174
- 1.3256484699249267
- 1.3165325927734375
- 1.30923184633255
- 1.308737177848816
- 1.299565727710724
- 1.3088877892494202
- 1.2856994891166686
- 1.2872012448310852
- 1.276044828891754
- 1.2720599961280823
- 1.258749659061432
- 1.2609291863441467
- 1.2453467917442322
- 1.2490875291824342
- 1.2414435052871704
- 1.2492088174819946
- 1.2326788592338562
- 1.2206762886047364
- 1.2468228673934936
- 1.2233980894088745
- 1.2079614090919495
- 1.2064335775375366
- 1.2162072682380676
- 1.2066654658317566
- 1.2069889140129089
- 1.2059796357154846
- 1.227345004081726
- 1.213445315361023
- 1.1893675827980041
- 1.187538228034973
- 1.1919415020942687
- 1.1914201998710632
- 1.187350561618805
- 1.1890833020210265
- 1.186742775440216
- 1.2100508213043213
- 1.183695330619812
- 1.1905067372322082
- 1.1840844821929932
- 1.1745208930969238
- 1.1706603169441223
- 1.161868441104889
- 1.1591096448898315
- 1.1539102935791015
- 1.1538820886611938
- 1.1641011595726014
- 1.163128035068512
- 1.160288897752762
- 1.1758275437355041
- 1.1590961933135986
- 1.1447331786155701
- 1.156404950618744
- 1.153186205625534
- 1.1485167610645295
- 1.156345292329788
- 1.1548710989952087
- 1.1699058055877685
- 1.1577804493904114
- 1.152777123451233
- 1.1509599328041076
- 1.1565589904785156
- 1.1516984987258911
- 1.1624404692649841
- 1.1545560336112977
- 1.1532969379425049
- 1.152483310699463
- 1.1694856703281402
- 1.15042578458786
- 1.1717267441749573
- 1.1510375213623047
- 1.1408156442642212
- 1.1572958886623383
- 1.1620114314556123
- 1.1517265033721924
- 1.1560489380359649
- 1.157717957496643
- 1.1580963706970215
- 1.1687635731697084
- 1.1651079773902893
- 1.162567880153656
- 1.1568322420120238
- 1.169701771736145
- 1.1628218698501587
train_accuracy:
- 0.037
- 0.104
- 0.106
- 0.13
- 0.184
- 0.0
- 0.171
- 0.0
- 0.166
- 0.217
- 0.0
- 0.177
- 0.198
- 0.166
- 0.265
- 0.211
- 0.215
- 0.22
- 0.227
- 0.241
- 0.236
- 0.238
- 0.0
- 0.236
- 0.259
- 0.257
- 0.218
- 0.309
- 0.216
- 0.245
- 0.205
- 0.279
- 0.0
- 0.274
- 0.223
- 0.311
- 0.271
- 0.281
- 0.241
- 0.237
- 0.239
- 0.283
- 0.299
- 0.246
- 0.239
- 0.241
- 0.343
- 0.338
- 0.276
- 0.289
- 0.296
- 0.279
- 0.271
- 0.298
- 0.0
- 0.303
- 0.0
- 0.299
- 0.326
- 0.344
- 0.292
- 0.322
- 0.331
- 0.329
- 0.325
- 0.298
- 0.291
- 0.319
- 0.299
- 0.307
- 0.283
- 0.313
- 0.339
- 0.0
- 0.0
- 0.29
- 0.318
- 0.327
- 0.31
- 0.283
- 0.338
- 0.335
- 0.328
- 0.0
- 0.343
- 0.326
- 0.312
- 0.289
- 0.315
- 0.307
- 0.288
- 0.325
- 0.297
- 0.369
- 0.336
- 0.299
- 0.288
- 0.328
- 0.324
- 0.338
train_loss:
- 4.354
- 3.848
- 3.655
- 3.466
- 2.421
- 2.276
- 3.105
- 2.085
- 2.188
- 2.99
- 2.131
- 2.046
- 2.655
- 2.759
- 2.704
- 2.612
- 1.783
- 1.809
- 2.444
- 2.189
- 2.142
- 2.296
- 1.571
- 2.11
- 1.878
- 2.089
- 1.925
- 2.14
- 1.981
- 1.5
- 1.414
- 1.671
- 1.337
- 1.763
- 1.667
- 1.165
- 1.217
- 1.56
- 1.527
- 1.105
- 1.532
- 1.307
- 1.464
- 1.107
- 1.04
- 1.261
- 1.175
- 1.243
- 1.185
- 1.166
- 1.101
- 1.008
- 0.78
- 1.225
- 0.994
- 0.899
- 0.797
- 0.871
- 0.99
- 1.002
- 0.957
- 0.971
- 0.902
- 0.817
- 0.772
- 0.75
- 0.766
- 0.762
- 0.815
- 0.736
- 0.713
- 0.613
- 0.67
- 0.572
- 0.569
- 0.798
- 0.607
- 0.626
- 0.548
- 0.614
- 0.564
- 0.607
- 0.485
- 0.554
- 0.585
- 0.495
- 0.472
- 0.539
- 0.458
- 0.484
- 0.478
- 0.41
- 0.496
- 0.46
- 0.416
- 0.409
- 0.439
- 0.39
- 0.392
- 0.396
unequal: 0
verbose: 1
