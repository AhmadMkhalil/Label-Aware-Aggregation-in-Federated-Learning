avg_train_accuracy: 0.332
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0415
- 0.0894
- 0.1056
- 0.1225
- 0.141
- 0.1508
- 0.1621
- 0.1677
- 0.1732
- 0.1849
- 0.1906
- 0.1925
- 0.2007
- 0.2053
- 0.2069
- 0.2136
- 0.2162
- 0.2251
- 0.2205
- 0.2303
- 0.2309
- 0.2296
- 0.2379
- 0.2466
- 0.2371
- 0.2429
- 0.2526
- 0.2483
- 0.256
- 0.259
- 0.2581
- 0.2656
- 0.2623
- 0.2733
- 0.271
- 0.2699
- 0.2723
- 0.2731
- 0.2784
- 0.2729
- 0.2818
- 0.2781
- 0.2867
- 0.2896
- 0.2905
- 0.2882
- 0.298
- 0.2899
- 0.2935
- 0.2926
- 0.2989
- 0.295
- 0.2914
- 0.2984
- 0.2979
- 0.3035
- 0.3
- 0.301
- 0.2977
- 0.3
- 0.3088
- 0.3082
- 0.3068
- 0.3022
- 0.306
- 0.3049
- 0.3139
- 0.3116
- 0.3144
- 0.3092
- 0.3034
- 0.3095
- 0.3112
- 0.3105
- 0.3189
- 0.3178
- 0.3093
- 0.3154
- 0.321
- 0.3194
- 0.3193
- 0.3133
- 0.3202
- 0.3153
- 0.325
- 0.3269
- 0.3159
- 0.3223
- 0.3247
- 0.3202
- 0.3185
- 0.3196
- 0.3176
- 0.3227
- 0.324
- 0.3212
- 0.3245
- 0.323
- 0.3254
- 0.3264
test_loss_list:
- 1.7955298137664795
- 1.6639673352241515
- 1.6236995363235474
- 1.5665913128852844
- 1.5337681365013123
- 1.513861665725708
- 1.4851816582679749
- 1.4618722987174988
- 1.4490114760398864
- 1.4417636060714722
- 1.417966024875641
- 1.4115233993530274
- 1.3932178115844727
- 1.374545955657959
- 1.3733548307418824
- 1.3570758986473084
- 1.3511836886405946
- 1.3444567346572875
- 1.346901354789734
- 1.3311273050308228
- 1.3246107292175293
- 1.3212694430351257
- 1.3142870378494262
- 1.3037749791145326
- 1.309647045135498
- 1.3000693225860596
- 1.2801436543464662
- 1.2769402861595154
- 1.2774309587478638
- 1.2685982728004455
- 1.2691629815101624
- 1.2544579100608826
- 1.2532101202011108
- 1.2444166350364685
- 1.2406554293632508
- 1.2491116166114806
- 1.23837012052536
- 1.236640124320984
- 1.2331723976135254
- 1.2488453364372254
- 1.2259061336517334
- 1.239310212135315
- 1.2119275975227355
- 1.2106306123733521
- 1.2073847579956054
- 1.2096715044975281
- 1.2067372369766236
- 1.216148955821991
- 1.207664122581482
- 1.2131613063812257
- 1.1999703335762024
- 1.2016498470306396
- 1.2162640857696534
- 1.2027009344100952
- 1.1994544506072997
- 1.1960092353820801
- 1.2030142545700073
- 1.1922114014625549
- 1.2061029481887817
- 1.1967715072631835
- 1.1858092522621155
- 1.1863544797897339
- 1.193174614906311
- 1.196407401561737
- 1.1964208579063416
- 1.1875391292572022
- 1.1750112962722778
- 1.1786360716819764
- 1.1858841490745544
- 1.1940207767486573
- 1.1975832724571227
- 1.1838882517814637
- 1.1740466284751891
- 1.1859068584442138
- 1.1649274253845214
- 1.179309117794037
- 1.1826133942604065
- 1.1826362442970275
- 1.1728700852394105
- 1.1677500748634337
- 1.1700759840011596
- 1.1896678686141968
- 1.1743790268898011
- 1.1742609643936157
- 1.1750533485412598
- 1.1688285183906555
- 1.1826064527034759
- 1.1700994753837586
- 1.1730291771888732
- 1.1689905965328216
- 1.181168076992035
- 1.1797889399528503
- 1.1764001262187957
- 1.1743042302131652
- 1.173287593126297
- 1.18284632563591
- 1.1743953204154969
- 1.1865095067024232
- 1.177449586391449
- 1.1743917536735535
train_accuracy:
- 0.057
- 0.08
- 0.0
- 0.115
- 0.141
- 0.152
- 0.13
- 0.153
- 0.177
- 0.167
- 0.165
- 0.165
- 0.188
- 0.183
- 0.19
- 0.196
- 0.198
- 0.208
- 0.192
- 0.187
- 0.195
- 0.201
- 0.218
- 0.198
- 0.187
- 0.209
- 0.197
- 0.237
- 0.0
- 0.234
- 0.238
- 0.23
- 0.269
- 0.23
- 0.227
- 0.0
- 0.255
- 0.26
- 0.267
- 0.0
- 0.291
- 0.0
- 0.272
- 0.288
- 0.266
- 0.265
- 0.238
- 0.272
- 0.275
- 0.263
- 0.295
- 0.279
- 0.24
- 0.247
- 0.281
- 0.303
- 0.301
- 0.26
- 0.27
- 0.309
- 0.293
- 0.296
- 0.334
- 0.296
- 0.262
- 0.0
- 0.266
- 0.265
- 0.284
- 0.0
- 0.0
- 0.302
- 0.318
- 0.296
- 0.268
- 0.261
- 0.312
- 0.303
- 0.293
- 0.319
- 0.308
- 0.305
- 0.307
- 0.302
- 0.297
- 0.276
- 0.296
- 0.311
- 0.287
- 0.277
- 0.301
- 0.316
- 0.311
- 0.303
- 0.333
- 0.312
- 0.315
- 0.299
- 0.331
- 0.332
train_loss:
- 4.34
- 3.954
- 2.626
- 3.637
- 3.391
- 3.279
- 3.157
- 3.149
- 2.964
- 2.917
- 2.84
- 2.204
- 2.817
- 2.661
- 2.621
- 2.522
- 2.455
- 2.547
- 1.773
- 2.247
- 1.655
- 2.051
- 2.037
- 2.121
- 1.511
- 2.108
- 1.882
- 1.945
- 1.526
- 1.918
- 1.451
- 1.843
- 1.367
- 1.71
- 1.741
- 1.145
- 1.637
- 1.601
- 1.434
- 0.978
- 1.676
- 1.158
- 1.468
- 1.26
- 1.35
- 1.283
- 1.192
- 1.161
- 1.0
- 1.23
- 1.162
- 1.275
- 0.953
- 1.043
- 0.85
- 1.045
- 1.017
- 1.041
- 0.755
- 0.965
- 1.029
- 0.88
- 0.717
- 0.766
- 0.7
- 0.811
- 0.795
- 0.645
- 0.653
- 0.67
- 0.721
- 0.755
- 0.83
- 0.527
- 0.652
- 0.612
- 0.668
- 0.595
- 0.573
- 0.687
- 0.634
- 0.498
- 0.537
- 0.545
- 0.479
- 0.517
- 0.489
- 0.568
- 0.48
- 0.529
- 0.484
- 0.427
- 0.516
- 0.427
- 0.497
- 0.388
- 0.382
- 0.434
- 0.45
- 0.429
unequal: 0
verbose: 1
