avg_train_accuracy: 0.328
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0381
- 0.0957
- 0.1143
- 0.1266
- 0.1472
- 0.1559
- 0.1579
- 0.1705
- 0.1738
- 0.1899
- 0.1846
- 0.1941
- 0.2007
- 0.2087
- 0.2142
- 0.216
- 0.2245
- 0.2215
- 0.2307
- 0.2329
- 0.237
- 0.2362
- 0.2422
- 0.2411
- 0.249
- 0.2392
- 0.2406
- 0.2458
- 0.2477
- 0.2613
- 0.2583
- 0.2589
- 0.2672
- 0.2678
- 0.2711
- 0.2708
- 0.2672
- 0.2706
- 0.272
- 0.2805
- 0.2746
- 0.2839
- 0.2836
- 0.2795
- 0.2871
- 0.2855
- 0.2836
- 0.2923
- 0.2926
- 0.2889
- 0.2932
- 0.288
- 0.2996
- 0.2919
- 0.2991
- 0.2967
- 0.2949
- 0.2972
- 0.3031
- 0.2988
- 0.2991
- 0.3029
- 0.3039
- 0.3057
- 0.297
- 0.3055
- 0.2987
- 0.2991
- 0.3103
- 0.3076
- 0.3065
- 0.3041
- 0.2974
- 0.3074
- 0.309
- 0.3092
- 0.3049
- 0.3148
- 0.3027
- 0.3172
- 0.3088
- 0.3169
- 0.3176
- 0.3169
- 0.3154
- 0.3212
- 0.3184
- 0.3119
- 0.3153
- 0.3217
- 0.3241
- 0.3106
- 0.3195
- 0.3167
- 0.3178
- 0.3201
- 0.3176
- 0.312
- 0.3203
- 0.3258
test_loss_list:
- 1.7875681877136231
- 1.6502245688438415
- 1.592790536880493
- 1.5628266859054565
- 1.5238552784919739
- 1.5062992644309998
- 1.4908637666702271
- 1.460507550239563
- 1.4449051475524903
- 1.4249715089797974
- 1.4250173664093018
- 1.4098548483848572
- 1.3936829328536988
- 1.3835699892044067
- 1.3645541429519654
- 1.3560687279701233
- 1.3484581518173218
- 1.341381652355194
- 1.3266104340553284
- 1.3204446840286255
- 1.313899507522583
- 1.3092872190475464
- 1.307356560230255
- 1.2930737733840942
- 1.2896632313728333
- 1.2994772100448608
- 1.2911188864707948
- 1.282473123073578
- 1.28041615486145
- 1.2575477528572083
- 1.261260323524475
- 1.2507833075523376
- 1.2494328379631043
- 1.238859736919403
- 1.2371349906921387
- 1.238082308769226
- 1.2448963141441345
- 1.2379512357711793
- 1.2300333070755005
- 1.2161812806129455
- 1.2404868340492248
- 1.2210271525382996
- 1.2167265248298644
- 1.226514937877655
- 1.1993748950958252
- 1.2044983696937561
- 1.2064267206192016
- 1.198943521976471
- 1.1967489790916443
- 1.2049575424194336
- 1.1898625540733336
- 1.202610948085785
- 1.190351161956787
- 1.1896144819259644
- 1.1867961621284484
- 1.1859990239143372
- 1.191079285144806
- 1.1909730863571166
- 1.18222491979599
- 1.189923393726349
- 1.1907921290397645
- 1.1972368335723877
- 1.188768117427826
- 1.1816057300567626
- 1.206680681705475
- 1.180283625125885
- 1.1979637789726256
- 1.189507372379303
- 1.1787517976760864
- 1.176495735645294
- 1.1906279873847962
- 1.187057478427887
- 1.2084504604339599
- 1.1915785956382752
- 1.1791654109954834
- 1.1760544753074647
- 1.1869323897361754
- 1.1711551237106324
- 1.1934351444244384
- 1.1765712451934816
- 1.1774724578857423
- 1.1733312487602234
- 1.1764967513084412
- 1.1707950448989868
- 1.1779819107055665
- 1.1696922612190246
- 1.1719646286964416
- 1.1877181005477906
- 1.1781214094161987
- 1.1666540145874023
- 1.1666585445404052
- 1.1826938009262085
- 1.1734420657157898
- 1.1787512755393983
- 1.1762621378898621
- 1.1751751279830933
- 1.1752654647827148
- 1.1833196544647218
- 1.169185025691986
- 1.1707141196727753
train_accuracy:
- 0.028
- 0.097
- 0.104
- 0.102
- 0.153
- 0.108
- 0.153
- 0.176
- 0.176
- 0.121
- 0.138
- 0.145
- 0.17
- 0.198
- 0.181
- 0.23
- 0.197
- 0.206
- 0.222
- 0.165
- 0.202
- 0.201
- 0.21
- 0.229
- 0.191
- 0.201
- 0.225
- 0.224
- 0.219
- 0.233
- 0.286
- 0.278
- 0.21
- 0.271
- 0.283
- 0.233
- 0.223
- 0.239
- 0.229
- 0.272
- 0.246
- 0.272
- 0.241
- 0.259
- 0.285
- 0.306
- 0.261
- 0.258
- 0.318
- 0.265
- 0.261
- 0.29
- 0.274
- 0.257
- 0.275
- 0.289
- 0.23
- 0.293
- 0.256
- 0.301
- 0.314
- 0.249
- 0.293
- 0.241
- 0.243
- 0.267
- 0.265
- 0.31
- 0.309
- 0.266
- 0.27
- 0.265
- 0.284
- 0.0
- 0.321
- 0.298
- 0.268
- 0.268
- 0.269
- 0.282
- 0.235
- 0.309
- 0.302
- 0.317
- 0.335
- 0.271
- 0.287
- 0.287
- 0.232
- 0.272
- 0.279
- 0.0
- 0.276
- 0.0
- 0.319
- 0.237
- 0.298
- 0.325
- 0.293
- 0.328
train_loss:
- 3.052
- 3.857
- 3.726
- 3.431
- 3.344
- 2.303
- 2.265
- 3.099
- 3.031
- 2.893
- 2.061
- 1.998
- 2.681
- 2.649
- 2.611
- 1.903
- 2.351
- 2.361
- 2.536
- 2.212
- 2.3
- 2.293
- 2.118
- 2.197
- 1.954
- 1.413
- 1.46
- 1.492
- 1.446
- 1.883
- 1.518
- 1.77
- 1.354
- 1.789
- 1.724
- 1.599
- 1.453
- 1.372
- 1.544
- 1.712
- 1.065
- 1.256
- 1.247
- 1.065
- 1.671
- 1.202
- 1.326
- 1.289
- 1.326
- 1.01
- 1.273
- 0.928
- 1.055
- 1.016
- 1.053
- 1.051
- 0.96
- 0.888
- 0.989
- 1.004
- 0.912
- 0.754
- 0.845
- 0.912
- 0.62
- 0.775
- 0.724
- 0.899
- 0.768
- 0.72
- 0.586
- 0.617
- 0.585
- 0.624
- 0.724
- 0.743
- 0.53
- 0.575
- 0.571
- 0.498
- 0.577
- 0.628
- 0.535
- 0.686
- 0.558
- 0.582
- 0.497
- 0.445
- 0.498
- 0.517
- 0.5
- 0.508
- 0.482
- 0.39
- 0.519
- 0.404
- 0.336
- 0.424
- 0.376
- 0.366
unequal: 0
verbose: 1
