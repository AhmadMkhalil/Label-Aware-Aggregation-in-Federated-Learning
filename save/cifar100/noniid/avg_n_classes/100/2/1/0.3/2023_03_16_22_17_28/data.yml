avg_train_accuracy: 0.319
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0363
- 0.0821
- 0.1068
- 0.121
- 0.144
- 0.1504
- 0.1657
- 0.1717
- 0.1838
- 0.1853
- 0.1928
- 0.1903
- 0.2062
- 0.213
- 0.2179
- 0.2209
- 0.2175
- 0.2181
- 0.2263
- 0.224
- 0.2301
- 0.2339
- 0.2461
- 0.2512
- 0.2451
- 0.248
- 0.2481
- 0.2514
- 0.2592
- 0.2603
- 0.2606
- 0.2599
- 0.2652
- 0.2664
- 0.2711
- 0.2754
- 0.2773
- 0.2708
- 0.2791
- 0.2845
- 0.2863
- 0.2814
- 0.2818
- 0.2818
- 0.2815
- 0.2894
- 0.2898
- 0.2959
- 0.2915
- 0.2926
- 0.2982
- 0.2979
- 0.2982
- 0.2944
- 0.2998
- 0.3017
- 0.2936
- 0.3042
- 0.2981
- 0.3012
- 0.3021
- 0.3027
- 0.3052
- 0.3118
- 0.3045
- 0.3044
- 0.3099
- 0.3114
- 0.3019
- 0.3116
- 0.3146
- 0.3154
- 0.3201
- 0.3172
- 0.3061
- 0.3153
- 0.3215
- 0.3154
- 0.3096
- 0.3189
- 0.3122
- 0.3132
- 0.3217
- 0.3224
- 0.3204
- 0.3203
- 0.3243
- 0.3225
- 0.3229
- 0.3223
- 0.3249
- 0.3287
- 0.3256
- 0.3215
- 0.3277
- 0.3221
- 0.3246
- 0.3268
- 0.3289
- 0.3302
test_loss_list:
- 1.7836342287063598
- 1.6643790340423583
- 1.5993465781211853
- 1.5535204219818115
- 1.522802665233612
- 1.4998242902755736
- 1.4768377351760864
- 1.4514492201805114
- 1.4355858707427978
- 1.4171366453170777
- 1.4044490671157837
- 1.402001748085022
- 1.3822628021240235
- 1.3628401160240173
- 1.3574184274673462
- 1.3510186934471131
- 1.357587010860443
- 1.3432113122940064
- 1.3233920216560364
- 1.3214061450958252
- 1.3187421131134034
- 1.3116443252563477
- 1.2852941155433655
- 1.2792752003669738
- 1.2858007502555848
- 1.2839216327667236
- 1.278498923778534
- 1.2776719641685486
- 1.262045269012451
- 1.2489906001091002
- 1.2630158925056458
- 1.2541943001747131
- 1.2499692583084105
- 1.242813572883606
- 1.2350414085388184
- 1.2291053056716919
- 1.2327544355392457
- 1.2460505390167236
- 1.2280306172370912
- 1.2170264339447021
- 1.210356035232544
- 1.215265085697174
- 1.2175373578071593
- 1.2146265196800232
- 1.2224682259559632
- 1.212647213935852
- 1.2100200700759887
- 1.197610583305359
- 1.2022698020935059
- 1.2092942118644714
- 1.1931402420997619
- 1.1957310700416566
- 1.195132384300232
- 1.2001219391822815
- 1.1882490849494933
- 1.1861131834983825
- 1.1963949632644653
- 1.1793984913825988
- 1.1901660227775575
- 1.1872022318840028
- 1.1904947876930236
- 1.1921722555160523
- 1.189093508720398
- 1.1856830954551696
- 1.1918152403831481
- 1.19455570936203
- 1.1861055970191956
- 1.1772211909294128
- 1.2043052983283997
- 1.184181990623474
- 1.165399353504181
- 1.1657159161567687
- 1.1663504886627196
- 1.168897535800934
- 1.1867271542549134
- 1.165501856803894
- 1.1618161177635193
- 1.1841765451431274
- 1.1960561323165892
- 1.1750193858146667
- 1.1793331980705262
- 1.1883314371109008
- 1.1704654479026795
- 1.165708167552948
- 1.172903389930725
- 1.1750731420516969
- 1.1752593731880188
- 1.182492458820343
- 1.175672709941864
- 1.1732437825202942
- 1.1693051266670227
- 1.1686063599586487
- 1.1698048257827758
- 1.1874347734451294
- 1.1701909804344177
- 1.18571763753891
- 1.1678321266174316
- 1.1755150818824769
- 1.177186942100525
- 1.1759689855575561
train_accuracy:
- 0.039
- 0.085
- 0.084
- 0.093
- 0.145
- 0.135
- 0.141
- 0.16
- 0.161
- 0.135
- 0.16
- 0.18
- 0.163
- 0.203
- 0.161
- 0.204
- 0.184
- 0.216
- 0.18
- 0.179
- 0.0
- 0.141
- 0.238
- 0.207
- 0.206
- 0.18
- 0.167
- 0.227
- 0.216
- 0.232
- 0.0
- 0.0
- 0.206
- 0.241
- 0.264
- 0.268
- 0.259
- 0.233
- 0.252
- 0.256
- 0.264
- 0.258
- 0.274
- 0.249
- 0.268
- 0.255
- 0.261
- 0.267
- 0.266
- 0.0
- 0.246
- 0.305
- 0.259
- 0.262
- 0.292
- 0.269
- 0.273
- 0.279
- 0.298
- 0.283
- 0.285
- 0.304
- 0.301
- 0.287
- 0.304
- 0.305
- 0.296
- 0.286
- 0.0
- 0.282
- 0.303
- 0.277
- 0.294
- 0.297
- 0.274
- 0.303
- 0.308
- 0.3
- 0.276
- 0.293
- 0.0
- 0.324
- 0.297
- 0.294
- 0.289
- 0.308
- 0.318
- 0.304
- 0.309
- 0.286
- 0.305
- 0.3
- 0.29
- 0.317
- 0.295
- 0.0
- 0.289
- 0.299
- 0.318
- 0.319
train_loss:
- 3.105
- 3.839
- 3.665
- 3.564
- 3.331
- 3.289
- 2.334
- 3.021
- 2.968
- 2.866
- 2.81
- 1.935
- 2.657
- 2.734
- 2.483
- 2.464
- 1.803
- 1.805
- 2.345
- 1.8
- 1.784
- 1.678
- 2.218
- 2.13
- 1.618
- 1.441
- 1.443
- 1.307
- 2.042
- 1.87
- 1.461
- 1.292
- 1.66
- 1.584
- 1.782
- 1.677
- 1.432
- 1.232
- 1.584
- 1.575
- 1.552
- 1.264
- 1.297
- 1.302
- 1.085
- 1.126
- 1.159
- 1.472
- 1.354
- 0.836
- 1.304
- 1.133
- 1.056
- 1.012
- 1.163
- 1.165
- 0.849
- 1.02
- 0.878
- 0.93
- 0.843
- 0.783
- 0.816
- 0.771
- 0.737
- 0.76
- 0.918
- 0.782
- 0.62
- 0.655
- 0.907
- 0.794
- 0.719
- 0.64
- 0.635
- 0.645
- 0.608
- 0.485
- 0.525
- 0.566
- 0.567
- 0.473
- 0.551
- 0.629
- 0.523
- 0.605
- 0.483
- 0.398
- 0.473
- 0.552
- 0.542
- 0.442
- 0.462
- 0.426
- 0.428
- 0.465
- 0.42
- 0.334
- 0.518
- 0.351
unequal: 0
verbose: 1
