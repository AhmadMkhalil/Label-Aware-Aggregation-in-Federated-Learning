avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0507
- 0.0855
- 0.1016
- 0.1153
- 0.1335
- 0.147
- 0.1512
- 0.1659
- 0.1728
- 0.1834
- 0.1912
- 0.1863
- 0.198
- 0.2055
- 0.2052
- 0.2162
- 0.2213
- 0.2227
- 0.2282
- 0.2225
- 0.2322
- 0.2315
- 0.2393
- 0.2466
- 0.2379
- 0.2451
- 0.2448
- 0.2537
- 0.2513
- 0.2643
- 0.267
- 0.2649
- 0.2723
- 0.2743
- 0.2784
- 0.2685
- 0.2759
- 0.278
- 0.2765
- 0.2791
- 0.2767
- 0.2815
- 0.2893
- 0.2936
- 0.2937
- 0.2866
- 0.2927
- 0.2811
- 0.2961
- 0.2941
- 0.2896
- 0.302
- 0.2987
- 0.2942
- 0.3023
- 0.3022
- 0.3068
- 0.3085
- 0.3084
- 0.313
- 0.3125
- 0.3103
- 0.3076
- 0.3117
- 0.3144
- 0.3181
- 0.3113
- 0.3159
- 0.3056
- 0.3016
- 0.3136
- 0.3164
- 0.3114
- 0.3183
- 0.3196
- 0.3144
- 0.3166
- 0.3215
- 0.3162
- 0.3194
- 0.3141
- 0.3197
- 0.32
- 0.3206
- 0.3227
- 0.3217
- 0.3217
- 0.3152
- 0.3229
- 0.3191
- 0.3251
- 0.3252
- 0.3224
- 0.3282
- 0.3276
- 0.3252
- 0.3293
- 0.3264
- 0.3295
- 0.3263
test_loss_list:
- 1.7831787776947021
- 1.6526961827278137
- 1.6011295771598817
- 1.5581749939918519
- 1.5265805339813232
- 1.4993806290626526
- 1.4791032481193542
- 1.4577294731140136
- 1.446221432685852
- 1.4275819206237792
- 1.4062708950042724
- 1.408655149936676
- 1.3879395341873169
- 1.3834343075752258
- 1.380883493423462
- 1.365504457950592
- 1.3411503005027772
- 1.3311685466766356
- 1.3307646608352661
- 1.3364615988731385
- 1.3113578653335571
- 1.3153676795959472
- 1.2954279351234437
- 1.2872122836112976
- 1.2945995807647706
- 1.2803595638275147
- 1.281125738620758
- 1.2633473658561707
- 1.2648419260978698
- 1.2487918901443482
- 1.2340735077857972
- 1.2399029994010926
- 1.2335825848579407
- 1.2324888396263123
- 1.222788987159729
- 1.2385523986816407
- 1.2244322681427002
- 1.2170332384109497
- 1.2228240299224853
- 1.2073228645324707
- 1.2149227166175842
- 1.2124981951713563
- 1.196930968761444
- 1.1933558988571167
- 1.1908732914924622
- 1.199965226650238
- 1.2035566616058349
- 1.2106421303749084
- 1.189025981426239
- 1.1936150455474854
- 1.199938750267029
- 1.1793990850448608
- 1.1893600773811341
- 1.1926752042770385
- 1.1838158011436462
- 1.1810068702697754
- 1.1721210336685182
- 1.175091028213501
- 1.176361837387085
- 1.167951453924179
- 1.1605844521522521
- 1.1704291987419129
- 1.1742225968837738
- 1.1716481685638427
- 1.1713948440551758
- 1.1626707887649537
- 1.177473863363266
- 1.1726703357696533
- 1.1874449014663697
- 1.1874216818809509
- 1.1718084335327148
- 1.1661334455013275
- 1.1679815244674683
- 1.1628348708152771
- 1.1614944553375244
- 1.1655529129505158
- 1.1674116039276123
- 1.159776668548584
- 1.1758974659442902
- 1.1596562671661377
- 1.1644261157512665
- 1.1646643364429474
- 1.1609112310409546
- 1.1608027338981628
- 1.1618234479427338
- 1.1704893863201142
- 1.1591082978248597
- 1.1707544100284577
- 1.1544484090805054
- 1.172172008752823
- 1.1531135058403015
- 1.159092229604721
- 1.163896267414093
- 1.1533007609844208
- 1.153765162229538
- 1.172036156654358
- 1.1618124616146088
- 1.1760891115665435
- 1.156702024936676
- 1.166051344871521
train_accuracy:
- 0.04
- 0.0
- 0.1
- 0.0
- 0.121
- 0.137
- 0.149
- 0.149
- 0.171
- 0.159
- 0.156
- 0.176
- 0.191
- 0.198
- 0.0
- 0.176
- 0.223
- 0.219
- 0.219
- 0.223
- 0.192
- 0.212
- 0.233
- 0.212
- 0.0
- 0.21
- 0.0
- 0.237
- 0.225
- 0.264
- 0.212
- 0.266
- 0.23
- 0.245
- 0.246
- 0.258
- 0.261
- 0.253
- 0.236
- 0.251
- 0.249
- 0.0
- 0.247
- 0.275
- 0.244
- 0.27
- 0.0
- 0.0
- 0.261
- 0.297
- 0.235
- 0.267
- 0.276
- 0.268
- 0.256
- 0.3
- 0.287
- 0.279
- 0.289
- 0.288
- 0.305
- 0.266
- 0.315
- 0.322
- 0.262
- 0.309
- 0.272
- 0.32
- 0.294
- 0.281
- 0.291
- 0.291
- 0.309
- 0.293
- 0.32
- 0.279
- 0.0
- 0.322
- 0.0
- 0.293
- 0.272
- 0.304
- 0.269
- 0.303
- 0.0
- 0.0
- 0.316
- 0.0
- 0.305
- 0.295
- 0.297
- 0.267
- 0.258
- 0.305
- 0.301
- 0.299
- 0.305
- 0.317
- 0.301
- 0.0
train_loss:
- 4.365
- 2.803
- 2.583
- 2.577
- 3.334
- 3.145
- 2.394
- 3.016
- 2.904
- 2.927
- 3.048
- 2.043
- 2.707
- 1.875
- 1.812
- 2.334
- 2.617
- 2.441
- 1.721
- 1.546
- 2.31
- 1.595
- 2.099
- 2.212
- 1.67
- 1.683
- 1.386
- 1.869
- 1.493
- 1.825
- 2.011
- 1.707
- 1.759
- 1.634
- 1.659
- 1.275
- 1.654
- 1.552
- 1.216
- 1.669
- 1.154
- 1.195
- 1.409
- 1.44
- 1.199
- 1.27
- 0.93
- 0.857
- 1.487
- 1.043
- 0.927
- 1.239
- 1.255
- 1.016
- 1.127
- 0.89
- 0.951
- 1.072
- 0.916
- 0.975
- 0.978
- 0.88
- 0.759
- 1.023
- 0.794
- 0.902
- 0.727
- 0.668
- 0.649
- 0.586
- 0.691
- 0.84
- 0.605
- 0.745
- 0.684
- 0.776
- 0.59
- 0.597
- 0.507
- 0.601
- 0.593
- 0.584
- 0.633
- 0.48
- 0.419
- 0.519
- 0.501
- 0.529
- 0.412
- 0.445
- 0.637
- 0.455
- 0.39
- 0.489
- 0.477
- 0.436
- 0.442
- 0.413
- 0.447
- 0.358
unequal: 0
verbose: 1
