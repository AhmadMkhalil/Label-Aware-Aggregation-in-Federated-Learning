avg_train_accuracy: 0.255
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0449
- 0.0946
- 0.1066
- 0.1253
- 0.1392
- 0.1519
- 0.1532
- 0.1719
- 0.1769
- 0.189
- 0.1917
- 0.2008
- 0.2025
- 0.2048
- 0.2083
- 0.2164
- 0.2221
- 0.2273
- 0.2358
- 0.2419
- 0.2395
- 0.2371
- 0.2488
- 0.2374
- 0.2431
- 0.2613
- 0.2529
- 0.258
- 0.2644
- 0.2659
- 0.2638
- 0.2682
- 0.2661
- 0.271
- 0.2739
- 0.2708
- 0.2786
- 0.2745
- 0.2672
- 0.2773
- 0.2795
- 0.2819
- 0.2861
- 0.2826
- 0.2851
- 0.2846
- 0.2903
- 0.2876
- 0.2819
- 0.2805
- 0.2787
- 0.2867
- 0.2934
- 0.2962
- 0.2956
- 0.2982
- 0.2985
- 0.2968
- 0.3036
- 0.3028
- 0.305
- 0.2943
- 0.3098
- 0.3012
- 0.3002
- 0.3045
- 0.3077
- 0.3042
- 0.3102
- 0.3074
- 0.3112
- 0.3126
- 0.3099
- 0.3177
- 0.3148
- 0.3108
- 0.3123
- 0.311
- 0.3155
- 0.3159
- 0.3127
- 0.3111
- 0.3166
- 0.3096
- 0.315
- 0.319
- 0.3153
- 0.3208
- 0.3191
- 0.3219
- 0.32
- 0.3206
- 0.3162
- 0.3181
- 0.3114
- 0.318
- 0.3265
- 0.3132
- 0.323
- 0.323
test_loss_list:
- 1.7754380130767822
- 1.654037253856659
- 1.60685879945755
- 1.558738477230072
- 1.532599229812622
- 1.5042914414405824
- 1.4947941732406616
- 1.4677526760101318
- 1.4517131924629212
- 1.4342542672157288
- 1.4218673872947694
- 1.4018553066253663
- 1.395418140888214
- 1.3850337696075439
- 1.378838381767273
- 1.3597238373756408
- 1.3495063233375548
- 1.3414097213745118
- 1.3320871829986571
- 1.3246016550064086
- 1.31559583902359
- 1.3212393307685852
- 1.3022306323051454
- 1.3133710598945618
- 1.3058170676231384
- 1.280144417285919
- 1.2762711644172668
- 1.2698806166648864
- 1.268440067768097
- 1.2681521248817444
- 1.2675907611846924
- 1.249778733253479
- 1.2602799367904662
- 1.2412723517417907
- 1.2387291049957276
- 1.2404114747047423
- 1.2336720824241638
- 1.2403106307983398
- 1.2513862442970276
- 1.2413871169090271
- 1.2309853410720826
- 1.2237509512901306
- 1.2269353199005126
- 1.2214083099365234
- 1.2175043964385985
- 1.2162777185440063
- 1.2172890520095825
- 1.2179022336006164
- 1.2298280167579652
- 1.2389564275741578
- 1.2353218770027161
- 1.2211682891845703
- 1.2104539585113525
- 1.2025414443016051
- 1.2017197728157043
- 1.200046787261963
- 1.1999350690841675
- 1.2047373914718629
- 1.2014187955856324
- 1.2012334442138672
- 1.2001465964317322
- 1.217126624584198
- 1.1909123945236206
- 1.2084515047073365
- 1.20251371383667
- 1.1954131484031678
- 1.1966943454742431
- 1.2028379130363465
- 1.1917391347885131
- 1.1947158646583558
- 1.184062852859497
- 1.187876784801483
- 1.1868176937103272
- 1.184997034072876
- 1.1867902994155883
- 1.1853954935073852
- 1.192771565914154
- 1.2011235308647157
- 1.1945710921287536
- 1.194697985649109
- 1.2042687320709229
- 1.1980891704559327
- 1.1867988204956055
- 1.2024463605880737
- 1.193392379283905
- 1.188416748046875
- 1.1938453030586242
- 1.1873394274711608
- 1.1971323680877686
- 1.1833963704109192
- 1.1910026907920837
- 1.1889028429985047
- 1.1960704874992372
- 1.2039279055595398
- 1.2057175517082215
- 1.1990555691719056
- 1.181479184627533
- 1.2069155979156494
- 1.1891360211372375
- 1.1889581131935119
train_accuracy:
- 0.0
- 0.085
- 0.0
- 0.119
- 0.117
- 0.124
- 0.119
- 0.159
- 0.128
- 0.164
- 0.131
- 0.142
- 0.174
- 0.17
- 0.0
- 0.168
- 0.207
- 0.188
- 0.221
- 0.214
- 0.253
- 0.199
- 0.225
- 0.197
- 0.228
- 0.251
- 0.245
- 0.0
- 0.216
- 0.201
- 0.0
- 0.271
- 0.268
- 0.218
- 0.24
- 0.0
- 0.248
- 0.222
- 0.229
- 0.204
- 0.259
- 0.293
- 0.263
- 0.263
- 0.283
- 0.283
- 0.288
- 0.261
- 0.0
- 0.0
- 0.0
- 0.252
- 0.305
- 0.318
- 0.29
- 0.262
- 0.259
- 0.328
- 0.324
- 0.269
- 0.28
- 0.236
- 0.312
- 0.295
- 0.324
- 0.3
- 0.288
- 0.0
- 0.297
- 0.0
- 0.299
- 0.308
- 0.302
- 0.335
- 0.328
- 0.304
- 0.342
- 0.277
- 0.308
- 0.275
- 0.324
- 0.293
- 0.292
- 0.344
- 0.283
- 0.316
- 0.309
- 0.3
- 0.325
- 0.321
- 0.299
- 0.31
- 0.278
- 0.321
- 0.333
- 0.291
- 0.311
- 0.312
- 0.0
- 0.255
train_loss:
- 3.046
- 3.854
- 2.631
- 3.468
- 3.334
- 3.369
- 2.381
- 3.059
- 2.98
- 2.884
- 2.874
- 2.797
- 2.052
- 2.558
- 1.984
- 2.537
- 2.464
- 2.349
- 2.396
- 2.369
- 2.332
- 1.673
- 2.212
- 1.643
- 1.537
- 2.098
- 1.956
- 1.659
- 1.912
- 1.853
- 1.436
- 1.838
- 1.364
- 1.761
- 1.658
- 1.269
- 1.55
- 1.49
- 1.07
- 1.389
- 1.54
- 1.479
- 1.115
- 1.422
- 1.354
- 1.281
- 1.223
- 1.18
- 0.961
- 0.848
- 0.772
- 1.122
- 1.224
- 1.326
- 1.132
- 1.065
- 0.918
- 0.876
- 0.913
- 0.835
- 0.879
- 0.622
- 1.039
- 0.687
- 0.785
- 1.054
- 0.833
- 0.664
- 0.944
- 0.665
- 0.777
- 0.759
- 0.869
- 0.797
- 0.743
- 0.581
- 0.595
- 0.53
- 0.637
- 0.599
- 0.632
- 0.535
- 0.572
- 0.532
- 0.488
- 0.581
- 0.52
- 0.542
- 0.467
- 0.611
- 0.421
- 0.45
- 0.393
- 0.391
- 0.366
- 0.348
- 0.566
- 0.5
- 0.507
- 0.465
unequal: 0
verbose: 1
