avg_train_accuracy: 0.286
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0425
- 0.0865
- 0.1165
- 0.1367
- 0.152
- 0.1586
- 0.1709
- 0.1725
- 0.1869
- 0.1847
- 0.2001
- 0.205
- 0.2108
- 0.2121
- 0.2198
- 0.2177
- 0.2217
- 0.2249
- 0.2221
- 0.239
- 0.2338
- 0.2403
- 0.2458
- 0.2481
- 0.2524
- 0.2562
- 0.2595
- 0.2587
- 0.2569
- 0.2633
- 0.2676
- 0.2625
- 0.2706
- 0.2703
- 0.2683
- 0.2695
- 0.2767
- 0.2771
- 0.2784
- 0.2828
- 0.2793
- 0.2813
- 0.2773
- 0.2862
- 0.2927
- 0.2827
- 0.2974
- 0.2914
- 0.2866
- 0.2929
- 0.2947
- 0.2884
- 0.3019
- 0.2937
- 0.3003
- 0.2927
- 0.2961
- 0.297
- 0.3086
- 0.295
- 0.3043
- 0.3027
- 0.3061
- 0.3065
- 0.3079
- 0.3088
- 0.3107
- 0.3025
- 0.3042
- 0.3046
- 0.3109
- 0.3059
- 0.3058
- 0.3051
- 0.3089
- 0.3177
- 0.3141
- 0.3108
- 0.3173
- 0.3227
- 0.317
- 0.318
- 0.3157
- 0.3187
- 0.3249
- 0.3197
- 0.3183
- 0.3208
- 0.3167
- 0.3238
- 0.3261
- 0.3252
- 0.3272
- 0.3268
- 0.3267
- 0.3243
- 0.3302
- 0.3273
- 0.329
- 0.3243
test_loss_list:
- 1.786393132209778
- 1.653101544380188
- 1.5993892288208007
- 1.5506087255477905
- 1.5133369255065918
- 1.4898623943328857
- 1.4733670783042907
- 1.4547807359695435
- 1.4384192395210267
- 1.4325188088417053
- 1.4027735424041747
- 1.3895457696914673
- 1.3750570106506348
- 1.3692933535575866
- 1.355139880180359
- 1.3600294375419617
- 1.3393673610687256
- 1.332936978340149
- 1.334352195262909
- 1.306974332332611
- 1.321287670135498
- 1.310037341117859
- 1.288739972114563
- 1.2842605805397034
- 1.2684099864959717
- 1.2707623624801636
- 1.2600603485107422
- 1.2627736139297485
- 1.2574878740310669
- 1.2551911234855653
- 1.2466456747055055
- 1.2506572556495668
- 1.236203167438507
- 1.2369903230667114
- 1.244945981502533
- 1.2362211322784424
- 1.2261077308654784
- 1.2227792716026307
- 1.2240517544746399
- 1.221950900554657
- 1.2179276514053345
- 1.2212744879722595
- 1.2310189247131347
- 1.210065405368805
- 1.1962998414039612
- 1.2056229066848756
- 1.1981690859794616
- 1.2057999229431153
- 1.220161657333374
- 1.2044775557518006
- 1.197854115962982
- 1.217984390258789
- 1.1828948879241943
- 1.2032719349861145
- 1.1841208195686341
- 1.1996189403533934
- 1.1903775453567504
- 1.1878126287460327
- 1.185329864025116
- 1.2015603518486022
- 1.1866723036766051
- 1.1825858283042907
- 1.1779084992408753
- 1.185007197856903
- 1.1839173555374145
- 1.1825696778297425
- 1.1739223575592042
- 1.1956103372573852
- 1.1940058803558349
- 1.1877272748947143
- 1.180102846622467
- 1.1895558881759642
- 1.1799763917922974
- 1.189585678577423
- 1.1873394060134888
- 1.1663100385665894
- 1.1769735836982727
- 1.1924458360671997
- 1.1764575266838073
- 1.1689051246643067
- 1.1810705947875977
- 1.1766732621192932
- 1.1776419544219972
- 1.1779171013832093
- 1.169692702293396
- 1.1840244555473327
- 1.1823667001724243
- 1.188857364654541
- 1.1879703688621521
- 1.1858621335029602
- 1.1815648150444031
- 1.1795447707176208
- 1.183459243774414
- 1.1890292358398438
- 1.1871558475494384
- 1.1856747364997864
- 1.1769236969947814
- 1.1842273497581481
- 1.1798491621017455
- 1.190857901573181
train_accuracy:
- 0.041
- 0.089
- 0.0
- 0.11
- 0.163
- 0.125
- 0.15
- 0.161
- 0.172
- 0.177
- 0.149
- 0.188
- 0.208
- 0.156
- 0.206
- 0.0
- 0.165
- 0.205
- 0.0
- 0.213
- 0.0
- 0.0
- 0.218
- 0.0
- 0.212
- 0.223
- 0.243
- 0.241
- 0.214
- 0.246
- 0.215
- 0.0
- 0.268
- 0.235
- 0.0
- 0.24
- 0.268
- 0.259
- 0.279
- 0.24
- 0.278
- 0.315
- 0.231
- 0.231
- 0.317
- 0.3
- 0.294
- 0.23
- 0.228
- 0.279
- 0.295
- 0.234
- 0.274
- 0.0
- 0.301
- 0.287
- 0.279
- 0.288
- 0.248
- 0.0
- 0.283
- 0.246
- 0.304
- 0.293
- 0.277
- 0.0
- 0.246
- 0.0
- 0.0
- 0.269
- 0.263
- 0.0
- 0.291
- 0.264
- 0.265
- 0.277
- 0.272
- 0.269
- 0.257
- 0.295
- 0.247
- 0.313
- 0.267
- 0.289
- 0.32
- 0.284
- 0.287
- 0.276
- 0.266
- 0.298
- 0.312
- 0.27
- 0.299
- 0.265
- 0.256
- 0.272
- 0.332
- 0.342
- 0.306
- 0.286
train_loss:
- 4.307
- 3.879
- 2.627
- 3.409
- 3.393
- 3.211
- 3.011
- 2.245
- 2.856
- 2.036
- 2.991
- 2.728
- 2.681
- 2.58
- 2.628
- 1.732
- 2.636
- 2.38
- 1.783
- 2.444
- 1.693
- 1.686
- 2.152
- 1.673
- 2.111
- 1.978
- 2.074
- 1.9
- 1.893
- 1.488
- 1.785
- 1.383
- 1.726
- 1.58
- 1.371
- 1.589
- 1.347
- 1.487
- 1.435
- 1.451
- 1.499
- 1.469
- 1.05
- 1.439
- 1.397
- 1.289
- 1.36
- 1.261
- 1.034
- 1.136
- 1.125
- 0.943
- 1.184
- 0.915
- 1.102
- 0.78
- 0.982
- 0.889
- 1.014
- 0.733
- 0.932
- 0.867
- 0.926
- 0.843
- 0.9
- 0.773
- 0.859
- 0.651
- 0.631
- 0.608
- 0.717
- 0.711
- 0.625
- 0.503
- 0.563
- 0.853
- 0.561
- 0.456
- 0.638
- 0.621
- 0.687
- 0.605
- 0.519
- 0.576
- 0.586
- 0.491
- 0.434
- 0.455
- 0.511
- 0.421
- 0.498
- 0.433
- 0.528
- 0.447
- 0.415
- 0.425
- 0.51
- 0.48
- 0.393
- 0.415
unequal: 0
verbose: 1
