avg_train_accuracy: 0.322
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0444
- 0.0971
- 0.1148
- 0.1303
- 0.1452
- 0.1653
- 0.1645
- 0.1788
- 0.1774
- 0.1878
- 0.195
- 0.1992
- 0.2038
- 0.2012
- 0.2126
- 0.2204
- 0.2227
- 0.2258
- 0.2201
- 0.2216
- 0.2364
- 0.242
- 0.243
- 0.2446
- 0.2434
- 0.2463
- 0.2501
- 0.2572
- 0.2628
- 0.2534
- 0.2532
- 0.2659
- 0.2713
- 0.2692
- 0.2702
- 0.2724
- 0.277
- 0.2756
- 0.2868
- 0.2832
- 0.2882
- 0.2898
- 0.2935
- 0.2941
- 0.2931
- 0.2901
- 0.2956
- 0.2943
- 0.3024
- 0.2923
- 0.2915
- 0.2953
- 0.3028
- 0.2978
- 0.3003
- 0.2993
- 0.2923
- 0.3013
- 0.3066
- 0.2998
- 0.3141
- 0.3098
- 0.3139
- 0.3086
- 0.3163
- 0.3103
- 0.3109
- 0.3122
- 0.3092
- 0.3082
- 0.3146
- 0.3167
- 0.3178
- 0.3162
- 0.3173
- 0.3138
- 0.3117
- 0.3138
- 0.3225
- 0.327
- 0.3109
- 0.3169
- 0.3177
- 0.3236
- 0.322
- 0.3214
- 0.3232
- 0.3219
- 0.3213
- 0.3219
- 0.3119
- 0.3249
- 0.3179
- 0.3235
- 0.3267
- 0.3273
- 0.3246
- 0.3222
- 0.3166
- 0.3292
test_loss_list:
- 1.7878343152999878
- 1.6569962739944457
- 1.603496024608612
- 1.565560646057129
- 1.5228954672813415
- 1.4910545921325684
- 1.478975896835327
- 1.452789738178253
- 1.4461105728149415
- 1.4285717487335206
- 1.4070615196228027
- 1.4013848662376405
- 1.3896064829826356
- 1.3920083165168762
- 1.3694159817695617
- 1.3568788576126098
- 1.3457021379470826
- 1.3397394347190856
- 1.3402899098396301
- 1.3381140518188477
- 1.3119438481330872
- 1.303219323158264
- 1.2997247362136841
- 1.2950214076042175
- 1.2910868430137634
- 1.2879314517974854
- 1.2795746421813965
- 1.2600255584716797
- 1.257321331501007
- 1.2728947257995606
- 1.2704926919937134
- 1.242265293598175
- 1.2360268020629883
- 1.237485065460205
- 1.2366471099853515
- 1.2341299295425414
- 1.2264119863510132
- 1.2333584070205688
- 1.208291666507721
- 1.2110065865516662
- 1.2107005286216737
- 1.2082166266441345
- 1.200437569618225
- 1.20346581697464
- 1.198284993171692
- 1.209481008052826
- 1.1967523050308229
- 1.2048788809776305
- 1.1944115924835206
- 1.2129464554786682
- 1.210732786655426
- 1.1930196475982666
- 1.1865595889091491
- 1.193880443572998
- 1.1868261742591857
- 1.1869546580314636
- 1.2087881875038147
- 1.1942964959144593
- 1.1798605847358703
- 1.1887466669082642
- 1.1693643140792847
- 1.1778528714179992
- 1.170657970905304
- 1.178674259185791
- 1.1699016213417053
- 1.1738712978363037
- 1.1772068905830384
- 1.1778060507774353
- 1.1832007908821105
- 1.1803884029388427
- 1.1694852900505066
- 1.1716539096832275
- 1.1714341640472412
- 1.179650719165802
- 1.1740222477912903
- 1.1742395853996277
- 1.1809469008445739
- 1.179254684448242
- 1.169785499572754
- 1.1676223826408387
- 1.1901309061050416
- 1.1907117438316346
- 1.172925398349762
- 1.16375789642334
- 1.164238030910492
- 1.1657746601104737
- 1.1687387323379517
- 1.17477073431015
- 1.1768783354759216
- 1.1967359828948974
- 1.1939422702789306
- 1.1740725564956664
- 1.181811079978943
- 1.1693236589431764
- 1.1690108633041383
- 1.1692587065696716
- 1.1645314812660217
- 1.1749672126770019
- 1.1919229936599731
- 1.1765586090087892
train_accuracy:
- 0.049
- 0.129
- 0.105
- 0.127
- 0.139
- 0.134
- 0.163
- 0.158
- 0.186
- 0.176
- 0.154
- 0.174
- 0.224
- 0.218
- 0.21
- 0.233
- 0.204
- 0.21
- 0.187
- 0.196
- 0.0
- 0.264
- 0.256
- 0.245
- 0.0
- 0.205
- 0.265
- 0.241
- 0.251
- 0.0
- 0.228
- 0.276
- 0.278
- 0.216
- 0.239
- 0.23
- 0.238
- 0.245
- 0.257
- 0.269
- 0.279
- 0.277
- 0.31
- 0.296
- 0.295
- 0.282
- 0.32
- 0.284
- 0.311
- 0.258
- 0.297
- 0.288
- 0.269
- 0.287
- 0.273
- 0.324
- 0.271
- 0.255
- 0.269
- 0.271
- 0.283
- 0.287
- 0.266
- 0.282
- 0.318
- 0.275
- 0.295
- 0.0
- 0.0
- 0.308
- 0.317
- 0.324
- 0.281
- 0.331
- 0.294
- 0.317
- 0.0
- 0.309
- 0.35
- 0.32
- 0.353
- 0.0
- 0.281
- 0.348
- 0.335
- 0.302
- 0.309
- 0.301
- 0.283
- 0.335
- 0.358
- 0.352
- 0.282
- 0.344
- 0.344
- 0.281
- 0.32
- 0.345
- 0.312
- 0.322
train_loss:
- 4.318
- 3.905
- 3.674
- 3.451
- 3.42
- 3.394
- 3.112
- 3.074
- 3.024
- 2.934
- 2.926
- 2.758
- 2.723
- 1.922
- 2.558
- 2.54
- 2.562
- 2.436
- 1.792
- 1.821
- 1.794
- 2.253
- 2.079
- 2.102
- 1.599
- 1.549
- 1.628
- 1.985
- 1.981
- 1.372
- 1.286
- 2.037
- 1.936
- 1.65
- 1.707
- 1.689
- 1.585
- 1.273
- 1.648
- 1.467
- 1.546
- 1.494
- 1.441
- 1.394
- 1.265
- 1.205
- 1.309
- 1.152
- 1.415
- 0.977
- 1.018
- 1.12
- 1.288
- 0.822
- 1.12
- 1.045
- 0.89
- 1.161
- 0.96
- 0.761
- 1.153
- 0.901
- 0.998
- 0.843
- 0.882
- 0.76
- 0.878
- 0.764
- 0.703
- 0.827
- 0.678
- 0.759
- 0.706
- 0.713
- 0.661
- 0.707
- 0.63
- 0.656
- 0.648
- 0.635
- 0.603
- 0.553
- 0.607
- 0.604
- 0.542
- 0.577
- 0.54
- 0.53
- 0.525
- 0.419
- 0.419
- 0.501
- 0.417
- 0.507
- 0.481
- 0.514
- 0.484
- 0.39
- 0.346
- 0.424
unequal: 0
verbose: 1
