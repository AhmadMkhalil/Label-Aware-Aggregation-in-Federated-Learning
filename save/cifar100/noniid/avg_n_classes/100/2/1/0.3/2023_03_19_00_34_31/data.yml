avg_train_accuracy: 0.199
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0485
- 0.0867
- 0.1195
- 0.1331
- 0.1405
- 0.153
- 0.1643
- 0.1727
- 0.1763
- 0.1859
- 0.1917
- 0.2017
- 0.1902
- 0.2089
- 0.2105
- 0.2171
- 0.2205
- 0.2203
- 0.2183
- 0.2248
- 0.2297
- 0.2375
- 0.2368
- 0.2313
- 0.243
- 0.2401
- 0.2427
- 0.2472
- 0.2554
- 0.2551
- 0.2558
- 0.258
- 0.2599
- 0.2555
- 0.2599
- 0.26
- 0.2603
- 0.2642
- 0.2676
- 0.2667
- 0.2649
- 0.2729
- 0.2729
- 0.2721
- 0.2786
- 0.2783
- 0.2779
- 0.2735
- 0.2767
- 0.2779
- 0.2819
- 0.2881
- 0.2853
- 0.286
- 0.286
- 0.2872
- 0.2842
- 0.2876
- 0.2777
- 0.2879
- 0.2906
- 0.2909
- 0.2977
- 0.2956
- 0.2905
- 0.3018
- 0.2969
- 0.2959
- 0.2921
- 0.2922
- 0.2938
- 0.2991
- 0.3044
- 0.3067
- 0.3052
- 0.3086
- 0.3044
- 0.2944
- 0.3078
- 0.3017
- 0.2962
- 0.2935
- 0.3012
- 0.3048
- 0.3092
- 0.3039
- 0.309
- 0.31
- 0.314
- 0.3115
- 0.3121
- 0.3192
- 0.3149
- 0.3056
- 0.3006
- 0.3114
- 0.3156
- 0.3174
- 0.3076
- 0.3072
test_loss_list:
- 1.781400113105774
- 1.652751567363739
- 1.5968377137184142
- 1.5598811292648316
- 1.5238845920562745
- 1.5122908186912536
- 1.4845044374465943
- 1.4696256113052368
- 1.4532410788536072
- 1.4386805129051208
- 1.4211524987220765
- 1.4056271648406982
- 1.414440360069275
- 1.3818771433830261
- 1.380022065639496
- 1.3708477711677551
- 1.3621298050880433
- 1.3589178490638734
- 1.347101435661316
- 1.3366885137557984
- 1.332054886817932
- 1.3209247875213623
- 1.3237103033065796
- 1.3268339538574219
- 1.3124990963935852
- 1.3098611259460449
- 1.3145310282707214
- 1.3022593188285827
- 1.291535999774933
- 1.286786572933197
- 1.288178458213806
- 1.271181707382202
- 1.2740721750259398
- 1.2874604749679566
- 1.2637666964530945
- 1.2733375310897828
- 1.2757322072982789
- 1.2650773096084595
- 1.2622221827507019
- 1.2638365626335144
- 1.2719167423248292
- 1.2502589154243469
- 1.2528934454917908
- 1.2476498365402222
- 1.2425280737876891
- 1.23918386220932
- 1.24627192735672
- 1.2528268814086914
- 1.2453802347183227
- 1.2365287137031555
- 1.2332233214378356
- 1.225175142288208
- 1.226180787086487
- 1.2374317336082459
- 1.2291583347320556
- 1.2232532262802125
- 1.2360613870620727
- 1.2283763408660888
- 1.2521293950080872
- 1.2289426350593566
- 1.2194797945022584
- 1.2227155327796937
- 1.204337055683136
- 1.2048030161857606
- 1.2285312747955321
- 1.2009243583679199
- 1.2099818682670593
- 1.214272837638855
- 1.2192421579360961
- 1.2232580709457397
- 1.2182405996322632
- 1.197193958759308
- 1.1938535118103026
- 1.1920953059196473
- 1.2054375052452087
- 1.1921356797218323
- 1.2005272674560548
- 1.2132689332962037
- 1.1990352725982667
- 1.2080843687057494
- 1.2236148262023925
- 1.2322431445121764
- 1.2154880356788635
- 1.200327398777008
- 1.1985404729843139
- 1.2132186722755431
- 1.2030662560462952
- 1.2041591858863832
- 1.1938176250457764
- 1.20073721408844
- 1.2009359908103943
- 1.1987806344032288
- 1.2064473485946656
- 1.2169282746315002
- 1.2222262239456176
- 1.209916250705719
- 1.2048257732391356
- 1.2013183283805846
- 1.2156913423538207
- 1.2208789157867432
train_accuracy:
- 0.047
- 0.096
- 0.101
- 0.15
- 0.13
- 0.157
- 0.17
- 0.124
- 0.187
- 0.145
- 0.18
- 0.184
- 0.0
- 0.192
- 0.189
- 0.2
- 0.151
- 0.216
- 0.178
- 0.216
- 0.245
- 0.242
- 0.232
- 0.0
- 0.223
- 0.238
- 0.249
- 0.0
- 0.261
- 0.239
- 0.262
- 0.203
- 0.274
- 0.245
- 0.17
- 0.181
- 0.202
- 0.261
- 0.27
- 0.274
- 0.0
- 0.245
- 0.27
- 0.235
- 0.258
- 0.267
- 0.272
- 0.233
- 0.264
- 0.257
- 0.236
- 0.305
- 0.269
- 0.286
- 0.251
- 0.229
- 0.238
- 0.281
- 0.279
- 0.0
- 0.331
- 0.0
- 0.272
- 0.319
- 0.297
- 0.251
- 0.325
- 0.251
- 0.185
- 0.202
- 0.0
- 0.282
- 0.303
- 0.212
- 0.184
- 0.286
- 0.303
- 0.0
- 0.251
- 0.247
- 0.0
- 0.242
- 0.337
- 0.206
- 0.325
- 0.206
- 0.269
- 0.265
- 0.287
- 0.344
- 0.191
- 0.356
- 0.309
- 0.324
- 0.0
- 0.287
- 0.359
- 0.317
- 0.0
- 0.199
train_loss:
- 4.343
- 3.819
- 3.717
- 3.468
- 3.426
- 2.32
- 3.085
- 2.973
- 2.989
- 2.835
- 2.856
- 2.851
- 1.87
- 2.788
- 2.475
- 2.27
- 2.615
- 1.915
- 1.769
- 2.234
- 2.288
- 2.341
- 2.036
- 1.456
- 2.058
- 1.915
- 1.744
- 1.659
- 2.051
- 1.766
- 1.817
- 1.911
- 1.683
- 1.204
- 1.795
- 1.432
- 1.315
- 1.508
- 1.472
- 1.389
- 1.086
- 1.462
- 1.562
- 1.173
- 1.428
- 1.308
- 1.228
- 1.064
- 0.924
- 1.108
- 1.232
- 1.176
- 1.121
- 0.848
- 0.951
- 1.12
- 0.836
- 0.949
- 0.771
- 0.776
- 0.749
- 0.992
- 1.06
- 0.84
- 0.631
- 1.048
- 0.876
- 0.932
- 0.651
- 0.577
- 0.723
- 0.695
- 0.824
- 0.815
- 0.635
- 0.77
- 0.59
- 0.535
- 0.604
- 0.509
- 0.476
- 0.426
- 0.487
- 0.616
- 0.514
- 0.511
- 0.594
- 0.435
- 0.607
- 0.385
- 0.419
- 0.56
- 0.385
- 0.405
- 0.405
- 0.355
- 0.489
- 0.493
- 0.375
- 0.415
unequal: 0
verbose: 1
