avg_train_accuracy: 0.927
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0444
- 0.078
- 0.0904
- 0.1064
- 0.1291
- 0.1244
- 0.1321
- 0.1404
- 0.1596
- 0.1631
- 0.0169
- 0.1609
- 0.1599
- 0.1703
- 0.1668
- 0.1682
- 0.1857
- 0.0191
- 0.186
- 0.1963
- 0.1965
- 0.206
- 0.2018
- 0.1979
- 0.2111
- 0.0185
- 0.2176
- 0.2251
- 0.0191
- 0.2213
- 0.2244
- 0.2262
- 0.2304
- 0.2395
- 0.2277
- 0.2424
- 0.2438
- 0.2458
- 0.2511
- 0.2528
- 0.2462
- 0.2476
- 0.2513
- 0.2453
- 0.2652
- 0.2584
- 0.2501
- 0.2627
- 0.2679
- 0.2683
- 0.2655
- 0.2762
- 0.2584
- 0.2627
- 0.2551
- 0.2586
- 0.2571
- 0.2565
- 0.2705
- 0.2607
- 0.2793
- 0.2661
- 0.2754
- 0.2696
- 0.2775
- 0.2867
- 0.2852
- 0.2877
- 0.2824
- 0.2801
- 0.2865
- 0.2846
- 0.0194
- 0.291
- 0.2925
- 0.2849
- 0.288
- 0.2845
- 0.2775
- 0.2763
- 0.2894
- 0.2949
- 0.2927
- 0.2683
- 0.2909
- 0.2928
- 0.3034
- 0.304
- 0.2989
- 0.302
- 0.2988
- 0.2959
- 0.2969
- 0.2944
- 0.2993
- 0.2985
- 0.295
- 0.3036
- 0.3034
- 0.0195
test_loss_list:
- 1.8007218217849732
- 1.6884432458877563
- 1.6599691963195802
- 1.6064777135849
- 1.5677675795555115
- 1.5619603848457337
- 1.5522160124778748
- 1.510148320198059
- 1.4895229172706603
- 1.4755394506454467
- 4.608152694702149
- 1.469514548778534
- 1.4817979907989502
- 1.454512677192688
- 1.4664412808418275
- 1.4521050238609314
- 1.4158649134635926
- 4.495926742553711
- 1.4020264339447022
- 1.3801450300216676
- 1.3765682435035707
- 1.3746720623970032
- 1.3699049162864685
- 1.390324182510376
- 1.357878363132477
- 4.483432703018188
- 1.34035489320755
- 1.3241166281700134
- 4.298707761764526
- 1.341234769821167
- 1.3257916355133057
- 1.325861496925354
- 1.31529394865036
- 1.2978405332565308
- 1.316493606567383
- 1.301318233013153
- 1.2999497246742249
- 1.2890234446525575
- 1.2734223794937134
- 1.2795958924293518
- 1.2905832052230835
- 1.285633795261383
- 1.2938967442512512
- 1.302961130142212
- 1.2575335955619813
- 1.2682899570465087
- 1.2834666514396667
- 1.2698368787765504
- 1.246881206035614
- 1.2468994021415711
- 1.2581110501289368
- 1.249006335735321
- 1.2706164860725402
- 1.2640356230735779
- 1.2822243213653564
- 1.2889477014541626
- 1.2766376233100891
- 1.290259976387024
- 1.2598810911178588
- 1.2824620842933654
- 1.2568076252937317
- 1.2906621408462524
- 1.261975655555725
- 1.2658603811264038
- 1.2639507937431336
- 1.2502353143692018
- 1.2237763738632201
- 1.2469819331169127
- 1.2570882725715637
- 1.2674342727661132
- 1.24392395734787
- 1.2463127660751343
- 4.309196825027466
- 1.2106695508956908
- 1.2151595091819762
- 1.2336337518692018
- 1.2279468703269958
- 1.2350671577453614
- 1.2405710244178771
- 1.2525440406799317
- 1.2318871426582336
- 1.2101531052589416
- 1.229703085422516
- 1.2979090571403504
- 1.2313760900497437
- 1.222520661354065
- 1.2087215828895568
- 1.2260188579559326
- 1.2161175227165222
- 1.2148801851272584
- 1.2199301028251648
- 1.2332846474647523
- 1.2417862963676454
- 1.2477080702781678
- 1.238363697528839
- 1.2357895731925965
- 1.2453711557388305
- 1.2412748456001281
- 1.2220871567726135
- 4.345062141418457
train_accuracy:
- 0.047
- 0.062
- 0.062
- 0.103
- 0.139
- 0.119
- 0.145
- 0.111
- 0.153
- 0.181
- 0.706
- 0.159
- 0.135
- 0.13
- 0.161
- 0.126
- 0.177
- 0.923
- 0.136
- 0.204
- 0.169
- 0.203
- 0.187
- 0.152
- 0.194
- 0.88
- 0.216
- 0.217
- 0.88
- 0.225
- 0.219
- 0.219
- 0.181
- 0.195
- 0.192
- 0.239
- 0.19
- 0.177
- 0.261
- 0.197
- 0.206
- 0.206
- 0.212
- 0.205
- 0.272
- 0.188
- 0.198
- 0.265
- 0.266
- 0.26
- 0.276
- 0.21
- 0.228
- 0.197
- 0.202
- 0.265
- 0.229
- 0.223
- 0.212
- 0.291
- 0.244
- 0.225
- 0.265
- 0.247
- 0.23
- 0.271
- 0.326
- 0.295
- 0.26
- 0.298
- 0.227
- 0.293
- 0.92
- 0.275
- 0.298
- 0.285
- 0.216
- 0.269
- 0.219
- 0.225
- 0.23
- 0.305
- 0.279
- 0.259
- 0.263
- 0.23
- 0.254
- 0.272
- 0.262
- 0.276
- 0.254
- 0.264
- 0.331
- 0.279
- 0.296
- 0.264
- 0.308
- 0.318
- 0.336
- 0.927
train_loss:
- 4.338
- 3.983
- 3.445
- 3.682
- 3.543
- 3.145
- 3.38
- 3.275
- 3.092
- 3.254
- 0.631
- 3.144
- 2.381
- 2.883
- 2.185
- 2.998
- 2.794
- 0.495
- 2.789
- 2.904
- 2.749
- 2.116
- 2.353
- 1.945
- 2.532
- 0.43
- 3.004
- 2.538
- 0.374
- 2.497
- 1.963
- 2.705
- 2.457
- 2.193
- 1.945
- 2.014
- 1.824
- 2.152
- 2.114
- 1.604
- 2.061
- 1.699
- 1.351
- 1.673
- 1.846
- 1.821
- 1.456
- 2.199
- 1.525
- 1.768
- 1.686
- 1.548
- 1.239
- 1.196
- 0.815
- 1.397
- 1.597
- 1.077
- 0.951
- 1.17
- 1.348
- 0.869
- 1.504
- 2.063
- 0.868
- 1.173
- 1.384
- 0.913
- 0.606
- 1.075
- 0.923
- 0.679
- 0.446
- 1.897
- 0.581
- 0.862
- 0.746
- 1.174
- 1.142
- 0.699
- 0.622
- 1.14
- 1.353
- 1.734
- 1.087
- 0.829
- 0.59
- 0.976
- 0.438
- 1.063
- 0.36
- 0.659
- 0.787
- 0.76
- 0.532
- 0.504
- 0.723
- 0.453
- 0.974
- 0.398
unequal: 0
verbose: 1
