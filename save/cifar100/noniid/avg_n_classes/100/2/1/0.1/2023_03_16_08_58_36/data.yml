avg_train_accuracy: 0.925
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0412
- 0.0767
- 0.101
- 0.1087
- 0.1217
- 0.1384
- 0.1348
- 0.1408
- 0.1561
- 0.1556
- 0.1683
- 0.1758
- 0.1835
- 0.1849
- 0.2021
- 0.1968
- 0.2011
- 0.2018
- 0.2055
- 0.208
- 0.1953
- 0.2144
- 0.2092
- 0.0177
- 0.2265
- 0.2175
- 0.2364
- 0.2293
- 0.2297
- 0.2373
- 0.2349
- 0.241
- 0.2427
- 0.2471
- 0.2491
- 0.2391
- 0.2474
- 0.2481
- 0.2459
- 0.0185
- 0.0187
- 0.2588
- 0.2546
- 0.2681
- 0.2693
- 0.2652
- 0.2683
- 0.2732
- 0.2663
- 0.2761
- 0.0191
- 0.2723
- 0.2778
- 0.2832
- 0.0191
- 0.2743
- 0.2797
- 0.2811
- 0.019
- 0.2762
- 0.2852
- 0.0196
- 0.285
- 0.0202
- 0.2932
- 0.2828
- 0.2943
- 0.2911
- 0.2877
- 0.2878
- 0.2966
- 0.2862
- 0.2955
- 0.2836
- 0.301
- 0.3034
- 0.3001
- 0.298
- 0.0195
- 0.3053
- 0.3051
- 0.3036
- 0.2994
- 0.2969
- 0.3054
- 0.3125
- 0.3111
- 0.3071
- 0.021
- 0.2918
- 0.3012
- 0.313
- 0.3063
- 0.3064
- 0.3048
- 0.3073
- 0.3042
- 0.311
- 0.313
- 0.0214
test_loss_list:
- 1.804287576675415
- 1.6959215211868286
- 1.6461157655715943
- 1.6212099862098694
- 1.5819212889671326
- 1.5469511222839356
- 1.5424455046653747
- 1.549043107032776
- 1.5087859201431275
- 1.4900678706169128
- 1.4608504891395568
- 1.4536977529525756
- 1.4425709414482117
- 1.4371478295326232
- 1.409970202445984
- 1.4158905386924743
- 1.4000271511077882
- 1.3988621211051941
- 1.4007771944999694
- 1.3938120770454407
- 1.3996112656593322
- 1.3793534326553345
- 1.382059359550476
- 4.882512998580933
- 1.3478505992889405
- 1.361482093334198
- 1.3339603686332702
- 1.3368955039978028
- 1.3304317688941956
- 1.3201269030570983
- 1.3157169198989869
- 1.3142044639587402
- 1.317535457611084
- 1.3009602808952332
- 1.2921889686584473
- 1.3209903192520143
- 1.3015974235534669
- 1.3054950642585754
- 1.2940174555778503
- 4.503467330932617
- 4.705724372863769
- 1.2623012685775756
- 1.2648064875602723
- 1.2414197278022767
- 1.2426868605613708
- 1.258072986602783
- 1.248029544353485
- 1.2375022983551025
- 1.2492788529396057
- 1.2272254776954652
- 4.429439840316772
- 1.2429889369010925
- 1.2225743293762208
- 1.217576789855957
- 4.222236499786377
- 1.2188086462020875
- 1.2278396725654601
- 1.2223165559768676
- 3.9970555019378664
- 1.2103978514671325
- 1.2093185448646546
- 4.112248287200928
- 1.2005749773979186
- 3.673918447494507
- 1.1822124123573303
- 1.2199546527862548
- 1.1930369710922242
- 1.2001723861694336
- 1.204916579723358
- 1.2082530093193053
- 1.2027579140663147
- 1.2132733750343323
- 1.2033586716651916
- 1.2403409957885743
- 1.1896739506721496
- 1.1899144196510314
- 1.202697582244873
- 1.202420949935913
- 3.8745506858825682
- 1.1915892219543458
- 1.18382271528244
- 1.1876168537139893
- 1.2104360628128052
- 1.2184734296798707
- 1.1912861490249633
- 1.1764021730422973
- 1.1981176543235779
- 1.1878233122825623
- 3.724780311584473
- 1.2083052396774292
- 1.189190878868103
- 1.1605907630920411
- 1.179101929664612
- 1.1826603960990907
- 1.1830194807052612
- 1.1895004868507386
- 1.1885845160484314
- 1.1752267217636108
- 1.1697180724143983
- 3.67462290763855
train_accuracy:
- 0.034
- 0.07
- 0.082
- 0.094
- 0.109
- 0.086
- 0.104
- 0.107
- 0.128
- 0.138
- 0.161
- 0.124
- 0.153
- 0.201
- 0.162
- 0.149
- 0.198
- 0.137
- 0.194
- 0.136
- 0.195
- 0.218
- 0.19
- 0.989
- 0.137
- 0.236
- 0.218
- 0.195
- 0.208
- 0.221
- 0.224
- 0.206
- 0.249
- 0.184
- 0.268
- 0.264
- 0.197
- 0.259
- 0.246
- 0.862
- 0.991
- 0.26
- 0.251
- 0.268
- 0.255
- 0.235
- 0.219
- 0.291
- 0.264
- 0.222
- 0.901
- 0.236
- 0.29
- 0.221
- 0.954
- 0.229
- 0.225
- 0.237
- 0.9
- 0.225
- 0.305
- 0.959
- 0.232
- 0.954
- 0.269
- 0.212
- 0.317
- 0.221
- 0.247
- 0.221
- 0.294
- 0.247
- 0.239
- 0.28
- 0.272
- 0.233
- 0.319
- 0.283
- 0.847
- 0.303
- 0.243
- 0.32
- 0.295
- 0.284
- 0.265
- 0.275
- 0.324
- 0.316
- 0.908
- 0.305
- 0.258
- 0.254
- 0.308
- 0.272
- 0.251
- 0.262
- 0.293
- 0.264
- 0.322
- 0.925
train_loss:
- 4.345
- 4.007
- 3.724
- 3.225
- 3.569
- 3.325
- 3.096
- 2.699
- 3.204
- 3.233
- 3.205
- 2.899
- 2.755
- 3.0
- 3.051
- 2.554
- 2.756
- 2.541
- 2.356
- 2.193
- 2.693
- 2.542
- 2.202
- 0.652
- 2.31
- 2.155
- 2.535
- 1.93
- 2.596
- 2.173
- 2.394
- 1.711
- 1.957
- 2.282
- 1.999
- 1.473
- 1.927
- 1.314
- 2.26
- 0.507
- 0.081
- 2.392
- 2.191
- 1.848
- 1.931
- 1.394
- 1.817
- 1.794
- 1.583
- 1.358
- 0.405
- 1.242
- 1.781
- 1.662
- 0.336
- 1.423
- 1.007
- 1.581
- 0.288
- 1.785
- 1.379
- 0.285
- 1.958
- 0.227
- 1.123
- 1.317
- 1.479
- 1.065
- 1.335
- 1.261
- 1.152
- 0.991
- 0.997
- 1.5
- 0.913
- 0.795
- 1.138
- 1.535
- 0.305
- 1.298
- 1.085
- 0.91
- 0.833
- 1.185
- 1.376
- 0.807
- 0.698
- 0.787
- 0.307
- 1.372
- 1.057
- 0.862
- 0.832
- 0.971
- 0.624
- 0.652
- 1.051
- 0.949
- 0.803
- 0.246
unequal: 0
verbose: 1
