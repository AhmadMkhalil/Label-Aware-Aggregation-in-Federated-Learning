avg_train_accuracy: 0.275
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0399
- 0.0756
- 0.1029
- 0.107
- 0.1154
- 0.1233
- 0.138
- 0.1333
- 0.1569
- 0.1637
- 0.1625
- 0.1701
- 0.1763
- 0.179
- 0.1799
- 0.1848
- 0.1881
- 0.1978
- 0.0186
- 0.1999
- 0.0193
- 0.2005
- 0.2068
- 0.2095
- 0.2122
- 0.2118
- 0.2194
- 0.2257
- 0.2219
- 0.2251
- 0.2227
- 0.2271
- 0.2249
- 0.2239
- 0.2329
- 0.2416
- 0.2356
- 0.2366
- 0.2315
- 0.0188
- 0.2373
- 0.2398
- 0.2425
- 0.2471
- 0.2397
- 0.2435
- 0.257
- 0.2578
- 0.2547
- 0.2647
- 0.2566
- 0.2679
- 0.2628
- 0.2689
- 0.267
- 0.2646
- 0.2682
- 0.2633
- 0.2709
- 0.2763
- 0.276
- 0.27
- 0.2574
- 0.2749
- 0.2893
- 0.269
- 0.2818
- 0.019
- 0.2828
- 0.2809
- 0.2687
- 0.2755
- 0.2874
- 0.2733
- 0.2842
- 0.2775
- 0.2881
- 0.0197
- 0.2873
- 0.2884
- 0.2827
- 0.2808
- 0.2894
- 0.2838
- 0.2807
- 0.285
- 0.2751
- 0.2896
- 0.2954
- 0.282
- 0.2886
- 0.2929
- 0.2997
- 0.2926
- 0.29
- 0.2882
- 0.2948
- 0.2952
- 0.0198
- 0.2902
test_loss_list:
- 1.8091321611404418
- 1.6892622232437133
- 1.6327034401893616
- 1.6076310563087464
- 1.5821451568603515
- 1.5711389565467835
- 1.54794273853302
- 1.5307899236679077
- 1.5001455402374269
- 1.4839229846000672
- 1.4783466601371764
- 1.4750202512741089
- 1.4657617044448852
- 1.4539886331558227
- 1.458928062915802
- 1.4413429665565491
- 1.4248631739616393
- 1.417325909137726
- 4.46722993850708
- 1.3923491978645324
- 4.340287036895752
- 1.3842907214164735
- 1.3807559061050414
- 1.3603347635269165
- 1.3632650661468506
- 1.3593612957000731
- 1.3487038016319275
- 1.3484656977653504
- 1.3687168264389038
- 1.3471370983123778
- 1.3601636219024658
- 1.3435484266281128
- 1.341750373840332
- 1.3557912087440491
- 1.3298398160934448
- 1.323583960533142
- 1.3187387943267823
- 1.3184639167785646
- 1.3417075896263122
- 4.360959987640381
- 1.3091016626358032
- 1.3047143721580505
- 1.3018919038772583
- 1.2979643106460572
- 1.32316397190094
- 1.2930828499794007
- 1.2786697745323181
- 1.2743441438674927
- 1.2901204872131347
- 1.2669057035446167
- 1.2903588724136352
- 1.266998143196106
- 1.2897898316383363
- 1.2644838905334472
- 1.2829923033714294
- 1.2832106852531433
- 1.2654344654083252
- 1.2679459285736083
- 1.2705890941619873
- 1.2607093405723573
- 1.2716550493240357
- 1.289873788356781
- 1.292744369506836
- 1.2612820410728454
- 1.2551891469955445
- 1.2794508719444275
- 1.2481162357330322
- 4.27539623260498
- 1.2481397986412048
- 1.2586383390426636
- 1.2756721377372742
- 1.2470342111587525
- 1.237445662021637
- 1.2567326831817627
- 1.2369711446762084
- 1.2705832195281983
- 1.2307147645950318
- 4.27447548866272
- 1.2260687589645385
- 1.233642807006836
- 1.2538064646720886
- 1.2545226764678956
- 1.2407579731941223
- 1.245302858352661
- 1.2558894038200379
- 1.2421303987503052
- 1.2688099265098571
- 1.240478856563568
- 1.2453235387802124
- 1.2766711115837097
- 1.2600578689575195
- 1.240230576992035
- 1.2296841263771057
- 1.2476410484313964
- 1.2700339150428772
- 1.2868955636024475
- 1.2515648126602172
- 1.2616706562042237
- 4.245711193084717
- 1.2429334425926208
train_accuracy:
- 0.064
- 0.051
- 0.078
- 0.09
- 0.09
- 0.091
- 0.154
- 0.11
- 0.108
- 0.106
- 0.09
- 0.14
- 0.13
- 0.175
- 0.125
- 0.117
- 0.188
- 0.191
- 0.899
- 0.217
- 0.932
- 0.191
- 0.206
- 0.211
- 0.134
- 0.235
- 0.176
- 0.179
- 0.165
- 0.164
- 0.177
- 0.211
- 0.206
- 0.18
- 0.156
- 0.244
- 0.278
- 0.209
- 0.206
- 0.863
- 0.204
- 0.265
- 0.186
- 0.245
- 0.24
- 0.212
- 0.275
- 0.216
- 0.174
- 0.196
- 0.283
- 0.283
- 0.266
- 0.263
- 0.191
- 0.29
- 0.225
- 0.287
- 0.21
- 0.279
- 0.287
- 0.281
- 0.249
- 0.299
- 0.298
- 0.272
- 0.234
- 0.877
- 0.285
- 0.227
- 0.217
- 0.249
- 0.314
- 0.266
- 0.255
- 0.227
- 0.309
- 0.95
- 0.252
- 0.307
- 0.31
- 0.259
- 0.322
- 0.319
- 0.241
- 0.276
- 0.23
- 0.29
- 0.328
- 0.283
- 0.218
- 0.261
- 0.321
- 0.217
- 0.231
- 0.235
- 0.324
- 0.23
- 0.909
- 0.275
train_loss:
- 4.355
- 3.936
- 3.796
- 3.574
- 3.307
- 2.849
- 3.468
- 3.311
- 3.13
- 3.181
- 2.739
- 2.641
- 2.789
- 3.043
- 2.445
- 2.457
- 2.943
- 2.604
- 0.615
- 3.113
- 0.454
- 3.041
- 2.302
- 2.529
- 2.209
- 2.454
- 2.28
- 2.187
- 1.699
- 2.587
- 1.557
- 2.362
- 1.963
- 1.504
- 1.959
- 2.004
- 2.095
- 1.467
- 1.1
- 0.484
- 2.031
- 1.758
- 1.689
- 1.996
- 1.436
- 2.437
- 1.581
- 2.157
- 1.63
- 1.427
- 1.407
- 1.319
- 1.09
- 2.063
- 1.374
- 0.992
- 1.221
- 1.133
- 0.926
- 1.498
- 0.914
- 1.101
- 1.995
- 1.026
- 0.79
- 1.452
- 0.939
- 0.435
- 1.062
- 0.678
- 1.718
- 1.333
- 0.751
- 0.887
- 0.675
- 0.447
- 1.652
- 0.356
- 1.057
- 1.097
- 0.667
- 1.411
- 0.612
- 0.823
- 1.202
- 1.052
- 0.83
- 0.77
- 0.632
- 0.565
- 0.717
- 1.416
- 0.776
- 0.548
- 0.355
- 0.273
- 0.726
- 0.302
- 0.352
- 1.092
unequal: 0
verbose: 1
