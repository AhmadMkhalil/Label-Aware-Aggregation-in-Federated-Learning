avg_train_accuracy: 0.254
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0383
- 0.0809
- 0.0186
- 0.0974
- 0.1071
- 0.1236
- 0.1365
- 0.1341
- 0.1501
- 0.0188
- 0.149
- 0.1593
- 0.1618
- 0.1669
- 0.1757
- 0.1783
- 0.1816
- 0.1843
- 0.1937
- 0.1946
- 0.2011
- 0.1995
- 0.2084
- 0.2076
- 0.2092
- 0.217
- 0.2195
- 0.2226
- 0.2243
- 0.0189
- 0.233
- 0.2278
- 0.2254
- 0.2236
- 0.233
- 0.2434
- 0.2369
- 0.238
- 0.2448
- 0.2409
- 0.2361
- 0.2485
- 0.2498
- 0.2431
- 0.2482
- 0.2471
- 0.2523
- 0.2549
- 0.2615
- 0.2636
- 0.265
- 0.2602
- 0.2656
- 0.2786
- 0.2664
- 0.2647
- 0.2641
- 0.2696
- 0.2754
- 0.2734
- 0.2819
- 0.0197
- 0.2765
- 0.272
- 0.268
- 0.2705
- 0.2727
- 0.0194
- 0.2675
- 0.2792
- 0.2794
- 0.2827
- 0.2891
- 0.2927
- 0.2896
- 0.2859
- 0.0203
- 0.2894
- 0.29
- 0.2943
- 0.2878
- 0.2878
- 0.2944
- 0.2932
- 0.2945
- 0.263
- 0.297
- 0.301
- 0.3005
- 0.2991
- 0.3015
- 0.2971
- 0.308
- 0.3007
- 0.3011
- 0.0204
- 0.2972
- 0.3004
- 0.2879
- 0.2918
test_loss_list:
- 1.7939376974105834
- 1.707188687324524
- 4.426717910766602
- 1.64307302236557
- 1.6298060345649719
- 1.6150905346870423
- 1.5707146072387694
- 1.573269658088684
- 1.5339578914642333
- 4.440652484893799
- 1.532321915626526
- 1.5076986598968505
- 1.4798536276817322
- 1.4839054679870605
- 1.4551482009887695
- 1.4551213788986206
- 1.443918833732605
- 1.4594594573974609
- 1.4241915702819825
- 1.4213638925552368
- 1.4159025382995605
- 1.4052829957008361
- 1.3900646018981933
- 1.3962579321861268
- 1.3802696299552917
- 1.378462426662445
- 1.3726244616508483
- 1.3605808568000795
- 1.3683718729019165
- 4.427909927368164
- 1.3393349170684814
- 1.3581824612617492
- 1.3350514006614684
- 1.3344619655609131
- 1.3215744638442992
- 1.3124619913101196
- 1.3238956642150879
- 1.328053228855133
- 1.3147722172737122
- 1.3399354529380798
- 1.346441707611084
- 1.3001560807228087
- 1.308566563129425
- 1.3226088428497313
- 1.3117642021179199
- 1.3259175300598145
- 1.3313604736328124
- 1.2901614022254944
- 1.2813976216316223
- 1.2799207019805907
- 1.2742430186271667
- 1.2709330320358276
- 1.2768821096420289
- 1.2655968022346498
- 1.2815379452705384
- 1.2941203355789184
- 1.2704689931869506
- 1.2657411789894104
- 1.2767861151695252
- 1.2739899134635926
- 1.2706265807151795
- 4.263537359237671
- 1.2529893445968627
- 1.26741290807724
- 1.253545916080475
- 1.2731212759017945
- 1.2660964035987854
- 4.267654800415039
- 1.256748321056366
- 1.2430459141731263
- 1.2288075280189514
- 1.2344846391677857
- 1.240340859889984
- 1.2374044346809387
- 1.239760446548462
- 1.229097397327423
- 4.032860593795776
- 1.2265837645530702
- 1.224815490245819
- 1.2314375996589662
- 1.222798306941986
- 1.2325486469268798
- 1.2271806263923646
- 1.208039996623993
- 1.2298839378356934
- 1.2960211849212646
- 1.2092183971405028
- 1.2188779044151306
- 1.2080072212219237
- 1.2055443572998046
- 1.208244502544403
- 1.216820652484894
- 1.2057722115516663
- 1.2100156736373902
- 1.2338823747634888
- 4.1790173053741455
- 1.2231404280662537
- 1.2177006196975708
- 1.241385052204132
- 1.247603039741516
train_accuracy:
- 0.034
- 0.083
- 0.911
- 0.079
- 0.108
- 0.111
- 0.146
- 0.143
- 0.164
- 0.919
- 0.132
- 0.098
- 0.181
- 0.104
- 0.129
- 0.181
- 0.209
- 0.167
- 0.153
- 0.214
- 0.16
- 0.189
- 0.153
- 0.15
- 0.174
- 0.181
- 0.17
- 0.245
- 0.18
- 0.946
- 0.216
- 0.188
- 0.226
- 0.176
- 0.228
- 0.198
- 0.183
- 0.191
- 0.21
- 0.195
- 0.172
- 0.18
- 0.186
- 0.183
- 0.2
- 0.193
- 0.21
- 0.261
- 0.216
- 0.189
- 0.203
- 0.288
- 0.225
- 0.281
- 0.218
- 0.206
- 0.289
- 0.197
- 0.227
- 0.211
- 0.225
- 0.869
- 0.187
- 0.225
- 0.216
- 0.283
- 0.275
- 0.961
- 0.189
- 0.246
- 0.201
- 0.238
- 0.255
- 0.253
- 0.302
- 0.282
- 0.912
- 0.228
- 0.233
- 0.278
- 0.191
- 0.2
- 0.243
- 0.278
- 0.251
- 0.279
- 0.243
- 0.243
- 0.315
- 0.211
- 0.231
- 0.267
- 0.304
- 0.215
- 0.296
- 0.941
- 0.263
- 0.214
- 0.216
- 0.254
train_loss:
- 4.296
- 3.544
- 0.544
- 4.063
- 3.184
- 2.736
- 3.434
- 2.918
- 3.362
- 0.551
- 2.903
- 3.231
- 2.963
- 3.228
- 3.077
- 2.678
- 2.613
- 2.294
- 2.974
- 2.343
- 2.667
- 2.973
- 2.872
- 2.284
- 2.586
- 2.341
- 2.174
- 2.539
- 1.956
- 0.519
- 2.603
- 1.661
- 2.141
- 2.262
- 2.208
- 1.995
- 2.456
- 1.551
- 1.664
- 1.258
- 2.033
- 2.049
- 1.471
- 1.716
- 1.298
- 0.964
- 1.237
- 1.796
- 1.571
- 2.33
- 1.949
- 1.948
- 1.284
- 1.863
- 1.024
- 1.569
- 1.557
- 1.205
- 1.119
- 1.199
- 0.825
- 0.47
- 1.29
- 0.691
- 1.946
- 1.574
- 1.028
- 0.366
- 1.762
- 1.093
- 1.119
- 1.139
- 0.84
- 0.702
- 1.029
- 1.314
- 0.348
- 0.798
- 0.968
- 0.856
- 1.097
- 0.768
- 0.779
- 1.032
- 0.532
- 1.509
- 0.982
- 1.525
- 0.891
- 1.013
- 0.723
- 1.171
- 0.859
- 0.742
- 0.54
- 0.315
- 1.142
- 0.614
- 0.356
- 0.558
unequal: 0
verbose: 1
