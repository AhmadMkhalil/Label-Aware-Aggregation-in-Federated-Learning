avg_train_accuracy: 0.333
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0372
- 0.0759
- 0.0967
- 0.1123
- 0.1186
- 0.1355
- 0.1398
- 0.1415
- 0.1551
- 0.1561
- 0.1693
- 0.173
- 0.1793
- 0.1789
- 0.1786
- 0.1941
- 0.0182
- 0.1858
- 0.1938
- 0.1957
- 0.2043
- 0.2101
- 0.2065
- 0.2119
- 0.2103
- 0.2209
- 0.2151
- 0.2174
- 0.2317
- 0.2275
- 0.2361
- 0.226
- 0.227
- 0.2385
- 0.2432
- 0.2451
- 0.2387
- 0.2381
- 0.2508
- 0.0186
- 0.2499
- 0.2494
- 0.25
- 0.2465
- 0.263
- 0.2558
- 0.2627
- 0.265
- 0.2509
- 0.2619
- 0.267
- 0.0193
- 0.2659
- 0.0201
- 0.2663
- 0.2821
- 0.2714
- 0.2806
- 0.2843
- 0.2759
- 0.2777
- 0.2846
- 0.285
- 0.0197
- 0.2832
- 0.2828
- 0.2798
- 0.0201
- 0.291
- 0.2829
- 0.0206
- 0.2937
- 0.2817
- 0.0214
- 0.0217
- 0.2897
- 0.2921
- 0.2909
- 0.299
- 0.2978
- 0.2927
- 0.2901
- 0.2928
- 0.2971
- 0.3065
- 0.306
- 0.2994
- 0.2984
- 0.0207
- 0.2988
- 0.3066
- 0.3088
- 0.3132
- 0.3074
- 0.3055
- 0.3111
- 0.3148
- 0.3134
- 0.3013
- 0.3183
test_loss_list:
- 1.8067570209503174
- 1.6947886610031129
- 1.648693904876709
- 1.606839141845703
- 1.5874555778503419
- 1.560731270313263
- 1.5378883695602417
- 1.5239616584777833
- 1.4999073553085327
- 1.4993579530715941
- 1.47130619764328
- 1.4665678334236145
- 1.4447624444961549
- 1.4462074780464171
- 1.4499576377868653
- 1.4260750961303712
- 4.678845062255859
- 1.4250083923339845
- 1.408627953529358
- 1.4010815477371217
- 1.3735398173332214
- 1.362411081790924
- 1.3763555765151978
- 1.3642588639259339
- 1.3708706092834473
- 1.3525160312652589
- 1.3507547283172607
- 1.3647584748268127
- 1.3396560263633728
- 1.3341570162773133
- 1.3199842882156372
- 1.3518723440170288
- 1.3531537652015686
- 1.3478749632835387
- 1.3161958384513854
- 1.3282855534553528
- 1.326458661556244
- 1.326484866142273
- 1.3174141979217528
- 4.5316971397399906
- 1.2863373136520386
- 1.309808506965637
- 1.2846755218505859
- 1.3039368748664857
- 1.2708195638656616
- 1.3009654307365417
- 1.2709549856185913
- 1.2864281058311462
- 1.2793738698959352
- 1.2764567852020263
- 1.2644148659706116
- 4.683863296508789
- 1.2634639310836793
- 4.334271192550659
- 1.2511817550659179
- 1.2181893491744995
- 1.2539900302886964
- 1.2263997292518616
- 1.2295587420463563
- 1.223097903728485
- 1.2188295340538025
- 1.2203455591201782
- 1.23887442111969
- 4.20111909866333
- 1.2160710883140564
- 1.2277168536186218
- 1.2547511982917785
- 4.2419607543945315
- 1.2067515349388123
- 1.232835214138031
- 3.9318144798278807
- 1.200583062171936
- 1.2321708393096924
- 3.8198537921905515
- 3.906658411026001
- 1.2136302971839905
- 1.2133342123031616
- 1.2143277859687804
- 1.1987070369720458
- 1.2043742942810058
- 1.215398371219635
- 1.219285135269165
- 1.1967889261245728
- 1.2065129280090332
- 1.208502423763275
- 1.1949334859848022
- 1.1994292616844178
- 1.2088548254966736
- 4.029079866409302
- 1.1869253087043763
- 1.1805867671966552
- 1.1862566423416139
- 1.1818298816680908
- 1.1914082717895509
- 1.1809309887886048
- 1.183370349407196
- 1.168954393863678
- 1.1808433866500854
- 1.2070280814170837
- 1.174099144935608
train_accuracy:
- 0.053
- 0.078
- 0.094
- 0.099
- 0.108
- 0.141
- 0.136
- 0.136
- 0.115
- 0.166
- 0.141
- 0.139
- 0.157
- 0.155
- 0.141
- 0.172
- 0.986
- 0.179
- 0.155
- 0.188
- 0.224
- 0.205
- 0.176
- 0.199
- 0.176
- 0.221
- 0.184
- 0.203
- 0.216
- 0.242
- 0.187
- 0.172
- 0.18
- 0.22
- 0.229
- 0.229
- 0.191
- 0.179
- 0.227
- 0.895
- 0.212
- 0.216
- 0.241
- 0.239
- 0.243
- 0.229
- 0.241
- 0.242
- 0.22
- 0.247
- 0.24
- 0.943
- 0.249
- 0.956
- 0.201
- 0.261
- 0.219
- 0.261
- 0.263
- 0.275
- 0.239
- 0.247
- 0.218
- 0.932
- 0.253
- 0.257
- 0.254
- 0.929
- 0.274
- 0.221
- 0.92
- 0.269
- 0.263
- 0.934
- 0.926
- 0.27
- 0.243
- 0.246
- 0.27
- 0.259
- 0.248
- 0.295
- 0.297
- 0.289
- 0.307
- 0.277
- 0.301
- 0.284
- 0.929
- 0.264
- 0.294
- 0.231
- 0.304
- 0.263
- 0.319
- 0.279
- 0.291
- 0.308
- 0.265
- 0.333
train_loss:
- 4.358
- 3.99
- 3.794
- 3.669
- 3.569
- 3.336
- 3.334
- 3.363
- 3.296
- 2.889
- 3.112
- 2.918
- 2.879
- 2.729
- 2.295
- 2.867
- 0.631
- 2.843
- 2.962
- 2.817
- 2.822
- 2.305
- 2.192
- 2.435
- 2.51
- 2.459
- 1.96
- 2.035
- 2.375
- 2.415
- 2.182
- 1.708
- 1.378
- 2.07
- 2.099
- 1.714
- 1.426
- 2.277
- 1.493
- 0.542
- 2.153
- 1.306
- 2.449
- 1.792
- 1.84
- 1.202
- 2.047
- 0.985
- 1.574
- 1.795
- 1.679
- 0.454
- 1.481
- 0.343
- 2.263
- 1.547
- 1.51
- 1.853
- 1.051
- 1.955
- 1.358
- 1.25
- 1.354
- 0.357
- 1.352
- 1.009
- 0.698
- 0.296
- 1.535
- 1.168
- 0.293
- 1.158
- 0.674
- 0.248
- 0.029
- 1.771
- 0.842
- 1.395
- 0.707
- 0.446
- 1.0
- 1.221
- 1.601
- 0.9
- 0.989
- 0.789
- 1.199
- 1.426
- 0.31
- 1.293
- 0.856
- 1.084
- 0.783
- 0.928
- 1.012
- 0.668
- 0.816
- 0.501
- 0.688
- 0.778
unequal: 0
verbose: 1
