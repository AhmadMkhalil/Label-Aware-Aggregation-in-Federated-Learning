avg_train_accuracy: 0.937
avg_train_loss: 0.0
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0406
- 0.0782
- 0.0977
- 0.0971
- 0.1145
- 0.1089
- 0.1235
- 0.1374
- 0.145
- 0.1424
- 0.1597
- 0.1592
- 0.159
- 0.1703
- 0.1665
- 0.1726
- 0.1829
- 0.1783
- 0.1858
- 0.1982
- 0.2038
- 0.214
- 0.2098
- 0.2195
- 0.2086
- 0.203
- 0.198
- 0.019
- 0.2133
- 0.2052
- 0.0191
- 0.2208
- 0.2341
- 0.2322
- 0.2408
- 0.2344
- 0.2287
- 0.019
- 0.2455
- 0.2539
- 0.0192
- 0.0186
- 0.0194
- 0.2459
- 0.2506
- 0.2519
- 0.2597
- 0.2481
- 0.0194
- 0.019
- 0.2562
- 0.2526
- 0.2611
- 0.2625
- 0.2635
- 0.2529
- 0.2682
- 0.262
- 0.2669
- 0.2624
- 0.2784
- 0.2748
- 0.2711
- 0.2654
- 0.2616
- 0.2657
- 0.2836
- 0.2883
- 0.2804
- 0.2793
- 0.2908
- 0.2771
- 0.2822
- 0.2863
- 0.2924
- 0.2853
- 0.2925
- 0.2845
- 0.2916
- 0.2882
- 0.2832
- 0.2814
- 0.02
- 0.3007
- 0.2918
- 0.2935
- 0.2918
- 0.2943
- 0.0205
- 0.2884
- 0.2921
- 0.3047
- 0.3014
- 0.298
- 0.294
- 0.3082
- 0.3033
- 0.3072
- 0.0209
- 0.0214
test_loss_list:
- 1.794544792175293
- 1.7013712430000305
- 1.6397803497314454
- 1.6130654859542846
- 1.5953758597373962
- 1.5873743557929993
- 1.5764261603355407
- 1.539936125278473
- 1.5296135592460631
- 1.5432648181915283
- 1.4936250424385071
- 1.5139832735061645
- 1.487046411037445
- 1.4560679721832275
- 1.4769801163673402
- 1.4875913977622985
- 1.4428315114974977
- 1.4427813243865968
- 1.4201076030731201
- 1.3959181237220764
- 1.3959518933296204
- 1.3736922478675841
- 1.3784514522552491
- 1.370254418849945
- 1.38036794424057
- 1.3969589161872864
- 1.4094936656951904
- 4.590626888275146
- 1.358482186794281
- 1.3772795510292053
- 4.4816412925720215
- 1.3357429671287537
- 1.306172902584076
- 1.3186943960189819
- 1.2980919122695922
- 1.3225758719444274
- 1.3258664512634277
- 4.359964075088501
- 1.283560552597046
- 1.266737735271454
- 4.1980296325683595
- 4.236722002029419
- 4.326408557891845
- 1.2786411333084107
- 1.2742070245742798
- 1.2716866040229797
- 1.2553103566169739
- 1.2750501894950867
- 3.9846082878112794
- 4.015287895202636
- 1.264153482913971
- 1.2668455004692079
- 1.2691146969795226
- 1.2471244597434998
- 1.2482710194587707
- 1.2727075505256653
- 1.2517748641967774
- 1.2628761911392212
- 1.2502564358711243
- 1.262810504436493
- 1.2318232107162475
- 1.2465196180343627
- 1.2447117757797241
- 1.2558501839637757
- 1.273205077648163
- 1.2670229482650757
- 1.2326842951774597
- 1.2259686779975891
- 1.2297692108154297
- 1.2552338767051696
- 1.2262363958358764
- 1.2520115637779237
- 1.2481997895240784
- 1.2390308928489686
- 1.2341786527633667
- 1.2405592203140259
- 1.2344558143615723
- 1.2489213299751283
- 1.2313555955886841
- 1.2319893765449523
- 1.2652633953094483
- 1.2557165503501893
- 4.0404867172241214
- 1.185567591190338
- 1.2154353523254395
- 1.2137980103492736
- 1.2265171241760253
- 1.2190020155906678
- 4.062023687362671
- 1.2383946037292481
- 1.212417275905609
- 1.1889345908164979
- 1.2047267472743988
- 1.2087493193149568
- 1.2114744567871094
- 1.1864408946037293
- 1.211048927307129
- 1.1936597371101378
- 3.92966365814209
- 3.8995206928253174
train_accuracy:
- 0.044
- 0.081
- 0.11
- 0.095
- 0.114
- 0.113
- 0.132
- 0.139
- 0.148
- 0.142
- 0.153
- 0.148
- 0.149
- 0.15
- 0.165
- 0.176
- 0.171
- 0.188
- 0.166
- 0.201
- 0.206
- 0.184
- 0.184
- 0.185
- 0.212
- 0.19
- 0.182
- 0.903
- 0.191
- 0.193
- 0.93
- 0.204
- 0.217
- 0.193
- 0.195
- 0.183
- 0.212
- 0.869
- 0.22
- 0.242
- 0.939
- 0.852
- 0.938
- 0.216
- 0.242
- 0.214
- 0.225
- 0.232
- 0.934
- 0.88
- 0.221
- 0.257
- 0.22
- 0.251
- 0.249
- 0.248
- 0.245
- 0.228
- 0.218
- 0.245
- 0.231
- 0.245
- 0.257
- 0.257
- 0.249
- 0.228
- 0.259
- 0.257
- 0.272
- 0.257
- 0.266
- 0.254
- 0.259
- 0.26
- 0.251
- 0.292
- 0.246
- 0.251
- 0.261
- 0.287
- 0.297
- 0.271
- 0.904
- 0.28
- 0.274
- 0.275
- 0.296
- 0.285
- 0.919
- 0.279
- 0.267
- 0.275
- 0.281
- 0.297
- 0.277
- 0.288
- 0.276
- 0.328
- 0.925
- 0.937
train_loss:
- 4.318
- 3.98
- 3.77
- 3.657
- 3.359
- 3.225
- 2.989
- 3.377
- 2.699
- 2.353
- 3.205
- 2.205
- 3.112
- 3.182
- 2.063
- 1.653
- 2.803
- 2.788
- 2.707
- 2.948
- 2.771
- 2.427
- 2.391
- 2.053
- 2.378
- 1.874
- 1.547
- 0.63
- 2.899
- 1.485
- 0.421
- 2.874
- 2.51
- 2.072
- 1.974
- 2.173
- 2.071
- 0.401
- 2.579
- 2.357
- 0.376
- 0.055
- 0.063
- 2.01
- 1.898
- 1.935
- 1.691
- 1.443
- 0.311
- 0.033
- 2.01
- 1.544
- 1.582
- 1.96
- 1.328
- 0.884
- 1.313
- 1.605
- 1.807
- 1.15
- 1.453
- 0.884
- 1.006
- 1.31
- 0.841
- 1.461
- 1.505
- 1.205
- 1.441
- 1.125
- 0.957
- 0.921
- 0.895
- 0.684
- 0.781
- 1.794
- 0.655
- 1.275
- 0.658
- 1.635
- 1.0
- 1.274
- 0.405
- 0.898
- 0.398
- 0.588
- 0.999
- 1.014
- 0.275
- 1.682
- 0.718
- 0.508
- 1.019
- 0.963
- 0.612
- 0.418
- 0.505
- 0.959
- 0.284
- 0.013
unequal: 0
verbose: 1
