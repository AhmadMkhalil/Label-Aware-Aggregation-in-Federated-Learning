avg_train_accuracy: 0.285
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0399
- 0.0799
- 0.094
- 0.1056
- 0.115
- 0.1238
- 0.1388
- 0.141
- 0.1433
- 0.1552
- 0.1666
- 0.1621
- 0.1584
- 0.0188
- 0.1766
- 0.1831
- 0.0182
- 0.0195
- 0.1771
- 0.1873
- 0.1908
- 0.1909
- 0.1862
- 0.1996
- 0.1982
- 0.1985
- 0.1971
- 0.2032
- 0.2142
- 0.2068
- 0.2139
- 0.2049
- 0.2146
- 0.2228
- 0.2236
- 0.2324
- 0.2301
- 0.2305
- 0.2363
- 0.234
- 0.2375
- 0.2347
- 0.2335
- 0.2412
- 0.2505
- 0.2481
- 0.248
- 0.2547
- 0.2528
- 0.2539
- 0.2589
- 0.2549
- 0.2585
- 0.2588
- 0.2629
- 0.2637
- 0.2502
- 0.2612
- 0.2673
- 0.2697
- 0.2675
- 0.2631
- 0.2665
- 0.252
- 0.2622
- 0.267
- 0.2676
- 0.2666
- 0.0196
- 0.2767
- 0.2762
- 0.282
- 0.2841
- 0.2801
- 0.2799
- 0.271
- 0.2685
- 0.2701
- 0.2766
- 0.2729
- 0.2719
- 0.2711
- 0.2862
- 0.0192
- 0.2834
- 0.284
- 0.2828
- 0.2809
- 0.2871
- 0.2874
- 0.2918
- 0.0194
- 0.2816
- 0.2902
- 0.273
- 0.2949
- 0.2745
- 0.2966
- 0.2805
- 0.2902
test_loss_list:
- 1.7996982431411743
- 1.701181674003601
- 1.6481822299957276
- 1.6236715865135194
- 1.5937592792510986
- 1.5664463257789611
- 1.5509598278999328
- 1.5338438725471497
- 1.5358597016334534
- 1.512883608341217
- 1.4893650484085084
- 1.4930059838294982
- 1.5005816388130189
- 4.47932991027832
- 1.4751284790039063
- 1.4471439504623413
- 4.333253421783447
- 4.415521450042725
- 1.4330892276763916
- 1.438961660861969
- 1.4080669689178467
- 1.4010452842712402
- 1.411703519821167
- 1.3906265926361083
- 1.3925723624229431
- 1.3952657461166382
- 1.4047205758094787
- 1.386515929698944
- 1.382622082233429
- 1.383638551235199
- 1.3707633876800538
- 1.4037836265563965
- 1.3705602979660034
- 1.3548942732810973
- 1.3633056616783141
- 1.3389796280860902
- 1.3302444171905519
- 1.3341653037071228
- 1.333384940624237
- 1.328891007900238
- 1.3280440068244934
- 1.3476376271247863
- 1.3300966906547547
- 1.3097409224510193
- 1.3150694394111633
- 1.2953706741333009
- 1.300991759300232
- 1.2851323580741882
- 1.2879523634910583
- 1.3057005047798156
- 1.2897142887115478
- 1.287096743583679
- 1.2883112812042237
- 1.2877036809921265
- 1.2869319248199462
- 1.282258815765381
- 1.307309648990631
- 1.2799797463417053
- 1.2803949975967408
- 1.2661786031723024
- 1.2767819929122926
- 1.2920626997947693
- 1.2815657353401184
- 1.3249957036972047
- 1.2967507600784303
- 1.282623233795166
- 1.284720492362976
- 1.2943067383766174
- 4.511856861114502
- 1.2356654047966003
- 1.2415973401069642
- 1.240340759754181
- 1.2409400916099549
- 1.2568116855621339
- 1.2456089973449707
- 1.2663143062591553
- 1.279872591495514
- 1.2837020397186278
- 1.2656079173088073
- 1.2656561994552613
- 1.2791874504089356
- 1.2702904081344604
- 1.245921905040741
- 4.352815580368042
- 1.2398218250274657
- 1.2440343379974366
- 1.2386376428604127
- 1.2478546810150146
- 1.2397220253944397
- 1.259626910686493
- 1.2436644434928894
- 4.184155731201172
- 1.253096091747284
- 1.234796223640442
- 1.2610596919059753
- 1.227834255695343
- 1.2760646510124207
- 1.238002474308014
- 1.2610488653182983
- 1.249966173171997
train_accuracy:
- 0.029
- 0.101
- 0.092
- 0.099
- 0.137
- 0.13
- 0.126
- 0.146
- 0.154
- 0.149
- 0.148
- 0.15
- 0.144
- 0.854
- 0.159
- 0.171
- 0.807
- 0.934
- 0.147
- 0.179
- 0.15
- 0.169
- 0.163
- 0.19
- 0.188
- 0.183
- 0.193
- 0.17
- 0.179
- 0.191
- 0.165
- 0.141
- 0.203
- 0.195
- 0.213
- 0.21
- 0.246
- 0.222
- 0.236
- 0.244
- 0.231
- 0.247
- 0.201
- 0.233
- 0.222
- 0.228
- 0.229
- 0.26
- 0.263
- 0.225
- 0.229
- 0.245
- 0.25
- 0.24
- 0.243
- 0.248
- 0.231
- 0.245
- 0.235
- 0.241
- 0.223
- 0.256
- 0.24
- 0.223
- 0.223
- 0.271
- 0.263
- 0.241
- 0.937
- 0.271
- 0.261
- 0.296
- 0.266
- 0.256
- 0.265
- 0.27
- 0.26
- 0.266
- 0.231
- 0.295
- 0.227
- 0.241
- 0.262
- 0.904
- 0.227
- 0.273
- 0.302
- 0.275
- 0.29
- 0.3
- 0.252
- 0.923
- 0.241
- 0.3
- 0.277
- 0.303
- 0.259
- 0.288
- 0.286
- 0.285
train_loss:
- 4.334
- 3.94
- 3.759
- 3.397
- 3.235
- 3.472
- 2.991
- 2.892
- 2.642
- 3.213
- 3.129
- 2.618
- 2.28
- 0.618
- 2.801
- 3.068
- 0.458
- 0.102
- 3.272
- 2.181
- 2.993
- 2.695
- 2.494
- 2.653
- 2.273
- 2.2
- 1.863
- 2.322
- 2.053
- 2.006
- 1.939
- 1.481
- 2.691
- 1.859
- 2.168
- 2.49
- 1.843
- 2.327
- 2.06
- 1.873
- 1.671
- 1.277
- 1.65
- 2.241
- 1.618
- 1.97
- 1.341
- 2.38
- 1.641
- 1.346
- 1.566
- 1.828
- 1.951
- 1.293
- 1.127
- 1.488
- 1.038
- 2.001
- 1.716
- 1.627
- 1.054
- 1.204
- 1.303
- 0.909
- 1.07
- 1.252
- 0.867
- 0.879
- 0.515
- 1.907
- 1.221
- 1.481
- 1.019
- 0.818
- 0.902
- 0.578
- 0.445
- 0.357
- 1.286
- 0.402
- 0.843
- 0.945
- 1.319
- 0.384
- 0.965
- 0.939
- 1.227
- 0.96
- 0.523
- 0.835
- 0.658
- 0.32
- 0.612
- 0.415
- 1.317
- 0.344
- 0.837
- 0.865
- 0.641
- 0.548
unequal: 0
verbose: 1
