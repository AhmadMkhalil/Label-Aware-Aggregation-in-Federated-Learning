avg_train_accuracy: 0.254
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0363
- 0.0764
- 0.0873
- 0.0988
- 0.1172
- 0.1247
- 0.1256
- 0.146
- 0.1501
- 0.1557
- 0.1677
- 0.176
- 0.1828
- 0.1829
- 0.192
- 0.1871
- 0.188
- 0.193
- 0.1935
- 0.0163
- 0.1903
- 0.1943
- 0.202
- 0.2086
- 0.2223
- 0.2196
- 0.2212
- 0.2157
- 0.2338
- 0.0188
- 0.0192
- 0.2264
- 0.2148
- 0.2365
- 0.237
- 0.238
- 0.0191
- 0.0193
- 0.2335
- 0.244
- 0.2518
- 0.2373
- 0.2497
- 0.2492
- 0.2372
- 0.2533
- 0.2561
- 0.2567
- 0.2569
- 0.2595
- 0.2618
- 0.266
- 0.2671
- 0.2736
- 0.2656
- 0.2616
- 0.0154
- 0.2694
- 0.2678
- 0.2629
- 0.2744
- 0.2742
- 0.2805
- 0.2807
- 0.2645
- 0.2721
- 0.2749
- 0.0196
- 0.282
- 0.0196
- 0.0198
- 0.2774
- 0.2771
- 0.2829
- 0.2819
- 0.2812
- 0.2792
- 0.2798
- 0.2806
- 0.2836
- 0.293
- 0.2787
- 0.0198
- 0.2929
- 0.297
- 0.2918
- 0.2885
- 0.297
- 0.3026
- 0.2941
- 0.2918
- 0.3017
- 0.2926
- 0.3036
- 0.0207
- 0.2991
- 0.3135
- 0.2944
- 0.2973
- 0.3024
test_loss_list:
- 1.8022725248336793
- 1.7010341024398803
- 1.647022008895874
- 1.6249158024787902
- 1.581790099143982
- 1.5636947631835938
- 1.5708699679374696
- 1.5253322148323059
- 1.5003311228752136
- 1.494234790802002
- 1.4739645075798036
- 1.4492975163459778
- 1.4349454188346862
- 1.433718309402466
- 1.4251475191116334
- 1.4415886473655701
- 1.4251759386062621
- 1.4320913243293762
- 1.4439096665382385
- 4.515432510375977
- 1.4097728109359742
- 1.4225907278060914
- 1.388848659992218
- 1.3580368375778198
- 1.3434164381027223
- 1.3476498126983643
- 1.3480238270759584
- 1.3565252614021301
- 1.3347797799110412
- 4.441311674118042
- 4.47209023475647
- 1.331588361263275
- 1.3521484875679015
- 1.3152028632164001
- 1.3160932517051698
- 1.3127426481246949
- 4.394958667755127
- 4.461926012039185
- 1.3105665683746337
- 1.3024568271636963
- 1.2791259598731994
- 1.3073999881744385
- 1.2946736216545105
- 1.302276303768158
- 1.309189977645874
- 1.2794197034835815
- 1.2844566249847411
- 1.2768378019332887
- 1.275729343891144
- 1.2665604329109192
- 1.2634088444709777
- 1.2603717422485352
- 1.2670180463790894
- 1.2474015974998474
- 1.2717270040512085
- 1.2751563453674317
- 4.48471830368042
- 1.256199004650116
- 1.26190279006958
- 1.2657122945785522
- 1.2483613419532775
- 1.2521297311782837
- 1.2364968466758728
- 1.2499308681488037
- 1.2787654566764832
- 1.250872359275818
- 1.2461550641059875
- 4.130478944778442
- 1.2155691027641295
- 3.927953395843506
- 3.9706133460998534
- 1.2235940051078797
- 1.2220400166511536
- 1.2214052963256836
- 1.224897186756134
- 1.2179245734214783
- 1.2274375295639037
- 1.2411153411865234
- 1.2441487503051758
- 1.2334000253677369
- 1.2346131992340088
- 1.2563849806785583
- 4.129720716476441
- 1.2185636711120607
- 1.2097610569000243
- 1.222801218032837
- 1.2239431190490722
- 1.2184246730804444
- 1.2100492644309997
- 1.2121244406700133
- 1.2455595302581788
- 1.2022214531898499
- 1.241882429122925
- 1.208794629573822
- 3.9535383319854738
- 1.1995843172073364
- 1.191818084716797
- 1.2248829460144044
- 1.2221039628982544
- 1.2174821424484252
train_accuracy:
- 0.025
- 0.075
- 0.097
- 0.093
- 0.121
- 0.12
- 0.117
- 0.148
- 0.129
- 0.147
- 0.159
- 0.146
- 0.165
- 0.184
- 0.158
- 0.153
- 0.187
- 0.162
- 0.165
- 0.658
- 0.162
- 0.174
- 0.202
- 0.171
- 0.211
- 0.178
- 0.208
- 0.187
- 0.19
- 0.883
- 0.937
- 0.248
- 0.226
- 0.212
- 0.221
- 0.239
- 0.904
- 0.916
- 0.217
- 0.232
- 0.211
- 0.219
- 0.232
- 0.22
- 0.237
- 0.238
- 0.224
- 0.24
- 0.239
- 0.249
- 0.249
- 0.263
- 0.248
- 0.243
- 0.249
- 0.24
- 0.565
- 0.275
- 0.235
- 0.256
- 0.261
- 0.282
- 0.275
- 0.256
- 0.253
- 0.252
- 0.268
- 0.914
- 0.257
- 0.923
- 0.914
- 0.27
- 0.238
- 0.285
- 0.271
- 0.309
- 0.303
- 0.281
- 0.288
- 0.282
- 0.263
- 0.291
- 0.956
- 0.289
- 0.28
- 0.28
- 0.284
- 0.277
- 0.278
- 0.261
- 0.245
- 0.257
- 0.257
- 0.241
- 0.929
- 0.275
- 0.267
- 0.272
- 0.282
- 0.254
train_loss:
- 4.375
- 3.972
- 3.762
- 3.278
- 3.405
- 2.972
- 2.593
- 3.35
- 3.218
- 2.877
- 3.141
- 2.822
- 3.02
- 2.486
- 2.529
- 2.05
- 2.182
- 1.896
- 1.587
- 0.609
- 3.003
- 2.141
- 2.869
- 2.829
- 2.531
- 2.306
- 2.439
- 2.168
- 1.75
- 0.484
- 0.099
- 2.289
- 1.496
- 2.142
- 2.063
- 2.12
- 0.392
- 0.076
- 2.189
- 1.698
- 1.82
- 1.562
- 1.503
- 1.563
- 2.257
- 1.424
- 1.22
- 1.838
- 2.2
- 1.438
- 1.208
- 1.559
- 1.139
- 1.592
- 1.03
- 1.873
- 0.431
- 1.306
- 1.181
- 2.254
- 0.976
- 1.524
- 0.935
- 0.59
- 0.461
- 1.691
- 1.582
- 0.382
- 2.108
- 0.281
- 0.029
- 1.54
- 1.41
- 0.994
- 1.102
- 1.323
- 0.831
- 0.82
- 1.043
- 0.774
- 0.731
- 0.627
- 0.325
- 1.652
- 0.652
- 0.707
- 1.155
- 0.508
- 0.662
- 1.126
- 0.721
- 1.372
- 0.656
- 0.952
- 0.293
- 1.569
- 0.714
- 0.902
- 0.559
- 0.543
unequal: 0
verbose: 1
