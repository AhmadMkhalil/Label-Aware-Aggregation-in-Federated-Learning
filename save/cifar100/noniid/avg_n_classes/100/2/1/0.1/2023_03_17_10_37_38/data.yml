avg_train_accuracy: 0.28
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0337
- 0.0755
- 0.0956
- 0.1076
- 0.1124
- 0.1274
- 0.0185
- 0.1389
- 0.1383
- 0.1497
- 0.1541
- 0.1632
- 0.1682
- 0.17
- 0.1761
- 0.1766
- 0.1825
- 0.1935
- 0.1949
- 0.1981
- 0.2065
- 0.2048
- 0.2127
- 0.2102
- 0.2205
- 0.2229
- 0.2221
- 0.0191
- 0.0192
- 0.2203
- 0.2299
- 0.2265
- 0.0192
- 0.2306
- 0.2421
- 0.2371
- 0.0193
- 0.2407
- 0.241
- 0.2381
- 0.2468
- 0.2485
- 0.2397
- 0.2584
- 0.2456
- 0.2408
- 0.2424
- 0.0193
- 0.2476
- 0.2656
- 0.2642
- 0.2618
- 0.2573
- 0.2713
- 0.2812
- 0.2746
- 0.2754
- 0.2681
- 0.2745
- 0.2805
- 0.2771
- 0.2776
- 0.277
- 0.2888
- 0.2846
- 0.0202
- 0.2825
- 0.2746
- 0.2889
- 0.2858
- 0.2916
- 0.2898
- 0.2967
- 0.0207
- 0.2891
- 0.0228
- 0.2978
- 0.2734
- 0.2888
- 0.2936
- 0.2894
- 0.2958
- 0.3005
- 0.303
- 0.2977
- 0.0205
- 0.2932
- 0.291
- 0.3013
- 0.3066
- 0.2895
- 0.2885
- 0.3011
- 0.2994
- 0.0223
- 0.303
- 0.3107
- 0.2994
- 0.3111
- 0.307
test_loss_list:
- 1.8217499876022338
- 1.6877831888198853
- 1.6497520899772644
- 1.6139348793029784
- 1.5783387398719788
- 1.5624725747108459
- 4.64909873008728
- 1.5420330548286438
- 1.5328237056732177
- 1.5043826222419738
- 1.5090471911430359
- 1.4732912635803224
- 1.4717287564277648
- 1.4644183802604676
- 1.4621379613876342
- 1.4703004026412965
- 1.4440415501594543
- 1.4284646010398865
- 1.4173956942558288
- 1.4202865910530091
- 1.3878513169288635
- 1.386599657535553
- 1.3846009707450866
- 1.3866141772270202
- 1.355110659599304
- 1.3630128383636475
- 1.362989284992218
- 4.537603893280029
- 4.561563577651977
- 1.3493181300163268
- 1.330756871700287
- 1.3356094551086426
- 4.264373035430908
- 1.314961941242218
- 1.3120043110847472
- 1.308402111530304
- 4.110369777679443
- 1.3069398260116578
- 1.308038935661316
- 1.3034461283683776
- 1.2869801306724549
- 1.2932627248764037
- 1.2904896998405457
- 1.2778069543838502
- 1.2830495071411132
- 1.3078549790382386
- 1.3064170670509339
- 4.191456298828125
- 1.2712274098396301
- 1.2494921159744263
- 1.2644997310638428
- 1.2521974968910217
- 1.2818920588493348
- 1.2365844774246215
- 1.23515926361084
- 1.2463047695159912
- 1.2321121668815613
- 1.2647447514533996
- 1.254005093574524
- 1.2413340878486634
- 1.2368280053138734
- 1.2486283779144287
- 1.2368608379364014
- 1.21615868806839
- 1.2247025895118713
- 4.0101070213317875
- 1.2207530999183656
- 1.2328858184814453
- 1.1994817137718201
- 1.2219093084335326
- 1.212128164768219
- 1.2249918103218078
- 1.2012655377388
- 3.805664510726929
- 1.2037456798553468
- 3.589615058898926
- 1.1966807675361633
- 1.2361582040786743
- 1.2095647859573364
- 1.2132461857795716
- 1.2182613897323609
- 1.2112287092208862
- 1.1999379062652589
- 1.194383978843689
- 1.2020597553253174
- 3.8053141593933106
- 1.211229956150055
- 1.2114268612861634
- 1.1993252372741698
- 1.1943461728096008
- 1.2390650224685669
- 1.2319320964813232
- 1.2103666496276855
- 1.2016309690475464
- 3.696134262084961
- 1.1958037328720093
- 1.1758959317207336
- 1.2008856272697448
- 1.1886610651016236
- 1.2044651985168457
train_accuracy:
- 0.031
- 0.085
- 0.095
- 0.103
- 0.098
- 0.096
- 0.885
- 0.113
- 0.119
- 0.162
- 0.115
- 0.157
- 0.166
- 0.142
- 0.157
- 0.165
- 0.151
- 0.165
- 0.186
- 0.178
- 0.204
- 0.204
- 0.212
- 0.208
- 0.199
- 0.232
- 0.191
- 0.899
- 0.923
- 0.222
- 0.198
- 0.199
- 0.908
- 0.204
- 0.206
- 0.223
- 0.899
- 0.196
- 0.244
- 0.243
- 0.2
- 0.24
- 0.247
- 0.204
- 0.196
- 0.198
- 0.204
- 0.911
- 0.226
- 0.302
- 0.282
- 0.261
- 0.219
- 0.214
- 0.282
- 0.316
- 0.227
- 0.291
- 0.307
- 0.267
- 0.268
- 0.231
- 0.248
- 0.284
- 0.269
- 0.912
- 0.243
- 0.226
- 0.269
- 0.245
- 0.256
- 0.248
- 0.289
- 0.887
- 0.272
- 0.906
- 0.29
- 0.273
- 0.259
- 0.255
- 0.254
- 0.246
- 0.314
- 0.327
- 0.267
- 0.895
- 0.275
- 0.27
- 0.24
- 0.281
- 0.273
- 0.271
- 0.27
- 0.274
- 0.91
- 0.296
- 0.297
- 0.281
- 0.273
- 0.28
train_loss:
- 4.364
- 4.033
- 3.823
- 3.648
- 3.547
- 3.54
- 0.596
- 3.75
- 3.358
- 3.241
- 2.934
- 3.147
- 2.683
- 2.955
- 2.469
- 2.101
- 2.891
- 2.926
- 2.869
- 2.374
- 2.905
- 2.674
- 2.157
- 2.706
- 2.482
- 1.84
- 2.229
- 0.539
- 0.096
- 2.637
- 2.409
- 1.95
- 0.398
- 2.699
- 2.431
- 1.765
- 0.342
- 2.226
- 2.141
- 1.503
- 2.074
- 1.74
- 2.233
- 1.699
- 2.282
- 1.657
- 1.36
- 0.343
- 2.105
- 1.873
- 1.381
- 1.488
- 2.01
- 1.989
- 1.364
- 0.919
- 1.663
- 0.883
- 0.651
- 1.511
- 1.28
- 1.497
- 1.568
- 1.19
- 1.032
- 0.36
- 2.065
- 1.529
- 1.282
- 1.231
- 1.624
- 1.065
- 0.945
- 0.321
- 0.806
- 0.227
- 1.275
- 1.466
- 1.106
- 1.459
- 0.818
- 1.088
- 0.921
- 0.943
- 1.128
- 0.278
- 1.417
- 0.77
- 0.881
- 0.848
- 0.708
- 0.471
- 0.672
- 1.177
- 0.258
- 1.02
- 0.761
- 0.819
- 0.555
- 1.014
unequal: 0
verbose: 1
