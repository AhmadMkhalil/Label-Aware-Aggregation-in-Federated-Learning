avg_train_accuracy: 0.318
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0458
- 0.1016
- 0.1203
- 0.1392
- 0.1549
- 0.1664
- 0.1777
- 0.1857
- 0.1899
- 0.1924
- 0.2008
- 0.2054
- 0.2088
- 0.2167
- 0.2184
- 0.227
- 0.2306
- 0.2331
- 0.236
- 0.2408
- 0.2425
- 0.2422
- 0.2479
- 0.2522
- 0.2549
- 0.2572
- 0.2599
- 0.2628
- 0.2646
- 0.2671
- 0.2684
- 0.2727
- 0.2766
- 0.2768
- 0.28
- 0.2827
- 0.2808
- 0.2809
- 0.2837
- 0.2892
- 0.2912
- 0.2916
- 0.2913
- 0.2951
- 0.2962
- 0.296
- 0.2948
- 0.2991
- 0.3043
- 0.301
- 0.3001
- 0.3022
- 0.3059
- 0.3042
- 0.3067
- 0.3033
- 0.3055
- 0.3069
- 0.3096
- 0.3116
- 0.3081
- 0.3084
- 0.3108
- 0.3117
- 0.3129
- 0.3117
- 0.3151
- 0.3134
- 0.3131
- 0.3183
- 0.3141
- 0.3175
- 0.3195
- 0.3128
- 0.3177
- 0.316
- 0.3155
- 0.3201
- 0.3192
- 0.3171
- 0.3159
- 0.3218
- 0.3199
- 0.3231
- 0.3244
- 0.3216
- 0.3219
- 0.3219
- 0.3228
- 0.3249
- 0.3196
- 0.3246
- 0.323
- 0.3245
- 0.3256
- 0.3272
- 0.3228
- 0.3267
- 0.3275
- 0.3277
test_loss_list:
- 1.7724962186813356
- 1.6385666465759277
- 1.5841707324981689
- 1.545662021636963
- 1.5101491332054138
- 1.4814106822013855
- 1.4620329451560974
- 1.440886173248291
- 1.424430012702942
- 1.4115356945991515
- 1.3933134436607362
- 1.3797428941726684
- 1.365134859085083
- 1.355475356578827
- 1.344849374294281
- 1.3351256370544433
- 1.3275446105003357
- 1.3153998398780822
- 1.3064948105812073
- 1.294126012325287
- 1.2866748571395874
- 1.2825817608833312
- 1.275558159351349
- 1.2645448875427245
- 1.2619547581672668
- 1.2552941513061524
- 1.2488495898246765
- 1.2422146773338318
- 1.2368789911270142
- 1.2316504693031312
- 1.2253717160224915
- 1.2214368844032288
- 1.2138459658622742
- 1.2117619681358338
- 1.2083531641960144
- 1.2031230235099792
- 1.2010450625419617
- 1.1988187384605409
- 1.1943458652496337
- 1.1920696806907654
- 1.1916153812408448
- 1.1889809942245484
- 1.1864649438858033
- 1.1804455018043518
- 1.1786021304130554
- 1.1755576539039612
- 1.175596284866333
- 1.174766936302185
- 1.17343501329422
- 1.1734226632118225
- 1.170094850063324
- 1.1670647525787354
- 1.1627502202987672
- 1.1650043964385985
- 1.1632074117660522
- 1.1622054052352906
- 1.1615206623077392
- 1.1627041220664978
- 1.1602290201187133
- 1.1582614064216614
- 1.1597504353523254
- 1.1587463521957397
- 1.1558766603469848
- 1.155202350616455
- 1.1547796392440797
- 1.1535624551773072
- 1.1489296913146974
- 1.151655786037445
- 1.1551151251792908
- 1.1493822097778321
- 1.1514718103408814
- 1.1537013697624205
- 1.1531114864349366
- 1.153332495689392
- 1.1490953016281127
- 1.1519114685058593
- 1.1494623494148255
- 1.1494287753105163
- 1.1504113817214965
- 1.1540528893470765
- 1.1545739126205445
- 1.1503566098213196
- 1.152250943183899
- 1.152773575782776
- 1.1506216263771056
- 1.1537211179733275
- 1.1516324496269226
- 1.151034643650055
- 1.1529184150695801
- 1.1525245118141174
- 1.1536274504661561
- 1.1524065947532653
- 1.152721426486969
- 1.1534862613677979
- 1.15552401304245
- 1.1542498421669007
- 1.1534033346176147
- 1.1523517489433288
- 1.1543699169158936
- 1.155831036567688
train_accuracy:
- 0.041
- 0.102
- 0.116
- 0.115
- 0.0
- 0.154
- 0.155
- 0.156
- 0.176
- 0.185
- 0.177
- 0.194
- 0.185
- 0.147
- 0.216
- 0.209
- 0.216
- 0.213
- 0.221
- 0.241
- 0.214
- 0.227
- 0.251
- 0.255
- 0.0
- 0.223
- 0.0
- 0.223
- 0.268
- 0.232
- 0.245
- 0.237
- 0.25
- 0.24
- 0.284
- 0.0
- 0.223
- 0.237
- 0.271
- 0.27
- 0.291
- 0.272
- 0.3
- 0.272
- 0.287
- 0.3
- 0.291
- 0.247
- 0.296
- 0.251
- 0.245
- 0.246
- 0.294
- 0.299
- 0.309
- 0.307
- 0.298
- 0.312
- 0.302
- 0.254
- 0.27
- 0.319
- 0.343
- 0.283
- 0.288
- 0.308
- 0.32
- 0.298
- 0.317
- 0.31
- 0.317
- 0.27
- 0.303
- 0.328
- 0.296
- 0.301
- 0.328
- 0.309
- 0.311
- 0.301
- 0.3
- 0.0
- 0.32
- 0.321
- 0.34
- 0.292
- 0.316
- 0.311
- 0.0
- 0.348
- 0.0
- 0.0
- 0.314
- 0.318
- 0.342
- 0.344
- 0.365
- 0.0
- 0.326
- 0.318
train_loss:
- 4.34
- 3.865
- 3.212
- 3.501
- 2.964
- 2.862
- 3.142
- 3.041
- 2.641
- 2.888
- 2.478
- 2.741
- 2.347
- 2.605
- 2.24
- 2.444
- 2.116
- 2.15
- 2.065
- 2.027
- 1.974
- 1.906
- 1.876
- 1.83
- 1.762
- 1.967
- 1.711
- 1.651
- 1.618
- 1.571
- 1.602
- 1.546
- 1.525
- 1.48
- 1.425
- 1.432
- 1.549
- 1.333
- 1.308
- 1.424
- 1.257
- 1.354
- 1.199
- 1.151
- 1.128
- 1.238
- 1.208
- 1.16
- 1.055
- 0.975
- 1.025
- 0.982
- 0.94
- 0.921
- 0.981
- 0.869
- 0.943
- 0.819
- 0.911
- 0.909
- 0.808
- 0.736
- 0.728
- 0.738
- 0.778
- 0.711
- 0.705
- 0.666
- 0.698
- 0.698
- 0.604
- 0.594
- 0.604
- 0.614
- 0.634
- 0.589
- 0.558
- 0.58
- 0.562
- 0.522
- 0.511
- 0.491
- 0.477
- 0.483
- 0.502
- 0.448
- 0.454
- 0.429
- 0.422
- 0.455
- 0.443
- 0.437
- 0.385
- 0.408
- 0.377
- 0.39
- 0.374
- 0.357
- 0.361
- 0.367
unequal: 0
verbose: 1
