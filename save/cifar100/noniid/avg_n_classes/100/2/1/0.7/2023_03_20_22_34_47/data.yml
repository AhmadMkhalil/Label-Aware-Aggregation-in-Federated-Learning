avg_train_accuracy: 0.336
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0329
- 0.0872
- 0.1058
- 0.1237
- 0.1396
- 0.1537
- 0.1661
- 0.1741
- 0.1891
- 0.1936
- 0.203
- 0.2112
- 0.2157
- 0.226
- 0.2237
- 0.2306
- 0.2339
- 0.2425
- 0.2468
- 0.2503
- 0.2507
- 0.2568
- 0.2619
- 0.2638
- 0.265
- 0.2676
- 0.2697
- 0.2754
- 0.2817
- 0.279
- 0.2809
- 0.2809
- 0.2849
- 0.2895
- 0.2911
- 0.2925
- 0.2961
- 0.2969
- 0.3022
- 0.2989
- 0.2971
- 0.3024
- 0.3013
- 0.3054
- 0.3008
- 0.3056
- 0.3063
- 0.3079
- 0.308
- 0.31
- 0.3116
- 0.3155
- 0.3153
- 0.3187
- 0.3198
- 0.3154
- 0.3168
- 0.3168
- 0.3183
- 0.3169
- 0.3155
- 0.3195
- 0.3201
- 0.3248
- 0.3259
- 0.3182
- 0.3257
- 0.3287
- 0.3254
- 0.3252
- 0.321
- 0.3255
- 0.3239
- 0.3284
- 0.3274
- 0.3261
- 0.3295
- 0.3305
- 0.3294
- 0.3295
- 0.3319
- 0.3328
- 0.3276
- 0.332
- 0.3326
- 0.3302
- 0.3305
- 0.3305
- 0.3321
- 0.3321
- 0.3308
- 0.3333
- 0.3327
- 0.3299
- 0.3337
- 0.3318
- 0.3366
- 0.3339
- 0.3346
- 0.3345
test_loss_list:
- 1.7860882663726807
- 1.6487477445602416
- 1.590039722919464
- 1.5437613368034362
- 1.5110925459861755
- 1.479557158946991
- 1.4556549406051635
- 1.43482675075531
- 1.4162382984161377
- 1.4018545937538147
- 1.3837018871307374
- 1.3705735993385315
- 1.3556949853897096
- 1.3443682312965393
- 1.3303073573112487
- 1.3172061443328857
- 1.3098253846168517
- 1.2989605712890624
- 1.2905433988571167
- 1.2830421781539918
- 1.2762848901748658
- 1.2660755729675293
- 1.2605740022659302
- 1.2570823526382446
- 1.2479017496109008
- 1.242155659198761
- 1.2375418639183045
- 1.2318490362167358
- 1.226470422744751
- 1.2204694223403931
- 1.2153710889816285
- 1.2145575499534607
- 1.2088922810554505
- 1.2010173034667968
- 1.1952995681762695
- 1.1901132130622865
- 1.1887910342216492
- 1.1859044671058654
- 1.1817931938171387
- 1.1794237565994263
- 1.1760383343696594
- 1.1718919682502746
- 1.1718938422203065
- 1.1670057702064514
- 1.1661983466148376
- 1.166598687171936
- 1.1673290085792543
- 1.159375696182251
- 1.1593267560005187
- 1.1559213662147523
- 1.1543364381790162
- 1.153018524646759
- 1.15666645526886
- 1.150503578186035
- 1.1497507095336914
- 1.15125422000885
- 1.1529577684402466
- 1.1496755433082582
- 1.1495624780654907
- 1.144109046459198
- 1.1492546725273132
- 1.1450246334075929
- 1.1453854656219482
- 1.1434248352050782
- 1.1422514271736146
- 1.1510519552230836
- 1.1409683156013488
- 1.143617208003998
- 1.1424933862686157
- 1.1455726265907287
- 1.1448813462257386
- 1.1411635494232177
- 1.1464727902412415
- 1.1391535878181458
- 1.1431938743591308
- 1.1378100109100342
- 1.1389084839820862
- 1.137174780368805
- 1.1374310231208802
- 1.1419549632072448
- 1.1410413527488708
- 1.1395280313491822
- 1.1493345379829407
- 1.1431089758872985
- 1.145041251182556
- 1.1445701718330383
- 1.142953667640686
- 1.1453852105140685
- 1.1433458256721496
- 1.144248504638672
- 1.1439659547805787
- 1.1418504810333252
- 1.1435910320281983
- 1.1439145994186402
- 1.1427412676811217
- 1.1449437260627746
- 1.1430167579650878
- 1.14348247051239
- 1.1475611186027528
- 1.1454769802093505
train_accuracy:
- 0.024
- 0.08
- 0.091
- 0.106
- 0.138
- 0.139
- 0.169
- 0.0
- 0.116
- 0.0
- 0.193
- 0.184
- 0.181
- 0.218
- 0.207
- 0.223
- 0.216
- 0.213
- 0.173
- 0.219
- 0.284
- 0.0
- 0.275
- 0.223
- 0.244
- 0.242
- 0.241
- 0.232
- 0.297
- 0.0
- 0.261
- 0.255
- 0.301
- 0.265
- 0.281
- 0.298
- 0.259
- 0.272
- 0.283
- 0.324
- 0.257
- 0.311
- 0.207
- 0.276
- 0.21
- 0.217
- 0.222
- 0.293
- 0.296
- 0.316
- 0.308
- 0.31
- 0.266
- 0.229
- 0.333
- 0.23
- 0.319
- 0.228
- 0.298
- 0.231
- 0.318
- 0.311
- 0.308
- 0.306
- 0.308
- 0.283
- 0.244
- 0.0
- 0.0
- 0.276
- 0.313
- 0.318
- 0.279
- 0.0
- 0.243
- 0.361
- 0.307
- 0.371
- 0.36
- 0.239
- 0.322
- 0.364
- 0.292
- 0.286
- 0.326
- 0.337
- 0.338
- 0.335
- 0.337
- 0.36
- 0.304
- 0.334
- 0.341
- 0.33
- 0.364
- 0.324
- 0.301
- 0.352
- 0.333
- 0.336
train_loss:
- 3.777
- 3.405
- 3.214
- 3.082
- 3.376
- 2.868
- 2.744
- 2.695
- 2.957
- 2.537
- 2.833
- 2.722
- 2.351
- 2.591
- 2.238
- 2.171
- 2.385
- 2.337
- 2.27
- 2.197
- 1.908
- 1.883
- 2.063
- 2.025
- 1.763
- 1.926
- 1.661
- 1.805
- 1.759
- 1.511
- 1.516
- 1.615
- 1.455
- 1.422
- 1.404
- 1.518
- 1.345
- 1.458
- 1.387
- 1.208
- 1.188
- 1.135
- 1.128
- 1.125
- 1.047
- 1.197
- 1.054
- 0.996
- 1.065
- 0.957
- 0.994
- 1.026
- 0.936
- 0.857
- 0.926
- 0.834
- 0.802
- 0.875
- 0.752
- 0.755
- 0.825
- 0.825
- 0.723
- 0.681
- 0.762
- 0.722
- 0.704
- 0.613
- 0.652
- 0.601
- 0.606
- 0.579
- 0.579
- 0.582
- 0.559
- 0.525
- 0.527
- 0.513
- 0.539
- 0.519
- 0.52
- 0.499
- 0.485
- 0.453
- 0.437
- 0.452
- 0.431
- 0.403
- 0.434
- 0.413
- 0.413
- 0.387
- 0.374
- 0.384
- 0.366
- 0.336
- 0.358
- 0.39
- 0.346
- 0.344
unequal: 0
verbose: 1
