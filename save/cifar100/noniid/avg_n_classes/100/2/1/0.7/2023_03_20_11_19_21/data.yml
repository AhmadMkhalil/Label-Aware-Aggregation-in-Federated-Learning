avg_train_accuracy: 0.309
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0487
- 0.0906
- 0.1172
- 0.1389
- 0.1492
- 0.159
- 0.1687
- 0.1803
- 0.1923
- 0.1978
- 0.2037
- 0.2114
- 0.2145
- 0.2192
- 0.2221
- 0.2291
- 0.2339
- 0.2335
- 0.2409
- 0.2448
- 0.247
- 0.2489
- 0.2502
- 0.2541
- 0.2557
- 0.2595
- 0.2603
- 0.2631
- 0.2649
- 0.2699
- 0.2758
- 0.2733
- 0.2774
- 0.2764
- 0.2802
- 0.2834
- 0.2813
- 0.2847
- 0.2872
- 0.2878
- 0.2919
- 0.291
- 0.2918
- 0.2955
- 0.2914
- 0.2954
- 0.2983
- 0.2966
- 0.3012
- 0.3048
- 0.301
- 0.3012
- 0.3021
- 0.3038
- 0.3054
- 0.303
- 0.3084
- 0.3078
- 0.306
- 0.3048
- 0.3121
- 0.3127
- 0.3105
- 0.3091
- 0.3142
- 0.316
- 0.3102
- 0.3139
- 0.3159
- 0.3156
- 0.3181
- 0.3152
- 0.318
- 0.3162
- 0.3197
- 0.3193
- 0.316
- 0.3211
- 0.3208
- 0.3199
- 0.3223
- 0.3218
- 0.3226
- 0.3207
- 0.3248
- 0.3222
- 0.324
- 0.3264
- 0.3237
- 0.3232
- 0.322
- 0.3277
- 0.3235
- 0.3286
- 0.3252
- 0.326
- 0.3242
- 0.3273
- 0.3275
- 0.3302
test_loss_list:
- 1.7723112535476684
- 1.6446805238723754
- 1.5837977743148803
- 1.5416077709197997
- 1.5071364784240722
- 1.4792869257926942
- 1.4614015817642212
- 1.4382281136512756
- 1.416867048740387
- 1.4010481595993043
- 1.3888984060287475
- 1.3779195833206177
- 1.3651635026931763
- 1.35381276845932
- 1.3479581999778747
- 1.338117687702179
- 1.328754291534424
- 1.3243822503089904
- 1.3106963348388672
- 1.302927191257477
- 1.2950126218795777
- 1.2849158000946046
- 1.276339931488037
- 1.269137647151947
- 1.2646783375740052
- 1.2604327845573424
- 1.2560030364990233
- 1.249564025402069
- 1.2443949460983277
- 1.2424102210998536
- 1.2329839634895325
- 1.2320988202095031
- 1.2244114565849304
- 1.2230652713775634
- 1.219216525554657
- 1.2145740652084351
- 1.2122880053520202
- 1.2086479139328004
- 1.2091687822341919
- 1.2036181354522706
- 1.2028610372543336
- 1.2038369703292846
- 1.1945360541343688
- 1.1986195707321168
- 1.1971188592910766
- 1.194229302406311
- 1.1890317058563233
- 1.1900355696678162
- 1.1876308512687683
- 1.1864394927024842
- 1.183343014717102
- 1.1835140347480775
- 1.1825048112869263
- 1.1771114897727966
- 1.1781928157806396
- 1.1804777455329896
- 1.1744826340675354
- 1.172834632396698
- 1.17467520236969
- 1.178137822151184
- 1.175398895740509
- 1.1732940649986268
- 1.1695067954063416
- 1.168973970413208
- 1.1710333943367004
- 1.168776285648346
- 1.1695052838325501
- 1.1700847911834718
- 1.169073188304901
- 1.1678335499763488
- 1.1673022842407226
- 1.1687139964103699
- 1.166422381401062
- 1.1681643438339233
- 1.1612176299095154
- 1.1673690247535706
- 1.170310492515564
- 1.1658535242080688
- 1.164263575077057
- 1.1667420363426209
- 1.1657402276992799
- 1.1665671348571778
- 1.1694096565246581
- 1.1688873195648193
- 1.1651135826110839
- 1.1693950963020325
- 1.169346466064453
- 1.1700375270843506
- 1.169673113822937
- 1.1693392658233643
- 1.1698459911346435
- 1.1695041847229004
- 1.1654470992088317
- 1.1672007322311402
- 1.1709711813926698
- 1.1715510630607604
- 1.1774240565299987
- 1.1719992876052856
- 1.172030370235443
- 1.1724017882347106
train_accuracy:
- 0.053
- 0.093
- 0.097
- 0.142
- 0.127
- 0.133
- 0.139
- 0.152
- 0.167
- 0.155
- 0.189
- 0.196
- 0.192
- 0.189
- 0.208
- 0.196
- 0.207
- 0.192
- 0.239
- 0.232
- 0.235
- 0.24
- 0.0
- 0.234
- 0.236
- 0.246
- 0.248
- 0.236
- 0.255
- 0.249
- 0.242
- 0.26
- 0.261
- 0.0
- 0.276
- 0.284
- 0.259
- 0.287
- 0.274
- 0.263
- 0.28
- 0.286
- 0.289
- 0.275
- 0.285
- 0.272
- 0.271
- 0.286
- 0.287
- 0.282
- 0.291
- 0.292
- 0.277
- 0.273
- 0.282
- 0.295
- 0.305
- 0.286
- 0.297
- 0.288
- 0.279
- 0.31
- 0.301
- 0.29
- 0.277
- 0.284
- 0.298
- 0.316
- 0.299
- 0.296
- 0.297
- 0.0
- 0.294
- 0.283
- 0.321
- 0.31
- 0.315
- 0.3
- 0.294
- 0.0
- 0.31
- 0.305
- 0.325
- 0.294
- 0.307
- 0.316
- 0.308
- 0.314
- 0.303
- 0.301
- 0.31
- 0.315
- 0.304
- 0.319
- 0.316
- 0.313
- 0.297
- 0.297
- 0.324
- 0.309
train_loss:
- 3.78
- 3.408
- 3.209
- 3.086
- 2.96
- 3.258
- 2.76
- 2.707
- 2.625
- 2.889
- 2.817
- 2.727
- 2.683
- 2.599
- 2.553
- 2.473
- 2.435
- 2.122
- 2.314
- 2.022
- 1.977
- 1.928
- 1.875
- 2.051
- 1.781
- 1.732
- 1.732
- 1.865
- 1.623
- 1.61
- 1.572
- 1.501
- 1.537
- 1.444
- 1.616
- 1.401
- 1.382
- 1.334
- 1.473
- 1.284
- 1.277
- 1.231
- 1.329
- 1.158
- 1.123
- 1.073
- 1.191
- 1.026
- 1.09
- 1.006
- 1.011
- 0.963
- 1.034
- 0.92
- 0.895
- 0.873
- 0.978
- 0.822
- 0.862
- 0.757
- 0.894
- 0.797
- 0.784
- 0.743
- 0.802
- 0.749
- 0.675
- 0.736
- 0.631
- 0.632
- 0.692
- 0.612
- 0.618
- 0.595
- 0.575
- 0.584
- 0.553
- 0.507
- 0.539
- 0.522
- 0.553
- 0.539
- 0.51
- 0.483
- 0.484
- 0.481
- 0.473
- 0.449
- 0.427
- 0.429
- 0.403
- 0.418
- 0.398
- 0.413
- 0.401
- 0.374
- 0.364
- 0.382
- 0.354
- 0.352
unequal: 0
verbose: 1
