avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0388
- 0.0965
- 0.122
- 0.1364
- 0.1495
- 0.1585
- 0.1727
- 0.1819
- 0.1895
- 0.1968
- 0.2024
- 0.2082
- 0.2104
- 0.2205
- 0.2246
- 0.2306
- 0.2329
- 0.2334
- 0.2371
- 0.24
- 0.2455
- 0.2482
- 0.2532
- 0.2575
- 0.2574
- 0.2599
- 0.2633
- 0.2652
- 0.2712
- 0.2695
- 0.2702
- 0.2785
- 0.2754
- 0.2777
- 0.2804
- 0.2824
- 0.2825
- 0.2833
- 0.287
- 0.2903
- 0.2922
- 0.2917
- 0.2938
- 0.2941
- 0.2963
- 0.2944
- 0.2987
- 0.2973
- 0.3005
- 0.3004
- 0.3053
- 0.3006
- 0.3027
- 0.3033
- 0.3026
- 0.3072
- 0.3084
- 0.3087
- 0.3109
- 0.3116
- 0.311
- 0.3118
- 0.3127
- 0.3147
- 0.3135
- 0.315
- 0.3162
- 0.3154
- 0.3147
- 0.3152
- 0.3183
- 0.3164
- 0.3205
- 0.3193
- 0.3215
- 0.322
- 0.3229
- 0.3231
- 0.3204
- 0.3223
- 0.3243
- 0.3248
- 0.3242
- 0.3271
- 0.3243
- 0.3226
- 0.3261
- 0.3276
- 0.3261
- 0.3286
- 0.3285
- 0.3315
- 0.3295
- 0.3322
- 0.3288
- 0.3286
- 0.3285
- 0.3323
- 0.3322
- 0.3316
test_loss_list:
- 1.7828816986083984
- 1.6420723938941955
- 1.5843898272514343
- 1.541985330581665
- 1.50768239736557
- 1.4801700568199159
- 1.456596601009369
- 1.4329722118377686
- 1.4140293765068055
- 1.3973526191711425
- 1.3830205035209655
- 1.3713536214828492
- 1.3624750614166259
- 1.343265163898468
- 1.3340329790115357
- 1.3240200686454773
- 1.3137204337120056
- 1.306833357810974
- 1.2998700904846192
- 1.286739935874939
- 1.2775762867927551
- 1.272360544204712
- 1.262342736721039
- 1.2567620253562928
- 1.2517995953559875
- 1.2488976573944093
- 1.2425802612304688
- 1.2374900579452515
- 1.2344125413894653
- 1.2302645111083985
- 1.2226249623298644
- 1.2170222306251526
- 1.217226390838623
- 1.2150072622299195
- 1.2118385124206543
- 1.2057170486450195
- 1.20492746591568
- 1.199039912223816
- 1.1963368797302245
- 1.1948030734062194
- 1.191483874320984
- 1.1885209584236145
- 1.190936315059662
- 1.1861262726783752
- 1.1816777539253236
- 1.178456165790558
- 1.177364206314087
- 1.173870952129364
- 1.167761037349701
- 1.170000023841858
- 1.1684885263442992
- 1.166966109275818
- 1.1698077702522278
- 1.1701405930519104
- 1.1636293935775757
- 1.1603630518913268
- 1.1599454402923584
- 1.1600522089004517
- 1.1568269729614258
- 1.1564572262763977
- 1.1528300404548646
- 1.1538904523849487
- 1.153728256225586
- 1.153541295528412
- 1.1505846238136292
- 1.1516611576080322
- 1.1525174164772034
- 1.1523945665359496
- 1.1537008261680604
- 1.1503453969955444
- 1.150719096660614
- 1.1541999769210816
- 1.1480326461791992
- 1.1491080236434936
- 1.146871910095215
- 1.1509869885444641
- 1.1475704431533813
- 1.1453222513198853
- 1.1484006524086
- 1.1487757873535156
- 1.1479813647270203
- 1.1473541378974914
- 1.1462025713920594
- 1.1474986124038695
- 1.1504341769218445
- 1.151330213546753
- 1.1496803736686707
- 1.1496988344192505
- 1.1463282489776612
- 1.1450980234146118
- 1.1485098552703858
- 1.1476337623596191
- 1.1442235112190247
- 1.1479235005378723
- 1.149065158367157
- 1.1516755366325377
- 1.1508575916290282
- 1.1521683216094971
- 1.1535223460197448
- 1.1540281772613525
train_accuracy:
- 0.045
- 0.116
- 0.11
- 0.109
- 0.125
- 0.17
- 0.0
- 0.158
- 0.192
- 0.0
- 0.184
- 0.191
- 0.0
- 0.196
- 0.208
- 0.188
- 0.224
- 0.216
- 0.22
- 0.245
- 0.245
- 0.232
- 0.224
- 0.228
- 0.229
- 0.0
- 0.284
- 0.241
- 0.251
- 0.239
- 0.265
- 0.256
- 0.249
- 0.302
- 0.245
- 0.266
- 0.0
- 0.0
- 0.241
- 0.272
- 0.27
- 0.242
- 0.271
- 0.283
- 0.309
- 0.241
- 0.273
- 0.0
- 0.273
- 0.277
- 0.286
- 0.287
- 0.303
- 0.289
- 0.0
- 0.264
- 0.291
- 0.297
- 0.287
- 0.274
- 0.314
- 0.349
- 0.292
- 0.298
- 0.268
- 0.36
- 0.281
- 0.299
- 0.299
- 0.314
- 0.305
- 0.287
- 0.0
- 0.297
- 0.285
- 0.35
- 0.376
- 0.316
- 0.365
- 0.0
- 0.293
- 0.325
- 0.367
- 0.284
- 0.321
- 0.37
- 0.312
- 0.301
- 0.288
- 0.327
- 0.295
- 0.284
- 0.29
- 0.307
- 0.296
- 0.326
- 0.318
- 0.299
- 0.302
- 0.0
train_loss:
- 3.838
- 3.425
- 3.708
- 3.52
- 2.996
- 2.882
- 2.801
- 2.711
- 2.657
- 2.559
- 2.814
- 2.422
- 2.386
- 2.348
- 2.578
- 2.238
- 2.163
- 2.104
- 2.055
- 2.037
- 1.977
- 1.903
- 1.88
- 1.829
- 1.799
- 1.73
- 1.962
- 1.874
- 1.615
- 1.65
- 1.579
- 1.746
- 1.652
- 1.657
- 1.478
- 1.408
- 1.399
- 1.345
- 1.3
- 1.44
- 1.413
- 1.333
- 1.17
- 1.152
- 1.125
- 1.178
- 1.087
- 1.024
- 1.094
- 1.035
- 1.095
- 1.069
- 1.049
- 0.933
- 0.933
- 0.89
- 0.926
- 0.866
- 0.844
- 0.823
- 0.798
- 0.747
- 0.82
- 0.815
- 0.735
- 0.72
- 0.745
- 0.748
- 0.652
- 0.655
- 0.679
- 0.614
- 0.593
- 0.586
- 0.561
- 0.558
- 0.587
- 0.544
- 0.519
- 0.52
- 0.499
- 0.495
- 0.501
- 0.461
- 0.498
- 0.454
- 0.437
- 0.43
- 0.434
- 0.447
- 0.421
- 0.411
- 0.398
- 0.394
- 0.396
- 0.366
- 0.371
- 0.364
- 0.361
- 0.359
unequal: 0
verbose: 1
