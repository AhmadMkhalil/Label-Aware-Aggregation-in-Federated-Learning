avg_train_accuracy: 0.324
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0469
- 0.0952
- 0.1177
- 0.1344
- 0.149
- 0.1608
- 0.1713
- 0.1807
- 0.1895
- 0.1955
- 0.2057
- 0.2104
- 0.2145
- 0.2202
- 0.2243
- 0.234
- 0.2362
- 0.2412
- 0.2429
- 0.2447
- 0.2509
- 0.2481
- 0.2566
- 0.2589
- 0.2602
- 0.2653
- 0.2614
- 0.2689
- 0.2697
- 0.2736
- 0.2745
- 0.2771
- 0.2775
- 0.2777
- 0.2801
- 0.281
- 0.2846
- 0.2842
- 0.2875
- 0.2869
- 0.2924
- 0.2922
- 0.2941
- 0.2969
- 0.2977
- 0.2975
- 0.3019
- 0.2995
- 0.3007
- 0.3007
- 0.3035
- 0.3003
- 0.3033
- 0.3063
- 0.3062
- 0.3075
- 0.3084
- 0.3053
- 0.3077
- 0.3113
- 0.3084
- 0.3084
- 0.3092
- 0.3095
- 0.3117
- 0.3131
- 0.3144
- 0.3102
- 0.3133
- 0.3174
- 0.3153
- 0.3134
- 0.317
- 0.3147
- 0.3175
- 0.3163
- 0.3145
- 0.3156
- 0.3155
- 0.3217
- 0.3169
- 0.3177
- 0.3197
- 0.3198
- 0.3218
- 0.319
- 0.3225
- 0.3202
- 0.3225
- 0.322
- 0.3238
- 0.3213
- 0.3239
- 0.3233
- 0.3199
- 0.3221
- 0.3257
- 0.3267
- 0.3241
- 0.3212
test_loss_list:
- 1.7822472906112672
- 1.6468342280387878
- 1.5910030555725099
- 1.5435920763015747
- 1.5054118633270264
- 1.4788569259643554
- 1.4573043060302735
- 1.4368509006500245
- 1.4217028260231017
- 1.4013680338859558
- 1.3858702707290649
- 1.3715954613685608
- 1.359858512878418
- 1.3482182097434998
- 1.337796368598938
- 1.3229654407501221
- 1.3129810547828675
- 1.3047901058197022
- 1.2947481322288512
- 1.2867352342605591
- 1.2797259998321533
- 1.272411241531372
- 1.26354731798172
- 1.260960726737976
- 1.2534344148635865
- 1.2460585188865663
- 1.2411973428726197
- 1.2361436676979065
- 1.2298759508132935
- 1.2235684204101562
- 1.2216774725914001
- 1.2166653704643249
- 1.2161394786834716
- 1.2097133374214173
- 1.2079837274551393
- 1.204674346446991
- 1.2013916683197021
- 1.2023789715766906
- 1.199133689403534
- 1.1953001475334168
- 1.1918873524665832
- 1.1910898828506469
- 1.186618971824646
- 1.1839970827102662
- 1.1806227517127992
- 1.181354854106903
- 1.1818264174461364
- 1.1796518564224243
- 1.1766588163375855
- 1.1719201397895813
- 1.1692807364463806
- 1.1706241512298583
- 1.1718148589134216
- 1.1713394522666931
- 1.1702312779426576
- 1.167294547557831
- 1.16504417181015
- 1.167841989994049
- 1.1644542336463928
- 1.1644139337539672
- 1.1623836636543274
- 1.160124261379242
- 1.1627746367454528
- 1.1587836647033691
- 1.1575238394737244
- 1.1568675804138184
- 1.1557619953155518
- 1.1592819666862488
- 1.1575375151634217
- 1.1542212677001953
- 1.1570747470855713
- 1.1604979181289672
- 1.1580173563957215
- 1.1562445402145385
- 1.1565525126457215
- 1.1589913749694825
- 1.1558159685134888
- 1.1564830040931702
- 1.1578811454772948
- 1.1560288786888122
- 1.1532753539085387
- 1.1561567497253418
- 1.154924852848053
- 1.1563423848152161
- 1.154443507194519
- 1.161358699798584
- 1.1571574997901917
- 1.1612752604484557
- 1.159802258014679
- 1.1565746474266052
- 1.1574784469604493
- 1.159859848022461
- 1.1591975331306457
- 1.1621643924713134
- 1.1627134799957275
- 1.1646235370635987
- 1.1605263543128967
- 1.163797879219055
- 1.1636495351791383
- 1.1636381697654725
train_accuracy:
- 0.05
- 0.125
- 0.079
- 0.0
- 0.114
- 0.146
- 0.152
- 0.213
- 0.209
- 0.174
- 0.225
- 0.247
- 0.234
- 0.237
- 0.254
- 0.237
- 0.26
- 0.26
- 0.235
- 0.266
- 0.285
- 0.236
- 0.235
- 0.196
- 0.0
- 0.251
- 0.243
- 0.28
- 0.0
- 0.281
- 0.284
- 0.0
- 0.274
- 0.271
- 0.33
- 0.212
- 0.285
- 0.269
- 0.254
- 0.299
- 0.225
- 0.32
- 0.301
- 0.323
- 0.277
- 0.306
- 0.0
- 0.281
- 0.278
- 0.241
- 0.0
- 0.314
- 0.3
- 0.358
- 0.327
- 0.0
- 0.288
- 0.243
- 0.0
- 0.0
- 0.295
- 0.0
- 0.294
- 0.32
- 0.317
- 0.0
- 0.291
- 0.26
- 0.342
- 0.358
- 0.325
- 0.343
- 0.299
- 0.34
- 0.258
- 0.329
- 0.311
- 0.263
- 0.327
- 0.322
- 0.375
- 0.0
- 0.315
- 0.331
- 0.306
- 0.0
- 0.32
- 0.291
- 0.0
- 0.318
- 0.0
- 0.318
- 0.34
- 0.316
- 0.362
- 0.355
- 0.324
- 0.346
- 0.329
- 0.324
train_loss:
- 4.339
- 3.411
- 3.67
- 3.07
- 2.935
- 3.222
- 3.133
- 2.685
- 2.612
- 2.538
- 2.461
- 2.731
- 2.311
- 2.574
- 2.268
- 2.179
- 2.159
- 2.079
- 2.053
- 2.286
- 2.206
- 1.911
- 1.888
- 2.028
- 1.805
- 1.781
- 1.71
- 1.873
- 1.642
- 1.589
- 1.764
- 1.523
- 1.463
- 1.438
- 1.401
- 1.366
- 1.52
- 1.328
- 1.471
- 1.285
- 1.389
- 1.238
- 1.185
- 1.157
- 1.129
- 1.225
- 1.066
- 1.033
- 1.037
- 0.998
- 1.016
- 1.043
- 0.896
- 0.981
- 0.923
- 0.856
- 0.818
- 0.782
- 0.811
- 0.82
- 0.801
- 0.777
- 0.775
- 0.741
- 0.694
- 0.713
- 0.693
- 0.656
- 0.631
- 0.658
- 0.614
- 0.615
- 0.645
- 0.604
- 0.589
- 0.538
- 0.528
- 0.508
- 0.526
- 0.52
- 0.52
- 0.514
- 0.483
- 0.464
- 0.484
- 0.466
- 0.446
- 0.425
- 0.447
- 0.426
- 0.421
- 0.41
- 0.414
- 0.423
- 0.377
- 0.355
- 0.352
- 0.372
- 0.351
- 0.355
unequal: 0
verbose: 1
