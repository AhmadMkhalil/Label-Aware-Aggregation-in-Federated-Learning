avg_train_accuracy: 0.289
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0501
- 0.096
- 0.12
- 0.1326
- 0.148
- 0.1629
- 0.1709
- 0.1793
- 0.1877
- 0.1955
- 0.2054
- 0.2112
- 0.2149
- 0.2236
- 0.2288
- 0.2294
- 0.2374
- 0.2391
- 0.2479
- 0.2506
- 0.2551
- 0.2543
- 0.2586
- 0.26
- 0.2613
- 0.2651
- 0.2698
- 0.272
- 0.2727
- 0.2757
- 0.2793
- 0.2819
- 0.2845
- 0.2861
- 0.287
- 0.2911
- 0.2863
- 0.2918
- 0.2918
- 0.2955
- 0.2945
- 0.3008
- 0.3001
- 0.2981
- 0.2971
- 0.3054
- 0.3049
- 0.3079
- 0.3062
- 0.3101
- 0.3133
- 0.3122
- 0.3104
- 0.3134
- 0.314
- 0.313
- 0.3146
- 0.3183
- 0.3158
- 0.3184
- 0.3213
- 0.3165
- 0.3151
- 0.3221
- 0.3147
- 0.3149
- 0.3221
- 0.3224
- 0.324
- 0.3204
- 0.3221
- 0.3222
- 0.3218
- 0.3236
- 0.3239
- 0.3223
- 0.3232
- 0.3291
- 0.3284
- 0.3318
- 0.3247
- 0.3251
- 0.3223
- 0.326
- 0.3268
- 0.3261
- 0.3225
- 0.3246
- 0.3282
- 0.3273
- 0.3302
- 0.331
- 0.3304
- 0.3294
- 0.3317
- 0.3287
- 0.3292
- 0.3338
- 0.3314
- 0.3317
test_loss_list:
- 1.778063850402832
- 1.642032630443573
- 1.5882644367218017
- 1.5456550979614259
- 1.511406044960022
- 1.4793123626708984
- 1.455373249053955
- 1.435235426425934
- 1.4167355370521546
- 1.401609058380127
- 1.3833949446678162
- 1.3674038887023925
- 1.3585536932945252
- 1.3438431882858277
- 1.3364373016357423
- 1.3253956127166748
- 1.3120928621292114
- 1.305934534072876
- 1.2910974717140198
- 1.2842401385307312
- 1.278619303703308
- 1.271861925125122
- 1.2646501421928407
- 1.2574087047576905
- 1.2515767431259155
- 1.2433134055137633
- 1.2388241696357727
- 1.2345148968696593
- 1.2277983856201171
- 1.21850745677948
- 1.216646602153778
- 1.2096419286727906
- 1.2033476042747497
- 1.2010334634780884
- 1.1999939584732056
- 1.1918998503684997
- 1.1924270391464233
- 1.1873061752319336
- 1.1848511147499083
- 1.1822844982147216
- 1.1792508459091187
- 1.1743448328971864
- 1.172332603931427
- 1.1733238124847412
- 1.1658588910102845
- 1.1637638902664185
- 1.1663703107833863
- 1.161138117313385
- 1.1651698875427245
- 1.1594788575172423
- 1.1554839301109314
- 1.1541897320747376
- 1.152636685371399
- 1.1528291368484498
- 1.1530508685112
- 1.1507993531227112
- 1.1474451756477355
- 1.1494685530662536
- 1.1444088459014892
- 1.1431382036209106
- 1.1439312243461608
- 1.1432325005531312
- 1.1463034439086914
- 1.1399979615211486
- 1.1498861026763916
- 1.1464746880531311
- 1.1380312538146973
- 1.1412798762321472
- 1.135483660697937
- 1.1378593301773072
- 1.139306790828705
- 1.1346109318733215
- 1.141636061668396
- 1.1390874552726746
- 1.1397828602790832
- 1.1381195497512817
- 1.1403114891052246
- 1.1351366257667541
- 1.134940903186798
- 1.13503981590271
- 1.1379420828819276
- 1.1350449347496032
- 1.1360901284217835
- 1.1371992349624633
- 1.1378683996200563
- 1.1382092809677125
- 1.1383451843261718
- 1.1374819231033326
- 1.1382262539863586
- 1.1405661582946778
- 1.138607668876648
- 1.1411923933029176
- 1.1411894583702087
- 1.1399428033828736
- 1.138818564414978
- 1.1410739707946778
- 1.1484328484535218
- 1.1404523134231568
- 1.1447679495811462
- 1.1447499775886536
train_accuracy:
- 0.056
- 0.101
- 0.141
- 0.137
- 0.114
- 0.0
- 0.129
- 0.0
- 0.185
- 0.122
- 0.0
- 0.219
- 0.144
- 0.229
- 0.203
- 0.0
- 0.237
- 0.229
- 0.253
- 0.174
- 0.186
- 0.246
- 0.204
- 0.263
- 0.282
- 0.202
- 0.204
- 0.201
- 0.272
- 0.265
- 0.293
- 0.282
- 0.212
- 0.246
- 0.271
- 0.22
- 0.259
- 0.247
- 0.0
- 0.0
- 0.237
- 0.254
- 0.0
- 0.235
- 0.316
- 0.352
- 0.285
- 0.357
- 0.354
- 0.251
- 0.293
- 0.272
- 0.252
- 0.265
- 0.323
- 0.309
- 0.306
- 0.286
- 0.32
- 0.286
- 0.384
- 0.285
- 0.301
- 0.0
- 0.33
- 0.316
- 0.315
- 0.297
- 0.312
- 0.331
- 0.314
- 0.275
- 0.265
- 0.275
- 0.312
- 0.293
- 0.278
- 0.0
- 0.317
- 0.31
- 0.322
- 0.326
- 0.311
- 0.303
- 0.352
- 0.327
- 0.316
- 0.321
- 0.288
- 0.281
- 0.279
- 0.311
- 0.335
- 0.279
- 0.275
- 0.397
- 0.329
- 0.367
- 0.319
- 0.289
train_loss:
- 3.786
- 3.902
- 3.654
- 3.057
- 2.951
- 2.854
- 2.766
- 2.693
- 2.606
- 2.896
- 2.487
- 2.417
- 2.658
- 2.596
- 2.542
- 2.177
- 2.427
- 2.088
- 2.096
- 2.014
- 2.217
- 1.917
- 1.873
- 1.834
- 1.775
- 1.753
- 1.895
- 1.671
- 1.656
- 1.624
- 1.747
- 1.546
- 1.516
- 1.46
- 1.413
- 1.387
- 1.391
- 1.475
- 1.284
- 1.275
- 1.238
- 1.355
- 1.185
- 1.142
- 1.157
- 1.233
- 1.232
- 1.037
- 1.117
- 1.047
- 1.102
- 1.091
- 0.949
- 1.039
- 0.99
- 0.871
- 0.855
- 0.793
- 0.855
- 0.773
- 0.853
- 0.789
- 0.763
- 0.739
- 0.705
- 0.701
- 0.776
- 0.714
- 0.681
- 0.62
- 0.655
- 0.616
- 0.666
- 0.563
- 0.554
- 0.58
- 0.545
- 0.538
- 0.516
- 0.533
- 0.541
- 0.523
- 0.494
- 0.452
- 0.476
- 0.46
- 0.437
- 0.434
- 0.46
- 0.413
- 0.42
- 0.417
- 0.446
- 0.376
- 0.417
- 0.395
- 0.373
- 0.407
- 0.36
- 0.356
unequal: 0
verbose: 1
