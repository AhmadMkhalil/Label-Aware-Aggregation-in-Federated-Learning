avg_train_accuracy: 0.279
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0431
- 0.0976
- 0.1186
- 0.1338
- 0.1499
- 0.1615
- 0.172
- 0.1783
- 0.1885
- 0.1976
- 0.2048
- 0.211
- 0.2167
- 0.2241
- 0.2291
- 0.2379
- 0.2396
- 0.2433
- 0.2488
- 0.2516
- 0.2568
- 0.2613
- 0.2652
- 0.2632
- 0.2676
- 0.2721
- 0.2771
- 0.2746
- 0.2772
- 0.2808
- 0.2792
- 0.285
- 0.2825
- 0.2832
- 0.2897
- 0.293
- 0.2879
- 0.2948
- 0.2931
- 0.2969
- 0.2987
- 0.2981
- 0.2963
- 0.302
- 0.3037
- 0.304
- 0.3056
- 0.3024
- 0.3077
- 0.3082
- 0.3052
- 0.3089
- 0.3087
- 0.3103
- 0.3104
- 0.3096
- 0.3091
- 0.3127
- 0.3129
- 0.3129
- 0.313
- 0.3159
- 0.3124
- 0.3139
- 0.3178
- 0.3175
- 0.3183
- 0.3196
- 0.3167
- 0.3191
- 0.3191
- 0.3181
- 0.3197
- 0.3178
- 0.32
- 0.3186
- 0.3196
- 0.3183
- 0.3217
- 0.3207
- 0.3184
- 0.3207
- 0.3245
- 0.3224
- 0.3228
- 0.3223
- 0.3243
- 0.3234
- 0.3215
- 0.3224
- 0.3251
- 0.3248
- 0.3259
- 0.3234
- 0.3237
- 0.3258
- 0.3246
- 0.3201
- 0.3247
- 0.3228
test_loss_list:
- 1.773568925857544
- 1.6372296166419984
- 1.5778077340126038
- 1.5398432731628418
- 1.5048759293556213
- 1.4768208265304565
- 1.4532004928588866
- 1.4353975248336792
- 1.4147184705734253
- 1.3988726258277893
- 1.3862307047843934
- 1.3703200674057008
- 1.357118968963623
- 1.3449930262565613
- 1.333790009021759
- 1.3183470368385315
- 1.309950017929077
- 1.3012115383148193
- 1.2929365539550781
- 1.2818637418746948
- 1.2728348064422608
- 1.2663148164749145
- 1.2609297037124634
- 1.2581959652900696
- 1.2484314227104187
- 1.2400803661346436
- 1.2363352608680724
- 1.2296906042098998
- 1.220747938156128
- 1.2174610543251037
- 1.2141885781288146
- 1.206372034549713
- 1.2047694873809816
- 1.2022140741348266
- 1.195274441242218
- 1.1889938855171203
- 1.1851387453079223
- 1.1822988629341125
- 1.179526343345642
- 1.1785737776756287
- 1.1786064910888672
- 1.183603515625
- 1.17923969745636
- 1.169689655303955
- 1.1764949131011964
- 1.1703646087646484
- 1.1664012360572815
- 1.162801525592804
- 1.162624683380127
- 1.1603710389137267
- 1.160730800628662
- 1.1594162821769713
- 1.157590820789337
- 1.1558291912078857
- 1.1557901978492737
- 1.1540922355651855
- 1.1547978496551514
- 1.1500240778923034
- 1.1532266998291016
- 1.1522830128669739
- 1.15075364112854
- 1.14955632686615
- 1.1483728623390197
- 1.1481040191650391
- 1.1464185547828674
- 1.149345462322235
- 1.1485873222351075
- 1.1451043152809144
- 1.1465134501457215
- 1.1460533809661866
- 1.146337113380432
- 1.1459450101852418
- 1.14183566570282
- 1.1459427928924562
- 1.1446109366416932
- 1.1460172295570374
- 1.1447093439102174
- 1.1503156089782716
- 1.143608672618866
- 1.1466474843025207
- 1.1497213077545165
- 1.1436951518058778
- 1.1470032715797425
- 1.1459607005119323
- 1.149122178554535
- 1.1504663372039794
- 1.147849223613739
- 1.146667513847351
- 1.1471695494651795
- 1.1476215624809265
- 1.151523699760437
- 1.146784358024597
- 1.1514827394485474
- 1.1464916038513184
- 1.1502115154266357
- 1.1460893487930297
- 1.14771390914917
- 1.1512655901908875
- 1.1519394755363463
- 1.15132595539093
train_accuracy:
- 0.038
- 0.101
- 0.117
- 0.149
- 0.132
- 0.174
- 0.144
- 0.166
- 0.197
- 0.205
- 0.162
- 0.216
- 0.163
- 0.196
- 0.175
- 0.0
- 0.224
- 0.184
- 0.211
- 0.229
- 0.22
- 0.241
- 0.225
- 0.227
- 0.237
- 0.238
- 0.253
- 0.245
- 0.0
- 0.231
- 0.0
- 0.258
- 0.0
- 0.227
- 0.251
- 0.292
- 0.222
- 0.297
- 0.272
- 0.275
- 0.276
- 0.284
- 0.292
- 0.298
- 0.0
- 0.286
- 0.268
- 0.289
- 0.276
- 0.292
- 0.303
- 0.302
- 0.296
- 0.0
- 0.317
- 0.253
- 0.317
- 0.326
- 0.314
- 0.328
- 0.32
- 0.323
- 0.336
- 0.273
- 0.298
- 0.307
- 0.315
- 0.31
- 0.281
- 0.316
- 0.257
- 0.0
- 0.294
- 0.263
- 0.26
- 0.288
- 0.31
- 0.276
- 0.275
- 0.332
- 0.315
- 0.28
- 0.342
- 0.265
- 0.0
- 0.32
- 0.32
- 0.283
- 0.329
- 0.0
- 0.319
- 0.0
- 0.292
- 0.332
- 0.33
- 0.324
- 0.342
- 0.321
- 0.283
- 0.279
train_loss:
- 3.768
- 3.364
- 3.218
- 3.041
- 3.365
- 2.84
- 2.763
- 2.669
- 2.591
- 2.508
- 2.78
- 2.433
- 2.614
- 2.284
- 2.259
- 2.195
- 2.126
- 2.078
- 2.021
- 1.989
- 1.964
- 2.095
- 2.05
- 1.778
- 1.784
- 1.705
- 1.692
- 1.616
- 1.588
- 1.62
- 1.508
- 1.471
- 1.485
- 1.392
- 1.417
- 1.38
- 1.31
- 1.347
- 1.277
- 1.405
- 1.331
- 1.299
- 1.143
- 1.171
- 1.142
- 1.054
- 1.192
- 1.044
- 1.136
- 0.973
- 0.96
- 1.048
- 0.913
- 0.88
- 0.977
- 0.834
- 0.931
- 0.807
- 0.861
- 0.765
- 0.766
- 0.813
- 0.767
- 0.693
- 0.764
- 0.678
- 0.718
- 0.656
- 0.666
- 0.62
- 0.599
- 0.607
- 0.606
- 0.611
- 0.577
- 0.576
- 0.582
- 0.517
- 0.524
- 0.526
- 0.479
- 0.482
- 0.504
- 0.466
- 0.462
- 0.442
- 0.429
- 0.446
- 0.399
- 0.424
- 0.388
- 0.389
- 0.383
- 0.401
- 0.361
- 0.367
- 0.366
- 0.343
- 0.329
- 0.344
unequal: 0
verbose: 1
