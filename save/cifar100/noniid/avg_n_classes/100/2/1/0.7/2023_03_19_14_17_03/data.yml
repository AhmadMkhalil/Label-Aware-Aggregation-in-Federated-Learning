avg_train_accuracy: 0.292
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0381
- 0.0898
- 0.1124
- 0.1286
- 0.1428
- 0.1581
- 0.1614
- 0.1702
- 0.1822
- 0.1887
- 0.1985
- 0.2022
- 0.2049
- 0.2109
- 0.2164
- 0.222
- 0.227
- 0.232
- 0.2345
- 0.2366
- 0.2449
- 0.2478
- 0.2491
- 0.2513
- 0.2561
- 0.2568
- 0.2593
- 0.2649
- 0.2673
- 0.2736
- 0.2744
- 0.2759
- 0.2816
- 0.2814
- 0.2844
- 0.2866
- 0.2842
- 0.2858
- 0.2879
- 0.2939
- 0.2906
- 0.2942
- 0.2931
- 0.2979
- 0.2941
- 0.295
- 0.2994
- 0.3004
- 0.302
- 0.3036
- 0.3059
- 0.3074
- 0.3103
- 0.306
- 0.3081
- 0.3101
- 0.3124
- 0.3118
- 0.3094
- 0.3141
- 0.3139
- 0.3133
- 0.3136
- 0.3139
- 0.3155
- 0.3178
- 0.3185
- 0.3194
- 0.3231
- 0.322
- 0.3224
- 0.3203
- 0.3204
- 0.32
- 0.3201
- 0.3244
- 0.3246
- 0.3256
- 0.3246
- 0.3222
- 0.3223
- 0.3249
- 0.3224
- 0.3277
- 0.3272
- 0.3272
- 0.3272
- 0.325
- 0.3273
- 0.3274
- 0.3284
- 0.3291
- 0.3293
- 0.3316
- 0.3309
- 0.3287
- 0.3284
- 0.3299
- 0.3309
- 0.3299
test_loss_list:
- 1.7845872974395751
- 1.6458747959136963
- 1.5897608923912048
- 1.5460225653648376
- 1.5095266032218932
- 1.4811468267440795
- 1.455675916671753
- 1.4371484422683716
- 1.4182631993293762
- 1.4018498659133911
- 1.384512071609497
- 1.3718071365356446
- 1.35838134765625
- 1.3468317484855652
- 1.3365944600105286
- 1.3263902497291564
- 1.3134882688522338
- 1.3032614779472351
- 1.2975165677070617
- 1.2922973132133484
- 1.28241286277771
- 1.2747624683380128
- 1.2660170578956604
- 1.2570097208023072
- 1.2519992661476136
- 1.247383406162262
- 1.2416640734672546
- 1.235252299308777
- 1.2293589735031127
- 1.2186260938644409
- 1.2149375343322755
- 1.2080112600326538
- 1.208800232410431
- 1.2018523049354553
- 1.194358501434326
- 1.1911359882354737
- 1.189784836769104
- 1.1852396821975708
- 1.178762423992157
- 1.1755086612701415
- 1.1753038668632507
- 1.1709900546073913
- 1.1731646060943604
- 1.164191288948059
- 1.164786262512207
- 1.1601560258865355
- 1.1590110540390015
- 1.1602511191368103
- 1.1579855728149413
- 1.1558860445022583
- 1.1554807353019714
- 1.1548996591567993
- 1.1507336950302125
- 1.149506046772003
- 1.1474663376808167
- 1.1447696447372437
- 1.1466386699676514
- 1.1448008847236633
- 1.139910373687744
- 1.1428945422172547
- 1.1450385451316833
- 1.1449274396896363
- 1.1433863711357117
- 1.1436552381515503
- 1.1411945390701295
- 1.1401337385177612
- 1.142292935848236
- 1.1398104465007781
- 1.1415644884109497
- 1.1412722444534302
- 1.1426220965385436
- 1.1404538202285766
- 1.1399602591991425
- 1.1425860404968262
- 1.1445764636993407
- 1.1415562391281129
- 1.1421237993240356
- 1.1448425340652466
- 1.1430656361579894
- 1.1468557476997376
- 1.1427554130554198
- 1.1425637698173523
- 1.1419635581970216
- 1.140689537525177
- 1.1449863767623902
- 1.1458527874946594
- 1.1377143216133119
- 1.1452143716812133
- 1.1413603591918946
- 1.1451657474040986
- 1.144693512916565
- 1.1496270060539246
- 1.1482637119293213
- 1.150080292224884
- 1.1463464188575745
- 1.1527343416213989
- 1.1454053115844727
- 1.1447125554084778
- 1.1455079579353333
- 1.144460587501526
train_accuracy:
- 0.0
- 0.081
- 0.114
- 0.14
- 0.156
- 0.121
- 0.14
- 0.155
- 0.141
- 0.172
- 0.182
- 0.176
- 0.21
- 0.214
- 0.203
- 0.0
- 0.215
- 0.19
- 0.219
- 0.201
- 0.22
- 0.216
- 0.232
- 0.0
- 0.0
- 0.211
- 0.252
- 0.292
- 0.248
- 0.233
- 0.249
- 0.263
- 0.214
- 0.289
- 0.0
- 0.245
- 0.237
- 0.272
- 0.262
- 0.249
- 0.0
- 0.254
- 0.282
- 0.299
- 0.298
- 0.0
- 0.269
- 0.269
- 0.245
- 0.286
- 0.0
- 0.283
- 0.0
- 0.253
- 0.252
- 0.0
- 0.267
- 0.336
- 0.283
- 0.279
- 0.28
- 0.273
- 0.279
- 0.271
- 0.274
- 0.292
- 0.306
- 0.271
- 0.282
- 0.305
- 0.282
- 0.273
- 0.27
- 0.296
- 0.304
- 0.299
- 0.284
- 0.312
- 0.309
- 0.324
- 0.0
- 0.29
- 0.347
- 0.0
- 0.299
- 0.279
- 0.0
- 0.324
- 0.283
- 0.304
- 0.267
- 0.305
- 0.306
- 0.288
- 0.284
- 0.368
- 0.348
- 0.364
- 0.378
- 0.292
train_loss:
- 3.856
- 3.933
- 3.247
- 3.073
- 3.373
- 2.888
- 2.781
- 3.083
- 2.616
- 2.563
- 2.488
- 2.758
- 2.375
- 2.329
- 2.238
- 2.202
- 2.19
- 2.107
- 2.317
- 2.024
- 2.246
- 1.956
- 1.898
- 1.849
- 1.811
- 1.749
- 1.665
- 1.677
- 1.589
- 1.624
- 1.573
- 1.757
- 1.492
- 1.483
- 1.411
- 1.409
- 1.374
- 1.305
- 1.326
- 1.423
- 1.239
- 1.353
- 1.184
- 1.14
- 1.258
- 1.129
- 1.076
- 1.034
- 1.139
- 1.121
- 0.966
- 0.963
- 0.97
- 0.913
- 0.894
- 0.88
- 0.876
- 0.818
- 0.798
- 0.854
- 0.839
- 0.788
- 0.743
- 0.726
- 0.695
- 0.718
- 0.669
- 0.71
- 0.71
- 0.626
- 0.649
- 0.614
- 0.597
- 0.624
- 0.602
- 0.6
- 0.547
- 0.558
- 0.562
- 0.512
- 0.505
- 0.501
- 0.492
- 0.478
- 0.478
- 0.449
- 0.456
- 0.436
- 0.428
- 0.427
- 0.439
- 0.415
- 0.408
- 0.401
- 0.398
- 0.369
- 0.361
- 0.367
- 0.348
- 0.349
unequal: 0
verbose: 1
