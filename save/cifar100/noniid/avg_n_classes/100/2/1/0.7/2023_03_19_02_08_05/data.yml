avg_train_accuracy: 0.289
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0384
- 0.0985
- 0.1181
- 0.1329
- 0.1474
- 0.1598
- 0.1636
- 0.1732
- 0.1798
- 0.1864
- 0.1917
- 0.1973
- 0.1993
- 0.2089
- 0.2102
- 0.2146
- 0.22
- 0.2258
- 0.2303
- 0.2337
- 0.2381
- 0.237
- 0.2431
- 0.25
- 0.2528
- 0.2544
- 0.2567
- 0.26
- 0.262
- 0.263
- 0.2657
- 0.264
- 0.269
- 0.2711
- 0.2743
- 0.2713
- 0.2794
- 0.2796
- 0.2802
- 0.2808
- 0.2835
- 0.2832
- 0.2866
- 0.2882
- 0.2902
- 0.2858
- 0.2905
- 0.2918
- 0.2939
- 0.2974
- 0.2957
- 0.2967
- 0.2974
- 0.2988
- 0.3037
- 0.3002
- 0.2968
- 0.3027
- 0.3011
- 0.3024
- 0.3058
- 0.3053
- 0.3051
- 0.3074
- 0.3067
- 0.309
- 0.3093
- 0.3072
- 0.3123
- 0.3073
- 0.3122
- 0.3104
- 0.3114
- 0.3111
- 0.3163
- 0.3122
- 0.3154
- 0.316
- 0.317
- 0.3181
- 0.3182
- 0.3165
- 0.3175
- 0.3182
- 0.3187
- 0.3166
- 0.3182
- 0.3164
- 0.3182
- 0.3198
- 0.322
- 0.321
- 0.32
- 0.3199
- 0.3249
- 0.3212
- 0.3218
- 0.3239
- 0.3252
- 0.3245
test_loss_list:
- 1.7802212142944336
- 1.643565902709961
- 1.585920627117157
- 1.5445084190368652
- 1.510718777179718
- 1.4865149021148683
- 1.4635400724411012
- 1.4457589387893677
- 1.427194344997406
- 1.413145694732666
- 1.4001455521583557
- 1.3860413789749146
- 1.3731061244010925
- 1.3596623635292053
- 1.3502068257331847
- 1.3405832171440124
- 1.330716757774353
- 1.3182798361778258
- 1.3055506920814515
- 1.2974290776252746
- 1.2905583691596985
- 1.285090298652649
- 1.2709131479263305
- 1.262122356891632
- 1.2547858715057374
- 1.248546154499054
- 1.239992241859436
- 1.2344438982009889
- 1.229856207370758
- 1.229054524898529
- 1.2265276145935058
- 1.2243203115463257
- 1.2177044200897216
- 1.2089346313476563
- 1.2064458322525025
- 1.2026252698898316
- 1.1952924036979675
- 1.1921706199645996
- 1.1882045102119445
- 1.1858688330650329
- 1.1839611053466796
- 1.1835713863372803
- 1.1767183685302733
- 1.174044153690338
- 1.1716671252250672
- 1.1813316345214844
- 1.1707644820213319
- 1.1658756041526794
- 1.165517635345459
- 1.1616051077842713
- 1.1652683734893798
- 1.1619607090950013
- 1.1603902649879456
- 1.1607993674278259
- 1.1548211646080018
- 1.1552306342124938
- 1.1603181958198547
- 1.1514334166049958
- 1.1563372254371642
- 1.152771589756012
- 1.1517197370529175
- 1.1531619095802308
- 1.1509952962398529
- 1.1521808886528015
- 1.1528356051445008
- 1.1501803231239318
- 1.1473249256610871
- 1.149373369216919
- 1.1490951037406922
- 1.1571912574768066
- 1.1440493965148926
- 1.147992525100708
- 1.1457261419296265
- 1.1472775006294251
- 1.1457434678077698
- 1.1492424345016479
- 1.1472154259681702
- 1.1434098875522614
- 1.1445988965034486
- 1.14343395113945
- 1.1484758949279785
- 1.1465575432777404
- 1.1473573875427245
- 1.1449729478359223
- 1.1450026619434357
- 1.1463907361030579
- 1.1430137240886689
- 1.1462788736820222
- 1.147776781320572
- 1.1457329154014588
- 1.146485993862152
- 1.14418239235878
- 1.1497700428962707
- 1.1546660995483398
- 1.1419462502002715
- 1.1487547385692596
- 1.147253761291504
- 1.1507056534290314
- 1.1477339637279511
- 1.152193375825882
train_accuracy:
- 0.029
- 0.097
- 0.115
- 0.154
- 0.118
- 0.181
- 0.172
- 0.0
- 0.182
- 0.213
- 0.214
- 0.22
- 0.176
- 0.212
- 0.218
- 0.254
- 0.201
- 0.0
- 0.216
- 0.256
- 0.212
- 0.207
- 0.241
- 0.243
- 0.228
- 0.269
- 0.256
- 0.254
- 0.26
- 0.271
- 0.269
- 0.254
- 0.259
- 0.246
- 0.304
- 0.274
- 0.277
- 0.265
- 0.29
- 0.265
- 0.273
- 0.339
- 0.3
- 0.0
- 0.283
- 0.238
- 0.305
- 0.252
- 0.279
- 0.274
- 0.301
- 0.301
- 0.291
- 0.283
- 0.29
- 0.298
- 0.293
- 0.306
- 0.299
- 0.316
- 0.26
- 0.306
- 0.294
- 0.27
- 0.311
- 0.35
- 0.301
- 0.311
- 0.28
- 0.301
- 0.349
- 0.343
- 0.321
- 0.296
- 0.315
- 0.28
- 0.359
- 0.307
- 0.31
- 0.28
- 0.32
- 0.328
- 0.0
- 0.267
- 0.309
- 0.266
- 0.321
- 0.331
- 0.312
- 0.285
- 0.286
- 0.318
- 0.326
- 0.0
- 0.317
- 0.32
- 0.0
- 0.365
- 0.354
- 0.289
train_loss:
- 4.321
- 3.398
- 3.205
- 3.483
- 3.36
- 2.856
- 3.14
- 2.693
- 2.973
- 2.896
- 2.502
- 2.744
- 2.398
- 2.3
- 2.528
- 2.197
- 2.153
- 2.122
- 2.354
- 2.021
- 1.954
- 1.903
- 1.887
- 1.819
- 1.81
- 1.765
- 1.715
- 1.678
- 1.833
- 1.756
- 1.726
- 1.523
- 1.497
- 1.637
- 1.435
- 1.375
- 1.379
- 1.343
- 1.316
- 1.271
- 1.392
- 1.22
- 1.195
- 1.157
- 1.273
- 1.108
- 1.087
- 1.065
- 1.036
- 1.133
- 0.979
- 0.954
- 0.954
- 0.895
- 0.91
- 0.889
- 0.841
- 0.837
- 0.815
- 0.78
- 0.778
- 0.747
- 0.739
- 0.766
- 0.684
- 0.697
- 0.712
- 0.673
- 0.637
- 0.717
- 0.638
- 0.623
- 0.59
- 0.567
- 0.571
- 0.565
- 0.553
- 0.604
- 0.538
- 0.521
- 0.544
- 0.493
- 0.488
- 0.475
- 0.449
- 0.46
- 0.449
- 0.439
- 0.431
- 0.449
- 0.437
- 0.4
- 0.402
- 0.382
- 0.402
- 0.38
- 0.372
- 0.363
- 0.36
- 0.362
unequal: 0
verbose: 1
