avg_train_accuracy: 0.271
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0364
- 0.0983
- 0.1204
- 0.1375
- 0.1486
- 0.1598
- 0.167
- 0.1708
- 0.1808
- 0.185
- 0.1872
- 0.1917
- 0.1961
- 0.1991
- 0.2042
- 0.2127
- 0.2096
- 0.2234
- 0.2224
- 0.2257
- 0.229
- 0.2287
- 0.2318
- 0.2323
- 0.2365
- 0.2431
- 0.2443
- 0.2449
- 0.2443
- 0.2512
- 0.2532
- 0.2552
- 0.2534
- 0.2554
- 0.256
- 0.2566
- 0.2586
- 0.2554
- 0.2624
- 0.2612
- 0.2586
- 0.2604
- 0.2608
- 0.2619
- 0.2616
- 0.2655
- 0.2677
- 0.2686
- 0.2702
- 0.273
- 0.27
- 0.2718
- 0.2736
- 0.2706
- 0.2693
- 0.272
- 0.2742
- 0.2773
- 0.2747
- 0.2786
- 0.2749
- 0.2785
- 0.2765
- 0.2752
- 0.2813
- 0.2777
- 0.2793
- 0.2795
- 0.2794
- 0.2798
- 0.2789
- 0.2795
- 0.2817
- 0.2763
- 0.2777
- 0.284
- 0.2792
- 0.2775
- 0.2825
- 0.2819
- 0.2767
- 0.2813
- 0.2847
- 0.2828
- 0.2777
- 0.2837
- 0.2815
- 0.2805
- 0.2824
- 0.2801
- 0.2861
- 0.2857
- 0.282
- 0.2853
- 0.2806
- 0.2808
- 0.2792
- 0.2842
- 0.2785
- 0.2825
test_loss_list:
- 1.8027479028701783
- 1.6825761365890504
- 1.6397907519340515
- 1.6106754779815673
- 1.583650906085968
- 1.5678492498397827
- 1.548658607006073
- 1.533794300556183
- 1.5196149301528932
- 1.5130482912063599
- 1.5014352869987488
- 1.4861107134819032
- 1.4916100788116455
- 1.4697638320922852
- 1.462392773628235
- 1.450866358280182
- 1.4505572819709778
- 1.4371888160705566
- 1.439908776283264
- 1.4278129124641419
- 1.4222973203659057
- 1.4235935878753663
- 1.4127221369743348
- 1.4186742734909057
- 1.4031622838973998
- 1.4012337708473206
- 1.3962527203559876
- 1.3951589393615722
- 1.3884979462623597
- 1.3871467208862305
- 1.3802319049835206
- 1.3828295516967772
- 1.3800667762756347
- 1.377116928100586
- 1.3768046474456788
- 1.3706484270095824
- 1.3697242069244384
- 1.3710863637924193
- 1.3696025443077087
- 1.368902292251587
- 1.3735158038139343
- 1.3633292531967163
- 1.361194474697113
- 1.364228925704956
- 1.358337459564209
- 1.3542655611038208
- 1.3527982258796691
- 1.3494149684906005
- 1.348867256641388
- 1.3453158140182495
- 1.3499583101272583
- 1.3492949414253235
- 1.350267686843872
- 1.3553124976158142
- 1.347575237751007
- 1.3478843402862548
- 1.3474075174331666
- 1.3513378715515136
- 1.3484192299842834
- 1.3448152256011963
- 1.3461329698562623
- 1.3457668685913087
- 1.3523127293586732
- 1.3519161653518676
- 1.3446010303497316
- 1.3511072945594789
- 1.3419918322563171
- 1.3415941619873046
- 1.3417109417915345
- 1.34067729473114
- 1.3454266309738159
- 1.3416952610015869
- 1.340114254951477
- 1.3490155172348022
- 1.3465031123161315
- 1.3426327085494996
- 1.3421164131164551
- 1.3430121374130248
- 1.3425166368484498
- 1.3459182739257813
- 1.3490772080421447
- 1.342800691127777
- 1.3385547375679017
- 1.3404018545150758
- 1.3401583886146546
- 1.345452070236206
- 1.3401039838790894
- 1.3407194638252258
- 1.3440341210365296
- 1.3439228701591492
- 1.343746464252472
- 1.3444979405403137
- 1.3518324780464173
- 1.345461733341217
- 1.347729983329773
- 1.3454440093040467
- 1.3422632670402528
- 1.34536062002182
- 1.3514046955108643
- 1.342066354751587
train_accuracy:
- 0.053
- 0.098
- 0.11
- 0.0
- 0.137
- 0.0
- 0.161
- 0.193
- 0.0
- 0.19
- 0.204
- 0.211
- 0.0
- 0.206
- 0.0
- 0.24
- 0.0
- 0.221
- 0.0
- 0.225
- 0.21
- 0.223
- 0.214
- 0.0
- 0.236
- 0.0
- 0.0
- 0.0
- 0.259
- 0.0
- 0.326
- 0.317
- 0.0
- 0.278
- 0.273
- 0.318
- 0.226
- 0.267
- 0.232
- 0.0
- 0.281
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.273
- 0.27
- 0.0
- 0.0
- 0.0
- 0.358
- 0.285
- 0.0
- 0.343
- 0.281
- 0.0
- 0.0
- 0.356
- 0.29
- 0.0
- 0.0
- 0.298
- 0.275
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.288
- 0.0
- 0.287
- 0.37
- 0.364
- 0.315
- 0.0
- 0.0
- 0.305
- 0.326
- 0.262
- 0.316
- 0.0
- 0.309
- 0.325
- 0.0
- 0.0
- 0.286
- 0.297
- 0.327
- 0.0
- 0.313
- 0.262
- 0.362
- 0.362
- 0.0
- 0.0
- 0.357
- 0.254
- 0.0
- 0.271
train_loss:
- 2.128
- 2.389
- 2.268
- 1.756
- 2.053
- 1.624
- 1.889
- 1.871
- 1.812
- 1.733
- 1.408
- 1.646
- 1.034
- 1.337
- 1.272
- 1.679
- 1.209
- 1.575
- 1.119
- 1.288
- 1.293
- 1.037
- 1.215
- 0.849
- 1.103
- 1.065
- 0.916
- 0.904
- 0.853
- 1.096
- 0.964
- 1.046
- 0.798
- 0.86
- 0.729
- 0.805
- 0.762
- 0.692
- 0.837
- 0.657
- 0.56
- 0.621
- 0.643
- 0.63
- 0.632
- 0.566
- 0.56
- 0.591
- 0.543
- 0.525
- 0.539
- 0.568
- 0.508
- 0.499
- 0.477
- 0.457
- 0.458
- 0.469
- 0.457
- 0.449
- 0.424
- 0.419
- 0.398
- 0.411
- 0.405
- 0.384
- 0.376
- 0.369
- 0.362
- 0.361
- 0.368
- 0.337
- 0.348
- 0.348
- 0.315
- 0.327
- 0.332
- 0.319
- 0.307
- 0.313
- 0.309
- 0.296
- 0.293
- 0.287
- 0.293
- 0.286
- 0.291
- 0.276
- 0.243
- 0.272
- 0.241
- 0.248
- 0.25
- 0.242
- 0.256
- 0.288
- 0.255
- 0.237
- 0.265
- 0.264
unequal: 0
verbose: 1
