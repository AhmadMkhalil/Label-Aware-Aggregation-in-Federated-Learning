avg_train_accuracy: 0.284
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0451
- 0.0937
- 0.1167
- 0.132
- 0.1403
- 0.1593
- 0.1613
- 0.1756
- 0.1784
- 0.1843
- 0.1909
- 0.1967
- 0.1986
- 0.2038
- 0.2125
- 0.2095
- 0.2168
- 0.2127
- 0.2167
- 0.219
- 0.2196
- 0.2241
- 0.2269
- 0.2263
- 0.23
- 0.2323
- 0.2339
- 0.2337
- 0.236
- 0.2388
- 0.234
- 0.2376
- 0.2434
- 0.2421
- 0.2453
- 0.2481
- 0.2448
- 0.2436
- 0.2468
- 0.2473
- 0.2482
- 0.2463
- 0.2491
- 0.2515
- 0.2509
- 0.2519
- 0.2511
- 0.2544
- 0.2528
- 0.256
- 0.2607
- 0.2547
- 0.2561
- 0.2548
- 0.2549
- 0.2622
- 0.2547
- 0.2616
- 0.2607
- 0.2602
- 0.2623
- 0.2595
- 0.2631
- 0.2619
- 0.2636
- 0.2623
- 0.263
- 0.2638
- 0.2606
- 0.2596
- 0.2646
- 0.2658
- 0.2579
- 0.2623
- 0.2674
- 0.2674
- 0.2617
- 0.2609
- 0.2656
- 0.2641
- 0.2602
- 0.2605
- 0.2654
- 0.2681
- 0.2704
- 0.266
- 0.2659
- 0.2701
- 0.2686
- 0.2675
- 0.2657
- 0.2692
- 0.2636
- 0.2643
- 0.2661
- 0.2678
- 0.2636
- 0.2695
- 0.2675
- 0.2716
test_loss_list:
- 1.8061268663406371
- 1.6915593028068543
- 1.6442619419097901
- 1.6161721658706665
- 1.5956394147872925
- 1.565523145198822
- 1.5513493013381958
- 1.53622633934021
- 1.5230475163459778
- 1.5151363110542297
- 1.50272310256958
- 1.4873017740249634
- 1.4848601150512695
- 1.4732907962799073
- 1.4594285583496094
- 1.45917560338974
- 1.4510549712181091
- 1.4452643084526062
- 1.435713424682617
- 1.4328514695167542
- 1.4293951272964478
- 1.4196702647209167
- 1.4172731781005858
- 1.4163157105445863
- 1.4112663865089417
- 1.4052523112297057
- 1.4057890200614929
- 1.404621546268463
- 1.4022824835777283
- 1.4008449220657349
- 1.3964413142204284
- 1.398724286556244
- 1.3862840509414673
- 1.3887237739562988
- 1.3837655234336852
- 1.3814509534835815
- 1.3847601461410521
- 1.3822381973266602
- 1.3749968957901002
- 1.37527193069458
- 1.3727047896385194
- 1.3817114925384522
- 1.3714798593521118
- 1.367357530593872
- 1.3677190351486206
- 1.3691297626495362
- 1.3648245668411254
- 1.359564595222473
- 1.3689222979545592
- 1.3639840078353882
- 1.3650103878974915
- 1.3655079460144044
- 1.3675585746765138
- 1.3650771379470825
- 1.3715648651123047
- 1.3570744848251344
- 1.3698561573028565
- 1.3604425311088562
- 1.359072687625885
- 1.3602727103233336
- 1.3598423767089844
- 1.3625548553466797
- 1.3584799575805664
- 1.36394713640213
- 1.357725658416748
- 1.3622442197799682
- 1.364141149520874
- 1.3620308423042298
- 1.3590681219100953
- 1.362553391456604
- 1.361850881576538
- 1.3602921843528748
- 1.3653822422027588
- 1.3616814041137695
- 1.3558814120292664
- 1.3554407501220702
- 1.3603913712501525
- 1.358748071193695
- 1.3585509610176087
- 1.3547204899787904
- 1.3607825613021851
- 1.3618359971046448
- 1.355703296661377
- 1.356707694530487
- 1.3569938731193543
- 1.3555598521232606
- 1.3607000875473023
- 1.351085557937622
- 1.354943835735321
- 1.356249897480011
- 1.3565915942192077
- 1.3571640825271607
- 1.363263602256775
- 1.3603412175178529
- 1.3582464933395386
- 1.3555666828155517
- 1.3673311424255372
- 1.359409818649292
- 1.3623239636421203
- 1.3646421909332276
train_accuracy:
- 0.046
- 0.0
- 0.123
- 0.0
- 0.0
- 0.133
- 0.0
- 0.197
- 0.0
- 0.0
- 0.229
- 0.241
- 0.229
- 0.0
- 0.211
- 0.0
- 0.0
- 0.171
- 0.0
- 0.218
- 0.0
- 0.221
- 0.251
- 0.264
- 0.257
- 0.266
- 0.0
- 0.268
- 0.271
- 0.253
- 0.0
- 0.269
- 0.0
- 0.27
- 0.0
- 0.254
- 0.0
- 0.206
- 0.0
- 0.287
- 0.0
- 0.0
- 0.0
- 0.272
- 0.0
- 0.272
- 0.259
- 0.0
- 0.249
- 0.0
- 0.311
- 0.282
- 0.271
- 0.206
- 0.256
- 0.256
- 0.0
- 0.205
- 0.0
- 0.0
- 0.308
- 0.0
- 0.275
- 0.0
- 0.0
- 0.0
- 0.221
- 0.221
- 0.317
- 0.307
- 0.22
- 0.227
- 0.0
- 0.0
- 0.284
- 0.329
- 0.269
- 0.0
- 0.267
- 0.325
- 0.0
- 0.291
- 0.287
- 0.292
- 0.0
- 0.208
- 0.0
- 0.0
- 0.0
- 0.275
- 0.0
- 0.284
- 0.0
- 0.0
- 0.219
- 0.333
- 0.0
- 0.0
- 0.0
- 0.284
train_loss:
- 2.675
- 1.969
- 2.281
- 1.792
- 1.353
- 2.331
- 1.605
- 1.537
- 1.762
- 1.413
- 1.413
- 1.664
- 1.291
- 1.547
- 1.554
- 1.491
- 1.17
- 1.2
- 1.143
- 1.317
- 1.076
- 1.251
- 1.183
- 0.992
- 1.114
- 1.283
- 1.205
- 1.043
- 0.994
- 0.959
- 0.966
- 0.803
- 0.888
- 0.865
- 0.717
- 0.935
- 0.701
- 0.73
- 0.769
- 0.748
- 0.721
- 0.565
- 0.638
- 0.696
- 0.642
- 0.609
- 0.603
- 0.614
- 0.563
- 0.588
- 0.561
- 0.524
- 0.51
- 0.483
- 0.45
- 0.535
- 0.451
- 0.488
- 0.48
- 0.463
- 0.47
- 0.458
- 0.423
- 0.403
- 0.4
- 0.407
- 0.385
- 0.373
- 0.371
- 0.379
- 0.364
- 0.342
- 0.366
- 0.345
- 0.344
- 0.309
- 0.316
- 0.318
- 0.291
- 0.296
- 0.318
- 0.329
- 0.291
- 0.275
- 0.302
- 0.304
- 0.298
- 0.29
- 0.279
- 0.295
- 0.272
- 0.288
- 0.256
- 0.286
- 0.284
- 0.256
- 0.275
- 0.227
- 0.236
- 0.234
unequal: 0
verbose: 1
