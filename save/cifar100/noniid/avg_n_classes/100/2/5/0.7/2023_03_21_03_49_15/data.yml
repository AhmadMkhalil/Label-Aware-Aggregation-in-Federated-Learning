avg_train_accuracy: 0.353
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0895
- 0.113
- 0.1268
- 0.1294
- 0.1489
- 0.152
- 0.1688
- 0.1736
- 0.1784
- 0.1824
- 0.1894
- 0.191
- 0.1902
- 0.206
- 0.2051
- 0.2108
- 0.217
- 0.2133
- 0.2229
- 0.2177
- 0.223
- 0.2244
- 0.2274
- 0.2307
- 0.2305
- 0.231
- 0.2328
- 0.2373
- 0.2324
- 0.2405
- 0.2395
- 0.2401
- 0.2441
- 0.2455
- 0.2477
- 0.2447
- 0.2494
- 0.2529
- 0.2501
- 0.2501
- 0.2543
- 0.2528
- 0.2522
- 0.2543
- 0.2518
- 0.2542
- 0.2544
- 0.2567
- 0.2566
- 0.2613
- 0.2598
- 0.2531
- 0.2603
- 0.2537
- 0.2595
- 0.2605
- 0.2617
- 0.2612
- 0.2596
- 0.2608
- 0.2657
- 0.2653
- 0.2619
- 0.264
- 0.2631
- 0.264
- 0.2609
- 0.264
- 0.2683
- 0.2681
- 0.2617
- 0.2671
- 0.2654
- 0.268
- 0.2673
- 0.2697
- 0.2683
- 0.2685
- 0.262
- 0.266
- 0.2656
- 0.2657
- 0.2692
- 0.2687
- 0.2697
- 0.2707
- 0.2709
- 0.2678
- 0.2721
- 0.272
- 0.2735
- 0.2711
- 0.2698
- 0.2703
- 0.2676
- 0.2715
- 0.2697
- 0.2721
- 0.2739
test_loss_list:
- 1.8029111623764038
- 1.6900199127197266
- 1.6518666791915892
- 1.6197840666770935
- 1.6100196576118468
- 1.5767863512039184
- 1.5605382776260377
- 1.5407428240776062
- 1.532424418926239
- 1.520508189201355
- 1.5068370962142945
- 1.4942606449127198
- 1.4913810753822327
- 1.4984089303016663
- 1.4664056301116943
- 1.4635770177841188
- 1.4569906735420226
- 1.4537670731544494
- 1.4426637554168702
- 1.4404468107223511
- 1.4436650609970092
- 1.4372411847114563
- 1.42181898355484
- 1.4256663179397584
- 1.4143301939964295
- 1.4136921167373657
- 1.4159736299514771
- 1.409026370048523
- 1.399610276222229
- 1.400297315120697
- 1.3932347226142883
- 1.389865186214447
- 1.3941043519973755
- 1.3817369890213014
- 1.3860249280929566
- 1.3808183360099793
- 1.3849498581886293
- 1.3733459830284118
- 1.3756335544586182
- 1.3765078473091126
- 1.375094885826111
- 1.3729059171676636
- 1.3717081356048584
- 1.3725889253616332
- 1.3701767897605897
- 1.3717485451698304
- 1.371107461452484
- 1.368146414756775
- 1.3665971779823303
- 1.3672319078445434
- 1.363008110523224
- 1.3661278176307678
- 1.371184411048889
- 1.3641885375976563
- 1.3776745176315308
- 1.3575673508644104
- 1.3593971586227418
- 1.3636189031600952
- 1.3578061962127685
- 1.3639063096046449
- 1.3608978796005249
- 1.3547468423843383
- 1.3568954038619996
- 1.361887812614441
- 1.3584129571914674
- 1.360009663105011
- 1.3592426991462707
- 1.363038218021393
- 1.3643058133125305
- 1.3567447876930236
- 1.3616099905967713
- 1.3679165148735046
- 1.3559950113296508
- 1.3554877471923827
- 1.3612142872810364
- 1.3651659774780274
- 1.3493279671669007
- 1.353213725090027
- 1.3555966114997864
- 1.3654192876815796
- 1.3543429374694824
- 1.3548212122917176
- 1.3569458866119384
- 1.3528514146804809
- 1.351661343574524
- 1.3551845240592957
- 1.3544133830070495
- 1.3568275260925293
- 1.357525703907013
- 1.356185986995697
- 1.357685477733612
- 1.3557445430755615
- 1.3650482511520385
- 1.3594306421279907
- 1.3615761399269104
- 1.3589509844779968
- 1.3584631991386413
- 1.3574958872795104
- 1.3572347640991211
- 1.358585195541382
train_accuracy:
- 0.031
- 0.108
- 0.0
- 0.0
- 0.0
- 0.0
- 0.166
- 0.0
- 0.0
- 0.0
- 0.207
- 0.0
- 0.197
- 0.0
- 0.0
- 0.0
- 0.189
- 0.0
- 0.253
- 0.198
- 0.0
- 0.225
- 0.0
- 0.241
- 0.0
- 0.276
- 0.262
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.241
- 0.291
- 0.247
- 0.0
- 0.0
- 0.278
- 0.277
- 0.246
- 0.313
- 0.0
- 0.272
- 0.281
- 0.0
- 0.0
- 0.274
- 0.297
- 0.26
- 0.0
- 0.0
- 0.26
- 0.295
- 0.0
- 0.0
- 0.304
- 0.292
- 0.315
- 0.287
- 0.263
- 0.0
- 0.322
- 0.0
- 0.0
- 0.288
- 0.279
- 0.0
- 0.0
- 0.282
- 0.329
- 0.284
- 0.0
- 0.288
- 0.292
- 0.0
- 0.287
- 0.305
- 0.0
- 0.304
- 0.294
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.307
- 0.0
- 0.332
- 0.303
- 0.296
- 0.3
- 0.323
- 0.278
- 0.0
- 0.0
- 0.326
- 0.293
- 0.319
- 0.353
train_loss:
- 2.662
- 2.415
- 1.875
- 1.79
- 1.334
- 2.039
- 1.597
- 1.885
- 1.523
- 1.395
- 1.776
- 1.414
- 1.329
- 1.036
- 1.612
- 1.477
- 1.455
- 1.456
- 1.155
- 1.589
- 1.053
- 1.009
- 1.295
- 0.973
- 1.179
- 1.139
- 0.95
- 0.909
- 1.063
- 0.824
- 0.866
- 0.848
- 0.86
- 0.885
- 0.803
- 0.799
- 0.73
- 0.809
- 0.838
- 0.629
- 0.738
- 0.691
- 0.705
- 0.636
- 0.587
- 0.584
- 0.627
- 0.602
- 0.627
- 0.574
- 0.561
- 0.553
- 0.545
- 0.582
- 0.477
- 0.507
- 0.503
- 0.496
- 0.488
- 0.464
- 0.479
- 0.44
- 0.454
- 0.446
- 0.429
- 0.44
- 0.407
- 0.363
- 0.377
- 0.369
- 0.395
- 0.372
- 0.347
- 0.381
- 0.37
- 0.31
- 0.371
- 0.297
- 0.355
- 0.346
- 0.332
- 0.311
- 0.318
- 0.338
- 0.318
- 0.304
- 0.315
- 0.333
- 0.294
- 0.291
- 0.253
- 0.248
- 0.298
- 0.3
- 0.268
- 0.287
- 0.268
- 0.286
- 0.248
- 0.262
unequal: 0
verbose: 1
