avg_train_accuracy: 0.308
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0286
- 0.0887
- 0.1115
- 0.1261
- 0.1445
- 0.1553
- 0.1611
- 0.1675
- 0.1746
- 0.1805
- 0.1839
- 0.1964
- 0.1975
- 0.2044
- 0.1987
- 0.2084
- 0.2112
- 0.2173
- 0.2215
- 0.2258
- 0.2266
- 0.2294
- 0.2326
- 0.234
- 0.2267
- 0.2379
- 0.2396
- 0.2444
- 0.2451
- 0.2436
- 0.2473
- 0.2411
- 0.2489
- 0.2533
- 0.2532
- 0.2498
- 0.2543
- 0.2557
- 0.2539
- 0.2551
- 0.2563
- 0.2587
- 0.2594
- 0.2596
- 0.2629
- 0.2607
- 0.2625
- 0.2643
- 0.2644
- 0.2621
- 0.2628
- 0.2655
- 0.2655
- 0.2656
- 0.2641
- 0.2657
- 0.268
- 0.2704
- 0.2686
- 0.2668
- 0.2711
- 0.2733
- 0.2679
- 0.2691
- 0.2706
- 0.2711
- 0.2723
- 0.2732
- 0.272
- 0.2713
- 0.2732
- 0.2697
- 0.2749
- 0.27
- 0.2669
- 0.2674
- 0.2685
- 0.276
- 0.2757
- 0.272
- 0.2749
- 0.2775
- 0.2751
- 0.2758
- 0.2786
- 0.273
- 0.2749
- 0.2741
- 0.2737
- 0.2746
- 0.2765
- 0.2758
- 0.2769
- 0.2788
- 0.2754
- 0.2793
- 0.2785
- 0.2829
- 0.2803
- 0.2772
test_loss_list:
- 1.8258386659622192
- 1.71052095413208
- 1.6620418620109558
- 1.6335784149169923
- 1.6040679693222046
- 1.5784027242660523
- 1.569149498939514
- 1.5501712656021118
- 1.5362766480445862
- 1.5241057324409484
- 1.509906334877014
- 1.497814872264862
- 1.490744755268097
- 1.4841530418395996
- 1.4835723543167114
- 1.4710389304161071
- 1.461967444419861
- 1.4571777868270874
- 1.4474502730369567
- 1.4390665197372436
- 1.4366018319129943
- 1.4346114897727966
- 1.4269439029693602
- 1.4257234573364257
- 1.4252098417282104
- 1.414263904094696
- 1.4065370917320252
- 1.4043122434616089
- 1.403062536716461
- 1.407466082572937
- 1.3984798550605775
- 1.4073441958427428
- 1.3942842984199524
- 1.392648401260376
- 1.392097029685974
- 1.3950844645500182
- 1.3870556378364562
- 1.3843324303627014
- 1.3820997285842895
- 1.3809153461456298
- 1.3771334648132325
- 1.3782428479194642
- 1.3761372542381287
- 1.3762986803054809
- 1.3717432713508606
- 1.3719749689102172
- 1.369736680984497
- 1.3647399306297303
- 1.3648732280731202
- 1.3700352597236634
- 1.3721970009803772
- 1.3694044971466064
- 1.3692687082290649
- 1.3591492581367492
- 1.357220184803009
- 1.359378025531769
- 1.3620171356201172
- 1.355954840183258
- 1.364780876636505
- 1.3658298397064208
- 1.3531872463226318
- 1.3606722092628478
- 1.3639594745635986
- 1.3679600048065186
- 1.3640637922286987
- 1.363419771194458
- 1.3589069271087646
- 1.3592714715003966
- 1.362335855960846
- 1.3572477316856384
- 1.3621075892448424
- 1.3649381017684936
- 1.3672809314727783
- 1.366276922225952
- 1.3679083204269409
- 1.3670076298713685
- 1.3647097730636597
- 1.356509416103363
- 1.3588161301612853
- 1.3610921835899352
- 1.3593538618087768
- 1.360785925388336
- 1.3532064580917358
- 1.3597640204429626
- 1.3560112881660462
- 1.3591896510124206
- 1.3571832776069641
- 1.3605332827568055
- 1.3629414701461793
- 1.3565250372886657
- 1.3527285313606263
- 1.359289116859436
- 1.3555683541297912
- 1.3587532377243041
- 1.3598497343063354
- 1.353102090358734
- 1.3567514061927795
- 1.356551353931427
- 1.3567513751983642
- 1.3579830932617187
train_accuracy:
- 0.015
- 0.125
- 0.099
- 0.0
- 0.102
- 0.168
- 0.0
- 0.177
- 0.0
- 0.0
- 0.206
- 0.198
- 0.123
- 0.0
- 0.211
- 0.222
- 0.168
- 0.0
- 0.0
- 0.0
- 0.238
- 0.0
- 0.234
- 0.0
- 0.209
- 0.253
- 0.0
- 0.217
- 0.0
- 0.179
- 0.257
- 0.179
- 0.0
- 0.0
- 0.259
- 0.225
- 0.305
- 0.306
- 0.239
- 0.0
- 0.0
- 0.282
- 0.0
- 0.275
- 0.245
- 0.0
- 0.0
- 0.0
- 0.0
- 0.263
- 0.0
- 0.0
- 0.0
- 0.0
- 0.286
- 0.0
- 0.254
- 0.329
- 0.0
- 0.0
- 0.288
- 0.225
- 0.227
- 0.333
- 0.0
- 0.0
- 0.327
- 0.294
- 0.0
- 0.0
- 0.292
- 0.252
- 0.247
- 0.0
- 0.0
- 0.28
- 0.0
- 0.236
- 0.263
- 0.295
- 0.0
- 0.303
- 0.0
- 0.0
- 0.336
- 0.0
- 0.302
- 0.293
- 0.33
- 0.335
- 0.311
- 0.0
- 0.0
- 0.0
- 0.334
- 0.259
- 0.343
- 0.29
- 0.0
- 0.308
train_loss:
- 2.715
- 1.964
- 2.273
- 1.378
- 1.698
- 1.999
- 1.264
- 1.508
- 1.483
- 1.767
- 1.442
- 1.648
- 1.351
- 1.569
- 1.281
- 1.477
- 1.414
- 1.212
- 1.565
- 1.327
- 1.268
- 1.052
- 1.216
- 1.037
- 0.973
- 0.996
- 1.112
- 1.207
- 1.023
- 0.877
- 0.969
- 0.69
- 1.049
- 0.882
- 0.844
- 0.775
- 0.809
- 0.703
- 0.752
- 0.758
- 0.823
- 0.65
- 0.645
- 0.62
- 0.672
- 0.616
- 0.585
- 0.609
- 0.605
- 0.555
- 0.495
- 0.46
- 0.438
- 0.516
- 0.541
- 0.483
- 0.487
- 0.514
- 0.458
- 0.43
- 0.45
- 0.463
- 0.413
- 0.388
- 0.421
- 0.414
- 0.394
- 0.389
- 0.373
- 0.388
- 0.373
- 0.365
- 0.345
- 0.37
- 0.355
- 0.347
- 0.347
- 0.35
- 0.317
- 0.326
- 0.311
- 0.301
- 0.313
- 0.306
- 0.303
- 0.309
- 0.302
- 0.289
- 0.288
- 0.277
- 0.278
- 0.266
- 0.276
- 0.278
- 0.275
- 0.264
- 0.251
- 0.248
- 0.252
- 0.254
unequal: 0
verbose: 1
