avg_train_accuracy: 0.256
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0178
- 0.0779
- 0.0185
- 0.0184
- 0.088
- 0.0178
- 0.1018
- 0.1163
- 0.018
- 0.0177
- 0.0172
- 0.0181
- 0.1239
- 0.1284
- 0.0179
- 0.147
- 0.0186
- 0.1449
- 0.0185
- 0.0178
- 0.0188
- 0.1544
- 0.1565
- 0.1565
- 0.0189
- 0.177
- 0.1772
- 0.1796
- 0.1817
- 0.0188
- 0.1835
- 0.0191
- 0.1762
- 0.0192
- 0.0188
- 0.1882
- 0.1952
- 0.2018
- 0.0189
- 0.0191
- 0.018
- 0.0181
- 0.0189
- 0.0191
- 0.0193
- 0.2055
- 0.2124
- 0.2103
- 0.2138
- 0.0184
- 0.0189
- 0.2156
- 0.2169
- 0.0189
- 0.019
- 0.2126
- 0.0193
- 0.0192
- 0.0192
- 0.2118
- 0.0188
- 0.019
- 0.0187
- 0.2214
- 0.2206
- 0.2277
- 0.0192
- 0.0185
- 0.0196
- 0.2259
- 0.2308
- 0.019
- 0.0195
- 0.0188
- 0.0185
- 0.0188
- 0.0192
- 0.0192
- 0.0189
- 0.2301
- 0.2251
- 0.0191
- 0.2336
- 0.2336
- 0.0205
- 0.0188
- 0.2465
- 0.2397
- 0.238
- 0.2425
- 0.2506
- 0.0209
- 0.2473
- 0.2473
- 0.0194
- 0.02
- 0.2375
- 0.2477
- 0.0198
- 0.2568
test_loss_list:
- 3.449815330505371
- 1.808921103477478
- 4.215208406448364
- 4.355120277404785
- 1.740498538017273
- 4.484484052658081
- 1.7108027124404908
- 1.6676259851455688
- 4.297344465255737
- 4.4030797576904295
- 4.715592908859253
- 4.3104557704925535
- 1.6265004801750182
- 1.635964379310608
- 4.5031074523925785
- 1.6163940978050233
- 4.443408145904541
- 1.5882422232627869
- 4.077157001495362
- 4.293764991760254
- 4.3331418704986575
- 1.5607719826698303
- 1.5686876463890076
- 1.5770329856872558
- 4.38452561378479
- 1.5313251519203186
- 1.5373345160484313
- 1.5428971195220946
- 1.5312072372436523
- 4.253803691864014
- 1.5277123475074768
- 4.117636318206787
- 1.5345531058311463
- 4.085055208206176
- 4.076742172241211
- 1.5157601428031922
- 1.5007821393013
- 1.498537344932556
- 4.307466154098511
- 4.1856879615783695
- 4.356541442871094
- 4.47684497833252
- 3.997156524658203
- 4.091693363189697
- 4.165722103118896
- 1.4257957649230957
- 1.4443873429298402
- 1.4678709888458252
- 1.4410969185829163
- 4.236068296432495
- 4.217549781799317
- 1.428183605670929
- 1.4387192702293397
- 4.12940013885498
- 4.004997129440308
- 1.4379291653633117
- 3.8056885528564455
- 3.914461822509766
- 3.9447841835021973
- 1.4390795183181764
- 4.110049657821655
- 3.9818843173980714
- 4.21275218963623
- 1.3881354355812072
- 1.4053107476234437
- 1.407426357269287
- 3.9938449096679687
- 4.178969211578369
- 3.9271962356567385
- 1.375000011920929
- 1.378450939655304
- 3.9035834217071534
- 3.9033708286285402
- 4.030097064971923
- 4.096987962722778
- 4.303473777770996
- 4.109610004425049
- 4.0872947883605955
- 3.8425314140319826
- 1.3451660585403442
- 1.3785187220573425
- 3.800319986343384
- 1.3762987685203552
- 1.3781901717185974
- 3.492175302505493
- 4.021400098800659
- 1.3544515919685365
- 1.3934728908538818
- 1.3876587343215943
- 1.3797264695167542
- 1.3887276482582092
- 3.584125337600708
- 1.3932283210754395
- 1.3936770367622375
- 3.891526107788086
- 3.9362324714660644
- 1.3988382339477539
- 1.3867973017692565
- 3.780307569503784
- 1.3631727480888367
train_accuracy:
- 0.916
- 0.06
- 0.963
- 0.944
- 0.109
- 0.913
- 0.116
- 0.107
- 0.855
- 0.904
- 0.755
- 0.919
- 0.119
- 0.123
- 0.859
- 0.16
- 0.961
- 0.125
- 0.889
- 0.943
- 0.957
- 0.177
- 0.154
- 0.171
- 0.805
- 0.182
- 0.163
- 0.17
- 0.189
- 0.843
- 0.184
- 0.892
- 0.177
- 0.892
- 0.879
- 0.184
- 0.214
- 0.193
- 0.935
- 0.927
- 0.819
- 0.878
- 0.864
- 0.88
- 0.865
- 0.184
- 0.213
- 0.21
- 0.212
- 0.929
- 0.94
- 0.221
- 0.22
- 0.908
- 0.904
- 0.214
- 0.91
- 0.901
- 0.896
- 0.204
- 0.925
- 0.898
- 0.902
- 0.199
- 0.21
- 0.21
- 0.855
- 0.905
- 0.906
- 0.249
- 0.218
- 0.87
- 0.938
- 0.929
- 0.909
- 0.952
- 0.953
- 0.938
- 0.839
- 0.227
- 0.241
- 0.938
- 0.241
- 0.214
- 0.905
- 0.909
- 0.233
- 0.234
- 0.253
- 0.233
- 0.247
- 0.92
- 0.281
- 0.267
- 0.917
- 0.92
- 0.227
- 0.259
- 0.931
- 0.256
train_loss:
- 0.522
- 4.532
- 0.485
- 0.116
- 4.148
- 0.624
- 3.951
- 3.44
- 0.567
- 0.852
- 0.953
- 0.704
- 3.533
- 2.763
- 0.472
- 3.364
- 0.469
- 3.426
- 0.468
- 0.748
- 0.634
- 2.981
- 2.518
- 2.101
- 0.599
- 3.178
- 2.848
- 2.404
- 2.042
- 0.472
- 2.716
- 0.391
- 2.02
- 0.353
- 0.673
- 2.353
- 2.245
- 2.427
- 0.404
- 0.581
- 0.792
- 0.095
- 0.654
- 0.518
- 0.04
- 2.846
- 2.088
- 1.661
- 2.178
- 0.35
- 0.687
- 2.25
- 1.97
- 0.355
- 0.616
- 1.735
- 0.338
- 0.036
- 0.03
- 1.451
- 0.332
- 0.52
- 0.646
- 2.206
- 1.472
- 1.704
- 0.345
- 0.615
- 0.524
- 1.963
- 1.405
- 0.309
- 0.498
- 0.524
- 0.539
- 0.448
- 0.494
- 0.036
- 0.585
- 2.036
- 1.257
- 0.258
- 1.69
- 1.276
- 0.265
- 0.479
- 1.741
- 1.053
- 1.371
- 1.111
- 1.022
- 0.263
- 1.49
- 1.134
- 0.33
- 0.447
- 1.035
- 1.249
- 0.308
- 1.138
unequal: 0
verbose: 1
