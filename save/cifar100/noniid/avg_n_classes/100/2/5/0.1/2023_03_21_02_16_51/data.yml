avg_train_accuracy: 0.931
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0187
- 0.0742
- 0.0183
- 0.1002
- 0.1155
- 0.1182
- 0.0195
- 0.1275
- 0.1415
- 0.0186
- 0.0151
- 0.1467
- 0.0179
- 0.0161
- 0.0198
- 0.019
- 0.1448
- 0.0197
- 0.1599
- 0.166
- 0.1701
- 0.0173
- 0.1691
- 0.1739
- 0.019
- 0.019
- 0.1825
- 0.0198
- 0.1795
- 0.0178
- 0.1843
- 0.018
- 0.0182
- 0.0168
- 0.0189
- 0.1847
- 0.0197
- 0.1897
- 0.205
- 0.0155
- 0.1992
- 0.0192
- 0.2041
- 0.0178
- 0.0175
- 0.1975
- 0.0173
- 0.0193
- 0.2025
- 0.2094
- 0.0188
- 0.2082
- 0.0191
- 0.2131
- 0.2227
- 0.02
- 0.0199
- 0.018
- 0.2242
- 0.2243
- 0.2225
- 0.0179
- 0.218
- 0.2291
- 0.2305
- 0.233
- 0.2247
- 0.2243
- 0.2269
- 0.0184
- 0.2324
- 0.0187
- 0.0192
- 0.2356
- 0.0171
- 0.2384
- 0.2399
- 0.2368
- 0.2343
- 0.2366
- 0.0191
- 0.2384
- 0.021
- 0.2386
- 0.2468
- 0.2403
- 0.2411
- 0.248
- 0.2486
- 0.0193
- 0.248
- 0.2535
- 0.0196
- 0.0191
- 0.2437
- 0.2438
- 0.0205
- 0.2522
- 0.2565
- 0.0223
test_loss_list:
- 3.4267745208740235
- 1.7720211267471313
- 4.525761508941651
- 1.7308682775497437
- 1.713160424232483
- 1.7069800519943237
- 4.619197769165039
- 1.6617389059066772
- 1.652322494983673
- 4.377345170974731
- 4.555228853225708
- 1.603400971889496
- 4.560295209884644
- 4.266349353790283
- 4.391456203460693
- 4.149599142074585
- 1.5746745085716247
- 4.231545763015747
- 1.5693955636024475
- 1.5888405323028565
- 1.5651181578636169
- 4.07835901260376
- 1.5693437004089354
- 1.560644464492798
- 4.127828063964844
- 4.186122674942016
- 1.5495726156234741
- 4.323132705688477
- 1.5286258053779602
- 4.124093837738037
- 1.5154002070426942
- 4.022071294784546
- 4.47039942741394
- 4.288006572723389
- 3.9995057678222654
- 1.4819941234588623
- 4.135568504333496
- 1.4766306900978088
- 1.4518710422515868
- 4.310436840057373
- 1.4754205226898194
- 3.861345748901367
- 1.4678169655799866
- 4.0517846298217775
- 4.2823756980895995
- 1.464137556552887
- 4.175886611938477
- 3.903780851364136
- 1.4567098331451416
- 1.4645256304740906
- 4.260563840866089
- 1.4553890752792358
- 3.8309092903137207
- 1.4602570009231568
- 1.44401282787323
- 3.7327271842956544
- 4.165848703384399
- 4.322841167449951
- 1.4037433290481567
- 1.426733374595642
- 1.44262291431427
- 4.1962353706359865
- 1.4561632895469665
- 1.4325518202781677
- 1.4304325842857362
- 1.4500514435768128
- 1.483099479675293
- 1.4945417284965514
- 1.4720040082931518
- 4.07495038986206
- 1.4389851355552674
- 3.9551529598236086
- 4.17350284576416
- 1.4300267028808593
- 4.181133460998535
- 1.4324874711036681
- 1.4321588706970214
- 1.4368105411529541
- 1.4537253594398498
- 1.42899409532547
- 4.204022455215454
- 1.438577151298523
- 3.7224862670898435
- 1.4290900182724
- 1.417489092350006
- 1.4540630269050598
- 1.4296356773376464
- 1.4348348665237427
- 1.421015100479126
- 4.1193350982666015
- 1.421303539276123
- 1.4273923254013061
- 4.0443831729888915
- 4.122904844284058
- 1.432650260925293
- 1.4354569554328918
- 4.0741162109375
- 1.426726026535034
- 1.4401747703552246
- 3.728255338668823
train_accuracy:
- 0.994
- 0.053
- 0.895
- 0.075
- 0.117
- 0.118
- 0.948
- 0.142
- 0.124
- 0.904
- 0.423
- 0.149
- 0.871
- 0.822
- 0.981
- 0.884
- 0.156
- 0.975
- 0.175
- 0.176
- 0.176
- 0.862
- 0.197
- 0.178
- 0.925
- 0.931
- 0.208
- 0.98
- 0.208
- 0.817
- 0.182
- 0.868
- 0.782
- 0.836
- 0.887
- 0.2
- 0.982
- 0.223
- 0.209
- 0.556
- 0.219
- 0.926
- 0.19
- 0.817
- 0.934
- 0.199
- 0.907
- 0.93
- 0.206
- 0.229
- 0.92
- 0.202
- 0.884
- 0.209
- 0.237
- 0.916
- 0.99
- 0.794
- 0.257
- 0.224
- 0.22
- 0.769
- 0.214
- 0.228
- 0.248
- 0.249
- 0.25
- 0.242
- 0.239
- 0.866
- 0.225
- 0.879
- 0.886
- 0.241
- 0.887
- 0.239
- 0.264
- 0.245
- 0.236
- 0.242
- 0.921
- 0.224
- 0.929
- 0.235
- 0.254
- 0.251
- 0.254
- 0.271
- 0.253
- 0.885
- 0.273
- 0.275
- 0.855
- 0.903
- 0.259
- 0.233
- 0.903
- 0.252
- 0.273
- 0.931
train_loss:
- 0.405
- 4.459
- 0.514
- 3.763
- 3.011
- 2.708
- 0.473
- 3.664
- 3.311
- 0.508
- 1.028
- 3.536
- 0.704
- 1.041
- 0.693
- 0.633
- 3.086
- 0.322
- 2.827
- 2.135
- 2.877
- 0.703
- 2.242
- 2.736
- 0.402
- 0.065
- 2.028
- 0.347
- 3.287
- 0.59
- 2.756
- 0.501
- 0.833
- 0.875
- 0.619
- 2.67
- 0.339
- 2.793
- 2.454
- 0.475
- 2.429
- 0.366
- 2.459
- 0.479
- 0.695
- 2.165
- 0.391
- 0.545
- 1.837
- 2.08
- 0.573
- 2.241
- 0.295
- 1.9
- 2.098
- 0.29
- 0.576
- 0.692
- 2.067
- 1.713
- 1.327
- 0.434
- 1.311
- 1.655
- 1.479
- 1.056
- 0.822
- 0.699
- 1.199
- 0.514
- 2.012
- 0.386
- 0.654
- 1.012
- 0.476
- 1.263
- 1.612
- 0.825
- 0.571
- 1.441
- 0.383
- 0.795
- 0.353
- 1.467
- 0.819
- 0.987
- 1.176
- 0.678
- 1.426
- 0.373
- 1.152
- 0.556
- 0.321
- 0.057
- 0.91
- 1.163
- 0.289
- 0.919
- 0.511
- 0.31
unequal: 0
verbose: 1
