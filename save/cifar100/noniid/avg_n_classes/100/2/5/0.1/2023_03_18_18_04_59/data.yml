avg_train_accuracy: 0.249
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0348
- 0.0918
- 0.103
- 0.1202
- 0.0186
- 0.1321
- 0.017
- 0.0197
- 0.0167
- 0.1343
- 0.0178
- 0.0198
- 0.018
- 0.0185
- 0.0178
- 0.0187
- 0.1413
- 0.1508
- 0.1558
- 0.1596
- 0.1677
- 0.018
- 0.0187
- 0.1643
- 0.1771
- 0.0183
- 0.1765
- 0.0185
- 0.1829
- 0.0191
- 0.1934
- 0.0183
- 0.1998
- 0.0172
- 0.0172
- 0.2006
- 0.2049
- 0.2012
- 0.0177
- 0.0179
- 0.2094
- 0.207
- 0.212
- 0.0196
- 0.0198
- 0.0185
- 0.209
- 0.0198
- 0.0186
- 0.214
- 0.0185
- 0.0193
- 0.0188
- 0.2172
- 0.0187
- 0.0194
- 0.0181
- 0.0188
- 0.2193
- 0.0198
- 0.0199
- 0.2209
- 0.0193
- 0.0182
- 0.0192
- 0.0199
- 0.2207
- 0.0187
- 0.2293
- 0.2256
- 0.0192
- 0.0187
- 0.2283
- 0.0194
- 0.0199
- 0.236
- 0.0193
- 0.0198
- 0.2392
- 0.2324
- 0.0195
- 0.2314
- 0.0198
- 0.0198
- 0.0193
- 0.237
- 0.02
- 0.241
- 0.2432
- 0.2469
- 0.0189
- 0.0197
- 0.245
- 0.2397
- 0.02
- 0.0187
- 0.2444
- 0.2421
- 0.02
- 0.2393
test_loss_list:
- 1.8241927337646484
- 1.7462201690673829
- 1.7260787868499756
- 1.6884980154037477
- 4.579154605865479
- 1.6662990474700927
- 4.315489292144775
- 4.570576095581055
- 4.586972045898437
- 1.6225002765655518
- 4.421712989807129
- 4.565037441253662
- 4.285310564041137
- 4.49170485496521
- 4.362300119400024
- 4.6308340644836425
- 1.597850980758667
- 1.5714357709884643
- 1.581504623889923
- 1.575921573638916
- 1.5747902607917785
- 4.205677461624146
- 4.326360368728638
- 1.5645007157325745
- 1.5467669510841369
- 4.143990964889526
- 1.5388186120986937
- 4.558435773849487
- 1.5251225686073304
- 4.193626098632812
- 1.504014015197754
- 3.996775703430176
- 1.4992201232910156
- 4.3005232334136965
- 4.353647184371948
- 1.484144651889801
- 1.4798355293273926
- 1.49895583152771
- 4.3276274871826175
- 4.394358682632446
- 1.4888483691215515
- 1.5007071495056152
- 1.4924037051200867
- 4.389932498931885
- 4.5311242198944095
- 3.9968757247924804
- 1.4675294947624207
- 4.279690361022949
- 4.31677279472351
- 1.444222378730774
- 4.09695987701416
- 4.120460653305054
- 4.326179313659668
- 1.4186738204956055
- 3.9708366203308105
- 4.17244812965393
- 4.237814846038819
- 4.244581241607666
- 1.4066903281211853
- 3.9166494750976564
- 4.037223587036133
- 1.4003141689300538
- 3.8577629375457763
- 3.9266306018829344
- 4.115553379058838
- 4.184714851379394
- 1.3922346138954163
- 3.8091127681732178
- 1.3814128136634827
- 1.4095723915100098
- 3.97290301322937
- 3.9137753582000734
- 1.3907191967964172
- 3.858217172622681
- 4.078407163619995
- 1.3774170589447021
- 3.7003410053253174
- 4.257910470962525
- 1.371791353225708
- 1.3719613099098205
- 3.8532651615142823
- 1.3925329494476317
- 3.787220630645752
- 4.154434156417847
- 4.171906185150147
- 1.37331214427948
- 3.7499359798431398
- 1.3717443799972535
- 1.3813050746917725
- 1.3822346138954162
- 3.971411552429199
- 4.0244639873504635
- 1.3976701092720032
- 1.4189356398582458
- 3.916934108734131
- 3.8218726539611816
- 1.3878476476669313
- 1.4109161591529846
- 3.8721344470977783
- 1.4144813799858094
train_accuracy:
- 0.041
- 0.119
- 0.133
- 0.123
- 0.833
- 0.124
- 0.814
- 0.988
- 0.747
- 0.112
- 0.743
- 0.991
- 0.938
- 0.875
- 0.861
- 0.873
- 0.123
- 0.152
- 0.165
- 0.179
- 0.195
- 0.9
- 0.863
- 0.17
- 0.181
- 0.948
- 0.179
- 0.956
- 0.211
- 0.923
- 0.2
- 0.927
- 0.21
- 0.947
- 0.836
- 0.204
- 0.205
- 0.193
- 0.894
- 0.879
- 0.21
- 0.205
- 0.2
- 0.957
- 0.981
- 0.922
- 0.209
- 0.984
- 0.886
- 0.212
- 0.871
- 0.913
- 0.896
- 0.244
- 0.866
- 0.909
- 0.905
- 0.881
- 0.224
- 0.935
- 0.973
- 0.245
- 0.944
- 0.898
- 0.906
- 0.986
- 0.247
- 0.884
- 0.226
- 0.248
- 0.928
- 0.941
- 0.267
- 0.89
- 0.984
- 0.239
- 0.903
- 0.989
- 0.271
- 0.2
- 0.858
- 0.261
- 0.951
- 0.976
- 0.935
- 0.255
- 0.892
- 0.288
- 0.26
- 0.251
- 0.891
- 0.92
- 0.253
- 0.234
- 0.91
- 0.92
- 0.261
- 0.242
- 0.892
- 0.249
train_loss:
- 4.29
- 3.842
- 3.282
- 3.344
- 0.632
- 3.752
- 0.794
- 0.746
- 1.041
- 3.676
- 0.61
- 0.605
- 0.865
- 0.65
- 0.626
- 0.533
- 3.438
- 3.18
- 2.667
- 2.902
- 2.43
- 0.485
- 0.691
- 2.39
- 2.822
- 0.398
- 3.032
- 0.534
- 2.854
- 0.43
- 2.742
- 0.385
- 2.298
- 0.683
- 0.172
- 2.823
- 2.195
- 1.775
- 0.467
- 0.101
- 2.414
- 1.719
- 2.416
- 0.436
- 0.054
- 0.68
- 1.855
- 0.28
- 0.692
- 2.059
- 0.331
- 0.64
- 0.537
- 2.518
- 0.293
- 0.517
- 0.695
- 0.468
- 1.816
- 0.28
- 0.579
- 2.172
- 0.272
- 0.586
- 0.505
- 0.505
- 1.77
- 0.283
- 1.601
- 1.025
- 0.379
- 0.527
- 2.113
- 0.302
- 0.485
- 1.833
- 0.289
- 0.448
- 1.744
- 2.06
- 0.318
- 1.445
- 0.294
- 0.418
- 0.408
- 1.659
- 0.264
- 1.789
- 1.111
- 1.149
- 0.376
- 0.062
- 1.118
- 0.674
- 0.299
- 0.531
- 1.196
- 0.642
- 0.295
- 0.69
unequal: 0
verbose: 1
