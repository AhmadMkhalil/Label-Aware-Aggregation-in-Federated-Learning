avg_train_accuracy: 0.262
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0169
- 0.0681
- 0.0858
- 0.0182
- 0.1111
- 0.1132
- 0.1272
- 0.0179
- 0.0181
- 0.1276
- 0.1358
- 0.1421
- 0.1558
- 0.158
- 0.1692
- 0.0191
- 0.0185
- 0.0164
- 0.0179
- 0.1746
- 0.173
- 0.1736
- 0.0186
- 0.0185
- 0.0162
- 0.1858
- 0.0174
- 0.1863
- 0.0179
- 0.1902
- 0.0192
- 0.1901
- 0.1921
- 0.2012
- 0.0185
- 0.1965
- 0.0187
- 0.0191
- 0.019
- 0.2071
- 0.2088
- 0.2104
- 0.216
- 0.2129
- 0.2128
- 0.0189
- 0.0179
- 0.0191
- 0.0184
- 0.2127
- 0.019
- 0.215
- 0.019
- 0.2169
- 0.0191
- 0.0191
- 0.0194
- 0.0192
- 0.019
- 0.2219
- 0.2172
- 0.0192
- 0.0187
- 0.2243
- 0.0177
- 0.0189
- 0.227
- 0.0198
- 0.235
- 0.019
- 0.0191
- 0.2295
- 0.0187
- 0.2325
- 0.0197
- 0.2293
- 0.0197
- 0.2371
- 0.2373
- 0.2343
- 0.0208
- 0.0195
- 0.2366
- 0.0199
- 0.2331
- 0.2417
- 0.242
- 0.0208
- 0.0193
- 0.0198
- 0.0201
- 0.2404
- 0.2473
- 0.0202
- 0.0201
- 0.0196
- 0.2515
- 0.0197
- 0.02
- 0.2501
test_loss_list:
- 3.6827403354644774
- 1.7802745771408082
- 1.7458857536315917
- 4.283642253875732
- 1.699819507598877
- 1.6973731327056885
- 1.6631446814537048
- 4.706247072219849
- 4.769339475631714
- 1.6567525267601013
- 1.6468403983116149
- 1.624155580997467
- 1.6016093945503236
- 1.605973470211029
- 1.6047127151489258
- 4.56048318862915
- 4.660165529251099
- 4.374758586883545
- 4.272017440795898
- 1.5169658493995666
- 1.5457293367385865
- 1.5474273037910462
- 4.266846380233765
- 4.631750831604004
- 4.3040316295623775
- 1.50488023519516
- 4.454576501846313
- 1.5191782736778259
- 4.090156974792481
- 1.51483256816864
- 4.2331474494934085
- 1.5120898079872132
- 1.495237069129944
- 1.4974580025672912
- 4.454167013168335
- 1.4788356518745422
- 4.430954027175903
- 4.23273983001709
- 4.306650133132934
- 1.4703554677963258
- 1.48364342212677
- 1.4866862320899963
- 1.4735490918159484
- 1.5026726722717285
- 1.4945067691802978
- 4.204424467086792
- 4.219599161148071
- 4.202224206924439
- 4.350404882431031
- 1.4548933005332947
- 4.066463432312012
- 1.4436011576652528
- 4.292591819763183
- 1.445869255065918
- 3.918875551223755
- 4.154106960296631
- 4.2622801780700685
- 4.052404909133911
- 4.184643812179566
- 1.4082245564460754
- 1.4327380013465882
- 3.8368259143829344
- 4.033737888336182
- 1.4140256190299987
- 4.074919404983521
- 3.999476613998413
- 1.4021344256401063
- 3.9411967182159424
- 1.4032611536979676
- 3.929160461425781
- 4.220959758758545
- 1.4092297172546386
- 3.8930931854248048
- 1.4157512426376342
- 4.183010730743408
- 1.4258400416374206
- 3.8170556449890136
- 1.417949573993683
- 1.4216943764686585
- 1.4220309662818909
- 3.796688175201416
- 4.114103469848633
- 1.3981017589569091
- 3.7202880287170412
- 1.4233659672737122
- 1.4134485363960265
- 1.4087214493751525
- 3.6911299228668213
- 4.152885322570801
- 4.171546945571899
- 4.246134901046753
- 1.4050801753997804
- 1.3933487224578858
- 3.7358244132995604
- 3.910935821533203
- 4.181951551437378
- 1.373849744796753
- 3.6547398662567137
- 3.803671636581421
- 1.3932572269439698
train_accuracy:
- 0.913
- 0.058
- 0.07
- 0.887
- 0.107
- 0.114
- 0.095
- 0.893
- 0.937
- 0.121
- 0.148
- 0.172
- 0.154
- 0.197
- 0.163
- 0.948
- 0.87
- 0.907
- 0.836
- 0.162
- 0.158
- 0.211
- 0.884
- 0.887
- 0.54
- 0.18
- 0.678
- 0.189
- 0.86
- 0.186
- 0.957
- 0.189
- 0.201
- 0.204
- 0.863
- 0.179
- 0.882
- 0.922
- 0.941
- 0.218
- 0.198
- 0.16
- 0.23
- 0.213
- 0.198
- 0.88
- 0.775
- 0.947
- 0.826
- 0.193
- 0.912
- 0.244
- 0.88
- 0.196
- 0.913
- 0.947
- 0.878
- 0.906
- 0.879
- 0.227
- 0.226
- 0.95
- 0.913
- 0.266
- 0.795
- 0.891
- 0.2
- 0.816
- 0.262
- 0.87
- 0.89
- 0.242
- 0.826
- 0.247
- 0.871
- 0.226
- 0.927
- 0.247
- 0.211
- 0.192
- 0.948
- 0.965
- 0.254
- 0.926
- 0.251
- 0.259
- 0.192
- 0.941
- 0.956
- 0.868
- 0.87
- 0.193
- 0.289
- 0.96
- 0.968
- 0.839
- 0.252
- 0.96
- 0.941
- 0.262
train_loss:
- 0.584
- 4.548
- 3.482
- 0.592
- 3.963
- 3.124
- 3.44
- 0.602
- 0.95
- 3.135
- 2.463
- 3.195
- 3.169
- 2.712
- 2.282
- 0.471
- 0.73
- 1.078
- 0.883
- 3.181
- 2.053
- 2.42
- 0.49
- 0.654
- 0.878
- 2.76
- 0.63
- 2.352
- 0.572
- 1.978
- 0.392
- 2.244
- 2.775
- 1.742
- 0.536
- 3.019
- 0.403
- 0.609
- 0.041
- 2.634
- 1.74
- 2.288
- 1.604
- 1.23
- 1.494
- 0.477
- 0.851
- 0.577
- 0.752
- 1.459
- 0.347
- 2.404
- 0.401
- 1.287
- 0.291
- 0.033
- 0.651
- 0.599
- 0.06
- 2.405
- 1.538
- 0.29
- 0.532
- 2.114
- 0.473
- 0.526
- 2.369
- 0.374
- 1.586
- 0.359
- 0.648
- 1.797
- 0.342
- 1.298
- 0.378
- 1.508
- 0.316
- 1.141
- 1.117
- 1.739
- 0.257
- 0.547
- 1.384
- 0.25
- 0.999
- 0.896
- 1.445
- 0.241
- 0.461
- 0.645
- 0.075
- 1.324
- 1.589
- 0.255
- 0.013
- 0.527
- 1.176
- 0.21
- 0.406
- 1.002
unequal: 0
verbose: 1
