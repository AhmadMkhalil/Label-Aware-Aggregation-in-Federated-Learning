avg_train_accuracy: 0.353
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0275
- 0.0886
- 0.1048
- 0.1328
- 0.1397
- 0.1539
- 0.1626
- 0.1689
- 0.1814
- 0.184
- 0.1874
- 0.2027
- 0.2047
- 0.2064
- 0.2089
- 0.2175
- 0.214
- 0.2278
- 0.2245
- 0.2345
- 0.2384
- 0.2383
- 0.2346
- 0.2382
- 0.235
- 0.2403
- 0.2403
- 0.2431
- 0.2437
- 0.2247
- 0.2371
- 0.2473
- 0.2494
- 0.2478
- 0.2552
- 0.2577
- 0.2595
- 0.2572
- 0.2559
- 0.2638
- 0.2583
- 0.262
- 0.2618
- 0.2552
- 0.2638
- 0.2625
- 0.2701
- 0.2662
- 0.2615
- 0.2614
- 0.2575
- 0.2686
- 0.2528
- 0.2595
- 0.2665
- 0.2695
- 0.2658
- 0.2487
- 0.2632
- 0.2754
- 0.2728
- 0.2756
- 0.2797
- 0.2791
- 0.2769
- 0.2669
- 0.2743
- 0.2663
- 0.2691
- 0.273
- 0.2787
- 0.2704
- 0.2754
- 0.2745
- 0.2764
- 0.279
- 0.2806
- 0.2833
- 0.2749
- 0.2712
- 0.2801
- 0.2777
- 0.274
- 0.2799
- 0.2777
- 0.2829
- 0.2828
- 0.284
- 0.2814
- 0.2828
- 0.286
- 0.2792
- 0.2761
- 0.2852
- 0.2815
- 0.2691
- 0.279
- 0.2865
- 0.2781
- 0.2858
test_loss_list:
- 1.837496461868286
- 1.702155156135559
- 1.6598437881469728
- 1.6207481598854065
- 1.607020480632782
- 1.5822800850868226
- 1.5639644956588745
- 1.5528434419631958
- 1.532604706287384
- 1.5311100029945373
- 1.5206672906875611
- 1.4942787861824036
- 1.4916330671310425
- 1.4957676720619202
- 1.4788431668281554
- 1.4653964781761168
- 1.4682204556465148
- 1.4525205397605896
- 1.4517135977745057
- 1.437319166660309
- 1.436954026222229
- 1.435019416809082
- 1.4373756217956544
- 1.4352604484558105
- 1.4390345120429993
- 1.4258387684822083
- 1.4260999131202698
- 1.4161918997764587
- 1.4214986395835876
- 1.463184027671814
- 1.4115108394622802
- 1.3989141249656678
- 1.4053553438186646
- 1.3987599062919616
- 1.3886361145973205
- 1.3871739792823792
- 1.3879862809181214
- 1.3875910496711732
- 1.401534571647644
- 1.3836692810058593
- 1.3949379062652587
- 1.3905313634872436
- 1.3898298597335816
- 1.4004565072059632
- 1.384698143005371
- 1.3910683631896972
- 1.3762280559539795
- 1.388499641418457
- 1.3905919647216798
- 1.3881759929656983
- 1.425519473552704
- 1.3766617488861084
- 1.4189286160469055
- 1.3994188022613525
- 1.3760075902938842
- 1.3792337083816528
- 1.3860544776916504
- 1.4222723627090454
- 1.3861352896690369
- 1.3591311812400817
- 1.366422553062439
- 1.3664765191078185
- 1.3619137477874756
- 1.3715569496154785
- 1.3762220811843873
- 1.383585660457611
- 1.3638457226753236
- 1.4032579040527344
- 1.3740730047225953
- 1.372384054660797
- 1.3659449005126953
- 1.3753662705421448
- 1.3690114116668701
- 1.3727173709869385
- 1.3753914642333984
- 1.37304612159729
- 1.372395703792572
- 1.3668058562278746
- 1.3810685062408448
- 1.387670648097992
- 1.3785834193229676
- 1.3797596740722655
- 1.3776170825958252
- 1.369825806617737
- 1.3728174734115601
- 1.3667035627365112
- 1.3748079657554626
- 1.3674441814422607
- 1.3765933871269227
- 1.3664091420173645
- 1.36447701215744
- 1.381410105228424
- 1.3756237840652465
- 1.370296151638031
- 1.3707636451721192
- 1.3966856908798218
- 1.3769654393196107
- 1.3639703702926635
- 1.3906400775909424
- 1.3618019032478332
train_accuracy:
- 0.0
- 0.107
- 0.079
- 0.151
- 0.158
- 0.0
- 0.183
- 0.0
- 0.218
- 0.0
- 0.236
- 0.215
- 0.0
- 0.0
- 0.214
- 0.0
- 0.247
- 0.237
- 0.216
- 0.261
- 0.0
- 0.0
- 0.0
- 0.233
- 0.0
- 0.0
- 0.216
- 0.224
- 0.266
- 0.233
- 0.0
- 0.0
- 0.0
- 0.274
- 0.284
- 0.244
- 0.307
- 0.303
- 0.0
- 0.0
- 0.295
- 0.27
- 0.0
- 0.0
- 0.0
- 0.24
- 0.308
- 0.0
- 0.0
- 0.267
- 0.0
- 0.335
- 0.0
- 0.268
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.273
- 0.288
- 0.29
- 0.0
- 0.281
- 0.285
- 0.0
- 0.0
- 0.312
- 0.0
- 0.323
- 0.293
- 0.0
- 0.297
- 0.0
- 0.298
- 0.297
- 0.331
- 0.278
- 0.273
- 0.287
- 0.275
- 0.297
- 0.0
- 0.303
- 0.0
- 0.0
- 0.0
- 0.272
- 0.0
- 0.303
- 0.0
- 0.291
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.339
- 0.353
train_loss:
- 1.31
- 2.511
- 1.791
- 2.258
- 1.612
- 1.587
- 1.581
- 1.51
- 1.545
- 1.412
- 1.362
- 1.743
- 1.627
- 1.265
- 1.326
- 1.303
- 1.109
- 1.221
- 1.117
- 1.592
- 1.284
- 1.209
- 1.153
- 1.204
- 0.97
- 1.072
- 1.035
- 1.115
- 0.889
- 0.636
- 1.007
- 0.928
- 0.842
- 0.83
- 0.773
- 0.839
- 0.813
- 0.858
- 0.715
- 0.86
- 0.649
- 0.709
- 0.761
- 0.617
- 0.725
- 0.657
- 0.726
- 0.582
- 0.573
- 0.557
- 0.465
- 0.603
- 0.47
- 0.48
- 0.52
- 0.483
- 0.512
- 0.388
- 0.415
- 0.599
- 0.561
- 0.435
- 0.506
- 0.46
- 0.432
- 0.402
- 0.449
- 0.387
- 0.445
- 0.375
- 0.361
- 0.408
- 0.339
- 0.371
- 0.377
- 0.321
- 0.364
- 0.396
- 0.373
- 0.427
- 0.328
- 0.372
- 0.337
- 0.334
- 0.347
- 0.276
- 0.298
- 0.237
- 0.334
- 0.328
- 0.303
- 0.31
- 0.339
- 0.301
- 0.301
- 0.301
- 0.324
- 0.283
- 0.356
- 0.215
unequal: 0
verbose: 1
