avg_train_accuracy: 0.299
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0425
- 0.0906
- 0.1053
- 0.1242
- 0.1389
- 0.1481
- 0.1517
- 0.1612
- 0.1679
- 0.1793
- 0.1885
- 0.1852
- 0.1891
- 0.1976
- 0.1871
- 0.2113
- 0.2055
- 0.2151
- 0.2088
- 0.2216
- 0.2142
- 0.2248
- 0.2282
- 0.2318
- 0.2259
- 0.2378
- 0.2372
- 0.2394
- 0.2407
- 0.2426
- 0.2493
- 0.2453
- 0.2516
- 0.2511
- 0.2467
- 0.2541
- 0.2471
- 0.2564
- 0.2573
- 0.2588
- 0.2588
- 0.2534
- 0.2555
- 0.2583
- 0.2575
- 0.2603
- 0.2634
- 0.2585
- 0.2651
- 0.2494
- 0.2636
- 0.2635
- 0.2575
- 0.2512
- 0.2517
- 0.2718
- 0.2737
- 0.2654
- 0.2544
- 0.2713
- 0.2738
- 0.2733
- 0.2699
- 0.2783
- 0.2745
- 0.2778
- 0.2735
- 0.2788
- 0.273
- 0.2759
- 0.2782
- 0.2788
- 0.2788
- 0.277
- 0.2812
- 0.2796
- 0.2771
- 0.2809
- 0.2797
- 0.268
- 0.2815
- 0.275
- 0.2786
- 0.2801
- 0.2653
- 0.2769
- 0.2791
- 0.2768
- 0.279
- 0.2799
- 0.2816
- 0.2822
- 0.2732
- 0.282
- 0.2784
- 0.2725
- 0.2832
- 0.2815
- 0.2846
- 0.2815
test_loss_list:
- 1.8114391565322876
- 1.7104614901542663
- 1.695342025756836
- 1.6529362726211547
- 1.6167503190040589
- 1.60618816614151
- 1.5935576915740968
- 1.567563121318817
- 1.5574046325683595
- 1.5311060404777528
- 1.5232731771469117
- 1.5341072535514833
- 1.5185935282707215
- 1.49728520154953
- 1.5317887473106384
- 1.4753670716285705
- 1.4907597208023071
- 1.4727240777015687
- 1.4873446750640869
- 1.4662598872184753
- 1.4753380441665649
- 1.4540832877159118
- 1.4488944292068482
- 1.4483620047569274
- 1.4403843307495117
- 1.4255996775627136
- 1.4278056859970092
- 1.4217932891845704
- 1.41695570230484
- 1.4111324787139892
- 1.4132071232795715
- 1.412371006011963
- 1.4091136121749879
- 1.4062888407707215
- 1.4164343428611756
- 1.4046559882164003
- 1.411421537399292
- 1.3924289560317993
- 1.3951044368743897
- 1.39659042596817
- 1.388682518005371
- 1.3985597968101502
- 1.3942162775993348
- 1.383861062526703
- 1.3993121433258056
- 1.3847584867477416
- 1.3840419125556946
- 1.3977205014228822
- 1.3905344343185424
- 1.4176298093795776
- 1.3779935693740846
- 1.3743984127044677
- 1.3862474870681762
- 1.4106231451034545
- 1.4046357941627503
- 1.357486562728882
- 1.3648040628433227
- 1.3654077339172364
- 1.4151191210746765
- 1.3639439153671264
- 1.3686609220504762
- 1.3674918389320374
- 1.3804670691490173
- 1.3624109816551209
- 1.36313645362854
- 1.3630103516578673
- 1.3767189764976502
- 1.3686213612556457
- 1.3701912665367126
- 1.3647752213478088
- 1.3669652771949767
- 1.3681707644462586
- 1.3714058208465576
- 1.3723371076583861
- 1.3669855856895448
- 1.3714414763450622
- 1.378106095790863
- 1.3670828533172608
- 1.3731033849716185
- 1.3971838426589966
- 1.3712463831901551
- 1.3721286940574646
- 1.3642406058311463
- 1.3699277544021606
- 1.401982319355011
- 1.372184889316559
- 1.3617008233070373
- 1.3732861971855164
- 1.3584651827812195
- 1.361137216091156
- 1.3622306299209594
- 1.367654013633728
- 1.383450951576233
- 1.3653256177902222
- 1.3767347025871277
- 1.3719201707839965
- 1.3585396814346313
- 1.372628517150879
- 1.3586029624938964
- 1.3651840162277222
train_accuracy:
- 0.069
- 0.0
- 0.0
- 0.0
- 0.16
- 0.131
- 0.153
- 0.194
- 0.0
- 0.192
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.176
- 0.0
- 0.231
- 0.229
- 0.245
- 0.177
- 0.0
- 0.0
- 0.239
- 0.0
- 0.258
- 0.217
- 0.204
- 0.262
- 0.0
- 0.258
- 0.0
- 0.263
- 0.267
- 0.0
- 0.2
- 0.27
- 0.223
- 0.286
- 0.296
- 0.28
- 0.216
- 0.0
- 0.223
- 0.0
- 0.234
- 0.225
- 0.0
- 0.216
- 0.0
- 0.21
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.301
- 0.0
- 0.293
- 0.319
- 0.0
- 0.274
- 0.0
- 0.232
- 0.28
- 0.0
- 0.303
- 0.228
- 0.249
- 0.269
- 0.253
- 0.225
- 0.0
- 0.324
- 0.0
- 0.242
- 0.0
- 0.232
- 0.224
- 0.339
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.305
- 0.0
- 0.264
- 0.306
- 0.0
- 0.249
- 0.0
- 0.304
- 0.0
- 0.0
- 0.289
- 0.0
- 0.283
- 0.299
train_loss:
- 2.739
- 1.82
- 1.18
- 1.636
- 2.073
- 1.61
- 1.528
- 1.497
- 1.458
- 2.322
- 2.167
- 1.324
- 1.319
- 1.351
- 0.877
- 1.966
- 1.13
- 1.455
- 1.062
- 1.314
- 0.999
- 1.108
- 1.166
- 1.407
- 1.046
- 1.217
- 1.104
- 1.174
- 1.072
- 1.099
- 1.003
- 0.924
- 0.964
- 1.047
- 0.767
- 0.872
- 0.704
- 0.889
- 0.82
- 0.789
- 0.81
- 0.609
- 0.665
- 0.697
- 0.59
- 0.636
- 0.603
- 0.556
- 0.543
- 0.455
- 0.617
- 0.57
- 0.479
- 0.433
- 0.509
- 0.643
- 0.491
- 0.561
- 0.485
- 0.542
- 0.492
- 0.413
- 0.483
- 0.428
- 0.438
- 0.433
- 0.453
- 0.413
- 0.387
- 0.379
- 0.372
- 0.353
- 0.381
- 0.353
- 0.353
- 0.326
- 0.367
- 0.321
- 0.293
- 0.371
- 0.333
- 0.354
- 0.373
- 0.306
- 0.346
- 0.316
- 0.314
- 0.304
- 0.288
- 0.316
- 0.261
- 0.282
- 0.317
- 0.239
- 0.294
- 0.3
- 0.247
- 0.276
- 0.215
- 0.246
unequal: 0
verbose: 1
