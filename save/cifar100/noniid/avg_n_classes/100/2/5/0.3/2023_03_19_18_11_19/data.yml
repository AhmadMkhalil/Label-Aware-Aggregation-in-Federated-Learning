avg_train_accuracy: 0.286
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.031
- 0.09
- 0.1172
- 0.1282
- 0.0881
- 0.1333
- 0.1404
- 0.1622
- 0.1565
- 0.1749
- 0.1632
- 0.1719
- 0.1703
- 0.1952
- 0.1828
- 0.1458
- 0.2051
- 0.2045
- 0.2003
- 0.2138
- 0.2023
- 0.2119
- 0.1629
- 0.2253
- 0.2064
- 0.2292
- 0.2307
- 0.2174
- 0.2142
- 0.2233
- 0.2351
- 0.2343
- 0.2381
- 0.2372
- 0.1896
- 0.2326
- 0.2268
- 0.1453
- 0.241
- 0.2338
- 0.2256
- 0.2413
- 0.1952
- 0.2472
- 0.2424
- 0.2368
- 0.231
- 0.2492
- 0.25
- 0.2372
- 0.2517
- 0.2512
- 0.2459
- 0.2558
- 0.2448
- 0.2534
- 0.2556
- 0.2433
- 0.2637
- 0.2637
- 0.2499
- 0.2538
- 0.2501
- 0.2695
- 0.2572
- 0.2653
- 0.2588
- 0.2591
- 0.2433
- 0.26
- 0.2674
- 0.2556
- 0.2614
- 0.2678
- 0.259
- 0.2699
- 0.2562
- 0.2673
- 0.2632
- 0.2539
- 0.256
- 0.2673
- 0.2229
- 0.2581
- 0.2668
- 0.276
- 0.2654
- 0.2638
- 0.2642
- 0.2607
- 0.2708
- 0.2615
- 0.2699
- 0.2763
- 0.2655
- 0.2721
- 0.2741
- 0.2584
- 0.2668
- 0.2692
test_loss_list:
- 1.8215195941925049
- 1.7055404901504516
- 1.6625742411613464
- 1.6424358987808227
- 1.6878466033935546
- 1.5915641903877258
- 1.5981891679763793
- 1.5579382538795472
- 1.583266441822052
- 1.543591969013214
- 1.5762697958946228
- 1.5470108151435853
- 1.5634396386146545
- 1.5204949760437012
- 1.5536671209335327
- 1.582092924118042
- 1.4552634620666505
- 1.4654732465744018
- 1.4916278910636902
- 1.4629949474334716
- 1.4892491674423218
- 1.4923776388168335
- 1.5139859056472778
- 1.404657425880432
- 1.4591418838500976
- 1.4292828965187072
- 1.4265119576454162
- 1.4694470930099488
- 1.4728389739990235
- 1.4417607617378234
- 1.4378350496292114
- 1.4404720330238343
- 1.434133439064026
- 1.4365618205070496
- 1.4792592120170593
- 1.414530692100525
- 1.4294015097618102
- 1.54878262758255
- 1.3573690724372864
- 1.4184155225753785
- 1.4319374680519104
- 1.3906688070297242
- 1.4502200055122376
- 1.3498494338989258
- 1.3704957461357117
- 1.4003801918029786
- 1.4206372332572936
- 1.3779989576339722
- 1.3870711135864258
- 1.4407077836990356
- 1.389614427089691
- 1.4079818296432496
- 1.4342829656600953
- 1.4012262558937072
- 1.4499821448326111
- 1.4178940868377685
- 1.4113897132873534
- 1.4481790208816527
- 1.3924718165397645
- 1.4048503255844116
- 1.4575692534446716
- 1.4394762706756592
- 1.4357802987098693
- 1.3903349661827087
- 1.4412106609344482
- 1.4018027400970459
- 1.4195781421661378
- 1.4409980058670044
- 1.445370635986328
- 1.4153364753723146
- 1.4054263234138489
- 1.4317399311065673
- 1.4211692380905152
- 1.410436978340149
- 1.4344870495796203
- 1.4162566351890564
- 1.4561054921150207
- 1.4133448910713196
- 1.4242072987556458
- 1.4666637587547302
- 1.4336941957473754
- 1.4147680473327637
- 1.4307924342155456
- 1.3810749983787536
- 1.356455762386322
- 1.3542570424079896
- 1.3917618465423585
- 1.3929234647750854
- 1.3970861506462098
- 1.4224603033065797
- 1.3832184743881226
- 1.4195153784751893
- 1.3854588079452514
- 1.3850439548492433
- 1.4116785883903504
- 1.3896388697624207
- 1.4035460448265076
- 1.4345342087745667
- 1.4205864572525024
- 1.403898355960846
train_accuracy:
- 0.033
- 0.0
- 0.136
- 0.138
- 0.382
- 0.149
- 0.0
- 0.182
- 0.197
- 0.0
- 0.0
- 0.188
- 0.0
- 0.195
- 0.0
- 0.403
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.223
- 0.535
- 0.245
- 0.0
- 0.0
- 0.241
- 0.0
- 0.239
- 0.227
- 0.0
- 0.0
- 0.264
- 0.239
- 0.57
- 0.243
- 0.0
- 0.001
- 0.262
- 0.0
- 0.241
- 0.0
- 0.443
- 0.261
- 0.267
- 0.0
- 0.0
- 0.0
- 0.284
- 0.266
- 0.278
- 0.285
- 0.0
- 0.276
- 0.0
- 0.278
- 0.277
- 0.0
- 0.29
- 0.281
- 0.0
- 0.0
- 0.0
- 0.303
- 0.0
- 0.276
- 0.0
- 0.284
- 0.0
- 0.33
- 0.278
- 0.0
- 0.0
- 0.0
- 0.0
- 0.281
- 0.0
- 0.278
- 0.281
- 0.0
- 0.0
- 0.265
- 0.084
- 0.0
- 0.31
- 0.288
- 0.0
- 0.0
- 0.263
- 0.278
- 0.288
- 0.287
- 0.315
- 0.332
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.286
train_loss:
- 1.792
- 2.636
- 2.549
- 2.355
- 0.609
- 2.266
- 1.363
- 3.117
- 1.322
- 2.132
- 1.261
- 1.312
- 1.193
- 2.421
- 1.167
- 0.542
- 1.903
- 1.583
- 1.223
- 1.642
- 1.033
- 1.143
- 0.579
- 1.993
- 1.002
- 1.378
- 1.346
- 0.91
- 0.98
- 1.137
- 1.168
- 1.046
- 1.437
- 1.177
- 0.494
- 0.638
- 0.739
- 0.474
- 1.094
- 0.726
- 0.606
- 1.102
- 0.437
- 0.826
- 0.795
- 0.667
- 0.537
- 0.912
- 0.744
- 0.532
- 0.748
- 0.631
- 0.581
- 0.666
- 0.518
- 0.56
- 0.628
- 0.661
- 0.713
- 0.52
- 0.42
- 0.511
- 0.508
- 0.745
- 0.426
- 0.64
- 0.442
- 0.431
- 0.514
- 0.575
- 0.451
- 0.414
- 0.367
- 0.392
- 0.387
- 0.327
- 0.399
- 0.334
- 0.34
- 0.33
- 0.462
- 0.36
- 0.428
- 0.272
- 0.437
- 0.292
- 0.284
- 0.335
- 0.287
- 0.316
- 0.46
- 0.299
- 0.366
- 0.334
- 0.372
- 0.282
- 0.253
- 0.394
- 0.336
- 0.319
unequal: 0
verbose: 1
