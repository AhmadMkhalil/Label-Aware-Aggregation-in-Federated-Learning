avg_train_accuracy: 0.276
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0382
- 0.0937
- 0.1183
- 0.1321
- 0.1434
- 0.1384
- 0.164
- 0.1712
- 0.1597
- 0.1746
- 0.1817
- 0.1478
- 0.1682
- 0.1709
- 0.1771
- 0.1793
- 0.1952
- 0.1871
- 0.1994
- 0.1873
- 0.2101
- 0.202
- 0.2201
- 0.2165
- 0.2113
- 0.2073
- 0.2104
- 0.2296
- 0.2115
- 0.2126
- 0.2227
- 0.2178
- 0.2396
- 0.2245
- 0.2327
- 0.2421
- 0.2273
- 0.2289
- 0.2433
- 0.2321
- 0.2391
- 0.2116
- 0.2401
- 0.1688
- 0.2383
- 0.2397
- 0.152
- 0.2468
- 0.2468
- 0.2516
- 0.2351
- 0.2292
- 0.2587
- 0.2502
- 0.2517
- 0.2517
- 0.2451
- 0.1922
- 0.2617
- 0.2373
- 0.2601
- 0.2561
- 0.2593
- 0.2587
- 0.2609
- 0.2607
- 0.2597
- 0.2491
- 0.2481
- 0.1939
- 0.26
- 0.2443
- 0.254
- 0.2512
- 0.2614
- 0.2525
- 0.2646
- 0.2701
- 0.2667
- 0.1968
- 0.259
- 0.2534
- 0.1832
- 0.1092
- 0.2688
- 0.2682
- 0.2633
- 0.2694
- 0.2588
- 0.2591
- 0.2705
- 0.2669
- 0.2719
- 0.272
- 0.2727
- 0.2073
- 0.2763
- 0.2761
- 0.261
- 0.2752
test_loss_list:
- 1.8238813066482544
- 1.7205749225616456
- 1.672589626312256
- 1.6461409091949464
- 1.627844204902649
- 1.6656767106056214
- 1.5898215246200562
- 1.5912884449958802
- 1.6329726362228394
- 1.584551751613617
- 1.5728796815872192
- 1.5424978733062744
- 1.5324742078781128
- 1.5502281975746155
- 1.5525388765335082
- 1.5460124468803407
- 1.5070814037322997
- 1.521629364490509
- 1.5018996715545654
- 1.5451268768310547
- 1.4863884878158569
- 1.5188286089897156
- 1.4674021768569947
- 1.477405970096588
- 1.497133014202118
- 1.5071424770355224
- 1.5006452488899231
- 1.4619362258911133
- 1.5118460702896117
- 1.4942691445350647
- 1.4840397620201111
- 1.4975927519798278
- 1.4504010033607484
- 1.5041822433471679
- 1.480103816986084
- 1.4433550238609314
- 1.4816843748092652
- 1.4810492777824402
- 1.4432932353019714
- 1.4797296476364137
- 1.4526224446296692
- 1.4151803159713745
- 1.3975347900390624
- 1.4813812375068665
- 1.3837867164611817
- 1.3937185406684875
- 1.5610354018211365
- 1.3487352418899536
- 1.3785555291175842
- 1.3681351613998414
- 1.411931722164154
- 1.4402974224090577
- 1.3766811418533325
- 1.40335595369339
- 1.403767716884613
- 1.4124534845352172
- 1.4390440320968627
- 1.4890597105026244
- 1.3492380666732788
- 1.4219836139678954
- 1.382425925731659
- 1.3916120624542236
- 1.3874818968772888
- 1.4061236429214476
- 1.4009137773513793
- 1.4017638707160949
- 1.4096384048461914
- 1.4321817398071288
- 1.4396914339065552
- 1.5226204800605774
- 1.3642899680137635
- 1.4317978239059448
- 1.4062894415855407
- 1.4109312081336975
- 1.3913777518272399
- 1.4240732502937317
- 1.405103132724762
- 1.3879824686050415
- 1.3986810660362243
- 1.547146005630493
- 1.3838289284706116
- 1.4018470692634581
- 1.5000297784805299
- 1.822967791557312
- 1.3221034908294678
- 1.3458238387107848
- 1.374381730556488
- 1.3555734968185424
- 1.4020534539222718
- 1.3980713295936584
- 1.375806005001068
- 1.3822409701347351
- 1.3812299323081971
- 1.3903698539733886
- 1.3969303250312806
- 1.5258246493339538
- 1.339912576675415
- 1.3496941137313843
- 1.3994102358818055
- 1.370369966030121
train_accuracy:
- 0.044
- 0.115
- 0.102
- 0.125
- 0.126
- 0.108
- 0.19
- 0.161
- 0.0
- 0.208
- 0.17
- 0.387
- 0.0
- 0.179
- 0.155
- 0.0
- 0.0
- 0.0
- 0.186
- 0.0
- 0.188
- 0.0
- 0.255
- 0.227
- 0.0
- 0.234
- 0.0
- 0.241
- 0.0
- 0.0
- 0.0
- 0.243
- 0.242
- 0.0
- 0.249
- 0.223
- 0.0
- 0.0
- 0.0
- 0.0
- 0.271
- 0.272
- 0.0
- 0.057
- 0.247
- 0.225
- 0.137
- 0.242
- 0.0
- 0.236
- 0.225
- 0.0
- 0.283
- 0.234
- 0.237
- 0.237
- 0.0
- 0.295
- 0.303
- 0.0
- 0.272
- 0.296
- 0.241
- 0.291
- 0.253
- 0.297
- 0.0
- 0.0
- 0.0
- 0.249
- 0.259
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.278
- 0.26
- 0.0
- 0.292
- 0.267
- 0.0
- 0.585
- 0.483
- 0.271
- 0.0
- 0.0
- 0.323
- 0.0
- 0.0
- 0.271
- 0.0
- 0.271
- 0.271
- 0.287
- 0.285
- 0.294
- 0.277
- 0.0
- 0.276
train_loss:
- 1.851
- 2.701
- 3.445
- 2.464
- 2.336
- 1.39
- 3.123
- 2.774
- 1.202
- 2.596
- 1.849
- 0.633
- 1.177
- 1.189
- 1.033
- 1.072
- 1.656
- 1.242
- 1.466
- 0.887
- 1.775
- 0.995
- 2.017
- 1.499
- 1.098
- 1.006
- 0.819
- 1.295
- 0.976
- 1.018
- 0.953
- 0.854
- 1.083
- 0.734
- 0.882
- 1.246
- 0.775
- 0.757
- 0.919
- 0.879
- 0.9
- 0.52
- 0.806
- 0.466
- 0.564
- 0.611
- 0.38
- 0.688
- 0.577
- 0.908
- 0.627
- 0.498
- 0.897
- 0.637
- 0.579
- 0.607
- 0.498
- 0.418
- 0.793
- 0.474
- 0.537
- 0.539
- 0.534
- 0.462
- 0.522
- 0.553
- 0.46
- 0.415
- 0.408
- 0.432
- 0.447
- 0.303
- 0.349
- 0.427
- 0.378
- 0.336
- 0.304
- 0.511
- 0.461
- 0.35
- 0.319
- 0.352
- 0.413
- 0.207
- 0.332
- 0.351
- 0.298
- 0.328
- 0.321
- 0.288
- 0.319
- 0.308
- 0.316
- 0.337
- 0.282
- 0.314
- 0.251
- 0.264
- 0.291
- 0.333
unequal: 0
verbose: 1
