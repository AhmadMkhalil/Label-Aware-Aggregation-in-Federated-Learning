avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0379
- 0.0957
- 0.1072
- 0.1272
- 0.1429
- 0.1474
- 0.1652
- 0.1674
- 0.1586
- 0.1425
- 0.1601
- 0.1798
- 0.1683
- 0.184
- 0.1732
- 0.1995
- 0.2032
- 0.1919
- 0.2074
- 0.2115
- 0.2198
- 0.2249
- 0.2214
- 0.2261
- 0.2103
- 0.2084
- 0.223
- 0.1898
- 0.229
- 0.2082
- 0.2151
- 0.2103
- 0.2357
- 0.2415
- 0.2359
- 0.2475
- 0.2376
- 0.244
- 0.2422
- 0.2299
- 0.2264
- 0.2205
- 0.2232
- 0.2479
- 0.2517
- 0.2385
- 0.2437
- 0.2516
- 0.2569
- 0.2084
- 0.1019
- 0.2534
- 0.2352
- 0.2563
- 0.264
- 0.2377
- 0.258
- 0.2394
- 0.1774
- 0.2425
- 0.2456
- 0.2453
- 0.2638
- 0.2663
- 0.2652
- 0.2413
- 0.2514
- 0.2442
- 0.2571
- 0.2427
- 0.2558
- 0.2656
- 0.2522
- 0.2643
- 0.2655
- 0.2707
- 0.2699
- 0.2573
- 0.251
- 0.27
- 0.256
- 0.2634
- 0.2453
- 0.2565
- 0.2696
- 0.2102
- 0.2553
- 0.2565
- 0.2687
- 0.2574
- 0.2663
- 0.2709
- 0.2766
- 0.2566
- 0.1981
- 0.2615
- 0.2601
- 0.2754
- 0.2629
- 0.2637
test_loss_list:
- 1.8050609588623048
- 1.700289011001587
- 1.6929662704467774
- 1.6304372191429137
- 1.6065273404121398
- 1.6042246627807617
- 1.5778123211860657
- 1.5750960421562195
- 1.5991220545768738
- 1.5603278517723083
- 1.5483407378196716
- 1.5120813703536988
- 1.5525643372535705
- 1.5164068245887756
- 1.546357226371765
- 1.5041292428970336
- 1.4973648524284362
- 1.5370195126533508
- 1.5044578433036804
- 1.4796903347969055
- 1.4819812488555908
- 1.4749190020561218
- 1.4658912348747253
- 1.4660488557815552
- 1.509801733493805
- 1.5086568427085876
- 1.4889508199691772
- 1.4649772357940674
- 1.4073109459877013
- 1.4631335473060607
- 1.4583152222633362
- 1.4770128726959229
- 1.4255214834213257
- 1.4255548191070557
- 1.4357441830635072
- 1.4251905179023743
- 1.4316310930252074
- 1.4365570068359375
- 1.4423284554481506
- 1.4795647001266479
- 1.4713009977340699
- 1.4797495985031128
- 1.4886817836761475
- 1.4356402635574341
- 1.4318324065208434
- 1.4592997407913209
- 1.4526649451255798
- 1.4247946119308472
- 1.4240494894981384
- 1.4429180002212525
- 1.7213605642318726
- 1.3488863039016723
- 1.3972796487808228
- 1.3669508337974547
- 1.3700529766082763
- 1.4097316241264344
- 1.3842144370079041
- 1.435099289417267
- 1.5324819159507752
- 1.3876504397392273
- 1.4107769751548767
- 1.4069238710403442
- 1.3721621942520141
- 1.3792436408996582
- 1.3788750290870666
- 1.4484894275665283
- 1.4170457053184509
- 1.425658597946167
- 1.3931341981887817
- 1.4402968573570252
- 1.404367437362671
- 1.3937833786010743
- 1.4283872175216674
- 1.4060857963562012
- 1.4011048102378845
- 1.3948590517044068
- 1.4082215714454651
- 1.4360004734992982
- 1.4517145252227783
- 1.402656216621399
- 1.4392052698135376
- 1.4150503778457642
- 1.4669603037834167
- 1.4384894347190857
- 1.4118555617332458
- 1.4917860770225524
- 1.3803236126899718
- 1.392075891494751
- 1.361195478439331
- 1.3920663285255432
- 1.3723777103424073
- 1.3735564613342286
- 1.3722114610671996
- 1.4348843312263488
- 1.5360338258743287
- 1.3599325156211852
- 1.3728995537757873
- 1.3411095356941223
- 1.403372712135315
- 1.3875553369522096
train_accuracy:
- 0.056
- 0.14
- 0.0
- 0.129
- 0.188
- 0.0
- 0.167
- 0.181
- 0.0
- 0.271
- 0.126
- 0.224
- 0.203
- 0.0
- 0.166
- 0.0
- 0.203
- 0.0
- 0.194
- 0.0
- 0.227
- 0.245
- 0.278
- 0.194
- 0.253
- 0.192
- 0.0
- 0.271
- 0.238
- 0.0
- 0.0
- 0.0
- 0.219
- 0.0
- 0.0
- 0.244
- 0.222
- 0.266
- 0.315
- 0.0
- 0.0
- 0.0
- 0.0
- 0.243
- 0.252
- 0.218
- 0.0
- 0.269
- 0.325
- 0.294
- 0.48
- 0.0
- 0.226
- 0.283
- 0.252
- 0.0
- 0.319
- 0.0
- 0.209
- 0.0
- 0.0
- 0.252
- 0.254
- 0.237
- 0.297
- 0.244
- 0.231
- 0.0
- 0.0
- 0.0
- 0.227
- 0.0
- 0.272
- 0.286
- 0.0
- 0.25
- 0.316
- 0.248
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.315
- 0.268
- 0.25
- 0.268
- 0.328
- 0.0
- 0.322
- 0.303
- 0.0
- 0.249
- 0.0
- 0.266
- 0.308
- 0.291
- 0.0
train_loss:
- 2.98
- 2.681
- 1.487
- 2.56
- 3.226
- 2.239
- 2.855
- 2.672
- 1.425
- 0.607
- 1.188
- 2.015
- 1.218
- 1.823
- 1.11
- 1.863
- 1.742
- 1.117
- 1.534
- 1.639
- 1.474
- 1.823
- 1.474
- 1.797
- 0.918
- 0.942
- 1.173
- 0.518
- 1.073
- 0.826
- 0.854
- 0.761
- 1.221
- 1.121
- 0.88
- 1.183
- 0.872
- 0.867
- 0.772
- 0.626
- 0.683
- 0.766
- 0.548
- 0.988
- 0.997
- 0.712
- 0.644
- 0.884
- 0.778
- 0.46
- 0.295
- 0.596
- 0.472
- 0.642
- 0.829
- 0.39
- 0.527
- 0.371
- 0.404
- 0.473
- 0.595
- 0.412
- 0.694
- 0.594
- 0.429
- 0.374
- 0.488
- 0.433
- 0.427
- 0.406
- 0.441
- 0.439
- 0.398
- 0.356
- 0.51
- 0.377
- 0.462
- 0.453
- 0.404
- 0.362
- 0.311
- 0.278
- 0.323
- 0.4
- 0.302
- 0.383
- 0.252
- 0.271
- 0.458
- 0.366
- 0.313
- 0.28
- 0.398
- 0.349
- 0.338
- 0.321
- 0.254
- 0.254
- 0.299
- 0.28
unequal: 0
verbose: 1
