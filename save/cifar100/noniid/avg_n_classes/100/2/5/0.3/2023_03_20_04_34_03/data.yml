avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0368
- 0.0915
- 0.1121
- 0.1197
- 0.0858
- 0.1221
- 0.1426
- 0.1604
- 0.1498
- 0.1722
- 0.1628
- 0.1142
- 0.1868
- 0.1904
- 0.1273
- 0.0596
- 0.1865
- 0.1816
- 0.2004
- 0.2128
- 0.2023
- 0.2007
- 0.2176
- 0.2275
- 0.2241
- 0.2198
- 0.2226
- 0.2317
- 0.2302
- 0.2267
- 0.244
- 0.2401
- 0.243
- 0.2442
- 0.2478
- 0.2261
- 0.251
- 0.2515
- 0.2457
- 0.2511
- 0.2306
- 0.2293
- 0.2496
- 0.2454
- 0.2551
- 0.2363
- 0.26
- 0.2554
- 0.2488
- 0.2495
- 0.2575
- 0.2082
- 0.2493
- 0.2657
- 0.2618
- 0.2513
- 0.2694
- 0.1899
- 0.256
- 0.252
- 0.2677
- 0.265
- 0.2634
- 0.2025
- 0.2551
- 0.2523
- 0.2707
- 0.2703
- 0.2718
- 0.2675
- 0.2717
- 0.2179
- 0.2666
- 0.2627
- 0.2554
- 0.2512
- 0.2713
- 0.2651
- 0.2719
- 0.2539
- 0.2717
- 0.2722
- 0.2751
- 0.2716
- 0.2645
- 0.2096
- 0.2717
- 0.269
- 0.2778
- 0.2029
- 0.2682
- 0.2652
- 0.2759
- 0.2631
- 0.2798
- 0.2753
- 0.2768
- 0.2637
- 0.206
- 0.2816
test_loss_list:
- 1.8187630558013916
- 1.7193727445602418
- 1.679500823020935
- 1.6633944535255432
- 1.6712576007843019
- 1.6159705924987793
- 1.588903455734253
- 1.5817742228507996
- 1.5854998207092286
- 1.5505422043800354
- 1.5842744565010072
- 1.5830019688606263
- 1.4756510400772094
- 1.4837124347686768
- 1.5537564849853516
- 1.9634367227554321
- 1.468775486946106
- 1.4892829942703247
- 1.454974868297577
- 1.4472240781784058
- 1.4794658041000366
- 1.4798427438735962
- 1.4538084554672241
- 1.4419651579856874
- 1.444866304397583
- 1.4594952964782715
- 1.463156452178955
- 1.4405346488952637
- 1.4577222108840941
- 1.457552342414856
- 1.4266776609420777
- 1.4358795070648194
- 1.4295603466033935
- 1.433822319507599
- 1.4223788714408874
- 1.4864363622665406
- 1.426055691242218
- 1.429273693561554
- 1.4410984992980957
- 1.4292884039878846
- 1.477843267917633
- 1.4903372383117677
- 1.4351982259750367
- 1.4406361079216004
- 1.43182865858078
- 1.4708347702026368
- 1.4160482454299927
- 1.432211458683014
- 1.4531953144073486
- 1.4488080406188966
- 1.4200956797599793
- 1.4250400519371034
- 1.3831715512275695
- 1.351560471057892
- 1.369505660533905
- 1.4134139275550843
- 1.3783182454109193
- 1.4664371848106383
- 1.3524622559547423
- 1.3734688925743104
- 1.3527922129631043
- 1.3726446199417115
- 1.3767469787597657
- 1.4646452975273132
- 1.3533473587036133
- 1.3728057503700257
- 1.337678668498993
- 1.3442191886901855
- 1.3570219802856445
- 1.3691623258590697
- 1.3651527166366577
- 1.4534893369674682
- 1.326061849594116
- 1.3688920879364013
- 1.3938253092765809
- 1.3941340804100038
- 1.3503785276412963
- 1.3857879400253297
- 1.3703594064712525
- 1.4021933722496032
- 1.3670238327980042
- 1.3782645344734192
- 1.3776257061958312
- 1.376313397884369
- 1.40750239610672
- 1.490782322883606
- 1.3248003554344177
- 1.3373960590362548
- 1.3395880913734437
- 1.5089611339569091
- 1.3445950365066528
- 1.3603022575378418
- 1.3476225805282593
- 1.3740575551986693
- 1.3473385906219482
- 1.358199474811554
- 1.3591185426712036
- 1.394405493736267
- 1.5034874963760376
- 1.3164272499084473
train_accuracy:
- 0.034
- 0.0
- 0.107
- 0.0
- 0.639
- 0.0
- 0.135
- 0.0
- 0.0
- 0.192
- 0.161
- 0.026
- 0.21
- 0.0
- 0.559
- 0.295
- 0.192
- 0.181
- 0.202
- 0.208
- 0.0
- 0.0
- 0.0
- 0.243
- 0.0
- 0.0
- 0.213
- 0.0
- 0.0
- 0.221
- 0.232
- 0.0
- 0.0
- 0.244
- 0.259
- 0.0
- 0.265
- 0.264
- 0.243
- 0.262
- 0.0
- 0.0
- 0.263
- 0.0
- 0.0
- 0.0
- 0.0
- 0.258
- 0.264
- 0.0
- 0.273
- 0.046
- 0.0
- 0.0
- 0.0
- 0.0
- 0.273
- 0.705
- 0.0
- 0.259
- 0.258
- 0.0
- 0.305
- 0.483
- 0.264
- 0.0
- 0.27
- 0.291
- 0.274
- 0.285
- 0.286
- 0.634
- 0.263
- 0.0
- 0.25
- 0.0
- 0.268
- 0.0
- 0.28
- 0.0
- 0.294
- 0.0
- 0.274
- 0.26
- 0.0
- 0.161
- 0.302
- 0.281
- 0.283
- 0.655
- 0.289
- 0.263
- 0.0
- 0.0
- 0.0
- 0.285
- 0.281
- 0.0
- 0.406
- 0.0
train_loss:
- 3.025
- 2.776
- 2.61
- 1.559
- 0.679
- 1.404
- 2.218
- 2.057
- 1.41
- 1.983
- 1.356
- 0.581
- 1.959
- 1.953
- 0.46
- 0.214
- 1.08
- 1.128
- 1.831
- 1.746
- 1.16
- 1.084
- 1.531
- 1.929
- 1.526
- 1.315
- 1.201
- 1.482
- 0.933
- 0.961
- 1.677
- 1.257
- 1.167
- 1.161
- 1.376
- 0.776
- 1.184
- 1.207
- 0.959
- 0.97
- 0.611
- 0.589
- 0.975
- 0.82
- 0.975
- 0.551
- 0.947
- 0.696
- 0.692
- 0.656
- 0.706
- 0.452
- 0.548
- 0.72
- 0.71
- 0.401
- 0.629
- 0.44
- 0.558
- 0.518
- 0.668
- 0.459
- 0.497
- 0.334
- 0.403
- 0.293
- 0.565
- 0.448
- 0.537
- 0.47
- 0.488
- 0.31
- 0.462
- 0.311
- 0.237
- 0.342
- 0.454
- 0.453
- 0.362
- 0.37
- 0.397
- 0.413
- 0.336
- 0.355
- 0.307
- 0.353
- 0.408
- 0.324
- 0.313
- 0.34
- 0.316
- 0.257
- 0.231
- 0.269
- 0.315
- 0.27
- 0.33
- 0.246
- 0.344
- 0.296
unequal: 0
verbose: 1
