avg_train_accuracy: 0.347
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0403
- 0.0806
- 0.1096
- 0.1274
- 0.1347
- 0.1407
- 0.1506
- 0.1531
- 0.1627
- 0.1752
- 0.1681
- 0.1761
- 0.1881
- 0.1992
- 0.1846
- 0.1907
- 0.2119
- 0.2181
- 0.207
- 0.2151
- 0.2139
- 0.2149
- 0.2098
- 0.226
- 0.2091
- 0.218
- 0.2308
- 0.2346
- 0.2188
- 0.221
- 0.2361
- 0.2411
- 0.2022
- 0.2272
- 0.2453
- 0.1619
- 0.2414
- 0.2485
- 0.2532
- 0.2491
- 0.2441
- 0.2375
- 0.2528
- 0.2545
- 0.2069
- 0.2547
- 0.2381
- 0.2376
- 0.243
- 0.1734
- 0.2596
- 0.243
- 0.2586
- 0.2395
- 0.2416
- 0.2457
- 0.2547
- 0.247
- 0.2426
- 0.2608
- 0.2629
- 0.2571
- 0.2619
- 0.2652
- 0.2501
- 0.264
- 0.2625
- 0.2603
- 0.2622
- 0.2652
- 0.2529
- 0.2721
- 0.2676
- 0.2562
- 0.2601
- 0.256
- 0.2672
- 0.2709
- 0.272
- 0.2568
- 0.2705
- 0.2675
- 0.2152
- 0.2703
- 0.2745
- 0.2562
- 0.2722
- 0.2709
- 0.2711
- 0.2672
- 0.2606
- 0.2628
- 0.2739
- 0.2761
- 0.2714
- 0.2735
- 0.2737
- 0.275
- 0.2696
- 0.2785
test_loss_list:
- 1.812915291786194
- 1.7437484502792358
- 1.6673081064224242
- 1.6380080080032349
- 1.6175054216384888
- 1.6084988498687744
- 1.600372452735901
- 1.6060162377357483
- 1.5889637756347657
- 1.5623305749893188
- 1.5709559321403503
- 1.5472734928131104
- 1.551667742729187
- 1.5179692482948304
- 1.5496342921257018
- 1.5338744258880614
- 1.4969554042816162
- 1.486503667831421
- 1.5154317975044251
- 1.494612693786621
- 1.4990318417549133
- 1.5057338190078735
- 1.509307053089142
- 1.476349995136261
- 1.5055528044700623
- 1.496043643951416
- 1.4663640761375427
- 1.4655224466323853
- 1.5061817789077758
- 1.4929555416107179
- 1.4556257009506226
- 1.445747742652893
- 1.4330839157104491
- 1.411360216140747
- 1.3907481002807618
- 1.512610456943512
- 1.360714991092682
- 1.361965661048889
- 1.3651555705070495
- 1.3864657926559447
- 1.4080027627944947
- 1.4338100481033325
- 1.3937880182266236
- 1.3875257062911988
- 1.4224213528633118
- 1.3498665118217468
- 1.4042442321777344
- 1.4138142251968384
- 1.4165967226028442
- 1.4974279880523682
- 1.3156015181541443
- 1.380483775138855
- 1.3524794387817383
- 1.399358296394348
- 1.4006042289733887
- 1.3983641910552977
- 1.3693342423439026
- 1.3951075387001037
- 1.4254590725898744
- 1.3746796226501465
- 1.371542730331421
- 1.392685899734497
- 1.3799930000305176
- 1.3776017570495604
- 1.4239944839477539
- 1.3827861094474792
- 1.3874582648277283
- 1.3922233748435975
- 1.3931234192848205
- 1.3921498203277587
- 1.4345357418060303
- 1.389339838027954
- 1.391884014606476
- 1.4166202878952026
- 1.4279784035682679
- 1.4405411052703858
- 1.4029635286331177
- 1.404371201992035
- 1.387591416835785
- 1.431286835670471
- 1.3954957103729249
- 1.4129983043670655
- 1.4711862802505493
- 1.328592028617859
- 1.349454436302185
- 1.396614706516266
- 1.3595211935043334
- 1.367833435535431
- 1.3760773825645447
- 1.3924915504455566
- 1.4012767910957336
- 1.4008656549453735
- 1.3751251101493835
- 1.3799862790107726
- 1.391229829788208
- 1.3825369000434875
- 1.3850818586349487
- 1.3833749794960022
- 1.3945805072784423
- 1.38594642162323
train_accuracy:
- 0.0
- 0.0
- 0.122
- 0.0
- 0.145
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.185
- 0.191
- 0.197
- 0.0
- 0.0
- 0.0
- 0.235
- 0.238
- 0.248
- 0.0
- 0.0
- 0.279
- 0.232
- 0.0
- 0.0
- 0.264
- 0.304
- 0.248
- 0.0
- 0.259
- 0.0
- 0.287
- 0.466
- 0.255
- 0.302
- 0.008
- 0.0
- 0.0
- 0.295
- 0.0
- 0.288
- 0.0
- 0.309
- 0.264
- 0.349
- 0.28
- 0.0
- 0.0
- 0.0
- 0.637
- 0.296
- 0.0
- 0.305
- 0.0
- 0.225
- 0.265
- 0.302
- 0.323
- 0.0
- 0.316
- 0.261
- 0.0
- 0.0
- 0.311
- 0.0
- 0.26
- 0.259
- 0.309
- 0.0
- 0.323
- 0.243
- 0.323
- 0.282
- 0.275
- 0.0
- 0.0
- 0.0
- 0.309
- 0.0
- 0.0
- 0.0
- 0.331
- 0.188
- 0.346
- 0.3
- 0.291
- 0.311
- 0.337
- 0.344
- 0.0
- 0.329
- 0.0
- 0.0
- 0.317
- 0.322
- 0.32
- 0.342
- 0.316
- 0.0
- 0.347
train_loss:
- 1.832
- 1.662
- 2.64
- 2.395
- 2.348
- 2.266
- 2.107
- 1.462
- 1.332
- 2.139
- 1.315
- 1.89
- 1.261
- 1.871
- 1.128
- 1.119
- 2.078
- 2.203
- 1.085
- 1.394
- 1.306
- 1.213
- 1.091
- 1.361
- 0.908
- 0.91
- 1.271
- 1.146
- 0.809
- 0.819
- 1.278
- 1.146
- 0.524
- 0.695
- 0.94
- 0.426
- 0.936
- 1.217
- 1.22
- 1.004
- 0.578
- 0.494
- 1.035
- 1.124
- 0.432
- 0.694
- 0.604
- 0.448
- 0.524
- 0.43
- 0.903
- 0.409
- 0.569
- 0.415
- 0.717
- 0.428
- 0.724
- 0.543
- 0.49
- 0.597
- 0.633
- 0.406
- 0.382
- 0.677
- 0.433
- 0.562
- 0.475
- 0.47
- 0.353
- 0.41
- 0.442
- 0.562
- 0.49
- 0.367
- 0.424
- 0.348
- 0.441
- 0.335
- 0.41
- 0.39
- 0.382
- 0.337
- 0.366
- 0.312
- 0.327
- 0.275
- 0.275
- 0.365
- 0.296
- 0.329
- 0.34
- 0.307
- 0.36
- 0.257
- 0.25
- 0.358
- 0.244
- 0.264
- 0.324
- 0.174
unequal: 0
verbose: 1
