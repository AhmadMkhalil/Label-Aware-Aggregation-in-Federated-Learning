avg_train_accuracy: 0.259
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0444
- 0.095
- 0.1162
- 0.1153
- 0.1255
- 0.1399
- 0.1518
- 0.1596
- 0.1635
- 0.1676
- 0.1666
- 0.1945
- 0.1846
- 0.1954
- 0.1893
- 0.206
- 0.1979
- 0.2185
- 0.221
- 0.1919
- 0.2236
- 0.2195
- 0.1494
- 0.0767
- 0.2279
- 0.2328
- 0.2173
- 0.1541
- 0.2311
- 0.2185
- 0.2248
- 0.2367
- 0.2209
- 0.1549
- 0.2387
- 0.234
- 0.2447
- 0.2498
- 0.2296
- 0.2512
- 0.2392
- 0.2521
- 0.233
- 0.2394
- 0.2606
- 0.2413
- 0.256
- 0.2236
- 0.241
- 0.1584
- 0.2393
- 0.2517
- 0.2564
- 0.2451
- 0.2586
- 0.2578
- 0.2579
- 0.2605
- 0.259
- 0.2466
- 0.2543
- 0.2516
- 0.2568
- 0.2626
- 0.2477
- 0.2568
- 0.2543
- 0.2607
- 0.2525
- 0.2576
- 0.2746
- 0.2686
- 0.2749
- 0.2753
- 0.2623
- 0.2728
- 0.2754
- 0.2646
- 0.2769
- 0.2731
- 0.2121
- 0.2584
- 0.2645
- 0.2743
- 0.2775
- 0.2713
- 0.2677
- 0.2652
- 0.2728
- 0.2659
- 0.2656
- 0.2761
- 0.2783
- 0.2614
- 0.2726
- 0.2701
- 0.2786
- 0.2714
- 0.2666
- 0.2784
test_loss_list:
- 1.81307870388031
- 1.6964648675918579
- 1.6596539688110352
- 1.6499830794334411
- 1.6424083399772644
- 1.6236017179489135
- 1.5956973099708558
- 1.5858798933029175
- 1.5838952803611754
- 1.5725407671928406
- 1.5684689021110534
- 1.5257778716087342
- 1.5527135920524597
- 1.5243778800964356
- 1.5505242705345155
- 1.5110042405128479
- 1.53536052942276
- 1.484208734035492
- 1.4896869444847107
- 1.4517132306098939
- 1.4108352088928222
- 1.4360982751846314
- 1.5097154712677001
- 1.7811651086807252
- 1.37191401720047
- 1.3833790922164917
- 1.4306102967262269
- 1.5179030036926269
- 1.3669996571540832
- 1.4209852004051209
- 1.4170446729660033
- 1.395123507976532
- 1.4339601302146912
- 1.5528186655044556
- 1.3601702642440796
- 1.3911779189109803
- 1.3760854959487916
- 1.3724096703529358
- 1.4182890009880067
- 1.3814119505882263
- 1.418808946609497
- 1.3845225620269774
- 1.425440616607666
- 1.424024043083191
- 1.378292462825775
- 1.427453110218048
- 1.3958486080169679
- 1.3885897064208985
- 1.379350917339325
- 1.5355397057533264
- 1.353683488368988
- 1.338886284828186
- 1.3372821187973023
- 1.3925729036331176
- 1.3514962244033812
- 1.3637652826309203
- 1.3637045764923095
- 1.3599216318130494
- 1.374334740638733
- 1.4205072808265686
- 1.4028314018249513
- 1.41187420129776
- 1.4026245546340943
- 1.3854228448867798
- 1.4252174019813537
- 1.393236949443817
- 1.408653554916382
- 1.39026780128479
- 1.409976065158844
- 1.4026371955871582
- 1.3632014107704162
- 1.3696205735206604
- 1.3705130767822267
- 1.3820758390426635
- 1.4180534291267395
- 1.376997241973877
- 1.3806351351737975
- 1.418076858520508
- 1.3769192171096802
- 1.3791754722595215
- 1.4915345191955567
- 1.3610677981376649
- 1.372244131565094
- 1.3398278617858888
- 1.3522925901412963
- 1.3825003576278687
- 1.3953885197639466
- 1.389364194869995
- 1.377164351940155
- 1.3928527188301087
- 1.390601897239685
- 1.3656681823730468
- 1.3717068552970886
- 1.4177390027046204
- 1.3910126328468322
- 1.3819964599609376
- 1.367341182231903
- 1.4064355659484864
- 1.4058992290496826
- 1.3716967058181764
train_accuracy:
- 0.0
- 0.102
- 0.093
- 0.118
- 0.0
- 0.0
- 0.165
- 0.0
- 0.0
- 0.0
- 0.147
- 0.206
- 0.151
- 0.0
- 0.164
- 0.179
- 0.196
- 0.239
- 0.0
- 0.138
- 0.209
- 0.208
- 0.734
- 0.054
- 0.188
- 0.196
- 0.0
- 0.412
- 0.201
- 0.0
- 0.0
- 0.21
- 0.0
- 0.389
- 0.0
- 0.0
- 0.0
- 0.258
- 0.0
- 0.219
- 0.0
- 0.263
- 0.0
- 0.248
- 0.267
- 0.221
- 0.271
- 0.312
- 0.223
- 0.192
- 0.218
- 0.266
- 0.218
- 0.0
- 0.0
- 0.231
- 0.276
- 0.233
- 0.266
- 0.0
- 0.267
- 0.0
- 0.22
- 0.241
- 0.218
- 0.0
- 0.268
- 0.0
- 0.0
- 0.221
- 0.285
- 0.274
- 0.285
- 0.0
- 0.0
- 0.28
- 0.0
- 0.0
- 0.246
- 0.0
- 0.544
- 0.0
- 0.0
- 0.283
- 0.274
- 0.0
- 0.227
- 0.237
- 0.0
- 0.0
- 0.0
- 0.0
- 0.289
- 0.216
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.259
train_loss:
- 1.76
- 2.796
- 2.577
- 1.523
- 1.467
- 1.512
- 2.016
- 2.135
- 1.37
- 1.393
- 1.356
- 2.581
- 1.214
- 1.814
- 1.129
- 1.758
- 1.143
- 2.275
- 1.641
- 0.612
- 2.033
- 1.386
- 0.492
- 0.272
- 1.393
- 1.748
- 0.834
- 0.464
- 1.385
- 0.744
- 0.786
- 1.241
- 0.736
- 0.392
- 0.902
- 0.743
- 1.014
- 1.154
- 0.653
- 1.072
- 0.869
- 0.988
- 0.643
- 0.684
- 1.069
- 0.629
- 0.689
- 0.46
- 0.456
- 0.342
- 0.331
- 0.573
- 0.751
- 0.383
- 0.822
- 0.48
- 0.663
- 0.597
- 0.526
- 0.364
- 0.577
- 0.452
- 0.406
- 0.62
- 0.537
- 0.546
- 0.364
- 0.421
- 0.451
- 0.477
- 0.598
- 0.502
- 0.516
- 0.487
- 0.384
- 0.442
- 0.426
- 0.36
- 0.395
- 0.379
- 0.342
- 0.182
- 0.356
- 0.355
- 0.319
- 0.374
- 0.266
- 0.317
- 0.342
- 0.334
- 0.31
- 0.25
- 0.346
- 0.341
- 0.386
- 0.327
- 0.285
- 0.291
- 0.251
- 0.349
unequal: 0
verbose: 1
