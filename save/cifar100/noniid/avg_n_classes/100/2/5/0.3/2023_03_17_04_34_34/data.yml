avg_train_accuracy: 0.307
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0449
- 0.1005
- 0.1145
- 0.1172
- 0.1362
- 0.128
- 0.1473
- 0.1643
- 0.1718
- 0.1795
- 0.1648
- 0.1666
- 0.1927
- 0.2015
- 0.2035
- 0.1852
- 0.1998
- 0.203
- 0.2049
- 0.203
- 0.2155
- 0.2179
- 0.205
- 0.2107
- 0.222
- 0.2281
- 0.2272
- 0.2214
- 0.2363
- 0.2384
- 0.2309
- 0.2402
- 0.2489
- 0.2536
- 0.2329
- 0.2456
- 0.2504
- 0.234
- 0.2093
- 0.2547
- 0.2553
- 0.2514
- 0.2495
- 0.2542
- 0.2388
- 0.254
- 0.2588
- 0.2539
- 0.2599
- 0.2502
- 0.2595
- 0.2515
- 0.2482
- 0.2473
- 0.2504
- 0.2485
- 0.2436
- 0.2512
- 0.2595
- 0.2594
- 0.2678
- 0.2651
- 0.2553
- 0.2564
- 0.2505
- 0.2559
- 0.2093
- 0.2581
- 0.2562
- 0.2621
- 0.2658
- 0.2694
- 0.2649
- 0.2706
- 0.2698
- 0.254
- 0.2536
- 0.2602
- 0.2613
- 0.2514
- 0.259
- 0.2645
- 0.2726
- 0.2764
- 0.2703
- 0.2618
- 0.2609
- 0.262
- 0.2762
- 0.265
- 0.2732
- 0.2724
- 0.2715
- 0.2672
- 0.2763
- 0.2678
- 0.2634
- 0.2735
- 0.2752
- 0.2697
test_loss_list:
- 1.7913801336288453
- 1.6923020362854004
- 1.6616457533836364
- 1.6781084442138672
- 1.6218473982810975
- 1.6513551545143128
- 1.6018043613433839
- 1.5814303517341615
- 1.5713524556159972
- 1.5704561924934388
- 1.5914970445632934
- 1.6093853735923767
- 1.5467393684387207
- 1.5291668438911439
- 1.536094193458557
- 1.5527277064323426
- 1.5246285581588745
- 1.5259020471572875
- 1.5376826643943786
- 1.5369766116142274
- 1.5066133332252503
- 1.50146151304245
- 1.5357235836982728
- 1.5166761922836303
- 1.4910888433456422
- 1.48718994140625
- 1.4827754020690918
- 1.5031441378593444
- 1.4690698337554933
- 1.465003023147583
- 1.4866283798217774
- 1.4750260996818543
- 1.4526758289337158
- 1.457011914253235
- 1.4957631945610046
- 1.473201913833618
- 1.4586764359474182
- 1.4957585668563842
- 1.4476442456245422
- 1.3755759358406068
- 1.3950557017326355
- 1.4100210309028625
- 1.4168781518936158
- 1.4179085993766785
- 1.4685356402397156
- 1.4265203619003295
- 1.425301606655121
- 1.4309088277816773
- 1.4239829301834106
- 1.4582956171035766
- 1.426169581413269
- 1.4475728511810302
- 1.45707998752594
- 1.4545532727241517
- 1.4545168089866638
- 1.4615147829055786
- 1.4782941961288452
- 1.4592147159576416
- 1.4177957916259765
- 1.424734628200531
- 1.4213902735710144
- 1.4173157215118408
- 1.4548232054710388
- 1.4503752708435058
- 1.4655286693572998
- 1.4471439743041992
- 1.4609371089935304
- 1.3908427906036378
- 1.3957809615135193
- 1.3928858971595763
- 1.387166223526001
- 1.3837473821640014
- 1.4053363633155822
- 1.3945193362236024
- 1.3942487239837646
- 1.436325831413269
- 1.4523325419425965
- 1.4318191647529601
- 1.4428641653060914
- 1.447269287109375
- 1.4217521286010741
- 1.4150957584381103
- 1.4070960474014282
- 1.4107140803337097
- 1.408420844078064
- 1.4352215003967286
- 1.4408389139175415
- 1.439742889404297
- 1.4100742769241332
- 1.436023256778717
- 1.4188592791557313
- 1.4171410655975343
- 1.4267306780815125
- 1.442951295375824
- 1.4191309762001039
- 1.4382343840599061
- 1.4430956172943115
- 1.413060986995697
- 1.4182442736625671
- 1.4389335918426513
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.121
- 0.0
- 0.132
- 0.138
- 0.215
- 0.106
- 0.21
- 0.195
- 0.0
- 0.0
- 0.254
- 0.155
- 0.0
- 0.249
- 0.0
- 0.0
- 0.0
- 0.271
- 0.0
- 0.208
- 0.216
- 0.214
- 0.253
- 0.0
- 0.0
- 0.0
- 0.289
- 0.0
- 0.0
- 0.26
- 0.303
- 0.0
- 0.286
- 0.279
- 0.0
- 0.107
- 0.271
- 0.282
- 0.267
- 0.0
- 0.23
- 0.0
- 0.297
- 0.0
- 0.233
- 0.305
- 0.0
- 0.263
- 0.0
- 0.26
- 0.304
- 0.0
- 0.0
- 0.0
- 0.0
- 0.276
- 0.291
- 0.306
- 0.278
- 0.0
- 0.289
- 0.302
- 0.268
- 0.261
- 0.277
- 0.0
- 0.0
- 0.313
- 0.281
- 0.28
- 0.305
- 0.271
- 0.248
- 0.0
- 0.267
- 0.0
- 0.0
- 0.259
- 0.253
- 0.251
- 0.32
- 0.318
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.251
- 0.312
- 0.0
- 0.0
- 0.0
- 0.288
- 0.0
- 0.285
- 0.307
train_loss:
- 3.084
- 2.637
- 2.47
- 1.507
- 2.419
- 1.557
- 2.22
- 2.236
- 2.098
- 1.957
- 1.306
- 1.132
- 2.045
- 2.238
- 1.723
- 1.304
- 1.666
- 1.517
- 1.161
- 0.998
- 1.745
- 1.377
- 1.029
- 1.134
- 1.346
- 1.207
- 1.254
- 1.067
- 1.194
- 1.33
- 0.905
- 1.083
- 1.399
- 1.257
- 0.757
- 0.923
- 1.034
- 0.759
- 0.522
- 1.148
- 0.855
- 0.858
- 0.811
- 0.778
- 0.573
- 0.797
- 0.841
- 0.648
- 0.796
- 0.615
- 0.652
- 0.625
- 0.618
- 0.549
- 0.58
- 0.517
- 0.465
- 0.552
- 0.673
- 0.624
- 0.526
- 0.519
- 0.466
- 0.417
- 0.52
- 0.385
- 0.539
- 0.408
- 0.456
- 0.412
- 0.369
- 0.464
- 0.371
- 0.35
- 0.362
- 0.405
- 0.425
- 0.391
- 0.359
- 0.436
- 0.445
- 0.334
- 0.304
- 0.357
- 0.314
- 0.31
- 0.361
- 0.377
- 0.372
- 0.37
- 0.348
- 0.333
- 0.277
- 0.292
- 0.28
- 0.336
- 0.401
- 0.333
- 0.248
- 0.329
unequal: 0
verbose: 1
