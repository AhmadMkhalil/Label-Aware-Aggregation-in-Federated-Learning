avg_train_accuracy: 0.0
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0483
- 0.0939
- 0.1053
- 0.1114
- 0.1363
- 0.1022
- 0.0381
- 0.0214
- 0.1329
- 0.1353
- 0.1571
- 0.1563
- 0.1588
- 0.1628
- 0.1329
- 0.0536
- 0.042
- 0.1732
- 0.171
- 0.1702
- 0.1841
- 0.1989
- 0.1911
- 0.1926
- 0.1508
- 0.1959
- 0.1951
- 0.1982
- 0.2101
- 0.2095
- 0.2058
- 0.1584
- 0.0753
- 0.0766
- 0.2068
- 0.1264
- 0.0884
- 0.2039
- 0.124
- 0.2072
- 0.1316
- 0.219
- 0.2181
- 0.1393
- 0.0735
- 0.2205
- 0.1426
- 0.2246
- 0.2127
- 0.2206
- 0.1591
- 0.2169
- 0.2162
- 0.224
- 0.1798
- 0.2207
- 0.2232
- 0.2269
- 0.1709
- 0.1307
- 0.0953
- 0.2188
- 0.14
- 0.2211
- 0.1471
- 0.1293
- 0.2335
- 0.1498
- 0.0961
- 0.2266
- 0.2281
- 0.2367
- 0.1727
- 0.2286
- 0.2249
- 0.1627
- 0.2376
- 0.1581
- 0.2328
- 0.1533
- 0.2308
- 0.1653
- 0.2334
- 0.2378
- 0.1702
- 0.2373
- 0.2317
- 0.1534
- 0.1402
- 0.2318
- 0.2309
- 0.2436
- 0.2462
- 0.1764
- 0.1259
- 0.2332
- 0.2378
- 0.2371
- 0.2346
- 0.2325
test_loss_list:
- 1.8120207262039185
- 1.7702692079544067
- 1.736216320991516
- 1.733312656879425
- 1.6818581008911133
- 1.6995067834854125
- 1.7943112659454346
- 1.8341748666763307
- 1.5975199246406555
- 1.6237900495529174
- 1.6157070565223695
- 1.6163362312316893
- 1.6107145404815675
- 1.6209990501403808
- 1.5928082942962647
- 1.7639098691940307
- 2.0516649866104126
- 1.5325927758216857
- 1.5580931615829468
- 1.5780220651626586
- 1.5795800042152406
- 1.5414437818527222
- 1.559426760673523
- 1.5626060390472412
- 1.575304307937622
- 1.5281036949157716
- 1.5499022507667541
- 1.5604053878784179
- 1.5313834691047667
- 1.5386371421813965
- 1.5568511366844178
- 1.6033451819419862
- 1.8912491989135742
- 1.7703601837158203
- 1.4760565209388732
- 1.6275011849403382
- 1.8437318086624146
- 1.4932577681541443
- 1.6620587873458863
- 1.4917349624633789
- 1.6203634691238404
- 1.445847713947296
- 1.4664512848854065
- 1.6395192790031432
- 2.0332383060455324
- 1.441103012561798
- 1.6334945154190064
- 1.4429970836639405
- 1.4932337021827697
- 1.483874945640564
- 1.580606291294098
- 1.4682375645637513
- 1.4925747680664063
- 1.4892245626449585
- 1.5465468573570251
- 1.4663360285758973
- 1.4908930945396424
- 1.4818913507461549
- 1.5679485416412353
- 1.658793532848358
- 1.8109142398834228
- 1.4583099389076233
- 1.7148358154296874
- 1.4581451797485352
- 1.600541114807129
- 1.6724624013900757
- 1.3939599800109863
- 1.6439652943611145
- 1.8884722518920898
- 1.4204329466819763
- 1.4413792848587037
- 1.4396523332595825
- 1.573405487537384
- 1.4355466866493225
- 1.4621280932426453
- 1.6214985132217408
- 1.4168826007843018
- 1.6185996913909912
- 1.4317802786827087
- 1.61806889295578
- 1.4230269742012025
- 1.6168538403511048
- 1.4223164844512939
- 1.4229883241653443
- 1.6015483570098876
- 1.4221338319778443
- 1.4585130333900451
- 1.6659542560577392
- 1.6360734677314759
- 1.4154174327850342
- 1.435202293395996
- 1.4268607020378112
- 1.4357984733581544
- 1.603049042224884
- 1.7557792782783508
- 1.4286273622512817
- 1.43084796667099
- 1.4478312635421753
- 1.4699904251098632
- 1.4832019448280334
train_accuracy:
- 0.079
- 0.0
- 0.108
- 0.0
- 0.167
- 0.065
- 0.806
- 0.811
- 0.17
- 0.0
- 0.0
- 0.17
- 0.202
- 0.0
- 0.245
- 0.002
- 0.261
- 0.0
- 0.0
- 0.2
- 0.265
- 0.21
- 0.0
- 0.0
- 0.0
- 0.253
- 0.263
- 0.27
- 0.225
- 0.0
- 0.0
- 0.508
- 0.543
- 0.667
- 0.0
- 0.038
- 0.278
- 0.244
- 0.68
- 0.258
- 0.004
- 0.0
- 0.0
- 0.196
- 0.444
- 0.0
- 0.216
- 0.29
- 0.0
- 0.0
- 0.42
- 0.303
- 0.283
- 0.261
- 0.463
- 0.0
- 0.0
- 0.0
- 0.252
- 0.046
- 0.606
- 0.0
- 0.622
- 0.0
- 0.527
- 0.392
- 0.26
- 0.669
- 0.539
- 0.277
- 0.266
- 0.25
- 0.453
- 0.0
- 0.0
- 0.104
- 0.309
- 0.34
- 0.001
- 0.455
- 0.288
- 0.45
- 0.001
- 0.301
- 0.258
- 0.0
- 0.314
- 0.31
- 0.338
- 0.001
- 0.0
- 0.001
- 0.274
- 0.518
- 0.553
- 0.0
- 0.0
- 0.0
- 0.305
- 0.0
train_loss:
- 3.034
- 1.706
- 1.666
- 1.472
- 2.304
- 0.699
- 0.576
- 0.584
- 1.169
- 1.208
- 1.254
- 1.149
- 1.297
- 1.187
- 0.572
- 0.442
- 0.303
- 1.143
- 0.82
- 0.808
- 1.09
- 1.448
- 0.927
- 1.027
- 0.583
- 0.91
- 0.766
- 0.72
- 1.152
- 0.856
- 0.674
- 0.457
- 0.404
- 0.321
- 0.813
- 0.372
- 0.246
- 0.596
- 0.434
- 0.548
- 0.48
- 0.675
- 0.594
- 0.429
- 0.245
- 0.848
- 0.384
- 0.718
- 0.522
- 0.642
- 0.392
- 0.533
- 0.424
- 0.554
- 0.372
- 0.308
- 0.427
- 0.45
- 0.335
- 0.333
- 0.23
- 0.375
- 0.239
- 0.334
- 0.303
- 0.269
- 0.595
- 0.306
- 0.157
- 0.382
- 0.392
- 0.41
- 0.288
- 0.311
- 0.316
- 0.308
- 0.488
- 0.272
- 0.288
- 0.246
- 0.35
- 0.292
- 0.33
- 0.354
- 0.295
- 0.268
- 0.237
- 0.226
- 0.234
- 0.196
- 0.337
- 0.301
- 0.263
- 0.25
- 0.164
- 0.306
- 0.313
- 0.26
- 0.291
- 0.217
unequal: 0
verbose: 1
