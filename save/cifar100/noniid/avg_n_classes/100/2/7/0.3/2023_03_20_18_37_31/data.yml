avg_train_accuracy: 0.256
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0484
- 0.0822
- 0.0504
- 0.0211
- 0.1053
- 0.0454
- 0.1208
- 0.1341
- 0.1435
- 0.1476
- 0.1088
- 0.1635
- 0.1242
- 0.1642
- 0.085
- 0.1642
- 0.184
- 0.173
- 0.1132
- 0.0724
- 0.1833
- 0.107
- 0.1782
- 0.1742
- 0.1935
- 0.1981
- 0.1923
- 0.2032
- 0.2019
- 0.1987
- 0.1625
- 0.1973
- 0.1331
- 0.0791
- 0.2009
- 0.2011
- 0.1548
- 0.2062
- 0.2075
- 0.2085
- 0.2055
- 0.2102
- 0.1664
- 0.1063
- 0.0734
- 0.0627
- 0.2074
- 0.2022
- 0.139
- 0.2291
- 0.2251
- 0.2172
- 0.224
- 0.1787
- 0.2161
- 0.1617
- 0.1046
- 0.2127
- 0.2241
- 0.2168
- 0.2215
- 0.2176
- 0.2298
- 0.2308
- 0.1897
- 0.2212
- 0.2171
- 0.2199
- 0.219
- 0.1736
- 0.168
- 0.2284
- 0.2368
- 0.2241
- 0.2234
- 0.2237
- 0.1728
- 0.2378
- 0.169
- 0.23
- 0.2375
- 0.2322
- 0.2309
- 0.2291
- 0.2262
- 0.233
- 0.1912
- 0.2381
- 0.23
- 0.1742
- 0.2269
- 0.1557
- 0.2331
- 0.2328
- 0.2388
- 0.2302
- 0.2377
- 0.2373
- 0.2287
- 0.2387
test_loss_list:
- 1.8130628871917724
- 1.765978503227234
- 1.7892731428146362
- 1.9434845113754273
- 1.673943943977356
- 1.78993679523468
- 1.6300067973136902
- 1.6352743983268738
- 1.6346390628814698
- 1.6501179075241088
- 1.6487075686454773
- 1.573225395679474
- 1.5852446842193604
- 1.5473420786857606
- 1.6948156213760377
- 1.5553039407730103
- 1.5244071459770203
- 1.5750058174133301
- 1.646153881549835
- 1.7526161432266236
- 1.5091735243797302
- 1.6294637036323547
- 1.5097916841506958
- 1.5510959792137147
- 1.5111387276649475
- 1.5211876511573792
- 1.5470876502990722
- 1.5190739035606384
- 1.5399213385581971
- 1.5523453187942504
- 1.5602346086502075
- 1.5102522730827332
- 1.6021263647079467
- 1.8560323810577393
- 1.4671851086616516
- 1.4934081602096558
- 1.5658708691596985
- 1.4644621706008911
- 1.485401575565338
- 1.514230043888092
- 1.517324719429016
- 1.5176621055603028
- 1.563791778087616
- 1.6920286011695862
- 1.8196626424789428
- 1.9933177375793456
- 1.4523659491539
- 1.492911500930786
- 1.6494771909713746
- 1.4214655613899232
- 1.4423370718955995
- 1.4853402805328368
- 1.4765767669677734
- 1.5289885950088502
- 1.4616772317886353
- 1.6093889093399047
- 1.8533682966232299
- 1.4563763427734375
- 1.452196514606476
- 1.4839013075828553
- 1.4830332541465758
- 1.4973350310325622
- 1.480418872833252
- 1.482222089767456
- 1.5349103951454162
- 1.4808790540695191
- 1.494361581802368
- 1.4994964623451232
- 1.5132668590545655
- 1.6194325804710388
- 1.5415194511413575
- 1.423360733985901
- 1.42146639585495
- 1.4798653101921082
- 1.4920556879043578
- 1.4841590428352356
- 1.6164666604995728
- 1.419961335659027
- 1.6351969480514525
- 1.4442131733894348
- 1.4469143438339234
- 1.4802949523925781
- 1.4916651773452758
- 1.5051282787322997
- 1.4989872932434083
- 1.4960392832756042
- 1.5296083307266235
- 1.4311282920837403
- 1.4667666363716125
- 1.5936320877075196
- 1.4430269408226013
- 1.6620483136177062
- 1.4409314537048339
- 1.457710611820221
- 1.4472831797599792
- 1.4738046360015868
- 1.4804786896705628
- 1.4659335160255431
- 1.494790165424347
- 1.478892424106598
train_accuracy:
- 0.055
- 0.108
- 0.286
- 0.002
- 0.0
- 0.672
- 0.0
- 0.0
- 0.172
- 0.176
- 0.138
- 0.0
- 0.476
- 0.0
- 0.02
- 0.162
- 0.0
- 0.0
- 0.552
- 0.189
- 0.0
- 0.118
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.2
- 0.0
- 0.0
- 0.309
- 0.208
- 0.303
- 0.742
- 0.001
- 0.253
- 0.554
- 0.0
- 0.0
- 0.0
- 0.0
- 0.227
- 0.454
- 0.88
- 0.633
- 0.7
- 0.0
- 0.223
- 0.618
- 0.246
- 0.0
- 0.241
- 0.0
- 0.358
- 0.261
- 0.518
- 0.788
- 0.0
- 0.23
- 0.0
- 0.24
- 0.0
- 0.264
- 0.0
- 0.298
- 0.249
- 0.0
- 0.235
- 0.0
- 0.56
- 0.458
- 0.0
- 0.27
- 0.289
- 0.0
- 0.0
- 0.45
- 0.275
- 0.51
- 0.269
- 0.271
- 0.0
- 0.283
- 0.0
- 0.253
- 0.0
- 0.566
- 0.27
- 0.0
- 0.544
- 0.0
- 0.393
- 0.28
- 0.001
- 0.0
- 0.0
- 0.002
- 0.296
- 0.0
- 0.256
train_loss:
- 2.996
- 1.59
- 0.708
- 0.526
- 1.434
- 0.541
- 1.39
- 1.29
- 1.351
- 1.213
- 0.513
- 1.832
- 0.518
- 1.37
- 0.502
- 1.154
- 1.699
- 0.997
- 0.481
- 0.384
- 0.96
- 0.365
- 0.903
- 0.733
- 1.064
- 0.946
- 0.776
- 1.033
- 0.893
- 0.741
- 0.446
- 0.662
- 0.373
- 0.253
- 0.839
- 0.624
- 0.425
- 0.67
- 0.714
- 0.583
- 0.695
- 0.642
- 0.341
- 0.394
- 0.279
- 0.288
- 0.435
- 0.392
- 0.32
- 0.873
- 0.783
- 0.452
- 0.528
- 0.366
- 0.466
- 0.27
- 0.222
- 0.439
- 0.578
- 0.402
- 0.498
- 0.389
- 0.488
- 0.475
- 0.333
- 0.419
- 0.334
- 0.33
- 0.275
- 0.301
- 0.394
- 0.336
- 0.394
- 0.267
- 0.295
- 0.297
- 0.314
- 0.429
- 0.258
- 0.311
- 0.311
- 0.246
- 0.275
- 0.28
- 0.339
- 0.346
- 0.312
- 0.322
- 0.266
- 0.257
- 0.327
- 0.248
- 0.219
- 0.25
- 0.256
- 0.271
- 0.227
- 0.21
- 0.256
- 0.198
unequal: 0
verbose: 1
