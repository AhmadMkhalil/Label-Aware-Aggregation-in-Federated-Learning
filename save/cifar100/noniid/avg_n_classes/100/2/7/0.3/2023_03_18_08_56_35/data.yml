avg_train_accuracy: 0.002
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0174
- 0.0691
- 0.0939
- 0.1042
- 0.0626
- 0.1142
- 0.1368
- 0.1444
- 0.0958
- 0.1486
- 0.0826
- 0.1433
- 0.1511
- 0.1564
- 0.1615
- 0.1653
- 0.1325
- 0.1651
- 0.1758
- 0.1488
- 0.1725
- 0.1892
- 0.1784
- 0.1853
- 0.1475
- 0.196
- 0.1845
- 0.1894
- 0.1545
- 0.1906
- 0.1883
- 0.1328
- 0.0854
- 0.1915
- 0.1929
- 0.2051
- 0.1965
- 0.2046
- 0.1988
- 0.205
- 0.2028
- 0.202
- 0.2026
- 0.2064
- 0.2035
- 0.199
- 0.2131
- 0.2109
- 0.2035
- 0.1788
- 0.2047
- 0.2127
- 0.207
- 0.2109
- 0.2086
- 0.1712
- 0.2141
- 0.2096
- 0.2186
- 0.2169
- 0.1652
- 0.2238
- 0.1581
- 0.2103
- 0.1519
- 0.2103
- 0.1593
- 0.2245
- 0.16
- 0.2128
- 0.1469
- 0.106
- 0.2124
- 0.2223
- 0.2165
- 0.2161
- 0.17
- 0.2144
- 0.1465
- 0.2275
- 0.2268
- 0.2292
- 0.1811
- 0.2264
- 0.2173
- 0.228
- 0.2269
- 0.1691
- 0.141
- 0.2252
- 0.2264
- 0.2265
- 0.1754
- 0.2214
- 0.1508
- 0.2323
- 0.2227
- 0.159
- 0.2282
- 0.2255
test_loss_list:
- 2.0401239824295043
- 1.7907920217514037
- 1.7466156768798828
- 1.7320843362808227
- 1.7629367351531982
- 1.6961935949325562
- 1.6647864627838134
- 1.6549115538597108
- 1.6784019732475282
- 1.6111955666542053
- 1.7273724746704102
- 1.6223496222496032
- 1.6444078874588013
- 1.6362127661705017
- 1.624108521938324
- 1.6388986563682557
- 1.6246557211875916
- 1.573639166355133
- 1.5888287544250488
- 1.5685020065307618
- 1.5489435172080994
- 1.5354689526557923
- 1.577255666255951
- 1.5705510330200196
- 1.5998460865020752
- 1.519419128894806
- 1.573707549571991
- 1.5788442540168761
- 1.581346344947815
- 1.5112075924873352
- 1.544664978981018
- 1.623743953704834
- 1.7253073930740357
- 1.5080494713783263
- 1.5271229124069214
- 1.5082432651519775
- 1.5444852352142333
- 1.531030123233795
- 1.5757929944992066
- 1.5526369261741637
- 1.5686642003059388
- 1.5853558850288392
- 1.5741444635391235
- 1.5815938210487366
- 1.586470627784729
- 1.6059107828140258
- 1.5650399947166442
- 1.588769781589508
- 1.5972144103050232
- 1.5833637738227844
- 1.5462343335151671
- 1.5222599244117736
- 1.5575452494621276
- 1.5707592344284058
- 1.583862428665161
- 1.5917056179046631
- 1.4964092564582825
- 1.5385069680213928
- 1.54132239818573
- 1.5396822261810303
- 1.632555296421051
- 1.4881872129440308
- 1.6001000452041625
- 1.4945857954025268
- 1.6509080338478088
- 1.4864406752586365
- 1.631855685710907
- 1.4482952117919923
- 1.6161064386367798
- 1.472004828453064
- 1.6937154364585876
- 1.826829195022583
- 1.4610549116134643
- 1.4649198508262635
- 1.499179286956787
- 1.5076898074150085
- 1.629808886051178
- 1.4893945479393005
- 1.6717987823486329
- 1.4472401452064514
- 1.4694427728652955
- 1.4839775204658507
- 1.6095650315284729
- 1.454870309829712
- 1.5061042284965516
- 1.4900219202041627
- 1.490600550174713
- 1.6510133242607117
- 1.70259028673172
- 1.4541046023368835
- 1.479414575099945
- 1.4954346299171448
- 1.6095767188072205
- 1.473905303478241
- 1.7214734220504762
- 1.4488778162002562
- 1.477089955806732
- 1.6933028435707091
- 1.4776706671714783
- 1.4856961226463319
train_accuracy:
- 0.55
- 0.088
- 0.0
- 0.0
- 0.589
- 0.0
- 0.0
- 0.155
- 0.315
- 0.181
- 0.566
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.04
- 0.227
- 0.0
- 0.335
- 0.0
- 0.2
- 0.0
- 0.257
- 0.51
- 0.259
- 0.0
- 0.0
- 0.263
- 0.0
- 0.0
- 0.338
- 0.011
- 0.0
- 0.0
- 0.277
- 0.0
- 0.0
- 0.0
- 0.264
- 0.251
- 0.0
- 0.0
- 0.0
- 0.249
- 0.0
- 0.234
- 0.0
- 0.0
- 0.426
- 0.0
- 0.309
- 0.0
- 0.298
- 0.0
- 0.221
- 0.0
- 0.0
- 0.0
- 0.239
- 0.228
- 0.238
- 0.287
- 0.224
- 0.206
- 0.0
- 0.325
- 0.0
- 0.575
- 0.0
- 0.32
- 0.111
- 0.311
- 0.321
- 0.0
- 0.322
- 0.245
- 0.0
- 0.606
- 0.0
- 0.0
- 0.326
- 0.392
- 0.314
- 0.0
- 0.317
- 0.299
- 0.442
- 0.746
- 0.002
- 0.247
- 0.287
- 0.353
- 0.0
- 0.619
- 0.275
- 0.0
- 0.306
- 0.274
- 0.002
train_loss:
- 0.542
- 1.602
- 1.643
- 1.481
- 0.538
- 1.362
- 1.479
- 1.94
- 0.645
- 2.045
- 0.544
- 1.031
- 0.956
- 1.153
- 1.341
- 0.993
- 0.493
- 1.245
- 0.998
- 0.57
- 0.8
- 1.343
- 0.837
- 1.054
- 0.504
- 1.609
- 0.785
- 0.83
- 0.47
- 0.856
- 0.627
- 0.433
- 0.4
- 0.649
- 0.614
- 1.032
- 0.709
- 0.789
- 0.535
- 0.652
- 0.689
- 0.549
- 0.633
- 0.504
- 0.557
- 0.45
- 0.684
- 0.458
- 0.503
- 0.457
- 0.41
- 0.581
- 0.501
- 0.508
- 0.425
- 0.392
- 0.366
- 0.38
- 0.366
- 0.447
- 0.306
- 0.308
- 0.393
- 0.349
- 0.284
- 0.403
- 0.316
- 0.305
- 0.286
- 0.27
- 0.29
- 0.205
- 0.166
- 0.264
- 0.288
- 0.246
- 0.32
- 0.233
- 0.294
- 0.261
- 0.228
- 0.24
- 0.247
- 0.254
- 0.244
- 0.233
- 0.24
- 0.24
- 0.209
- 0.23
- 0.209
- 0.222
- 0.314
- 0.205
- 0.202
- 0.241
- 0.142
- 0.193
- 0.265
- 0.183
unequal: 0
verbose: 1
