avg_train_accuracy: 0.278
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.093
- 0.0491
- 0.1148
- 0.0477
- 0.0227
- 0.1252
- 0.1363
- 0.1529
- 0.1599
- 0.1612
- 0.1751
- 0.1759
- 0.1852
- 0.1703
- 0.1598
- 0.0625
- 0.1823
- 0.1831
- 0.1868
- 0.187
- 0.1815
- 0.1971
- 0.1893
- 0.197
- 0.1826
- 0.1964
- 0.1981
- 0.2119
- 0.2087
- 0.2045
- 0.2016
- 0.1644
- 0.0784
- 0.2052
- 0.2042
- 0.2181
- 0.2077
- 0.2054
- 0.2211
- 0.212
- 0.2213
- 0.2131
- 0.2131
- 0.1807
- 0.2257
- 0.1637
- 0.2163
- 0.215
- 0.1533
- 0.2119
- 0.1423
- 0.0993
- 0.1073
- 0.2118
- 0.1554
- 0.2277
- 0.1538
- 0.1123
- 0.2118
- 0.1495
- 0.1011
- 0.1197
- 0.0833
- 0.2102
- 0.2171
- 0.2209
- 0.2195
- 0.2241
- 0.2183
- 0.2201
- 0.1624
- 0.2227
- 0.1632
- 0.1429
- 0.2244
- 0.2222
- 0.1644
- 0.218
- 0.1552
- 0.2275
- 0.1582
- 0.2232
- 0.1675
- 0.1256
- 0.2166
- 0.2273
- 0.1793
- 0.1547
- 0.2356
- 0.2341
- 0.1737
- 0.2285
- 0.2252
- 0.2317
- 0.1708
- 0.2333
- 0.2279
- 0.2323
- 0.1775
test_loss_list:
- 1.830796241760254
- 1.7413427591323853
- 1.7972690296173095
- 1.6716552829742433
- 1.7555278253555298
- 2.048062663078308
- 1.629769515991211
- 1.6572355818748474
- 1.6269711065292358
- 1.6184476113319397
- 1.6504495644569397
- 1.6121891164779663
- 1.6144058442115783
- 1.6067847275733949
- 1.6472919154167176
- 1.6006607484817506
- 1.740336730480194
- 1.5339007258415223
- 1.5519676089286805
- 1.5564984846115113
- 1.5769374918937684
- 1.591455864906311
- 1.568002917766571
- 1.603839566707611
- 1.5731648373603822
- 1.5402235174179078
- 1.5345416259765625
- 1.557730610370636
- 1.5302015519142151
- 1.5495770263671875
- 1.5804593920707704
- 1.5853426051139832
- 1.5990861415863038
- 1.8425386047363281
- 1.5058502840995789
- 1.5356099700927734
- 1.5039613699913026
- 1.5420293140411376
- 1.5638561201095582
- 1.5210902762413026
- 1.5638000392913818
- 1.5439168310165405
- 1.5641064882278441
- 1.576094124317169
- 1.5641906833648682
- 1.48696387052536
- 1.599150812625885
- 1.4770798540115357
- 1.5037478017807007
- 1.649360144138336
- 1.4988913655281066
- 1.6771844744682312
- 1.8873612022399902
- 1.7694029664993287
- 1.4615401196479798
- 1.6243276238441466
- 1.4299719882011415
- 1.6134757161140443
- 1.7606221556663513
- 1.455456018447876
- 1.6604441809654236
- 1.8483489990234374
- 1.7041988277435303
- 1.932086057662964
- 1.4382809710502624
- 1.4458004856109619
- 1.4617370128631593
- 1.470336573123932
- 1.4792071986198425
- 1.506288616657257
- 1.4981068634986878
- 1.646863627433777
- 1.4687716150283814
- 1.6240929794311523
- 1.6496587324142455
- 1.4353772830963134
- 1.4664638495445252
- 1.6483499264717103
- 1.4666235208511353
- 1.6523119473457337
- 1.4398998165130614
- 1.6827677536010741
- 1.4435576701164246
- 1.647194628715515
- 1.7993007373809815
- 1.4455075073242187
- 1.4521048331260682
- 1.5983712577819824
- 1.6659725952148436
- 1.3975678491592407
- 1.4205543684959412
- 1.5943213319778442
- 1.438115928173065
- 1.4588483500480651
- 1.4523600363731384
- 1.6460058450698853
- 1.42480144739151
- 1.4621335434913636
- 1.453341863155365
- 1.6290931916236877
train_accuracy:
- 0.0
- 0.119
- 0.216
- 0.116
- 0.74
- 0.495
- 0.127
- 0.133
- 0.144
- 0.16
- 0.192
- 0.146
- 0.201
- 0.0
- 0.0
- 0.031
- 0.007
- 0.0
- 0.0
- 0.189
- 0.19
- 0.0
- 0.0
- 0.0
- 0.218
- 0.405
- 0.175
- 0.0
- 0.172
- 0.229
- 0.0
- 0.0
- 0.56
- 0.622
- 0.0
- 0.217
- 0.0
- 0.0
- 0.0
- 0.0
- 0.218
- 0.0
- 0.0
- 0.235
- 0.509
- 0.0
- 0.664
- 0.0
- 0.225
- 0.675
- 0.001
- 0.782
- 0.5
- 0.632
- 0.0
- 0.517
- 0.001
- 0.15
- 0.442
- 0.0
- 0.536
- 0.09
- 0.419
- 0.547
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.51
- 0.0
- 0.575
- 0.419
- 0.263
- 0.0
- 0.498
- 0.0
- 0.322
- 0.008
- 0.477
- 0.009
- 0.39
- 0.488
- 0.002
- 0.001
- 0.297
- 0.516
- 0.249
- 0.001
- 0.102
- 0.004
- 0.001
- 0.252
- 0.464
- 0.253
- 0.246
- 0.218
- 0.278
train_loss:
- 1.69
- 2.669
- 0.639
- 2.507
- 0.59
- 0.464
- 2.486
- 1.369
- 2.121
- 2.715
- 1.421
- 1.98
- 1.723
- 1.736
- 1.062
- 0.752
- 0.468
- 1.038
- 1.069
- 0.987
- 0.881
- 0.884
- 1.214
- 0.801
- 1.189
- 0.521
- 0.75
- 0.788
- 1.38
- 0.96
- 0.776
- 0.631
- 0.499
- 0.298
- 0.695
- 0.678
- 0.833
- 0.644
- 0.592
- 0.832
- 0.448
- 0.697
- 0.613
- 0.464
- 0.45
- 0.76
- 0.447
- 0.294
- 0.507
- 0.333
- 0.217
- 0.47
- 0.177
- 0.305
- 0.568
- 0.258
- 0.428
- 0.423
- 0.281
- 0.346
- 0.262
- 0.2
- 0.397
- 0.21
- 0.402
- 0.373
- 0.285
- 0.548
- 0.277
- 0.261
- 0.42
- 0.326
- 0.403
- 0.298
- 0.317
- 0.282
- 0.325
- 0.251
- 0.373
- 0.291
- 0.203
- 0.203
- 0.128
- 0.288
- 0.204
- 0.355
- 0.246
- 0.293
- 0.223
- 0.246
- 0.224
- 0.269
- 0.235
- 0.22
- 0.232
- 0.23
- 0.254
- 0.176
- 0.213
- 0.296
unequal: 0
verbose: 1
