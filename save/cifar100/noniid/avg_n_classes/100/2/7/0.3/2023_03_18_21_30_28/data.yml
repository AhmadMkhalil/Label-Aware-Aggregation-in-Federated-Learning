avg_train_accuracy: 0.229
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0176
- 0.0179
- 0.0672
- 0.081
- 0.0385
- 0.0397
- 0.1051
- 0.1194
- 0.1269
- 0.0887
- 0.139
- 0.1549
- 0.1025
- 0.1619
- 0.1707
- 0.1768
- 0.1797
- 0.1494
- 0.0636
- 0.1832
- 0.1145
- 0.1869
- 0.1733
- 0.1872
- 0.1772
- 0.1839
- 0.154
- 0.1874
- 0.1892
- 0.14
- 0.202
- 0.1887
- 0.1407
- 0.1944
- 0.1991
- 0.1981
- 0.1996
- 0.2115
- 0.1519
- 0.2042
- 0.1509
- 0.2083
- 0.2133
- 0.2044
- 0.2089
- 0.2095
- 0.2081
- 0.2115
- 0.2126
- 0.2095
- 0.2054
- 0.2121
- 0.2173
- 0.2155
- 0.1753
- 0.2218
- 0.1494
- 0.2274
- 0.2169
- 0.211
- 0.1661
- 0.2227
- 0.2156
- 0.2233
- 0.2301
- 0.1853
- 0.1694
- 0.1051
- 0.2245
- 0.2226
- 0.2317
- 0.2267
- 0.2209
- 0.2181
- 0.1712
- 0.112
- 0.0822
- 0.1006
- 0.2201
- 0.2275
- 0.2299
- 0.2297
- 0.1657
- 0.0973
- 0.2308
- 0.2276
- 0.231
- 0.1814
- 0.2285
- 0.1714
- 0.2256
- 0.2284
- 0.1692
- 0.2263
- 0.2234
- 0.1759
- 0.2272
- 0.2373
- 0.1769
- 0.2344
test_loss_list:
- 2.0742396688461304
- 2.3452616500854493
- 1.7653159284591675
- 1.73244252204895
- 1.8276757383346558
- 1.7637349557876587
- 1.653975157737732
- 1.6419815707206726
- 1.65168048620224
- 1.6839457559585571
- 1.6117600464820863
- 1.5879174995422363
- 1.6217245841026307
- 1.5442490601539611
- 1.5554270029067994
- 1.5657098364830018
- 1.561754457950592
- 1.5525412964820862
- 1.859186086654663
- 1.5078462338447571
- 1.5964486765861512
- 1.4788943791389466
- 1.5406337356567383
- 1.5225606656074524
- 1.5720177698135376
- 1.5420143580436707
- 1.551946187019348
- 1.5195967745780945
- 1.5314368104934692
- 1.5636070466041565
- 1.467228763103485
- 1.5269931483268737
- 1.5669854617118835
- 1.4836828303337097
- 1.5037034916877747
- 1.509728467464447
- 1.521078646183014
- 1.5074743604660035
- 1.5840113377571106
- 1.482672266960144
- 1.5513654518127442
- 1.4499785709381103
- 1.452983865737915
- 1.50044429063797
- 1.5036936068534852
- 1.5123289179801942
- 1.5280044078826904
- 1.5171536803245544
- 1.5215535807609557
- 1.5384307217597961
- 1.5515985417366027
- 1.5185468792915344
- 1.5270878601074218
- 1.531508936882019
- 1.5385178637504577
- 1.4498482632637024
- 1.603836896419525
- 1.4350678181648255
- 1.4782458066940307
- 1.5106363654136659
- 1.5969467926025391
- 1.4660679507255554
- 1.4895860362052917
- 1.4890963459014892
- 1.4706725978851318
- 1.5293286514282227
- 1.5074777364730836
- 1.7446873712539672
- 1.4047183871269227
- 1.4386736059188843
- 1.4186086440086365
- 1.4608971667289734
- 1.4717956709861755
- 1.5054920172691346
- 1.6030239725112916
- 1.853157525062561
- 1.9102360391616822
- 1.7266373538970947
- 1.4157244706153869
- 1.4351535606384278
- 1.4299409914016723
- 1.4636073589324952
- 1.6216905426979065
- 1.9817593431472778
- 1.4123802208900451
- 1.4534268879890442
- 1.4603862237930298
- 1.58530220746994
- 1.4356434488296508
- 1.586321201324463
- 1.4302682089805603
- 1.447615656852722
- 1.632115294933319
- 1.438228552341461
- 1.4547670793533325
- 1.5736856269836426
- 1.4265735602378846
- 1.4221605372428894
- 1.6060372972488404
- 1.4183930516242982
train_accuracy:
- 0.001
- 0.266
- 0.072
- 0.0
- 0.29
- 0.015
- 0.0
- 0.0
- 0.141
- 0.176
- 0.0
- 0.135
- 0.664
- 0.189
- 0.162
- 0.19
- 0.171
- 0.164
- 0.005
- 0.165
- 0.288
- 0.181
- 0.0
- 0.22
- 0.0
- 0.189
- 0.36
- 0.176
- 0.0
- 0.645
- 0.216
- 0.0
- 0.312
- 0.0
- 0.0
- 0.218
- 0.242
- 0.222
- 0.295
- 0.0
- 0.138
- 0.0
- 0.0
- 0.0
- 0.256
- 0.24
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.202
- 0.305
- 0.0
- 0.11
- 0.261
- 0.211
- 0.0
- 0.63
- 0.0
- 0.0
- 0.258
- 0.237
- 0.426
- 0.164
- 0.722
- 0.001
- 0.24
- 0.285
- 0.0
- 0.0
- 0.0
- 0.354
- 0.328
- 0.129
- 0.911
- 0.0
- 0.001
- 0.237
- 0.0
- 0.198
- 0.222
- 0.0
- 0.281
- 0.0
- 0.525
- 0.0
- 0.287
- 0.0
- 0.0
- 0.548
- 0.28
- 0.222
- 0.505
- 0.018
- 0.269
- 0.475
- 0.229
train_loss:
- 0.552
- 0.511
- 1.634
- 1.582
- 0.512
- 0.591
- 1.48
- 1.403
- 1.253
- 0.537
- 1.229
- 2.097
- 0.507
- 1.913
- 1.853
- 1.729
- 1.702
- 0.496
- 0.281
- 1.741
- 0.45
- 1.552
- 0.86
- 1.367
- 0.792
- 1.028
- 0.438
- 0.696
- 0.747
- 0.471
- 1.193
- 0.612
- 0.407
- 0.88
- 0.701
- 0.568
- 0.676
- 0.776
- 0.369
- 0.664
- 0.359
- 0.52
- 0.805
- 0.487
- 0.623
- 0.405
- 0.391
- 0.562
- 0.436
- 0.359
- 0.36
- 0.688
- 0.559
- 0.575
- 0.383
- 0.445
- 0.301
- 0.516
- 0.452
- 0.393
- 0.334
- 0.431
- 0.361
- 0.366
- 0.448
- 0.341
- 0.361
- 0.199
- 0.237
- 0.214
- 0.432
- 0.322
- 0.329
- 0.276
- 0.309
- 0.204
- 0.193
- 0.261
- 0.231
- 0.261
- 0.227
- 0.231
- 0.244
- 0.103
- 0.382
- 0.286
- 0.238
- 0.271
- 0.271
- 0.271
- 0.23
- 0.237
- 0.238
- 0.225
- 0.233
- 0.234
- 0.171
- 0.233
- 0.219
- 0.2
unequal: 0
verbose: 1
