avg_train_accuracy: 0.275
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0194
- 0.0588
- 0.0758
- 0.0828
- 0.1164
- 0.1253
- 0.1287
- 0.1452
- 0.1273
- 0.0428
- 0.1383
- 0.147
- 0.0918
- 0.1666
- 0.1671
- 0.1792
- 0.1309
- 0.1783
- 0.1348
- 0.1743
- 0.0993
- 0.1781
- 0.1903
- 0.1243
- 0.1822
- 0.1137
- 0.1931
- 0.1281
- 0.1922
- 0.1863
- 0.1876
- 0.2082
- 0.1845
- 0.1997
- 0.2098
- 0.2015
- 0.2147
- 0.1778
- 0.2086
- 0.2143
- 0.2087
- 0.1663
- 0.2064
- 0.1447
- 0.2151
- 0.2102
- 0.2163
- 0.2164
- 0.1636
- 0.1163
- 0.0897
- 0.2193
- 0.2174
- 0.1446
- 0.1002
- 0.0967
- 0.0943
- 0.2282
- 0.1372
- 0.1262
- 0.2197
- 0.1558
- 0.2291
- 0.2134
- 0.22
- 0.2314
- 0.2244
- 0.2214
- 0.2272
- 0.1672
- 0.221
- 0.1611
- 0.2309
- 0.2216
- 0.2214
- 0.2314
- 0.2243
- 0.2257
- 0.1813
- 0.2267
- 0.2372
- 0.236
- 0.2296
- 0.2271
- 0.2293
- 0.1836
- 0.1463
- 0.1207
- 0.2303
- 0.2392
- 0.2298
- 0.2206
- 0.2376
- 0.2311
- 0.2293
- 0.2335
- 0.2309
- 0.2398
- 0.2326
- 0.2348
test_loss_list:
- 2.0936965417861937
- 1.7762104225158692
- 1.7589800691604613
- 1.749253420829773
- 1.708218402862549
- 1.674871084690094
- 1.6991906213760375
- 1.6958060359954834
- 1.6535414481163024
- 1.8170061206817627
- 1.5995487189292907
- 1.6151617646217347
- 1.6964256548881531
- 1.5680012202262879
- 1.5792852783203124
- 1.5644391751289368
- 1.6346409511566162
- 1.536318371295929
- 1.5413879656791687
- 1.5318402028083802
- 1.710686116218567
- 1.5145525217056275
- 1.5291544556617738
- 1.627456042766571
- 1.5251207184791564
- 1.6702255940437316
- 1.5038821911811828
- 1.6154130029678344
- 1.5115466618537903
- 1.5181028246879578
- 1.5442876315116882
- 1.5069887328147888
- 1.5721190190315246
- 1.5623279666900636
- 1.5295785236358643
- 1.5773682641983031
- 1.5307938528060914
- 1.5429806804656983
- 1.516477003097534
- 1.5039557552337646
- 1.536315095424652
- 1.5909058094024657
- 1.4994649004936218
- 1.5885939836502074
- 1.4813775491714478
- 1.4980250215530395
- 1.5033302664756776
- 1.5268245935440063
- 1.5934422039985656
- 1.6934702372550965
- 1.8405004405975343
- 1.4299374651908874
- 1.4898106145858765
- 1.705028200149536
- 1.83823712348938
- 1.8564957189559936
- 1.79084490776062
- 1.416542706489563
- 1.6755115628242492
- 1.750855975151062
- 1.4369613432884216
- 1.6362548685073852
- 1.4177198576927186
- 1.476652784347534
- 1.4895818972587584
- 1.4739797496795655
- 1.5176299810409546
- 1.5364064383506775
- 1.5013393712043763
- 1.6084651851654053
- 1.4860127139091492
- 1.6015063047409057
- 1.447936282157898
- 1.4911465716362
- 1.4871094799041749
- 1.4923384022712707
- 1.5294949293136597
- 1.5385975074768066
- 1.5984244322776795
- 1.4863563466072083
- 1.4693767642974853
- 1.4846918511390685
- 1.5306327271461486
- 1.5175634002685547
- 1.5395341038703918
- 1.5929549312591553
- 1.6705403566360473
- 1.7406197929382323
- 1.4244665837287902
- 1.4288792967796327
- 1.4851068592071532
- 1.5049896335601807
- 1.4739112424850465
- 1.5012855482101441
- 1.5142493772506713
- 1.5171130657196046
- 1.535493140220642
- 1.5098736429214477
- 1.52842946767807
- 1.5410902070999146
train_accuracy:
- 0.16
- 0.061
- 0.0
- 0.0
- 0.0
- 0.17
- 0.0
- 0.183
- 0.139
- 0.0
- 0.0
- 0.0
- 0.043
- 0.0
- 0.0
- 0.206
- 0.146
- 0.223
- 0.032
- 0.0
- 0.154
- 0.206
- 0.0
- 0.278
- 0.0
- 0.656
- 0.0
- 0.527
- 0.0
- 0.0
- 0.0
- 0.187
- 0.0
- 0.0
- 0.248
- 0.235
- 0.199
- 0.399
- 0.243
- 0.253
- 0.196
- 0.546
- 0.0
- 0.649
- 0.0
- 0.0
- 0.0
- 0.0
- 0.147
- 0.222
- 0.641
- 0.212
- 0.258
- 0.108
- 0.529
- 0.836
- 0.132
- 0.263
- 0.459
- 0.742
- 0.0
- 0.731
- 0.0
- 0.242
- 0.0
- 0.276
- 0.269
- 0.0
- 0.271
- 0.321
- 0.001
- 0.722
- 0.281
- 0.0
- 0.0
- 0.277
- 0.0
- 0.0
- 0.288
- 0.0
- 0.21
- 0.272
- 0.0
- 0.0
- 0.269
- 0.726
- 0.209
- 0.911
- 0.271
- 0.288
- 0.211
- 0.0
- 0.0
- 0.0
- 0.0
- 0.278
- 0.0
- 0.288
- 0.0
- 0.275
train_loss:
- 0.569
- 2.984
- 1.621
- 1.462
- 1.569
- 2.296
- 1.357
- 1.209
- 0.596
- 0.606
- 1.259
- 1.144
- 0.577
- 1.664
- 1.266
- 1.616
- 0.497
- 1.533
- 0.527
- 0.807
- 0.409
- 0.972
- 0.967
- 0.462
- 0.787
- 0.366
- 0.983
- 0.389
- 0.806
- 0.771
- 0.657
- 1.076
- 0.586
- 0.755
- 1.119
- 0.697
- 0.995
- 0.418
- 0.601
- 0.87
- 0.536
- 0.414
- 0.725
- 0.488
- 0.523
- 0.61
- 0.559
- 0.454
- 0.41
- 0.292
- 0.249
- 0.677
- 0.433
- 0.33
- 0.229
- 0.181
- 0.306
- 0.651
- 0.275
- 0.262
- 0.362
- 0.244
- 0.579
- 0.395
- 0.379
- 0.427
- 0.302
- 0.317
- 0.457
- 0.303
- 0.266
- 0.303
- 0.341
- 0.292
- 0.307
- 0.3
- 0.28
- 0.324
- 0.286
- 0.27
- 0.356
- 0.259
- 0.236
- 0.262
- 0.272
- 0.35
- 0.233
- 0.236
- 0.191
- 0.305
- 0.328
- 0.276
- 0.243
- 0.244
- 0.303
- 0.277
- 0.29
- 0.223
- 0.308
- 0.276
unequal: 0
verbose: 1
