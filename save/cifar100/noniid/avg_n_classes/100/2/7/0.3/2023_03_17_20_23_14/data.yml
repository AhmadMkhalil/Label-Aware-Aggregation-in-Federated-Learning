avg_train_accuracy: 0.003
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0549
- 0.0949
- 0.1118
- 0.0653
- 0.13
- 0.0701
- 0.1298
- 0.0737
- 0.0571
- 0.1365
- 0.0642
- 0.1566
- 0.1475
- 0.0994
- 0.0536
- 0.047
- 0.1551
- 0.0923
- 0.162
- 0.1754
- 0.1754
- 0.1768
- 0.1486
- 0.1753
- 0.1974
- 0.177
- 0.1267
- 0.1798
- 0.1012
- 0.0768
- 0.1967
- 0.1865
- 0.127
- 0.2045
- 0.2015
- 0.1923
- 0.1683
- 0.2045
- 0.147
- 0.1386
- 0.2174
- 0.1987
- 0.2129
- 0.1523
- 0.0914
- 0.2243
- 0.2174
- 0.2128
- 0.159
- 0.2194
- 0.2254
- 0.2151
- 0.2264
- 0.2156
- 0.21
- 0.1719
- 0.2307
- 0.2248
- 0.2217
- 0.2176
- 0.2265
- 0.1938
- 0.117
- 0.1094
- 0.2221
- 0.1634
- 0.2159
- 0.2233
- 0.2233
- 0.2303
- 0.2286
- 0.2238
- 0.2344
- 0.2289
- 0.2268
- 0.2243
- 0.1925
- 0.2314
- 0.222
- 0.1675
- 0.1178
- 0.1152
- 0.2183
- 0.1386
- 0.2252
- 0.2257
- 0.2225
- 0.1595
- 0.2347
- 0.1732
- 0.2305
- 0.2414
- 0.1793
- 0.232
- 0.2321
- 0.1785
- 0.2362
- 0.1721
- 0.135
- 0.235
test_loss_list:
- 1.804413595199585
- 1.7544243478775023
- 1.7382637643814087
- 1.749966344833374
- 1.667767925262451
- 1.7306683683395385
- 1.6630931520462036
- 1.733506236076355
- 1.7504037046432495
- 1.5884510278701782
- 1.7804534149169922
- 1.5642920327186585
- 1.6135553431510925
- 1.7007595777511597
- 1.8004101085662843
- 2.0829439687728883
- 1.5729411101341249
- 1.7708674716949462
- 1.5500343179702758
- 1.5461492681503295
- 1.567123408317566
- 1.586768684387207
- 1.5805732941627502
- 1.5457809948921204
- 1.5198431968688966
- 1.5676612734794617
- 1.618861141204834
- 1.545296540260315
- 1.687811713218689
- 1.6834698915481567
- 1.4886489391326905
- 1.5177516436576843
- 1.6135065126419068
- 1.486186809539795
- 1.5222210192680359
- 1.5542879509925842
- 1.5814282727241515
- 1.4901428079605104
- 1.5950447177886964
- 1.5788855028152466
- 1.4219269418716431
- 1.4874146056175233
- 1.4975503396987915
- 1.5857817482948304
- 1.8005612754821778
- 1.4339537501335144
- 1.4903875541687013
- 1.5244195556640625
- 1.6093391299247741
- 1.4721536874771117
- 1.4586386561393738
- 1.5076472973823547
- 1.4845343351364135
- 1.5108765602111816
- 1.541899197101593
- 1.559417760372162
- 1.4532455682754517
- 1.496687614917755
- 1.510287811756134
- 1.5332403993606567
- 1.5215314531326294
- 1.5301088142395018
- 1.7528097248077392
- 1.799042363166809
- 1.4653294610977172
- 1.587676317691803
- 1.437499029636383
- 1.4657716178894042
- 1.4636527919769287
- 1.485517578125
- 1.504569697380066
- 1.494656777381897
- 1.476086633205414
- 1.5213231182098388
- 1.535607349872589
- 1.5185949754714967
- 1.5511379003524781
- 1.476693603992462
- 1.4824181270599366
- 1.5907683873176575
- 1.7411236190795898
- 1.7427171230316163
- 1.4308690738677978
- 1.7137744331359863
- 1.4554205799102784
- 1.448170862197876
- 1.4692544007301331
- 1.666301338672638
- 1.4517051243782044
- 1.611903998851776
- 1.444557285308838
- 1.4332051467895508
- 1.558247859477997
- 1.4502452683448792
- 1.4458915615081787
- 1.5976795697212218
- 1.4532987642288209
- 1.6472393131256104
- 1.7769039392471313
- 1.422806203365326
train_accuracy:
- 0.063
- 0.106
- 0.152
- 0.061
- 0.0
- 0.029
- 0.0
- 0.682
- 0.031
- 0.16
- 0.318
- 0.166
- 0.187
- 0.516
- 0.855
- 0.516
- 0.196
- 0.513
- 0.0
- 0.187
- 0.0
- 0.0
- 0.448
- 0.0
- 0.212
- 0.0
- 0.224
- 0.0
- 0.554
- 0.745
- 0.0
- 0.0
- 0.222
- 0.0
- 0.0
- 0.0
- 0.498
- 0.24
- 0.718
- 0.235
- 0.237
- 0.227
- 0.0
- 0.235
- 0.06
- 0.262
- 0.208
- 0.0
- 0.445
- 0.0
- 0.0
- 0.255
- 0.0
- 0.0
- 0.24
- 0.305
- 0.274
- 0.237
- 0.0
- 0.0
- 0.0
- 0.026
- 0.231
- 0.668
- 0.277
- 0.354
- 0.26
- 0.0
- 0.253
- 0.243
- 0.0
- 0.257
- 0.0
- 0.0
- 0.0
- 0.0
- 0.489
- 0.291
- 0.0
- 0.229
- 0.568
- 0.603
- 0.012
- 0.475
- 0.284
- 0.0
- 0.265
- 0.166
- 0.0
- 0.674
- 0.0
- 0.0
- 0.505
- 0.001
- 0.26
- 0.592
- 0.264
- 0.436
- 0.805
- 0.003
train_loss:
- 4.197
- 1.676
- 1.587
- 0.662
- 2.258
- 0.69
- 1.346
- 0.596
- 0.485
- 1.392
- 0.457
- 2.006
- 1.104
- 0.572
- 0.401
- 0.276
- 1.038
- 0.507
- 1.14
- 1.592
- 1.191
- 0.987
- 0.493
- 1.03
- 1.477
- 0.836
- 0.417
- 0.897
- 0.516
- 0.366
- 0.967
- 0.853
- 0.375
- 0.933
- 0.639
- 0.77
- 0.492
- 0.867
- 0.335
- 0.491
- 0.963
- 0.622
- 0.559
- 0.368
- 0.206
- 1.178
- 0.425
- 0.405
- 0.351
- 0.618
- 0.885
- 0.602
- 0.68
- 0.499
- 0.383
- 0.351
- 0.754
- 0.553
- 0.512
- 0.41
- 0.44
- 0.458
- 0.315
- 0.186
- 0.352
- 0.437
- 0.346
- 0.452
- 0.363
- 0.366
- 0.42
- 0.471
- 0.39
- 0.351
- 0.32
- 0.362
- 0.28
- 0.335
- 0.278
- 0.305
- 0.292
- 0.328
- 0.169
- 0.291
- 0.263
- 0.216
- 0.2
- 0.209
- 0.271
- 0.309
- 0.295
- 0.236
- 0.249
- 0.206
- 0.283
- 0.3
- 0.194
- 0.267
- 0.165
- 0.215
unequal: 0
verbose: 1
