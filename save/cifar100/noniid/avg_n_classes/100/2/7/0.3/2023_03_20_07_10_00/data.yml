avg_train_accuracy: 0.0
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0235
- 0.0271
- 0.092
- 0.0387
- 0.0296
- 0.1054
- 0.1372
- 0.1349
- 0.1505
- 0.101
- 0.0385
- 0.0337
- 0.1522
- 0.0841
- 0.1547
- 0.1572
- 0.1809
- 0.1687
- 0.1313
- 0.0795
- 0.1836
- 0.1938
- 0.1265
- 0.1809
- 0.116
- 0.1893
- 0.1201
- 0.2053
- 0.1915
- 0.1255
- 0.1994
- 0.2163
- 0.203
- 0.1596
- 0.1966
- 0.1299
- 0.1095
- 0.2033
- 0.2027
- 0.1494
- 0.2061
- 0.2113
- 0.2119
- 0.2304
- 0.2114
- 0.1751
- 0.1133
- 0.2143
- 0.2153
- 0.216
- 0.2143
- 0.2185
- 0.2158
- 0.2331
- 0.2234
- 0.2153
- 0.2138
- 0.2233
- 0.1794
- 0.2348
- 0.2325
- 0.2207
- 0.2231
- 0.1731
- 0.2252
- 0.2345
- 0.2248
- 0.2315
- 0.2254
- 0.2393
- 0.231
- 0.2279
- 0.225
- 0.2398
- 0.2015
- 0.2331
- 0.2322
- 0.2342
- 0.2319
- 0.1741
- 0.174
- 0.1097
- 0.2327
- 0.2333
- 0.1648
- 0.2332
- 0.227
- 0.2341
- 0.2437
- 0.242
- 0.2355
- 0.2359
- 0.2434
- 0.2378
- 0.1865
- 0.2436
- 0.2346
- 0.1871
- 0.2365
test_loss_list:
- 1.827168607711792
- 1.8954253482818604
- 2.1079265546798704
- 1.708201403617859
- 1.8039475250244141
- 2.064598784446716
- 1.668010308742523
- 1.6232845377922058
- 1.6568762683868408
- 1.6301999020576476
- 1.6383826184272765
- 1.919205527305603
- 1.962284951210022
- 1.5686432909965515
- 1.6904390001296996
- 1.5474769282341003
- 1.5649343276023864
- 1.5457062578201295
- 1.5954995036125184
- 1.5785782289505006
- 1.6460220956802367
- 1.5018729972839355
- 1.4990303754806518
- 1.588755145072937
- 1.5106816101074219
- 1.6089111733436585
- 1.4956771516799927
- 1.6057393169403076
- 1.460089385509491
- 1.5132101631164552
- 1.5823414182662965
- 1.4714519453048707
- 1.4643758535385132
- 1.5113301348686219
- 1.5436010456085205
- 1.4875509238243103
- 1.5851527786254882
- 1.6588391828536988
- 1.4496183824539184
- 1.4641108894348145
- 1.5889130878448485
- 1.4661848640441895
- 1.482490475177765
- 1.497181785106659
- 1.4666501545906068
- 1.5256875705718995
- 1.5472429418563842
- 1.6580283904075623
- 1.4576526498794555
- 1.4569423484802246
- 1.491015202999115
- 1.5053589487075805
- 1.4902874183654786
- 1.5138537096977234
- 1.4744406414031983
- 1.5088814282417298
- 1.5288597297668458
- 1.5348950147628784
- 1.5236671113967895
- 1.5547723865509033
- 1.4535986661911011
- 1.4734438276290893
- 1.510721423625946
- 1.5218670415878295
- 1.5834824514389039
- 1.4708336758613587
- 1.457410957813263
- 1.4955600023269653
- 1.499447386264801
- 1.510356867313385
- 1.4792473435401916
- 1.5171417570114136
- 1.515810809135437
- 1.5279931020736695
- 1.4922683763504028
- 1.5340867280960082
- 1.4618944358825683
- 1.4782629442214965
- 1.4945143890380859
- 1.5102909517288208
- 1.6415103244781495
- 1.5528857946395873
- 1.7405168390274048
- 1.4133879613876343
- 1.4310290336608886
- 1.6207340049743653
- 1.423557047843933
- 1.4526600313186646
- 1.4523852825164796
- 1.4439149141311645
- 1.457446231842041
- 1.4788993048667907
- 1.5012337613105773
- 1.470795075893402
- 1.497159459590912
- 1.5963455891609193
- 1.4344631958007812
- 1.4866825485229491
- 1.5850365042686463
- 1.4386981511116028
train_accuracy:
- 0.0
- 0.084
- 0.71
- 0.11
- 0.052
- 0.556
- 0.0
- 0.097
- 0.0
- 0.12
- 0.537
- 0.791
- 0.527
- 0.18
- 0.645
- 0.17
- 0.0
- 0.159
- 0.0
- 0.462
- 0.836
- 0.0
- 0.183
- 0.661
- 0.21
- 0.439
- 0.0
- 0.445
- 0.23
- 0.0
- 0.203
- 0.22
- 0.0
- 0.0
- 0.11
- 0.0
- 0.058
- 0.346
- 0.182
- 0.0
- 0.194
- 0.233
- 0.0
- 0.215
- 0.235
- 0.0
- 0.613
- 0.081
- 0.0
- 0.0
- 0.247
- 0.0
- 0.0
- 0.229
- 0.0
- 0.2
- 0.0
- 0.0
- 0.263
- 0.117
- 0.0
- 0.0
- 0.0
- 0.0
- 0.46
- 0.0
- 0.227
- 0.24
- 0.0
- 0.0
- 0.277
- 0.0
- 0.215
- 0.0
- 0.277
- 0.283
- 0.0
- 0.231
- 0.26
- 0.266
- 0.327
- 0.061
- 0.245
- 0.0
- 0.001
- 0.269
- 0.007
- 0.001
- 0.001
- 0.232
- 0.281
- 0.0
- 0.274
- 0.261
- 0.273
- 0.427
- 0.0
- 0.0
- 0.281
- 0.0
train_loss:
- 1.823
- 0.54
- 0.407
- 1.648
- 0.468
- 0.312
- 1.423
- 2.344
- 1.385
- 1.483
- 0.525
- 0.374
- 0.363
- 1.017
- 0.493
- 1.274
- 1.086
- 1.854
- 0.927
- 0.421
- 0.38
- 1.142
- 1.583
- 0.499
- 0.859
- 0.388
- 1.022
- 0.34
- 1.403
- 0.806
- 0.372
- 0.861
- 1.24
- 0.768
- 0.392
- 0.652
- 0.444
- 0.322
- 0.66
- 0.557
- 0.326
- 0.533
- 0.813
- 0.604
- 1.11
- 0.544
- 0.366
- 0.328
- 0.522
- 0.555
- 0.494
- 0.406
- 0.448
- 0.433
- 0.737
- 0.581
- 0.536
- 0.447
- 0.538
- 0.377
- 0.467
- 0.489
- 0.427
- 0.375
- 0.356
- 0.414
- 0.492
- 0.408
- 0.398
- 0.414
- 0.449
- 0.339
- 0.367
- 0.296
- 0.39
- 0.364
- 0.333
- 0.383
- 0.325
- 0.284
- 0.295
- 0.395
- 0.201
- 0.253
- 0.278
- 0.237
- 0.234
- 0.216
- 0.278
- 0.218
- 0.252
- 0.223
- 0.314
- 0.201
- 0.259
- 0.281
- 0.242
- 0.248
- 0.229
- 0.176
unequal: 0
verbose: 1
