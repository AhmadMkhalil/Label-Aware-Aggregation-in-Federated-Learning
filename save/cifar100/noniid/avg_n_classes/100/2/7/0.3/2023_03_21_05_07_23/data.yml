avg_train_accuracy: 0.477
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0139
- 0.0243
- 0.0734
- 0.0941
- 0.116
- 0.1229
- 0.084
- 0.1331
- 0.1517
- 0.1433
- 0.1576
- 0.1568
- 0.1736
- 0.1407
- 0.1654
- 0.1012
- 0.1733
- 0.1029
- 0.185
- 0.1933
- 0.182
- 0.1811
- 0.1799
- 0.1835
- 0.1961
- 0.2008
- 0.2042
- 0.2021
- 0.2061
- 0.1907
- 0.1583
- 0.202
- 0.2047
- 0.2139
- 0.2059
- 0.2171
- 0.2054
- 0.2057
- 0.2035
- 0.2038
- 0.2103
- 0.2023
- 0.2168
- 0.2136
- 0.1932
- 0.1026
- 0.0896
- 0.2279
- 0.1427
- 0.211
- 0.137
- 0.0999
- 0.1225
- 0.2161
- 0.1492
- 0.2268
- 0.2326
- 0.232
- 0.1723
- 0.2157
- 0.2248
- 0.2192
- 0.2191
- 0.1535
- 0.2291
- 0.1703
- 0.2278
- 0.2236
- 0.2287
- 0.2335
- 0.1852
- 0.2279
- 0.1544
- 0.228
- 0.1636
- 0.2292
- 0.2417
- 0.1696
- 0.2267
- 0.1648
- 0.224
- 0.2374
- 0.1824
- 0.2398
- 0.225
- 0.1688
- 0.2256
- 0.2276
- 0.2273
- 0.1704
- 0.1374
- 0.1179
- 0.233
- 0.1617
- 0.1329
- 0.2367
- 0.227
- 0.2374
- 0.2291
- 0.1695
test_loss_list:
- 2.10336678981781
- 2.5590390968322754
- 1.7568835592269898
- 1.7618442630767823
- 1.6902645993232728
- 1.6972416973114013
- 1.7040373134613036
- 1.6469514417648314
- 1.6234390044212341
- 1.6550731873512268
- 1.660735421180725
- 1.6692606711387634
- 1.6113993215560913
- 1.6134068083763122
- 1.5965984201431274
- 1.6884241676330567
- 1.5550954008102418
- 1.6941769456863403
- 1.548750262260437
- 1.5327795028686524
- 1.5808053183555604
- 1.6097642588615417
- 1.5885766625404358
- 1.5993257427215577
- 1.573379077911377
- 1.5778731060028077
- 1.5674332666397095
- 1.598318603038788
- 1.5858018517494201
- 1.6213042330741883
- 1.569384307861328
- 1.5299342775344849
- 1.547834837436676
- 1.5262963843345643
- 1.579174087047577
- 1.544769299030304
- 1.5854595756530763
- 1.5688172125816344
- 1.5869507837295531
- 1.5909240818023682
- 1.599263184070587
- 1.6098580527305604
- 1.5780484199523925
- 1.601553773880005
- 1.5400427794456482
- 1.7094651246070862
- 1.8416804265975952
- 1.4263273763656616
- 1.647355875968933
- 1.4762290453910827
- 1.6784023904800416
- 1.8331604051589965
- 1.6270862936973571
- 1.435157642364502
- 1.617600371837616
- 1.4145758986473083
- 1.425260283946991
- 1.4482445335388183
- 1.5668240427970885
- 1.466085114479065
- 1.4824173307418824
- 1.495771999359131
- 1.518217113018036
- 1.6559121704101563
- 1.4660023331642151
- 1.5975225758552551
- 1.440956265926361
- 1.4792458605766297
- 1.4757803559303284
- 1.4698085498809814
- 1.5526139307022095
- 1.460260214805603
- 1.6199410200119018
- 1.4412263345718384
- 1.614559495449066
- 1.4261533308029175
- 1.4233589220046996
- 1.615549168586731
- 1.435922589302063
- 1.6398024702072143
- 1.4264606356620788
- 1.4281919169425965
- 1.5739207458496094
- 1.4023771858215333
- 1.4577315282821655
- 1.637720923423767
- 1.443856327533722
- 1.4644260239601135
- 1.463655288219452
- 1.6234212255477904
- 1.7602668237686157
- 1.8251059198379516
- 1.414964678287506
- 1.6639637708663941
- 1.7423950958251953
- 1.3852379035949707
- 1.446765320301056
- 1.4497853016853333
- 1.454623339176178
- 1.6241798353195191
train_accuracy:
- 0.966
- 0.344
- 0.072
- 0.0
- 0.12
- 0.0
- 0.286
- 0.142
- 0.152
- 0.132
- 0.0
- 0.0
- 0.0
- 0.215
- 0.196
- 0.134
- 0.163
- 0.557
- 0.0
- 0.186
- 0.0
- 0.181
- 0.0
- 0.168
- 0.203
- 0.218
- 0.235
- 0.0
- 0.232
- 0.209
- 0.339
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.191
- 0.0
- 0.0
- 0.0
- 0.245
- 0.0
- 0.0
- 0.0
- 0.16
- 0.682
- 0.636
- 0.218
- 0.657
- 0.0
- 0.679
- 0.204
- 0.689
- 0.253
- 0.595
- 0.0
- 0.222
- 0.2
- 0.654
- 0.0
- 0.0
- 0.0
- 0.0
- 0.664
- 0.0
- 0.335
- 0.003
- 0.25
- 0.0
- 0.216
- 0.566
- 0.0
- 0.411
- 0.001
- 0.648
- 0.262
- 0.291
- 0.442
- 0.0
- 0.533
- 0.0
- 0.229
- 0.452
- 0.217
- 0.251
- 0.497
- 0.01
- 0.001
- 0.266
- 0.631
- 0.39
- 0.236
- 0.007
- 0.302
- 0.159
- 0.288
- 0.26
- 0.0
- 0.0
- 0.477
train_loss:
- 0.548
- 0.378
- 2.917
- 1.501
- 2.488
- 1.45
- 0.605
- 1.421
- 2.099
- 1.199
- 1.306
- 1.098
- 1.895
- 0.577
- 1.11
- 0.47
- 1.09
- 0.49
- 0.964
- 1.518
- 0.876
- 0.79
- 0.99
- 0.795
- 1.064
- 0.98
- 1.183
- 0.703
- 0.86
- 0.644
- 0.47
- 0.841
- 0.656
- 0.857
- 0.47
- 0.716
- 0.511
- 0.784
- 0.614
- 0.569
- 0.518
- 0.461
- 0.579
- 0.439
- 0.499
- 0.398
- 0.293
- 0.644
- 0.308
- 0.459
- 0.267
- 0.205
- 0.395
- 0.407
- 0.242
- 0.452
- 0.47
- 0.4
- 0.319
- 0.261
- 0.367
- 0.366
- 0.313
- 0.331
- 0.406
- 0.263
- 0.294
- 0.228
- 0.389
- 0.272
- 0.318
- 0.298
- 0.261
- 0.262
- 0.251
- 0.342
- 0.298
- 0.272
- 0.199
- 0.253
- 0.199
- 0.283
- 0.245
- 0.236
- 0.202
- 0.233
- 0.189
- 0.181
- 0.284
- 0.266
- 0.199
- 0.216
- 0.215
- 0.195
- 0.184
- 0.213
- 0.192
- 0.181
- 0.213
- 0.238
unequal: 0
verbose: 1
