avg_train_accuracy: 0.254
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0468
- 0.0876
- 0.113
- 0.1243
- 0.1371
- 0.1315
- 0.1394
- 0.1624
- 0.1683
- 0.1695
- 0.1688
- 0.175
- 0.1779
- 0.1804
- 0.1904
- 0.1911
- 0.1791
- 0.1934
- 0.1931
- 0.2
- 0.2019
- 0.198
- 0.1993
- 0.2065
- 0.2028
- 0.2104
- 0.2078
- 0.2049
- 0.2127
- 0.2097
- 0.2072
- 0.2181
- 0.2173
- 0.2041
- 0.2185
- 0.2166
- 0.2169
- 0.2211
- 0.2216
- 0.2195
- 0.2212
- 0.2218
- 0.2202
- 0.2243
- 0.2244
- 0.214
- 0.2267
- 0.2242
- 0.2239
- 0.2204
- 0.2256
- 0.2279
- 0.2262
- 0.2271
- 0.2266
- 0.2255
- 0.2208
- 0.2277
- 0.2226
- 0.2287
- 0.2297
- 0.228
- 0.2293
- 0.2295
- 0.2289
- 0.2213
- 0.2197
- 0.2304
- 0.2315
- 0.232
- 0.2318
- 0.2316
- 0.2254
- 0.2212
- 0.2337
- 0.2333
- 0.2271
- 0.2343
- 0.2316
- 0.237
- 0.2341
- 0.2312
- 0.2339
- 0.2288
- 0.2381
- 0.2368
- 0.2374
- 0.2362
- 0.2381
- 0.2351
- 0.2359
- 0.2277
- 0.2384
- 0.2374
- 0.2378
- 0.2346
- 0.2313
- 0.235
- 0.239
- 0.2326
test_loss_list:
- 1.8187208652496338
- 1.7338253688812255
- 1.686654920578003
- 1.665040431022644
- 1.6417514300346374
- 1.672562174797058
- 1.6441486597061157
- 1.6047518634796143
- 1.5927757120132446
- 1.584868724346161
- 1.6068288278579712
- 1.5689824414253235
- 1.568507158756256
- 1.5636349844932556
- 1.5530930137634278
- 1.5555188822746278
- 1.5794369888305664
- 1.5391727948188783
- 1.5351483726501465
- 1.5247845721244813
- 1.5272853040695191
- 1.5390694808959962
- 1.530087447166443
- 1.5195660758018494
- 1.5300205588340758
- 1.5183747601509094
- 1.524177417755127
- 1.5325718784332276
- 1.5067134523391723
- 1.509152238368988
- 1.517358388900757
- 1.5058171081542968
- 1.5017818689346314
- 1.5349849987030029
- 1.5033847308158874
- 1.5075339031219483
- 1.5023551344871522
- 1.4978293895721435
- 1.5049663424491881
- 1.5086266326904296
- 1.5029776740074157
- 1.505159351825714
- 1.5002911400794983
- 1.500962176322937
- 1.4987282967567443
- 1.5213702940940856
- 1.4886201906204224
- 1.5000746941566467
- 1.4946455144882203
- 1.376464650630951
- 1.419886646270752
- 1.442097523212433
- 1.4602293610572814
- 1.4669357061386108
- 1.4696218872070312
- 1.4761778950691222
- 1.491576919555664
- 1.474585564136505
- 1.5000898623466492
- 1.478604118824005
- 1.4771956515312195
- 1.482020423412323
- 1.4768841719627381
- 1.4801748633384704
- 1.4771848845481872
- 1.5167010450363159
- 1.517598397731781
- 1.473015387058258
- 1.4822960114479065
- 1.4754813480377198
- 1.4832814860343932
- 1.4799800944328307
- 1.5115798115730286
- 1.50632488489151
- 1.4759807538986207
- 1.4852133226394653
- 1.4961064648628235
- 1.479878535270691
- 1.48486558675766
- 1.4787495493888856
- 1.475202465057373
- 1.4819255685806274
- 1.4823009037971497
- 1.498541054725647
- 1.472054934501648
- 1.4761704540252685
- 1.4764788198471068
- 1.4747744965553284
- 1.4771403288841247
- 1.4813684296607972
- 1.4795701241493224
- 1.5032394552230834
- 1.4745524191856385
- 1.4784575152397155
- 1.4772230672836304
- 1.4722114849090575
- 1.4897928643226623
- 1.4806991934776306
- 1.4744188022613525
- 1.4892814779281616
train_accuracy:
- 0.0
- 0.0
- 0.137
- 0.0
- 0.162
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.2
- 0.194
- 0.0
- 0.0
- 0.227
- 0.178
- 0.0
- 0.0
- 0.252
- 0.0
- 0.22
- 0.0
- 0.0
- 0.0
- 0.231
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.225
- 0.271
- 0.0
- 0.0
- 0.278
- 0.0
- 0.0
- 0.247
- 0.0
- 0.0
- 0.251
- 0.236
- 0.0
- 0.269
- 0.0
- 0.0
- 0.0
- 0.246
- 0.0
- 0.276
- 0.246
- 0.0
- 0.0
- 0.0
- 0.277
- 0.0
- 0.239
- 0.0
- 0.0
- 0.0
- 0.0
- 0.233
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.235
- 0.237
- 0.246
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.255
- 0.0
- 0.0
- 0.0
- 0.255
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.259
- 0.0
- 0.0
- 0.249
- 0.0
- 0.0
- 0.254
train_loss:
- 1.1
- 1.488
- 1.436
- 1.392
- 1.672
- 0.905
- 0.964
- 1.493
- 1.161
- 1.112
- 0.831
- 1.091
- 1.017
- 0.955
- 0.985
- 0.902
- 0.723
- 0.952
- 0.856
- 0.963
- 0.941
- 0.776
- 0.786
- 0.872
- 0.721
- 0.737
- 0.696
- 0.586
- 0.655
- 0.639
- 0.57
- 0.686
- 0.629
- 0.517
- 0.603
- 0.593
- 0.519
- 0.56
- 0.523
- 0.469
- 0.53
- 0.496
- 0.475
- 0.47
- 0.443
- 0.445
- 0.466
- 0.415
- 0.407
- 0.417
- 0.351
- 0.344
- 0.383
- 0.37
- 0.378
- 0.359
- 0.381
- 0.333
- 0.367
- 0.324
- 0.357
- 0.329
- 0.365
- 0.314
- 0.313
- 0.348
- 0.344
- 0.31
- 0.346
- 0.287
- 0.313
- 0.315
- 0.322
- 0.331
- 0.274
- 0.283
- 0.319
- 0.309
- 0.307
- 0.265
- 0.24
- 0.299
- 0.282
- 0.317
- 0.278
- 0.261
- 0.268
- 0.261
- 0.249
- 0.248
- 0.233
- 0.299
- 0.253
- 0.275
- 0.235
- 0.24
- 0.255
- 0.26
- 0.215
- 0.272
unequal: 0
verbose: 1
