avg_train_accuracy: 0.91
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.013
- 0.0182
- 0.067
- 0.0902
- 0.1029
- 0.0189
- 0.0132
- 0.1216
- 0.1314
- 0.1392
- 0.019
- 0.1468
- 0.0164
- 0.018
- 0.0171
- 0.0193
- 0.0175
- 0.1445
- 0.0178
- 0.0166
- 0.0196
- 0.017
- 0.1471
- 0.1529
- 0.018
- 0.1566
- 0.0185
- 0.0166
- 0.0172
- 0.019
- 0.1671
- 0.166
- 0.0181
- 0.1652
- 0.0182
- 0.0184
- 0.0164
- 0.0182
- 0.0157
- 0.0187
- 0.0187
- 0.0186
- 0.0183
- 0.0185
- 0.1637
- 0.0178
- 0.0186
- 0.0185
- 0.0155
- 0.0189
- 0.0179
- 0.0182
- 0.1709
- 0.019
- 0.0194
- 0.1762
- 0.1781
- 0.1812
- 0.0189
- 0.0176
- 0.0175
- 0.0195
- 0.0185
- 0.0185
- 0.018
- 0.0189
- 0.0185
- 0.1824
- 0.0187
- 0.0177
- 0.1906
- 0.019
- 0.0191
- 0.0162
- 0.0184
- 0.1932
- 0.019
- 0.019
- 0.0165
- 0.0189
- 0.1986
- 0.0193
- 0.0191
- 0.1946
- 0.2029
- 0.2054
- 0.0196
- 0.2039
- 0.02
- 0.2033
- 0.0203
- 0.0198
- 0.0198
- 0.2145
- 0.02
- 0.0179
- 0.0196
- 0.0192
- 0.0195
- 0.0182
test_loss_list:
- 3.5528106117248535
- 4.954250011444092
- 1.7928165817260742
- 1.7711080646514892
- 1.7366952991485596
- 4.436562366485596
- 4.37091667175293
- 1.7226052975654602
- 1.6961681246757507
- 1.6827138996124267
- 4.389969253540039
- 1.6854240775108338
- 4.2685809898376466
- 4.323478012084961
- 4.691308622360229
- 4.276542587280273
- 4.686298513412476
- 1.6430891394615172
- 4.342321472167969
- 4.435897855758667
- 4.3492076587677
- 4.4736021900177
- 1.6362002682685852
- 1.6307738423347473
- 4.173385276794433
- 1.6516827154159546
- 4.293493976593018
- 4.41791298866272
- 4.598616962432861
- 4.856519069671631
- 1.5820421719551085
- 1.6158427214622497
- 4.353515377044678
- 1.6085017895698548
- 4.236885080337524
- 4.3404497623443605
- 4.368037509918213
- 4.4400340270996095
- 4.508729820251465
- 4.592412166595459
- 4.511853227615356
- 4.263967046737671
- 4.403007335662842
- 4.503772964477539
- 1.5701440501213073
- 4.319116554260254
- 4.140443239212036
- 4.269093952178955
- 4.241329536437989
- 4.372515249252319
- 4.472357587814331
- 4.5380038642883305
- 1.522789442539215
- 3.9756696319580076
- 4.035802192687989
- 1.5224605774879456
- 1.5420264315605163
- 1.5497110152244569
- 4.015540533065796
- 4.268252515792847
- 4.390338668823242
- 4.135771751403809
- 4.123266296386719
- 4.080589990615845
- 4.408357276916504
- 4.442967405319214
- 4.211620779037475
- 1.488998188972473
- 3.9605398559570313
- 4.265186204910278
- 1.49542409658432
- 3.949654808044434
- 3.8980691719055174
- 4.122485647201538
- 4.079117136001587
- 1.4795608830451965
- 4.317854642868042
- 3.97263783454895
- 4.2318613147735595
- 4.062209091186523
- 1.4668886470794678
- 3.855553846359253
- 3.9105868244171145
- 1.4885395216941832
- 1.4926649951934814
- 1.4906234955787658
- 3.7666610717773437
- 1.5173934054374696
- 3.8614645290374754
- 1.516694314479828
- 3.937727117538452
- 3.9233722114562988
- 4.0260020446777345
- 1.483706088066101
- 3.697939157485962
- 4.172148761749267
- 3.967439041137695
- 4.076218967437744
- 3.972316198348999
- 4.074537096023559
train_accuracy:
- 0.271
- 0.896
- 0.094
- 0.096
- 0.132
- 0.716
- 0.384
- 0.155
- 0.138
- 0.141
- 0.921
- 0.146
- 0.868
- 0.91
- 0.889
- 0.819
- 0.91
- 0.166
- 0.728
- 0.743
- 0.925
- 0.778
- 0.183
- 0.174
- 0.938
- 0.18
- 0.907
- 0.703
- 0.766
- 0.928
- 0.185
- 0.188
- 0.951
- 0.174
- 0.915
- 0.842
- 0.773
- 0.821
- 0.648
- 0.92
- 0.914
- 0.924
- 0.872
- 0.895
- 0.205
- 0.81
- 0.9
- 0.816
- 0.596
- 0.917
- 0.852
- 0.835
- 0.189
- 0.903
- 0.933
- 0.18
- 0.202
- 0.208
- 0.883
- 0.845
- 0.868
- 0.887
- 0.879
- 0.938
- 0.855
- 0.914
- 0.863
- 0.199
- 0.904
- 0.868
- 0.235
- 0.868
- 0.916
- 0.691
- 0.919
- 0.222
- 0.933
- 0.91
- 0.645
- 0.889
- 0.224
- 0.858
- 0.893
- 0.214
- 0.229
- 0.238
- 0.936
- 0.238
- 0.933
- 0.244
- 0.883
- 0.894
- 0.947
- 0.236
- 0.931
- 0.786
- 0.938
- 0.849
- 0.92
- 0.91
train_loss:
- 0.52
- 0.722
- 4.652
- 3.451
- 3.553
- 0.563
- 1.113
- 3.434
- 3.376
- 2.955
- 0.444
- 3.247
- 0.769
- 0.87
- 0.902
- 0.707
- 0.706
- 3.027
- 0.5
- 0.826
- 0.579
- 0.673
- 3.118
- 2.477
- 0.455
- 2.376
- 0.426
- 0.749
- 0.781
- 0.781
- 3.017
- 2.028
- 0.565
- 1.975
- 0.398
- 0.65
- 0.698
- 0.568
- 0.553
- 0.832
- 0.546
- 0.595
- 0.071
- 0.484
- 2.004
- 0.493
- 0.597
- 0.512
- 0.598
- 0.486
- 0.6
- 0.49
- 2.784
- 0.299
- 0.641
- 2.255
- 1.638
- 1.634
- 0.306
- 0.604
- 0.086
- 0.579
- 0.586
- 0.581
- 0.514
- 0.693
- 0.499
- 1.919
- 0.287
- 0.521
- 2.713
- 0.298
- 0.458
- 0.655
- 0.551
- 1.761
- 0.334
- 0.461
- 0.563
- 0.466
- 2.356
- 0.271
- 0.026
- 1.478
- 1.747
- 1.583
- 0.294
- 1.318
- 0.261
- 1.746
- 0.251
- 0.557
- 0.031
- 1.591
- 0.275
- 0.549
- 0.43
- 0.476
- 0.485
- 0.598
unequal: 0
verbose: 1
