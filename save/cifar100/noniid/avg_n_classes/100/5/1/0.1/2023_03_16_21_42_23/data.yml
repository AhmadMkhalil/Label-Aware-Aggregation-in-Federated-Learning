avg_train_accuracy: 0.249
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0277
- 0.0653
- 0.0324
- 0.0797
- 0.1025
- 0.0324
- 0.1153
- 0.1211
- 0.144
- 0.1436
- 0.1438
- 0.166
- 0.1578
- 0.1498
- 0.1585
- 0.1733
- 0.1716
- 0.1852
- 0.1833
- 0.1934
- 0.1995
- 0.1995
- 0.1946
- 0.208
- 0.2153
- 0.2101
- 0.2128
- 0.2183
- 0.2148
- 0.2228
- 0.2168
- 0.2375
- 0.2388
- 0.2339
- 0.2422
- 0.2366
- 0.2452
- 0.2448
- 0.2536
- 0.2519
- 0.2454
- 0.0341
- 0.2473
- 0.2622
- 0.2563
- 0.2516
- 0.2562
- 0.2572
- 0.2599
- 0.2643
- 0.2653
- 0.2718
- 0.2628
- 0.2649
- 0.0376
- 0.2747
- 0.2696
- 0.2747
- 0.2737
- 0.2715
- 0.2853
- 0.2868
- 0.0388
- 0.2688
- 0.2717
- 0.2651
- 0.2685
- 0.2806
- 0.2715
- 0.2625
- 0.2888
- 0.2873
- 0.282
- 0.2821
- 0.2936
- 0.2922
- 0.2773
- 0.2945
- 0.2857
- 0.2918
- 0.2885
- 0.3019
- 0.2958
- 0.2998
- 0.3016
- 0.3073
- 0.304
- 0.3037
- 0.3031
- 0.3151
- 0.3014
- 0.3099
- 0.299
- 0.304
- 0.306
- 0.2992
- 0.301
- 0.3052
- 0.0434
- 0.3017
test_loss_list:
- 3.1669784450531004
- 1.7530586862564086
- 3.6800531768798828
- 1.6821874618530273
- 1.6314311194419862
- 3.6116512298583983
- 1.5845310878753662
- 1.5752799582481385
- 1.5400768733024597
- 1.543298122882843
- 1.5302376747131348
- 1.509974467754364
- 1.5131593465805053
- 1.5337113785743712
- 1.512565495967865
- 1.4833477854728698
- 1.477478132247925
- 1.4684785962104798
- 1.4688914442062377
- 1.4525539255142212
- 1.4380385541915894
- 1.4398513770103454
- 1.4510265493392944
- 1.4310866928100585
- 1.4166641402244569
- 1.4382421922683717
- 1.4252150177955627
- 1.4149840831756593
- 1.4283620309829712
- 1.3965112829208375
- 1.4271717858314514
- 1.3767605900764466
- 1.3824780416488647
- 1.4071661949157714
- 1.378249433040619
- 1.3985731983184815
- 1.3709074544906616
- 1.3776198148727417
- 1.3547172331809998
- 1.3636766624450685
- 1.377051055431366
- 3.401870346069336
- 1.303464274406433
- 1.2815577507019043
- 1.3009057760238647
- 1.3332499289512634
- 1.3231578993797302
- 1.3178616619110108
- 1.3206620359420775
- 1.3087113165855409
- 1.2995877838134766
- 1.2933627080917358
- 1.3241542744636536
- 1.312956280708313
- 3.2121102952957155
- 1.2621278309822082
- 1.2816593766212463
- 1.2778561115264893
- 1.2853517889976502
- 1.302004635334015
- 1.273944730758667
- 1.2762830018997193
- 3.1333890104293824
- 1.2755984926223756
- 1.2794715356826782
- 1.2981950974464416
- 1.3037980461120606
- 1.2900463795661927
- 1.310581715106964
- 1.3281312704086303
- 1.2620618963241577
- 1.2784100580215454
- 1.285816993713379
- 1.2972614932060242
- 1.2694859981536866
- 1.2800499081611634
- 1.3054856705665587
- 1.2724066352844239
- 1.2998427414894105
- 1.2884866452217103
- 1.2802312564849854
- 1.2679613637924194
- 1.273546118736267
- 1.2787993907928468
- 1.2733068013191222
- 1.267967221736908
- 1.276082832813263
- 1.2801656913757324
- 1.2792059874534607
- 1.2485455250740052
- 1.2715704584121703
- 1.2586948895454406
- 1.2840832901000976
- 1.2823737335205079
- 1.295489056110382
- 1.314831449985504
- 1.2960856866836548
- 1.2966792941093446
- 3.0792224550247194
- 1.2193690347671509
train_accuracy:
- 0.0
- 0.045
- 0.0
- 0.089
- 0.119
- 0.0
- 0.104
- 0.133
- 0.11
- 0.12
- 0.137
- 0.142
- 0.162
- 0.161
- 0.147
- 0.152
- 0.195
- 0.198
- 0.168
- 0.195
- 0.227
- 0.203
- 0.226
- 0.214
- 0.252
- 0.221
- 0.252
- 0.227
- 0.205
- 0.234
- 0.22
- 0.199
- 0.268
- 0.264
- 0.192
- 0.243
- 0.199
- 0.28
- 0.199
- 0.239
- 0.268
- 0.0
- 0.215
- 0.192
- 0.208
- 0.193
- 0.255
- 0.259
- 0.264
- 0.305
- 0.259
- 0.291
- 0.284
- 0.262
- 0.0
- 0.21
- 0.289
- 0.281
- 0.26
- 0.279
- 0.275
- 0.301
- 0.0
- 0.264
- 0.26
- 0.275
- 0.257
- 0.276
- 0.291
- 0.258
- 0.32
- 0.32
- 0.276
- 0.298
- 0.244
- 0.287
- 0.308
- 0.297
- 0.306
- 0.294
- 0.311
- 0.292
- 0.315
- 0.334
- 0.342
- 0.316
- 0.26
- 0.318
- 0.295
- 0.279
- 0.32
- 0.327
- 0.31
- 0.326
- 0.33
- 0.306
- 0.32
- 0.308
- 0.0
- 0.249
train_loss:
- 1.058
- 4.607
- 0.803
- 4.133
- 3.597
- 0.745
- 3.8
- 3.395
- 3.236
- 3.073
- 3.259
- 2.999
- 2.93
- 2.484
- 2.823
- 2.662
- 2.978
- 2.624
- 2.484
- 2.943
- 2.632
- 2.376
- 2.327
- 2.662
- 2.283
- 2.235
- 2.054
- 2.256
- 2.206
- 2.426
- 1.905
- 2.479
- 2.066
- 1.577
- 2.108
- 1.847
- 2.485
- 1.907
- 1.849
- 1.934
- 1.533
- 0.851
- 2.336
- 1.626
- 1.666
- 1.254
- 1.654
- 1.713
- 1.926
- 1.42
- 1.9
- 1.398
- 1.547
- 1.778
- 0.633
- 1.616
- 1.226
- 1.191
- 1.431
- 1.028
- 1.617
- 1.031
- 0.513
- 1.147
- 0.669
- 0.514
- 0.425
- 0.899
- 0.555
- 1.361
- 1.426
- 1.111
- 0.612
- 0.64
- 1.44
- 1.144
- 1.127
- 0.594
- 0.779
- 0.459
- 1.555
- 0.952
- 1.376
- 0.776
- 0.64
- 0.719
- 1.226
- 0.938
- 1.213
- 1.188
- 0.692
- 1.068
- 0.766
- 0.73
- 0.592
- 0.363
- 0.622
- 0.312
- 0.556
- 1.148
unequal: 0
verbose: 1
