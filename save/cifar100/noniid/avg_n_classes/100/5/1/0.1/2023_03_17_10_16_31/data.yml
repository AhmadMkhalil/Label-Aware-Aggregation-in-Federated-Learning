avg_train_accuracy: 0.316
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0413
- 0.0803
- 0.0993
- 0.1141
- 0.1254
- 0.1352
- 0.1464
- 0.164
- 0.0316
- 0.1597
- 0.1579
- 0.1735
- 0.1754
- 0.172
- 0.1685
- 0.1855
- 0.1901
- 0.1887
- 0.1998
- 0.0322
- 0.2086
- 0.2105
- 0.2145
- 0.2051
- 0.1978
- 0.2159
- 0.2204
- 0.2261
- 0.2334
- 0.2353
- 0.2386
- 0.2431
- 0.2331
- 0.2324
- 0.2305
- 0.2237
- 0.24
- 0.0348
- 0.2418
- 0.249
- 0.2512
- 0.2623
- 0.2559
- 0.2553
- 0.2532
- 0.2738
- 0.2522
- 0.2682
- 0.2708
- 0.2595
- 0.2636
- 0.2722
- 0.2798
- 0.2743
- 0.2803
- 0.2809
- 0.2844
- 0.2873
- 0.278
- 0.2714
- 0.2817
- 0.2843
- 0.0356
- 0.2872
- 0.2934
- 0.2918
- 0.2962
- 0.2958
- 0.2895
- 0.2844
- 0.2864
- 0.2956
- 0.2997
- 0.287
- 0.2922
- 0.2993
- 0.3006
- 0.2972
- 0.2988
- 0.3015
- 0.2982
- 0.3024
- 0.2959
- 0.2928
- 0.0479
- 0.3036
- 0.3049
- 0.3004
- 0.3024
- 0.311
- 0.3053
- 0.2962
- 0.3028
- 0.3101
- 0.3125
- 0.3062
- 0.3026
- 0.3102
- 0.3024
- 0.3032
test_loss_list:
- 1.8130452585220338
- 1.7132194709777833
- 1.680850067138672
- 1.6233426523208618
- 1.6053091764450074
- 1.5848133158683777
- 1.5614735341072083
- 1.529472312927246
- 3.7146401596069336
- 1.5019136047363282
- 1.4998768854141236
- 1.4778863549232484
- 1.4789733815193176
- 1.4959545207023621
- 1.5131748867034913
- 1.4702436327934265
- 1.451563160419464
- 1.4711699414253234
- 1.4468173265457154
- 3.6096319580078124
- 1.3892668247222901
- 1.3842221045494079
- 1.3930549550056457
- 1.40814950466156
- 1.4332298612594605
- 1.3874195837974548
- 1.3738258266448975
- 1.3765517497062683
- 1.3687816596031188
- 1.3602862167358398
- 1.3548098754882814
- 1.3505127286911012
- 1.380642237663269
- 1.3965748262405395
- 1.4169717001914979
- 1.4369476795196534
- 1.3775744581222533
- 3.5220807933807374
- 1.3157906937599182
- 1.3025769329071044
- 1.3044244980812072
- 1.3040952181816101
- 1.3220743465423583
- 1.3226743292808534
- 1.3090802383422853
- 1.2922827792167664
- 1.3283720922470093
- 1.316254050731659
- 1.3031843781471253
- 1.3219633674621583
- 1.3108419871330261
- 1.3089889860153199
- 1.299505741596222
- 1.3121210575103759
- 1.3043530511856078
- 1.301225335597992
- 1.2866833472251893
- 1.298524558544159
- 1.320034577846527
- 1.3386074852943421
- 1.3180229473114013
- 1.2979992628097534
- 3.448636178970337
- 1.2433890986442566
- 1.250231294631958
- 1.2524452304840088
- 1.2545067572593689
- 1.2643197059631348
- 1.2705122661590575
- 1.2859850764274596
- 1.2876472473144531
- 1.2684240078926086
- 1.2686920261383057
- 1.294279499053955
- 1.271981918811798
- 1.2634156775474548
- 1.2712391233444214
- 1.267725179195404
- 1.2699193334579468
- 1.2820551013946533
- 1.2859749150276185
- 1.280347728729248
- 1.2973565673828125
- 1.3148083472251892
- 3.2346951818466185
- 1.230825970172882
- 1.241638412475586
- 1.2514038920402526
- 1.2581360626220703
- 1.2449900341033935
- 1.258682963848114
- 1.2764040446281433
- 1.2655453062057496
- 1.2569392132759094
- 1.277688102722168
- 1.2746020436286927
- 1.2822930550575256
- 1.2596841669082641
- 1.2925825142860412
- 1.2812403011322022
train_accuracy:
- 0.064
- 0.062
- 0.084
- 0.105
- 0.134
- 0.118
- 0.137
- 0.121
- 0.0
- 0.138
- 0.174
- 0.149
- 0.172
- 0.198
- 0.162
- 0.152
- 0.165
- 0.159
- 0.166
- 0.0
- 0.189
- 0.158
- 0.181
- 0.213
- 0.201
- 0.232
- 0.185
- 0.187
- 0.225
- 0.2
- 0.258
- 0.21
- 0.208
- 0.198
- 0.192
- 0.191
- 0.257
- 0.0
- 0.26
- 0.237
- 0.262
- 0.222
- 0.232
- 0.281
- 0.275
- 0.224
- 0.263
- 0.272
- 0.277
- 0.238
- 0.285
- 0.241
- 0.298
- 0.216
- 0.29
- 0.289
- 0.267
- 0.29
- 0.277
- 0.27
- 0.271
- 0.285
- 0.0
- 0.238
- 0.283
- 0.316
- 0.269
- 0.25
- 0.289
- 0.284
- 0.272
- 0.255
- 0.301
- 0.303
- 0.323
- 0.256
- 0.297
- 0.34
- 0.311
- 0.296
- 0.28
- 0.311
- 0.285
- 0.325
- 0.0
- 0.275
- 0.289
- 0.283
- 0.285
- 0.322
- 0.282
- 0.32
- 0.325
- 0.285
- 0.268
- 0.324
- 0.291
- 0.332
- 0.267
- 0.316
train_loss:
- 4.369
- 3.916
- 3.375
- 3.614
- 3.539
- 3.399
- 3.217
- 3.157
- 1.066
- 3.251
- 3.191
- 2.79
- 2.73
- 2.335
- 2.017
- 2.99
- 2.764
- 1.987
- 2.751
- 0.845
- 2.68
- 2.385
- 2.466
- 1.862
- 1.419
- 2.575
- 2.132
- 2.413
- 2.107
- 2.356
- 2.545
- 2.11
- 1.581
- 1.319
- 1.095
- 0.938
- 2.225
- 0.751
- 2.439
- 2.058
- 2.394
- 2.016
- 1.153
- 1.925
- 1.633
- 1.716
- 1.185
- 1.815
- 1.717
- 1.046
- 1.853
- 1.694
- 1.503
- 1.276
- 1.447
- 1.201
- 1.706
- 1.002
- 0.708
- 0.543
- 1.363
- 1.285
- 0.691
- 1.761
- 1.087
- 1.541
- 1.28
- 1.192
- 0.952
- 1.201
- 0.995
- 1.043
- 0.812
- 0.919
- 1.257
- 1.022
- 0.717
- 0.907
- 0.707
- 0.574
- 0.821
- 0.536
- 0.482
- 0.406
- 0.595
- 1.062
- 0.432
- 0.578
- 0.924
- 0.425
- 0.658
- 1.098
- 0.61
- 0.944
- 0.518
- 0.596
- 0.57
- 0.493
- 0.373
- 0.894
unequal: 0
verbose: 1
