avg_train_accuracy: 0.28
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0415
- 0.0317
- 0.0899
- 0.0989
- 0.1077
- 0.1254
- 0.1236
- 0.1472
- 0.1495
- 0.1528
- 0.1646
- 0.1555
- 0.1716
- 0.1709
- 0.1811
- 0.0332
- 0.1797
- 0.1815
- 0.1896
- 0.1866
- 0.195
- 0.1947
- 0.0333
- 0.2017
- 0.2062
- 0.2081
- 0.2204
- 0.2147
- 0.2289
- 0.2216
- 0.2174
- 0.2343
- 0.035
- 0.2291
- 0.2336
- 0.2321
- 0.2424
- 0.2273
- 0.2363
- 0.2351
- 0.2464
- 0.2414
- 0.0359
- 0.2446
- 0.2485
- 0.2482
- 0.2556
- 0.2553
- 0.0378
- 0.2581
- 0.2589
- 0.2597
- 0.2615
- 0.0381
- 0.2608
- 0.2686
- 0.0431
- 0.2617
- 0.2612
- 0.2582
- 0.2632
- 0.2656
- 0.2701
- 0.2641
- 0.2756
- 0.2697
- 0.2797
- 0.2855
- 0.2726
- 0.2789
- 0.2765
- 0.2887
- 0.2838
- 0.2861
- 0.2816
- 0.2775
- 0.2866
- 0.0412
- 0.2858
- 0.2873
- 0.2893
- 0.3003
- 0.2892
- 0.3005
- 0.3083
- 0.3055
- 0.297
- 0.2951
- 0.2973
- 0.2982
- 0.0432
- 0.2975
- 0.2943
- 0.2944
- 0.3015
- 0.2966
- 0.3004
- 0.2917
- 0.3047
- 0.3051
test_loss_list:
- 1.8004815006256103
- 3.769357833862305
- 1.6642752814292907
- 1.641260781288147
- 1.6112076330184937
- 1.5932890343666077
- 1.5833260250091552
- 1.544542098045349
- 1.535113935470581
- 1.5221317553520202
- 1.5111647033691407
- 1.5177935791015624
- 1.5010327982902527
- 1.5091733169555663
- 1.4916330099105835
- 3.6751068210601807
- 1.4414883303642272
- 1.4458778524398803
- 1.4486948490142821
- 1.444779999256134
- 1.4304381036758422
- 1.4209888172149658
- 3.471119146347046
- 1.3652153491973877
- 1.3830627751350404
- 1.3872498321533202
- 1.3746114349365235
- 1.3734975337982178
- 1.3659931373596192
- 1.3758492612838744
- 1.3929230093955993
- 1.3665245699882507
- 3.417912359237671
- 1.3335740351676941
- 1.3335156321525574
- 1.3440504240989686
- 1.3333720183372497
- 1.3668445229530335
- 1.3510872364044189
- 1.3678066182136535
- 1.3378743147850036
- 1.3493266129493713
- 3.360839567184448
- 1.304938826560974
- 1.3037653303146362
- 1.31157479763031
- 1.3112118244171143
- 1.316409409046173
- 3.2441736173629763
- 1.2736250925064088
- 1.2938705706596374
- 1.302505736351013
- 1.2943239712715149
- 3.2163981771469117
- 1.287540991306305
- 1.2755875706672668
- 3.043851819038391
- 1.2816473722457886
- 1.2675643134117127
- 1.3080861949920655
- 1.2764909362792969
- 1.2938607740402222
- 1.278322229385376
- 1.2936421036720276
- 1.2860922479629517
- 1.2871708941459656
- 1.2750876760482788
- 1.266735064983368
- 1.2902853727340697
- 1.27333340883255
- 1.2771612977981568
- 1.2747477579116822
- 1.2906787371635438
- 1.2781444454193116
- 1.2969553470611572
- 1.2941151690483093
- 1.2970193243026733
- 3.155651054382324
- 1.234775779247284
- 1.2426692652702331
- 1.2402388191223144
- 1.222081069946289
- 1.251154091358185
- 1.2426060438156128
- 1.2320704388618469
- 1.2459781575202942
- 1.2522468519210816
- 1.2689364171028137
- 1.262283821105957
- 1.2644945144653321
- 3.07601065158844
- 1.2318262100219726
- 1.2509283661842345
- 1.242683107852936
- 1.2466796255111694
- 1.2517195677757262
- 1.2450635743141174
- 1.2763181471824645
- 1.2519948315620422
- 1.2427357363700866
train_accuracy:
- 0.034
- 0.0
- 0.101
- 0.096
- 0.113
- 0.138
- 0.142
- 0.14
- 0.118
- 0.113
- 0.152
- 0.141
- 0.175
- 0.163
- 0.169
- 0.0
- 0.209
- 0.195
- 0.169
- 0.198
- 0.148
- 0.157
- 0.0
- 0.197
- 0.18
- 0.243
- 0.206
- 0.162
- 0.219
- 0.233
- 0.201
- 0.296
- 0.0
- 0.166
- 0.231
- 0.181
- 0.241
- 0.171
- 0.179
- 0.173
- 0.228
- 0.243
- 0.0
- 0.225
- 0.206
- 0.257
- 0.254
- 0.262
- 0.0
- 0.227
- 0.237
- 0.218
- 0.232
- 0.0
- 0.184
- 0.272
- 0.0
- 0.264
- 0.258
- 0.217
- 0.221
- 0.266
- 0.278
- 0.258
- 0.252
- 0.317
- 0.224
- 0.287
- 0.309
- 0.263
- 0.271
- 0.25
- 0.263
- 0.26
- 0.236
- 0.218
- 0.249
- 0.0
- 0.254
- 0.327
- 0.35
- 0.312
- 0.36
- 0.29
- 0.265
- 0.317
- 0.267
- 0.245
- 0.232
- 0.256
- 0.0
- 0.262
- 0.255
- 0.305
- 0.245
- 0.321
- 0.287
- 0.232
- 0.261
- 0.28
train_loss:
- 4.35
- 1.003
- 4.237
- 3.386
- 3.552
- 3.034
- 3.442
- 3.371
- 3.184
- 3.208
- 2.93
- 2.759
- 2.926
- 2.488
- 2.479
- 0.902
- 3.13
- 2.33
- 2.432
- 2.114
- 2.92
- 2.703
- 0.731
- 3.038
- 2.169
- 1.964
- 2.503
- 2.512
- 1.896
- 1.671
- 1.535
- 2.533
- 0.685
- 2.425
- 1.531
- 2.268
- 1.231
- 1.817
- 1.888
- 1.514
- 1.565
- 1.141
- 0.582
- 2.459
- 1.638
- 0.978
- 2.074
- 0.807
- 0.496
- 2.023
- 0.736
- 1.295
- 1.514
- 0.426
- 1.597
- 0.686
- 0.355
- 0.603
- 2.138
- 1.15
- 1.591
- 0.603
- 1.714
- 1.377
- 0.992
- 1.902
- 1.296
- 0.56
- 1.437
- 1.281
- 1.37
- 0.864
- 0.548
- 1.013
- 1.031
- 1.444
- 0.637
- 0.474
- 0.991
- 1.283
- 1.773
- 0.609
- 1.275
- 1.463
- 0.824
- 0.473
- 0.535
- 0.588
- 1.119
- 0.448
- 0.403
- 0.419
- 0.218
- 1.122
- 0.274
- 1.085
- 0.801
- 0.93
- 0.3
- 0.58
unequal: 0
verbose: 1
