avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0437
- 0.0826
- 0.1044
- 0.1176
- 0.1244
- 0.1411
- 0.1453
- 0.1496
- 0.1525
- 0.151
- 0.1709
- 0.1811
- 0.0314
- 0.178
- 0.1903
- 0.1899
- 0.1904
- 0.1828
- 0.1994
- 0.2013
- 0.2033
- 0.0333
- 0.2177
- 0.2194
- 0.218
- 0.2205
- 0.2191
- 0.2191
- 0.2251
- 0.0341
- 0.2253
- 0.2333
- 0.2276
- 0.2381
- 0.0356
- 0.0352
- 0.2327
- 0.2382
- 0.0371
- 0.2307
- 0.2441
- 0.2437
- 0.2404
- 0.0385
- 0.246
- 0.2498
- 0.2601
- 0.0426
- 0.2672
- 0.2616
- 0.2602
- 0.2733
- 0.2633
- 0.265
- 0.2649
- 0.2616
- 0.2704
- 0.2611
- 0.0444
- 0.2579
- 0.2638
- 0.2725
- 0.0456
- 0.2677
- 0.2669
- 0.2719
- 0.2827
- 0.2794
- 0.2825
- 0.2863
- 0.2807
- 0.2765
- 0.2803
- 0.2842
- 0.2835
- 0.285
- 0.2856
- 0.2891
- 0.2929
- 0.2793
- 0.2906
- 0.2968
- 0.2919
- 0.2943
- 0.2975
- 0.2678
- 0.2971
- 0.303
- 0.0514
- 0.2866
- 0.3019
- 0.2937
- 0.2985
- 0.2887
- 0.2897
- 0.3031
- 0.3057
- 0.3074
- 0.3056
- 0.0519
test_loss_list:
- 1.7990539360046387
- 1.6947700309753417
- 1.643877227306366
- 1.6216275668144227
- 1.5959547662734985
- 1.5791819500923157
- 1.5539823937416077
- 1.5443498969078064
- 1.5337659859657287
- 1.5245043158531189
- 1.5023820400238037
- 1.4879680466651917
- 3.7596231937408446
- 1.4466958546638489
- 1.4269766211509705
- 1.4300312042236327
- 1.4254450750350953
- 1.4479081201553345
- 1.4333962464332581
- 1.426423089504242
- 1.423075258731842
- 3.6310855293273927
- 1.3604531168937684
- 1.3666999745368957
- 1.3634935712814331
- 1.384066369533539
- 1.3766580939292907
- 1.3908975553512573
- 1.3659476232528687
- 3.456791887283325
- 1.3295377564430237
- 1.334279284477234
- 1.3618055605888366
- 1.3406817603111267
- 3.348974175453186
- 3.45209023475647
- 1.3412524151802063
- 1.331908564567566
- 3.156225848197937
- 1.337593116760254
- 1.3095347237586976
- 1.321760721206665
- 1.3449536418914796
- 3.188231658935547
- 1.2939979529380798
- 1.3047814440727235
- 1.287509162425995
- 3.0773940801620485
- 1.2607846713066102
- 1.2733850622177123
- 1.2834175944328308
- 1.2754916477203369
- 1.285191571712494
- 1.2965817260742187
- 1.2989057731628417
- 1.319623622894287
- 1.2948916411399842
- 1.324521450996399
- 3.159469413757324
- 1.2981088829040528
- 1.2840811276435853
- 1.2719415307044983
- 2.9679409217834474
- 1.268254954814911
- 1.2808076930046082
- 1.266774652004242
- 1.2724701237678528
- 1.2884365367889403
- 1.2783696556091309
- 1.270053379535675
- 1.281771593093872
- 1.3040984058380127
- 1.282271635532379
- 1.289235122203827
- 1.2890011262893677
- 1.294373631477356
- 1.290434055328369
- 1.2870609760284424
- 1.2719986319541932
- 1.2971432900428772
- 1.2803946828842163
- 1.2681158900260925
- 1.2796663045883179
- 1.2788904452323913
- 1.2778904604911805
- 1.310200138092041
- 1.269671516418457
- 1.2625179672241211
- 2.9486188888549805
- 1.2392125916481018
- 1.230875356197357
- 1.2491728496551513
- 1.2444414114952087
- 1.2721764636039734
- 1.2785013461112975
- 1.2500421762466432
- 1.2592295265197755
- 1.2516824388504029
- 1.2784868097305297
- 2.9646057319641113
train_accuracy:
- 0.043
- 0.083
- 0.106
- 0.111
- 0.115
- 0.114
- 0.165
- 0.141
- 0.135
- 0.193
- 0.161
- 0.197
- 0.0
- 0.172
- 0.241
- 0.177
- 0.176
- 0.175
- 0.249
- 0.215
- 0.188
- 0.0
- 0.228
- 0.191
- 0.233
- 0.186
- 0.2
- 0.189
- 0.241
- 0.0
- 0.28
- 0.261
- 0.23
- 0.233
- 0.0
- 0.0
- 0.248
- 0.254
- 0.0
- 0.235
- 0.243
- 0.227
- 0.241
- 0.0
- 0.246
- 0.265
- 0.256
- 0.0
- 0.308
- 0.275
- 0.264
- 0.309
- 0.283
- 0.264
- 0.277
- 0.254
- 0.28
- 0.245
- 0.0
- 0.223
- 0.275
- 0.283
- 0.0
- 0.253
- 0.264
- 0.303
- 0.273
- 0.274
- 0.276
- 0.32
- 0.314
- 0.287
- 0.293
- 0.285
- 0.301
- 0.323
- 0.295
- 0.288
- 0.312
- 0.295
- 0.286
- 0.301
- 0.322
- 0.317
- 0.308
- 0.295
- 0.311
- 0.347
- 0.0
- 0.319
- 0.293
- 0.328
- 0.295
- 0.312
- 0.318
- 0.321
- 0.274
- 0.345
- 0.34
- 0.0
train_loss:
- 4.351
- 3.876
- 3.627
- 3.288
- 3.524
- 2.92
- 3.343
- 3.053
- 3.255
- 3.168
- 3.131
- 2.817
- 1.09
- 3.35
- 2.855
- 2.579
- 2.748
- 2.29
- 2.478
- 2.601
- 2.12
- 0.823
- 2.644
- 2.726
- 2.539
- 2.272
- 1.977
- 1.99
- 2.22
- 0.702
- 2.806
- 2.199
- 1.633
- 1.872
- 0.577
- 0.215
- 1.778
- 1.54
- 0.419
- 1.524
- 2.437
- 1.811
- 1.252
- 0.438
- 2.343
- 1.932
- 1.79
- 0.388
- 2.173
- 1.564
- 1.415
- 1.617
- 1.471
- 1.754
- 1.231
- 1.338
- 1.384
- 1.789
- 0.477
- 1.43
- 1.053
- 1.739
- 0.346
- 1.317
- 1.342
- 1.305
- 1.292
- 0.831
- 1.091
- 1.512
- 0.937
- 0.59
- 1.049
- 0.905
- 0.6
- 1.182
- 0.941
- 0.778
- 1.246
- 1.264
- 1.338
- 0.881
- 0.558
- 0.712
- 0.798
- 1.923
- 0.946
- 0.644
- 0.456
- 1.534
- 1.086
- 0.966
- 0.763
- 0.76
- 0.515
- 0.735
- 0.564
- 0.634
- 1.098
- 0.37
unequal: 0
verbose: 1
