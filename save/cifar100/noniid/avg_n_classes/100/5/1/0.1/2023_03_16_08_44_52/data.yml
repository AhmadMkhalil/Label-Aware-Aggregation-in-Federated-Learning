avg_train_accuracy: 0.269
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0368
- 0.0862
- 0.0985
- 0.1108
- 0.1182
- 0.1327
- 0.1382
- 0.1353
- 0.1526
- 0.1603
- 0.1552
- 0.1723
- 0.0314
- 0.171
- 0.0319
- 0.1754
- 0.1889
- 0.1981
- 0.1946
- 0.1998
- 0.034
- 0.2075
- 0.2031
- 0.2067
- 0.2122
- 0.0335
- 0.0348
- 0.2152
- 0.2255
- 0.2255
- 0.2281
- 0.2285
- 0.2329
- 0.2346
- 0.2345
- 0.2402
- 0.2405
- 0.2336
- 0.0355
- 0.0348
- 0.2412
- 0.0374
- 0.2506
- 0.2531
- 0.2487
- 0.246
- 0.2521
- 0.0389
- 0.2458
- 0.2458
- 0.2452
- 0.2542
- 0.2556
- 0.2535
- 0.2663
- 0.2654
- 0.2562
- 0.2711
- 0.2677
- 0.2707
- 0.2804
- 0.2779
- 0.2721
- 0.2625
- 0.2799
- 0.2829
- 0.2803
- 0.2732
- 0.2789
- 0.2842
- 0.2838
- 0.2806
- 0.2892
- 0.2709
- 0.2863
- 0.2893
- 0.289
- 0.2949
- 0.287
- 0.2825
- 0.2854
- 0.2947
- 0.2777
- 0.293
- 0.2929
- 0.2941
- 0.2987
- 0.2909
- 0.2928
- 0.2906
- 0.3036
- 0.3076
- 0.299
- 0.3056
- 0.3
- 0.3011
- 0.299
- 0.3035
- 0.3049
- 0.3053
test_loss_list:
- 1.8064262771606445
- 1.7042788314819335
- 1.6523369026184083
- 1.6391266727447509
- 1.6009633088111876
- 1.5876617312431336
- 1.5743916821479798
- 1.565345413684845
- 1.5533617615699769
- 1.5404448056221007
- 1.5427706599235536
- 1.5046810030937194
- 3.8043917083740233
- 1.4540381288528443
- 3.533845901489258
- 1.4529449224472046
- 1.4223045635223388
- 1.4249242901802064
- 1.415477740764618
- 1.4072466373443604
- 3.5056503009796143
- 1.384712905883789
- 1.3818393659591675
- 1.3923963284492493
- 1.3848583030700683
- 3.436825742721558
- 3.5777219200134276
- 1.3448427414894104
- 1.3488733243942261
- 1.3548079061508178
- 1.3519996762275697
- 1.3460955619812012
- 1.3326807928085327
- 1.337676568031311
- 1.3480856466293334
- 1.3332252025604248
- 1.3353186583518981
- 1.354311966896057
- 3.3555323314666747
- 3.6138263607025145
- 1.3027517986297608
- 3.1987374687194823
- 1.2772263813018798
- 1.2728102803230286
- 1.2928194618225097
- 1.3199981927871705
- 1.3031924653053284
- 3.1649036502838133
- 1.2936429262161255
- 1.297460994720459
- 1.313844838142395
- 1.298561999797821
- 1.2984754586219787
- 1.3160320544242858
- 1.2852683877944946
- 1.2946028161048888
- 1.322179925441742
- 1.2866762804985046
- 1.2923414492607117
- 1.2786856579780579
- 1.2758126401901244
- 1.2740746569633483
- 1.2921760559082032
- 1.3216083550453186
- 1.274338104724884
- 1.2884001302719117
- 1.28041597366333
- 1.2845317912101746
- 1.2921713638305663
- 1.293125283718109
- 1.2834050703048705
- 1.2933305287361145
- 1.2732069277763367
- 1.32117436170578
- 1.295499219894409
- 1.2839081859588624
- 1.292517204284668
- 1.275055410861969
- 1.3002927231788635
- 1.316037130355835
- 1.3127213311195374
- 1.2982135272026063
- 1.3476495504379273
- 1.2873023533821106
- 1.2959700226783752
- 1.3017622661590575
- 1.2894029211997986
- 1.293946487903595
- 1.295697395801544
- 1.3046685934066773
- 1.273510253429413
- 1.273754301071167
- 1.3035896396636963
- 1.2868074154853821
- 1.3032930707931518
- 1.3054472589492798
- 1.3111985182762147
- 1.279919662475586
- 1.2917582082748413
- 1.2985944271087646
train_accuracy:
- 0.049
- 0.101
- 0.109
- 0.122
- 0.127
- 0.122
- 0.121
- 0.162
- 0.178
- 0.15
- 0.169
- 0.148
- 0.0
- 0.146
- 0.0
- 0.153
- 0.2
- 0.185
- 0.182
- 0.178
- 0.0
- 0.199
- 0.195
- 0.192
- 0.188
- 0.0
- 0.0
- 0.21
- 0.228
- 0.216
- 0.212
- 0.222
- 0.204
- 0.221
- 0.217
- 0.223
- 0.213
- 0.226
- 0.0
- 0.0
- 0.25
- 0.0
- 0.217
- 0.237
- 0.21
- 0.214
- 0.227
- 0.0
- 0.223
- 0.224
- 0.229
- 0.272
- 0.26
- 0.244
- 0.254
- 0.24
- 0.281
- 0.26
- 0.221
- 0.269
- 0.234
- 0.302
- 0.27
- 0.266
- 0.302
- 0.263
- 0.268
- 0.291
- 0.282
- 0.258
- 0.262
- 0.312
- 0.276
- 0.323
- 0.269
- 0.288
- 0.302
- 0.298
- 0.286
- 0.34
- 0.255
- 0.251
- 0.307
- 0.233
- 0.266
- 0.274
- 0.278
- 0.269
- 0.251
- 0.309
- 0.319
- 0.285
- 0.291
- 0.337
- 0.282
- 0.282
- 0.294
- 0.318
- 0.263
- 0.269
train_loss:
- 4.382
- 3.86
- 3.753
- 3.663
- 3.339
- 3.172
- 3.225
- 3.205
- 2.809
- 2.942
- 2.866
- 3.094
- 1.054
- 3.411
- 0.692
- 2.857
- 3.012
- 2.97
- 2.599
- 2.593
- 0.671
- 2.795
- 2.715
- 2.192
- 2.292
- 0.602
- 0.236
- 2.622
- 2.503
- 2.003
- 2.381
- 2.133
- 2.258
- 2.08
- 2.261
- 1.901
- 2.021
- 1.554
- 0.576
- 0.174
- 2.723
- 0.364
- 1.998
- 1.84
- 1.436
- 1.083
- 1.522
- 0.415
- 1.333
- 1.96
- 1.373
- 2.223
- 1.636
- 1.131
- 2.09
- 1.299
- 1.771
- 1.276
- 1.695
- 1.793
- 1.059
- 1.841
- 1.486
- 1.57
- 1.48
- 1.203
- 1.156
- 1.098
- 1.177
- 0.936
- 0.986
- 1.29
- 0.902
- 0.95
- 1.04
- 1.043
- 0.752
- 0.772
- 0.844
- 0.9
- 0.822
- 0.851
- 0.637
- 1.361
- 0.762
- 1.611
- 0.563
- 0.743
- 1.05
- 1.465
- 0.845
- 0.561
- 0.321
- 0.584
- 0.305
- 0.215
- 1.269
- 0.532
- 0.873
- 0.736
unequal: 0
verbose: 1
