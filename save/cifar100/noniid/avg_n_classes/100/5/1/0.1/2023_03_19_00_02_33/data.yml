avg_train_accuracy: 0.293
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0316
- 0.0787
- 0.1019
- 0.0317
- 0.0322
- 0.121
- 0.1218
- 0.1294
- 0.1374
- 0.1506
- 0.1493
- 0.1625
- 0.1697
- 0.1658
- 0.1688
- 0.1855
- 0.1859
- 0.2043
- 0.2038
- 0.2076
- 0.2069
- 0.2025
- 0.2122
- 0.2205
- 0.2119
- 0.0334
- 0.2086
- 0.2215
- 0.0345
- 0.2314
- 0.2307
- 0.2362
- 0.2369
- 0.0351
- 0.2315
- 0.2301
- 0.2455
- 0.243
- 0.2526
- 0.0354
- 0.2437
- 0.252
- 0.2593
- 0.0365
- 0.2536
- 0.265
- 0.2587
- 0.2665
- 0.2592
- 0.2659
- 0.2667
- 0.2646
- 0.2558
- 0.2672
- 0.2698
- 0.2724
- 0.2701
- 0.2822
- 0.038
- 0.2842
- 0.2843
- 0.2829
- 0.2919
- 0.2859
- 0.286
- 0.0456
- 0.2842
- 0.2786
- 0.2797
- 0.0432
- 0.2982
- 0.2899
- 0.287
- 0.2937
- 0.2915
- 0.2914
- 0.2892
- 0.2998
- 0.2887
- 0.2983
- 0.2972
- 0.2892
- 0.3007
- 0.2966
- 0.3055
- 0.3033
- 0.2897
- 0.0445
- 0.3118
- 0.3032
- 0.2957
- 0.2934
- 0.049
- 0.3069
- 0.3178
- 0.3082
- 0.3039
- 0.0518
- 0.3185
- 0.3141
test_loss_list:
- 1.8089952564239502
- 1.698566861152649
- 1.6499585437774658
- 3.6827247238159178
- 3.8486363983154295
- 1.5979474902153015
- 1.5783919072151185
- 1.556865155696869
- 1.552037410736084
- 1.537692437171936
- 1.5287076616287232
- 1.504659276008606
- 1.5004227757453918
- 1.4828064990043641
- 1.4911137461662292
- 1.4610853385925293
- 1.4607507038116454
- 1.4313459491729736
- 1.4250733137130738
- 1.4243189811706543
- 1.4275467491149902
- 1.4503118944168092
- 1.4114730286598205
- 1.4008553528785705
- 1.4266443037986756
- 3.4676482582092287
- 1.3755801606178284
- 1.3435616731643676
- 3.3053074741363524
- 1.3331652617454528
- 1.3530847120285034
- 1.3418385100364685
- 1.3495087957382201
- 3.292678561210632
- 1.3469108247756958
- 1.3264290165901185
- 1.3140958786010741
- 1.3306987500190735
- 1.3110321044921875
- 3.2647945356369017
- 1.3029455518722535
- 1.3004444861412048
- 1.2873958826065064
- 3.164048662185669
- 1.2838834166526794
- 1.2805718207359313
- 1.296033306121826
- 1.2824281883239745
- 1.3070092344284057
- 1.2927455615997314
- 1.3009745454788209
- 1.290715250968933
- 1.3014222717285155
- 1.2937050580978393
- 1.3038596272468568
- 1.3140371561050415
- 1.2985529446601867
- 1.2906391143798828
- 3.1046643257141113
- 1.2597807836532593
- 1.2527607035636903
- 1.2567396402359008
- 1.2447201704978943
- 1.2683099126815796
- 1.2505746459960938
- 2.971751470565796
- 1.2470080971717834
- 1.2688489484786987
- 1.2644685649871825
- 3.0816856145858766
- 1.2210541200637817
- 1.237142598628998
- 1.251634488105774
- 1.2355406403541564
- 1.2468646621704103
- 1.262715187072754
- 1.2633008503913878
- 1.2478203654289246
- 1.2534174275398255
- 1.259769034385681
- 1.2639980101585389
- 1.2980941176414489
- 1.2568588089942931
- 1.2686047601699828
- 1.272214970588684
- 1.2481691217422486
- 1.2723178005218505
- 3.181501307487488
- 1.2121273326873778
- 1.2196082758903504
- 1.252684257030487
- 1.251121804714203
- 2.9111495304107664
- 1.214474103450775
- 1.2076238656044007
- 1.2129136729240417
- 1.2242926144599915
- 2.849424276351929
- 1.1959147334098816
- 1.220395634174347
train_accuracy:
- 0.051
- 0.07
- 0.11
- 0.0
- 0.0
- 0.122
- 0.104
- 0.13
- 0.106
- 0.162
- 0.132
- 0.113
- 0.185
- 0.187
- 0.141
- 0.187
- 0.175
- 0.162
- 0.189
- 0.154
- 0.174
- 0.17
- 0.221
- 0.178
- 0.157
- 0.0
- 0.222
- 0.237
- 0.0
- 0.183
- 0.195
- 0.269
- 0.221
- 0.0
- 0.201
- 0.254
- 0.244
- 0.254
- 0.219
- 0.0
- 0.263
- 0.202
- 0.218
- 0.0
- 0.225
- 0.256
- 0.231
- 0.317
- 0.3
- 0.249
- 0.261
- 0.295
- 0.279
- 0.282
- 0.256
- 0.257
- 0.247
- 0.234
- 0.0
- 0.229
- 0.284
- 0.253
- 0.257
- 0.279
- 0.307
- 0.0
- 0.275
- 0.28
- 0.299
- 0.0
- 0.265
- 0.303
- 0.28
- 0.272
- 0.308
- 0.262
- 0.305
- 0.249
- 0.306
- 0.258
- 0.267
- 0.254
- 0.258
- 0.315
- 0.281
- 0.316
- 0.316
- 0.0
- 0.271
- 0.319
- 0.323
- 0.322
- 0.0
- 0.272
- 0.287
- 0.338
- 0.341
- 0.0
- 0.29
- 0.293
train_loss:
- 4.339
- 3.903
- 3.731
- 1.074
- 0.508
- 3.575
- 3.474
- 3.27
- 3.001
- 2.898
- 2.918
- 3.161
- 2.576
- 3.05
- 2.666
- 3.007
- 2.618
- 2.947
- 2.861
- 2.498
- 2.338
- 1.847
- 2.586
- 2.257
- 1.788
- 0.848
- 2.981
- 2.275
- 0.568
- 1.926
- 1.833
- 2.237
- 1.487
- 0.558
- 1.345
- 2.231
- 2.352
- 1.79
- 1.648
- 0.488
- 2.438
- 2.396
- 1.351
- 0.426
- 2.434
- 1.11
- 0.795
- 1.904
- 1.317
- 1.792
- 1.211
- 1.925
- 1.882
- 1.438
- 1.242
- 0.82
- 1.959
- 1.932
- 0.515
- 1.535
- 0.947
- 1.505
- 1.07
- 0.773
- 1.532
- 0.417
- 1.485
- 1.138
- 1.723
- 0.353
- 1.074
- 1.274
- 1.031
- 1.392
- 1.037
- 0.825
- 0.785
- 0.764
- 1.417
- 0.576
- 0.358
- 0.289
- 1.418
- 0.818
- 0.986
- 1.367
- 1.21
- 0.412
- 0.978
- 0.822
- 0.511
- 1.148
- 0.313
- 0.972
- 0.735
- 1.101
- 0.637
- 0.266
- 0.623
- 0.286
unequal: 0
verbose: 1
