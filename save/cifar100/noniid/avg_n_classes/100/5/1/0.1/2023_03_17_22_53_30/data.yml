avg_train_accuracy: 0.299
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0405
- 0.0853
- 0.0946
- 0.1137
- 0.1214
- 0.1344
- 0.1342
- 0.1459
- 0.1595
- 0.1643
- 0.1623
- 0.0322
- 0.1745
- 0.0322
- 0.1793
- 0.1835
- 0.1913
- 0.201
- 0.1914
- 0.1925
- 0.201
- 0.2113
- 0.0331
- 0.2208
- 0.2276
- 0.2189
- 0.231
- 0.2377
- 0.2388
- 0.035
- 0.2396
- 0.2341
- 0.2397
- 0.2431
- 0.2495
- 0.2518
- 0.2543
- 0.2472
- 0.2587
- 0.2606
- 0.0369
- 0.2603
- 0.2585
- 0.2672
- 0.0374
- 0.2665
- 0.2629
- 0.2733
- 0.2744
- 0.2618
- 0.2725
- 0.2711
- 0.279
- 0.2782
- 0.2827
- 0.2795
- 0.28
- 0.2921
- 0.2929
- 0.0412
- 0.2857
- 0.2941
- 0.292
- 0.2928
- 0.2869
- 0.2906
- 0.2923
- 0.2905
- 0.3002
- 0.3021
- 0.299
- 0.2984
- 0.3031
- 0.3064
- 0.2963
- 0.3027
- 0.3069
- 0.3052
- 0.3055
- 0.3024
- 0.3034
- 0.3021
- 0.0447
- 0.3106
- 0.0493
- 0.3041
- 0.3178
- 0.3125
- 0.3131
- 0.3066
- 0.3035
- 0.3079
- 0.3021
- 0.3174
- 0.3201
- 0.3127
- 0.3214
- 0.3137
- 0.3255
- 0.3222
test_loss_list:
- 1.8061124849319459
- 1.7073375749588013
- 1.6624028944969178
- 1.6277637195587158
- 1.6001242876052857
- 1.5770662450790405
- 1.5840699481964111
- 1.5520204615592956
- 1.5340964937210082
- 1.5356309485435486
- 1.5499057245254517
- 3.7532732391357424
- 1.4642947936058044
- 3.53837459564209
- 1.4447361159324645
- 1.4393295669555664
- 1.428904058933258
- 1.4219594240188598
- 1.4455121970176696
- 1.4622827243804932
- 1.4174070787429809
- 1.4142248511314393
- 3.4142574501037597
- 1.3652919840812683
- 1.3561550426483153
- 1.3780796813964844
- 1.3536500692367555
- 1.3388515520095825
- 1.3518764805793761
- 3.3374830150604247
- 1.3160257887840272
- 1.3374175333976746
- 1.3333602142333985
- 1.3346307015419006
- 1.3238457083702087
- 1.3263104891777038
- 1.3095302820205688
- 1.3284354162216188
- 1.3170378255844115
- 1.323069007396698
- 3.1540433835983275
- 1.2786845397949218
- 1.2841957712173462
- 1.2708061289787294
- 3.1589465045928957
- 1.2630068731307984
- 1.2697483348846434
- 1.260349133014679
- 1.2738093543052673
- 1.3079567289352416
- 1.2722237348556518
- 1.284392545223236
- 1.2718871641159057
- 1.2725612688064576
- 1.2806074523925781
- 1.2762210369110107
- 1.2838272833824158
- 1.2572198247909545
- 1.2560700297355651
- 3.0181323671340943
- 1.231926007270813
- 1.2300593280792236
- 1.2340445232391357
- 1.228149664402008
- 1.262209882736206
- 1.2498268365859986
- 1.2497393918037414
- 1.2490955233573913
- 1.2460383033752442
- 1.2478894925117492
- 1.2437435507774353
- 1.25850035905838
- 1.2435234880447388
- 1.2447394514083863
- 1.2496669220924377
- 1.2372790122032165
- 1.2529986310005188
- 1.232767071723938
- 1.2579950022697448
- 1.266395845413208
- 1.2615660166740417
- 1.2659907126426697
- 3.1019842624664307
- 1.206303927898407
- 2.8940987634658812
- 1.218307557106018
- 1.1895336174964906
- 1.2125580883026124
- 1.22643399477005
- 1.2358473062515258
- 1.2612934231758117
- 1.2338001728057861
- 1.2457521295547485
- 1.2206295156478881
- 1.222128508090973
- 1.2390940976142883
- 1.2308865547180177
- 1.247030837535858
- 1.2276686835289001
- 1.2373058438301086
train_accuracy:
- 0.051
- 0.061
- 0.102
- 0.118
- 0.11
- 0.144
- 0.139
- 0.12
- 0.146
- 0.183
- 0.171
- 0.0
- 0.15
- 0.0
- 0.167
- 0.19
- 0.139
- 0.179
- 0.182
- 0.176
- 0.211
- 0.188
- 0.0
- 0.193
- 0.237
- 0.192
- 0.219
- 0.221
- 0.241
- 0.0
- 0.242
- 0.213
- 0.231
- 0.255
- 0.251
- 0.234
- 0.221
- 0.229
- 0.225
- 0.235
- 0.0
- 0.279
- 0.262
- 0.252
- 0.0
- 0.257
- 0.259
- 0.247
- 0.244
- 0.261
- 0.294
- 0.247
- 0.247
- 0.289
- 0.234
- 0.266
- 0.273
- 0.235
- 0.266
- 0.0
- 0.291
- 0.273
- 0.279
- 0.252
- 0.248
- 0.297
- 0.289
- 0.3
- 0.289
- 0.324
- 0.284
- 0.29
- 0.282
- 0.271
- 0.278
- 0.255
- 0.262
- 0.302
- 0.283
- 0.257
- 0.289
- 0.294
- 0.0
- 0.285
- 0.0
- 0.264
- 0.285
- 0.275
- 0.295
- 0.275
- 0.26
- 0.319
- 0.293
- 0.329
- 0.304
- 0.282
- 0.332
- 0.288
- 0.293
- 0.299
train_loss:
- 4.351
- 3.927
- 3.701
- 3.559
- 3.237
- 3.303
- 2.86
- 3.323
- 2.851
- 2.608
- 2.235
- 1.072
- 3.378
- 0.682
- 3.239
- 2.988
- 2.796
- 2.493
- 2.027
- 1.766
- 2.896
- 2.586
- 0.729
- 2.743
- 2.664
- 2.109
- 2.724
- 2.199
- 2.133
- 0.627
- 2.667
- 1.902
- 1.973
- 1.812
- 1.869
- 1.614
- 2.215
- 1.749
- 1.615
- 1.809
- 0.587
- 2.369
- 1.494
- 2.22
- 0.456
- 1.999
- 2.222
- 1.565
- 1.295
- 0.924
- 1.811
- 1.315
- 1.479
- 1.457
- 1.041
- 1.891
- 1.622
- 1.748
- 0.926
- 0.514
- 1.781
- 1.608
- 1.19
- 0.819
- 0.533
- 1.354
- 1.264
- 1.317
- 1.541
- 1.145
- 0.993
- 0.855
- 1.231
- 1.311
- 1.092
- 0.723
- 0.942
- 1.16
- 0.87
- 0.767
- 0.965
- 0.576
- 0.519
- 0.78
- 0.265
- 0.557
- 1.4
- 0.428
- 0.786
- 0.467
- 0.352
- 0.989
- 0.71
- 1.121
- 1.111
- 0.622
- 0.805
- 0.537
- 0.525
- 0.359
unequal: 0
verbose: 1
