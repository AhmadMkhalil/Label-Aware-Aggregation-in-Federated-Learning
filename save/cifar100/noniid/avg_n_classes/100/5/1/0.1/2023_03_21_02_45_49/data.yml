avg_train_accuracy: 0.233
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0383
- 0.0839
- 0.1027
- 0.1219
- 0.1272
- 0.1305
- 0.1371
- 0.1546
- 0.1561
- 0.1671
- 0.0315
- 0.1595
- 0.166
- 0.1858
- 0.1785
- 0.1873
- 0.1879
- 0.1963
- 0.1919
- 0.1952
- 0.1981
- 0.2111
- 0.2182
- 0.2182
- 0.2163
- 0.2273
- 0.2224
- 0.2197
- 0.2255
- 0.2242
- 0.2338
- 0.2354
- 0.2404
- 0.2355
- 0.2372
- 0.2484
- 0.2512
- 0.2459
- 0.2541
- 0.2647
- 0.2499
- 0.255
- 0.2639
- 0.2584
- 0.2462
- 0.2603
- 0.0338
- 0.2578
- 0.2705
- 0.2613
- 0.2624
- 0.2749
- 0.2692
- 0.2702
- 0.2612
- 0.2665
- 0.036
- 0.2762
- 0.2743
- 0.2772
- 0.2754
- 0.0376
- 0.277
- 0.269
- 0.2825
- 0.2775
- 0.2716
- 0.2805
- 0.2871
- 0.2901
- 0.2862
- 0.0395
- 0.2835
- 0.2907
- 0.2873
- 0.2866
- 0.2829
- 0.2907
- 0.2916
- 0.2956
- 0.2903
- 0.2892
- 0.2958
- 0.2925
- 0.0443
- 0.3021
- 0.2975
- 0.0461
- 0.2985
- 0.0462
- 0.2972
- 0.2928
- 0.3051
- 0.0517
- 0.2996
- 0.304
- 0.297
- 0.301
- 0.3027
- 0.2931
test_loss_list:
- 1.8021088600158692
- 1.7122961568832398
- 1.6523238682746888
- 1.6191184067726134
- 1.6102528476715088
- 1.5903723526000977
- 1.5932132577896119
- 1.5571955728530884
- 1.544244408607483
- 1.537815933227539
- 3.637416296005249
- 1.4822159242630004
- 1.4860373973846435
- 1.4555196809768676
- 1.481737232208252
- 1.4629330897331239
- 1.463106529712677
- 1.45005366563797
- 1.4656839561462403
- 1.4455422687530517
- 1.4439342427253723
- 1.415751576423645
- 1.4108288025856017
- 1.4081019926071168
- 1.410037796497345
- 1.3937190961837769
- 1.410617492198944
- 1.4101172089576721
- 1.3977556133270264
- 1.4085477566719056
- 1.391905858516693
- 1.392954306602478
- 1.3780791711807252
- 1.3757791018486023
- 1.3794284415245057
- 1.3605911755561828
- 1.3563931488990784
- 1.3661981463432311
- 1.345126874446869
- 1.334015290737152
- 1.3517550611495972
- 1.3519283270835876
- 1.3501441097259521
- 1.3526097559928894
- 1.3599229598045348
- 1.3462528657913209
- 3.616048412322998
- 1.2923077487945556
- 1.2813636302947997
- 1.2957771134376526
- 1.3027225708961487
- 1.2921287298202515
- 1.3009705591201781
- 1.2843047404289245
- 1.3176478838920593
- 1.3153430128097534
- 3.24094669342041
- 1.2561555624008178
- 1.2707329988479614
- 1.275937216281891
- 1.2843078017234801
- 3.1962361669540407
- 1.2615090036392211
- 1.2796976065635681
- 1.2587274813652038
- 1.2765703535079955
- 1.2948142743110658
- 1.2702311420440673
- 1.2639005708694457
- 1.2660636925697326
- 1.2929650473594665
- 3.1880294561386107
- 1.2468077945709228
- 1.2377515125274658
- 1.2546101760864259
- 1.2585383749008179
- 1.2811552023887633
- 1.262684965133667
- 1.2536372232437134
- 1.2444866514205932
- 1.2634923005104064
- 1.2831906747817994
- 1.259182813167572
- 1.2765231728553772
- 3.1165562677383423
- 1.2155639004707337
- 1.2318100690841676
- 3.0116393899917604
- 1.2185764527320861
- 2.8952330350875854
- 1.2208299160003662
- 1.2392726492881776
- 1.2349062585830688
- 2.9245355463027956
- 1.228095166683197
- 1.2325540566444397
- 1.249016089439392
- 1.248764123916626
- 1.2390713119506835
- 1.2687139058113097
train_accuracy:
- 0.048
- 0.102
- 0.114
- 0.101
- 0.164
- 0.12
- 0.145
- 0.162
- 0.125
- 0.213
- 0.0
- 0.15
- 0.156
- 0.177
- 0.175
- 0.196
- 0.193
- 0.189
- 0.202
- 0.187
- 0.229
- 0.169
- 0.197
- 0.211
- 0.19
- 0.254
- 0.246
- 0.215
- 0.191
- 0.232
- 0.192
- 0.245
- 0.238
- 0.265
- 0.219
- 0.281
- 0.21
- 0.234
- 0.207
- 0.279
- 0.246
- 0.221
- 0.289
- 0.291
- 0.28
- 0.239
- 0.0
- 0.243
- 0.31
- 0.26
- 0.308
- 0.311
- 0.256
- 0.254
- 0.222
- 0.262
- 0.0
- 0.271
- 0.318
- 0.305
- 0.266
- 0.0
- 0.273
- 0.257
- 0.275
- 0.304
- 0.255
- 0.261
- 0.351
- 0.308
- 0.357
- 0.0
- 0.274
- 0.305
- 0.268
- 0.275
- 0.278
- 0.336
- 0.247
- 0.35
- 0.294
- 0.285
- 0.285
- 0.24
- 0.0
- 0.33
- 0.31
- 0.0
- 0.283
- 0.0
- 0.299
- 0.289
- 0.341
- 0.0
- 0.293
- 0.352
- 0.293
- 0.345
- 0.26
- 0.233
train_loss:
- 4.278
- 3.859
- 3.689
- 3.633
- 3.438
- 3.186
- 2.8
- 3.12
- 3.258
- 2.918
- 1.078
- 3.262
- 2.846
- 2.745
- 2.538
- 2.366
- 2.569
- 2.873
- 2.33
- 2.572
- 2.717
- 2.791
- 2.489
- 2.178
- 2.309
- 2.163
- 1.659
- 2.198
- 1.991
- 1.782
- 1.902
- 1.612
- 2.582
- 2.281
- 2.097
- 2.107
- 1.815
- 1.645
- 2.219
- 1.504
- 1.343
- 1.625
- 1.197
- 1.761
- 1.902
- 1.745
- 0.903
- 1.555
- 1.106
- 2.081
- 1.609
- 0.94
- 1.226
- 1.851
- 1.269
- 1.078
- 0.639
- 1.974
- 1.371
- 0.922
- 1.328
- 0.495
- 1.113
- 0.946
- 1.428
- 1.149
- 0.757
- 1.324
- 1.497
- 0.902
- 1.041
- 0.51
- 1.204
- 1.352
- 1.166
- 0.78
- 0.498
- 0.838
- 1.488
- 1.004
- 0.573
- 0.349
- 0.905
- 1.134
- 0.495
- 1.018
- 0.691
- 0.313
- 0.935
- 0.268
- 0.615
- 0.551
- 0.636
- 0.268
- 0.557
- 0.469
- 0.334
- 0.881
- 0.99
- 0.556
unequal: 0
verbose: 1
