avg_train_accuracy: 0.307
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0292
- 0.0323
- 0.0717
- 0.0827
- 0.1094
- 0.1251
- 0.1323
- 0.1427
- 0.1446
- 0.1492
- 0.1592
- 0.1608
- 0.1722
- 0.1735
- 0.178
- 0.0328
- 0.1914
- 0.1907
- 0.1959
- 0.1953
- 0.1999
- 0.2141
- 0.0334
- 0.2102
- 0.211
- 0.2191
- 0.2124
- 0.2119
- 0.2094
- 0.2093
- 0.2244
- 0.231
- 0.2252
- 0.2353
- 0.2381
- 0.2411
- 0.2523
- 0.2418
- 0.251
- 0.2516
- 0.035
- 0.2592
- 0.2574
- 0.2581
- 0.2433
- 0.2592
- 0.2461
- 0.258
- 0.2479
- 0.2641
- 0.0414
- 0.261
- 0.268
- 0.039
- 0.0384
- 0.2711
- 0.2676
- 0.2581
- 0.2723
- 0.2771
- 0.2755
- 0.2688
- 0.273
- 0.2822
- 0.2837
- 0.2759
- 0.0448
- 0.2796
- 0.2801
- 0.2928
- 0.2805
- 0.2779
- 0.2647
- 0.2866
- 0.2971
- 0.285
- 0.2872
- 0.2763
- 0.2876
- 0.0481
- 0.2939
- 0.2867
- 0.298
- 0.2944
- 0.3003
- 0.2969
- 0.2869
- 0.2966
- 0.3032
- 0.2918
- 0.3005
- 0.3066
- 0.2951
- 0.3034
- 0.3063
- 0.3027
- 0.3056
- 0.2999
- 0.2959
- 0.3057
test_loss_list:
- 3.1363660717010498
- 4.045353679656983
- 1.7338360452651977
- 1.6799344396591187
- 1.6283821749687195
- 1.5946283888816835
- 1.5798687791824342
- 1.5627737712860108
- 1.5509918880462648
- 1.5386652398109435
- 1.519158616065979
- 1.5120947885513305
- 1.4963515019416809
- 1.494163122177124
- 1.491615571975708
- 3.494198369979858
- 1.4304258561134338
- 1.4286345911026002
- 1.428711006641388
- 1.451513602733612
- 1.4217346382141114
- 1.4022526884078979
- 3.3879306602478025
- 1.3652771949768066
- 1.3902220940589904
- 1.3762991309165955
- 1.3890540146827697
- 1.4011499333381652
- 1.418968162536621
- 1.4339831280708313
- 1.386114637851715
- 1.3698209476470948
- 1.3880693984031678
- 1.3732749128341675
- 1.3653678321838378
- 1.350968780517578
- 1.341961977481842
- 1.3522733640670777
- 1.3466842699050903
- 1.3500427627563476
- 3.3190327978134153
- 1.293251440525055
- 1.3103040480613708
- 1.315607500076294
- 1.34931081533432
- 1.311484010219574
- 1.3441360878944397
- 1.3133916974067688
- 1.3411793661117555
- 1.3103389263153076
- 3.191113300323486
- 1.2665090537071229
- 1.2765157580375672
- 3.1443910074234007
- 3.2655331611633303
- 1.2524553036689758
- 1.262713165283203
- 1.2869414067268372
- 1.272935039997101
- 1.2698799800872802
- 1.2837951326370238
- 1.29062260389328
- 1.2955338120460511
- 1.2694059634208679
- 1.2813393664360047
- 1.2786629915237426
- 3.0197008562088015
- 1.2341782641410828
- 1.242431001663208
- 1.2446065187454223
- 1.272931625843048
- 1.2797815656661988
- 1.3034948825836181
- 1.2618235492706298
- 1.2478295302391051
- 1.279201385974884
- 1.2712945818901062
- 1.2994493579864501
- 1.2759542512893676
- 2.983423261642456
- 1.227526409626007
- 1.2309291362762451
- 1.2288975429534912
- 1.2367707252502442
- 1.2278432822227479
- 1.2548419857025146
- 1.2845018887519837
- 1.2537542915344237
- 1.2490164470672607
- 1.2635467386245727
- 1.2526834797859192
- 1.2641557431221009
- 1.2883157277107238
- 1.2707796359062196
- 1.271828532218933
- 1.2625979900360107
- 1.2602596068382264
- 1.2927204060554505
- 1.3140621542930604
- 1.2752643847465515
train_accuracy:
- 0.0
- 0.0
- 0.068
- 0.065
- 0.086
- 0.123
- 0.123
- 0.142
- 0.13
- 0.136
- 0.125
- 0.138
- 0.187
- 0.126
- 0.16
- 0.0
- 0.231
- 0.196
- 0.2
- 0.189
- 0.174
- 0.233
- 0.0
- 0.23
- 0.251
- 0.238
- 0.185
- 0.172
- 0.17
- 0.169
- 0.252
- 0.248
- 0.189
- 0.225
- 0.278
- 0.192
- 0.226
- 0.212
- 0.289
- 0.247
- 0.0
- 0.246
- 0.221
- 0.241
- 0.215
- 0.299
- 0.275
- 0.247
- 0.236
- 0.284
- 0.0
- 0.278
- 0.26
- 0.0
- 0.0
- 0.253
- 0.204
- 0.205
- 0.225
- 0.277
- 0.229
- 0.234
- 0.271
- 0.326
- 0.271
- 0.224
- 0.0
- 0.252
- 0.302
- 0.289
- 0.287
- 0.23
- 0.323
- 0.286
- 0.251
- 0.307
- 0.249
- 0.227
- 0.243
- 0.0
- 0.3
- 0.336
- 0.322
- 0.303
- 0.281
- 0.293
- 0.253
- 0.313
- 0.336
- 0.261
- 0.333
- 0.255
- 0.253
- 0.32
- 0.311
- 0.327
- 0.316
- 0.266
- 0.248
- 0.307
train_loss:
- 0.974
- 0.469
- 4.556
- 3.834
- 3.662
- 3.541
- 3.443
- 3.115
- 2.987
- 3.102
- 3.002
- 3.034
- 3.009
- 2.653
- 2.646
- 0.867
- 2.859
- 2.985
- 2.44
- 2.112
- 2.892
- 2.338
- 0.663
- 3.072
- 1.989
- 2.416
- 2.532
- 1.997
- 1.67
- 1.399
- 1.912
- 2.433
- 1.436
- 1.965
- 1.617
- 2.381
- 2.095
- 1.885
- 1.415
- 2.278
- 0.672
- 1.949
- 1.421
- 1.399
- 1.045
- 1.287
- 0.878
- 1.926
- 1.37
- 1.834
- 0.562
- 2.319
- 1.222
- 0.394
- 0.122
- 1.665
- 2.086
- 1.427
- 1.812
- 1.057
- 1.288
- 1.325
- 0.847
- 1.053
- 1.246
- 1.194
- 0.471
- 2.05
- 0.874
- 0.794
- 0.491
- 1.247
- 1.693
- 1.415
- 1.086
- 0.995
- 0.779
- 1.229
- 1.064
- 0.413
- 0.756
- 1.346
- 0.791
- 1.081
- 0.538
- 0.329
- 0.97
- 1.104
- 0.66
- 1.493
- 0.854
- 0.785
- 0.456
- 0.45
- 0.266
- 0.556
- 0.273
- 0.495
- 0.321
- 0.257
unequal: 0
verbose: 1
