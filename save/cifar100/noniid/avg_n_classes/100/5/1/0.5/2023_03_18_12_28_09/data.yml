avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0454
- 0.1058
- 0.1294
- 0.1386
- 0.148
- 0.166
- 0.1706
- 0.1783
- 0.1851
- 0.1959
- 0.1994
- 0.2101
- 0.215
- 0.2172
- 0.2257
- 0.2286
- 0.2343
- 0.234
- 0.2379
- 0.2479
- 0.2461
- 0.247
- 0.2548
- 0.2526
- 0.2605
- 0.2621
- 0.2632
- 0.2714
- 0.2648
- 0.2755
- 0.2751
- 0.2774
- 0.2768
- 0.2826
- 0.2825
- 0.2835
- 0.2826
- 0.2853
- 0.2849
- 0.289
- 0.2928
- 0.296
- 0.2994
- 0.2956
- 0.2975
- 0.2969
- 0.3064
- 0.3034
- 0.3055
- 0.3095
- 0.3088
- 0.31
- 0.3103
- 0.3062
- 0.3092
- 0.3094
- 0.3077
- 0.3119
- 0.3146
- 0.3145
- 0.3139
- 0.3156
- 0.3143
- 0.3157
- 0.313
- 0.3209
- 0.3195
- 0.3172
- 0.3228
- 0.3209
- 0.3178
- 0.3218
- 0.3232
- 0.3213
- 0.3219
- 0.3274
- 0.326
- 0.3255
- 0.3246
- 0.3247
- 0.3252
- 0.3247
- 0.327
- 0.3256
- 0.3256
- 0.3273
- 0.3295
- 0.3259
- 0.3296
- 0.3322
- 0.3354
- 0.3288
- 0.3285
- 0.3334
- 0.3307
- 0.3253
- 0.331
- 0.3282
- 0.3304
- 0.3316
test_loss_list:
- 1.7754708242416382
- 1.6467787098884583
- 1.5962619400024414
- 1.564236443042755
- 1.5337995886802673
- 1.5120905661582946
- 1.4908244657516478
- 1.4701395750045776
- 1.4580955028533935
- 1.4401986527442932
- 1.4228157687187195
- 1.4097912168502809
- 1.3982587718963624
- 1.3930154609680176
- 1.3854847741127014
- 1.37043949842453
- 1.350671362876892
- 1.3442578029632568
- 1.328930857181549
- 1.3270415091514587
- 1.3277053618431092
- 1.315553867816925
- 1.2987900876998901
- 1.2954885983467102
- 1.2879901552200317
- 1.2784408164024352
- 1.2845354104042053
- 1.2798534178733825
- 1.2707249569892882
- 1.2662548565864562
- 1.2663925719261169
- 1.2605633449554443
- 1.2612493324279785
- 1.2580281281471253
- 1.2573058676719666
- 1.2596008133888246
- 1.2471955847740173
- 1.248084020614624
- 1.240750985145569
- 1.2303375148773192
- 1.2315393090248108
- 1.2302721881866454
- 1.2311758947372438
- 1.2339399242401123
- 1.233710687160492
- 1.225613157749176
- 1.2220393919944763
- 1.2218507027626038
- 1.2237308812141419
- 1.2223183441162109
- 1.2094733810424805
- 1.2090218663215637
- 1.2159812378883361
- 1.2077972936630248
- 1.19982177734375
- 1.196455340385437
- 1.196319568157196
- 1.1877879333496093
- 1.1926713681221008
- 1.1991726922988892
- 1.1891503071784972
- 1.1929303240776061
- 1.1986257863044738
- 1.1899380326271056
- 1.190340120792389
- 1.1924141216278077
- 1.192117350101471
- 1.1936754512786865
- 1.197441613674164
- 1.1908835196495056
- 1.184321870803833
- 1.186836450099945
- 1.1827251100540161
- 1.1808163809776306
- 1.1771633839607238
- 1.1704727220535278
- 1.1795656895637512
- 1.1738507223129273
- 1.173047785758972
- 1.1846574974060058
- 1.1876771879196166
- 1.1968392848968505
- 1.1935052847862244
- 1.1876471471786498
- 1.1957332324981689
- 1.1937135434150696
- 1.1971948409080506
- 1.1954347681999207
- 1.1907121181488036
- 1.1961961030960082
- 1.1953942012786865
- 1.2044875979423524
- 1.2029641938209534
- 1.204764494895935
- 1.2050638389587403
- 1.2142156195640563
- 1.195489854812622
- 1.1926800775527955
- 1.197222695350647
- 1.1902795839309692
train_accuracy:
- 0.052
- 0.121
- 0.169
- 0.141
- 0.152
- 0.141
- 0.182
- 0.0
- 0.206
- 0.252
- 0.195
- 0.17
- 0.208
- 0.211
- 0.217
- 0.0
- 0.0
- 0.245
- 0.235
- 0.178
- 0.272
- 0.281
- 0.273
- 0.284
- 0.243
- 0.283
- 0.205
- 0.255
- 0.239
- 0.251
- 0.268
- 0.218
- 0.279
- 0.283
- 0.314
- 0.298
- 0.296
- 0.269
- 0.258
- 0.313
- 0.255
- 0.281
- 0.264
- 0.304
- 0.273
- 0.316
- 0.276
- 0.315
- 0.285
- 0.318
- 0.292
- 0.291
- 0.253
- 0.342
- 0.302
- 0.316
- 0.304
- 0.0
- 0.307
- 0.328
- 0.311
- 0.318
- 0.308
- 0.296
- 0.32
- 0.339
- 0.3
- 0.309
- 0.326
- 0.0
- 0.314
- 0.307
- 0.327
- 0.316
- 0.0
- 0.271
- 0.324
- 0.0
- 0.274
- 0.303
- 0.272
- 0.308
- 0.314
- 0.281
- 0.358
- 0.326
- 0.356
- 0.274
- 0.325
- 0.343
- 0.336
- 0.286
- 0.31
- 0.358
- 0.349
- 0.346
- 0.345
- 0.374
- 0.318
- 0.0
train_loss:
- 4.285
- 3.787
- 3.594
- 3.375
- 3.274
- 3.139
- 3.077
- 2.614
- 2.889
- 2.84
- 2.365
- 2.636
- 2.597
- 2.5
- 2.446
- 2.092
- 2.109
- 1.971
- 1.928
- 2.096
- 2.094
- 1.792
- 1.851
- 1.736
- 1.989
- 1.725
- 1.858
- 1.801
- 1.595
- 1.714
- 1.696
- 1.45
- 1.582
- 1.635
- 1.504
- 1.473
- 1.386
- 1.485
- 1.284
- 1.248
- 1.367
- 1.274
- 1.212
- 1.236
- 1.22
- 1.021
- 1.167
- 1.153
- 1.122
- 1.033
- 1.097
- 1.04
- 0.923
- 0.895
- 0.88
- 0.864
- 0.944
- 0.8
- 0.934
- 0.856
- 0.822
- 0.845
- 0.775
- 0.773
- 0.719
- 0.719
- 0.708
- 0.691
- 0.711
- 0.7
- 0.651
- 0.656
- 0.6
- 0.581
- 0.603
- 0.595
- 0.566
- 0.569
- 0.539
- 0.534
- 0.55
- 0.541
- 0.501
- 0.506
- 0.501
- 0.491
- 0.453
- 0.458
- 0.443
- 0.453
- 0.423
- 0.417
- 0.395
- 0.4
- 0.384
- 0.362
- 0.426
- 0.393
- 0.377
- 0.399
unequal: 0
verbose: 1
