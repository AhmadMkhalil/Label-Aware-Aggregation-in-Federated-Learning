avg_train_accuracy: 0.34
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0485
- 0.0946
- 0.1188
- 0.1333
- 0.1474
- 0.1544
- 0.1662
- 0.1767
- 0.1824
- 0.1883
- 0.1935
- 0.1922
- 0.2036
- 0.2069
- 0.2124
- 0.2198
- 0.2239
- 0.2281
- 0.2313
- 0.2351
- 0.2386
- 0.2383
- 0.2424
- 0.2462
- 0.2515
- 0.254
- 0.2537
- 0.261
- 0.2605
- 0.264
- 0.2647
- 0.2666
- 0.2727
- 0.277
- 0.2765
- 0.2775
- 0.2789
- 0.2815
- 0.2825
- 0.2864
- 0.2898
- 0.2919
- 0.2889
- 0.2902
- 0.2933
- 0.2958
- 0.2981
- 0.299
- 0.2987
- 0.3023
- 0.3026
- 0.3018
- 0.3011
- 0.308
- 0.3058
- 0.3092
- 0.3119
- 0.309
- 0.3133
- 0.3097
- 0.3098
- 0.3114
- 0.3108
- 0.3124
- 0.3106
- 0.315
- 0.3122
- 0.3152
- 0.3163
- 0.3128
- 0.3188
- 0.3183
- 0.3213
- 0.3157
- 0.321
- 0.3165
- 0.3234
- 0.3192
- 0.3175
- 0.3215
- 0.3181
- 0.3238
- 0.3215
- 0.3188
- 0.3232
- 0.3209
- 0.3248
- 0.3222
- 0.3264
- 0.3245
- 0.3244
- 0.3226
- 0.3239
- 0.3264
- 0.3219
- 0.3255
- 0.327
- 0.3272
- 0.3242
- 0.3272
test_loss_list:
- 1.7838627290725708
- 1.6588900732994079
- 1.6077355337142945
- 1.5726836323738098
- 1.5415216088294983
- 1.5128823590278626
- 1.4918027853965758
- 1.4694003200531005
- 1.4542415285110473
- 1.442310061454773
- 1.426302363872528
- 1.4131981778144835
- 1.4062027764320373
- 1.3941286182403565
- 1.376464228630066
- 1.359273226261139
- 1.3551403427124022
- 1.3436230325698852
- 1.3386691236495971
- 1.339189465045929
- 1.331326458454132
- 1.325119981765747
- 1.3112183451652526
- 1.3021005225181579
- 1.2989978098869324
- 1.2950035905838013
- 1.2850316858291626
- 1.2785396432876588
- 1.2813397669792175
- 1.2818168354034425
- 1.270335328578949
- 1.2641439056396484
- 1.2588227653503419
- 1.257103235721588
- 1.2588685250282288
- 1.2521997594833374
- 1.2402043151855469
- 1.2443191695213318
- 1.2361415100097657
- 1.2317332077026366
- 1.2265195989608764
- 1.2252010703086853
- 1.23299325466156
- 1.2239537572860717
- 1.2144010972976684
- 1.2089593172073365
- 1.2173229575157165
- 1.2031933522224427
- 1.2027966570854187
- 1.2080343198776244
- 1.2085017156600952
- 1.20649879693985
- 1.2045283675193788
- 1.205654354095459
- 1.2088745832443237
- 1.2091018056869507
- 1.2073258137702942
- 1.2013039898872375
- 1.1958857011795043
- 1.1996068620681763
- 1.2043124747276306
- 1.198278226852417
- 1.194159948825836
- 1.1892751288414
- 1.1851304697990417
- 1.1904851126670837
- 1.1964808750152587
- 1.2025454950332641
- 1.2041180276870727
- 1.199524908065796
- 1.1987825012207032
- 1.1914667677879334
- 1.188292508125305
- 1.1871038317680358
- 1.191306037902832
- 1.1866702699661256
- 1.1900387239456176
- 1.1968070721626283
- 1.1991493034362792
- 1.2014295196533202
- 1.1952888536453248
- 1.1994625091552735
- 1.2014732241630555
- 1.2094073176383973
- 1.2003819131851197
- 1.2009487462043762
- 1.2053706932067871
- 1.1989458107948303
- 1.2027810740470886
- 1.2080168509483338
- 1.2121502208709716
- 1.2003100657463073
- 1.1958810448646546
- 1.200885922908783
- 1.1993564081192016
- 1.1890800023078918
- 1.201602439880371
- 1.2010437965393066
- 1.2001786994934083
- 1.1910355710983276
train_accuracy:
- 0.057
- 0.111
- 0.131
- 0.132
- 0.132
- 0.166
- 0.15
- 0.195
- 0.21
- 0.214
- 0.206
- 0.2
- 0.225
- 0.201
- 0.232
- 0.202
- 0.19
- 0.222
- 0.24
- 0.21
- 0.214
- 0.238
- 0.277
- 0.258
- 0.255
- 0.218
- 0.29
- 0.197
- 0.267
- 0.295
- 0.214
- 0.265
- 0.259
- 0.279
- 0.227
- 0.295
- 0.236
- 0.29
- 0.224
- 0.302
- 0.294
- 0.242
- 0.287
- 0.311
- 0.239
- 0.0
- 0.239
- 0.259
- 0.0
- 0.315
- 0.298
- 0.293
- 0.286
- 0.318
- 0.317
- 0.303
- 0.283
- 0.258
- 0.326
- 0.33
- 0.307
- 0.269
- 0.0
- 0.33
- 0.325
- 0.268
- 0.327
- 0.267
- 0.243
- 0.0
- 0.271
- 0.339
- 0.316
- 0.302
- 0.296
- 0.263
- 0.31
- 0.293
- 0.342
- 0.351
- 0.271
- 0.358
- 0.276
- 0.257
- 0.0
- 0.326
- 0.291
- 0.0
- 0.317
- 0.331
- 0.31
- 0.268
- 0.321
- 0.278
- 0.269
- 0.0
- 0.352
- 0.359
- 0.336
- 0.34
train_loss:
- 4.291
- 3.293
- 3.614
- 3.414
- 3.286
- 2.746
- 3.11
- 2.606
- 2.928
- 2.823
- 2.402
- 2.287
- 2.573
- 2.2
- 2.176
- 2.17
- 2.374
- 1.985
- 2.304
- 2.206
- 2.197
- 1.797
- 1.879
- 1.806
- 1.973
- 1.637
- 1.665
- 1.9
- 1.76
- 1.76
- 1.521
- 1.455
- 1.685
- 1.6
- 1.606
- 1.382
- 1.351
- 1.475
- 1.245
- 1.446
- 1.246
- 1.357
- 1.294
- 1.132
- 1.109
- 1.073
- 1.165
- 1.032
- 1.053
- 1.113
- 1.092
- 0.938
- 0.936
- 0.985
- 0.995
- 0.92
- 1.001
- 0.823
- 0.828
- 0.892
- 0.845
- 0.784
- 0.764
- 0.71
- 0.694
- 0.883
- 0.756
- 0.752
- 0.731
- 0.623
- 0.669
- 0.662
- 0.649
- 0.588
- 0.617
- 0.559
- 0.591
- 0.608
- 0.557
- 0.538
- 0.537
- 0.539
- 0.483
- 0.521
- 0.508
- 0.463
- 0.471
- 0.488
- 0.5
- 0.404
- 0.446
- 0.449
- 0.435
- 0.406
- 0.402
- 0.414
- 0.365
- 0.409
- 0.397
- 0.377
unequal: 0
verbose: 1
