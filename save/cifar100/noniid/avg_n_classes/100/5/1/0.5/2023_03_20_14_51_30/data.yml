avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0485
- 0.1029
- 0.1181
- 0.1347
- 0.1513
- 0.1576
- 0.1672
- 0.1749
- 0.1866
- 0.1898
- 0.1959
- 0.2017
- 0.2087
- 0.2157
- 0.2209
- 0.223
- 0.2263
- 0.2334
- 0.2361
- 0.2375
- 0.2443
- 0.2494
- 0.2494
- 0.2494
- 0.2546
- 0.2581
- 0.2575
- 0.2654
- 0.2653
- 0.2682
- 0.2657
- 0.2702
- 0.2758
- 0.2752
- 0.2757
- 0.281
- 0.2811
- 0.2877
- 0.281
- 0.2922
- 0.2895
- 0.2917
- 0.2944
- 0.2951
- 0.2924
- 0.2921
- 0.3012
- 0.3004
- 0.3022
- 0.3026
- 0.305
- 0.3016
- 0.3052
- 0.3047
- 0.3043
- 0.3062
- 0.3108
- 0.3084
- 0.309
- 0.3101
- 0.3139
- 0.3102
- 0.3113
- 0.3113
- 0.3121
- 0.3149
- 0.3178
- 0.3187
- 0.3183
- 0.3182
- 0.3168
- 0.3178
- 0.3222
- 0.3167
- 0.3215
- 0.3237
- 0.3253
- 0.3222
- 0.3233
- 0.3224
- 0.3236
- 0.3254
- 0.3315
- 0.3287
- 0.3258
- 0.3279
- 0.322
- 0.3255
- 0.3244
- 0.3246
- 0.3275
- 0.3266
- 0.3278
- 0.3252
- 0.3299
- 0.3288
- 0.3316
- 0.3297
- 0.3301
- 0.3297
test_loss_list:
- 1.7818518352508546
- 1.6495468616485596
- 1.596020004749298
- 1.5555256223678589
- 1.5282798552513122
- 1.506213331222534
- 1.4866163659095764
- 1.459444944858551
- 1.439580864906311
- 1.4378475856781006
- 1.4269040036201477
- 1.4095588731765747
- 1.388800778388977
- 1.375136194229126
- 1.373626902103424
- 1.3659571480751038
- 1.3657053923606872
- 1.3568856978416444
- 1.3454735350608826
- 1.3320634460449219
- 1.3248316168785095
- 1.3179785227775573
- 1.3127165532112122
- 1.3031025433540344
- 1.2932134675979614
- 1.284174349308014
- 1.2799658799171447
- 1.269287543296814
- 1.2650120615959168
- 1.2680848813056946
- 1.270463123321533
- 1.2599706912040711
- 1.2551076626777649
- 1.2564331603050232
- 1.2588563990592956
- 1.2458313512802124
- 1.2386098861694337
- 1.2338083505630493
- 1.2304621267318725
- 1.2248853158950805
- 1.2333266520500183
- 1.2306541800498962
- 1.2310934448242188
- 1.2356717133522033
- 1.2289702224731445
- 1.2217640614509582
- 1.2127846956253052
- 1.2187360215187073
- 1.2197718739509582
- 1.222497591972351
- 1.2138174867630005
- 1.2074230885505677
- 1.2007610368728638
- 1.1975443029403687
- 1.1943630814552306
- 1.1917157030105592
- 1.193551046848297
- 1.2011722683906556
- 1.2030752730369567
- 1.192372863292694
- 1.1884784173965455
- 1.1925507545471192
- 1.1923279786109924
- 1.1935648608207703
- 1.1943991661071778
- 1.1945030426979064
- 1.1951713156700134
- 1.1891140389442443
- 1.183870325088501
- 1.191637098789215
- 1.1947336459159852
- 1.1983534073829651
- 1.1977026772499084
- 1.1983410477638246
- 1.188859362602234
- 1.183729693889618
- 1.1846187591552735
- 1.1827106499671936
- 1.1783692288398742
- 1.1924402976036073
- 1.1961081862449645
- 1.2008024334907532
- 1.19950706243515
- 1.1951385951042175
- 1.1850231075286866
- 1.192862548828125
- 1.1884539365768432
- 1.1832175135612488
- 1.1876712083816527
- 1.1807506942749024
- 1.1798261833190917
- 1.1848774933815003
- 1.1891428351402282
- 1.1829447960853576
- 1.1816074228286744
- 1.1766535902023316
- 1.181550714969635
- 1.1878365302085876
- 1.179840967655182
- 1.1817964482307435
train_accuracy:
- 0.061
- 0.09
- 0.0
- 0.114
- 0.138
- 0.154
- 0.176
- 0.172
- 0.148
- 0.184
- 0.225
- 0.178
- 0.179
- 0.189
- 0.265
- 0.173
- 0.176
- 0.209
- 0.191
- 0.0
- 0.228
- 0.217
- 0.0
- 0.231
- 0.21
- 0.305
- 0.227
- 0.247
- 0.245
- 0.227
- 0.225
- 0.273
- 0.267
- 0.226
- 0.28
- 0.243
- 0.256
- 0.268
- 0.0
- 0.264
- 0.259
- 0.264
- 0.342
- 0.288
- 0.337
- 0.26
- 0.341
- 0.276
- 0.296
- 0.313
- 0.286
- 0.337
- 0.298
- 0.309
- 0.326
- 0.266
- 0.309
- 0.257
- 0.317
- 0.0
- 0.327
- 0.281
- 0.304
- 0.266
- 0.301
- 0.27
- 0.32
- 0.338
- 0.0
- 0.321
- 0.281
- 0.33
- 0.338
- 0.315
- 0.0
- 0.315
- 0.322
- 0.367
- 0.375
- 0.322
- 0.333
- 0.296
- 0.336
- 0.0
- 0.0
- 0.336
- 0.334
- 0.0
- 0.337
- 0.328
- 0.319
- 0.33
- 0.341
- 0.337
- 0.301
- 0.0
- 0.323
- 0.351
- 0.359
- 0.0
train_loss:
- 4.269
- 3.813
- 3.065
- 2.943
- 3.272
- 3.192
- 2.663
- 2.6
- 2.51
- 2.79
- 2.734
- 2.323
- 2.309
- 2.242
- 2.507
- 2.451
- 2.387
- 2.34
- 1.978
- 1.951
- 2.191
- 2.157
- 1.801
- 1.752
- 1.69
- 1.717
- 1.667
- 1.598
- 1.558
- 1.815
- 1.686
- 1.442
- 1.671
- 1.452
- 1.528
- 1.407
- 1.356
- 1.251
- 1.239
- 1.479
- 1.47
- 1.3
- 1.417
- 1.236
- 1.133
- 1.107
- 1.271
- 1.162
- 1.197
- 1.105
- 0.96
- 1.014
- 0.897
- 0.899
- 0.857
- 0.859
- 0.995
- 0.87
- 0.862
- 0.898
- 0.768
- 0.731
- 0.727
- 0.826
- 0.703
- 0.74
- 0.77
- 0.704
- 0.735
- 0.718
- 0.72
- 0.676
- 0.694
- 0.618
- 0.595
- 0.633
- 0.584
- 0.585
- 0.587
- 0.546
- 0.555
- 0.528
- 0.518
- 0.489
- 0.502
- 0.499
- 0.469
- 0.474
- 0.433
- 0.443
- 0.428
- 0.386
- 0.443
- 0.401
- 0.412
- 0.388
- 0.412
- 0.4
- 0.415
- 0.402
unequal: 0
verbose: 1
