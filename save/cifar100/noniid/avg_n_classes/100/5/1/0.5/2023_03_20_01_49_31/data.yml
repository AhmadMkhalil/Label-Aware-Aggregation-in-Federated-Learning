avg_train_accuracy: 0.329
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0436
- 0.0903
- 0.111
- 0.125
- 0.146
- 0.1475
- 0.1572
- 0.1716
- 0.1821
- 0.1908
- 0.1942
- 0.1996
- 0.2041
- 0.2087
- 0.2125
- 0.2219
- 0.2288
- 0.2307
- 0.2361
- 0.2424
- 0.2427
- 0.2488
- 0.249
- 0.2538
- 0.2579
- 0.2593
- 0.2568
- 0.2606
- 0.262
- 0.2698
- 0.2693
- 0.2661
- 0.2675
- 0.2654
- 0.2746
- 0.2785
- 0.2796
- 0.2812
- 0.2789
- 0.2796
- 0.2831
- 0.2836
- 0.2819
- 0.2847
- 0.2829
- 0.2827
- 0.2828
- 0.2848
- 0.2829
- 0.293
- 0.2923
- 0.2966
- 0.2912
- 0.2929
- 0.2954
- 0.2995
- 0.2932
- 0.2974
- 0.297
- 0.3002
- 0.299
- 0.303
- 0.3106
- 0.3035
- 0.304
- 0.3052
- 0.309
- 0.3121
- 0.3049
- 0.3105
- 0.3063
- 0.3105
- 0.3098
- 0.3127
- 0.3128
- 0.3132
- 0.3146
- 0.3139
- 0.308
- 0.3162
- 0.3185
- 0.3143
- 0.3169
- 0.3165
- 0.3141
- 0.3182
- 0.319
- 0.3218
- 0.3169
- 0.3192
- 0.3209
- 0.317
- 0.3253
- 0.3214
- 0.3173
- 0.3183
- 0.3188
- 0.3175
- 0.3204
- 0.3199
test_loss_list:
- 1.794359564781189
- 1.6701269459724426
- 1.6125025057792663
- 1.5761564135551454
- 1.5448354864120484
- 1.5144930481910706
- 1.4896863627433776
- 1.4729359793663024
- 1.4588224291801453
- 1.4461135363578796
- 1.4240367531776428
- 1.4043858766555786
- 1.399434094429016
- 1.3838528275489808
- 1.371388726234436
- 1.3532380151748657
- 1.3436520648002626
- 1.3380565929412842
- 1.325638358592987
- 1.31870778799057
- 1.3143583178520202
- 1.3111152529716492
- 1.3018765997886659
- 1.3014144849777223
- 1.3030276012420654
- 1.3027486538887023
- 1.3002145767211915
- 1.2921699261665345
- 1.2799350380897523
- 1.2762856245040894
- 1.2677269387245178
- 1.2657795572280883
- 1.265093276500702
- 1.257791404724121
- 1.2458115720748901
- 1.2437467384338379
- 1.2463502502441406
- 1.2497414064407348
- 1.24327388048172
- 1.2430905842781066
- 1.2370607137680054
- 1.2289868903160095
- 1.2364603185653686
- 1.241214771270752
- 1.2348261618614196
- 1.2298249793052674
- 1.2322258710861207
- 1.2249550127983093
- 1.2195290732383728
- 1.213245120048523
- 1.2216886854171753
- 1.2131984686851502
- 1.2227667927742005
- 1.2241598105430602
- 1.2158688831329345
- 1.2115053033828735
- 1.216274676322937
- 1.2088470768928528
- 1.2033771681785583
- 1.2076831340789795
- 1.2102942895889282
- 1.1956199193000794
- 1.1977050995826721
- 1.2085382080078124
- 1.198303737640381
- 1.207132966518402
- 1.210475037097931
- 1.2092545294761659
- 1.2059151029586792
- 1.2068322539329528
- 1.2080079913139343
- 1.2110598039627076
- 1.2009934377670288
- 1.205291359424591
- 1.2122794795036316
- 1.209230399131775
- 1.2097743225097657
- 1.2191865563392639
- 1.2193296313285829
- 1.2061596655845641
- 1.211282787322998
- 1.2083644008636474
- 1.2112414646148681
- 1.2111754608154297
- 1.2082047533988953
- 1.208953206539154
- 1.210086486339569
- 1.201778063774109
- 1.197979428768158
- 1.1860187125205994
- 1.1907829642295837
- 1.1911042904853821
- 1.2013809299468994
- 1.1913612008094787
- 1.1966551780700683
- 1.1945110988616943
- 1.2003028893470764
- 1.196327018737793
- 1.2035457038879394
- 1.2056887197494506
train_accuracy:
- 0.058
- 0.065
- 0.153
- 0.142
- 0.126
- 0.0
- 0.0
- 0.17
- 0.194
- 0.153
- 0.203
- 0.209
- 0.164
- 0.0
- 0.239
- 0.191
- 0.0
- 0.195
- 0.194
- 0.248
- 0.212
- 0.229
- 0.252
- 0.218
- 0.235
- 0.209
- 0.225
- 0.219
- 0.281
- 0.255
- 0.0
- 0.303
- 0.236
- 0.254
- 0.242
- 0.0
- 0.261
- 0.262
- 0.287
- 0.266
- 0.304
- 0.0
- 0.262
- 0.266
- 0.267
- 0.301
- 0.258
- 0.315
- 0.306
- 0.271
- 0.265
- 0.315
- 0.27
- 0.313
- 0.246
- 0.304
- 0.285
- 0.0
- 0.326
- 0.299
- 0.3
- 0.0
- 0.296
- 0.29
- 0.312
- 0.337
- 0.293
- 0.356
- 0.0
- 0.304
- 0.285
- 0.337
- 0.316
- 0.347
- 0.279
- 0.283
- 0.333
- 0.306
- 0.349
- 0.311
- 0.293
- 0.348
- 0.346
- 0.337
- 0.313
- 0.309
- 0.319
- 0.307
- 0.311
- 0.314
- 0.318
- 0.316
- 0.325
- 0.323
- 0.331
- 0.278
- 0.265
- 0.348
- 0.329
- 0.329
train_loss:
- 3.662
- 3.897
- 3.105
- 3.499
- 3.391
- 2.793
- 2.732
- 3.055
- 2.976
- 2.868
- 2.453
- 2.381
- 2.637
- 2.257
- 2.182
- 2.136
- 2.08
- 2.436
- 2.034
- 1.941
- 2.236
- 2.174
- 1.857
- 2.049
- 2.04
- 1.92
- 1.973
- 1.626
- 1.612
- 1.816
- 1.57
- 1.466
- 1.406
- 1.487
- 1.406
- 1.396
- 1.528
- 1.441
- 1.316
- 1.488
- 1.227
- 1.257
- 1.27
- 1.21
- 1.086
- 1.047
- 0.988
- 1.048
- 0.999
- 1.285
- 1.164
- 1.018
- 1.053
- 1.017
- 0.884
- 1.114
- 0.872
- 0.836
- 0.802
- 0.906
- 0.741
- 0.855
- 0.867
- 0.834
- 0.838
- 0.818
- 0.742
- 0.755
- 0.704
- 0.741
- 0.613
- 0.644
- 0.686
- 0.675
- 0.597
- 0.649
- 0.606
- 0.611
- 0.566
- 0.566
- 0.558
- 0.516
- 0.54
- 0.527
- 0.51
- 0.554
- 0.505
- 0.5
- 0.466
- 0.481
- 0.445
- 0.459
- 0.441
- 0.422
- 0.417
- 0.398
- 0.367
- 0.374
- 0.357
- 0.37
unequal: 0
verbose: 1
