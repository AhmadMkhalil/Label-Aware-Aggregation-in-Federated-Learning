avg_train_accuracy: 0.263
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0428
- 0.1059
- 0.1229
- 0.1424
- 0.152
- 0.1651
- 0.1741
- 0.1845
- 0.1903
- 0.1964
- 0.2033
- 0.211
- 0.2173
- 0.2203
- 0.2253
- 0.2329
- 0.2342
- 0.2377
- 0.2427
- 0.2478
- 0.2467
- 0.2504
- 0.2534
- 0.2635
- 0.2646
- 0.2667
- 0.2673
- 0.2695
- 0.2768
- 0.2734
- 0.2774
- 0.2847
- 0.2798
- 0.2797
- 0.2829
- 0.2871
- 0.2884
- 0.2931
- 0.2969
- 0.2952
- 0.2986
- 0.3001
- 0.3034
- 0.3
- 0.3053
- 0.3056
- 0.302
- 0.3084
- 0.3083
- 0.3119
- 0.3126
- 0.3121
- 0.3122
- 0.3138
- 0.3139
- 0.3132
- 0.3121
- 0.318
- 0.3155
- 0.319
- 0.3175
- 0.32
- 0.3161
- 0.3174
- 0.32
- 0.3182
- 0.3221
- 0.3197
- 0.3241
- 0.3191
- 0.3225
- 0.3213
- 0.3205
- 0.3221
- 0.327
- 0.3244
- 0.3239
- 0.3206
- 0.3218
- 0.3248
- 0.3276
- 0.3262
- 0.3263
- 0.3271
- 0.3284
- 0.3314
- 0.3241
- 0.3286
- 0.3269
- 0.3204
- 0.3246
- 0.3248
- 0.3292
- 0.3263
- 0.3282
- 0.3282
- 0.3284
- 0.3278
- 0.3298
- 0.3318
test_loss_list:
- 1.7771295166015626
- 1.6410029101371766
- 1.5892690801620484
- 1.545185101032257
- 1.5186847734451294
- 1.4869664740562438
- 1.4659255361557006
- 1.4539163303375244
- 1.4398341536521913
- 1.4311708307266235
- 1.418080849647522
- 1.4101570630073548
- 1.4001683330535888
- 1.3850940561294556
- 1.3653158950805664
- 1.3571297526359558
- 1.3430260515213013
- 1.3308013010025024
- 1.3190575098991395
- 1.3076415681838989
- 1.2987663531303406
- 1.3000557255744933
- 1.2942116260528564
- 1.2917887473106384
- 1.2798716807365418
- 1.2788515853881837
- 1.2663148307800294
- 1.2607372975349427
- 1.2479717063903808
- 1.250341339111328
- 1.2523620796203614
- 1.2461496639251708
- 1.2404459142684936
- 1.236916527748108
- 1.2266551017761231
- 1.221106824874878
- 1.2198653864860534
- 1.2036252665519713
- 1.2119128942489623
- 1.2128063011169434
- 1.2126339745521546
- 1.2089625787734986
- 1.2034457421302795
- 1.200014865398407
- 1.2005458498001098
- 1.1999460935592652
- 1.1956813144683838
- 1.198248996734619
- 1.1888229751586914
- 1.1881331419944763
- 1.1869500613212585
- 1.1933773350715637
- 1.1888053297996521
- 1.1868280220031737
- 1.1808866930007935
- 1.1770817971229552
- 1.1747656226158143
- 1.1786495757102966
- 1.1803995013236999
- 1.184371120929718
- 1.1848923325538636
- 1.183317904472351
- 1.1823199963569642
- 1.188843297958374
- 1.1879887700080871
- 1.1902251219749451
- 1.1926216030120849
- 1.1853708791732789
- 1.1832459354400635
- 1.1861305856704711
- 1.1828772473335265
- 1.175391721725464
- 1.1760009479522706
- 1.170962121486664
- 1.1706062173843383
- 1.175845549106598
- 1.183808913230896
- 1.1911119961738585
- 1.1944055700302123
- 1.1802495646476745
- 1.1742715620994568
- 1.1857788133621217
- 1.182017195224762
- 1.1784089660644532
- 1.1792644119262696
- 1.18793781042099
- 1.1800320148468018
- 1.1773796391487121
- 1.1720905828475952
- 1.176967453956604
- 1.171397626399994
- 1.1680134963989257
- 1.1776014733314515
- 1.1707803297042847
- 1.1800329852104188
- 1.1823351716995238
- 1.189550805091858
- 1.192183198928833
- 1.192552137374878
- 1.18912273645401
train_accuracy:
- 0.0
- 0.121
- 0.137
- 0.0
- 0.134
- 0.158
- 0.17
- 0.184
- 0.159
- 0.161
- 0.166
- 0.216
- 0.21
- 0.179
- 0.229
- 0.194
- 0.0
- 0.216
- 0.199
- 0.0
- 0.0
- 0.206
- 0.225
- 0.263
- 0.239
- 0.227
- 0.217
- 0.0
- 0.298
- 0.207
- 0.301
- 0.288
- 0.0
- 0.0
- 0.0
- 0.246
- 0.236
- 0.291
- 0.213
- 0.306
- 0.297
- 0.284
- 0.308
- 0.266
- 0.383
- 0.31
- 0.265
- 0.271
- 0.275
- 0.273
- 0.247
- 0.322
- 0.252
- 0.332
- 0.295
- 0.318
- 0.325
- 0.277
- 0.254
- 0.251
- 0.404
- 0.251
- 0.0
- 0.328
- 0.314
- 0.294
- 0.294
- 0.326
- 0.34
- 0.0
- 0.281
- 0.0
- 0.398
- 0.302
- 0.287
- 0.337
- 0.302
- 0.325
- 0.409
- 0.277
- 0.309
- 0.332
- 0.338
- 0.0
- 0.316
- 0.303
- 0.334
- 0.0
- 0.0
- 0.341
- 0.303
- 0.307
- 0.311
- 0.0
- 0.301
- 0.348
- 0.269
- 0.342
- 0.3
- 0.263
train_loss:
- 3.64
- 3.827
- 3.048
- 2.944
- 2.79
- 2.77
- 2.626
- 3.01
- 2.917
- 2.85
- 2.757
- 2.68
- 2.585
- 2.199
- 2.202
- 2.472
- 2.066
- 2.015
- 1.915
- 1.951
- 1.815
- 2.07
- 1.991
- 2.004
- 1.753
- 1.894
- 1.583
- 1.557
- 1.569
- 1.67
- 1.677
- 1.681
- 1.343
- 1.342
- 1.367
- 1.586
- 1.291
- 1.396
- 1.391
- 1.377
- 1.368
- 1.211
- 1.313
- 1.086
- 1.241
- 1.238
- 1.021
- 1.113
- 1.026
- 1.134
- 0.999
- 0.977
- 0.83
- 1.015
- 0.938
- 0.853
- 0.889
- 0.901
- 0.924
- 0.828
- 0.802
- 0.827
- 0.784
- 0.795
- 0.773
- 0.749
- 0.716
- 0.677
- 0.722
- 0.628
- 0.676
- 0.609
- 0.584
- 0.565
- 0.655
- 0.552
- 0.539
- 0.513
- 0.524
- 0.559
- 0.475
- 0.533
- 0.471
- 0.509
- 0.527
- 0.435
- 0.443
- 0.501
- 0.432
- 0.436
- 0.407
- 0.41
- 0.404
- 0.412
- 0.368
- 0.378
- 0.373
- 0.371
- 0.375
- 0.394
unequal: 0
verbose: 1
