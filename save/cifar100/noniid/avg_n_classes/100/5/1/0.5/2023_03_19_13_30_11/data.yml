avg_train_accuracy: 0.343
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0447
- 0.0978
- 0.1138
- 0.1371
- 0.15
- 0.159
- 0.1616
- 0.1798
- 0.1804
- 0.1883
- 0.191
- 0.2009
- 0.205
- 0.2137
- 0.2123
- 0.2225
- 0.2228
- 0.2264
- 0.2287
- 0.2346
- 0.2386
- 0.2369
- 0.2429
- 0.2508
- 0.2506
- 0.2548
- 0.2499
- 0.2594
- 0.2605
- 0.2645
- 0.2651
- 0.2688
- 0.2708
- 0.2681
- 0.2764
- 0.2762
- 0.28
- 0.2815
- 0.28
- 0.278
- 0.285
- 0.2833
- 0.2844
- 0.2868
- 0.2912
- 0.2884
- 0.2907
- 0.293
- 0.2922
- 0.2949
- 0.2961
- 0.2953
- 0.2935
- 0.2933
- 0.2954
- 0.2938
- 0.3027
- 0.3024
- 0.3027
- 0.305
- 0.305
- 0.3044
- 0.3056
- 0.308
- 0.3026
- 0.3041
- 0.3064
- 0.3091
- 0.3066
- 0.309
- 0.314
- 0.3136
- 0.3139
- 0.3127
- 0.3119
- 0.3084
- 0.3151
- 0.3162
- 0.3162
- 0.3142
- 0.3138
- 0.3139
- 0.311
- 0.3177
- 0.3198
- 0.315
- 0.32
- 0.3217
- 0.3196
- 0.3171
- 0.3214
- 0.3216
- 0.3199
- 0.3216
- 0.3204
- 0.3208
- 0.3212
- 0.3177
- 0.3216
- 0.3225
test_loss_list:
- 1.784108543395996
- 1.6514217901229857
- 1.604152913093567
- 1.5600216031074523
- 1.5366742849349975
- 1.5183372354507447
- 1.5016996550559998
- 1.4756610870361329
- 1.4720166325569153
- 1.4492068672180176
- 1.4276910829544067
- 1.420458767414093
- 1.413220262527466
- 1.4015260672569274
- 1.3979113030433654
- 1.3871472072601319
- 1.3737198662757875
- 1.3601341867446899
- 1.3477729058265686
- 1.3358829355239867
- 1.3350899457931518
- 1.3281012177467346
- 1.3120175790786743
- 1.3106269001960755
- 1.3035568380355835
- 1.3041336393356324
- 1.297679352760315
- 1.2911172652244567
- 1.290965337753296
- 1.2855781936645507
- 1.277426540851593
- 1.2636847043037414
- 1.2605119228363038
- 1.264134726524353
- 1.2593110299110413
- 1.2605376648902893
- 1.2530125617980956
- 1.2559906697273255
- 1.2550458097457886
- 1.253315896987915
- 1.2430479550361633
- 1.2367952346801758
- 1.2359405088424682
- 1.2284375715255738
- 1.232230725288391
- 1.2327819895744323
- 1.2338949704170228
- 1.2371678233146668
- 1.2243247938156128
- 1.2303943514823914
- 1.2311764764785766
- 1.2209179210662842
- 1.2182022047042846
- 1.2082061004638671
- 1.2013146519660949
- 1.2045823383331298
- 1.2039060759544373
- 1.2096166706085205
- 1.202968909740448
- 1.1983527421951294
- 1.2037882709503174
- 1.2049054265022279
- 1.2071045923233032
- 1.2087225341796874
- 1.2151823163032531
- 1.206422221660614
- 1.2013003277778624
- 1.2007238960266113
- 1.1950679397583008
- 1.1960222125053406
- 1.193401165008545
- 1.1864477562904359
- 1.1944464063644409
- 1.1914831042289733
- 1.1940280246734618
- 1.1918064045906067
- 1.187955105304718
- 1.192247576713562
- 1.1881133723258972
- 1.1858495545387269
- 1.1817560696601868
- 1.1876199126243592
- 1.180981662273407
- 1.1773753786087036
- 1.187356767654419
- 1.190653076171875
- 1.1952063345909119
- 1.1964656472206117
- 1.1907913875579834
- 1.1955714464187621
- 1.1853341674804687
- 1.1836084127426147
- 1.1939908790588378
- 1.1829901552200317
- 1.1989954543113708
- 1.1917628169059753
- 1.1953982138633727
- 1.193691086769104
- 1.1938001227378845
- 1.1867293095588685
train_accuracy:
- 0.0
- 0.106
- 0.099
- 0.144
- 0.163
- 0.13
- 0.136
- 0.244
- 0.154
- 0.0
- 0.223
- 0.221
- 0.235
- 0.21
- 0.184
- 0.228
- 0.245
- 0.279
- 0.207
- 0.195
- 0.203
- 0.0
- 0.237
- 0.261
- 0.301
- 0.252
- 0.236
- 0.237
- 0.249
- 0.255
- 0.0
- 0.267
- 0.249
- 0.286
- 0.284
- 0.301
- 0.225
- 0.291
- 0.251
- 0.299
- 0.227
- 0.286
- 0.263
- 0.25
- 0.294
- 0.3
- 0.302
- 0.316
- 0.0
- 0.305
- 0.348
- 0.31
- 0.0
- 0.277
- 0.316
- 0.334
- 0.245
- 0.312
- 0.36
- 0.322
- 0.328
- 0.336
- 0.325
- 0.332
- 0.32
- 0.0
- 0.32
- 0.334
- 0.321
- 0.35
- 0.316
- 0.319
- 0.334
- 0.317
- 0.313
- 0.0
- 0.0
- 0.334
- 0.294
- 0.337
- 0.367
- 0.324
- 0.336
- 0.276
- 0.35
- 0.334
- 0.358
- 0.337
- 0.315
- 0.0
- 0.361
- 0.322
- 0.336
- 0.334
- 0.333
- 0.334
- 0.345
- 0.329
- 0.332
- 0.343
train_loss:
- 3.638
- 3.868
- 3.077
- 3.443
- 3.324
- 3.141
- 2.635
- 2.99
- 2.891
- 2.427
- 2.456
- 2.712
- 2.672
- 2.57
- 2.493
- 2.445
- 2.096
- 2.056
- 1.971
- 1.926
- 2.187
- 1.769
- 1.829
- 2.042
- 1.674
- 1.94
- 1.663
- 1.849
- 1.832
- 1.57
- 1.623
- 1.499
- 1.436
- 1.593
- 1.641
- 1.508
- 1.321
- 1.414
- 1.427
- 1.236
- 1.172
- 1.203
- 1.419
- 1.165
- 1.218
- 1.188
- 1.192
- 1.148
- 1.078
- 1.13
- 1.078
- 0.943
- 0.927
- 0.939
- 0.897
- 0.899
- 0.929
- 0.941
- 0.862
- 0.835
- 0.869
- 0.83
- 0.856
- 0.772
- 0.751
- 0.695
- 0.718
- 0.72
- 0.628
- 0.623
- 0.689
- 0.625
- 0.647
- 0.634
- 0.608
- 0.558
- 0.554
- 0.592
- 0.567
- 0.498
- 0.521
- 0.501
- 0.506
- 0.469
- 0.493
- 0.46
- 0.518
- 0.432
- 0.47
- 0.437
- 0.462
- 0.402
- 0.395
- 0.375
- 0.362
- 0.381
- 0.389
- 0.376
- 0.362
- 0.395
unequal: 0
verbose: 1
