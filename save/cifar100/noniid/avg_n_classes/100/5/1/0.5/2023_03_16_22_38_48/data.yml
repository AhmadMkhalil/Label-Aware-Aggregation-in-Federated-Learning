avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0871
- 0.1078
- 0.1287
- 0.1485
- 0.1563
- 0.1689
- 0.1826
- 0.188
- 0.1939
- 0.1989
- 0.2058
- 0.2083
- 0.2166
- 0.2181
- 0.2234
- 0.2321
- 0.2313
- 0.235
- 0.2384
- 0.242
- 0.2474
- 0.2513
- 0.2553
- 0.2587
- 0.2545
- 0.2611
- 0.263
- 0.2671
- 0.2658
- 0.262
- 0.2672
- 0.2716
- 0.274
- 0.2756
- 0.2772
- 0.2789
- 0.2802
- 0.2879
- 0.2878
- 0.2876
- 0.2913
- 0.2935
- 0.2931
- 0.2929
- 0.2916
- 0.2944
- 0.2991
- 0.2957
- 0.2962
- 0.2962
- 0.2951
- 0.3045
- 0.3037
- 0.3054
- 0.3026
- 0.3042
- 0.3024
- 0.309
- 0.3081
- 0.3051
- 0.3115
- 0.3117
- 0.3111
- 0.313
- 0.313
- 0.3136
- 0.3146
- 0.3141
- 0.311
- 0.3128
- 0.3165
- 0.3182
- 0.3163
- 0.3169
- 0.3187
- 0.3189
- 0.32
- 0.3213
- 0.3214
- 0.3201
- 0.3204
- 0.317
- 0.3197
- 0.3242
- 0.3231
- 0.3195
- 0.321
- 0.3227
- 0.3225
- 0.3212
- 0.3177
- 0.3273
- 0.328
- 0.3275
- 0.3289
- 0.3217
- 0.3286
- 0.3225
- 0.3262
test_loss_list:
- 1.7962671852111816
- 1.675062084197998
- 1.621427798271179
- 1.5827141785621643
- 1.5508132362365723
- 1.5252424240112306
- 1.4968091130256653
- 1.4803252148628234
- 1.4644278621673583
- 1.4410106110572816
- 1.4280825448036194
- 1.4069201779365539
- 1.3942674446105956
- 1.3808990216255188
- 1.3748363542556763
- 1.3639352655410766
- 1.3579363918304443
- 1.3493571257591248
- 1.3355698323249816
- 1.3228786993026733
- 1.3223132753372193
- 1.3165668058395386
- 1.3103079867362977
- 1.3002828216552735
- 1.300994930267334
- 1.2968282556533814
- 1.286588430404663
- 1.2759698581695558
- 1.2756349968910217
- 1.2769503426551818
- 1.2806373691558839
- 1.2692160606384277
- 1.2637693643569947
- 1.2666790199279785
- 1.2555764627456665
- 1.260270164012909
- 1.2526666402816773
- 1.2435120415687562
- 1.241634509563446
- 1.2411644625663758
- 1.2341567754745484
- 1.2191636919975282
- 1.2199524998664857
- 1.2085459876060485
- 1.216446304321289
- 1.2108241200447083
- 1.2022491002082825
- 1.2026343822479248
- 1.2060866498947143
- 1.2017245888710022
- 1.1939604687690735
- 1.1963326478004455
- 1.2017025113105775
- 1.2044826674461364
- 1.197212827205658
- 1.19254980802536
- 1.1888571429252623
- 1.196450912952423
- 1.19503075838089
- 1.2001242113113404
- 1.1961489582061768
- 1.1885838651657104
- 1.1806932711601257
- 1.1802200436592103
- 1.1778152704238891
- 1.1778118419647217
- 1.1866430282592773
- 1.189263105392456
- 1.1862151789665223
- 1.1875415706634522
- 1.1890767431259155
- 1.191186900138855
- 1.189826147556305
- 1.1904536437988282
- 1.1976963186264038
- 1.1956338095664978
- 1.1969847667217255
- 1.2038901615142823
- 1.1936241674423218
- 1.1982110929489136
- 1.2002466201782227
- 1.2030903935432433
- 1.2000339531898498
- 1.1906710481643676
- 1.1965634632110596
- 1.197383668422699
- 1.191208689212799
- 1.2011941051483155
- 1.1947242856025695
- 1.1879984331130982
- 1.1889082598686218
- 1.190189323425293
- 1.1751214098930358
- 1.189007887840271
- 1.1921107792854309
- 1.187356514930725
- 1.2066763830184937
- 1.2044764566421509
- 1.199432373046875
- 1.1869456553459168
train_accuracy:
- 0.042
- 0.077
- 0.098
- 0.124
- 0.138
- 0.145
- 0.178
- 0.186
- 0.172
- 0.195
- 0.201
- 0.0
- 0.201
- 0.204
- 0.176
- 0.0
- 0.235
- 0.199
- 0.225
- 0.0
- 0.223
- 0.249
- 0.0
- 0.24
- 0.224
- 0.225
- 0.239
- 0.303
- 0.257
- 0.228
- 0.265
- 0.279
- 0.267
- 0.282
- 0.305
- 0.263
- 0.31
- 0.283
- 0.284
- 0.263
- 0.301
- 0.0
- 0.0
- 0.281
- 0.335
- 0.0
- 0.277
- 0.26
- 0.292
- 0.31
- 0.0
- 0.0
- 0.306
- 0.329
- 0.349
- 0.319
- 0.0
- 0.361
- 0.339
- 0.337
- 0.298
- 0.341
- 0.264
- 0.324
- 0.0
- 0.31
- 0.332
- 0.322
- 0.326
- 0.249
- 0.299
- 0.291
- 0.329
- 0.378
- 0.341
- 0.316
- 0.326
- 0.292
- 0.302
- 0.356
- 0.339
- 0.353
- 0.34
- 0.269
- 0.336
- 0.289
- 0.316
- 0.279
- 0.272
- 0.0
- 0.279
- 0.317
- 0.365
- 0.265
- 0.34
- 0.323
- 0.325
- 0.355
- 0.319
- 0.0
train_loss:
- 4.312
- 3.324
- 3.644
- 3.463
- 3.312
- 3.191
- 2.699
- 3.035
- 2.931
- 2.477
- 2.363
- 2.329
- 2.213
- 2.224
- 2.44
- 2.091
- 2.364
- 1.949
- 1.964
- 1.879
- 2.153
- 2.165
- 1.785
- 2.01
- 1.965
- 1.975
- 1.667
- 1.658
- 1.744
- 1.685
- 1.632
- 1.483
- 1.537
- 1.58
- 1.393
- 1.5
- 1.416
- 1.287
- 1.422
- 1.359
- 1.205
- 1.265
- 1.146
- 1.081
- 1.103
- 1.117
- 1.059
- 1.046
- 1.115
- 1.025
- 0.929
- 0.91
- 1.09
- 0.982
- 0.892
- 0.859
- 0.813
- 0.896
- 0.901
- 0.864
- 0.709
- 0.769
- 0.788
- 0.729
- 0.747
- 0.674
- 0.736
- 0.73
- 0.594
- 0.607
- 0.654
- 0.657
- 0.647
- 0.68
- 0.585
- 0.629
- 0.54
- 0.556
- 0.538
- 0.539
- 0.57
- 0.505
- 0.501
- 0.499
- 0.484
- 0.449
- 0.457
- 0.453
- 0.442
- 0.411
- 0.408
- 0.39
- 0.465
- 0.409
- 0.404
- 0.384
- 0.371
- 0.384
- 0.379
- 0.357
unequal: 0
verbose: 1
