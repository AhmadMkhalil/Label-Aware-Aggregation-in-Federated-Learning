avg_train_accuracy: 0.334
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0393
- 0.0954
- 0.1175
- 0.1317
- 0.1478
- 0.1602
- 0.1709
- 0.1815
- 0.1907
- 0.1945
- 0.2019
- 0.2091
- 0.2187
- 0.224
- 0.2266
- 0.2328
- 0.2347
- 0.2422
- 0.2437
- 0.2485
- 0.251
- 0.2539
- 0.2571
- 0.2603
- 0.2639
- 0.2675
- 0.2713
- 0.2715
- 0.2712
- 0.2771
- 0.2772
- 0.282
- 0.2825
- 0.2833
- 0.2878
- 0.2907
- 0.2924
- 0.2917
- 0.2935
- 0.2936
- 0.2995
- 0.2981
- 0.3001
- 0.3014
- 0.3012
- 0.3045
- 0.3038
- 0.3033
- 0.3106
- 0.3111
- 0.3121
- 0.31
- 0.3118
- 0.3121
- 0.3102
- 0.3151
- 0.3128
- 0.3169
- 0.3159
- 0.3143
- 0.3189
- 0.3188
- 0.3197
- 0.3179
- 0.3235
- 0.32
- 0.3179
- 0.3237
- 0.3215
- 0.3267
- 0.3261
- 0.3261
- 0.3274
- 0.3273
- 0.3281
- 0.3315
- 0.3268
- 0.3313
- 0.3251
- 0.3297
- 0.3303
- 0.33
- 0.3352
- 0.3308
- 0.3325
- 0.3329
- 0.3314
- 0.3342
- 0.3363
- 0.334
- 0.3383
- 0.3371
- 0.3368
- 0.3333
- 0.3349
- 0.3381
- 0.3356
- 0.3375
- 0.3369
- 0.3395
test_loss_list:
- 1.7930342769622802
- 1.662927496433258
- 1.611374125480652
- 1.5628439569473267
- 1.5332008767127991
- 1.5025399780273438
- 1.4835883355140687
- 1.4572640419006349
- 1.4431069588661194
- 1.4233895802497865
- 1.4136550879478456
- 1.3941169357299805
- 1.3790153169631958
- 1.3627271890640258
- 1.3478626370429994
- 1.3447993969917298
- 1.331970100402832
- 1.3294076895713807
- 1.3247921109199523
- 1.3128401017189026
- 1.311469087600708
- 1.2987517380714417
- 1.2977912664413451
- 1.2946315813064575
- 1.2930446600914
- 1.2773790764808655
- 1.278017795085907
- 1.2753010988235474
- 1.2632643795013427
- 1.2615575218200683
- 1.2522062039375306
- 1.241899960041046
- 1.232678987979889
- 1.227998478412628
- 1.224913547039032
- 1.212929606437683
- 1.2200037956237793
- 1.2129025053977966
- 1.2065318393707276
- 1.203822193145752
- 1.1983442091941834
- 1.2015307426452637
- 1.1964252471923829
- 1.1891727757453918
- 1.1985590744018555
- 1.1975525617599487
- 1.1911539602279664
- 1.1977752614021302
- 1.1849002957344055
- 1.1795058751106262
- 1.1743861317634583
- 1.184858012199402
- 1.1781340718269349
- 1.1753626227378846
- 1.172568335533142
- 1.1700052952766418
- 1.1767477822303771
- 1.1786865139007567
- 1.1762347793579102
- 1.1745706868171693
- 1.1762328886985778
- 1.1673266530036925
- 1.164382085800171
- 1.1670756435394287
- 1.1573757743835449
- 1.1603854298591614
- 1.1646171808242798
- 1.1578357982635499
- 1.160032982826233
- 1.1688452458381653
- 1.158351607322693
- 1.1660018658638
- 1.1698714995384216
- 1.1736212968826294
- 1.179402687549591
- 1.1776535677909852
- 1.1708841252326965
- 1.177950267791748
- 1.1778843212127685
- 1.1632387447357178
- 1.1568587493896485
- 1.15804988861084
- 1.1545997643470765
- 1.1674751901626588
- 1.17152508020401
- 1.1683940029144286
- 1.1690977334976196
- 1.1620159530639649
- 1.1594679498672484
- 1.159222869873047
- 1.154986391067505
- 1.1652455019950867
- 1.1609315085411072
- 1.1597485899925233
- 1.1555647349357605
- 1.1582461619377136
- 1.1675214195251464
- 1.1620629572868346
- 1.172499806880951
- 1.1716792106628418
train_accuracy:
- 0.038
- 0.093
- 0.1
- 0.129
- 0.166
- 0.148
- 0.182
- 0.216
- 0.199
- 0.224
- 0.21
- 0.179
- 0.195
- 0.0
- 0.203
- 0.226
- 0.0
- 0.237
- 0.237
- 0.203
- 0.217
- 0.222
- 0.266
- 0.268
- 0.227
- 0.297
- 0.276
- 0.266
- 0.0
- 0.242
- 0.279
- 0.276
- 0.263
- 0.286
- 0.0
- 0.273
- 0.289
- 0.302
- 0.27
- 0.31
- 0.299
- 0.269
- 0.0
- 0.314
- 0.293
- 0.314
- 0.311
- 0.315
- 0.316
- 0.335
- 0.0
- 0.336
- 0.0
- 0.333
- 0.296
- 0.336
- 0.324
- 0.305
- 0.348
- 0.306
- 0.31
- 0.359
- 0.307
- 0.361
- 0.336
- 0.322
- 0.298
- 0.326
- 0.319
- 0.316
- 0.349
- 0.325
- 0.34
- 0.328
- 0.343
- 0.308
- 0.318
- 0.345
- 0.322
- 0.0
- 0.318
- 0.372
- 0.338
- 0.333
- 0.338
- 0.347
- 0.35
- 0.377
- 0.326
- 0.337
- 0.309
- 0.324
- 0.34
- 0.334
- 0.373
- 0.332
- 0.346
- 0.386
- 0.356
- 0.334
train_loss:
- 3.839
- 3.457
- 3.661
- 3.124
- 3.329
- 2.894
- 3.11
- 2.726
- 2.937
- 2.577
- 2.775
- 2.441
- 2.379
- 2.309
- 2.251
- 2.456
- 2.135
- 2.299
- 2.274
- 2.039
- 2.176
- 1.966
- 2.107
- 2.022
- 1.973
- 1.777
- 1.926
- 1.87
- 1.672
- 1.791
- 1.598
- 1.532
- 1.522
- 1.49
- 1.418
- 1.464
- 1.512
- 1.349
- 1.302
- 1.304
- 1.266
- 1.337
- 1.227
- 1.173
- 1.223
- 1.234
- 1.094
- 1.153
- 1.051
- 1.034
- 1.02
- 1.045
- 0.942
- 0.939
- 0.879
- 0.926
- 0.94
- 0.917
- 0.858
- 0.831
- 0.857
- 0.77
- 0.81
- 0.739
- 0.758
- 0.719
- 0.697
- 0.67
- 0.67
- 0.685
- 0.656
- 0.694
- 0.652
- 0.654
- 0.616
- 0.602
- 0.578
- 0.556
- 0.564
- 0.555
- 0.537
- 0.504
- 0.497
- 0.514
- 0.497
- 0.467
- 0.485
- 0.446
- 0.437
- 0.451
- 0.431
- 0.425
- 0.42
- 0.403
- 0.39
- 0.39
- 0.384
- 0.368
- 0.369
- 0.354
unequal: 0
verbose: 1
