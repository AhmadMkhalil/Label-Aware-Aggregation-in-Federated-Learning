avg_train_accuracy: 0.326
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0476
- 0.1012
- 0.1183
- 0.1332
- 0.1446
- 0.1611
- 0.171
- 0.1837
- 0.1904
- 0.1942
- 0.1995
- 0.2077
- 0.2089
- 0.2164
- 0.2171
- 0.2271
- 0.2316
- 0.2346
- 0.2367
- 0.2412
- 0.2406
- 0.2438
- 0.25
- 0.2554
- 0.2555
- 0.2633
- 0.2612
- 0.2676
- 0.2684
- 0.2671
- 0.2699
- 0.2726
- 0.2745
- 0.2784
- 0.2801
- 0.2793
- 0.2828
- 0.2872
- 0.2879
- 0.2921
- 0.2893
- 0.2872
- 0.2934
- 0.2944
- 0.2983
- 0.2957
- 0.2967
- 0.2975
- 0.2992
- 0.3005
- 0.2964
- 0.3018
- 0.3063
- 0.3051
- 0.3067
- 0.3072
- 0.3084
- 0.3117
- 0.3092
- 0.3105
- 0.311
- 0.3131
- 0.3117
- 0.3128
- 0.3138
- 0.3173
- 0.318
- 0.3187
- 0.3164
- 0.3182
- 0.3166
- 0.3204
- 0.315
- 0.3191
- 0.3183
- 0.3218
- 0.3206
- 0.3191
- 0.3212
- 0.3191
- 0.3227
- 0.3235
- 0.3218
- 0.3242
- 0.3251
- 0.3233
- 0.3248
- 0.3197
- 0.3258
- 0.3225
- 0.3277
- 0.3274
- 0.3235
- 0.3222
- 0.3255
- 0.3278
- 0.3258
- 0.3247
- 0.3269
- 0.3312
test_loss_list:
- 1.7857736444473267
- 1.6488713002204896
- 1.588817744255066
- 1.5503859782218934
- 1.5179098463058471
- 1.491687970161438
- 1.4668083024024963
- 1.449580409526825
- 1.4319836282730103
- 1.4153655695915222
- 1.4030145263671876
- 1.3825119805336
- 1.3714287781715393
- 1.3592716336250306
- 1.3503831934928894
- 1.3367585730552674
- 1.333820333480835
- 1.335065531730652
- 1.3179944777488708
- 1.3095101380348206
- 1.301489109992981
- 1.292462170124054
- 1.2831810188293458
- 1.2837367033958436
- 1.2757505440711976
- 1.2749544620513915
- 1.2675919079780578
- 1.2625227522850038
- 1.2546313309669495
- 1.2475411772727967
- 1.247413170337677
- 1.236554844379425
- 1.241608180999756
- 1.2347088932991028
- 1.2230058741569518
- 1.2168633580207824
- 1.2230849862098694
- 1.2186156797409058
- 1.2090580534934998
- 1.2028127384185792
- 1.208540699481964
- 1.2035929155349732
- 1.2047761631011964
- 1.2109737277030945
- 1.1993029022216797
- 1.1958409023284913
- 1.1978253364562987
- 1.2033494377136231
- 1.1958135986328124
- 1.1959974002838134
- 1.1940020108222962
- 1.1874994397163392
- 1.1922617030143738
- 1.1844519329071046
- 1.1839967465400696
- 1.1768385505676269
- 1.1736742496490478
- 1.172019956111908
- 1.178828067779541
- 1.1755394840240478
- 1.1705144953727722
- 1.1701684522628784
- 1.1701440501213074
- 1.1665223026275635
- 1.1781608605384826
- 1.1770244002342225
- 1.1793311834335327
- 1.1747497701644898
- 1.1813264894485473
- 1.171856780052185
- 1.1811720323562622
- 1.1815788531303406
- 1.1726233339309693
- 1.1799017000198364
- 1.1865249013900756
- 1.178418095111847
- 1.1807518029212951
- 1.1770413613319397
- 1.1741265344619751
- 1.1712240624427794
- 1.1672916388511658
- 1.174711093902588
- 1.1669036364555359
- 1.1642660188674927
- 1.1715808725357055
- 1.1684581065177917
- 1.169265170097351
- 1.175064582824707
- 1.1647359943389892
- 1.1804435873031616
- 1.1704387164115906
- 1.1741245794296264
- 1.1712330079078674
- 1.179482171535492
- 1.1728145813941955
- 1.1713905668258666
- 1.1689761447906495
- 1.1687088322639465
- 1.1761977505683898
- 1.177527859210968
train_accuracy:
- 0.054
- 0.108
- 0.132
- 0.105
- 0.166
- 0.16
- 0.15
- 0.21
- 0.185
- 0.194
- 0.16
- 0.225
- 0.161
- 0.199
- 0.228
- 0.227
- 0.239
- 0.216
- 0.205
- 0.223
- 0.255
- 0.206
- 0.208
- 0.248
- 0.253
- 0.227
- 0.0
- 0.238
- 0.263
- 0.24
- 0.241
- 0.275
- 0.279
- 0.274
- 0.0
- 0.259
- 0.296
- 0.266
- 0.0
- 0.287
- 0.296
- 0.294
- 0.308
- 0.299
- 0.269
- 0.276
- 0.314
- 0.286
- 0.273
- 0.31
- 0.287
- 0.293
- 0.273
- 0.289
- 0.302
- 0.0
- 0.0
- 0.302
- 0.306
- 0.0
- 0.291
- 0.299
- 0.336
- 0.0
- 0.31
- 0.28
- 0.327
- 0.312
- 0.315
- 0.325
- 0.305
- 0.315
- 0.316
- 0.287
- 0.287
- 0.0
- 0.313
- 0.323
- 0.308
- 0.31
- 0.328
- 0.313
- 0.325
- 0.32
- 0.326
- 0.347
- 0.305
- 0.31
- 0.312
- 0.335
- 0.318
- 0.34
- 0.327
- 0.322
- 0.293
- 0.336
- 0.323
- 0.317
- 0.328
- 0.326
train_loss:
- 4.314
- 3.428
- 3.223
- 3.42
- 2.935
- 3.166
- 2.741
- 2.969
- 2.593
- 2.512
- 2.434
- 2.405
- 2.337
- 2.304
- 2.219
- 2.181
- 2.379
- 2.3
- 2.088
- 2.005
- 1.965
- 1.892
- 1.859
- 2.039
- 1.783
- 1.921
- 1.686
- 1.838
- 1.629
- 1.555
- 1.716
- 1.528
- 1.631
- 1.439
- 1.437
- 1.406
- 1.492
- 1.32
- 1.294
- 1.282
- 1.326
- 1.197
- 1.303
- 1.249
- 1.127
- 1.093
- 1.166
- 1.116
- 1.002
- 1.072
- 0.967
- 0.949
- 0.977
- 0.939
- 0.9
- 0.929
- 0.861
- 0.845
- 0.878
- 0.8
- 0.798
- 0.763
- 0.746
- 0.725
- 0.783
- 0.748
- 0.726
- 0.672
- 0.682
- 0.638
- 0.676
- 0.639
- 0.6
- 0.615
- 0.618
- 0.569
- 0.559
- 0.535
- 0.528
- 0.5
- 0.503
- 0.528
- 0.479
- 0.488
- 0.486
- 0.463
- 0.455
- 0.437
- 0.449
- 0.44
- 0.406
- 0.421
- 0.404
- 0.39
- 0.402
- 0.386
- 0.377
- 0.35
- 0.353
- 0.357
unequal: 0
verbose: 1
