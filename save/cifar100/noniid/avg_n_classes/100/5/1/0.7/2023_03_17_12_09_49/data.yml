avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0457
- 0.0932
- 0.1155
- 0.1354
- 0.1509
- 0.1663
- 0.1762
- 0.1858
- 0.1928
- 0.2
- 0.208
- 0.2163
- 0.2194
- 0.2264
- 0.2335
- 0.2326
- 0.2384
- 0.2454
- 0.245
- 0.2503
- 0.2571
- 0.2563
- 0.2573
- 0.2621
- 0.266
- 0.267
- 0.2719
- 0.2762
- 0.2758
- 0.2773
- 0.2813
- 0.2819
- 0.2867
- 0.2846
- 0.2859
- 0.2915
- 0.2928
- 0.2913
- 0.2969
- 0.2966
- 0.2995
- 0.301
- 0.3029
- 0.3068
- 0.3029
- 0.3087
- 0.308
- 0.3112
- 0.3133
- 0.3125
- 0.3155
- 0.3125
- 0.3148
- 0.3171
- 0.315
- 0.3188
- 0.3172
- 0.3207
- 0.3233
- 0.3197
- 0.3217
- 0.3226
- 0.3227
- 0.3216
- 0.3227
- 0.3255
- 0.325
- 0.324
- 0.3293
- 0.3271
- 0.3301
- 0.3279
- 0.3308
- 0.3298
- 0.3308
- 0.3318
- 0.3296
- 0.3313
- 0.3318
- 0.3305
- 0.3323
- 0.3323
- 0.3289
- 0.333
- 0.3305
- 0.3362
- 0.334
- 0.3333
- 0.337
- 0.3347
- 0.3336
- 0.3364
- 0.3369
- 0.3334
- 0.3381
- 0.3382
- 0.3398
- 0.3393
- 0.3366
- 0.3379
test_loss_list:
- 1.7937654542922974
- 1.664246644973755
- 1.6064427423477172
- 1.5571079206466676
- 1.5208575987815858
- 1.4991008424758911
- 1.4776550602912903
- 1.45596040725708
- 1.4313257098197938
- 1.4212358355522157
- 1.4031665587425233
- 1.3829267621040344
- 1.3800059628486634
- 1.3723908853530884
- 1.3499920439720154
- 1.350158531665802
- 1.3464685654640198
- 1.3389621353149415
- 1.3254701900482178
- 1.3179630327224732
- 1.313951141834259
- 1.3110995364189149
- 1.2994311141967774
- 1.2963578605651855
- 1.2833537149429322
- 1.2734784245491029
- 1.2633632016181946
- 1.2653064727783203
- 1.25126238822937
- 1.244970636367798
- 1.237615134716034
- 1.2439131355285644
- 1.2341142082214356
- 1.2298096561431884
- 1.2230377507209778
- 1.2148874258995057
- 1.2096328711509705
- 1.2064740300178527
- 1.201750316619873
- 1.1956163001060487
- 1.1966318917274474
- 1.2006384921073914
- 1.1928648924827576
- 1.1867345213890075
- 1.200534451007843
- 1.1949551820755004
- 1.1858478593826294
- 1.181442720890045
- 1.177458782196045
- 1.18173654794693
- 1.183826243877411
- 1.1768980407714844
- 1.171306118965149
- 1.1674722838401794
- 1.1692032170295716
- 1.174181454181671
- 1.1653250193595885
- 1.165167853832245
- 1.1579664373397827
- 1.1700337147712707
- 1.1618172311782837
- 1.1554467678070068
- 1.1671128749847413
- 1.160393431186676
- 1.1606315183639526
- 1.1550200963020325
- 1.1536976647377015
- 1.164053373336792
- 1.166101050376892
- 1.1693393230438232
- 1.1593151903152465
- 1.1546609044075011
- 1.1533189082145692
- 1.1533116340637206
- 1.1458643388748169
- 1.1481736516952514
- 1.1450960564613342
- 1.1504770398139954
- 1.1607620334625244
- 1.1654160511493683
- 1.1561039185523987
- 1.1569726252555848
- 1.1583728837966918
- 1.160320954322815
- 1.1558208227157594
- 1.148248528242111
- 1.152889714241028
- 1.151528356075287
- 1.1482653641700744
- 1.1478019535541535
- 1.1519802570343018
- 1.1634150338172913
- 1.1526878106594085
- 1.1520029067993165
- 1.149305648803711
- 1.1495799684524537
- 1.1510379362106322
- 1.1617799949645997
- 1.1582151937484741
- 1.1538381683826446
train_accuracy:
- 0.0
- 0.077
- 0.165
- 0.18
- 0.0
- 0.187
- 0.183
- 0.201
- 0.217
- 0.205
- 0.223
- 0.172
- 0.24
- 0.255
- 0.236
- 0.271
- 0.241
- 0.239
- 0.266
- 0.263
- 0.202
- 0.24
- 0.283
- 0.272
- 0.268
- 0.275
- 0.298
- 0.235
- 0.269
- 0.281
- 0.304
- 0.308
- 0.25
- 0.304
- 0.327
- 0.301
- 0.285
- 0.311
- 0.311
- 0.325
- 0.338
- 0.319
- 0.327
- 0.324
- 0.301
- 0.325
- 0.322
- 0.3
- 0.335
- 0.33
- 0.281
- 0.34
- 0.318
- 0.0
- 0.0
- 0.312
- 0.0
- 0.336
- 0.344
- 0.333
- 0.311
- 0.0
- 0.319
- 0.368
- 0.298
- 0.331
- 0.356
- 0.353
- 0.336
- 0.329
- 0.345
- 0.357
- 0.333
- 0.299
- 0.294
- 0.34
- 0.328
- 0.347
- 0.326
- 0.365
- 0.361
- 0.323
- 0.0
- 0.371
- 0.346
- 0.354
- 0.386
- 0.361
- 0.368
- 0.335
- 0.354
- 0.347
- 0.361
- 0.377
- 0.326
- 0.359
- 0.336
- 0.351
- 0.298
- 0.0
train_loss:
- 3.862
- 3.883
- 3.261
- 3.135
- 2.992
- 3.205
- 3.122
- 2.709
- 2.646
- 2.839
- 2.477
- 2.433
- 2.615
- 2.559
- 2.277
- 2.41
- 2.337
- 2.301
- 2.066
- 2.203
- 2.157
- 2.089
- 1.859
- 2.006
- 1.76
- 1.745
- 1.713
- 1.868
- 1.629
- 1.595
- 1.555
- 1.671
- 1.489
- 1.497
- 1.443
- 1.394
- 1.332
- 1.334
- 1.287
- 1.26
- 1.253
- 1.301
- 1.18
- 1.162
- 1.251
- 1.183
- 1.072
- 1.031
- 1.024
- 1.081
- 1.048
- 0.957
- 0.938
- 0.936
- 0.904
- 0.935
- 0.872
- 0.84
- 0.789
- 0.846
- 0.774
- 0.753
- 0.799
- 0.74
- 0.72
- 0.716
- 0.699
- 0.704
- 0.701
- 0.668
- 0.612
- 0.598
- 0.6
- 0.599
- 0.548
- 0.564
- 0.555
- 0.535
- 0.524
- 0.529
- 0.51
- 0.484
- 0.488
- 0.506
- 0.475
- 0.456
- 0.435
- 0.448
- 0.447
- 0.436
- 0.4
- 0.39
- 0.393
- 0.397
- 0.374
- 0.382
- 0.356
- 0.375
- 0.37
- 0.337
unequal: 0
verbose: 1
