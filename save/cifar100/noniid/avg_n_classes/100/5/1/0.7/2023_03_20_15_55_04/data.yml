avg_train_accuracy: 0.288
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0378
- 0.0938
- 0.1096
- 0.1287
- 0.1421
- 0.1587
- 0.1692
- 0.1797
- 0.1855
- 0.1979
- 0.2013
- 0.2054
- 0.2138
- 0.2195
- 0.2229
- 0.2267
- 0.233
- 0.2335
- 0.2429
- 0.2451
- 0.2492
- 0.2533
- 0.2519
- 0.2564
- 0.2616
- 0.2584
- 0.2663
- 0.2672
- 0.2687
- 0.2689
- 0.2722
- 0.2737
- 0.2751
- 0.2791
- 0.2768
- 0.2809
- 0.2837
- 0.2817
- 0.2843
- 0.2843
- 0.2862
- 0.2919
- 0.2901
- 0.2905
- 0.2937
- 0.2966
- 0.2955
- 0.2967
- 0.2986
- 0.301
- 0.2966
- 0.2991
- 0.3024
- 0.3038
- 0.3046
- 0.3023
- 0.3056
- 0.3043
- 0.3063
- 0.3091
- 0.3074
- 0.3089
- 0.3063
- 0.3104
- 0.3073
- 0.3115
- 0.3106
- 0.3135
- 0.3121
- 0.3154
- 0.3134
- 0.3122
- 0.3156
- 0.3132
- 0.3136
- 0.3159
- 0.317
- 0.3165
- 0.3184
- 0.3171
- 0.3167
- 0.3199
- 0.32
- 0.3208
- 0.3195
- 0.3201
- 0.3231
- 0.3207
- 0.3189
- 0.3214
- 0.3196
- 0.3219
- 0.3217
- 0.3236
- 0.3223
- 0.3229
- 0.3255
- 0.3268
- 0.3241
- 0.3264
test_loss_list:
- 1.7868643856048585
- 1.6548294234275818
- 1.6015156292915345
- 1.5588215470314026
- 1.5301955366134643
- 1.5072920799255372
- 1.4794146490097047
- 1.462980616092682
- 1.441282947063446
- 1.427190794944763
- 1.4219331860542297
- 1.40182021856308
- 1.393150200843811
- 1.384886803627014
- 1.3667590141296386
- 1.3626387786865235
- 1.3528626155853272
- 1.349926438331604
- 1.3341346549987794
- 1.3172279953956605
- 1.3051191115379333
- 1.3077299475669861
- 1.2914271688461303
- 1.2860083961486817
- 1.279311046600342
- 1.2722190642356872
- 1.2647165727615357
- 1.260134346485138
- 1.262740466594696
- 1.2567811942100524
- 1.2512234354019165
- 1.2476790070533752
- 1.251645152568817
- 1.239556038379669
- 1.2363035225868224
- 1.2309543943405152
- 1.2326491570472717
- 1.2380400013923645
- 1.2330022501945495
- 1.2338504314422607
- 1.2236299777030946
- 1.2228828144073487
- 1.2269200563430787
- 1.2187717413902284
- 1.2093350577354431
- 1.2057819223403932
- 1.2034864521026611
- 1.2015049719810487
- 1.1987487912178039
- 1.1966032218933105
- 1.1922853088378906
- 1.1936524510383606
- 1.1974357962608337
- 1.1887982702255249
- 1.1888137316703797
- 1.1885611414909363
- 1.1961719489097595
- 1.1879678297042846
- 1.1950030040740967
- 1.1874673175811767
- 1.1972136354446412
- 1.1913260674476625
- 1.187940969467163
- 1.1828116464614868
- 1.1851254940032958
- 1.187508885860443
- 1.1812244272232055
- 1.1905616855621337
- 1.185482132434845
- 1.1812812542915345
- 1.179019536972046
- 1.1754736042022704
- 1.178463978767395
- 1.1778606271743775
- 1.17676607131958
- 1.1744672131538392
- 1.174594202041626
- 1.1764966535568238
- 1.175866813659668
- 1.1841005325317382
- 1.1800021862983703
- 1.174434859752655
- 1.1743729400634766
- 1.171968958377838
- 1.1768204498291015
- 1.17646089553833
- 1.1836677646636964
- 1.1794301056861878
- 1.181514217853546
- 1.176287751197815
- 1.177489755153656
- 1.1732524061203002
- 1.1833712220191956
- 1.1805270171165467
- 1.1757252931594848
- 1.1746833562850951
- 1.1756242680549622
- 1.1754684567451477
- 1.1773152732849121
- 1.1793519902229308
train_accuracy:
- 0.034
- 0.101
- 0.0
- 0.139
- 0.132
- 0.136
- 0.113
- 0.135
- 0.173
- 0.201
- 0.212
- 0.218
- 0.193
- 0.268
- 0.231
- 0.216
- 0.226
- 0.242
- 0.255
- 0.265
- 0.265
- 0.176
- 0.28
- 0.271
- 0.296
- 0.291
- 0.3
- 0.279
- 0.302
- 0.272
- 0.276
- 0.3
- 0.227
- 0.321
- 0.0
- 0.313
- 0.292
- 0.316
- 0.0
- 0.312
- 0.303
- 0.258
- 0.249
- 0.326
- 0.26
- 0.276
- 0.0
- 0.252
- 0.308
- 0.268
- 0.344
- 0.312
- 0.256
- 0.314
- 0.322
- 0.339
- 0.271
- 0.378
- 0.282
- 0.372
- 0.322
- 0.26
- 0.362
- 0.0
- 0.272
- 0.342
- 0.316
- 0.376
- 0.348
- 0.334
- 0.317
- 0.0
- 0.282
- 0.337
- 0.33
- 0.311
- 0.374
- 0.327
- 0.282
- 0.331
- 0.328
- 0.282
- 0.331
- 0.373
- 0.342
- 0.384
- 0.358
- 0.0
- 0.285
- 0.386
- 0.332
- 0.288
- 0.324
- 0.0
- 0.0
- 0.0
- 0.368
- 0.0
- 0.332
- 0.288
train_loss:
- 3.837
- 3.449
- 3.256
- 3.101
- 3.309
- 3.218
- 2.764
- 3.024
- 2.646
- 2.862
- 2.752
- 2.455
- 2.642
- 2.556
- 2.257
- 2.43
- 2.39
- 2.312
- 2.046
- 2.048
- 1.969
- 2.092
- 1.918
- 1.821
- 1.803
- 1.768
- 1.745
- 1.696
- 1.808
- 1.599
- 1.557
- 1.498
- 1.645
- 1.503
- 1.437
- 1.418
- 1.515
- 1.457
- 1.314
- 1.444
- 1.245
- 1.374
- 1.323
- 1.173
- 1.171
- 1.158
- 1.076
- 1.085
- 1.044
- 1.04
- 1.007
- 0.962
- 1.019
- 0.968
- 0.909
- 0.884
- 0.914
- 0.886
- 0.911
- 0.844
- 0.832
- 0.761
- 0.754
- 0.766
- 0.697
- 0.772
- 0.72
- 0.727
- 0.663
- 0.687
- 0.629
- 0.634
- 0.632
- 0.615
- 0.573
- 0.59
- 0.57
- 0.581
- 0.53
- 0.557
- 0.491
- 0.54
- 0.494
- 0.502
- 0.478
- 0.457
- 0.486
- 0.452
- 0.426
- 0.431
- 0.447
- 0.406
- 0.43
- 0.397
- 0.415
- 0.398
- 0.386
- 0.389
- 0.367
- 0.368
unequal: 0
verbose: 1
