avg_train_accuracy: 0.302
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0432
- 0.0979
- 0.1192
- 0.1375
- 0.1552
- 0.1628
- 0.1763
- 0.1779
- 0.1914
- 0.1994
- 0.2006
- 0.2042
- 0.213
- 0.2163
- 0.225
- 0.2276
- 0.2357
- 0.2369
- 0.2408
- 0.2469
- 0.2469
- 0.2509
- 0.2538
- 0.2572
- 0.2588
- 0.2606
- 0.2642
- 0.2633
- 0.2701
- 0.27
- 0.2726
- 0.276
- 0.2776
- 0.2786
- 0.2792
- 0.2817
- 0.2856
- 0.2856
- 0.284
- 0.288
- 0.2889
- 0.2893
- 0.2925
- 0.2918
- 0.2905
- 0.2961
- 0.2937
- 0.296
- 0.2985
- 0.2969
- 0.3013
- 0.3024
- 0.2979
- 0.3046
- 0.3027
- 0.3069
- 0.3029
- 0.3094
- 0.3089
- 0.307
- 0.3056
- 0.3113
- 0.3117
- 0.3129
- 0.3134
- 0.3132
- 0.3153
- 0.3168
- 0.3172
- 0.316
- 0.3144
- 0.3181
- 0.317
- 0.3187
- 0.3171
- 0.3182
- 0.3156
- 0.3186
- 0.3213
- 0.3221
- 0.3239
- 0.3198
- 0.3208
- 0.319
- 0.3241
- 0.3235
- 0.3234
- 0.3254
- 0.3236
- 0.3275
- 0.3252
- 0.3265
- 0.3239
- 0.3229
- 0.3284
- 0.3237
- 0.3289
- 0.3286
- 0.3281
- 0.3287
test_loss_list:
- 1.783945460319519
- 1.6492027306556702
- 1.592493371963501
- 1.546533944606781
- 1.5131539392471314
- 1.4878472375869751
- 1.469193572998047
- 1.4478103113174439
- 1.4259512209892273
- 1.4167634630203247
- 1.402444076538086
- 1.384208333492279
- 1.3712885975837708
- 1.3583686447143555
- 1.3553097820281983
- 1.3450624585151671
- 1.3291368079185486
- 1.3197383522987365
- 1.3184708857536316
- 1.3165298438072204
- 1.3018323588371277
- 1.2927838897705077
- 1.2909776449203492
- 1.293197853565216
- 1.288567101955414
- 1.2812753057479858
- 1.279203600883484
- 1.2678337216377258
- 1.2685162568092345
- 1.2662290406227112
- 1.2565920042991638
- 1.246920506954193
- 1.2413251423835754
- 1.2445750379562377
- 1.2368765473365784
- 1.2289124274253844
- 1.2367413783073424
- 1.2357029438018798
- 1.2288263440132141
- 1.2336016583442688
- 1.2268428134918212
- 1.217946002483368
- 1.2243767309188842
- 1.2182240104675293
- 1.2086413788795471
- 1.203381757736206
- 1.2036532950401306
- 1.2023733282089233
- 1.200847222805023
- 1.198250503540039
- 1.1973794174194337
- 1.2007962465286255
- 1.199880986213684
- 1.2030701661109924
- 1.209955747127533
- 1.1958059334754945
- 1.1959961819648743
- 1.1890862202644348
- 1.203735933303833
- 1.1916961765289307
- 1.1906764173507691
- 1.1847505068778992
- 1.1862881445884705
- 1.1847303438186645
- 1.1815923047065735
- 1.1869858169555665
- 1.1824401497840882
- 1.1786120295524598
- 1.1821829080581665
- 1.1866195964813233
- 1.1941886520385743
- 1.1865435791015626
- 1.182473611831665
- 1.1892261385917664
- 1.1863920712471008
- 1.1903744745254516
- 1.1865076971054078
- 1.1816125917434692
- 1.1939667248725891
- 1.1908141350746155
- 1.1948624062538147
- 1.199966413974762
- 1.1918879652023315
- 1.1870184087753295
- 1.1892846536636352
- 1.1970905327796937
- 1.1941514921188354
- 1.1776394653320312
- 1.193206021785736
- 1.18413711309433
- 1.1945628929138183
- 1.1962767839431763
- 1.2025369882583619
- 1.1904257225990296
- 1.1964728569984435
- 1.1917635416984558
- 1.1840732717514038
- 1.181294662952423
- 1.1910166096687318
- 1.1880493760108948
train_accuracy:
- 0.066
- 0.114
- 0.129
- 0.134
- 0.12
- 0.161
- 0.177
- 0.176
- 0.0
- 0.171
- 0.198
- 0.205
- 0.249
- 0.214
- 0.228
- 0.188
- 0.252
- 0.235
- 0.289
- 0.237
- 0.22
- 0.234
- 0.26
- 0.255
- 0.268
- 0.246
- 0.318
- 0.0
- 0.251
- 0.249
- 0.24
- 0.327
- 0.0
- 0.335
- 0.278
- 0.342
- 0.274
- 0.339
- 0.35
- 0.275
- 0.0
- 0.289
- 0.346
- 0.269
- 0.353
- 0.0
- 0.298
- 0.346
- 0.0
- 0.35
- 0.314
- 0.357
- 0.314
- 0.317
- 0.275
- 0.304
- 0.287
- 0.37
- 0.298
- 0.326
- 0.306
- 0.302
- 0.323
- 0.285
- 0.33
- 0.319
- 0.374
- 0.308
- 0.287
- 0.298
- 0.352
- 0.292
- 0.305
- 0.367
- 0.295
- 0.322
- 0.377
- 0.0
- 0.297
- 0.335
- 0.394
- 0.308
- 0.0
- 0.39
- 0.403
- 0.305
- 0.0
- 0.291
- 0.371
- 0.353
- 0.303
- 0.401
- 0.318
- 0.0
- 0.333
- 0.325
- 0.323
- 0.344
- 0.397
- 0.302
train_loss:
- 3.831
- 3.409
- 3.206
- 3.053
- 2.937
- 2.857
- 3.077
- 2.718
- 2.593
- 2.828
- 2.483
- 2.411
- 2.354
- 2.294
- 2.477
- 2.162
- 2.142
- 2.045
- 2.252
- 2.188
- 1.978
- 1.898
- 2.036
- 2.006
- 1.954
- 1.736
- 1.869
- 1.663
- 1.795
- 1.723
- 1.544
- 1.541
- 1.473
- 1.599
- 1.422
- 1.397
- 1.465
- 1.442
- 1.295
- 1.355
- 1.232
- 1.223
- 1.293
- 1.171
- 1.125
- 1.134
- 1.065
- 1.059
- 0.997
- 0.993
- 0.997
- 1.055
- 0.952
- 0.968
- 0.933
- 0.933
- 0.859
- 0.826
- 0.89
- 0.806
- 0.807
- 0.795
- 0.73
- 0.708
- 0.73
- 0.729
- 0.7
- 0.681
- 0.675
- 0.689
- 0.628
- 0.599
- 0.636
- 0.624
- 0.577
- 0.607
- 0.564
- 0.581
- 0.551
- 0.545
- 0.53
- 0.504
- 0.501
- 0.484
- 0.479
- 0.441
- 0.462
- 0.474
- 0.451
- 0.429
- 0.441
- 0.412
- 0.383
- 0.395
- 0.396
- 0.393
- 0.381
- 0.388
- 0.368
- 0.381
unequal: 0
verbose: 1
