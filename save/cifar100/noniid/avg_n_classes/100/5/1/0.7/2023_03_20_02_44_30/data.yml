avg_train_accuracy: 0.329
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0478
- 0.0987
- 0.1175
- 0.1348
- 0.1448
- 0.1594
- 0.167
- 0.1778
- 0.188
- 0.1939
- 0.2016
- 0.2106
- 0.2169
- 0.2176
- 0.2231
- 0.2259
- 0.2326
- 0.2375
- 0.2405
- 0.2432
- 0.2487
- 0.2518
- 0.2542
- 0.2586
- 0.2545
- 0.26
- 0.2636
- 0.2684
- 0.2677
- 0.2719
- 0.271
- 0.273
- 0.2759
- 0.2794
- 0.2762
- 0.2801
- 0.284
- 0.2829
- 0.2834
- 0.2907
- 0.2914
- 0.2892
- 0.294
- 0.2923
- 0.2973
- 0.2963
- 0.2989
- 0.2978
- 0.3025
- 0.3015
- 0.302
- 0.303
- 0.3025
- 0.3054
- 0.3081
- 0.3073
- 0.3073
- 0.3062
- 0.3081
- 0.3109
- 0.3104
- 0.3158
- 0.3132
- 0.3127
- 0.3146
- 0.318
- 0.3186
- 0.3192
- 0.3173
- 0.3173
- 0.3219
- 0.3187
- 0.3195
- 0.3212
- 0.3219
- 0.3216
- 0.3237
- 0.3235
- 0.3241
- 0.3258
- 0.3243
- 0.3265
- 0.3243
- 0.327
- 0.3283
- 0.3296
- 0.327
- 0.3289
- 0.3305
- 0.3301
- 0.3331
- 0.3311
- 0.3316
- 0.3325
- 0.3297
- 0.3313
- 0.3325
- 0.3324
- 0.3317
- 0.335
test_loss_list:
- 1.7907938241958619
- 1.6576469087600707
- 1.602075765132904
- 1.5637625885009765
- 1.529472110271454
- 1.5011315488815307
- 1.476400899887085
- 1.4527489733695984
- 1.4352682781219483
- 1.4180551552772522
- 1.4012155079841613
- 1.3947416377067565
- 1.3778102493286133
- 1.3661154413223267
- 1.3530251502990722
- 1.3423757791519164
- 1.3310933113098145
- 1.3298205208778382
- 1.3194376492500306
- 1.3166218829154968
- 1.3042976450920105
- 1.2974982023239137
- 1.2951095294952393
- 1.2943791031837464
- 1.28583251953125
- 1.2754446530342103
- 1.263554539680481
- 1.2566829895973206
- 1.2521546149253846
- 1.2548435711860657
- 1.2512439703941345
- 1.2425950384140014
- 1.2370467877388
- 1.2296812152862548
- 1.230693073272705
- 1.222366337776184
- 1.224591293334961
- 1.2310196018218995
- 1.222842881679535
- 1.2114422702789307
- 1.217334349155426
- 1.2119282817840575
- 1.2014704489707946
- 1.2003656268119811
- 1.2054603385925293
- 1.195479872226715
- 1.1900605392456054
- 1.188686122894287
- 1.1902488780021667
- 1.1913817572593688
- 1.1946156096458436
- 1.1959775257110596
- 1.2007708621025086
- 1.191132960319519
- 1.193857157230377
- 1.1877275729179382
- 1.1817286324501037
- 1.1775806212425233
- 1.1744657611846925
- 1.175299379825592
- 1.17941388130188
- 1.1706717896461487
- 1.1797032642364502
- 1.1708268070220946
- 1.1751669287681579
- 1.1684861826896666
- 1.1634533524513244
- 1.1730432391166687
- 1.1681844925880431
- 1.1663834524154664
- 1.1754850268363952
- 1.1673543953895569
- 1.178853645324707
- 1.179738781452179
- 1.1810356664657593
- 1.1876631116867065
- 1.1885796618461608
- 1.1904383516311645
- 1.1781124305725097
- 1.1856911182403564
- 1.1877458095550537
- 1.181475031375885
- 1.1886783599853517
- 1.1855569195747375
- 1.1886171627044677
- 1.190972855091095
- 1.1836627197265626
- 1.17765704870224
- 1.1733583903312683
- 1.1683061814308167
- 1.1646101474761963
- 1.1627923965454101
- 1.1666199851036072
- 1.158760290145874
- 1.1635745120048524
- 1.1605032396316528
- 1.1615063261985779
- 1.1624330592155456
- 1.1668474793434143
- 1.1615459728240967
train_accuracy:
- 0.043
- 0.103
- 0.0
- 0.105
- 0.15
- 0.151
- 0.17
- 0.0
- 0.167
- 0.183
- 0.206
- 0.228
- 0.0
- 0.211
- 0.206
- 0.215
- 0.243
- 0.227
- 0.213
- 0.237
- 0.247
- 0.231
- 0.233
- 0.254
- 0.22
- 0.235
- 0.281
- 0.241
- 0.248
- 0.287
- 0.259
- 0.274
- 0.257
- 0.238
- 0.266
- 0.294
- 0.249
- 0.308
- 0.3
- 0.253
- 0.277
- 0.299
- 0.275
- 0.261
- 0.301
- 0.255
- 0.283
- 0.28
- 0.302
- 0.309
- 0.318
- 0.316
- 0.327
- 0.315
- 0.312
- 0.278
- 0.329
- 0.0
- 0.339
- 0.279
- 0.33
- 0.303
- 0.321
- 0.307
- 0.284
- 0.348
- 0.341
- 0.29
- 0.0
- 0.341
- 0.322
- 0.0
- 0.295
- 0.295
- 0.285
- 0.312
- 0.322
- 0.289
- 0.329
- 0.306
- 0.344
- 0.345
- 0.321
- 0.32
- 0.354
- 0.295
- 0.321
- 0.284
- 0.346
- 0.352
- 0.337
- 0.312
- 0.341
- 0.309
- 0.0
- 0.299
- 0.0
- 0.35
- 0.341
- 0.329
train_loss:
- 4.297
- 3.425
- 3.263
- 3.441
- 2.949
- 2.9
- 2.777
- 2.72
- 2.613
- 2.558
- 2.503
- 2.701
- 2.391
- 2.328
- 2.257
- 2.199
- 2.169
- 2.326
- 2.047
- 2.232
- 2.008
- 1.904
- 2.075
- 2.026
- 1.762
- 1.721
- 1.737
- 1.691
- 1.632
- 1.766
- 1.567
- 1.537
- 1.501
- 1.451
- 1.427
- 1.39
- 1.493
- 1.458
- 1.297
- 1.297
- 1.395
- 1.212
- 1.198
- 1.183
- 1.254
- 1.1
- 1.105
- 1.078
- 1.154
- 0.987
- 1.057
- 1.025
- 1.027
- 0.933
- 0.982
- 0.903
- 0.865
- 0.834
- 0.808
- 0.884
- 0.793
- 0.783
- 0.796
- 0.745
- 0.722
- 0.697
- 0.696
- 0.705
- 0.662
- 0.655
- 0.654
- 0.623
- 0.634
- 0.62
- 0.626
- 0.58
- 0.56
- 0.576
- 0.557
- 0.538
- 0.509
- 0.493
- 0.493
- 0.506
- 0.49
- 0.461
- 0.472
- 0.446
- 0.455
- 0.44
- 0.412
- 0.418
- 0.397
- 0.406
- 0.375
- 0.387
- 0.36
- 0.358
- 0.356
- 0.355
unequal: 0
verbose: 1
