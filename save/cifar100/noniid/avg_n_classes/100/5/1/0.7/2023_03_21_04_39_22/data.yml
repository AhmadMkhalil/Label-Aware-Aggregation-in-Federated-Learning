avg_train_accuracy: 0.296
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0364
- 0.0969
- 0.1174
- 0.1376
- 0.1494
- 0.16
- 0.1699
- 0.1786
- 0.1863
- 0.1983
- 0.201
- 0.2139
- 0.218
- 0.2224
- 0.2273
- 0.2336
- 0.24
- 0.2406
- 0.2446
- 0.2491
- 0.2529
- 0.2581
- 0.2592
- 0.2598
- 0.2623
- 0.2659
- 0.2716
- 0.2722
- 0.2758
- 0.2762
- 0.2787
- 0.2779
- 0.281
- 0.279
- 0.28
- 0.2835
- 0.2841
- 0.2853
- 0.2884
- 0.2884
- 0.2908
- 0.2954
- 0.2933
- 0.2978
- 0.296
- 0.2944
- 0.3025
- 0.3002
- 0.302
- 0.3043
- 0.3025
- 0.3052
- 0.3073
- 0.309
- 0.3049
- 0.3089
- 0.3082
- 0.3086
- 0.3121
- 0.3146
- 0.3105
- 0.3135
- 0.3125
- 0.3136
- 0.3133
- 0.3126
- 0.318
- 0.3152
- 0.3151
- 0.3154
- 0.3185
- 0.3156
- 0.3201
- 0.3186
- 0.3172
- 0.3222
- 0.3198
- 0.322
- 0.3221
- 0.3217
- 0.3238
- 0.3251
- 0.3221
- 0.3243
- 0.3254
- 0.3222
- 0.3236
- 0.325
- 0.326
- 0.3276
- 0.3273
- 0.3278
- 0.3262
- 0.3296
- 0.33
- 0.3264
- 0.328
- 0.3289
- 0.3309
- 0.329
test_loss_list:
- 1.7905047750473022
- 1.6560885572433472
- 1.597166497707367
- 1.5514088845252991
- 1.5185428690910339
- 1.4936832690238953
- 1.471027534008026
- 1.4513054895401
- 1.4296925711631774
- 1.4202996587753296
- 1.4129893851280213
- 1.4031663131713867
- 1.393558804988861
- 1.3775311160087584
- 1.3571709632873534
- 1.3532698273658752
- 1.3392183327674865
- 1.3281840133666991
- 1.317405536174774
- 1.307373995780945
- 1.2983805465698242
- 1.2896000623703003
- 1.2851474642753602
- 1.2761634588241577
- 1.270972225666046
- 1.2618768453598022
- 1.2565097641944885
- 1.261699206829071
- 1.2511536145210267
- 1.2542253947257995
- 1.249422905445099
- 1.2513847041130066
- 1.2514682269096375
- 1.2432624626159667
- 1.2367486548423767
- 1.2321983480453491
- 1.2360941672325134
- 1.2264667820930482
- 1.2274905109405518
- 1.2326660227775574
- 1.2256462979316711
- 1.2140643095970154
- 1.2142209959030152
- 1.205089292526245
- 1.2030344247817992
- 1.2012082695961
- 1.1948559069633484
- 1.1964756393432616
- 1.1998954582214356
- 1.1905250072479248
- 1.1922007203102112
- 1.1974828433990479
- 1.1964883875846863
- 1.204294466972351
- 1.1950070571899414
- 1.1977423644065857
- 1.1916486716270447
- 1.196721601486206
- 1.1899581551551819
- 1.184425811767578
- 1.190699851512909
- 1.1916433119773864
- 1.189389510154724
- 1.182770140171051
- 1.1804880023002624
- 1.1795122408866883
- 1.1849929594993591
- 1.182749903202057
- 1.178252980709076
- 1.1742943382263185
- 1.1731956219673156
- 1.1796182584762573
- 1.1706862258911133
- 1.174306528568268
- 1.1724672079086305
- 1.1723168969154358
- 1.172183313369751
- 1.1714488029479981
- 1.172079038619995
- 1.172148015499115
- 1.1713607573509217
- 1.1696447443962097
- 1.1834392166137695
- 1.1793164443969726
- 1.1820202660560608
- 1.17818354845047
- 1.1881300592422486
- 1.1832610392570495
- 1.1746698355674743
- 1.1850768280029298
- 1.187986400127411
- 1.1953251791000366
- 1.1815500664710998
- 1.1806232929229736
- 1.1871753025054932
- 1.1839271235466002
- 1.189977879524231
- 1.1825895881652833
- 1.182667498588562
- 1.1774246954917909
train_accuracy:
- 0.058
- 0.122
- 0.0
- 0.129
- 0.168
- 0.158
- 0.152
- 0.162
- 0.218
- 0.215
- 0.223
- 0.19
- 0.225
- 0.197
- 0.229
- 0.252
- 0.253
- 0.251
- 0.254
- 0.255
- 0.264
- 0.272
- 0.247
- 0.235
- 0.0
- 0.251
- 0.244
- 0.276
- 0.281
- 0.253
- 0.292
- 0.252
- 0.245
- 0.266
- 0.285
- 0.0
- 0.283
- 0.284
- 0.249
- 0.303
- 0.249
- 0.3
- 0.294
- 0.291
- 0.293
- 0.292
- 0.255
- 0.279
- 0.275
- 0.312
- 0.244
- 0.3
- 0.311
- 0.344
- 0.312
- 0.317
- 0.322
- 0.269
- 0.0
- 0.263
- 0.344
- 0.296
- 0.326
- 0.322
- 0.303
- 0.335
- 0.301
- 0.303
- 0.327
- 0.329
- 0.308
- 0.298
- 0.311
- 0.344
- 0.31
- 0.298
- 0.296
- 0.0
- 0.324
- 0.301
- 0.334
- 0.353
- 0.301
- 0.349
- 0.356
- 0.309
- 0.322
- 0.263
- 0.0
- 0.297
- 0.293
- 0.286
- 0.356
- 0.33
- 0.308
- 0.296
- 0.29
- 0.282
- 0.0
- 0.296
train_loss:
- 3.835
- 3.859
- 3.239
- 3.104
- 2.971
- 2.865
- 2.769
- 2.671
- 2.627
- 2.847
- 2.742
- 2.677
- 2.628
- 2.292
- 2.265
- 2.437
- 2.144
- 2.068
- 2.01
- 1.975
- 1.907
- 1.922
- 1.843
- 1.779
- 1.82
- 1.757
- 1.733
- 1.855
- 1.667
- 1.758
- 1.57
- 1.671
- 1.61
- 1.452
- 1.411
- 1.378
- 1.475
- 1.351
- 1.454
- 1.362
- 1.243
- 1.217
- 1.197
- 1.141
- 1.117
- 1.08
- 1.111
- 1.067
- 1.137
- 1.045
- 0.964
- 1.049
- 1.017
- 0.979
- 0.907
- 0.95
- 0.897
- 0.894
- 0.823
- 0.821
- 0.841
- 0.817
- 0.755
- 0.752
- 0.749
- 0.702
- 0.735
- 0.683
- 0.666
- 0.652
- 0.635
- 0.615
- 0.594
- 0.59
- 0.56
- 0.564
- 0.563
- 0.547
- 0.544
- 0.538
- 0.507
- 0.496
- 0.503
- 0.497
- 0.479
- 0.452
- 0.453
- 0.455
- 0.43
- 0.439
- 0.427
- 0.424
- 0.42
- 0.41
- 0.392
- 0.378
- 0.381
- 0.373
- 0.372
- 0.354
unequal: 0
verbose: 1
