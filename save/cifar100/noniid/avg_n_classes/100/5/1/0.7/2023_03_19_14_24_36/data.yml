avg_train_accuracy: 0.29
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0412
- 0.1017
- 0.122
- 0.1425
- 0.1525
- 0.1627
- 0.1757
- 0.1795
- 0.19
- 0.1975
- 0.2046
- 0.2107
- 0.2163
- 0.2195
- 0.2283
- 0.2291
- 0.2352
- 0.2359
- 0.2441
- 0.2442
- 0.251
- 0.253
- 0.2557
- 0.2627
- 0.2641
- 0.2669
- 0.2692
- 0.2711
- 0.2729
- 0.278
- 0.2806
- 0.2844
- 0.2803
- 0.2839
- 0.2842
- 0.2878
- 0.2843
- 0.2916
- 0.2938
- 0.2927
- 0.2928
- 0.2937
- 0.2947
- 0.2983
- 0.3001
- 0.301
- 0.3001
- 0.3013
- 0.3046
- 0.3034
- 0.3048
- 0.3037
- 0.3055
- 0.3051
- 0.3055
- 0.3087
- 0.308
- 0.3087
- 0.3115
- 0.3131
- 0.3138
- 0.3135
- 0.3111
- 0.3134
- 0.3132
- 0.3133
- 0.3156
- 0.317
- 0.3158
- 0.3176
- 0.3185
- 0.3173
- 0.3179
- 0.3196
- 0.3205
- 0.3205
- 0.3212
- 0.3224
- 0.3214
- 0.3205
- 0.3222
- 0.3202
- 0.3232
- 0.3241
- 0.3268
- 0.3251
- 0.3234
- 0.3262
- 0.325
- 0.3281
- 0.3281
- 0.329
- 0.3259
- 0.3258
- 0.3298
- 0.3284
- 0.3247
- 0.3269
- 0.3297
- 0.3284
test_loss_list:
- 1.7932099103927612
- 1.6471515607833862
- 1.5882760214805602
- 1.5462125897407533
- 1.5187123322486877
- 1.4869538307189942
- 1.473264412879944
- 1.4511411046981813
- 1.4362652015686035
- 1.4244443321228026
- 1.412076668739319
- 1.3940379285812379
- 1.3856227922439575
- 1.3702883982658387
- 1.3497438645362854
- 1.3391146731376649
- 1.3256330919265746
- 1.31919331073761
- 1.3158218336105347
- 1.30352046251297
- 1.3059483075141907
- 1.2957953691482544
- 1.2933811020851136
- 1.2921762466430664
- 1.2794244003295898
- 1.266017074584961
- 1.2689052367210387
- 1.2672457242012023
- 1.2571326780319214
- 1.2471950149536133
- 1.237399971485138
- 1.2302881479263306
- 1.2367413425445557
- 1.2277223706245421
- 1.234258713722229
- 1.2237914252281188
- 1.218542857170105
- 1.2130570220947265
- 1.2034036016464233
- 1.2032567977905273
- 1.2029919290542603
- 1.1967027306556701
- 1.1965109610557556
- 1.1984318327903747
- 1.1960718321800232
- 1.1909010243415832
- 1.2023922109603882
- 1.2015379500389098
- 1.1954761624336243
- 1.1885489845275878
- 1.1842642426490784
- 1.191606845855713
- 1.1838399291038513
- 1.1894710087776184
- 1.181927411556244
- 1.1864042425155639
- 1.1911718893051146
- 1.1868070006370544
- 1.1780937361717223
- 1.1868488430976867
- 1.175800256729126
- 1.1751671099662782
- 1.1837372541427613
- 1.1721767234802245
- 1.1733485341072083
- 1.1685219931602477
- 1.1659905552864074
- 1.1638023948669434
- 1.1675966334342958
- 1.163185133934021
- 1.163979697227478
- 1.1670167446136475
- 1.1634741997718812
- 1.164269027709961
- 1.1611152219772338
- 1.1634953260421752
- 1.1649898481369019
- 1.1610872149467468
- 1.1599895715713502
- 1.1622192859649658
- 1.170427005290985
- 1.1764090609550477
- 1.169726243019104
- 1.164985897541046
- 1.1745639991760255
- 1.168679850101471
- 1.1691620469093322
- 1.1652979779243469
- 1.1685559558868408
- 1.1765233302116394
- 1.1682142663002013
- 1.1701835918426513
- 1.1766412663459778
- 1.1750616335868835
- 1.168707585334778
- 1.1663584756851195
- 1.1780063581466675
- 1.1840275311470032
- 1.1749795794487
- 1.173792700767517
train_accuracy:
- 0.064
- 0.105
- 0.127
- 0.11
- 0.13
- 0.207
- 0.154
- 0.181
- 0.229
- 0.207
- 0.216
- 0.0
- 0.216
- 0.245
- 0.225
- 0.251
- 0.239
- 0.258
- 0.251
- 0.279
- 0.258
- 0.255
- 0.283
- 0.273
- 0.23
- 0.0
- 0.267
- 0.245
- 0.286
- 0.295
- 0.292
- 0.3
- 0.299
- 0.296
- 0.307
- 0.0
- 0.0
- 0.315
- 0.312
- 0.0
- 0.0
- 0.315
- 0.0
- 0.317
- 0.313
- 0.325
- 0.308
- 0.345
- 0.323
- 0.0
- 0.345
- 0.275
- 0.347
- 0.349
- 0.332
- 0.273
- 0.271
- 0.307
- 0.331
- 0.324
- 0.335
- 0.322
- 0.344
- 0.364
- 0.274
- 0.325
- 0.334
- 0.36
- 0.0
- 0.0
- 0.0
- 0.0
- 0.317
- 0.367
- 0.316
- 0.278
- 0.349
- 0.335
- 0.281
- 0.348
- 0.345
- 0.383
- 0.0
- 0.357
- 0.339
- 0.329
- 0.383
- 0.344
- 0.355
- 0.356
- 0.332
- 0.346
- 0.295
- 0.336
- 0.344
- 0.377
- 0.372
- 0.378
- 0.349
- 0.29
train_loss:
- 3.826
- 3.429
- 3.219
- 3.093
- 3.31
- 2.865
- 3.083
- 2.667
- 2.9
- 2.806
- 2.709
- 2.418
- 2.566
- 2.267
- 2.264
- 2.168
- 2.107
- 2.056
- 2.229
- 1.937
- 2.093
- 1.836
- 2.028
- 2.001
- 1.808
- 1.706
- 1.861
- 1.811
- 1.614
- 1.591
- 1.558
- 1.526
- 1.631
- 1.423
- 1.54
- 1.374
- 1.325
- 1.327
- 1.32
- 1.258
- 1.187
- 1.225
- 1.16
- 1.249
- 1.108
- 1.093
- 1.169
- 1.123
- 1.03
- 1.012
- 0.967
- 1.02
- 0.942
- 0.972
- 0.914
- 0.937
- 0.89
- 0.834
- 0.81
- 0.822
- 0.801
- 0.767
- 0.794
- 0.743
- 0.693
- 0.678
- 0.64
- 0.676
- 0.652
- 0.63
- 0.643
- 0.609
- 0.607
- 0.561
- 0.58
- 0.542
- 0.559
- 0.552
- 0.515
- 0.516
- 0.529
- 0.507
- 0.483
- 0.476
- 0.499
- 0.454
- 0.447
- 0.425
- 0.442
- 0.436
- 0.429
- 0.39
- 0.415
- 0.401
- 0.392
- 0.373
- 0.393
- 0.358
- 0.35
- 0.345
unequal: 0
verbose: 1
