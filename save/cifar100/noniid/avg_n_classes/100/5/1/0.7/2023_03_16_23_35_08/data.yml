avg_train_accuracy: 0.406
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0378
- 0.0966
- 0.1229
- 0.1386
- 0.1508
- 0.1617
- 0.1699
- 0.1795
- 0.1847
- 0.1957
- 0.2049
- 0.2089
- 0.2154
- 0.2183
- 0.2255
- 0.2355
- 0.2352
- 0.2392
- 0.2454
- 0.254
- 0.2555
- 0.2591
- 0.2638
- 0.2683
- 0.2692
- 0.2741
- 0.2778
- 0.2797
- 0.2807
- 0.2811
- 0.2869
- 0.2887
- 0.289
- 0.2947
- 0.2927
- 0.2982
- 0.3014
- 0.2985
- 0.301
- 0.3037
- 0.3017
- 0.3078
- 0.3067
- 0.3063
- 0.3083
- 0.3085
- 0.3093
- 0.3101
- 0.3121
- 0.3133
- 0.3115
- 0.3126
- 0.314
- 0.3171
- 0.3164
- 0.3207
- 0.3179
- 0.3202
- 0.3155
- 0.3226
- 0.321
- 0.3204
- 0.3232
- 0.3271
- 0.3239
- 0.3213
- 0.3258
- 0.3236
- 0.3268
- 0.3261
- 0.3259
- 0.327
- 0.3302
- 0.3289
- 0.327
- 0.3297
- 0.3316
- 0.3338
- 0.3323
- 0.3293
- 0.3305
- 0.3321
- 0.3324
- 0.3329
- 0.3295
- 0.332
- 0.3366
- 0.334
- 0.3351
- 0.332
- 0.3332
- 0.3343
- 0.3345
- 0.3316
- 0.3338
- 0.3372
- 0.3371
- 0.3369
- 0.3377
- 0.3367
test_loss_list:
- 1.792095685005188
- 1.6512465691566467
- 1.598038787841797
- 1.560536048412323
- 1.5234842324256896
- 1.4954868364334106
- 1.4775695013999939
- 1.4554766416549683
- 1.43642751455307
- 1.4250582480430602
- 1.415659236907959
- 1.4036832976341247
- 1.3846247863769532
- 1.3695413708686828
- 1.356386046409607
- 1.3420174717903137
- 1.3286373829841613
- 1.317497673034668
- 1.305821237564087
- 1.296799533367157
- 1.2871254968643189
- 1.286200964450836
- 1.2806770181655884
- 1.2778790473937989
- 1.2784474301338196
- 1.2639158797264098
- 1.25053435087204
- 1.2422695112228395
- 1.2438874650001526
- 1.239203963279724
- 1.2246196627616883
- 1.227828164100647
- 1.2190241813659668
- 1.2229380917549133
- 1.2145804953575134
- 1.2027557516098022
- 1.196991548538208
- 1.194172306060791
- 1.1900875425338746
- 1.1858128309249878
- 1.1855232334136963
- 1.1818018913269044
- 1.1862455272674561
- 1.1830057144165038
- 1.1853428387641907
- 1.1778025674819945
- 1.1795764231681825
- 1.1826034426689147
- 1.1752662324905396
- 1.1721630907058715
- 1.1648235273361207
- 1.1644302940368652
- 1.1601169300079346
- 1.1656060242652893
- 1.1599365067481995
- 1.1629631233215332
- 1.171474142074585
- 1.1725919818878174
- 1.1728660774230957
- 1.161973397731781
- 1.1567831945419311
- 1.1535434556007385
- 1.149948182106018
- 1.157373297214508
- 1.1510841393470763
- 1.1493383026123047
- 1.1553776836395264
- 1.1551481509208679
- 1.1491192650794984
- 1.1504734468460083
- 1.1483988642692566
- 1.1463749599456787
- 1.151281886100769
- 1.1596740555763245
- 1.1528415608406066
- 1.149142210483551
- 1.1465656638145447
- 1.1424394512176514
- 1.1419138526916504
- 1.1520081329345704
- 1.1477827787399293
- 1.1456952214241027
- 1.1442686200141907
- 1.151093430519104
- 1.148094012737274
- 1.1475125980377197
- 1.143320620059967
- 1.1470295238494872
- 1.153180522918701
- 1.1485207772254944
- 1.1484160423278809
- 1.151914083957672
- 1.1587190175056457
- 1.1579978609085082
- 1.151565613746643
- 1.1588241529464722
- 1.1496984410285949
- 1.1509522485733032
- 1.1475928235054016
- 1.1489677047729492
train_accuracy:
- 0.035
- 0.094
- 0.095
- 0.135
- 0.0
- 0.139
- 0.164
- 0.174
- 0.211
- 0.212
- 0.212
- 0.216
- 0.216
- 0.2
- 0.199
- 0.267
- 0.247
- 0.238
- 0.234
- 0.214
- 0.199
- 0.268
- 0.272
- 0.283
- 0.211
- 0.213
- 0.283
- 0.254
- 0.282
- 0.249
- 0.26
- 0.234
- 0.224
- 0.242
- 0.0
- 0.289
- 0.286
- 0.337
- 0.299
- 0.305
- 0.281
- 0.278
- 0.247
- 0.254
- 0.26
- 0.296
- 0.277
- 0.294
- 0.285
- 0.374
- 0.0
- 0.329
- 0.287
- 0.372
- 0.31
- 0.299
- 0.303
- 0.345
- 0.31
- 0.297
- 0.376
- 0.296
- 0.382
- 0.319
- 0.296
- 0.344
- 0.284
- 0.311
- 0.341
- 0.317
- 0.303
- 0.358
- 0.332
- 0.305
- 0.309
- 0.301
- 0.305
- 0.295
- 0.295
- 0.302
- 0.331
- 0.294
- 0.317
- 0.323
- 0.346
- 0.307
- 0.326
- 0.408
- 0.33
- 0.406
- 0.383
- 0.296
- 0.32
- 0.42
- 0.316
- 0.327
- 0.332
- 0.302
- 0.327
- 0.406
train_loss:
- 3.858
- 3.863
- 3.609
- 3.425
- 2.965
- 2.847
- 3.107
- 2.708
- 2.613
- 2.826
- 2.758
- 2.699
- 2.371
- 2.307
- 2.247
- 2.207
- 2.135
- 2.075
- 2.048
- 2.005
- 1.921
- 2.098
- 2.073
- 1.971
- 1.933
- 1.741
- 1.701
- 1.622
- 1.769
- 1.554
- 1.542
- 1.64
- 1.437
- 1.555
- 1.367
- 1.415
- 1.294
- 1.311
- 1.285
- 1.224
- 1.185
- 1.172
- 1.249
- 1.121
- 1.198
- 1.097
- 1.147
- 1.103
- 1.005
- 0.969
- 0.997
- 0.931
- 0.923
- 0.949
- 0.884
- 0.926
- 0.882
- 0.852
- 0.856
- 0.802
- 0.795
- 0.74
- 0.747
- 0.752
- 0.703
- 0.686
- 0.696
- 0.627
- 0.635
- 0.597
- 0.613
- 0.616
- 0.63
- 0.593
- 0.556
- 0.557
- 0.527
- 0.532
- 0.503
- 0.517
- 0.52
- 0.475
- 0.463
- 0.452
- 0.477
- 0.453
- 0.428
- 0.404
- 0.423
- 0.42
- 0.396
- 0.403
- 0.383
- 0.384
- 0.37
- 0.373
- 0.366
- 0.346
- 0.358
- 0.348
unequal: 0
verbose: 1
