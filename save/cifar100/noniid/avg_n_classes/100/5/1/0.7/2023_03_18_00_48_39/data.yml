avg_train_accuracy: 0.386
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0451
- 0.0995
- 0.1166
- 0.1335
- 0.1474
- 0.1626
- 0.1693
- 0.1762
- 0.185
- 0.19
- 0.1959
- 0.2031
- 0.2057
- 0.2126
- 0.2168
- 0.223
- 0.2259
- 0.233
- 0.2361
- 0.2383
- 0.2461
- 0.2473
- 0.2511
- 0.255
- 0.26
- 0.2635
- 0.2658
- 0.2671
- 0.2722
- 0.272
- 0.2792
- 0.2816
- 0.2823
- 0.2847
- 0.2844
- 0.2861
- 0.2906
- 0.2925
- 0.2965
- 0.2975
- 0.2942
- 0.2972
- 0.2958
- 0.3025
- 0.3038
- 0.3053
- 0.3036
- 0.3076
- 0.312
- 0.3122
- 0.3108
- 0.3091
- 0.312
- 0.3159
- 0.3131
- 0.3173
- 0.3158
- 0.3145
- 0.318
- 0.318
- 0.3163
- 0.3205
- 0.3161
- 0.3212
- 0.3218
- 0.3212
- 0.3237
- 0.3168
- 0.3231
- 0.3236
- 0.3243
- 0.3236
- 0.3265
- 0.3291
- 0.3259
- 0.3252
- 0.3274
- 0.3291
- 0.3282
- 0.3296
- 0.3283
- 0.3289
- 0.3296
- 0.334
- 0.3327
- 0.3321
- 0.3347
- 0.3307
- 0.3332
- 0.3336
- 0.3358
- 0.3335
- 0.3363
- 0.3323
- 0.3343
- 0.3356
- 0.3356
- 0.3359
- 0.3357
- 0.3312
test_loss_list:
- 1.783863582611084
- 1.6542616081237793
- 1.6022136831283569
- 1.5603715705871581
- 1.5315180206298828
- 1.4986902356147767
- 1.4784934663772582
- 1.462927632331848
- 1.443770065307617
- 1.42643306016922
- 1.409169020652771
- 1.3928240394592286
- 1.389305236339569
- 1.3736873722076417
- 1.3615060544013977
- 1.3500267148017884
- 1.3359667325019837
- 1.3343905353546142
- 1.3211051154136657
- 1.3190921473503112
- 1.305130226612091
- 1.2960082507133484
- 1.2887239289283752
- 1.2791618657112123
- 1.2732865595817566
- 1.2741119766235351
- 1.2633257079124451
- 1.263871328830719
- 1.255239613056183
- 1.2442755579948426
- 1.2475726056098937
- 1.2496761178970337
- 1.2370901584625245
- 1.229062829017639
- 1.2301473665237426
- 1.2235990428924561
- 1.2227387571334838
- 1.2190332341194152
- 1.2174319458007812
- 1.2155252408981323
- 1.2076279282569886
- 1.2013358759880066
- 1.196518235206604
- 1.2005821037292481
- 1.1927723741531373
- 1.194964156150818
- 1.192602288722992
- 1.1811352801322936
- 1.18632666349411
- 1.1966454577445984
- 1.1819097208976745
- 1.1770613646507264
- 1.1802089023590088
- 1.1812291169166564
- 1.1788689374923706
- 1.1714290261268616
- 1.1742871713638305
- 1.1702032136917113
- 1.1647959351539612
- 1.1619292283058167
- 1.1674490284919739
- 1.172807171344757
- 1.1679993534088136
- 1.1622978925704956
- 1.1574425721168518
- 1.1693214297294616
- 1.1712903332710267
- 1.1704142808914184
- 1.1593298530578613
- 1.1569701766967773
- 1.1542455315589906
- 1.1634985685348511
- 1.1542497992515564
- 1.1524678897857665
- 1.1529216957092285
- 1.1528649759292602
- 1.1593786644935609
- 1.151603980064392
- 1.1500456476211547
- 1.1623193907737732
- 1.1550577688217163
- 1.1653621459007264
- 1.1612623476982116
- 1.1565960454940796
- 1.1522456860542298
- 1.1604824948310852
- 1.1506902027130126
- 1.163605933189392
- 1.1661759471893312
- 1.1552555692195892
- 1.1650359272956847
- 1.162353286743164
- 1.1635602188110352
- 1.1626697969436646
- 1.156348226070404
- 1.161834431886673
- 1.1617862796783447
- 1.1635527122020721
- 1.1698217737674712
- 1.1727664279937744
train_accuracy:
- 0.068
- 0.107
- 0.0
- 0.136
- 0.136
- 0.202
- 0.137
- 0.171
- 0.168
- 0.196
- 0.165
- 0.186
- 0.193
- 0.196
- 0.0
- 0.217
- 0.195
- 0.233
- 0.212
- 0.247
- 0.236
- 0.202
- 0.21
- 0.214
- 0.219
- 0.268
- 0.269
- 0.209
- 0.0
- 0.243
- 0.221
- 0.277
- 0.291
- 0.247
- 0.251
- 0.252
- 0.245
- 0.0
- 0.229
- 0.279
- 0.0
- 0.263
- 0.237
- 0.291
- 0.254
- 0.257
- 0.332
- 0.305
- 0.277
- 0.277
- 0.316
- 0.328
- 0.339
- 0.291
- 0.0
- 0.329
- 0.312
- 0.292
- 0.0
- 0.343
- 0.309
- 0.283
- 0.308
- 0.313
- 0.0
- 0.309
- 0.317
- 0.344
- 0.3
- 0.307
- 0.358
- 0.304
- 0.319
- 0.341
- 0.306
- 0.295
- 0.317
- 0.282
- 0.324
- 0.304
- 0.355
- 0.297
- 0.0
- 0.331
- 0.324
- 0.324
- 0.37
- 0.301
- 0.322
- 0.0
- 0.291
- 0.303
- 0.368
- 0.292
- 0.335
- 0.318
- 0.301
- 0.29
- 0.296
- 0.386
train_loss:
- 4.29
- 3.446
- 3.275
- 3.111
- 2.984
- 2.917
- 2.81
- 3.026
- 2.644
- 2.586
- 2.499
- 2.453
- 2.646
- 2.356
- 2.253
- 2.21
- 2.168
- 2.35
- 2.095
- 2.246
- 1.972
- 1.938
- 1.894
- 1.872
- 1.79
- 1.973
- 1.784
- 1.871
- 1.671
- 1.635
- 1.765
- 1.695
- 1.536
- 1.499
- 1.601
- 1.401
- 1.561
- 1.35
- 1.457
- 1.429
- 1.287
- 1.24
- 1.205
- 1.304
- 1.167
- 1.234
- 1.102
- 1.071
- 1.188
- 1.1
- 1.023
- 1.001
- 1.027
- 1.032
- 0.918
- 0.901
- 0.97
- 0.891
- 0.854
- 0.837
- 0.873
- 0.84
- 0.791
- 0.788
- 0.741
- 0.753
- 0.722
- 0.698
- 0.682
- 0.674
- 0.645
- 0.678
- 0.623
- 0.647
- 0.592
- 0.596
- 0.599
- 0.557
- 0.555
- 0.563
- 0.546
- 0.534
- 0.503
- 0.51
- 0.472
- 0.496
- 0.487
- 0.462
- 0.451
- 0.461
- 0.446
- 0.424
- 0.424
- 0.402
- 0.41
- 0.406
- 0.377
- 0.386
- 0.369
- 0.385
unequal: 0
verbose: 1
