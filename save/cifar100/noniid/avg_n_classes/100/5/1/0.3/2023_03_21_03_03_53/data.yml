avg_train_accuracy: 0.305
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0479
- 0.0897
- 0.1138
- 0.1231
- 0.1455
- 0.1567
- 0.1646
- 0.1727
- 0.1769
- 0.1855
- 0.1881
- 0.1949
- 0.1946
- 0.2055
- 0.2052
- 0.2143
- 0.2253
- 0.2261
- 0.2234
- 0.2322
- 0.2323
- 0.2349
- 0.2399
- 0.2403
- 0.237
- 0.2384
- 0.2414
- 0.245
- 0.2591
- 0.258
- 0.26
- 0.2614
- 0.2587
- 0.2593
- 0.261
- 0.2639
- 0.2627
- 0.2674
- 0.2672
- 0.2702
- 0.266
- 0.275
- 0.2694
- 0.2757
- 0.2771
- 0.274
- 0.2799
- 0.2767
- 0.277
- 0.2848
- 0.2885
- 0.2888
- 0.2809
- 0.2891
- 0.2865
- 0.2925
- 0.2948
- 0.2932
- 0.2963
- 0.2921
- 0.2968
- 0.3029
- 0.3016
- 0.2971
- 0.2961
- 0.3027
- 0.2992
- 0.2952
- 0.2888
- 0.3007
- 0.3034
- 0.3096
- 0.3072
- 0.3104
- 0.305
- 0.3022
- 0.3067
- 0.3021
- 0.308
- 0.3054
- 0.3141
- 0.3048
- 0.3077
- 0.3099
- 0.3108
- 0.3137
- 0.3079
- 0.304
- 0.3171
- 0.3206
- 0.3107
- 0.3176
- 0.3122
- 0.3189
- 0.3164
- 0.313
- 0.3169
- 0.3127
- 0.3121
- 0.318
test_loss_list:
- 1.789483494758606
- 1.6685196924209595
- 1.6123507595062256
- 1.583161425590515
- 1.551682903766632
- 1.531875033378601
- 1.5149150133132934
- 1.4989030647277832
- 1.4787612462043762
- 1.467418179512024
- 1.4552895665168761
- 1.43725670337677
- 1.4238531613349914
- 1.408348400592804
- 1.4070450901985168
- 1.3885505628585815
- 1.3791351413726807
- 1.3772951197624206
- 1.3721949696540832
- 1.3614748859405517
- 1.3585632848739624
- 1.3532900953292846
- 1.3470140099525452
- 1.339613516330719
- 1.3402042698860168
- 1.3388866710662841
- 1.3204856681823731
- 1.3192347502708435
- 1.304000027179718
- 1.3079621911048889
- 1.3082589411735535
- 1.3012870645523071
- 1.3043123865127564
- 1.3070683121681212
- 1.3064275860786438
- 1.300658278465271
- 1.3086511421203613
- 1.2983640384674073
- 1.2836269068717956
- 1.2915831756591798
- 1.278899748325348
- 1.2737982225418092
- 1.284032530784607
- 1.2697514748573304
- 1.2680040717124939
- 1.2631660032272338
- 1.2569828343391418
- 1.2711028242111206
- 1.2614846849441528
- 1.258639681339264
- 1.2469157481193542
- 1.2560434794425965
- 1.2594050717353822
- 1.253160798549652
- 1.2480868458747865
- 1.245822515487671
- 1.2428745698928834
- 1.2443078541755677
- 1.248942675590515
- 1.2535045838356018
- 1.2523260021209717
- 1.2549009919166565
- 1.2491796326637268
- 1.2477087831497193
- 1.2327608227729798
- 1.239651424884796
- 1.246632719039917
- 1.2452014088630676
- 1.2421618509292602
- 1.2267836284637452
- 1.2293419241905212
- 1.2283987808227539
- 1.2352933502197265
- 1.228033573627472
- 1.2376379346847535
- 1.2368262577056885
- 1.2240832829475403
- 1.2396468997001648
- 1.2351436233520507
- 1.2396482300758362
- 1.2382392811775207
- 1.2405567502975463
- 1.2314141726493835
- 1.2341550230979919
- 1.228328776359558
- 1.23894464969635
- 1.224604983329773
- 1.2267523360252381
- 1.2194956374168395
- 1.2201611185073853
- 1.2236151552200318
- 1.2281753158569335
- 1.2210292196273804
- 1.2211772918701171
- 1.229115948677063
- 1.2318317914009094
- 1.2267211389541626
- 1.2203397750854492
- 1.2205960249900818
- 1.2225306224822998
train_accuracy:
- 0.054
- 0.097
- 0.098
- 0.141
- 0.139
- 0.166
- 0.177
- 0.154
- 0.157
- 0.159
- 0.0
- 0.191
- 0.179
- 0.224
- 0.0
- 0.17
- 0.188
- 0.228
- 0.0
- 0.192
- 0.201
- 0.251
- 0.22
- 0.219
- 0.217
- 0.237
- 0.22
- 0.273
- 0.215
- 0.213
- 0.225
- 0.257
- 0.259
- 0.248
- 0.244
- 0.249
- 0.262
- 0.242
- 0.257
- 0.295
- 0.234
- 0.275
- 0.226
- 0.268
- 0.255
- 0.233
- 0.296
- 0.305
- 0.29
- 0.251
- 0.249
- 0.283
- 0.251
- 0.298
- 0.0
- 0.295
- 0.245
- 0.295
- 0.265
- 0.286
- 0.32
- 0.313
- 0.282
- 0.311
- 0.245
- 0.288
- 0.311
- 0.301
- 0.0
- 0.259
- 0.301
- 0.328
- 0.283
- 0.298
- 0.263
- 0.0
- 0.319
- 0.251
- 0.314
- 0.315
- 0.307
- 0.331
- 0.0
- 0.338
- 0.345
- 0.269
- 0.296
- 0.269
- 0.297
- 0.294
- 0.328
- 0.348
- 0.308
- 0.341
- 0.334
- 0.0
- 0.327
- 0.29
- 0.0
- 0.305
train_loss:
- 4.27
- 2.937
- 3.593
- 3.367
- 3.327
- 3.27
- 3.116
- 3.003
- 3.052
- 2.913
- 2.204
- 2.221
- 2.029
- 2.669
- 2.038
- 2.482
- 2.564
- 2.382
- 1.775
- 2.346
- 2.312
- 2.236
- 2.246
- 2.121
- 1.696
- 1.586
- 1.564
- 1.986
- 2.068
- 1.823
- 1.7
- 1.882
- 1.687
- 1.55
- 1.694
- 1.707
- 1.478
- 1.567
- 1.388
- 1.581
- 1.2
- 1.483
- 1.185
- 1.33
- 1.315
- 1.15
- 1.361
- 1.243
- 1.095
- 1.301
- 1.084
- 1.128
- 0.96
- 1.196
- 0.948
- 1.107
- 1.025
- 0.981
- 0.872
- 0.972
- 1.003
- 0.996
- 0.836
- 0.856
- 0.791
- 0.778
- 0.709
- 0.822
- 0.687
- 0.766
- 0.722
- 0.836
- 0.659
- 0.751
- 0.6
- 0.598
- 0.745
- 0.578
- 0.702
- 0.527
- 0.529
- 0.671
- 0.666
- 0.567
- 0.596
- 0.506
- 0.569
- 0.552
- 0.62
- 0.498
- 0.526
- 0.486
- 0.494
- 0.427
- 0.393
- 0.542
- 0.456
- 0.44
- 0.471
- 0.394
unequal: 0
verbose: 1
