avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0366
- 0.0853
- 0.1101
- 0.1335
- 0.1455
- 0.1531
- 0.1681
- 0.1683
- 0.18
- 0.1843
- 0.1948
- 0.2047
- 0.2053
- 0.2088
- 0.2088
- 0.2211
- 0.2294
- 0.2326
- 0.2306
- 0.235
- 0.2358
- 0.2445
- 0.2456
- 0.2492
- 0.2571
- 0.2561
- 0.2621
- 0.261
- 0.2632
- 0.2689
- 0.2672
- 0.2685
- 0.2694
- 0.2765
- 0.2717
- 0.2651
- 0.2706
- 0.282
- 0.2767
- 0.2814
- 0.2831
- 0.2845
- 0.2852
- 0.2817
- 0.2903
- 0.2857
- 0.2913
- 0.2979
- 0.3037
- 0.3001
- 0.3041
- 0.3025
- 0.2953
- 0.296
- 0.3047
- 0.302
- 0.2995
- 0.3064
- 0.3092
- 0.3018
- 0.3095
- 0.304
- 0.3106
- 0.3075
- 0.3047
- 0.3096
- 0.3023
- 0.3139
- 0.3074
- 0.3102
- 0.3186
- 0.3093
- 0.3158
- 0.3167
- 0.3186
- 0.3188
- 0.3219
- 0.3213
- 0.3241
- 0.3155
- 0.3104
- 0.3223
- 0.3255
- 0.3224
- 0.3203
- 0.318
- 0.3178
- 0.3203
- 0.324
- 0.323
- 0.3267
- 0.3226
- 0.3244
- 0.3269
- 0.3241
- 0.3269
- 0.3261
- 0.3256
- 0.3287
- 0.3229
test_loss_list:
- 1.7971738815307616
- 1.6800772142410278
- 1.6273820352554322
- 1.588970468044281
- 1.5652723288536072
- 1.5341431593894959
- 1.5115717649459839
- 1.4933998274803162
- 1.4708597445487976
- 1.456734869480133
- 1.4403838968276979
- 1.4276254177093506
- 1.42362797498703
- 1.4168308115005492
- 1.4065837478637695
- 1.3900805401802063
- 1.378043978214264
- 1.363979890346527
- 1.3599179291725159
- 1.3552441453933717
- 1.3593442726135254
- 1.3483877348899842
- 1.3435307502746583
- 1.3376741886138916
- 1.3228823733329773
- 1.3241979670524597
- 1.317891218662262
- 1.3200896930694581
- 1.3224967789649964
- 1.3109240460395812
- 1.3130981135368347
- 1.3095409417152404
- 1.3112393498420716
- 1.3050533866882323
- 1.3032784724235535
- 1.3053018712997437
- 1.2822698497772216
- 1.2715962624549866
- 1.2699165225028992
- 1.2640527486801147
- 1.262922878265381
- 1.2726807522773742
- 1.2674836134910583
- 1.2641665744781494
- 1.2527176642417908
- 1.2524913501739503
- 1.2497780656814574
- 1.2393068981170654
- 1.2342305636405946
- 1.2323524594306945
- 1.2277502989768982
- 1.2212373161315917
- 1.2312804460525513
- 1.2361069440841674
- 1.224436810016632
- 1.2245648384094239
- 1.2304536342620849
- 1.2187864208221435
- 1.2167081427574158
- 1.228372323513031
- 1.2154022455215454
- 1.2225761580467225
- 1.2079813432693483
- 1.2218421864509583
- 1.2195688486099243
- 1.215763738155365
- 1.2220431423187257
- 1.202794189453125
- 1.2135042190551757
- 1.211372582912445
- 1.2074796628952027
- 1.2060746502876283
- 1.209414403438568
- 1.2049497389793395
- 1.2025055837631227
- 1.2021321988105773
- 1.2020170164108277
- 1.1997055840492248
- 1.2024234247207641
- 1.2168729543685912
- 1.223847827911377
- 1.208770501613617
- 1.1976068210601807
- 1.2043266487121582
- 1.2200420165061951
- 1.2079373621940612
- 1.2030306339263916
- 1.2027152347564698
- 1.2070631504058837
- 1.2050545024871826
- 1.214335343837738
- 1.2089367532730102
- 1.212157108783722
- 1.197571268081665
- 1.1999691700935364
- 1.2007434821128846
- 1.207170386314392
- 1.204206063747406
- 1.201791024208069
- 1.207285888195038
train_accuracy:
- 0.063
- 0.094
- 0.11
- 0.147
- 0.134
- 0.136
- 0.175
- 0.174
- 0.158
- 0.157
- 0.191
- 0.202
- 0.199
- 0.181
- 0.213
- 0.212
- 0.227
- 0.242
- 0.233
- 0.192
- 0.234
- 0.238
- 0.204
- 0.222
- 0.214
- 0.296
- 0.24
- 0.267
- 0.28
- 0.26
- 0.304
- 0.267
- 0.261
- 0.252
- 0.303
- 0.234
- 0.266
- 0.249
- 0.0
- 0.287
- 0.291
- 0.305
- 0.291
- 0.292
- 0.289
- 0.279
- 0.323
- 0.307
- 0.319
- 0.343
- 0.253
- 0.351
- 0.315
- 0.309
- 0.332
- 0.309
- 0.0
- 0.325
- 0.29
- 0.254
- 0.345
- 0.0
- 0.335
- 0.278
- 0.0
- 0.305
- 0.343
- 0.319
- 0.325
- 0.0
- 0.357
- 0.309
- 0.283
- 0.344
- 0.287
- 0.0
- 0.277
- 0.322
- 0.345
- 0.322
- 0.0
- 0.339
- 0.335
- 0.337
- 0.378
- 0.285
- 0.322
- 0.327
- 0.337
- 0.338
- 0.35
- 0.329
- 0.315
- 0.0
- 0.0
- 0.354
- 0.346
- 0.313
- 0.341
- 0.0
train_loss:
- 4.32
- 3.871
- 3.575
- 3.472
- 3.245
- 3.319
- 3.131
- 2.4
- 2.949
- 2.246
- 2.758
- 2.824
- 2.621
- 2.645
- 1.998
- 2.563
- 2.438
- 2.494
- 1.807
- 2.247
- 2.088
- 2.206
- 2.064
- 2.032
- 2.228
- 1.946
- 1.997
- 1.895
- 1.819
- 1.782
- 1.786
- 1.775
- 1.519
- 1.669
- 1.696
- 1.317
- 1.452
- 1.599
- 1.19
- 1.348
- 1.323
- 1.159
- 1.183
- 1.122
- 1.268
- 1.119
- 1.27
- 1.418
- 1.347
- 1.039
- 1.127
- 1.053
- 1.0
- 0.863
- 0.897
- 1.028
- 0.754
- 1.01
- 1.042
- 1.021
- 0.848
- 0.737
- 0.889
- 0.915
- 0.808
- 0.723
- 0.625
- 0.845
- 0.63
- 0.779
- 0.831
- 0.74
- 0.71
- 0.703
- 0.716
- 0.664
- 0.676
- 0.74
- 0.579
- 0.537
- 0.592
- 0.51
- 0.662
- 0.61
- 0.499
- 0.533
- 0.598
- 0.519
- 0.427
- 0.52
- 0.491
- 0.456
- 0.525
- 0.522
- 0.482
- 0.455
- 0.369
- 0.437
- 0.383
- 0.411
unequal: 0
verbose: 1
