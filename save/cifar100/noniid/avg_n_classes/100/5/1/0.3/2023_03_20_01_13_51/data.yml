avg_train_accuracy: 0.278
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0473
- 0.0924
- 0.1093
- 0.1273
- 0.1447
- 0.158
- 0.1681
- 0.1768
- 0.1856
- 0.1934
- 0.2019
- 0.2037
- 0.2024
- 0.2158
- 0.2132
- 0.2286
- 0.2325
- 0.2346
- 0.2272
- 0.238
- 0.2469
- 0.2463
- 0.2536
- 0.2604
- 0.2564
- 0.2596
- 0.2633
- 0.2619
- 0.2642
- 0.2673
- 0.2643
- 0.266
- 0.2708
- 0.2667
- 0.2719
- 0.2658
- 0.2673
- 0.2743
- 0.28
- 0.2827
- 0.2799
- 0.2853
- 0.2889
- 0.2873
- 0.2931
- 0.2914
- 0.2907
- 0.2943
- 0.2967
- 0.2868
- 0.2905
- 0.2978
- 0.3015
- 0.3006
- 0.2937
- 0.2887
- 0.3051
- 0.2993
- 0.3067
- 0.2996
- 0.3066
- 0.3066
- 0.3085
- 0.3128
- 0.3002
- 0.3116
- 0.3085
- 0.3103
- 0.3081
- 0.3116
- 0.3152
- 0.315
- 0.3169
- 0.3187
- 0.3177
- 0.3231
- 0.325
- 0.3182
- 0.3144
- 0.3129
- 0.3193
- 0.3204
- 0.3244
- 0.3145
- 0.3188
- 0.3184
- 0.32
- 0.3167
- 0.3174
- 0.3208
- 0.3248
- 0.3176
- 0.3214
- 0.3207
- 0.3116
- 0.3238
- 0.3167
- 0.3242
- 0.3236
- 0.3232
test_loss_list:
- 1.7843087387084962
- 1.667810447216034
- 1.6166172242164611
- 1.5767577385902405
- 1.5474594593048097
- 1.5236388182640075
- 1.5075675392150878
- 1.4913317036628724
- 1.4796505546569825
- 1.4667767095565796
- 1.4481005454063416
- 1.4457386636734009
- 1.4427809381484986
- 1.4207253122329713
- 1.4052219676971436
- 1.3831106615066528
- 1.3746052122116088
- 1.3752303552627563
- 1.3713139581680298
- 1.3463271284103393
- 1.3428971481323242
- 1.3329391002655029
- 1.3279887557029724
- 1.3250441861152649
- 1.3270553827285767
- 1.3250658845901488
- 1.321097047328949
- 1.3203074741363525
- 1.3135081219673157
- 1.312322096824646
- 1.3235608220100403
- 1.3066801953315734
- 1.3017422842979431
- 1.3047967147827149
- 1.296995828151703
- 1.3055318236351012
- 1.2883310890197754
- 1.2819515466690063
- 1.2561621761322022
- 1.2590666556358336
- 1.2645383501052856
- 1.2565802359580993
- 1.2570848226547242
- 1.244534614086151
- 1.2426834750175475
- 1.246099500656128
- 1.248508677482605
- 1.2379118037223815
- 1.2357550883293151
- 1.2483641266822816
- 1.2408508086204528
- 1.2284139680862427
- 1.2281750535964966
- 1.2341043400764464
- 1.2317850160598756
- 1.2450537514686584
- 1.2188217878341674
- 1.2226047253608703
- 1.2212646293640137
- 1.2297513127326964
- 1.2177889442443848
- 1.2134822916984558
- 1.2164521956443786
- 1.2113970828056335
- 1.225043272972107
- 1.2137641358375548
- 1.2229682445526122
- 1.2040824341773986
- 1.21498703956604
- 1.204974546432495
- 1.2092456817626953
- 1.2141611313819884
- 1.2127745604515077
- 1.2176208782196045
- 1.2086293244361876
- 1.2142863202095031
- 1.2109594082832336
- 1.218153555393219
- 1.2176901745796203
- 1.2219842720031737
- 1.2097643828392028
- 1.2130404686927796
- 1.20685818195343
- 1.222605938911438
- 1.2130312514305115
- 1.205789430141449
- 1.2127482175827027
- 1.2199398899078369
- 1.2155162835121154
- 1.221755278110504
- 1.2121738767623902
- 1.2153518891334534
- 1.2143899178504944
- 1.2172793126106263
- 1.2227986669540405
- 1.2128501319885254
- 1.2242310452461242
- 1.2126251816749574
- 1.220035321712494
- 1.221597545146942
train_accuracy:
- 0.062
- 0.098
- 0.105
- 0.0
- 0.154
- 0.121
- 0.132
- 0.174
- 0.189
- 0.176
- 0.171
- 0.192
- 0.166
- 0.225
- 0.223
- 0.221
- 0.26
- 0.2
- 0.201
- 0.221
- 0.213
- 0.291
- 0.257
- 0.233
- 0.222
- 0.226
- 0.28
- 0.279
- 0.253
- 0.272
- 0.271
- 0.293
- 0.31
- 0.0
- 0.279
- 0.283
- 0.256
- 0.303
- 0.261
- 0.288
- 0.233
- 0.278
- 0.307
- 0.31
- 0.318
- 0.299
- 0.0
- 0.34
- 0.331
- 0.312
- 0.0
- 0.248
- 0.322
- 0.273
- 0.258
- 0.297
- 0.301
- 0.0
- 0.299
- 0.268
- 0.323
- 0.0
- 0.322
- 0.315
- 0.0
- 0.322
- 0.332
- 0.309
- 0.315
- 0.0
- 0.28
- 0.294
- 0.258
- 0.312
- 0.254
- 0.334
- 0.329
- 0.0
- 0.329
- 0.321
- 0.324
- 0.344
- 0.346
- 0.0
- 0.306
- 0.309
- 0.273
- 0.312
- 0.382
- 0.338
- 0.0
- 0.336
- 0.296
- 0.32
- 0.0
- 0.365
- 0.324
- 0.302
- 0.334
- 0.278
train_loss:
- 3.211
- 3.879
- 2.789
- 2.634
- 3.325
- 3.203
- 3.117
- 3.052
- 2.965
- 2.857
- 2.796
- 2.674
- 2.048
- 2.525
- 1.996
- 2.527
- 2.402
- 2.251
- 1.722
- 1.956
- 2.217
- 2.174
- 2.169
- 2.029
- 1.956
- 1.931
- 1.95
- 1.824
- 1.758
- 1.787
- 1.765
- 1.66
- 1.692
- 1.473
- 1.525
- 1.26
- 1.167
- 1.256
- 1.251
- 1.423
- 1.409
- 1.563
- 1.464
- 1.193
- 1.2
- 1.316
- 1.082
- 1.237
- 1.269
- 0.933
- 0.957
- 1.355
- 1.027
- 1.123
- 0.942
- 0.864
- 0.94
- 0.899
- 0.992
- 0.782
- 0.948
- 0.866
- 0.855
- 0.893
- 0.784
- 0.923
- 0.68
- 0.732
- 0.749
- 0.716
- 0.691
- 0.745
- 0.722
- 0.602
- 0.654
- 0.588
- 0.617
- 0.495
- 0.68
- 0.622
- 0.695
- 0.531
- 0.639
- 0.601
- 0.486
- 0.513
- 0.429
- 0.476
- 0.528
- 0.54
- 0.526
- 0.415
- 0.459
- 0.516
- 0.48
- 0.414
- 0.32
- 0.515
- 0.426
- 0.447
unequal: 0
verbose: 1
