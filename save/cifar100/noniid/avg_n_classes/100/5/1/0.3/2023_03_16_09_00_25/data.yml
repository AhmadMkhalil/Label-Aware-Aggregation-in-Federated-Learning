avg_train_accuracy: 0.333
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0527
- 0.0882
- 0.1126
- 0.1269
- 0.1374
- 0.1524
- 0.1656
- 0.1699
- 0.1796
- 0.1847
- 0.1832
- 0.2024
- 0.2095
- 0.2177
- 0.2103
- 0.2236
- 0.2279
- 0.2332
- 0.2347
- 0.2439
- 0.242
- 0.2448
- 0.2472
- 0.2529
- 0.2493
- 0.2592
- 0.2681
- 0.2612
- 0.2669
- 0.264
- 0.2699
- 0.2742
- 0.2624
- 0.2641
- 0.2772
- 0.2738
- 0.2852
- 0.2855
- 0.2861
- 0.2916
- 0.2905
- 0.2891
- 0.2909
- 0.2881
- 0.2957
- 0.2953
- 0.3009
- 0.2895
- 0.3058
- 0.2965
- 0.2941
- 0.3056
- 0.3041
- 0.2992
- 0.295
- 0.3049
- 0.297
- 0.3094
- 0.3111
- 0.3054
- 0.3092
- 0.3072
- 0.307
- 0.3122
- 0.3204
- 0.3089
- 0.3183
- 0.3187
- 0.3088
- 0.3188
- 0.3142
- 0.3111
- 0.3199
- 0.3173
- 0.3154
- 0.3206
- 0.3192
- 0.3183
- 0.3202
- 0.3187
- 0.3255
- 0.3177
- 0.3108
- 0.3228
- 0.3188
- 0.3268
- 0.3154
- 0.3244
- 0.3258
- 0.3193
- 0.3198
- 0.3292
- 0.3299
- 0.3272
- 0.3264
- 0.3301
- 0.3284
- 0.3296
- 0.3235
- 0.3264
test_loss_list:
- 1.7865818452835083
- 1.676322238445282
- 1.621970570087433
- 1.5910180592536927
- 1.5566322541236877
- 1.5324946928024292
- 1.5085775709152223
- 1.491445107460022
- 1.470377585887909
- 1.4561736726760863
- 1.4462317299842835
- 1.421085901260376
- 1.4092518639564515
- 1.3952141880989075
- 1.4001484107971192
- 1.3722584819793702
- 1.3721548533439636
- 1.3672970914840699
- 1.3682602334022522
- 1.3442487859725951
- 1.3382441687583924
- 1.3337636017799377
- 1.3351857447624207
- 1.3303112840652467
- 1.3218775987625122
- 1.3037247848510742
- 1.2889012908935547
- 1.2907830595970153
- 1.288375701904297
- 1.2896232867240907
- 1.2835035848617553
- 1.2753827810287475
- 1.2812183356285096
- 1.279555423259735
- 1.2499074006080628
- 1.260610706806183
- 1.238588774204254
- 1.246918363571167
- 1.248496413230896
- 1.240374698638916
- 1.237055354118347
- 1.2521569895744324
- 1.2577307271957396
- 1.2453514909744263
- 1.2313631558418274
- 1.2332715845108033
- 1.2310625004768372
- 1.2480240917205812
- 1.214548282623291
- 1.230302243232727
- 1.2275026440620422
- 1.2013569569587708
- 1.2188223004341125
- 1.2232869029045106
- 1.2202304005622864
- 1.2103379368782043
- 1.2193166422843933
- 1.2010821437835693
- 1.2083660292625427
- 1.2092752242088318
- 1.206563663482666
- 1.2086692118644715
- 1.2201296377182007
- 1.204686439037323
- 1.2031304836273193
- 1.226398983001709
- 1.2047409844398498
- 1.2120122146606445
- 1.218386423587799
- 1.2038976883888244
- 1.213472864627838
- 1.2176934957504273
- 1.1998448944091797
- 1.210604295730591
- 1.2043783497810363
- 1.1999019193649292
- 1.2034699296951294
- 1.200262167453766
- 1.1995897150039674
- 1.2049628233909606
- 1.1940515184402465
- 1.1984846138954162
- 1.2096240377426148
- 1.1936330270767213
- 1.2056595540046693
- 1.1951256132125854
- 1.2047229290008545
- 1.1947143650054932
- 1.2102094960212708
- 1.1989811968803405
- 1.2110264372825623
- 1.1899677538871765
- 1.1959028124809266
- 1.2049657249450683
- 1.1980580973625183
- 1.2031594586372376
- 1.2039203453063965
- 1.2079045271873474
- 1.2058561873435973
- 1.210685043334961
train_accuracy:
- 0.057
- 0.075
- 0.13
- 0.129
- 0.0
- 0.149
- 0.183
- 0.188
- 0.182
- 0.185
- 0.169
- 0.204
- 0.2
- 0.225
- 0.202
- 0.212
- 0.22
- 0.232
- 0.225
- 0.214
- 0.209
- 0.218
- 0.236
- 0.256
- 0.252
- 0.221
- 0.264
- 0.0
- 0.291
- 0.272
- 0.269
- 0.281
- 0.0
- 0.254
- 0.287
- 0.283
- 0.291
- 0.298
- 0.288
- 0.32
- 0.324
- 0.329
- 0.276
- 0.299
- 0.298
- 0.334
- 0.274
- 0.0
- 0.302
- 0.282
- 0.0
- 0.305
- 0.307
- 0.337
- 0.0
- 0.337
- 0.0
- 0.323
- 0.287
- 0.314
- 0.314
- 0.293
- 0.326
- 0.34
- 0.287
- 0.29
- 0.337
- 0.299
- 0.299
- 0.323
- 0.308
- 0.333
- 0.308
- 0.287
- 0.352
- 0.0
- 0.367
- 0.336
- 0.341
- 0.324
- 0.323
- 0.0
- 0.287
- 0.332
- 0.374
- 0.316
- 0.317
- 0.339
- 0.332
- 0.349
- 0.302
- 0.334
- 0.328
- 0.356
- 0.335
- 0.317
- 0.352
- 0.323
- 0.352
- 0.333
train_loss:
- 4.303
- 3.8
- 3.617
- 3.382
- 2.614
- 3.12
- 3.076
- 2.943
- 2.351
- 2.225
- 2.051
- 2.671
- 2.694
- 2.652
- 1.886
- 2.697
- 2.272
- 2.332
- 2.148
- 2.332
- 1.805
- 2.168
- 1.88
- 2.109
- 1.661
- 1.979
- 2.035
- 1.586
- 1.711
- 1.321
- 1.71
- 1.584
- 1.374
- 1.235
- 1.874
- 1.203
- 1.633
- 1.519
- 1.473
- 1.461
- 1.34
- 1.214
- 1.093
- 1.277
- 1.468
- 1.244
- 1.336
- 1.061
- 1.182
- 0.933
- 0.974
- 1.176
- 1.022
- 0.917
- 0.803
- 0.969
- 0.807
- 1.029
- 0.986
- 0.851
- 0.721
- 0.777
- 0.748
- 0.983
- 0.872
- 0.87
- 0.716
- 0.85
- 0.699
- 0.653
- 0.698
- 0.647
- 0.85
- 0.672
- 0.757
- 0.676
- 0.531
- 0.564
- 0.64
- 0.606
- 0.569
- 0.555
- 0.554
- 0.522
- 0.477
- 0.66
- 0.6
- 0.472
- 0.473
- 0.526
- 0.417
- 0.514
- 0.472
- 0.487
- 0.42
- 0.443
- 0.381
- 0.444
- 0.44
- 0.397
unequal: 0
verbose: 1
