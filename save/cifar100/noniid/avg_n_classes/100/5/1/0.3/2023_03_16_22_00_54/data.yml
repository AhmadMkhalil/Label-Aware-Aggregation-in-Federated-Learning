avg_train_accuracy: 0.328
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0427
- 0.097
- 0.1152
- 0.1254
- 0.147
- 0.1529
- 0.1717
- 0.177
- 0.189
- 0.186
- 0.196
- 0.1964
- 0.2062
- 0.2131
- 0.2175
- 0.2221
- 0.2258
- 0.224
- 0.2213
- 0.2272
- 0.2382
- 0.2447
- 0.2464
- 0.2452
- 0.2473
- 0.2538
- 0.2497
- 0.255
- 0.2535
- 0.2628
- 0.2687
- 0.2716
- 0.2643
- 0.2709
- 0.2705
- 0.2762
- 0.2802
- 0.2807
- 0.276
- 0.2815
- 0.284
- 0.2879
- 0.2894
- 0.2862
- 0.2935
- 0.2985
- 0.2915
- 0.2936
- 0.2956
- 0.3006
- 0.3027
- 0.3029
- 0.304
- 0.3014
- 0.3044
- 0.306
- 0.3088
- 0.3059
- 0.307
- 0.3069
- 0.3134
- 0.3043
- 0.3101
- 0.3123
- 0.31
- 0.309
- 0.3151
- 0.3142
- 0.3192
- 0.3177
- 0.3158
- 0.3094
- 0.3154
- 0.3189
- 0.3159
- 0.3179
- 0.3146
- 0.3157
- 0.3209
- 0.3254
- 0.3217
- 0.3225
- 0.3266
- 0.321
- 0.3265
- 0.3261
- 0.3286
- 0.3178
- 0.3156
- 0.3278
- 0.3279
- 0.3179
- 0.3232
- 0.3249
- 0.3256
- 0.3294
- 0.3281
- 0.3296
- 0.3257
- 0.3328
test_loss_list:
- 1.7886207580566407
- 1.6600488781929017
- 1.6141099047660827
- 1.5763439702987672
- 1.5429142570495606
- 1.5155194187164307
- 1.495363733768463
- 1.483630771636963
- 1.4628237247467042
- 1.4620139956474305
- 1.4340065741539
- 1.4316813158988952
- 1.4118004417419434
- 1.4040926790237427
- 1.397497546672821
- 1.3899201774597167
- 1.3830315494537353
- 1.3828987050056458
- 1.3842111229896545
- 1.355884084701538
- 1.3421708130836487
- 1.3355703139305115
- 1.3306170320510864
- 1.3280093693733215
- 1.315466618537903
- 1.3046723294258118
- 1.3076971888542175
- 1.2929863953590393
- 1.294170958995819
- 1.2794842290878297
- 1.2723465466499329
- 1.2717851901054382
- 1.2726394820213318
- 1.2677667188644408
- 1.2553760671615601
- 1.2580074405670165
- 1.2613675022125244
- 1.2472960686683654
- 1.2474673867225647
- 1.247001416683197
- 1.2457392311096191
- 1.2404250288009644
- 1.2341265439987184
- 1.235562379360199
- 1.2327433443069458
- 1.227488980293274
- 1.2368758177757264
- 1.2276764059066771
- 1.2204015469551086
- 1.2046215200424195
- 1.199707999229431
- 1.21265864610672
- 1.1971133470535278
- 1.2044722175598144
- 1.2076149153709412
- 1.208306109905243
- 1.1965750646591187
- 1.2101419758796692
- 1.1985179090499878
- 1.206693410873413
- 1.1988910484313964
- 1.2050425863265992
- 1.1989033889770508
- 1.205154356956482
- 1.2067861080169677
- 1.1944699168205262
- 1.1871323108673095
- 1.195230073928833
- 1.1852499389648437
- 1.195654056072235
- 1.18956524848938
- 1.1970420002937316
- 1.1954898071289062
- 1.183596706390381
- 1.1917068982124328
- 1.188908040523529
- 1.1941973376274109
- 1.187641303539276
- 1.1882625532150268
- 1.188561165332794
- 1.1882269644737244
- 1.1968940305709839
- 1.1991352891921998
- 1.1860855054855346
- 1.1881987833976746
- 1.194177076816559
- 1.2061789226531983
- 1.2041177177429199
- 1.1995102047920227
- 1.1836750459671022
- 1.187204954624176
- 1.2026204323768617
- 1.1741774129867553
- 1.1830614399909973
- 1.1917901062965393
- 1.1947668886184692
- 1.190010311603546
- 1.1948634243011476
- 1.1924295163154601
- 1.1896955251693726
train_accuracy:
- 0.041
- 0.069
- 0.091
- 0.121
- 0.124
- 0.13
- 0.146
- 0.152
- 0.16
- 0.153
- 0.165
- 0.151
- 0.189
- 0.212
- 0.198
- 0.233
- 0.239
- 0.213
- 0.228
- 0.226
- 0.221
- 0.214
- 0.227
- 0.2
- 0.224
- 0.23
- 0.0
- 0.0
- 0.277
- 0.217
- 0.244
- 0.236
- 0.0
- 0.325
- 0.228
- 0.245
- 0.255
- 0.234
- 0.238
- 0.288
- 0.274
- 0.295
- 0.261
- 0.275
- 0.273
- 0.326
- 0.283
- 0.281
- 0.275
- 0.285
- 0.298
- 0.298
- 0.278
- 0.309
- 0.312
- 0.299
- 0.27
- 0.345
- 0.291
- 0.309
- 0.287
- 0.275
- 0.326
- 0.284
- 0.0
- 0.0
- 0.297
- 0.284
- 0.298
- 0.288
- 0.0
- 0.33
- 0.333
- 0.343
- 0.0
- 0.34
- 0.301
- 0.0
- 0.303
- 0.3
- 0.369
- 0.334
- 0.253
- 0.334
- 0.259
- 0.318
- 0.331
- 0.342
- 0.291
- 0.316
- 0.267
- 0.0
- 0.306
- 0.325
- 0.308
- 0.314
- 0.334
- 0.334
- 0.0
- 0.328
train_loss:
- 4.3
- 3.899
- 2.779
- 2.677
- 3.343
- 2.469
- 3.065
- 3.076
- 2.941
- 2.234
- 2.847
- 2.091
- 2.745
- 2.698
- 2.605
- 2.555
- 2.472
- 2.315
- 1.836
- 1.867
- 2.353
- 2.28
- 2.212
- 1.644
- 1.622
- 1.995
- 1.538
- 1.535
- 1.401
- 1.909
- 1.851
- 1.823
- 1.541
- 1.593
- 1.44
- 1.485
- 1.539
- 1.394
- 1.191
- 1.362
- 1.439
- 1.129
- 1.336
- 1.358
- 1.404
- 1.369
- 1.384
- 1.143
- 1.029
- 1.132
- 1.21
- 0.907
- 1.258
- 1.072
- 0.858
- 1.063
- 1.061
- 0.888
- 0.943
- 0.965
- 1.006
- 0.831
- 1.007
- 0.869
- 0.774
- 0.843
- 0.741
- 0.704
- 0.854
- 0.738
- 0.71
- 0.661
- 0.697
- 0.797
- 0.674
- 0.634
- 0.677
- 0.714
- 0.608
- 0.666
- 0.663
- 0.575
- 0.571
- 0.567
- 0.604
- 0.543
- 0.533
- 0.496
- 0.476
- 0.62
- 0.485
- 0.462
- 0.518
- 0.416
- 0.421
- 0.527
- 0.47
- 0.398
- 0.443
- 0.438
unequal: 0
verbose: 1
