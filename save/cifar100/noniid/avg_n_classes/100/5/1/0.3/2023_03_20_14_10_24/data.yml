avg_train_accuracy: 0.354
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0418
- 0.0965
- 0.1173
- 0.1336
- 0.144
- 0.1485
- 0.1575
- 0.1686
- 0.1725
- 0.185
- 0.1942
- 0.1986
- 0.2004
- 0.2077
- 0.2173
- 0.2213
- 0.2234
- 0.2332
- 0.2359
- 0.2386
- 0.2425
- 0.2426
- 0.2429
- 0.2504
- 0.2518
- 0.2604
- 0.2577
- 0.2597
- 0.2699
- 0.2654
- 0.2681
- 0.272
- 0.2775
- 0.2797
- 0.2849
- 0.2823
- 0.2863
- 0.2868
- 0.281
- 0.2888
- 0.2862
- 0.2871
- 0.2916
- 0.2929
- 0.2919
- 0.2966
- 0.3047
- 0.3008
- 0.3046
- 0.3014
- 0.3001
- 0.2999
- 0.3122
- 0.3115
- 0.3002
- 0.3086
- 0.3135
- 0.3139
- 0.3168
- 0.3145
- 0.3196
- 0.3145
- 0.3124
- 0.3155
- 0.3184
- 0.3166
- 0.3125
- 0.3226
- 0.3226
- 0.3143
- 0.3228
- 0.3145
- 0.3138
- 0.3237
- 0.3238
- 0.3196
- 0.3234
- 0.3257
- 0.3229
- 0.3212
- 0.326
- 0.3277
- 0.3284
- 0.3327
- 0.3254
- 0.3224
- 0.3281
- 0.3251
- 0.3315
- 0.3331
- 0.3256
- 0.3315
- 0.3277
- 0.3319
- 0.3289
- 0.3365
- 0.3232
- 0.3293
- 0.3323
- 0.3326
test_loss_list:
- 1.796657314300537
- 1.6652469229698181
- 1.6174231004714965
- 1.5787929129600524
- 1.552675814628601
- 1.5354672026634217
- 1.514552788734436
- 1.4918030452728273
- 1.4773061347007752
- 1.452833652496338
- 1.4432653832435607
- 1.430321888923645
- 1.4115149450302125
- 1.3971336698532104
- 1.3877799725532531
- 1.3789695620536804
- 1.3717278194427491
- 1.3640274310112
- 1.3550102663040162
- 1.3555409502983093
- 1.3449081134796144
- 1.3348157691955567
- 1.3316409254074097
- 1.3199827027320863
- 1.321543550491333
- 1.306287226676941
- 1.302207956314087
- 1.294323480129242
- 1.282766842842102
- 1.2868906497955321
- 1.2812996077537537
- 1.2758799886703491
- 1.2623243451118469
- 1.259934196472168
- 1.2494897389411925
- 1.2565629696846008
- 1.2481504487991333
- 1.2584649538993835
- 1.2699799299240113
- 1.2555936241149903
- 1.2505057787895202
- 1.2384501886367798
- 1.2361489391326905
- 1.2268862771987914
- 1.2339787912368774
- 1.2173623132705689
- 1.2102656269073486
- 1.2326404070854187
- 1.2174357676506042
- 1.217853126525879
- 1.2216146874427796
- 1.2209075665473939
- 1.2111445951461792
- 1.2117837977409363
- 1.2288083267211913
- 1.1936096239089966
- 1.1932661080360412
- 1.2026782822608948
- 1.2043687963485719
- 1.2050938677787781
- 1.2058731150627136
- 1.2134165954589844
- 1.2180415630340575
- 1.2143342304229736
- 1.206643123626709
- 1.2180891728401184
- 1.208183844089508
- 1.1977719712257384
- 1.2033777117729187
- 1.2069218707084657
- 1.1895190167427063
- 1.2026433229446412
- 1.1914676225185394
- 1.1896704137325287
- 1.1887175977230071
- 1.1970499408245088
- 1.1805234527587891
- 1.1882636618614197
- 1.1991062700748443
- 1.1939146065711974
- 1.1979855298995972
- 1.1941582942008973
- 1.1878217446804047
- 1.1805993592739106
- 1.1863680481910706
- 1.1785706639289857
- 1.1883445954322815
- 1.1879542756080628
- 1.179645800590515
- 1.178231167793274
- 1.187200071811676
- 1.190821430683136
- 1.184958394765854
- 1.171845247745514
- 1.1839819526672364
- 1.183582191467285
- 1.1966692972183228
- 1.1851149606704712
- 1.1967257130146027
- 1.2004255425930024
train_accuracy:
- 0.048
- 0.09
- 0.119
- 0.114
- 0.134
- 0.144
- 0.145
- 0.159
- 0.0
- 0.19
- 0.178
- 0.168
- 0.194
- 0.19
- 0.19
- 0.202
- 0.198
- 0.21
- 0.257
- 0.23
- 0.226
- 0.234
- 0.233
- 0.263
- 0.225
- 0.234
- 0.0
- 0.256
- 0.263
- 0.238
- 0.248
- 0.262
- 0.245
- 0.261
- 0.252
- 0.268
- 0.279
- 0.264
- 0.272
- 0.257
- 0.272
- 0.284
- 0.259
- 0.273
- 0.254
- 0.318
- 0.304
- 0.301
- 0.287
- 0.27
- 0.296
- 0.285
- 0.319
- 0.307
- 0.292
- 0.0
- 0.319
- 0.318
- 0.291
- 0.29
- 0.297
- 0.311
- 0.317
- 0.323
- 0.312
- 0.338
- 0.0
- 0.288
- 0.285
- 0.0
- 0.307
- 0.0
- 0.309
- 0.289
- 0.309
- 0.324
- 0.298
- 0.316
- 0.304
- 0.311
- 0.315
- 0.31
- 0.311
- 0.307
- 0.297
- 0.307
- 0.317
- 0.293
- 0.343
- 0.297
- 0.0
- 0.313
- 0.0
- 0.332
- 0.316
- 0.308
- 0.0
- 0.303
- 0.355
- 0.354
train_loss:
- 3.189
- 3.911
- 3.659
- 3.501
- 3.285
- 3.11
- 3.16
- 3.052
- 2.345
- 2.922
- 2.808
- 2.053
- 2.218
- 2.665
- 2.499
- 2.353
- 2.578
- 2.362
- 2.341
- 2.33
- 2.292
- 1.735
- 2.065
- 2.138
- 1.696
- 2.004
- 1.554
- 2.028
- 1.879
- 1.448
- 1.783
- 1.724
- 1.437
- 1.68
- 1.605
- 1.643
- 1.471
- 1.381
- 1.378
- 1.229
- 1.228
- 1.102
- 1.392
- 1.118
- 0.979
- 1.421
- 1.291
- 1.087
- 1.197
- 1.147
- 1.051
- 1.022
- 1.002
- 1.108
- 0.911
- 1.08
- 1.029
- 0.879
- 0.733
- 0.97
- 0.772
- 0.824
- 0.875
- 0.833
- 0.727
- 0.747
- 0.857
- 0.919
- 0.737
- 0.823
- 0.797
- 0.73
- 0.651
- 0.661
- 0.642
- 0.562
- 0.711
- 0.581
- 0.549
- 0.608
- 0.537
- 0.511
- 0.697
- 0.51
- 0.601
- 0.517
- 0.552
- 0.468
- 0.563
- 0.447
- 0.456
- 0.399
- 0.463
- 0.55
- 0.386
- 0.395
- 0.419
- 0.371
- 0.317
- 0.376
unequal: 0
verbose: 1
