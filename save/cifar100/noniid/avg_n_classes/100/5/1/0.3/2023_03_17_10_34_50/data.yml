avg_train_accuracy: 0.333
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0373
- 0.0904
- 0.114
- 0.1291
- 0.1449
- 0.1557
- 0.156
- 0.1666
- 0.1825
- 0.1876
- 0.1973
- 0.203
- 0.2059
- 0.2051
- 0.2126
- 0.2289
- 0.2308
- 0.2305
- 0.2325
- 0.2399
- 0.2411
- 0.2479
- 0.2489
- 0.2499
- 0.249
- 0.2609
- 0.2603
- 0.2578
- 0.2674
- 0.2665
- 0.267
- 0.2591
- 0.2702
- 0.2778
- 0.281
- 0.2771
- 0.2845
- 0.2858
- 0.2772
- 0.2806
- 0.2902
- 0.2838
- 0.2922
- 0.292
- 0.2978
- 0.2985
- 0.2947
- 0.297
- 0.3022
- 0.2969
- 0.2966
- 0.3039
- 0.3014
- 0.2951
- 0.3088
- 0.3097
- 0.3095
- 0.3113
- 0.3117
- 0.3136
- 0.3119
- 0.3109
- 0.3119
- 0.3142
- 0.3129
- 0.3073
- 0.3171
- 0.3206
- 0.3167
- 0.3173
- 0.3201
- 0.3154
- 0.3197
- 0.3196
- 0.3126
- 0.3221
- 0.3241
- 0.3211
- 0.3233
- 0.3194
- 0.3212
- 0.3217
- 0.3243
- 0.325
- 0.3259
- 0.3248
- 0.3237
- 0.3299
- 0.3249
- 0.3254
- 0.3232
- 0.3263
- 0.3274
- 0.3264
- 0.3262
- 0.33
- 0.3289
- 0.3278
- 0.3304
- 0.3289
test_loss_list:
- 1.8089826154708861
- 1.6703183484077453
- 1.618912823200226
- 1.5837800359725953
- 1.5471069192886353
- 1.5260558581352235
- 1.5076688623428345
- 1.4827669548988343
- 1.464061279296875
- 1.451302673816681
- 1.4437888264656067
- 1.4319657397270202
- 1.4205359721183777
- 1.4175988149642944
- 1.3992417788505553
- 1.3813133144378662
- 1.3785855174064636
- 1.3682532978057862
- 1.359020800590515
- 1.343843491077423
- 1.331320171356201
- 1.3233701419830322
- 1.3200804591178894
- 1.3128732275962829
- 1.3123437929153443
- 1.2958562684059143
- 1.296780939102173
- 1.2937829351425172
- 1.2901684045791626
- 1.2858549737930298
- 1.288846890926361
- 1.3009579110145568
- 1.273370726108551
- 1.2732284331321717
- 1.2602034878730775
- 1.2648340582847595
- 1.2567453861236573
- 1.2552751445770263
- 1.2663050818443298
- 1.2556271862983703
- 1.247584686279297
- 1.2497118186950684
- 1.2353010535240174
- 1.2415678238868713
- 1.2316798305511474
- 1.2334702658653258
- 1.2361158370971679
- 1.2275080823898314
- 1.2253735613822938
- 1.239179105758667
- 1.2288639307022096
- 1.2217139744758605
- 1.225898859500885
- 1.2264116239547729
- 1.218380150794983
- 1.212863085269928
- 1.2106662034988402
- 1.2151991176605224
- 1.2131315898895263
- 1.2159961032867432
- 1.2264627981185914
- 1.2248206782341002
- 1.231386842727661
- 1.2205212283134461
- 1.2228209972381592
- 1.2309064030647279
- 1.2103829550743104
- 1.2100633215904235
- 1.2186148023605348
- 1.2224538707733155
- 1.2181183457374574
- 1.2320479941368103
- 1.2256491684913635
- 1.2298009014129638
- 1.2287160873413085
- 1.2190017914772033
- 1.2087605834007262
- 1.2107255530357361
- 1.2062826609611512
- 1.2066770672798157
- 1.2001308345794677
- 1.205807249546051
- 1.2003486132621766
- 1.2029788947105409
- 1.1959201765060425
- 1.1976978802680969
- 1.1938720726966858
- 1.1940642762184144
- 1.1997636246681214
- 1.2082972502708436
- 1.2139176869392394
- 1.2233356928825379
- 1.2132997274398805
- 1.2050297045707703
- 1.199150595664978
- 1.2038336968421937
- 1.1986244344711303
- 1.21443279504776
- 1.2094432044029235
- 1.206801154613495
train_accuracy:
- 0.05
- 0.085
- 0.103
- 0.116
- 0.133
- 0.202
- 0.153
- 0.0
- 0.146
- 0.164
- 0.163
- 0.152
- 0.225
- 0.0
- 0.182
- 0.239
- 0.195
- 0.217
- 0.233
- 0.242
- 0.201
- 0.217
- 0.269
- 0.23
- 0.0
- 0.255
- 0.23
- 0.0
- 0.277
- 0.296
- 0.258
- 0.261
- 0.268
- 0.265
- 0.255
- 0.266
- 0.26
- 0.236
- 0.0
- 0.0
- 0.291
- 0.0
- 0.298
- 0.295
- 0.276
- 0.255
- 0.276
- 0.0
- 0.27
- 0.275
- 0.0
- 0.295
- 0.296
- 0.252
- 0.286
- 0.312
- 0.283
- 0.316
- 0.31
- 0.309
- 0.29
- 0.298
- 0.289
- 0.311
- 0.333
- 0.299
- 0.321
- 0.316
- 0.301
- 0.283
- 0.313
- 0.301
- 0.334
- 0.343
- 0.253
- 0.314
- 0.305
- 0.328
- 0.326
- 0.322
- 0.0
- 0.311
- 0.316
- 0.287
- 0.321
- 0.311
- 0.0
- 0.325
- 0.292
- 0.301
- 0.305
- 0.279
- 0.0
- 0.289
- 0.0
- 0.29
- 0.347
- 0.306
- 0.292
- 0.333
train_loss:
- 4.296
- 3.851
- 3.609
- 2.643
- 3.321
- 3.232
- 2.421
- 2.373
- 3.026
- 2.867
- 2.782
- 2.775
- 2.605
- 1.989
- 2.507
- 2.595
- 2.384
- 1.926
- 1.84
- 2.339
- 1.773
- 2.181
- 2.096
- 1.668
- 1.503
- 2.034
- 1.829
- 1.551
- 1.768
- 1.382
- 1.581
- 1.22
- 1.777
- 1.625
- 1.666
- 1.285
- 1.503
- 1.429
- 1.035
- 1.052
- 1.381
- 1.1
- 1.263
- 1.389
- 1.531
- 1.273
- 1.116
- 1.038
- 0.991
- 1.093
- 0.948
- 1.011
- 0.976
- 0.996
- 1.075
- 1.15
- 0.787
- 0.881
- 0.946
- 0.829
- 0.75
- 0.887
- 0.702
- 0.875
- 0.795
- 0.89
- 0.746
- 0.829
- 0.614
- 0.653
- 0.764
- 0.659
- 0.692
- 0.697
- 0.705
- 0.561
- 0.636
- 0.572
- 0.682
- 0.52
- 0.538
- 0.633
- 0.599
- 0.589
- 0.539
- 0.499
- 0.505
- 0.438
- 0.528
- 0.473
- 0.461
- 0.433
- 0.534
- 0.469
- 0.411
- 0.422
- 0.406
- 0.373
- 0.331
- 0.381
unequal: 0
verbose: 1
