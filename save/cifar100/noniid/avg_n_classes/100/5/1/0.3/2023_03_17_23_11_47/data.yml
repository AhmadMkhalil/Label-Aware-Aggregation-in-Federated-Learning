avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0446
- 0.0908
- 0.1128
- 0.1302
- 0.143
- 0.153
- 0.1611
- 0.1703
- 0.1787
- 0.1838
- 0.1986
- 0.2038
- 0.2007
- 0.2059
- 0.2104
- 0.2212
- 0.2223
- 0.2233
- 0.2273
- 0.2298
- 0.2394
- 0.242
- 0.2477
- 0.2486
- 0.2478
- 0.2473
- 0.2615
- 0.2572
- 0.2662
- 0.2695
- 0.276
- 0.2731
- 0.2765
- 0.2756
- 0.2791
- 0.2769
- 0.2803
- 0.2821
- 0.2872
- 0.2842
- 0.2889
- 0.2901
- 0.2922
- 0.2937
- 0.2963
- 0.2947
- 0.2957
- 0.2951
- 0.3078
- 0.3002
- 0.2951
- 0.3095
- 0.3045
- 0.3019
- 0.3103
- 0.3054
- 0.3093
- 0.3051
- 0.3116
- 0.3165
- 0.3155
- 0.3076
- 0.3103
- 0.3137
- 0.316
- 0.3161
- 0.3233
- 0.3246
- 0.3227
- 0.3222
- 0.3267
- 0.3205
- 0.3245
- 0.3234
- 0.32
- 0.3237
- 0.3231
- 0.3281
- 0.3182
- 0.3195
- 0.3223
- 0.3289
- 0.3183
- 0.3316
- 0.3308
- 0.3326
- 0.3336
- 0.324
- 0.3342
- 0.3314
- 0.3324
- 0.3282
- 0.3321
- 0.3353
- 0.3325
- 0.3263
- 0.333
- 0.337
- 0.3359
- 0.3339
test_loss_list:
- 1.7932437753677368
- 1.6698042511940003
- 1.6141937780380249
- 1.5754959464073182
- 1.5525190424919129
- 1.5299459409713745
- 1.5032432889938354
- 1.4852407312393188
- 1.4646692895889282
- 1.4453539180755615
- 1.426114683151245
- 1.4201452541351318
- 1.4164934730529786
- 1.4125362205505372
- 1.4067550373077393
- 1.390350685119629
- 1.3805643725395202
- 1.3713432478904723
- 1.36363689661026
- 1.3444898271560668
- 1.3406146574020386
- 1.335416579246521
- 1.331236732006073
- 1.3300956511497497
- 1.3295248818397523
- 1.3105666375160216
- 1.2871892929077149
- 1.2926112008094788
- 1.2770925855636597
- 1.2762771511077882
- 1.2666900539398194
- 1.2682269096374512
- 1.2630217385292053
- 1.2665871667861939
- 1.2713890838623048
- 1.2689823579788209
- 1.2424294471740722
- 1.2382067894935609
- 1.2302380776405335
- 1.2374377608299256
- 1.2287514400482178
- 1.2358077478408813
- 1.2347672200202942
- 1.235569109916687
- 1.2344998741149902
- 1.2268395972251893
- 1.2302008748054505
- 1.226971161365509
- 1.2077343010902404
- 1.2243191838264464
- 1.2225074148178101
- 1.209179973602295
- 1.2205453181266785
- 1.219031000137329
- 1.2154514694213867
- 1.221565947532654
- 1.2219030594825744
- 1.2276240301132202
- 1.220374779701233
- 1.2198560047149658
- 1.2205865502357482
- 1.2334274673461914
- 1.2118994522094726
- 1.2080136442184448
- 1.2073063158988953
- 1.2128055047988893
- 1.2021642470359801
- 1.2038681197166443
- 1.208174455165863
- 1.2165942430496215
- 1.2100501012802125
- 1.2155631875991821
- 1.2068236255645752
- 1.2122570252418519
- 1.202830445766449
- 1.203573031425476
- 1.2087147569656371
- 1.209981255531311
- 1.2120977330207825
- 1.2111312818527222
- 1.2059019136428832
- 1.2040562438964844
- 1.2204303359985351
- 1.199295823574066
- 1.1997946333885192
- 1.1992902255058289
- 1.2026852703094482
- 1.2056391191482545
- 1.191110053062439
- 1.2036679673194886
- 1.2038411426544189
- 1.2069147276878356
- 1.199736816883087
- 1.1948129963874816
- 1.205685977935791
- 1.2158331060409546
- 1.2092188000679016
- 1.2115780878067017
- 1.2153211998939515
- 1.2088549423217774
train_accuracy:
- 0.031
- 0.077
- 0.103
- 0.128
- 0.175
- 0.135
- 0.151
- 0.155
- 0.188
- 0.162
- 0.182
- 0.151
- 0.184
- 0.253
- 0.241
- 0.246
- 0.213
- 0.0
- 0.198
- 0.202
- 0.211
- 0.226
- 0.231
- 0.218
- 0.0
- 0.281
- 0.241
- 0.27
- 0.249
- 0.246
- 0.296
- 0.309
- 0.292
- 0.314
- 0.264
- 0.294
- 0.0
- 0.266
- 0.291
- 0.268
- 0.33
- 0.281
- 0.267
- 0.269
- 0.318
- 0.0
- 0.329
- 0.318
- 0.3
- 0.311
- 0.296
- 0.301
- 0.319
- 0.307
- 0.328
- 0.299
- 0.329
- 0.299
- 0.336
- 0.336
- 0.275
- 0.319
- 0.312
- 0.33
- 0.316
- 0.311
- 0.298
- 0.332
- 0.335
- 0.325
- 0.33
- 0.0
- 0.307
- 0.321
- 0.315
- 0.321
- 0.339
- 0.357
- 0.338
- 0.296
- 0.335
- 0.317
- 0.309
- 0.316
- 0.356
- 0.359
- 0.371
- 0.324
- 0.338
- 0.332
- 0.35
- 0.0
- 0.321
- 0.321
- 0.305
- 0.331
- 0.359
- 0.346
- 0.362
- 0.0
train_loss:
- 4.316
- 3.88
- 3.622
- 3.532
- 3.328
- 2.479
- 2.419
- 2.996
- 2.336
- 2.286
- 2.88
- 2.716
- 2.661
- 2.553
- 2.427
- 2.557
- 1.869
- 1.883
- 2.295
- 1.864
- 2.018
- 2.323
- 2.116
- 2.03
- 1.6
- 1.677
- 1.554
- 1.675
- 1.782
- 1.754
- 1.915
- 1.324
- 1.769
- 1.558
- 1.408
- 1.341
- 1.449
- 1.345
- 1.523
- 1.291
- 1.465
- 1.407
- 1.262
- 1.242
- 1.208
- 1.035
- 1.266
- 1.041
- 1.284
- 1.191
- 0.991
- 1.151
- 1.032
- 1.281
- 1.011
- 0.898
- 0.925
- 0.917
- 1.114
- 0.932
- 0.878
- 0.771
- 0.968
- 0.93
- 0.836
- 0.807
- 0.784
- 0.768
- 0.694
- 0.796
- 0.649
- 0.666
- 0.707
- 0.63
- 0.699
- 0.667
- 0.628
- 0.671
- 0.601
- 0.569
- 0.613
- 0.492
- 0.486
- 0.5
- 0.564
- 0.602
- 0.47
- 0.477
- 0.621
- 0.511
- 0.466
- 0.526
- 0.423
- 0.404
- 0.428
- 0.412
- 0.441
- 0.374
- 0.392
- 0.462
unequal: 0
verbose: 1
