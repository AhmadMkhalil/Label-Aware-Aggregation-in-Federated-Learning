avg_train_accuracy: 0.345
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0416
- 0.0964
- 0.1189
- 0.1344
- 0.147
- 0.1629
- 0.1698
- 0.1772
- 0.1807
- 0.183
- 0.1974
- 0.2043
- 0.2118
- 0.2182
- 0.2198
- 0.2207
- 0.2243
- 0.2275
- 0.2315
- 0.236
- 0.2412
- 0.2417
- 0.2421
- 0.241
- 0.2455
- 0.2501
- 0.2481
- 0.258
- 0.2547
- 0.2549
- 0.2601
- 0.26
- 0.2636
- 0.2584
- 0.2612
- 0.2636
- 0.265
- 0.266
- 0.2712
- 0.2653
- 0.2737
- 0.2751
- 0.2738
- 0.2757
- 0.2716
- 0.2834
- 0.2783
- 0.2802
- 0.2848
- 0.2888
- 0.2879
- 0.2863
- 0.2841
- 0.2858
- 0.2922
- 0.2873
- 0.291
- 0.2876
- 0.2908
- 0.2881
- 0.2921
- 0.2899
- 0.2935
- 0.2982
- 0.2936
- 0.2931
- 0.2969
- 0.2928
- 0.2981
- 0.2955
- 0.2956
- 0.2923
- 0.2991
- 0.2988
- 0.2956
- 0.2972
- 0.2968
- 0.2978
- 0.2955
- 0.3017
- 0.3037
- 0.3019
- 0.3017
- 0.2982
- 0.3024
- 0.3003
- 0.3042
- 0.3031
- 0.3011
- 0.3027
- 0.3015
- 0.2997
- 0.2996
- 0.3024
- 0.3043
- 0.3079
- 0.3031
- 0.3022
- 0.3078
- 0.2973
test_loss_list:
- 1.8105687284469605
- 1.7107192134857179
- 1.6807297658920288
- 1.6530791568756102
- 1.6243954968452454
- 1.5994337034225463
- 1.579761700630188
- 1.5704427790641784
- 1.5572103071212768
- 1.5465776419639587
- 1.5202716374397278
- 1.5140966606140136
- 1.508252878189087
- 1.4935543847084045
- 1.490892083644867
- 1.4898664212226869
- 1.4778901052474975
- 1.479893808364868
- 1.4630218935012818
- 1.4600564336776733
- 1.4699094843864442
- 1.480976026058197
- 1.4621541428565978
- 1.463078031539917
- 1.4592724347114563
- 1.4512958693504334
- 1.4397818207740785
- 1.445888569355011
- 1.4349457025527954
- 1.4192568945884705
- 1.4191559338569641
- 1.4141841340065002
- 1.4108746337890625
- 1.4039954519271851
- 1.3987647318840026
- 1.3926683616638185
- 1.3893359422683715
- 1.3883271598815918
- 1.3893683338165284
- 1.3855665040016174
- 1.3802828145027162
- 1.3857512474060059
- 1.3884247279167174
- 1.3744707489013672
- 1.3694202709197998
- 1.3710857105255128
- 1.3650117063522338
- 1.3558144164085388
- 1.3596400022506714
- 1.3641196370124817
- 1.3674711990356445
- 1.370804750919342
- 1.3620878672599792
- 1.3532083344459533
- 1.3526108360290527
- 1.361183865070343
- 1.3789179635047912
- 1.3803022933006286
- 1.3622654509544372
- 1.3602407264709473
- 1.3485193848609924
- 1.3446957612037658
- 1.333351411819458
- 1.3500545835494995
- 1.3509591841697692
- 1.3587257146835328
- 1.3402491331100463
- 1.3453062200546264
- 1.3610703992843627
- 1.3599326300621033
- 1.3489705634117126
- 1.343204951286316
- 1.3279603362083434
- 1.3410007858276367
- 1.33506356716156
- 1.3370992565155029
- 1.3473004364967347
- 1.3454192066192627
- 1.3438517951965332
- 1.329946436882019
- 1.340762860774994
- 1.3459916353225707
- 1.3491206359863281
- 1.3426925206184388
- 1.3292365527153016
- 1.3272186017036438
- 1.3274936485290527
- 1.3246773338317872
- 1.3313241934776305
- 1.3403040838241578
- 1.3430582308769226
- 1.3414680409431456
- 1.3337810516357422
- 1.3472402215003967
- 1.342333426475525
- 1.3616900849342346
- 1.359730727672577
- 1.3425517344474793
- 1.3398308038711548
- 1.3403077936172485
train_accuracy:
- 0.046
- 0.0
- 0.119
- 0.129
- 0.0
- 0.191
- 0.19
- 0.193
- 0.201
- 0.205
- 0.248
- 0.0
- 0.201
- 0.0
- 0.261
- 0.233
- 0.271
- 0.263
- 0.0
- 0.266
- 0.294
- 0.256
- 0.0
- 0.0
- 0.247
- 0.303
- 0.273
- 0.298
- 0.263
- 0.299
- 0.278
- 0.0
- 0.322
- 0.0
- 0.302
- 0.322
- 0.332
- 0.307
- 0.317
- 0.0
- 0.301
- 0.315
- 0.328
- 0.301
- 0.324
- 0.327
- 0.334
- 0.303
- 0.289
- 0.336
- 0.332
- 0.0
- 0.0
- 0.326
- 0.334
- 0.296
- 0.308
- 0.338
- 0.308
- 0.325
- 0.311
- 0.343
- 0.336
- 0.0
- 0.312
- 0.333
- 0.344
- 0.343
- 0.334
- 0.312
- 0.0
- 0.0
- 0.0
- 0.336
- 0.0
- 0.359
- 0.362
- 0.355
- 0.331
- 0.0
- 0.359
- 0.0
- 0.317
- 0.359
- 0.0
- 0.357
- 0.0
- 0.0
- 0.329
- 0.341
- 0.367
- 0.373
- 0.318
- 0.325
- 0.33
- 0.318
- 0.354
- 0.335
- 0.312
- 0.345
train_loss:
- 2.993
- 3.21
- 3.008
- 2.873
- 2.322
- 2.272
- 2.186
- 2.503
- 2.02
- 1.977
- 1.999
- 1.871
- 2.154
- 1.826
- 2.067
- 2.038
- 1.673
- 1.884
- 1.656
- 1.758
- 2.036
- 1.951
- 1.471
- 1.625
- 1.556
- 1.587
- 1.402
- 1.652
- 1.26
- 1.248
- 1.321
- 1.235
- 1.367
- 1.185
- 1.145
- 1.127
- 1.169
- 1.033
- 1.091
- 1.009
- 1.117
- 1.02
- 1.05
- 0.853
- 0.769
- 1.156
- 0.858
- 0.862
- 0.936
- 0.894
- 0.854
- 0.81
- 0.774
- 0.743
- 0.804
- 0.749
- 0.776
- 0.72
- 0.702
- 0.65
- 0.643
- 0.683
- 0.642
- 0.601
- 0.642
- 0.597
- 0.579
- 0.532
- 0.528
- 0.583
- 0.503
- 0.493
- 0.583
- 0.507
- 0.517
- 0.497
- 0.509
- 0.485
- 0.468
- 0.472
- 0.454
- 0.409
- 0.428
- 0.443
- 0.422
- 0.398
- 0.408
- 0.403
- 0.38
- 0.343
- 0.371
- 0.364
- 0.375
- 0.323
- 0.332
- 0.282
- 0.335
- 0.411
- 0.311
- 0.323
unequal: 0
verbose: 1
