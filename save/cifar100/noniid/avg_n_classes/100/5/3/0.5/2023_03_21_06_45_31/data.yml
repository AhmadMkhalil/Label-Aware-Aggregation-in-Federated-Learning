avg_train_accuracy: 0.349
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0383
- 0.0885
- 0.1106
- 0.136
- 0.1467
- 0.1567
- 0.1692
- 0.1762
- 0.1898
- 0.1914
- 0.1986
- 0.204
- 0.2044
- 0.2174
- 0.2195
- 0.2192
- 0.2218
- 0.2295
- 0.2296
- 0.2243
- 0.232
- 0.2305
- 0.2322
- 0.2348
- 0.2472
- 0.2473
- 0.2508
- 0.2434
- 0.2502
- 0.2512
- 0.2516
- 0.2574
- 0.2616
- 0.2604
- 0.2609
- 0.2631
- 0.2598
- 0.2644
- 0.2664
- 0.2693
- 0.2654
- 0.2632
- 0.2704
- 0.2683
- 0.2676
- 0.2723
- 0.2713
- 0.2706
- 0.2715
- 0.2824
- 0.2788
- 0.2795
- 0.2763
- 0.2798
- 0.2772
- 0.2773
- 0.2775
- 0.2826
- 0.2825
- 0.2802
- 0.2857
- 0.2819
- 0.2842
- 0.2868
- 0.2869
- 0.2838
- 0.2836
- 0.2869
- 0.2874
- 0.2889
- 0.2843
- 0.2846
- 0.2893
- 0.2881
- 0.2907
- 0.2875
- 0.2941
- 0.287
- 0.2887
- 0.2902
- 0.2954
- 0.294
- 0.2876
- 0.2937
- 0.2956
- 0.2923
- 0.3004
- 0.2952
- 0.2933
- 0.2917
- 0.2932
- 0.2973
- 0.2948
- 0.2928
- 0.2946
- 0.2914
- 0.2949
- 0.2975
- 0.2961
- 0.2984
test_loss_list:
- 1.8151112842559813
- 1.7233479595184327
- 1.6836082434654236
- 1.656585943698883
- 1.6296370458602905
- 1.6162172770500183
- 1.601646134853363
- 1.5832219266891479
- 1.5674017667770386
- 1.5547633528709413
- 1.5445987105369567
- 1.536720836162567
- 1.5243743872642517
- 1.512804617881775
- 1.5132953906059265
- 1.491443395614624
- 1.4760210084915162
- 1.4707728219032288
- 1.459560856819153
- 1.4568790316581726
- 1.4472406435012817
- 1.4432309556007386
- 1.4435869479179382
- 1.4395534777641297
- 1.4315355944633483
- 1.4207176399230956
- 1.429719593524933
- 1.419499125480652
- 1.410243606567383
- 1.40441721200943
- 1.4140545988082887
- 1.4130028319358825
- 1.4225860190391542
- 1.422493917942047
- 1.4114641880989074
- 1.4127264952659606
- 1.4204080533981323
- 1.418559331893921
- 1.4100668621063233
- 1.3985720157623291
- 1.3919517803192138
- 1.3724512338638306
- 1.3566272258758545
- 1.366926293373108
- 1.3662689661979674
- 1.3706723380088806
- 1.3720669054985046
- 1.3640956211090087
- 1.3695373797416688
- 1.3698038983345031
- 1.3675991630554198
- 1.3584463357925416
- 1.3588906955718993
- 1.3665824270248412
- 1.3719975924491883
- 1.3656477093696595
- 1.3594056487083435
- 1.3659286665916444
- 1.3585778093338012
- 1.3603695964813232
- 1.3754265308380127
- 1.3711391305923462
- 1.3669120812416076
- 1.3598944759368896
- 1.3617192935943603
- 1.3542151594161986
- 1.3487591075897216
- 1.3438453960418701
- 1.3560485434532166
- 1.370642433166504
- 1.3537421607971192
- 1.355642125606537
- 1.3658337926864623
- 1.3715101504325866
- 1.373807988166809
- 1.3559716939926147
- 1.3520624876022338
- 1.3507781958580016
- 1.3725596594810485
- 1.3614073204994201
- 1.3732631993293762
- 1.3669383645057678
- 1.3602527403831481
- 1.3662771773338318
- 1.3555289435386657
- 1.3532038450241088
- 1.3670665454864501
- 1.3504248595237731
- 1.3560300540924073
- 1.3512100672721863
- 1.3466923117637635
- 1.3506241416931153
- 1.3532496547698976
- 1.3492165184020997
- 1.3418528938293457
- 1.337480673789978
- 1.3457707643508912
- 1.3498574852943421
- 1.372721221446991
- 1.3773222613334655
train_accuracy:
- 0.036
- 0.0
- 0.099
- 0.0
- 0.138
- 0.13
- 0.0
- 0.183
- 0.191
- 0.0
- 0.0
- 0.205
- 0.214
- 0.0
- 0.212
- 0.0
- 0.239
- 0.247
- 0.0
- 0.0
- 0.0
- 0.21
- 0.0
- 0.235
- 0.285
- 0.0
- 0.264
- 0.0
- 0.286
- 0.218
- 0.271
- 0.261
- 0.3
- 0.247
- 0.262
- 0.272
- 0.0
- 0.292
- 0.273
- 0.0
- 0.0
- 0.284
- 0.286
- 0.282
- 0.0
- 0.311
- 0.0
- 0.311
- 0.0
- 0.31
- 0.271
- 0.0
- 0.0
- 0.326
- 0.316
- 0.334
- 0.298
- 0.287
- 0.0
- 0.0
- 0.339
- 0.335
- 0.303
- 0.285
- 0.341
- 0.324
- 0.0
- 0.28
- 0.285
- 0.322
- 0.304
- 0.311
- 0.303
- 0.346
- 0.339
- 0.0
- 0.312
- 0.338
- 0.316
- 0.0
- 0.326
- 0.33
- 0.326
- 0.0
- 0.0
- 0.311
- 0.355
- 0.303
- 0.343
- 0.0
- 0.301
- 0.332
- 0.334
- 0.35
- 0.325
- 0.348
- 0.373
- 0.318
- 0.317
- 0.349
train_loss:
- 3.639
- 2.173
- 3.0
- 2.913
- 2.391
- 2.641
- 2.557
- 2.136
- 2.415
- 2.034
- 2.244
- 2.25
- 1.841
- 2.206
- 1.993
- 1.455
- 1.798
- 1.73
- 1.574
- 1.254
- 1.408
- 1.488
- 1.202
- 1.307
- 1.614
- 1.385
- 1.452
- 1.205
- 1.349
- 1.223
- 1.448
- 1.452
- 1.568
- 1.233
- 1.191
- 1.244
- 1.162
- 1.153
- 1.22
- 1.012
- 0.914
- 0.892
- 1.019
- 0.895
- 0.91
- 1.018
- 0.942
- 0.866
- 0.768
- 0.85
- 0.764
- 0.88
- 0.834
- 0.786
- 0.793
- 0.678
- 0.664
- 0.804
- 0.758
- 0.651
- 0.743
- 0.724
- 0.596
- 0.604
- 0.732
- 0.657
- 0.614
- 0.598
- 0.562
- 0.597
- 0.562
- 0.507
- 0.516
- 0.538
- 0.515
- 0.473
- 0.511
- 0.514
- 0.499
- 0.499
- 0.447
- 0.466
- 0.466
- 0.426
- 0.468
- 0.428
- 0.392
- 0.447
- 0.397
- 0.389
- 0.402
- 0.374
- 0.327
- 0.39
- 0.414
- 0.371
- 0.307
- 0.34
- 0.299
- 0.283
unequal: 0
verbose: 1
