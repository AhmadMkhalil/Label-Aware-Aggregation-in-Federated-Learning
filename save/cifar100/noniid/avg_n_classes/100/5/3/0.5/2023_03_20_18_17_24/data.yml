avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0454
- 0.0932
- 0.1167
- 0.1266
- 0.1436
- 0.1543
- 0.1671
- 0.1727
- 0.1785
- 0.1817
- 0.1978
- 0.1907
- 0.2076
- 0.2073
- 0.2117
- 0.215
- 0.2193
- 0.2243
- 0.2264
- 0.2258
- 0.2283
- 0.2355
- 0.2398
- 0.2379
- 0.2442
- 0.2442
- 0.245
- 0.248
- 0.2541
- 0.2469
- 0.2543
- 0.261
- 0.2606
- 0.2622
- 0.2665
- 0.2684
- 0.266
- 0.268
- 0.2676
- 0.2726
- 0.2736
- 0.2763
- 0.276
- 0.2725
- 0.2739
- 0.279
- 0.2809
- 0.2813
- 0.2828
- 0.2806
- 0.2839
- 0.2848
- 0.2871
- 0.2843
- 0.2852
- 0.284
- 0.2892
- 0.2891
- 0.2885
- 0.2874
- 0.2871
- 0.2878
- 0.2905
- 0.2935
- 0.2924
- 0.2901
- 0.2899
- 0.2895
- 0.2915
- 0.2929
- 0.2949
- 0.2956
- 0.29
- 0.2984
- 0.2975
- 0.2969
- 0.2951
- 0.2985
- 0.2983
- 0.2906
- 0.2931
- 0.2989
- 0.2972
- 0.3
- 0.3005
- 0.2969
- 0.2955
- 0.2992
- 0.3002
- 0.2986
- 0.3009
- 0.2997
- 0.3028
- 0.3026
- 0.3017
- 0.3026
- 0.3038
- 0.3009
- 0.3035
- 0.302
test_loss_list:
- 1.8104462623596191
- 1.7058411741256714
- 1.675340929031372
- 1.646497449874878
- 1.6186716699600219
- 1.607713074684143
- 1.595128185749054
- 1.585298433303833
- 1.5705279183387757
- 1.5533770370483397
- 1.5492943835258484
- 1.5474732685089112
- 1.5377955985069276
- 1.536866183280945
- 1.5342139792442322
- 1.5296000123023987
- 1.5215038228034974
- 1.4992298102378845
- 1.4875478982925414
- 1.4728342747688294
- 1.4665242433547974
- 1.4698413372039796
- 1.4790173649787903
- 1.466072247028351
- 1.4446540093421936
- 1.4541486310958862
- 1.4576944088935853
- 1.4411437106132508
- 1.4376997613906861
- 1.4303538131713867
- 1.4222679781913756
- 1.4104591584205628
- 1.4055277037620544
- 1.4031802916526794
- 1.4056312108039857
- 1.4089843034744263
- 1.3987990760803222
- 1.4075042390823365
- 1.409342257976532
- 1.4219330835342407
- 1.4030085110664368
- 1.4053415036201478
- 1.4125329494476317
- 1.4022952246665954
- 1.4088527131080628
- 1.392020206451416
- 1.3956873083114625
- 1.3915869092941284
- 1.3797674584388733
- 1.3674330377578736
- 1.3731700944900513
- 1.37724107503891
- 1.396091468334198
- 1.379277493953705
- 1.3723556804656982
- 1.3810557842254638
- 1.3853521513938905
- 1.3728807711601256
- 1.3689898538589478
- 1.3656224012374878
- 1.3694702911376953
- 1.3602278184890748
- 1.355846755504608
- 1.3639101910591125
- 1.3546172046661378
- 1.356048698425293
- 1.3640531921386718
- 1.3718254661560059
- 1.3600913071632386
- 1.3500789284706116
- 1.355658266544342
- 1.365540566444397
- 1.3550179290771485
- 1.3682888221740723
- 1.359118528366089
- 1.3538521027565003
- 1.3495200228691102
- 1.3459319019317626
- 1.357594449520111
- 1.3627893590927125
- 1.3521337294578553
- 1.3393617296218872
- 1.3418169593811036
- 1.3403579139709472
- 1.3513646030426025
- 1.3553773331642152
- 1.3512783002853395
- 1.3451511311531066
- 1.3536352634429931
- 1.3513944959640503
- 1.3474841141700744
- 1.35253470659256
- 1.3587132811546325
- 1.3577828621864318
- 1.3644519019126893
- 1.351488833427429
- 1.3494679021835327
- 1.3416616415977478
- 1.3493729639053345
- 1.3631503510475158
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.167
- 0.0
- 0.16
- 0.207
- 0.0
- 0.21
- 0.239
- 0.211
- 0.208
- 0.222
- 0.241
- 0.208
- 0.211
- 0.261
- 0.245
- 0.244
- 0.24
- 0.268
- 0.229
- 0.0
- 0.0
- 0.261
- 0.28
- 0.277
- 0.284
- 0.296
- 0.254
- 0.0
- 0.0
- 0.0
- 0.293
- 0.275
- 0.0
- 0.328
- 0.283
- 0.299
- 0.0
- 0.293
- 0.299
- 0.288
- 0.294
- 0.0
- 0.277
- 0.307
- 0.293
- 0.0
- 0.0
- 0.299
- 0.29
- 0.0
- 0.297
- 0.0
- 0.345
- 0.289
- 0.295
- 0.321
- 0.0
- 0.305
- 0.304
- 0.313
- 0.0
- 0.311
- 0.334
- 0.338
- 0.326
- 0.328
- 0.329
- 0.335
- 0.33
- 0.292
- 0.35
- 0.0
- 0.335
- 0.339
- 0.336
- 0.336
- 0.33
- 0.331
- 0.331
- 0.0
- 0.323
- 0.0
- 0.333
- 0.335
- 0.338
- 0.332
- 0.326
- 0.0
- 0.299
- 0.335
- 0.3
- 0.322
- 0.355
- 0.0
- 0.346
- 0.0
train_loss:
- 3.573
- 2.166
- 2.965
- 1.97
- 2.378
- 2.677
- 2.536
- 2.481
- 2.081
- 2.016
- 2.298
- 1.883
- 2.122
- 2.021
- 1.972
- 1.977
- 1.95
- 1.694
- 1.629
- 1.591
- 1.473
- 1.693
- 1.83
- 1.431
- 1.453
- 1.463
- 1.511
- 1.379
- 1.435
- 1.251
- 1.313
- 1.247
- 1.148
- 1.164
- 1.095
- 1.207
- 1.057
- 1.103
- 1.138
- 1.248
- 0.968
- 1.064
- 0.974
- 0.861
- 0.938
- 0.894
- 0.889
- 0.966
- 0.877
- 0.804
- 0.848
- 0.846
- 0.834
- 0.755
- 0.751
- 0.742
- 0.706
- 0.717
- 0.706
- 0.643
- 0.609
- 0.65
- 0.584
- 0.672
- 0.577
- 0.6
- 0.585
- 0.577
- 0.575
- 0.615
- 0.554
- 0.544
- 0.527
- 0.503
- 0.508
- 0.487
- 0.523
- 0.463
- 0.454
- 0.427
- 0.412
- 0.481
- 0.48
- 0.425
- 0.413
- 0.367
- 0.378
- 0.419
- 0.401
- 0.383
- 0.371
- 0.386
- 0.37
- 0.327
- 0.354
- 0.371
- 0.329
- 0.361
- 0.348
- 0.281
unequal: 0
verbose: 1
