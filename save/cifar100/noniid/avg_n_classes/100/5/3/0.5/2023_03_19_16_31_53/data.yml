avg_train_accuracy: 0.326
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0465
- 0.0963
- 0.1184
- 0.135
- 0.1527
- 0.1631
- 0.1691
- 0.1771
- 0.1879
- 0.1922
- 0.1955
- 0.2074
- 0.2051
- 0.2156
- 0.2185
- 0.2223
- 0.2224
- 0.2247
- 0.2342
- 0.2307
- 0.2415
- 0.2393
- 0.2449
- 0.2421
- 0.2531
- 0.2495
- 0.2523
- 0.2594
- 0.2505
- 0.2586
- 0.2632
- 0.2664
- 0.2686
- 0.2687
- 0.267
- 0.2678
- 0.2769
- 0.2754
- 0.2685
- 0.2716
- 0.2819
- 0.2763
- 0.281
- 0.2812
- 0.283
- 0.2797
- 0.2825
- 0.2881
- 0.2851
- 0.2905
- 0.2908
- 0.2924
- 0.2959
- 0.2845
- 0.2898
- 0.2947
- 0.2974
- 0.2961
- 0.3003
- 0.2985
- 0.3018
- 0.3004
- 0.2984
- 0.2932
- 0.2991
- 0.2965
- 0.3015
- 0.2998
- 0.2966
- 0.2979
- 0.3017
- 0.2995
- 0.2986
- 0.3026
- 0.3034
- 0.3047
- 0.3026
- 0.3043
- 0.2994
- 0.3049
- 0.3033
- 0.3032
- 0.3028
- 0.3019
- 0.3034
- 0.3059
- 0.3017
- 0.3051
- 0.3073
- 0.3041
- 0.3074
- 0.3075
- 0.3066
- 0.2994
- 0.304
- 0.3061
- 0.3032
- 0.3056
- 0.3061
- 0.3087
test_loss_list:
- 1.8177477836608886
- 1.7159096336364745
- 1.6796734189987184
- 1.6432834315299987
- 1.6241054844856262
- 1.605798637866974
- 1.5891655611991882
- 1.588525264263153
- 1.588819534778595
- 1.5655864763259888
- 1.5457958459854126
- 1.5482940888404846
- 1.5345030784606934
- 1.5384159207344055
- 1.5183717346191405
- 1.5116416454315185
- 1.4991361284255982
- 1.4862495517730714
- 1.4688845777511597
- 1.4752294516563416
- 1.4670108199119567
- 1.4622851729393005
- 1.4729576587677002
- 1.4606302905082702
- 1.4544595074653626
- 1.4372580432891846
- 1.4366876244544984
- 1.4336750745773315
- 1.4230749082565308
- 1.4042621326446534
- 1.4137480425834656
- 1.4095490741729737
- 1.4005243396759033
- 1.3968906569480897
- 1.4051088070869446
- 1.3906031823158265
- 1.4020699596405028
- 1.3928999853134156
- 1.3840489315986633
- 1.3666482615470885
- 1.3684696388244628
- 1.3703559684753417
- 1.368700499534607
- 1.3779259204864502
- 1.3796176242828369
- 1.3908869981765748
- 1.375976459980011
- 1.376428072452545
- 1.3694195342063904
- 1.357257068157196
- 1.3463919734954835
- 1.346952316761017
- 1.3547697901725768
- 1.354953191280365
- 1.3452665305137634
- 1.3477106070518494
- 1.3592355942726135
- 1.3508050990104676
- 1.3491639709472656
- 1.3539958596229553
- 1.3684182167053223
- 1.3744732880592345
- 1.3682426643371581
- 1.370696303844452
- 1.3601335597038269
- 1.353477759361267
- 1.3586954402923583
- 1.3519340062141418
- 1.349228482246399
- 1.344949414730072
- 1.3540595293045044
- 1.3600062704086304
- 1.3663943600654602
- 1.3664261507987976
- 1.3604334378242493
- 1.3807574224472046
- 1.3717877411842345
- 1.3698264980316162
- 1.3689721488952638
- 1.3615887880325317
- 1.3487891554832458
- 1.359676377773285
- 1.350972683429718
- 1.3597162866592407
- 1.351870129108429
- 1.351776053905487
- 1.3615322089195252
- 1.3536892342567444
- 1.357654116153717
- 1.3453572082519532
- 1.3557466959953308
- 1.359066457748413
- 1.3465551018714905
- 1.3551818895339967
- 1.3720446038246155
- 1.363736526966095
- 1.3517756748199463
- 1.3396398735046386
- 1.347898097038269
- 1.3392980098724365
train_accuracy:
- 0.0
- 0.116
- 0.0
- 0.158
- 0.0
- 0.167
- 0.175
- 0.177
- 0.197
- 0.214
- 0.213
- 0.253
- 0.233
- 0.259
- 0.255
- 0.211
- 0.0
- 0.219
- 0.267
- 0.217
- 0.261
- 0.242
- 0.281
- 0.27
- 0.245
- 0.0
- 0.291
- 0.249
- 0.0
- 0.267
- 0.309
- 0.277
- 0.253
- 0.288
- 0.0
- 0.274
- 0.292
- 0.0
- 0.285
- 0.0
- 0.295
- 0.0
- 0.311
- 0.309
- 0.298
- 0.0
- 0.315
- 0.311
- 0.302
- 0.311
- 0.0
- 0.311
- 0.33
- 0.312
- 0.307
- 0.32
- 0.325
- 0.0
- 0.364
- 0.0
- 0.319
- 0.308
- 0.342
- 0.0
- 0.0
- 0.319
- 0.322
- 0.312
- 0.0
- 0.334
- 0.331
- 0.314
- 0.311
- 0.0
- 0.328
- 0.332
- 0.0
- 0.325
- 0.326
- 0.337
- 0.326
- 0.338
- 0.357
- 0.0
- 0.366
- 0.0
- 0.334
- 0.32
- 0.336
- 0.345
- 0.348
- 0.341
- 0.335
- 0.0
- 0.339
- 0.349
- 0.0
- 0.329
- 0.338
- 0.326
train_loss:
- 3.651
- 2.705
- 2.545
- 1.971
- 2.819
- 2.276
- 2.142
- 2.931
- 2.737
- 2.104
- 1.975
- 2.643
- 1.933
- 2.441
- 1.825
- 2.088
- 1.709
- 1.72
- 1.644
- 1.829
- 1.838
- 1.484
- 1.935
- 1.517
- 1.717
- 1.228
- 1.506
- 1.492
- 1.162
- 1.293
- 1.388
- 1.411
- 1.261
- 1.234
- 1.32
- 0.994
- 1.433
- 1.105
- 0.956
- 0.874
- 1.176
- 0.89
- 1.049
- 1.037
- 1.059
- 0.985
- 0.956
- 0.936
- 0.927
- 0.865
- 0.76
- 0.852
- 0.808
- 0.688
- 0.821
- 0.808
- 0.784
- 0.724
- 0.753
- 0.686
- 0.71
- 0.744
- 0.698
- 0.646
- 0.655
- 0.657
- 0.594
- 0.624
- 0.585
- 0.577
- 0.576
- 0.528
- 0.503
- 0.506
- 0.517
- 0.491
- 0.495
- 0.509
- 0.487
- 0.472
- 0.454
- 0.406
- 0.493
- 0.422
- 0.473
- 0.425
- 0.355
- 0.425
- 0.392
- 0.418
- 0.429
- 0.361
- 0.443
- 0.404
- 0.291
- 0.388
- 0.406
- 0.374
- 0.31
- 0.386
unequal: 0
verbose: 1
