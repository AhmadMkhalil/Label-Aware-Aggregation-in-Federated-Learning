avg_train_accuracy: 0.409
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0486
- 0.0998
- 0.1236
- 0.141
- 0.1563
- 0.1664
- 0.1692
- 0.1812
- 0.1809
- 0.1897
- 0.1915
- 0.1973
- 0.2025
- 0.2051
- 0.2101
- 0.2159
- 0.2176
- 0.2191
- 0.2253
- 0.2292
- 0.2347
- 0.2349
- 0.2387
- 0.2418
- 0.2484
- 0.2478
- 0.2494
- 0.2538
- 0.2486
- 0.2552
- 0.2596
- 0.2593
- 0.2591
- 0.2652
- 0.2674
- 0.2706
- 0.2692
- 0.2711
- 0.2731
- 0.2733
- 0.2739
- 0.2705
- 0.2758
- 0.2748
- 0.2768
- 0.2779
- 0.2793
- 0.281
- 0.2799
- 0.2845
- 0.2811
- 0.2836
- 0.2824
- 0.2853
- 0.285
- 0.2877
- 0.2843
- 0.2888
- 0.2906
- 0.2849
- 0.2897
- 0.2907
- 0.2936
- 0.2924
- 0.2891
- 0.2874
- 0.2913
- 0.292
- 0.2883
- 0.2972
- 0.2934
- 0.2955
- 0.2958
- 0.2975
- 0.2959
- 0.3005
- 0.2912
- 0.2934
- 0.2911
- 0.2973
- 0.2968
- 0.2912
- 0.2949
- 0.2992
- 0.2942
- 0.2981
- 0.2993
- 0.2999
- 0.2942
- 0.2986
- 0.2987
- 0.2986
- 0.3021
- 0.2963
- 0.2991
- 0.2991
- 0.3
- 0.301
- 0.2997
- 0.2993
test_loss_list:
- 1.8088358926773072
- 1.7165668296813965
- 1.6816207194328308
- 1.655765929222107
- 1.6327287483215331
- 1.6171723651885985
- 1.6053701972961425
- 1.6039852499961853
- 1.5823548173904418
- 1.5615937209129334
- 1.5461564898490905
- 1.5284477853775025
- 1.5229395532608032
- 1.5267991995811463
- 1.5190155005455017
- 1.5067551851272583
- 1.5072270011901856
- 1.4920561408996582
- 1.4774717617034911
- 1.468529100418091
- 1.466806995868683
- 1.4566061329841613
- 1.439782886505127
- 1.4401181769371032
- 1.4383576369285584
- 1.4410494351387024
- 1.438945972919464
- 1.4288974213600159
- 1.4184052729606629
- 1.4139296793937683
- 1.4205108499526977
- 1.4100302076339721
- 1.4131197834014892
- 1.3989123511314392
- 1.4005365014076232
- 1.4024074411392211
- 1.38750226020813
- 1.383677294254303
- 1.3839937853813171
- 1.3804311656951904
- 1.373959927558899
- 1.3729878234863282
- 1.3787310552597045
- 1.3744972658157348
- 1.3798319625854492
- 1.3722999835014342
- 1.3762116575241088
- 1.380215003490448
- 1.3822458171844483
- 1.3710029768943786
- 1.366735680103302
- 1.3597394943237304
- 1.3633026313781738
- 1.3613274240493773
- 1.3689923238754274
- 1.3576214170455934
- 1.362587342262268
- 1.366666660308838
- 1.3655269598960877
- 1.3746810531616211
- 1.3647188472747802
- 1.367197299003601
- 1.3866272282600403
- 1.379214563369751
- 1.3706552124023437
- 1.360451090335846
- 1.3750350952148438
- 1.387516324520111
- 1.3652781891822814
- 1.3510480451583862
- 1.3515528059005737
- 1.3550648140907287
- 1.3488662362098693
- 1.3564834856987
- 1.3523335933685303
- 1.3722556853294372
- 1.3608483624458314
- 1.3618561220169068
- 1.3645328044891358
- 1.3476360034942627
- 1.3545268511772155
- 1.3545349669456481
- 1.3499495530128478
- 1.3472057747840882
- 1.3502004504203797
- 1.3586879229545594
- 1.35457186460495
- 1.3604568219184876
- 1.345335624217987
- 1.3398098921775818
- 1.3454326176643372
- 1.3335464692115784
- 1.3441477155685424
- 1.3530932140350342
- 1.3512956833839416
- 1.3581067943572998
- 1.3498121762275697
- 1.3459642267227172
- 1.3412255144119263
- 1.3352843356132507
train_accuracy:
- 0.057
- 0.0
- 0.147
- 0.146
- 0.16
- 0.193
- 0.187
- 0.189
- 0.199
- 0.0
- 0.203
- 0.219
- 0.225
- 0.222
- 0.257
- 0.0
- 0.248
- 0.217
- 0.0
- 0.0
- 0.0
- 0.25
- 0.0
- 0.0
- 0.0
- 0.311
- 0.271
- 0.258
- 0.0
- 0.263
- 0.278
- 0.0
- 0.281
- 0.283
- 0.266
- 0.265
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.273
- 0.285
- 0.344
- 0.302
- 0.31
- 0.358
- 0.293
- 0.349
- 0.281
- 0.289
- 0.0
- 0.316
- 0.0
- 0.0
- 0.306
- 0.349
- 0.321
- 0.0
- 0.358
- 0.305
- 0.336
- 0.357
- 0.0
- 0.29
- 0.324
- 0.348
- 0.0
- 0.384
- 0.326
- 0.385
- 0.329
- 0.0
- 0.32
- 0.39
- 0.386
- 0.0
- 0.31
- 0.321
- 0.0
- 0.389
- 0.294
- 0.0
- 0.334
- 0.295
- 0.335
- 0.0
- 0.0
- 0.0
- 0.299
- 0.319
- 0.338
- 0.291
- 0.0
- 0.332
- 0.331
- 0.0
- 0.409
train_loss:
- 2.951
- 3.175
- 3.002
- 2.42
- 2.752
- 2.604
- 2.541
- 2.842
- 1.729
- 2.025
- 1.955
- 1.934
- 2.147
- 2.063
- 2.032
- 1.731
- 1.883
- 1.611
- 1.632
- 1.505
- 1.695
- 1.5
- 1.293
- 1.646
- 1.634
- 1.484
- 1.329
- 1.291
- 1.13
- 1.424
- 1.35
- 1.187
- 1.136
- 1.078
- 1.293
- 1.19
- 1.075
- 1.039
- 1.001
- 1.042
- 0.984
- 0.894
- 0.979
- 0.945
- 0.983
- 0.833
- 0.876
- 0.952
- 0.856
- 0.831
- 0.805
- 0.789
- 0.729
- 0.721
- 0.768
- 0.725
- 0.687
- 0.737
- 0.689
- 0.673
- 0.66
- 0.61
- 0.634
- 0.635
- 0.572
- 0.571
- 0.561
- 0.574
- 0.566
- 0.557
- 0.51
- 0.52
- 0.527
- 0.482
- 0.51
- 0.458
- 0.49
- 0.449
- 0.441
- 0.469
- 0.415
- 0.428
- 0.421
- 0.434
- 0.43
- 0.399
- 0.397
- 0.379
- 0.434
- 0.396
- 0.356
- 0.407
- 0.331
- 0.346
- 0.334
- 0.321
- 0.34
- 0.352
- 0.344
- 0.351
unequal: 0
verbose: 1
