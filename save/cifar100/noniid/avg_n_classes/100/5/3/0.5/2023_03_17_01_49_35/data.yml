avg_train_accuracy: 0.342
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.038
- 0.0901
- 0.1137
- 0.1347
- 0.1482
- 0.1524
- 0.1669
- 0.1723
- 0.1807
- 0.1852
- 0.1912
- 0.1942
- 0.2008
- 0.206
- 0.2113
- 0.2176
- 0.2188
- 0.227
- 0.2298
- 0.2264
- 0.2359
- 0.2356
- 0.2364
- 0.2389
- 0.2407
- 0.2401
- 0.2436
- 0.2536
- 0.2536
- 0.2528
- 0.2557
- 0.2593
- 0.2601
- 0.2609
- 0.2618
- 0.2589
- 0.261
- 0.2664
- 0.2608
- 0.2634
- 0.2691
- 0.2648
- 0.2711
- 0.2728
- 0.2755
- 0.2743
- 0.2781
- 0.2786
- 0.2706
- 0.2814
- 0.2838
- 0.2791
- 0.2825
- 0.2889
- 0.2853
- 0.2823
- 0.284
- 0.289
- 0.287
- 0.2805
- 0.2831
- 0.2826
- 0.2824
- 0.2852
- 0.2836
- 0.2925
- 0.2879
- 0.2848
- 0.2948
- 0.2888
- 0.2928
- 0.2931
- 0.2997
- 0.2945
- 0.2969
- 0.2995
- 0.2928
- 0.291
- 0.2976
- 0.2954
- 0.2964
- 0.2978
- 0.2941
- 0.2932
- 0.2953
- 0.2993
- 0.2982
- 0.3014
- 0.2963
- 0.3008
- 0.2931
- 0.299
- 0.3018
- 0.3021
- 0.2993
- 0.3018
- 0.2996
- 0.299
- 0.2957
- 0.3007
test_loss_list:
- 1.8202841520309447
- 1.7196766901016236
- 1.6803501391410827
- 1.6556044054031371
- 1.643362638950348
- 1.6142856240272523
- 1.6012743830680847
- 1.5952395176887513
- 1.5763959312438964
- 1.560179693698883
- 1.5380367755889892
- 1.5256601881980896
- 1.517044379711151
- 1.5149775314331055
- 1.5230353808403014
- 1.5090725684165955
- 1.5033154797554016
- 1.5000988674163818
- 1.5068798804283141
- 1.4952398800849915
- 1.4938608193397522
- 1.4796769762039184
- 1.4674179720878602
- 1.461051414012909
- 1.4641167116165161
- 1.4375447130203247
- 1.440630588531494
- 1.4299044036865234
- 1.41629789352417
- 1.4269829058647157
- 1.4138530349731446
- 1.4177164769172668
- 1.420598509311676
- 1.40517715215683
- 1.40211745262146
- 1.4002756476402283
- 1.3975626158714294
- 1.3986940240859986
- 1.3980559206008911
- 1.3944237446784973
- 1.3907525873184203
- 1.3780504083633422
- 1.3676519322395324
- 1.3769034504890443
- 1.3616865277290344
- 1.3722552967071533
- 1.3616611170768738
- 1.3599979925155639
- 1.3733894586563111
- 1.3554206657409669
- 1.3731790351867676
- 1.3665923166275025
- 1.3717541885375977
- 1.36995774269104
- 1.374766812324524
- 1.3716346716880798
- 1.3622204399108886
- 1.365298044681549
- 1.3552405428886414
- 1.3654957604408264
- 1.3567704939842224
- 1.3562501358985901
- 1.3509370636940004
- 1.3506305956840514
- 1.3460953283309935
- 1.3457019352912902
- 1.3444231176376342
- 1.3464322471618653
- 1.3244664216041564
- 1.3476446413993834
- 1.3321025276184082
- 1.3439903306961059
- 1.350290117263794
- 1.345486617088318
- 1.3428729176521301
- 1.3539810299873352
- 1.3562013053894042
- 1.3469297528266906
- 1.343863663673401
- 1.3385586500167848
- 1.3443542289733887
- 1.343351833820343
- 1.3502580142021179
- 1.340938730239868
- 1.3391963648796081
- 1.3568816995620727
- 1.366322500705719
- 1.3576224493980407
- 1.3606558561325073
- 1.3573649287223817
- 1.3559957551956177
- 1.348312201499939
- 1.3475441884994508
- 1.355822992324829
- 1.3579547834396362
- 1.350373079776764
- 1.3439085674285889
- 1.3407120108604431
- 1.3271743631362916
- 1.333731005191803
train_accuracy:
- 0.053
- 0.11
- 0.0
- 0.146
- 0.0
- 0.0
- 0.195
- 0.184
- 0.163
- 0.0
- 0.0
- 0.212
- 0.0
- 0.0
- 0.194
- 0.0
- 0.238
- 0.202
- 0.244
- 0.241
- 0.254
- 0.0
- 0.0
- 0.296
- 0.274
- 0.0
- 0.259
- 0.289
- 0.0
- 0.231
- 0.284
- 0.299
- 0.285
- 0.333
- 0.271
- 0.312
- 0.0
- 0.303
- 0.0
- 0.323
- 0.306
- 0.306
- 0.0
- 0.324
- 0.25
- 0.328
- 0.0
- 0.313
- 0.318
- 0.265
- 0.261
- 0.0
- 0.326
- 0.0
- 0.0
- 0.304
- 0.341
- 0.334
- 0.0
- 0.0
- 0.0
- 0.321
- 0.0
- 0.366
- 0.316
- 0.0
- 0.0
- 0.332
- 0.383
- 0.336
- 0.276
- 0.277
- 0.327
- 0.329
- 0.304
- 0.327
- 0.0
- 0.0
- 0.0
- 0.0
- 0.326
- 0.309
- 0.287
- 0.324
- 0.29
- 0.348
- 0.332
- 0.0
- 0.338
- 0.0
- 0.334
- 0.0
- 0.344
- 0.344
- 0.327
- 0.366
- 0.0
- 0.365
- 0.345
- 0.342
train_loss:
- 3.643
- 2.202
- 2.528
- 2.875
- 2.758
- 2.282
- 2.588
- 2.497
- 2.11
- 1.979
- 1.989
- 1.913
- 1.822
- 2.13
- 2.35
- 1.681
- 1.958
- 1.933
- 2.064
- 1.579
- 2.029
- 1.491
- 1.42
- 1.666
- 1.501
- 1.225
- 1.491
- 1.513
- 1.367
- 1.394
- 1.234
- 1.314
- 1.226
- 1.155
- 1.096
- 1.032
- 1.044
- 1.168
- 0.937
- 1.111
- 1.106
- 0.843
- 0.991
- 0.986
- 0.963
- 0.785
- 0.857
- 0.829
- 0.774
- 0.858
- 0.926
- 0.758
- 0.813
- 0.781
- 0.818
- 0.752
- 0.706
- 0.762
- 0.64
- 0.603
- 0.598
- 0.579
- 0.594
- 0.651
- 0.581
- 0.651
- 0.58
- 0.521
- 0.62
- 0.503
- 0.581
- 0.552
- 0.538
- 0.503
- 0.532
- 0.453
- 0.454
- 0.463
- 0.476
- 0.438
- 0.395
- 0.468
- 0.476
- 0.454
- 0.417
- 0.384
- 0.396
- 0.405
- 0.381
- 0.371
- 0.413
- 0.36
- 0.368
- 0.337
- 0.36
- 0.373
- 0.368
- 0.405
- 0.371
- 0.344
unequal: 0
verbose: 1
