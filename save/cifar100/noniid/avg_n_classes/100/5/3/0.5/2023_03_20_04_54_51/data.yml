avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0403
- 0.1016
- 0.1149
- 0.135
- 0.1498
- 0.1594
- 0.1689
- 0.1768
- 0.1833
- 0.1904
- 0.1991
- 0.2022
- 0.2068
- 0.2122
- 0.2186
- 0.2187
- 0.2202
- 0.2272
- 0.227
- 0.2346
- 0.2395
- 0.2337
- 0.2386
- 0.2426
- 0.2455
- 0.247
- 0.2487
- 0.2529
- 0.2548
- 0.2577
- 0.2544
- 0.2579
- 0.265
- 0.2657
- 0.2645
- 0.2585
- 0.2626
- 0.266
- 0.2651
- 0.2718
- 0.2738
- 0.2733
- 0.2705
- 0.2719
- 0.2788
- 0.276
- 0.2773
- 0.283
- 0.283
- 0.2814
- 0.2835
- 0.2831
- 0.284
- 0.2744
- 0.2862
- 0.2905
- 0.2846
- 0.2908
- 0.2895
- 0.2898
- 0.2872
- 0.2921
- 0.2922
- 0.2932
- 0.2896
- 0.2881
- 0.2933
- 0.293
- 0.2876
- 0.2932
- 0.2907
- 0.2919
- 0.2863
- 0.2933
- 0.2949
- 0.2921
- 0.2932
- 0.2886
- 0.2916
- 0.2903
- 0.2979
- 0.2974
- 0.2895
- 0.2951
- 0.2924
- 0.2977
- 0.2995
- 0.2972
- 0.2933
- 0.2996
- 0.2967
- 0.2971
- 0.2973
- 0.2953
- 0.2991
- 0.2952
- 0.3025
- 0.2989
- 0.2989
- 0.2953
test_loss_list:
- 1.8098346757888795
- 1.717310299873352
- 1.6854835605621339
- 1.6500358510017394
- 1.6307018971443177
- 1.6083704924583435
- 1.5834640407562255
- 1.573830029964447
- 1.5621281456947327
- 1.5466121816635132
- 1.5311720085144043
- 1.5235608053207397
- 1.5097026991844178
- 1.503158175945282
- 1.512016487121582
- 1.496843433380127
- 1.4936687111854554
- 1.490448567867279
- 1.4790602707862854
- 1.4746098828315735
- 1.4602358198165895
- 1.4537585163116455
- 1.4404059886932372
- 1.4378815937042235
- 1.4575955939292908
- 1.4539516735076905
- 1.4395121002197266
- 1.4414825630187988
- 1.436592516899109
- 1.429288890361786
- 1.4202767539024352
- 1.4198829579353331
- 1.4193407940864562
- 1.4158386635780333
- 1.416799705028534
- 1.4104749536514283
- 1.4062113070487976
- 1.4084386396408082
- 1.4010712027549743
- 1.3988221096992492
- 1.3997559547424316
- 1.4015960788726807
- 1.3855028462409973
- 1.378431441783905
- 1.392387535572052
- 1.397331519126892
- 1.3846610641479493
- 1.3968877625465392
- 1.397440037727356
- 1.3910374522209168
- 1.3910116386413574
- 1.3843923783302308
- 1.3672331190109253
- 1.3685539746284485
- 1.367683310508728
- 1.3788116908073424
- 1.3892517518997192
- 1.3812953639030456
- 1.3881847524642945
- 1.389478030204773
- 1.3959873843193054
- 1.4087021279335021
- 1.4164970374107362
- 1.4194214892387391
- 1.419065968990326
- 1.3901014113426209
- 1.4048305821418763
- 1.3984538006782532
- 1.3834810996055602
- 1.4010476183891296
- 1.3791076397895814
- 1.3660339307785034
- 1.3484256434440614
- 1.3549727845191955
- 1.374771704673767
- 1.3569734740257262
- 1.367865858078003
- 1.367444829940796
- 1.3593770456314087
- 1.359122738838196
- 1.3586279106140138
- 1.352244098186493
- 1.3497598004341125
- 1.3511884546279906
- 1.3431072044372558
- 1.3485759210586548
- 1.3489453721046447
- 1.3548567056655885
- 1.3474124383926391
- 1.3538020944595337
- 1.3480471515655517
- 1.3551717853546144
- 1.3610236167907714
- 1.3494049668312074
- 1.348379497528076
- 1.3557004261016845
- 1.3515016889572145
- 1.3696914172172547
- 1.3615792465209962
- 1.357370240688324
train_accuracy:
- 0.055
- 0.0
- 0.128
- 0.177
- 0.137
- 0.169
- 0.0
- 0.0
- 0.0
- 0.0
- 0.192
- 0.192
- 0.205
- 0.255
- 0.209
- 0.267
- 0.262
- 0.196
- 0.206
- 0.216
- 0.0
- 0.0
- 0.0
- 0.245
- 0.246
- 0.253
- 0.0
- 0.266
- 0.251
- 0.249
- 0.236
- 0.0
- 0.246
- 0.0
- 0.249
- 0.263
- 0.234
- 0.281
- 0.0
- 0.0
- 0.256
- 0.263
- 0.0
- 0.0
- 0.271
- 0.273
- 0.344
- 0.275
- 0.279
- 0.326
- 0.318
- 0.318
- 0.0
- 0.309
- 0.0
- 0.307
- 0.274
- 0.366
- 0.299
- 0.365
- 0.333
- 0.289
- 0.371
- 0.297
- 0.305
- 0.0
- 0.287
- 0.0
- 0.365
- 0.301
- 0.0
- 0.0
- 0.306
- 0.299
- 0.288
- 0.0
- 0.0
- 0.352
- 0.305
- 0.352
- 0.33
- 0.0
- 0.0
- 0.316
- 0.29
- 0.298
- 0.326
- 0.0
- 0.376
- 0.0
- 0.299
- 0.392
- 0.388
- 0.304
- 0.311
- 0.36
- 0.0
- 0.343
- 0.3
- 0.0
train_loss:
- 4.201
- 3.171
- 2.986
- 2.437
- 2.713
- 2.269
- 2.205
- 2.466
- 2.084
- 1.987
- 2.343
- 1.875
- 1.858
- 2.187
- 2.314
- 1.738
- 1.909
- 1.88
- 1.645
- 1.798
- 1.522
- 1.289
- 1.444
- 1.601
- 1.772
- 1.494
- 1.371
- 1.421
- 1.421
- 1.507
- 1.073
- 1.396
- 1.262
- 1.288
- 1.209
- 1.062
- 0.969
- 1.228
- 1.076
- 1.095
- 1.096
- 0.973
- 0.852
- 0.934
- 1.014
- 0.94
- 0.888
- 1.012
- 0.951
- 0.855
- 0.906
- 0.775
- 0.806
- 0.688
- 0.799
- 0.796
- 0.721
- 0.702
- 0.69
- 0.698
- 0.638
- 0.65
- 0.62
- 0.62
- 0.621
- 0.646
- 0.579
- 0.566
- 0.589
- 0.521
- 0.534
- 0.546
- 0.586
- 0.485
- 0.49
- 0.523
- 0.455
- 0.486
- 0.489
- 0.458
- 0.458
- 0.447
- 0.446
- 0.414
- 0.452
- 0.4
- 0.42
- 0.379
- 0.392
- 0.387
- 0.402
- 0.327
- 0.334
- 0.372
- 0.345
- 0.367
- 0.323
- 0.264
- 0.352
- 0.344
unequal: 0
verbose: 1
