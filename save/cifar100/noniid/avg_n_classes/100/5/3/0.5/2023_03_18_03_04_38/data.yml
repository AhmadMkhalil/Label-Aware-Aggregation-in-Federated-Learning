avg_train_accuracy: 0.382
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0389
- 0.0945
- 0.1164
- 0.1386
- 0.144
- 0.1558
- 0.1656
- 0.172
- 0.1721
- 0.1838
- 0.1946
- 0.1954
- 0.2006
- 0.2095
- 0.2118
- 0.2209
- 0.226
- 0.228
- 0.232
- 0.2341
- 0.2391
- 0.2441
- 0.2441
- 0.2534
- 0.255
- 0.2458
- 0.2492
- 0.2546
- 0.2612
- 0.2506
- 0.262
- 0.2667
- 0.2649
- 0.2709
- 0.2676
- 0.2745
- 0.2724
- 0.2745
- 0.2757
- 0.2726
- 0.279
- 0.2839
- 0.2859
- 0.2824
- 0.2829
- 0.2745
- 0.2852
- 0.2893
- 0.286
- 0.2878
- 0.2834
- 0.2919
- 0.291
- 0.2896
- 0.2807
- 0.2926
- 0.2885
- 0.2892
- 0.2955
- 0.2912
- 0.2921
- 0.2943
- 0.2887
- 0.2995
- 0.3006
- 0.2986
- 0.2957
- 0.2962
- 0.2953
- 0.2993
- 0.3003
- 0.3014
- 0.3019
- 0.302
- 0.3065
- 0.3034
- 0.2972
- 0.3058
- 0.3063
- 0.3036
- 0.2995
- 0.306
- 0.3039
- 0.3063
- 0.3026
- 0.3078
- 0.308
- 0.3054
- 0.3088
- 0.3116
- 0.31
- 0.3112
- 0.3075
- 0.3099
- 0.3064
- 0.3099
- 0.3108
- 0.3111
- 0.3107
- 0.3117
test_loss_list:
- 1.8178486490249635
- 1.7215725135803224
- 1.6783291506767273
- 1.649768352508545
- 1.6251979064941406
- 1.5985649776458741
- 1.5768411302566527
- 1.5602230310440064
- 1.5501043272018433
- 1.52903076171875
- 1.5423059010505675
- 1.522708647251129
- 1.5086541771888733
- 1.501288833618164
- 1.503331503868103
- 1.4948368620872499
- 1.4943446588516236
- 1.4810895252227783
- 1.474599120616913
- 1.4641179966926574
- 1.4477703738212586
- 1.4350255513191223
- 1.4254801559448242
- 1.4253661727905274
- 1.4438729286193848
- 1.4283413553237916
- 1.4092227411270142
- 1.399074981212616
- 1.398354744911194
- 1.394659149646759
- 1.3958612513542175
- 1.3933741068840027
- 1.3811309003829957
- 1.3780654716491698
- 1.3681678080558777
- 1.3649134016036988
- 1.3593767428398131
- 1.360777337551117
- 1.3574866318702699
- 1.360979356765747
- 1.3647220349311828
- 1.3716773080825806
- 1.377569580078125
- 1.3661867904663085
- 1.3600928044319154
- 1.3540863990783691
- 1.3562440061569214
- 1.3567796111106873
- 1.3626490020751953
- 1.3658625149726868
- 1.36002277135849
- 1.3708227467536926
- 1.358980083465576
- 1.3615527653694153
- 1.3547809314727783
- 1.3494812560081482
- 1.3567350482940674
- 1.345263533592224
- 1.3486157059669495
- 1.3409398555755616
- 1.3384026408195495
- 1.3434394693374634
- 1.3349385666847229
- 1.3480493021011353
- 1.3604947471618651
- 1.3571934580802918
- 1.3489301347732543
- 1.3530533123016357
- 1.33409991979599
- 1.342712833881378
- 1.3266232585906983
- 1.3289787220954894
- 1.3295793867111205
- 1.3269437050819397
- 1.34080050945282
- 1.3567570662498474
- 1.3403276205062866
- 1.3382403063774109
- 1.3508409905433654
- 1.3413860416412353
- 1.3460068321228027
- 1.3429102110862732
- 1.346726312637329
- 1.3613175535202027
- 1.3430176019668578
- 1.3334465742111206
- 1.3389699745178223
- 1.3296474027633667
- 1.3163095545768737
- 1.3261548209190368
- 1.334056828022003
- 1.328447892665863
- 1.3289776945114136
- 1.3359606504440307
- 1.3496449208259582
- 1.3274258804321288
- 1.3206146359443665
- 1.328035545349121
- 1.3362906432151795
- 1.3339081048965453
train_accuracy:
- 0.03
- 0.098
- 0.0
- 0.0
- 0.0
- 0.0
- 0.161
- 0.19
- 0.203
- 0.179
- 0.182
- 0.178
- 0.227
- 0.26
- 0.236
- 0.206
- 0.0
- 0.216
- 0.223
- 0.258
- 0.271
- 0.227
- 0.255
- 0.267
- 0.278
- 0.0
- 0.263
- 0.315
- 0.318
- 0.0
- 0.296
- 0.294
- 0.0
- 0.305
- 0.274
- 0.303
- 0.325
- 0.0
- 0.324
- 0.328
- 0.31
- 0.338
- 0.319
- 0.319
- 0.307
- 0.288
- 0.318
- 0.338
- 0.354
- 0.337
- 0.331
- 0.318
- 0.0
- 0.0
- 0.0
- 0.352
- 0.326
- 0.353
- 0.343
- 0.346
- 0.0
- 0.324
- 0.0
- 0.33
- 0.315
- 0.322
- 0.349
- 0.339
- 0.0
- 0.3
- 0.364
- 0.348
- 0.359
- 0.0
- 0.367
- 0.299
- 0.0
- 0.388
- 0.361
- 0.0
- 0.293
- 0.366
- 0.319
- 0.365
- 0.358
- 0.384
- 0.378
- 0.0
- 0.336
- 0.0
- 0.0
- 0.364
- 0.0
- 0.348
- 0.318
- 0.0
- 0.312
- 0.354
- 0.381
- 0.382
train_loss:
- 2.993
- 3.242
- 2.558
- 2.861
- 1.925
- 2.268
- 1.81
- 2.536
- 1.709
- 2.103
- 2.63
- 1.961
- 1.851
- 2.153
- 2.063
- 1.987
- 1.911
- 1.695
- 1.87
- 1.602
- 1.552
- 1.462
- 1.514
- 1.623
- 1.791
- 1.203
- 1.135
- 1.267
- 1.453
- 1.142
- 1.443
- 1.359
- 1.225
- 1.131
- 0.995
- 1.104
- 1.073
- 1.095
- 0.996
- 0.959
- 1.106
- 1.213
- 1.07
- 0.892
- 0.862
- 0.906
- 0.946
- 0.941
- 0.914
- 0.831
- 0.743
- 0.965
- 0.736
- 0.773
- 0.661
- 0.758
- 0.807
- 0.672
- 0.742
- 0.631
- 0.664
- 0.666
- 0.582
- 0.639
- 0.656
- 0.616
- 0.556
- 0.508
- 0.56
- 0.521
- 0.533
- 0.496
- 0.568
- 0.519
- 0.513
- 0.44
- 0.52
- 0.468
- 0.466
- 0.478
- 0.463
- 0.462
- 0.375
- 0.417
- 0.487
- 0.441
- 0.358
- 0.398
- 0.359
- 0.392
- 0.312
- 0.353
- 0.369
- 0.352
- 0.357
- 0.401
- 0.382
- 0.303
- 0.309
- 0.271
unequal: 0
verbose: 1
