avg_train_accuracy: 0.317
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.034
- 0.0992
- 0.0708
- 0.1168
- 0.0789
- 0.1424
- 0.1508
- 0.1399
- 0.1742
- 0.1536
- 0.1771
- 0.169
- 0.1905
- 0.1917
- 0.2013
- 0.1936
- 0.2027
- 0.2103
- 0.2096
- 0.2184
- 0.2238
- 0.2256
- 0.2265
- 0.2257
- 0.2314
- 0.2336
- 0.2425
- 0.2392
- 0.2463
- 0.242
- 0.2396
- 0.2493
- 0.2533
- 0.2563
- 0.259
- 0.2457
- 0.2595
- 0.2453
- 0.2577
- 0.2562
- 0.2671
- 0.2506
- 0.2519
- 0.269
- 0.2628
- 0.2726
- 0.2687
- 0.2725
- 0.2712
- 0.2705
- 0.2614
- 0.2711
- 0.2759
- 0.2771
- 0.2748
- 0.28
- 0.2795
- 0.2732
- 0.2811
- 0.2883
- 0.2896
- 0.2829
- 0.2843
- 0.2696
- 0.2821
- 0.2763
- 0.2823
- 0.2823
- 0.2883
- 0.2711
- 0.2867
- 0.2855
- 0.2906
- 0.2857
- 0.2886
- 0.29
- 0.2742
- 0.274
- 0.2799
- 0.2999
- 0.2907
- 0.2941
- 0.2937
- 0.2989
- 0.2957
- 0.2848
- 0.2918
- 0.3039
- 0.2967
- 0.2869
- 0.3007
- 0.2809
- 0.2905
- 0.2993
- 0.3028
- 0.3021
- 0.2884
- 0.298
- 0.2968
- 0.2974
test_loss_list:
- 1.8291278886795044
- 1.7293246459960938
- 1.69481595993042
- 1.6332339096069335
- 1.6920208883285524
- 1.5868463826179504
- 1.5942171430587768
- 1.605414593219757
- 1.5671101999282837
- 1.5077191185951233
- 1.500842034816742
- 1.5425471210479735
- 1.521500403881073
- 1.5204755854606629
- 1.5140321850776672
- 1.5297355246543884
- 1.499998905658722
- 1.5015545773506165
- 1.5048850107192993
- 1.4931281900405884
- 1.4889573979377746
- 1.4820760703086853
- 1.4773225212097167
- 1.4762307858467103
- 1.4754340386390685
- 1.4776343178749085
- 1.4574976181983947
- 1.4639286589622498
- 1.4670030426979066
- 1.478369309902191
- 1.47758291721344
- 1.4552002143859863
- 1.4562848448753356
- 1.4612846350669861
- 1.4632000017166138
- 1.4808401322364808
- 1.4512100267410277
- 1.4715407514572143
- 1.4381498861312867
- 1.438190779685974
- 1.4345707178115845
- 1.4484585452079772
- 1.4281837582588195
- 1.4080483055114745
- 1.420566794872284
- 1.4162955784797668
- 1.4283501386642456
- 1.4219276547431945
- 1.424005401134491
- 1.4193719601631165
- 1.4338164734840393
- 1.4264289665222167
- 1.4315540242195128
- 1.421738214492798
- 1.4179459881782532
- 1.4092900466918945
- 1.4164959263801575
- 1.4175084400177003
- 1.4127711987495422
- 1.4139927506446839
- 1.408314824104309
- 1.4156274175643921
- 1.4014953970909119
- 1.4300907111167909
- 1.3972988533973694
- 1.4074435329437256
- 1.3965526914596558
- 1.3992117547988892
- 1.3827183318138123
- 1.4137993240356446
- 1.378436062335968
- 1.3865105390548706
- 1.390457375049591
- 1.3936853146553039
- 1.402611575126648
- 1.38954021692276
- 1.4205597305297852
- 1.4124537134170532
- 1.3958752489089965
- 1.379786970615387
- 1.388729510307312
- 1.381192877292633
- 1.3948902797698974
- 1.3819360613822937
- 1.3856446218490601
- 1.4017374730110168
- 1.384181308746338
- 1.3869468903541564
- 1.3864047408103943
- 1.4118953275680541
- 1.379016330242157
- 1.3281888222694398
- 1.3214162945747376
- 1.3290551710128784
- 1.348370201587677
- 1.3575820684432984
- 1.3728520607948302
- 1.357865936756134
- 1.3688274025917053
- 1.363762288093567
train_accuracy:
- 0.028
- 0.075
- 0.0
- 0.0
- 0.0
- 0.165
- 0.0
- 0.0
- 0.243
- 0.0
- 0.177
- 0.0
- 0.263
- 0.0
- 0.215
- 0.0
- 0.225
- 0.215
- 0.0
- 0.256
- 0.0
- 0.242
- 0.248
- 0.209
- 0.232
- 0.208
- 0.34
- 0.0
- 0.295
- 0.324
- 0.0
- 0.253
- 0.0
- 0.339
- 0.297
- 0.0
- 0.268
- 0.236
- 0.0
- 0.255
- 0.271
- 0.314
- 0.0
- 0.0
- 0.0
- 0.32
- 0.283
- 0.309
- 0.0
- 0.352
- 0.0
- 0.328
- 0.309
- 0.308
- 0.317
- 0.277
- 0.295
- 0.0
- 0.0
- 0.349
- 0.0
- 0.0
- 0.35
- 0.0
- 0.306
- 0.0
- 0.358
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.301
- 0.374
- 0.309
- 0.0
- 0.0
- 0.0
- 0.322
- 0.0
- 0.289
- 0.322
- 0.303
- 0.325
- 0.0
- 0.0
- 0.299
- 0.386
- 0.0
- 0.373
- 0.0
- 0.316
- 0.358
- 0.332
- 0.31
- 0.0
- 0.383
- 0.0
- 0.317
train_loss:
- 3.238
- 3.704
- 1.215
- 2.661
- 1.001
- 3.322
- 2.375
- 1.608
- 3.083
- 0.952
- 2.816
- 1.4
- 2.729
- 2.037
- 2.559
- 1.383
- 1.956
- 2.25
- 1.71
- 1.74
- 1.753
- 1.633
- 1.651
- 1.481
- 1.434
- 1.862
- 1.689
- 1.37
- 1.706
- 1.607
- 1.117
- 1.732
- 1.297
- 1.529
- 1.42
- 1.088
- 1.54
- 0.972
- 1.292
- 1.111
- 1.223
- 0.992
- 0.896
- 0.927
- 0.864
- 1.176
- 1.044
- 1.012
- 0.866
- 1.03
- 0.679
- 0.8
- 0.866
- 0.943
- 0.888
- 0.796
- 0.759
- 0.995
- 0.783
- 0.72
- 0.682
- 0.639
- 0.798
- 0.659
- 0.778
- 0.638
- 0.702
- 0.583
- 0.634
- 0.637
- 0.731
- 0.618
- 0.576
- 0.476
- 0.637
- 0.61
- 0.537
- 0.647
- 0.565
- 0.518
- 0.488
- 0.523
- 0.464
- 0.396
- 0.383
- 0.535
- 0.509
- 0.362
- 0.447
- 0.489
- 0.513
- 0.556
- 0.326
- 0.376
- 0.385
- 0.369
- 0.485
- 0.37
- 0.364
- 0.329
unequal: 0
verbose: 1
