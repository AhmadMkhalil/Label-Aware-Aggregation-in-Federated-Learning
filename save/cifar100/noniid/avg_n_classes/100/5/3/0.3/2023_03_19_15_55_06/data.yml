avg_train_accuracy: 0.328
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0428
- 0.102
- 0.1102
- 0.1288
- 0.1388
- 0.1475
- 0.1582
- 0.162
- 0.1726
- 0.1777
- 0.1837
- 0.1832
- 0.1962
- 0.1947
- 0.1902
- 0.1973
- 0.2141
- 0.2212
- 0.2191
- 0.2298
- 0.2276
- 0.2304
- 0.2267
- 0.2278
- 0.2206
- 0.2373
- 0.2374
- 0.2405
- 0.2356
- 0.2392
- 0.248
- 0.2388
- 0.2511
- 0.2506
- 0.2538
- 0.2535
- 0.2567
- 0.2556
- 0.261
- 0.261
- 0.2647
- 0.2572
- 0.2571
- 0.2421
- 0.2704
- 0.2736
- 0.2643
- 0.2643
- 0.261
- 0.2701
- 0.2697
- 0.268
- 0.2749
- 0.2752
- 0.2779
- 0.2712
- 0.275
- 0.2642
- 0.273
- 0.2469
- 0.2803
- 0.2638
- 0.2853
- 0.2782
- 0.2748
- 0.269
- 0.2729
- 0.2581
- 0.2786
- 0.2772
- 0.2819
- 0.2809
- 0.2823
- 0.2861
- 0.289
- 0.2748
- 0.2957
- 0.2866
- 0.2805
- 0.2879
- 0.2867
- 0.2988
- 0.2939
- 0.2934
- 0.292
- 0.2871
- 0.294
- 0.2908
- 0.2859
- 0.2904
- 0.2968
- 0.2927
- 0.2914
- 0.2926
- 0.2987
- 0.2943
- 0.2869
- 0.2778
- 0.2854
- 0.2886
test_loss_list:
- 1.8286084604263306
- 1.7293376636505127
- 1.703914852142334
- 1.6710935235023499
- 1.6734515643119812
- 1.6468827843666076
- 1.6398502802848816
- 1.6242927145957946
- 1.6163861489295959
- 1.5924434566497803
- 1.601486485004425
- 1.5991797542572022
- 1.5752845549583434
- 1.5723303270339966
- 1.5799672555923463
- 1.5517863416671753
- 1.5334174919128418
- 1.5332699131965637
- 1.5353031945228577
- 1.5252602338790893
- 1.5338568019866943
- 1.5286852717399597
- 1.5243753910064697
- 1.5289021801948548
- 1.5121845054626464
- 1.485070631504059
- 1.4933248090744018
- 1.482704484462738
- 1.49877703666687
- 1.497180986404419
- 1.4924084782600402
- 1.4923045611381531
- 1.4587340760231018
- 1.465706262588501
- 1.4709892821311952
- 1.4801333236694336
- 1.47419709444046
- 1.4912341570854186
- 1.4883051466941835
- 1.486424207687378
- 1.4911342978477478
- 1.488034496307373
- 1.4937944865226747
- 1.5231943130493164
- 1.4742377138137817
- 1.465049409866333
- 1.4818741250038148
- 1.4642083072662353
- 1.4796026182174682
- 1.448684232234955
- 1.4559543299674989
- 1.444668848514557
- 1.436461787223816
- 1.4442379760742188
- 1.4289255809783936
- 1.4391547703742982
- 1.4332598614692689
- 1.4592184019088745
- 1.4320926833152772
- 1.3614301872253418
- 1.3467038011550903
- 1.3957834243774414
- 1.384175009727478
- 1.3884726762771606
- 1.4146279525756835
- 1.4296380352973939
- 1.4154442834854126
- 1.4420149898529053
- 1.4072604370117188
- 1.4183019638061523
- 1.4346064877510072
- 1.4273528480529785
- 1.4254578852653503
- 1.4163566780090333
- 1.4279272389411926
- 1.44299489736557
- 1.412452428340912
- 1.4239517784118652
- 1.4277113747596741
- 1.4197087979316712
- 1.4233343267440797
- 1.4249497413635255
- 1.42198082447052
- 1.4145428442955017
- 1.4166487431526185
- 1.4123376512527466
- 1.4261170744895935
- 1.4217358016967774
- 1.431411702632904
- 1.4379562520980835
- 1.4364165306091308
- 1.4342977905273437
- 1.439837598800659
- 1.4526523232460022
- 1.4302448415756226
- 1.4274427771568299
- 1.4525030159950256
- 1.4598723149299622
- 1.4343454647064209
- 1.415642340183258
train_accuracy:
- 0.049
- 0.121
- 0.0
- 0.154
- 0.168
- 0.164
- 0.0
- 0.204
- 0.191
- 0.227
- 0.224
- 0.0
- 0.0
- 0.204
- 0.193
- 0.208
- 0.233
- 0.262
- 0.0
- 0.269
- 0.3
- 0.0
- 0.29
- 0.0
- 0.281
- 0.0
- 0.0
- 0.338
- 0.0
- 0.322
- 0.317
- 0.0
- 0.299
- 0.323
- 0.325
- 0.0
- 0.314
- 0.27
- 0.352
- 0.0
- 0.312
- 0.291
- 0.275
- 0.254
- 0.3
- 0.303
- 0.284
- 0.334
- 0.0
- 0.313
- 0.0
- 0.0
- 0.336
- 0.357
- 0.325
- 0.291
- 0.0
- 0.294
- 0.354
- 0.0
- 0.317
- 0.339
- 0.321
- 0.281
- 0.371
- 0.0
- 0.0
- 0.0
- 0.335
- 0.322
- 0.342
- 0.31
- 0.299
- 0.346
- 0.353
- 0.294
- 0.382
- 0.333
- 0.309
- 0.0
- 0.378
- 0.383
- 0.337
- 0.329
- 0.382
- 0.0
- 0.312
- 0.0
- 0.342
- 0.328
- 0.32
- 0.0
- 0.29
- 0.376
- 0.334
- 0.0
- 0.333
- 0.0
- 0.0
- 0.328
train_loss:
- 3.173
- 2.879
- 1.915
- 2.53
- 1.752
- 2.33
- 2.211
- 2.239
- 2.188
- 2.184
- 2.382
- 1.995
- 1.968
- 2.116
- 1.535
- 1.409
- 2.303
- 2.144
- 1.681
- 2.173
- 1.567
- 1.56
- 1.442
- 1.441
- 1.277
- 1.618
- 1.355
- 1.347
- 1.213
- 1.182
- 1.497
- 1.135
- 1.368
- 1.23
- 1.392
- 1.037
- 1.307
- 1.243
- 1.178
- 1.184
- 1.085
- 1.074
- 0.97
- 0.798
- 1.011
- 1.229
- 0.824
- 1.034
- 0.734
- 0.886
- 0.779
- 0.826
- 0.884
- 0.766
- 0.874
- 0.703
- 0.658
- 0.665
- 0.716
- 0.681
- 0.804
- 0.502
- 0.748
- 0.651
- 0.474
- 0.516
- 0.461
- 0.479
- 0.72
- 0.581
- 0.448
- 0.708
- 0.593
- 0.687
- 0.471
- 0.67
- 0.561
- 0.596
- 0.514
- 0.546
- 0.463
- 0.542
- 0.484
- 0.428
- 0.492
- 0.48
- 0.352
- 0.544
- 0.452
- 0.286
- 0.35
- 0.417
- 0.342
- 0.223
- 0.484
- 0.475
- 0.405
- 0.494
- 0.455
- 0.317
unequal: 0
verbose: 1
