avg_train_accuracy: 0.307
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0399
- 0.0917
- 0.1094
- 0.1351
- 0.1495
- 0.1629
- 0.1683
- 0.1747
- 0.1854
- 0.18
- 0.1939
- 0.1953
- 0.2053
- 0.2087
- 0.2133
- 0.2142
- 0.2179
- 0.2186
- 0.1999
- 0.2199
- 0.208
- 0.2277
- 0.2341
- 0.2308
- 0.2153
- 0.2222
- 0.2339
- 0.2166
- 0.239
- 0.2367
- 0.2488
- 0.2558
- 0.2531
- 0.25
- 0.2438
- 0.2513
- 0.2405
- 0.2604
- 0.2586
- 0.2622
- 0.2518
- 0.2636
- 0.2658
- 0.2631
- 0.2693
- 0.2681
- 0.2797
- 0.2796
- 0.2806
- 0.2756
- 0.2797
- 0.2825
- 0.281
- 0.2854
- 0.2809
- 0.2805
- 0.2704
- 0.2816
- 0.2614
- 0.2719
- 0.2652
- 0.2828
- 0.2836
- 0.286
- 0.2872
- 0.284
- 0.2775
- 0.2719
- 0.2952
- 0.2854
- 0.2913
- 0.2912
- 0.2957
- 0.2944
- 0.2934
- 0.2968
- 0.2857
- 0.2789
- 0.2887
- 0.2954
- 0.2971
- 0.2966
- 0.282
- 0.2919
- 0.284
- 0.297
- 0.2932
- 0.2955
- 0.2935
- 0.2907
- 0.2836
- 0.2946
- 0.2929
- 0.2941
- 0.2951
- 0.3033
- 0.2997
- 0.2974
- 0.2991
- 0.2992
test_loss_list:
- 1.8167691230773926
- 1.721767144203186
- 1.6985647201538085
- 1.6593954730033875
- 1.6520138478279114
- 1.636489951610565
- 1.6271272563934327
- 1.6239329028129577
- 1.6102026796340942
- 1.6059962582588196
- 1.6032405853271485
- 1.605139102935791
- 1.585920479297638
- 1.5796033263206481
- 1.5670098495483398
- 1.5658446407318116
- 1.554238395690918
- 1.5558348083496094
- 1.4281982278823853
- 1.44613037109375
- 1.4878381013870239
- 1.4796423387527466
- 1.4841091871261596
- 1.492327742576599
- 1.4149838018417358
- 1.4316875314712525
- 1.4418888568878174
- 1.4785361123085021
- 1.4412751913070678
- 1.4490529990196228
- 1.4323492884635924
- 1.4361787748336792
- 1.4513328528404237
- 1.4695462489128113
- 1.4673205423355102
- 1.459881727695465
- 1.4585624647140503
- 1.421686158180237
- 1.4317579245567322
- 1.4360346221923828
- 1.4374039626121522
- 1.432060444355011
- 1.4335325598716735
- 1.43743577003479
- 1.4277874159812927
- 1.4304483532905579
- 1.4250045466423034
- 1.4376632213592528
- 1.4435935831069946
- 1.4418254137039184
- 1.44370046377182
- 1.4485386657714843
- 1.457643220424652
- 1.4614000940322875
- 1.4606274962425232
- 1.4544083452224732
- 1.4575365424156188
- 1.439937970638275
- 1.4700307655334472
- 1.427972412109375
- 1.4398158478736878
- 1.3989563155174256
- 1.38839430809021
- 1.4047584772109984
- 1.3929370546340942
- 1.405942838191986
- 1.412138569355011
- 1.416543595790863
- 1.3906433272361756
- 1.4074608635902406
- 1.3937452816963196
- 1.3970288300514222
- 1.4034159636497499
- 1.4205436134338378
- 1.421924228668213
- 1.4182855010032653
- 1.4280905961990356
- 1.4460395550727845
- 1.4103722667694092
- 1.4168319368362428
- 1.4151104974746704
- 1.4305602359771727
- 1.426156919002533
- 1.4109378552436829
- 1.415849528312683
- 1.3934282064437866
- 1.3965948438644409
- 1.3795342111587525
- 1.3869068622589111
- 1.400985336303711
- 1.4102716040611267
- 1.3756452202796936
- 1.3919231128692626
- 1.3940760135650634
- 1.3843870496749877
- 1.3792786693572998
- 1.3948772025108338
- 1.3894499444961548
- 1.3827812814712523
- 1.3882197380065917
train_accuracy:
- 0.055
- 0.088
- 0.0
- 0.0
- 0.182
- 0.191
- 0.0
- 0.202
- 0.176
- 0.179
- 0.177
- 0.243
- 0.237
- 0.0
- 0.275
- 0.0
- 0.216
- 0.227
- 0.0
- 0.0
- 0.0
- 0.233
- 0.262
- 0.31
- 0.0
- 0.212
- 0.247
- 0.0
- 0.26
- 0.0
- 0.0
- 0.281
- 0.283
- 0.269
- 0.0
- 0.282
- 0.309
- 0.295
- 0.237
- 0.303
- 0.0
- 0.342
- 0.343
- 0.0
- 0.292
- 0.289
- 0.337
- 0.266
- 0.34
- 0.359
- 0.347
- 0.314
- 0.267
- 0.303
- 0.355
- 0.328
- 0.303
- 0.0
- 0.312
- 0.0
- 0.282
- 0.0
- 0.36
- 0.332
- 0.0
- 0.352
- 0.0
- 0.0
- 0.343
- 0.361
- 0.0
- 0.34
- 0.362
- 0.348
- 0.312
- 0.349
- 0.0
- 0.0
- 0.355
- 0.341
- 0.355
- 0.339
- 0.319
- 0.0
- 0.323
- 0.0
- 0.349
- 0.294
- 0.0
- 0.0
- 0.0
- 0.0
- 0.321
- 0.37
- 0.0
- 0.0
- 0.313
- 0.338
- 0.328
- 0.307
train_loss:
- 2.179
- 2.89
- 1.934
- 2.492
- 3.196
- 2.441
- 2.312
- 2.77
- 2.212
- 2.056
- 2.67
- 2.483
- 2.055
- 1.941
- 2.362
- 1.79
- 1.759
- 1.683
- 1.002
- 1.529
- 1.141
- 1.922
- 1.813
- 1.601
- 0.84
- 0.85
- 1.675
- 1.081
- 1.387
- 1.088
- 1.52
- 1.709
- 1.362
- 1.266
- 1.205
- 1.251
- 1.063
- 1.135
- 1.039
- 1.186
- 0.994
- 1.07
- 1.25
- 0.931
- 1.159
- 0.95
- 1.24
- 0.967
- 1.02
- 0.812
- 0.955
- 1.093
- 0.968
- 0.866
- 0.74
- 0.789
- 0.827
- 0.682
- 0.675
- 0.704
- 0.632
- 0.787
- 0.957
- 0.682
- 0.803
- 0.705
- 0.66
- 0.708
- 0.709
- 0.593
- 0.556
- 0.615
- 0.574
- 0.536
- 0.536
- 0.475
- 0.562
- 0.541
- 0.507
- 0.491
- 0.489
- 0.34
- 0.621
- 0.491
- 0.523
- 0.445
- 0.456
- 0.546
- 0.397
- 0.481
- 0.51
- 0.479
- 0.431
- 0.403
- 0.389
- 0.404
- 0.337
- 0.383
- 0.363
- 0.392
unequal: 0
verbose: 1
