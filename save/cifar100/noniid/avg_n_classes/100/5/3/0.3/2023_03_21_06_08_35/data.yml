avg_train_accuracy: 0.326
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0478
- 0.0912
- 0.1143
- 0.1315
- 0.1453
- 0.1526
- 0.1534
- 0.1724
- 0.1679
- 0.1847
- 0.1821
- 0.188
- 0.1958
- 0.2015
- 0.1942
- 0.214
- 0.1957
- 0.2093
- 0.2201
- 0.2235
- 0.2254
- 0.2133
- 0.228
- 0.2242
- 0.2355
- 0.2422
- 0.2408
- 0.2409
- 0.2393
- 0.2289
- 0.2456
- 0.2392
- 0.2494
- 0.2586
- 0.2317
- 0.2431
- 0.2471
- 0.2631
- 0.2597
- 0.2653
- 0.2585
- 0.2645
- 0.2694
- 0.277
- 0.2556
- 0.2724
- 0.273
- 0.2794
- 0.2744
- 0.2779
- 0.2733
- 0.274
- 0.2614
- 0.2814
- 0.2746
- 0.2791
- 0.28
- 0.2857
- 0.2822
- 0.2909
- 0.2847
- 0.28
- 0.2811
- 0.2888
- 0.2842
- 0.287
- 0.2871
- 0.2863
- 0.2621
- 0.2763
- 0.2878
- 0.2964
- 0.2763
- 0.2894
- 0.2782
- 0.2873
- 0.2973
- 0.2804
- 0.291
- 0.2916
- 0.2948
- 0.2831
- 0.2825
- 0.2824
- 0.2937
- 0.2876
- 0.2736
- 0.2939
- 0.2891
- 0.3002
- 0.294
- 0.2835
- 0.2926
- 0.301
- 0.2918
- 0.3009
- 0.2815
- 0.3026
- 0.3
- 0.2982
test_loss_list:
- 1.8101793003082276
- 1.7395625448226928
- 1.7141331958770751
- 1.6856847763061524
- 1.6615197777748107
- 1.6549321222305298
- 1.6458555698394775
- 1.6223561620712281
- 1.623838472366333
- 1.615605833530426
- 1.617561581134796
- 1.6056568312644959
- 1.595325195789337
- 1.5805642533302307
- 1.592444727420807
- 1.5592616271972657
- 1.434515540599823
- 1.4578178906440735
- 1.4777407574653625
- 1.4967041444778442
- 1.495585436820984
- 1.5048302984237671
- 1.4796577429771423
- 1.4867393827438355
- 1.4832966470718383
- 1.480770573616028
- 1.4880305552482604
- 1.4777586722373963
- 1.4802426028251647
- 1.3739757585525512
- 1.3982120013237
- 1.4247619605064392
- 1.4142808818817139
- 1.4224157428741455
- 1.481105191707611
- 1.45235258102417
- 1.440975739955902
- 1.4257977938652038
- 1.4381586909294128
- 1.4188511657714844
- 1.4323168921470641
- 1.4185824942588807
- 1.4197095704078675
- 1.4279375886917114
- 1.4527183675765991
- 1.422138524055481
- 1.436191577911377
- 1.435246195793152
- 1.442158455848694
- 1.4542543005943298
- 1.4408587288856507
- 1.4475036978721618
- 1.486828067302704
- 1.4417556953430175
- 1.4453738355636596
- 1.4142221665382386
- 1.418142704963684
- 1.4129796886444093
- 1.4161831545829773
- 1.4128541517257691
- 1.433176302909851
- 1.4427271175384522
- 1.4451067543029785
- 1.4363169288635254
- 1.4255853700637817
- 1.4258837842941283
- 1.4187446689605714
- 1.4379278349876403
- 1.4733389568328858
- 1.4206784749031067
- 1.3993079113960265
- 1.4120057225227356
- 1.430668168067932
- 1.4160773873329162
- 1.4245209336280822
- 1.4104195308685303
- 1.403851776123047
- 1.4253273463249208
- 1.398511188030243
- 1.3973863053321838
- 1.3961084914207458
- 1.4167522644996644
- 1.406472749710083
- 1.3944944334030152
- 1.3823355007171632
- 1.3968843197822571
- 1.4135093355178834
- 1.3770428109169006
- 1.394657621383667
- 1.3954941463470458
- 1.4021272158622742
- 1.418438913822174
- 1.3967626190185547
- 1.394829216003418
- 1.4086040592193603
- 1.412866792678833
- 1.4331354641914367
- 1.4004140734672545
- 1.4078474736213684
- 1.4027204513549805
train_accuracy:
- 0.047
- 0.0
- 0.119
- 0.0
- 0.158
- 0.174
- 0.0
- 0.183
- 0.177
- 0.19
- 0.202
- 0.199
- 0.187
- 0.226
- 0.0
- 0.233
- 0.0
- 0.0
- 0.227
- 0.229
- 0.229
- 0.0
- 0.235
- 0.251
- 0.264
- 0.0
- 0.257
- 0.0
- 0.289
- 0.0
- 0.254
- 0.249
- 0.0
- 0.268
- 0.0
- 0.257
- 0.0
- 0.265
- 0.285
- 0.3
- 0.0
- 0.276
- 0.0
- 0.285
- 0.292
- 0.287
- 0.295
- 0.289
- 0.29
- 0.269
- 0.307
- 0.0
- 0.0
- 0.304
- 0.0
- 0.0
- 0.0
- 0.0
- 0.317
- 0.295
- 0.29
- 0.332
- 0.321
- 0.314
- 0.321
- 0.312
- 0.0
- 0.283
- 0.265
- 0.289
- 0.306
- 0.314
- 0.304
- 0.29
- 0.0
- 0.325
- 0.318
- 0.309
- 0.303
- 0.328
- 0.323
- 0.0
- 0.0
- 0.333
- 0.318
- 0.297
- 0.323
- 0.324
- 0.303
- 0.31
- 0.313
- 0.329
- 0.301
- 0.307
- 0.312
- 0.327
- 0.0
- 0.0
- 0.35
- 0.326
train_loss:
- 3.239
- 2.858
- 3.431
- 2.56
- 2.479
- 2.355
- 1.651
- 2.844
- 2.088
- 2.566
- 1.991
- 1.9
- 2.366
- 2.012
- 1.404
- 2.255
- 1.035
- 1.666
- 2.071
- 1.865
- 1.656
- 1.308
- 1.692
- 1.746
- 1.849
- 1.554
- 1.678
- 1.364
- 1.333
- 0.834
- 1.636
- 1.045
- 1.334
- 1.492
- 1.034
- 1.048
- 0.917
- 1.525
- 1.193
- 1.103
- 1.027
- 1.215
- 1.025
- 1.191
- 0.839
- 0.89
- 1.036
- 1.189
- 0.797
- 0.971
- 0.767
- 0.744
- 0.727
- 0.899
- 0.964
- 0.803
- 0.857
- 0.79
- 0.722
- 0.805
- 0.693
- 0.623
- 0.623
- 0.676
- 0.772
- 0.638
- 0.618
- 0.598
- 0.714
- 0.776
- 0.628
- 0.587
- 0.542
- 0.48
- 0.56
- 0.586
- 0.625
- 0.544
- 0.529
- 0.548
- 0.597
- 0.507
- 0.543
- 0.567
- 0.489
- 0.523
- 0.512
- 0.49
- 0.452
- 0.434
- 0.419
- 0.467
- 0.492
- 0.37
- 0.446
- 0.345
- 0.504
- 0.433
- 0.341
- 0.404
unequal: 0
verbose: 1
