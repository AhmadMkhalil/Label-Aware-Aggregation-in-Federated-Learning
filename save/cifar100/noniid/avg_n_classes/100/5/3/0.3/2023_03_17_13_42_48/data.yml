avg_train_accuracy: 0.313
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0458
- 0.0931
- 0.1199
- 0.1352
- 0.1408
- 0.1526
- 0.1619
- 0.1602
- 0.1796
- 0.185
- 0.1847
- 0.1842
- 0.1937
- 0.2123
- 0.212
- 0.2177
- 0.2174
- 0.2214
- 0.2316
- 0.2331
- 0.2323
- 0.2317
- 0.242
- 0.2393
- 0.2449
- 0.2433
- 0.2439
- 0.2487
- 0.2532
- 0.2586
- 0.2543
- 0.2545
- 0.2612
- 0.2659
- 0.2659
- 0.2475
- 0.2694
- 0.2605
- 0.265
- 0.2703
- 0.2705
- 0.2629
- 0.2742
- 0.2752
- 0.2793
- 0.2795
- 0.2716
- 0.2783
- 0.2757
- 0.2841
- 0.2822
- 0.2721
- 0.2853
- 0.2753
- 0.2728
- 0.2878
- 0.277
- 0.2727
- 0.2874
- 0.2898
- 0.2944
- 0.2891
- 0.2729
- 0.2743
- 0.2832
- 0.2966
- 0.294
- 0.2901
- 0.2917
- 0.2907
- 0.2964
- 0.2961
- 0.2962
- 0.3017
- 0.2916
- 0.2939
- 0.2967
- 0.298
- 0.3051
- 0.2987
- 0.294
- 0.2948
- 0.3013
- 0.2916
- 0.3015
- 0.3036
- 0.2988
- 0.3043
- 0.3021
- 0.2972
- 0.307
- 0.3052
- 0.2989
- 0.309
- 0.3006
- 0.2994
- 0.3062
- 0.2943
- 0.3063
- 0.3052
test_loss_list:
- 1.8093338584899903
- 1.71626549243927
- 1.6913079047203063
- 1.6673061752319336
- 1.651434350013733
- 1.6331206727027894
- 1.6294324326515197
- 1.6116102528572083
- 1.5896503639221191
- 1.5813311004638673
- 1.5772022533416747
- 1.5735892248153687
- 1.5549915838241577
- 1.5315717434883118
- 1.5375520658493043
- 1.5307536339759826
- 1.5249746131896973
- 1.5109472846984864
- 1.50671954870224
- 1.5166066884994507
- 1.5112891149520875
- 1.5074526405334472
- 1.504460062980652
- 1.5074919605255126
- 1.4943198847770691
- 1.4949613070487977
- 1.4875562191009521
- 1.4782907724380494
- 1.4677705311775207
- 1.4795082378387452
- 1.4816472554206848
- 1.4810271453857422
- 1.4813527846336365
- 1.4831688165664674
- 1.4825227689743041
- 1.4989619588851928
- 1.4636199927330018
- 1.4850004196166993
- 1.4666690826416016
- 1.4535764861106872
- 1.440625298023224
- 1.4512061595916748
- 1.429831645488739
- 1.4183131742477417
- 1.4373670959472655
- 1.4290446972846984
- 1.4291387224197387
- 1.4256821823120118
- 1.4313080430030822
- 1.4248741841316224
- 1.4246788120269775
- 1.4349929666519166
- 1.4091586565971375
- 1.4221758794784547
- 1.4111950778961182
- 1.3913203644752503
- 1.4036529183387756
- 1.4204577493667603
- 1.3907862281799317
- 1.396299033164978
- 1.390317075252533
- 1.4093769240379332
- 1.4264036107063294
- 1.4087072682380677
- 1.400928976535797
- 1.3886362743377685
- 1.3908551692962647
- 1.3959416508674622
- 1.3990433740615844
- 1.3966028165817261
- 1.4050152468681336
- 1.4023151206970215
- 1.3917497730255126
- 1.4042836666107177
- 1.414634017944336
- 1.4095963525772095
- 1.4018024682998658
- 1.3952624917030334
- 1.4055324506759643
- 1.404499475955963
- 1.4120841670036315
- 1.405365958213806
- 1.3952350282669068
- 1.4105067944526672
- 1.3904232931137086
- 1.3996512460708619
- 1.3973999953269958
- 1.403094666004181
- 1.406351466178894
- 1.4120064616203307
- 1.3788247323036193
- 1.4035926604270934
- 1.4012108373641967
- 1.4059125447273255
- 1.4043081665039063
- 1.402150604724884
- 1.404062521457672
- 1.4218182826042176
- 1.4017099285125731
- 1.3983188271522522
train_accuracy:
- 0.0
- 0.103
- 0.145
- 0.105
- 0.164
- 0.0
- 0.169
- 0.0
- 0.171
- 0.0
- 0.161
- 0.0
- 0.0
- 0.17
- 0.21
- 0.0
- 0.25
- 0.0
- 0.275
- 0.202
- 0.229
- 0.0
- 0.278
- 0.216
- 0.256
- 0.255
- 0.275
- 0.295
- 0.0
- 0.255
- 0.27
- 0.0
- 0.226
- 0.279
- 0.31
- 0.0
- 0.317
- 0.0
- 0.0
- 0.272
- 0.0
- 0.281
- 0.263
- 0.0
- 0.322
- 0.299
- 0.281
- 0.266
- 0.28
- 0.301
- 0.29
- 0.0
- 0.0
- 0.0
- 0.279
- 0.271
- 0.261
- 0.263
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.298
- 0.273
- 0.313
- 0.0
- 0.291
- 0.311
- 0.0
- 0.338
- 0.343
- 0.378
- 0.32
- 0.0
- 0.0
- 0.339
- 0.318
- 0.329
- 0.299
- 0.314
- 0.0
- 0.35
- 0.0
- 0.0
- 0.332
- 0.0
- 0.374
- 0.0
- 0.0
- 0.361
- 0.382
- 0.327
- 0.343
- 0.324
- 0.0
- 0.346
- 0.0
- 0.324
- 0.313
train_loss:
- 2.129
- 2.882
- 2.681
- 2.699
- 2.501
- 2.372
- 1.75
- 1.775
- 2.226
- 2.182
- 2.171
- 1.522
- 1.531
- 2.571
- 1.882
- 1.859
- 1.836
- 1.983
- 2.182
- 2.037
- 1.742
- 1.589
- 2.061
- 1.574
- 1.54
- 1.412
- 1.503
- 1.46
- 1.425
- 1.532
- 1.236
- 1.171
- 1.483
- 1.367
- 1.398
- 1.223
- 1.412
- 0.957
- 1.182
- 1.1
- 1.218
- 1.077
- 0.965
- 1.137
- 1.053
- 1.03
- 1.077
- 0.922
- 0.869
- 0.812
- 0.89
- 0.747
- 0.886
- 0.878
- 0.763
- 0.904
- 0.887
- 0.771
- 0.808
- 0.767
- 0.687
- 0.684
- 0.768
- 0.743
- 0.645
- 0.69
- 0.613
- 0.608
- 0.542
- 0.601
- 0.611
- 0.575
- 0.69
- 0.466
- 0.588
- 0.538
- 0.603
- 0.535
- 0.473
- 0.508
- 0.464
- 0.512
- 0.556
- 0.495
- 0.49
- 0.355
- 0.48
- 0.465
- 0.424
- 0.465
- 0.48
- 0.376
- 0.392
- 0.289
- 0.378
- 0.412
- 0.337
- 0.5
- 0.265
- 0.495
unequal: 0
verbose: 1
