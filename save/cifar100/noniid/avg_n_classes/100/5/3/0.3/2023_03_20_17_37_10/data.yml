avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0462
- 0.0966
- 0.1226
- 0.1318
- 0.1489
- 0.1617
- 0.1604
- 0.1738
- 0.1845
- 0.1885
- 0.1888
- 0.1981
- 0.1876
- 0.1851
- 0.2111
- 0.2014
- 0.2101
- 0.2053
- 0.2249
- 0.2168
- 0.2297
- 0.2242
- 0.2286
- 0.2354
- 0.2415
- 0.2441
- 0.2454
- 0.2414
- 0.2254
- 0.2382
- 0.2442
- 0.255
- 0.2529
- 0.2578
- 0.2372
- 0.2639
- 0.2656
- 0.2523
- 0.2667
- 0.2747
- 0.2706
- 0.2758
- 0.2791
- 0.2821
- 0.2801
- 0.2724
- 0.2799
- 0.2696
- 0.2694
- 0.2835
- 0.281
- 0.2819
- 0.2826
- 0.2906
- 0.2837
- 0.2872
- 0.2918
- 0.2807
- 0.2856
- 0.2893
- 0.2895
- 0.2959
- 0.2933
- 0.2921
- 0.291
- 0.2914
- 0.2971
- 0.2777
- 0.2923
- 0.2921
- 0.2849
- 0.2971
- 0.2973
- 0.2895
- 0.2879
- 0.295
- 0.294
- 0.2987
- 0.295
- 0.3008
- 0.3002
- 0.288
- 0.2999
- 0.3035
- 0.3022
- 0.3006
- 0.2968
- 0.3029
- 0.3063
- 0.3022
- 0.307
- 0.2999
- 0.2981
- 0.3002
- 0.2875
- 0.3022
- 0.3001
- 0.31
- 0.3013
- 0.3047
test_loss_list:
- 1.8191784858703612
- 1.7295294713973999
- 1.7031109523773194
- 1.693201014995575
- 1.6631327700614928
- 1.6579403758049012
- 1.6573470377922057
- 1.6280460357666016
- 1.6235187220573426
- 1.6291438126564026
- 1.6207941722869874
- 1.6029279446601867
- 1.6090091228485108
- 1.6049756836891174
- 1.5489199924468995
- 1.5558903861045836
- 1.542816698551178
- 1.5511540102958679
- 1.5282605791091919
- 1.5327046418190002
- 1.505470814704895
- 1.5126973152160645
- 1.4913053488731385
- 1.476580080986023
- 1.475935070514679
- 1.4851452374458314
- 1.4848320960998536
- 1.4864217662811279
- 1.4951338958740235
- 1.476022391319275
- 1.4634659838676454
- 1.4580949831008911
- 1.460313262939453
- 1.457769637107849
- 1.481266541481018
- 1.4277050256729127
- 1.4381870222091675
- 1.4475414204597472
- 1.4199603819847106
- 1.4257187128067017
- 1.428990294933319
- 1.4421570158004762
- 1.4380435013771058
- 1.450968267917633
- 1.4571950268745422
- 1.4500120306015014
- 1.4411161541938782
- 1.45357426404953
- 1.4562738728523255
- 1.4246299934387208
- 1.4245942378044127
- 1.4167570567131043
- 1.424348337650299
- 1.423853073120117
- 1.4288365316390992
- 1.4333073091506958
- 1.426308376789093
- 1.4390936398506164
- 1.4204119515419007
- 1.4296814489364624
- 1.4268200063705445
- 1.4216427421569824
- 1.4443486785888673
- 1.4334901475906372
- 1.4337410473823546
- 1.4241795301437379
- 1.429087269306183
- 1.3007716608047486
- 1.3289682006835937
- 1.3435481190681458
- 1.3761261534690856
- 1.367240116596222
- 1.3815241694450378
- 1.387439706325531
- 1.3858242702484131
- 1.3712287712097169
- 1.3799488019943238
- 1.379842460155487
- 1.390656807422638
- 1.3898582935333252
- 1.4064696717262268
- 1.4027078437805176
- 1.3853859949111937
- 1.391102328300476
- 1.3926770639419557
- 1.3977188563346863
- 1.4078870511054993
- 1.4094212293624877
- 1.4142675709724426
- 1.4168661141395569
- 1.4007962512969971
- 1.4060250735282898
- 1.4194465208053588
- 1.4135899829864502
- 1.4265142107009887
- 1.3962132120132447
- 1.400650954246521
- 1.398898673057556
- 1.4246539855003357
- 1.4119064497947693
train_accuracy:
- 0.0
- 0.121
- 0.148
- 0.143
- 0.153
- 0.138
- 0.132
- 0.206
- 0.169
- 0.152
- 0.2
- 0.226
- 0.194
- 0.0
- 0.233
- 0.0
- 0.0
- 0.0
- 0.246
- 0.251
- 0.205
- 0.0
- 0.214
- 0.0
- 0.197
- 0.278
- 0.0
- 0.255
- 0.295
- 0.0
- 0.206
- 0.221
- 0.261
- 0.269
- 0.291
- 0.0
- 0.238
- 0.0
- 0.0
- 0.267
- 0.301
- 0.271
- 0.318
- 0.322
- 0.255
- 0.263
- 0.29
- 0.0
- 0.0
- 0.255
- 0.262
- 0.301
- 0.0
- 0.358
- 0.301
- 0.292
- 0.309
- 0.0
- 0.297
- 0.0
- 0.288
- 0.315
- 0.305
- 0.0
- 0.0
- 0.0
- 0.373
- 0.0
- 0.351
- 0.0
- 0.274
- 0.324
- 0.336
- 0.302
- 0.0
- 0.304
- 0.0
- 0.341
- 0.0
- 0.338
- 0.0
- 0.322
- 0.376
- 0.329
- 0.313
- 0.328
- 0.363
- 0.348
- 0.311
- 0.0
- 0.0
- 0.374
- 0.286
- 0.0
- 0.0
- 0.0
- 0.363
- 0.299
- 0.392
- 0.0
train_loss:
- 3.181
- 3.735
- 3.391
- 2.473
- 3.231
- 2.929
- 1.785
- 2.788
- 2.748
- 2.53
- 2.051
- 2.016
- 1.507
- 1.334
- 2.056
- 1.479
- 1.684
- 1.449
- 2.138
- 1.356
- 1.853
- 1.227
- 1.366
- 1.718
- 1.581
- 1.693
- 1.374
- 1.325
- 1.17
- 1.223
- 1.299
- 1.586
- 1.239
- 1.335
- 0.925
- 1.37
- 1.134
- 1.143
- 1.205
- 1.277
- 1.057
- 1.111
- 1.323
- 1.071
- 1.2
- 0.977
- 1.044
- 0.763
- 0.882
- 0.948
- 0.927
- 0.918
- 0.848
- 0.911
- 0.72
- 0.815
- 0.898
- 0.803
- 0.777
- 0.681
- 0.691
- 0.834
- 0.597
- 0.742
- 0.723
- 0.653
- 0.626
- 0.742
- 0.678
- 0.645
- 0.579
- 0.667
- 0.569
- 0.567
- 0.534
- 0.635
- 0.547
- 0.532
- 0.504
- 0.484
- 0.468
- 0.528
- 0.517
- 0.507
- 0.415
- 0.481
- 0.472
- 0.431
- 0.356
- 0.421
- 0.485
- 0.405
- 0.422
- 0.417
- 0.455
- 0.527
- 0.367
- 0.379
- 0.363
- 0.405
unequal: 0
verbose: 1
