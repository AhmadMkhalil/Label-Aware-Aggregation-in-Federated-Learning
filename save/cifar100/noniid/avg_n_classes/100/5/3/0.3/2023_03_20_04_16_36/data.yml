avg_train_accuracy: 0.322
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0453
- 0.0904
- 0.107
- 0.1314
- 0.1481
- 0.1399
- 0.1517
- 0.1747
- 0.1695
- 0.1818
- 0.1925
- 0.1913
- 0.1934
- 0.2027
- 0.1906
- 0.2076
- 0.216
- 0.2184
- 0.221
- 0.2269
- 0.2255
- 0.2294
- 0.2371
- 0.238
- 0.2407
- 0.245
- 0.2416
- 0.2331
- 0.2477
- 0.2426
- 0.2515
- 0.2529
- 0.2514
- 0.2509
- 0.2425
- 0.2421
- 0.2367
- 0.2602
- 0.257
- 0.2676
- 0.2654
- 0.2688
- 0.2576
- 0.2684
- 0.2733
- 0.254
- 0.2571
- 0.2537
- 0.2656
- 0.2643
- 0.2704
- 0.2705
- 0.2808
- 0.2789
- 0.267
- 0.2717
- 0.2786
- 0.2783
- 0.2804
- 0.2678
- 0.2792
- 0.284
- 0.2831
- 0.2789
- 0.2706
- 0.2798
- 0.2818
- 0.2815
- 0.2744
- 0.281
- 0.2537
- 0.2812
- 0.2794
- 0.2905
- 0.2764
- 0.2859
- 0.2861
- 0.2896
- 0.2928
- 0.2892
- 0.294
- 0.2955
- 0.2891
- 0.2906
- 0.2895
- 0.2967
- 0.2954
- 0.2931
- 0.2921
- 0.2942
- 0.283
- 0.2942
- 0.2932
- 0.2954
- 0.2984
- 0.2914
- 0.2801
- 0.2648
- 0.293
- 0.2948
test_loss_list:
- 1.8203963041305542
- 1.748814549446106
- 1.701517481803894
- 1.677248318195343
- 1.6639554262161256
- 1.675928852558136
- 1.6437753343582153
- 1.6295911741256714
- 1.6240895128250121
- 1.6151178455352784
- 1.6125268721580506
- 1.597641611099243
- 1.6062459468841552
- 1.5882785868644715
- 1.5868356561660766
- 1.5572931456565857
- 1.549144196510315
- 1.549491708278656
- 1.5495195603370666
- 1.5325073957443238
- 1.5351129627227784
- 1.5201391935348512
- 1.5127653551101685
- 1.5131072735786437
- 1.5238203597068787
- 1.520980668067932
- 1.5131160259246825
- 1.5264620614051818
- 1.5031426692008971
- 1.5211387610435485
- 1.509669041633606
- 1.5079748463630676
- 1.5122989296913147
- 1.499437963962555
- 1.5105027556419373
- 1.4841844820976258
- 1.4752238702774048
- 1.4446970415115357
- 1.4459190368652344
- 1.4594450664520264
- 1.448959150314331
- 1.4602775955200196
- 1.4692730736732482
- 1.4494184422492982
- 1.4598720288276672
- 1.4708297729492188
- 1.4616325855255128
- 1.451113564968109
- 1.4389410853385924
- 1.428245437145233
- 1.4430874609947204
- 1.430476315021515
- 1.4452763962745667
- 1.4381818199157714
- 1.4419415831565856
- 1.4345111703872682
- 1.4370071864128113
- 1.439992401599884
- 1.4369686985015868
- 1.4424050092697143
- 1.4441193532943726
- 1.4432229447364806
- 1.4514437913894653
- 1.464719567298889
- 1.4504520249366761
- 1.4387900400161744
- 1.436069917678833
- 1.4251282548904418
- 1.4299279975891113
- 1.4188469576835632
- 1.3627822422981262
- 1.3312696433067321
- 1.3838044118881225
- 1.367597634792328
- 1.3925159192085266
- 1.3916768336296081
- 1.383866424560547
- 1.3950809025764466
- 1.4119252634048463
- 1.4013981413841248
- 1.411359589099884
- 1.4239383482933043
- 1.4331545567512511
- 1.4295527839660644
- 1.4510491228103637
- 1.4416913652420045
- 1.441485207080841
- 1.442579860687256
- 1.443295259475708
- 1.4532856154441833
- 1.450509696006775
- 1.4349419617652892
- 1.4235047054290773
- 1.4373878979682921
- 1.4460736179351807
- 1.4414441609382629
- 1.4614925909042358
- 1.367374496459961
- 1.3273633456230163
- 1.3654840517044067
train_accuracy:
- 0.052
- 0.0
- 0.0
- 0.127
- 0.174
- 0.0
- 0.143
- 0.222
- 0.0
- 0.212
- 0.24
- 0.219
- 0.229
- 0.207
- 0.0
- 0.225
- 0.208
- 0.0
- 0.204
- 0.299
- 0.205
- 0.302
- 0.0
- 0.201
- 0.236
- 0.307
- 0.0
- 0.196
- 0.292
- 0.278
- 0.305
- 0.249
- 0.285
- 0.301
- 0.0
- 0.0
- 0.0
- 0.325
- 0.326
- 0.3
- 0.0
- 0.289
- 0.0
- 0.284
- 0.316
- 0.33
- 0.0
- 0.0
- 0.282
- 0.0
- 0.308
- 0.268
- 0.349
- 0.266
- 0.327
- 0.331
- 0.31
- 0.329
- 0.289
- 0.0
- 0.336
- 0.3
- 0.331
- 0.321
- 0.333
- 0.0
- 0.295
- 0.289
- 0.0
- 0.328
- 0.0
- 0.0
- 0.0
- 0.338
- 0.0
- 0.0
- 0.263
- 0.0
- 0.297
- 0.283
- 0.279
- 0.35
- 0.295
- 0.295
- 0.299
- 0.332
- 0.338
- 0.336
- 0.334
- 0.308
- 0.0
- 0.277
- 0.312
- 0.338
- 0.301
- 0.289
- 0.283
- 0.0
- 0.371
- 0.322
train_loss:
- 3.208
- 2.014
- 2.699
- 2.639
- 3.143
- 1.747
- 2.301
- 2.918
- 2.146
- 2.082
- 2.534
- 2.183
- 1.449
- 2.267
- 1.494
- 2.086
- 2.212
- 1.861
- 1.619
- 2.257
- 1.605
- 1.716
- 1.674
- 1.92
- 1.811
- 1.793
- 1.616
- 1.166
- 1.691
- 1.222
- 1.573
- 1.608
- 1.187
- 1.269
- 1.013
- 1.166
- 0.948
- 1.323
- 1.193
- 1.24
- 1.118
- 1.168
- 0.95
- 1.129
- 1.155
- 0.892
- 0.855
- 0.76
- 0.827
- 0.802
- 0.872
- 0.934
- 0.901
- 0.906
- 0.676
- 0.712
- 0.818
- 0.811
- 0.745
- 0.586
- 0.695
- 0.642
- 0.753
- 0.752
- 0.573
- 0.715
- 0.592
- 0.768
- 0.593
- 0.666
- 0.649
- 0.42
- 0.626
- 0.642
- 0.591
- 0.544
- 0.58
- 0.588
- 0.53
- 0.582
- 0.484
- 0.409
- 0.462
- 0.433
- 0.451
- 0.393
- 0.394
- 0.488
- 0.411
- 0.333
- 0.549
- 0.317
- 0.45
- 0.294
- 0.389
- 0.393
- 0.511
- 0.558
- 0.355
- 0.405
unequal: 0
verbose: 1
