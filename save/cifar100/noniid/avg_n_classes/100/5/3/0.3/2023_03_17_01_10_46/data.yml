avg_train_accuracy: 0.371
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0492
- 0.0949
- 0.1157
- 0.1326
- 0.1423
- 0.1529
- 0.1568
- 0.1618
- 0.1749
- 0.1678
- 0.1816
- 0.19
- 0.189
- 0.1969
- 0.2029
- 0.2083
- 0.2131
- 0.2165
- 0.2165
- 0.2296
- 0.2084
- 0.2269
- 0.2317
- 0.2339
- 0.2291
- 0.2363
- 0.244
- 0.2294
- 0.2524
- 0.2455
- 0.2505
- 0.2576
- 0.2534
- 0.2429
- 0.2591
- 0.2477
- 0.2645
- 0.2736
- 0.2702
- 0.2555
- 0.2568
- 0.2627
- 0.2744
- 0.2736
- 0.2712
- 0.2677
- 0.2584
- 0.2752
- 0.2754
- 0.2607
- 0.2764
- 0.2824
- 0.2777
- 0.2809
- 0.2656
- 0.2626
- 0.2785
- 0.284
- 0.2909
- 0.2867
- 0.2727
- 0.2732
- 0.2889
- 0.2892
- 0.2911
- 0.2902
- 0.2948
- 0.2993
- 0.2912
- 0.2793
- 0.2911
- 0.2767
- 0.2825
- 0.2944
- 0.2929
- 0.2856
- 0.2953
- 0.2965
- 0.2991
- 0.2971
- 0.3057
- 0.2883
- 0.2977
- 0.3024
- 0.2827
- 0.3022
- 0.3006
- 0.2985
- 0.2967
- 0.2972
- 0.3047
- 0.2976
- 0.2892
- 0.3018
- 0.2925
- 0.2895
- 0.29
- 0.2968
- 0.3016
- 0.3039
test_loss_list:
- 1.8061104393005372
- 1.736557879447937
- 1.7076282238960265
- 1.691573555469513
- 1.6608778977394103
- 1.6562687849998474
- 1.6586868405342101
- 1.6468013834953308
- 1.6267030572891235
- 1.6296229481697082
- 1.600573422908783
- 1.6024076819419861
- 1.605413284301758
- 1.5905657625198364
- 1.590508041381836
- 1.5842337036132812
- 1.569134066104889
- 1.5753818845748901
- 1.5812461280822754
- 1.5750247383117675
- 1.579565668106079
- 1.5454487442970275
- 1.541425688266754
- 1.5396438264846801
- 1.5383531665802002
- 1.5252633690834045
- 1.5087979412078858
- 1.5180469703674317
- 1.4805271863937377
- 1.4922674036026
- 1.5023184871673585
- 1.498947434425354
- 1.4987533402442932
- 1.5155419516563415
- 1.4735870504379271
- 1.5116211986541748
- 1.4742239809036255
- 1.4599721097946168
- 1.4753051972389222
- 1.488929626941681
- 1.4808754873275758
- 1.452684462070465
- 1.4538307785987854
- 1.4572933197021485
- 1.4529349946975707
- 1.4693181133270263
- 1.4668277859687806
- 1.4275451064109803
- 1.441119270324707
- 1.461262152194977
- 1.4194182324409486
- 1.4383748769760132
- 1.4340963530540467
- 1.4282096815109253
- 1.446400043964386
- 1.4564277625083923
- 1.4182456588745118
- 1.4139047050476075
- 1.4277454566955567
- 1.4205183053016663
- 1.4469719552993774
- 1.4212945222854614
- 1.4174515533447265
- 1.43160315990448
- 1.4197660446166993
- 1.4232782292366029
- 1.4215558242797852
- 1.4332346892356873
- 1.425727925300598
- 1.4454290795326232
- 1.4328780698776244
- 1.4494129157066344
- 1.4271991276741027
- 1.3981220078468324
- 1.4183443880081177
- 1.431664731502533
- 1.3976953125
- 1.4022782635688782
- 1.4169911074638366
- 1.4148937940597535
- 1.418355906009674
- 1.437524104118347
- 1.4169387865066527
- 1.4104836463928223
- 1.4402919340133666
- 1.4207444763183594
- 1.4111719703674317
- 1.4225940608978271
- 1.4085117602348327
- 1.4114685678482055
- 1.4263694071769715
- 1.4229119086265565
- 1.4305415153503418
- 1.4009025335311889
- 1.423513824939728
- 1.4170237064361573
- 1.416792905330658
- 1.401508195400238
- 1.3966426348686218
- 1.3927201652526855
train_accuracy:
- 0.048
- 0.098
- 0.126
- 0.0
- 0.147
- 0.17
- 0.189
- 0.0
- 0.185
- 0.0
- 0.202
- 0.242
- 0.0
- 0.218
- 0.0
- 0.206
- 0.283
- 0.227
- 0.252
- 0.251
- 0.245
- 0.246
- 0.262
- 0.269
- 0.257
- 0.273
- 0.246
- 0.242
- 0.331
- 0.268
- 0.269
- 0.274
- 0.259
- 0.246
- 0.311
- 0.254
- 0.267
- 0.314
- 0.309
- 0.0
- 0.0
- 0.328
- 0.334
- 0.298
- 0.0
- 0.312
- 0.27
- 0.0
- 0.291
- 0.0
- 0.303
- 0.354
- 0.287
- 0.337
- 0.0
- 0.0
- 0.319
- 0.326
- 0.317
- 0.319
- 0.0
- 0.0
- 0.304
- 0.322
- 0.339
- 0.337
- 0.319
- 0.307
- 0.309
- 0.0
- 0.0
- 0.302
- 0.311
- 0.0
- 0.352
- 0.288
- 0.344
- 0.353
- 0.298
- 0.323
- 0.336
- 0.0
- 0.34
- 0.346
- 0.0
- 0.358
- 0.0
- 0.0
- 0.342
- 0.0
- 0.342
- 0.34
- 0.0
- 0.0
- 0.0
- 0.0
- 0.342
- 0.316
- 0.361
- 0.371
train_loss:
- 4.247
- 3.712
- 3.484
- 2.597
- 2.666
- 3.012
- 2.383
- 2.254
- 2.832
- 1.756
- 2.262
- 2.519
- 1.972
- 2.509
- 1.978
- 2.171
- 1.968
- 2.112
- 2.046
- 2.168
- 1.371
- 1.687
- 1.917
- 1.64
- 1.486
- 1.518
- 1.524
- 1.386
- 1.821
- 1.506
- 1.536
- 1.546
- 1.231
- 1.145
- 1.342
- 1.088
- 1.361
- 1.42
- 1.303
- 1.083
- 1.048
- 0.998
- 1.114
- 1.261
- 1.117
- 0.885
- 0.99
- 1.029
- 0.983
- 0.883
- 1.045
- 0.893
- 0.833
- 0.859
- 0.793
- 0.846
- 0.909
- 0.739
- 0.72
- 0.699
- 0.87
- 0.679
- 0.735
- 0.575
- 0.789
- 0.729
- 0.714
- 0.535
- 0.667
- 0.622
- 0.537
- 0.674
- 0.747
- 0.689
- 0.449
- 0.603
- 0.592
- 0.626
- 0.398
- 0.499
- 0.408
- 0.643
- 0.501
- 0.533
- 0.616
- 0.381
- 0.56
- 0.46
- 0.568
- 0.426
- 0.312
- 0.409
- 0.528
- 0.398
- 0.525
- 0.557
- 0.569
- 0.508
- 0.425
- 0.374
unequal: 0
verbose: 1
