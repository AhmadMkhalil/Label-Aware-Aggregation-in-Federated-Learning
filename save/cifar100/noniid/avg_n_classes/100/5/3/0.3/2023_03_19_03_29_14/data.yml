avg_train_accuracy: 0.283
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0459
- 0.1038
- 0.1207
- 0.1372
- 0.1469
- 0.1612
- 0.1637
- 0.1594
- 0.1667
- 0.1848
- 0.1779
- 0.1752
- 0.2037
- 0.2017
- 0.2134
- 0.2173
- 0.2108
- 0.2063
- 0.2231
- 0.2248
- 0.218
- 0.225
- 0.2284
- 0.2298
- 0.2276
- 0.2236
- 0.2342
- 0.2485
- 0.2482
- 0.2519
- 0.2422
- 0.2503
- 0.2517
- 0.247
- 0.2642
- 0.2612
- 0.2646
- 0.2658
- 0.264
- 0.2497
- 0.2528
- 0.273
- 0.2541
- 0.2683
- 0.2775
- 0.2597
- 0.2751
- 0.2657
- 0.2758
- 0.2712
- 0.2733
- 0.2762
- 0.2843
- 0.2764
- 0.2799
- 0.2721
- 0.2779
- 0.2813
- 0.2897
- 0.2843
- 0.2914
- 0.2723
- 0.2828
- 0.2916
- 0.2942
- 0.2906
- 0.2898
- 0.2872
- 0.2934
- 0.2924
- 0.2749
- 0.2892
- 0.2949
- 0.2916
- 0.2979
- 0.2926
- 0.2975
- 0.2893
- 0.2931
- 0.3001
- 0.2943
- 0.2879
- 0.293
- 0.2806
- 0.2951
- 0.3004
- 0.2977
- 0.2941
- 0.2936
- 0.3015
- 0.3006
- 0.2982
- 0.2953
- 0.299
- 0.3028
- 0.2962
- 0.3042
- 0.3028
- 0.3019
- 0.3035
test_loss_list:
- 1.8115580129623412
- 1.7352593326568604
- 1.7073033571243286
- 1.6828973817825317
- 1.655302450656891
- 1.6409268116950988
- 1.6365957283973693
- 1.627048454284668
- 1.621922960281372
- 1.5857487535476684
- 1.5912428736686706
- 1.5819268655776977
- 1.5522459578514098
- 1.5492374300956726
- 1.5485752725601196
- 1.540253918170929
- 1.5305782628059388
- 1.5356173634529113
- 1.5184344840049744
- 1.5211756420135498
- 1.525994439125061
- 1.4987953877449036
- 1.492182502746582
- 1.491334707736969
- 1.4966562247276307
- 1.491932520866394
- 1.4751702880859374
- 1.472164559364319
- 1.4839681768417359
- 1.4855182766914368
- 1.4981040620803834
- 1.4846427154541015
- 1.4710490822792053
- 1.4813659358024598
- 1.4555134534835816
- 1.4727163648605346
- 1.4696698212623596
- 1.465208077430725
- 1.4611399531364442
- 1.472515618801117
- 1.4607334804534913
- 1.4492194080352783
- 1.465829303264618
- 1.4509585738182067
- 1.440811870098114
- 1.4536894750595093
- 1.4475766944885253
- 1.4513753843307495
- 1.4325202989578247
- 1.4276122903823854
- 1.429348692893982
- 1.4291919517517089
- 1.4257172393798827
- 1.4211837863922119
- 1.4251419186592102
- 1.423905041217804
- 1.4210231280326844
- 1.4117169213294982
- 1.415436773300171
- 1.416783242225647
- 1.4253991365432739
- 1.4461230516433716
- 1.4149772763252257
- 1.4194260263442993
- 1.4223116517066956
- 1.4399970936775208
- 1.4378297924995422
- 1.4331476092338562
- 1.429298186302185
- 1.4460426378250122
- 1.4508452558517455
- 1.4319354557991029
- 1.432243938446045
- 1.4477161169052124
- 1.4412967443466187
- 1.4428946495056152
- 1.4392760181427002
- 1.4507309484481812
- 1.444880177974701
- 1.440198965072632
- 1.4431259608268738
- 1.4490328192710877
- 1.4378446316719056
- 1.430149757862091
- 1.4154776763916015
- 1.4076996970176696
- 1.412300684452057
- 1.4172416090965272
- 1.4198676705360413
- 1.407098183631897
- 1.4081573939323426
- 1.4107765674591064
- 1.4122925591468811
- 1.4175293850898742
- 1.4081811118125915
- 1.4187809085845948
- 1.421168920993805
- 1.416110155582428
- 1.4280035400390625
- 1.4352083349227904
train_accuracy:
- 0.042
- 0.12
- 0.116
- 0.147
- 0.123
- 0.0
- 0.193
- 0.0
- 0.166
- 0.162
- 0.0
- 0.171
- 0.242
- 0.175
- 0.22
- 0.0
- 0.0
- 0.0
- 0.233
- 0.249
- 0.2
- 0.0
- 0.0
- 0.216
- 0.264
- 0.0
- 0.235
- 0.265
- 0.287
- 0.231
- 0.241
- 0.237
- 0.278
- 0.0
- 0.313
- 0.295
- 0.259
- 0.262
- 0.0
- 0.0
- 0.253
- 0.266
- 0.25
- 0.319
- 0.329
- 0.243
- 0.292
- 0.281
- 0.256
- 0.0
- 0.27
- 0.0
- 0.281
- 0.294
- 0.266
- 0.0
- 0.308
- 0.0
- 0.341
- 0.334
- 0.337
- 0.31
- 0.273
- 0.281
- 0.321
- 0.285
- 0.309
- 0.0
- 0.0
- 0.353
- 0.0
- 0.361
- 0.316
- 0.327
- 0.286
- 0.281
- 0.3
- 0.272
- 0.0
- 0.34
- 0.329
- 0.271
- 0.304
- 0.0
- 0.297
- 0.34
- 0.0
- 0.322
- 0.304
- 0.336
- 0.324
- 0.335
- 0.0
- 0.348
- 0.0
- 0.0
- 0.346
- 0.0
- 0.358
- 0.283
train_loss:
- 3.217
- 3.74
- 2.702
- 2.547
- 2.559
- 2.431
- 2.283
- 1.711
- 1.577
- 2.865
- 1.518
- 1.533
- 2.467
- 2.138
- 2.316
- 1.84
- 1.875
- 1.455
- 2.173
- 1.609
- 1.354
- 1.778
- 1.573
- 1.65
- 1.276
- 1.17
- 1.548
- 1.658
- 1.517
- 1.676
- 1.287
- 1.304
- 1.324
- 1.062
- 1.52
- 1.38
- 1.405
- 1.165
- 1.224
- 1.074
- 1.114
- 1.264
- 0.94
- 1.082
- 0.925
- 0.903
- 1.146
- 0.827
- 0.899
- 0.914
- 0.942
- 0.9
- 1.016
- 0.834
- 0.854
- 0.711
- 0.767
- 0.876
- 0.821
- 0.674
- 0.786
- 0.72
- 0.803
- 0.64
- 0.555
- 0.541
- 0.578
- 0.591
- 0.674
- 0.489
- 0.602
- 0.709
- 0.461
- 0.521
- 0.508
- 0.517
- 0.622
- 0.577
- 0.518
- 0.445
- 0.504
- 0.552
- 0.468
- 0.603
- 0.549
- 0.462
- 0.49
- 0.397
- 0.451
- 0.396
- 0.451
- 0.479
- 0.397
- 0.391
- 0.397
- 0.388
- 0.325
- 0.373
- 0.323
- 0.214
unequal: 0
verbose: 1
