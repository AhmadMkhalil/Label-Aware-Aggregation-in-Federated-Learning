avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0447
- 0.0913
- 0.1178
- 0.1312
- 0.1474
- 0.1523
- 0.1626
- 0.1645
- 0.171
- 0.1754
- 0.1794
- 0.1878
- 0.1752
- 0.1955
- 0.1999
- 0.2071
- 0.1893
- 0.2198
- 0.2174
- 0.2085
- 0.2288
- 0.2158
- 0.2277
- 0.2275
- 0.2322
- 0.2335
- 0.2393
- 0.228
- 0.2371
- 0.2379
- 0.2422
- 0.2515
- 0.2518
- 0.2548
- 0.2582
- 0.2558
- 0.2547
- 0.2575
- 0.2525
- 0.2694
- 0.2646
- 0.2655
- 0.2714
- 0.2729
- 0.2571
- 0.2657
- 0.2617
- 0.265
- 0.2747
- 0.2773
- 0.2784
- 0.2773
- 0.2695
- 0.2843
- 0.2783
- 0.2823
- 0.2803
- 0.2775
- 0.284
- 0.2863
- 0.2906
- 0.2702
- 0.2903
- 0.2889
- 0.2786
- 0.2886
- 0.276
- 0.2732
- 0.2878
- 0.2879
- 0.2732
- 0.2862
- 0.2908
- 0.2887
- 0.2873
- 0.2948
- 0.2857
- 0.276
- 0.285
- 0.2895
- 0.294
- 0.2729
- 0.2781
- 0.2932
- 0.3011
- 0.2947
- 0.2965
- 0.2982
- 0.2983
- 0.2971
- 0.2935
- 0.3008
- 0.3027
- 0.3031
- 0.2893
- 0.2988
- 0.3023
- 0.3015
- 0.3015
- 0.3034
test_loss_list:
- 1.8180968570709228
- 1.7482366466522217
- 1.7216698956489562
- 1.6944278168678284
- 1.6647585201263428
- 1.6547264122962952
- 1.6491457962989806
- 1.6448129558563231
- 1.6442088985443115
- 1.6231557130813599
- 1.6133396911621094
- 1.5999888324737548
- 1.6198834156990052
- 1.5680175924301147
- 1.5783449268341065
- 1.5599163842201234
- 1.5926366138458252
- 1.5370966148376466
- 1.5342366766929627
- 1.5505875444412232
- 1.5111704444885254
- 1.5423208642005921
- 1.5123976135253907
- 1.510426995754242
- 1.4958142256736755
- 1.488814311027527
- 1.4722991847991944
- 1.4968073201179504
- 1.4741798043251038
- 1.483081703186035
- 1.4776720380783082
- 1.4706257271766663
- 1.4673992395401
- 1.4614153289794922
- 1.4740375566482544
- 1.468589904308319
- 1.4713970732688904
- 1.4782273554801941
- 1.4734495615959167
- 1.456877248287201
- 1.4665656638145448
- 1.4762283635139466
- 1.4661364316940309
- 1.4632381796836853
- 1.4772288370132447
- 1.4553006815910339
- 1.4611418771743774
- 1.4490357208251954
- 1.442402093410492
- 1.4270347905158998
- 1.4294635796546935
- 1.4314935564994813
- 1.4373234462738038
- 1.4317580151557923
- 1.439792149066925
- 1.449619574546814
- 1.4345785999298095
- 1.4410738110542298
- 1.4255370903015137
- 1.4368784523010254
- 1.4413780355453492
- 1.4612141704559327
- 1.435074472427368
- 1.4458448553085328
- 1.4465268754959106
- 1.4328388833999635
- 1.446771183013916
- 1.440734224319458
- 1.408002007007599
- 1.4102615308761597
- 1.4288894534111023
- 1.4095015573501586
- 1.4030486488342284
- 1.4091261982917787
- 1.4189999032020568
- 1.4028927183151245
- 1.4068966293334961
- 1.428510489463806
- 1.3984254026412963
- 1.417217891216278
- 1.4176390290260314
- 1.44728933095932
- 1.42548828125
- 1.38840815782547
- 1.405468761920929
- 1.4081186604499818
- 1.4125923538208007
- 1.410588369369507
- 1.4098524570465087
- 1.4088233613967895
- 1.4158465456962586
- 1.4208432579040526
- 1.389729425907135
- 1.4097606205940247
- 1.4269734978675843
- 1.4004799675941468
- 1.390782070159912
- 1.4023879981040954
- 1.395571129322052
- 1.3959549427032472
train_accuracy:
- 0.049
- 0.1
- 0.114
- 0.116
- 0.164
- 0.0
- 0.0
- 0.19
- 0.206
- 0.0
- 0.0
- 0.17
- 0.0
- 0.0
- 0.238
- 0.0
- 0.0
- 0.259
- 0.234
- 0.0
- 0.253
- 0.0
- 0.255
- 0.233
- 0.261
- 0.251
- 0.303
- 0.225
- 0.293
- 0.256
- 0.303
- 0.302
- 0.302
- 0.0
- 0.273
- 0.294
- 0.262
- 0.29
- 0.0
- 0.302
- 0.299
- 0.313
- 0.309
- 0.29
- 0.0
- 0.319
- 0.0
- 0.287
- 0.32
- 0.34
- 0.0
- 0.338
- 0.302
- 0.299
- 0.0
- 0.338
- 0.0
- 0.0
- 0.0
- 0.344
- 0.359
- 0.0
- 0.312
- 0.345
- 0.0
- 0.328
- 0.317
- 0.0
- 0.357
- 0.333
- 0.338
- 0.333
- 0.332
- 0.329
- 0.0
- 0.312
- 0.0
- 0.0
- 0.0
- 0.329
- 0.338
- 0.336
- 0.353
- 0.315
- 0.319
- 0.33
- 0.334
- 0.0
- 0.37
- 0.324
- 0.287
- 0.342
- 0.0
- 0.319
- 0.336
- 0.361
- 0.0
- 0.0
- 0.367
- 0.0
train_loss:
- 4.214
- 3.688
- 2.648
- 2.495
- 2.625
- 2.326
- 2.315
- 2.15
- 1.949
- 2.023
- 2.153
- 2.208
- 1.454
- 2.007
- 2.184
- 1.937
- 1.207
- 2.491
- 1.786
- 1.313
- 2.337
- 1.284
- 1.596
- 1.516
- 1.643
- 1.518
- 1.743
- 1.173
- 1.43
- 1.222
- 1.548
- 1.555
- 1.345
- 1.358
- 1.334
- 1.367
- 1.078
- 1.141
- 1.15
- 1.359
- 1.08
- 1.268
- 1.211
- 1.056
- 0.991
- 0.945
- 0.971
- 0.914
- 1.07
- 0.861
- 0.974
- 0.934
- 0.833
- 0.947
- 0.813
- 0.786
- 0.855
- 0.707
- 0.653
- 0.754
- 0.685
- 0.731
- 0.677
- 0.662
- 0.686
- 0.663
- 0.628
- 0.531
- 0.751
- 0.549
- 0.66
- 0.659
- 0.565
- 0.594
- 0.541
- 0.484
- 0.529
- 0.525
- 0.427
- 0.402
- 0.385
- 0.614
- 0.609
- 0.467
- 0.458
- 0.395
- 0.529
- 0.527
- 0.478
- 0.412
- 0.476
- 0.34
- 0.468
- 0.326
- 0.504
- 0.345
- 0.439
- 0.41
- 0.33
- 0.424
unequal: 0
verbose: 1
