avg_train_accuracy: 0.367
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0474
- 0.0992
- 0.12
- 0.1375
- 0.1472
- 0.16
- 0.1694
- 0.1757
- 0.1813
- 0.1946
- 0.2001
- 0.2058
- 0.2109
- 0.2163
- 0.2167
- 0.2233
- 0.221
- 0.2285
- 0.2321
- 0.2353
- 0.2415
- 0.2435
- 0.2468
- 0.2496
- 0.2572
- 0.2568
- 0.2577
- 0.2578
- 0.2561
- 0.2631
- 0.2627
- 0.2646
- 0.2713
- 0.2694
- 0.2672
- 0.275
- 0.2777
- 0.28
- 0.2787
- 0.2793
- 0.2809
- 0.2828
- 0.284
- 0.2857
- 0.2828
- 0.2861
- 0.2859
- 0.2888
- 0.29
- 0.2902
- 0.2879
- 0.2881
- 0.2902
- 0.2917
- 0.2941
- 0.295
- 0.2972
- 0.2951
- 0.2968
- 0.2954
- 0.2967
- 0.2961
- 0.3004
- 0.2998
- 0.2963
- 0.3015
- 0.299
- 0.2998
- 0.2996
- 0.3018
- 0.3005
- 0.3032
- 0.302
- 0.297
- 0.3018
- 0.3021
- 0.301
- 0.3006
- 0.3014
- 0.3037
- 0.3039
- 0.3047
- 0.3072
- 0.3054
- 0.3036
- 0.3052
- 0.3048
- 0.3053
- 0.3073
- 0.3076
- 0.3079
- 0.3077
- 0.3083
- 0.3084
- 0.3107
- 0.3077
- 0.3088
- 0.3081
- 0.3054
- 0.3103
test_loss_list:
- 1.806776657104492
- 1.704286780357361
- 1.661801266670227
- 1.6410017728805542
- 1.6099534034729004
- 1.5904063963890076
- 1.5791279435157777
- 1.5606620597839356
- 1.5381119441986084
- 1.5255625891685485
- 1.526081109046936
- 1.5143755960464478
- 1.5108560919761658
- 1.4963690948486328
- 1.4784547352790833
- 1.4614613819122315
- 1.4526081824302672
- 1.4418592286109924
- 1.4346035742759704
- 1.4248185563087463
- 1.4171587562561034
- 1.4159281849861145
- 1.4141736459732055
- 1.4204595136642455
- 1.4078125190734863
- 1.3992527985572816
- 1.3995622301101684
- 1.3981153321266175
- 1.3928698754310609
- 1.3777689552307129
- 1.3747778582572936
- 1.3619766712188721
- 1.3517580461502074
- 1.3586706447601318
- 1.3525594329833985
- 1.3402042055130006
- 1.3346189999580382
- 1.3534883308410643
- 1.3418591547012328
- 1.3518113207817077
- 1.344939181804657
- 1.3426524186134339
- 1.330354824066162
- 1.3291049551963807
- 1.32474112033844
- 1.325554678440094
- 1.339469585418701
- 1.3349557137489318
- 1.3232875180244446
- 1.325465304851532
- 1.3275928378105164
- 1.327745134830475
- 1.3167004895210266
- 1.3213439917564391
- 1.331504602432251
- 1.326063232421875
- 1.3198650789260864
- 1.3352327537536621
- 1.3180986523628235
- 1.3120303297042846
- 1.304487931728363
- 1.3017183756828308
- 1.3065073609352111
- 1.3223970532417297
- 1.3081564331054687
- 1.3184822297096253
- 1.3258857798576356
- 1.3190409231185913
- 1.3164012908935547
- 1.3143309092521667
- 1.3288744854927064
- 1.3176148414611817
- 1.3066495418548585
- 1.303644165992737
- 1.2992466497421264
- 1.3126595640182495
- 1.299781823158264
- 1.295075716972351
- 1.3015133738517761
- 1.3013148021697998
- 1.295396053791046
- 1.3003631186485292
- 1.2998091220855712
- 1.3044603061676026
- 1.3062765717506408
- 1.2991892719268798
- 1.3135792922973633
- 1.3089036536216736
- 1.2949827122688293
- 1.3157553243637086
- 1.3049477124214173
- 1.3038748455047608
- 1.3079036283493042
- 1.3213858270645142
- 1.3117877888679503
- 1.3019496870040894
- 1.2943822932243347
- 1.2963594722747802
- 1.2935993552207947
- 1.2969271421432496
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.18
- 0.17
- 0.181
- 0.0
- 0.21
- 0.0
- 0.0
- 0.233
- 0.0
- 0.242
- 0.251
- 0.255
- 0.0
- 0.212
- 0.0
- 0.0
- 0.218
- 0.26
- 0.287
- 0.283
- 0.279
- 0.248
- 0.271
- 0.278
- 0.0
- 0.0
- 0.304
- 0.0
- 0.296
- 0.294
- 0.3
- 0.0
- 0.0
- 0.298
- 0.331
- 0.295
- 0.325
- 0.0
- 0.285
- 0.311
- 0.303
- 0.323
- 0.323
- 0.329
- 0.315
- 0.0
- 0.324
- 0.332
- 0.0
- 0.318
- 0.33
- 0.324
- 0.307
- 0.333
- 0.343
- 0.0
- 0.0
- 0.0
- 0.334
- 0.346
- 0.0
- 0.0
- 0.366
- 0.302
- 0.324
- 0.332
- 0.0
- 0.355
- 0.312
- 0.337
- 0.305
- 0.357
- 0.316
- 0.338
- 0.34
- 0.0
- 0.0
- 0.334
- 0.329
- 0.314
- 0.0
- 0.0
- 0.329
- 0.358
- 0.0
- 0.358
- 0.0
- 0.344
- 0.37
- 0.37
- 0.32
- 0.346
- 0.0
- 0.383
- 0.378
- 0.367
train_loss:
- 3.781
- 2.641
- 2.484
- 2.959
- 2.27
- 2.502
- 2.664
- 2.322
- 2.027
- 2.221
- 2.367
- 2.105
- 2.262
- 1.971
- 1.712
- 1.648
- 1.64
- 1.808
- 1.756
- 1.488
- 1.68
- 1.587
- 1.596
- 1.736
- 1.508
- 1.49
- 1.418
- 1.378
- 1.327
- 1.211
- 1.27
- 1.185
- 1.158
- 1.261
- 1.074
- 1.098
- 1.045
- 1.209
- 1.012
- 1.141
- 1.018
- 1.006
- 0.937
- 0.962
- 0.87
- 0.94
- 0.931
- 0.866
- 0.801
- 0.842
- 0.82
- 0.797
- 0.713
- 0.734
- 0.767
- 0.751
- 0.708
- 0.697
- 0.674
- 0.649
- 0.639
- 0.614
- 0.626
- 0.605
- 0.599
- 0.604
- 0.564
- 0.566
- 0.525
- 0.511
- 0.548
- 0.514
- 0.504
- 0.483
- 0.484
- 0.491
- 0.485
- 0.452
- 0.444
- 0.444
- 0.425
- 0.414
- 0.429
- 0.391
- 0.396
- 0.414
- 0.393
- 0.4
- 0.42
- 0.362
- 0.371
- 0.348
- 0.357
- 0.32
- 0.351
- 0.337
- 0.349
- 0.319
- 0.355
- 0.319
unequal: 0
verbose: 1
