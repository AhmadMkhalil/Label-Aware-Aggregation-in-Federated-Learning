avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0433
- 0.108
- 0.1253
- 0.1396
- 0.1484
- 0.1616
- 0.1703
- 0.1725
- 0.1798
- 0.187
- 0.1929
- 0.202
- 0.204
- 0.2084
- 0.2118
- 0.2121
- 0.2206
- 0.223
- 0.2281
- 0.2285
- 0.2346
- 0.2352
- 0.2386
- 0.239
- 0.2432
- 0.2477
- 0.2521
- 0.2524
- 0.2561
- 0.2557
- 0.2597
- 0.2647
- 0.267
- 0.2653
- 0.2672
- 0.2704
- 0.266
- 0.269
- 0.2754
- 0.2754
- 0.2744
- 0.2787
- 0.2791
- 0.2778
- 0.2761
- 0.278
- 0.2822
- 0.2842
- 0.2849
- 0.2843
- 0.2861
- 0.2838
- 0.286
- 0.2868
- 0.2855
- 0.2885
- 0.2912
- 0.2916
- 0.2926
- 0.2913
- 0.2927
- 0.2923
- 0.2965
- 0.2934
- 0.2932
- 0.292
- 0.2971
- 0.2945
- 0.2939
- 0.2961
- 0.2966
- 0.2931
- 0.2948
- 0.2985
- 0.2965
- 0.3003
- 0.2992
- 0.3004
- 0.2942
- 0.2989
- 0.3024
- 0.3016
- 0.301
- 0.2987
- 0.2996
- 0.3013
- 0.2993
- 0.2974
- 0.3005
- 0.3009
- 0.3005
- 0.3007
- 0.301
- 0.3031
- 0.302
- 0.3014
- 0.3033
- 0.3043
- 0.3041
- 0.3028
test_loss_list:
- 1.8086829948425294
- 1.7097239780426026
- 1.674141845703125
- 1.638268163204193
- 1.6157341694831848
- 1.6110740065574647
- 1.5892360377311707
- 1.5627683758735658
- 1.5369522786140442
- 1.5206025123596192
- 1.506123604774475
- 1.491386103630066
- 1.4876586532592773
- 1.4803487324714661
- 1.4668692469596862
- 1.4575563049316407
- 1.4505006337165833
- 1.469549753665924
- 1.4653268837928772
- 1.4565429997444153
- 1.4571778345108033
- 1.4413321375846864
- 1.4241351056098939
- 1.4119004225730896
- 1.4080772376060486
- 1.3954658961296083
- 1.3841405367851258
- 1.3845767235755921
- 1.390406928062439
- 1.3994662857055664
- 1.3787425541877747
- 1.3919972801208496
- 1.3920473790168761
- 1.373517813682556
- 1.3701103854179382
- 1.3676974296569824
- 1.3596886062622071
- 1.3483430552482605
- 1.3413522911071778
- 1.3481526279449463
- 1.3618102860450745
- 1.3566071486473084
- 1.3642167377471923
- 1.3485229301452637
- 1.335018103122711
- 1.350971415042877
- 1.3595475625991822
- 1.3597837805747985
- 1.3493624210357666
- 1.3587682557106018
- 1.363233299255371
- 1.3445690298080444
- 1.3436802458763122
- 1.3279243636131286
- 1.3215288233757019
- 1.32535347700119
- 1.3255302381515504
- 1.3269732737541198
- 1.337862684726715
- 1.3364663076400758
- 1.3318203425407409
- 1.3276973748207093
- 1.326323344707489
- 1.3239010286331176
- 1.327029299736023
- 1.3161901092529298
- 1.30408118724823
- 1.314263780117035
- 1.3175698328018188
- 1.3179197573661805
- 1.3298972845077515
- 1.3253167796134948
- 1.3147970747947693
- 1.328304898738861
- 1.3228816509246826
- 1.3191253447532654
- 1.3325335574150086
- 1.3289268898963928
- 1.3274931335449218
- 1.3203875231742859
- 1.3088230633735656
- 1.3124755215644837
- 1.3027216911315918
- 1.3023470544815063
- 1.3047438788414
- 1.3089396858215332
- 1.3000060677528382
- 1.300710997581482
- 1.3068121290206909
- 1.3067070245742798
- 1.3004419255256652
- 1.308172562122345
- 1.3065081787109376
- 1.318927493095398
- 1.3169223141670228
- 1.3101703858375549
- 1.2967851734161377
- 1.3167278528213502
- 1.3044801831245423
- 1.3115011310577394
train_accuracy:
- 0.0
- 0.123
- 0.127
- 0.0
- 0.0
- 0.194
- 0.0
- 0.226
- 0.213
- 0.0
- 0.206
- 0.0
- 0.225
- 0.0
- 0.27
- 0.219
- 0.0
- 0.245
- 0.239
- 0.253
- 0.23
- 0.239
- 0.0
- 0.295
- 0.31
- 0.0
- 0.0
- 0.266
- 0.0
- 0.279
- 0.294
- 0.327
- 0.292
- 0.0
- 0.0
- 0.303
- 0.27
- 0.292
- 0.0
- 0.312
- 0.356
- 0.0
- 0.341
- 0.0
- 0.336
- 0.338
- 0.314
- 0.298
- 0.309
- 0.331
- 0.31
- 0.321
- 0.35
- 0.0
- 0.333
- 0.0
- 0.0
- 0.309
- 0.313
- 0.362
- 0.346
- 0.0
- 0.308
- 0.0
- 0.0
- 0.0
- 0.0
- 0.332
- 0.375
- 0.329
- 0.0
- 0.0
- 0.0
- 0.358
- 0.318
- 0.0
- 0.335
- 0.317
- 0.31
- 0.323
- 0.0
- 0.319
- 0.0
- 0.336
- 0.359
- 0.381
- 0.0
- 0.347
- 0.344
- 0.331
- 0.383
- 0.348
- 0.349
- 0.317
- 0.362
- 0.328
- 0.0
- 0.348
- 0.0
- 0.0
train_loss:
- 3.32
- 3.354
- 2.79
- 2.385
- 2.578
- 3.044
- 2.363
- 2.077
- 2.013
- 1.985
- 2.142
- 1.841
- 2.032
- 1.985
- 1.677
- 1.614
- 1.81
- 2.174
- 1.93
- 1.697
- 1.825
- 1.641
- 1.434
- 1.403
- 1.493
- 1.379
- 1.339
- 1.367
- 1.421
- 1.435
- 1.232
- 1.442
- 1.378
- 1.145
- 1.18
- 1.15
- 1.028
- 1.023
- 1.035
- 1.053
- 1.119
- 0.987
- 1.024
- 0.905
- 0.87
- 0.987
- 0.972
- 0.928
- 0.896
- 0.885
- 0.861
- 0.768
- 0.772
- 0.762
- 0.728
- 0.729
- 0.743
- 0.687
- 0.741
- 0.673
- 0.64
- 0.64
- 0.634
- 0.609
- 0.588
- 0.602
- 0.553
- 0.569
- 0.563
- 0.528
- 0.532
- 0.539
- 0.509
- 0.503
- 0.492
- 0.479
- 0.462
- 0.453
- 0.474
- 0.414
- 0.447
- 0.449
- 0.443
- 0.422
- 0.382
- 0.402
- 0.415
- 0.392
- 0.381
- 0.367
- 0.365
- 0.356
- 0.37
- 0.334
- 0.343
- 0.341
- 0.351
- 0.304
- 0.333
- 0.314
unequal: 0
verbose: 1
