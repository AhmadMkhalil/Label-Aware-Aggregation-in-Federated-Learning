avg_train_accuracy: 0.349
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0375
- 0.1016
- 0.1282
- 0.1404
- 0.1494
- 0.1612
- 0.1698
- 0.1812
- 0.1912
- 0.1951
- 0.1985
- 0.2059
- 0.2075
- 0.2127
- 0.2179
- 0.2184
- 0.2249
- 0.2272
- 0.2273
- 0.2369
- 0.2389
- 0.2389
- 0.2433
- 0.2433
- 0.2486
- 0.2522
- 0.2525
- 0.2537
- 0.2544
- 0.2611
- 0.2592
- 0.2648
- 0.2631
- 0.2646
- 0.266
- 0.2675
- 0.2664
- 0.2744
- 0.2722
- 0.2679
- 0.2769
- 0.2755
- 0.2766
- 0.2794
- 0.2759
- 0.28
- 0.2803
- 0.2828
- 0.2859
- 0.2832
- 0.285
- 0.2862
- 0.286
- 0.2844
- 0.2891
- 0.2861
- 0.2885
- 0.2881
- 0.2895
- 0.2894
- 0.2885
- 0.2895
- 0.2901
- 0.2925
- 0.2917
- 0.2953
- 0.296
- 0.2933
- 0.2917
- 0.295
- 0.2949
- 0.2933
- 0.2955
- 0.2973
- 0.2964
- 0.296
- 0.2992
- 0.2948
- 0.2967
- 0.2956
- 0.3002
- 0.2958
- 0.2976
- 0.2984
- 0.2992
- 0.301
- 0.2983
- 0.3
- 0.3006
- 0.2986
- 0.2991
- 0.3006
- 0.2978
- 0.3019
- 0.3013
- 0.2997
- 0.299
- 0.2987
- 0.3023
- 0.3025
test_loss_list:
- 1.810276255607605
- 1.7171858310699464
- 1.6820823121070863
- 1.6480005884170532
- 1.627025716304779
- 1.5931313991546632
- 1.5770697045326232
- 1.5678221416473388
- 1.558444516658783
- 1.5519099974632262
- 1.525145585536957
- 1.5087214994430542
- 1.4866299557685851
- 1.4907437086105346
- 1.472920994758606
- 1.45474755525589
- 1.448737745285034
- 1.444328680038452
- 1.44230717420578
- 1.4338650631904601
- 1.4218860912322997
- 1.4194415378570557
- 1.415020272731781
- 1.4113951110839844
- 1.4090987467765808
- 1.4050320339202882
- 1.396965470314026
- 1.3835714221000672
- 1.383319902420044
- 1.4078346657752991
- 1.3857171607017518
- 1.394619436264038
- 1.3878381085395812
- 1.3887598752975463
- 1.3746862649917602
- 1.3713226580619813
- 1.3647176289558411
- 1.3710586071014403
- 1.3668082213401795
- 1.3645316648483277
- 1.3553479671478272
- 1.3569263195991517
- 1.3552552103996276
- 1.353444242477417
- 1.3444228339195252
- 1.357648673057556
- 1.3484077119827271
- 1.3370478701591493
- 1.335696005821228
- 1.3489583802223206
- 1.3423909902572633
- 1.3489430093765258
- 1.3454955148696899
- 1.3430699706077576
- 1.3570241928100586
- 1.3460752940177918
- 1.3271545839309693
- 1.329450068473816
- 1.332084400653839
- 1.320393762588501
- 1.3144982933998108
- 1.3066917419433595
- 1.3191242289543152
- 1.3095109367370605
- 1.3087635445594787
- 1.3115642738342286
- 1.3186738801002502
- 1.3273694539070129
- 1.31432044506073
- 1.3200144243240357
- 1.3345018410682679
- 1.3277444410324097
- 1.3267997217178344
- 1.3252890634536743
- 1.3256633329391478
- 1.327813878059387
- 1.3237899351119995
- 1.3102269268035889
- 1.3279888391494752
- 1.3126210236549378
- 1.314114406108856
- 1.3050469541549683
- 1.299988775253296
- 1.29780855178833
- 1.3095941948890686
- 1.307594747543335
- 1.3111884999275207
- 1.3086322140693665
- 1.309386100769043
- 1.2993374633789063
- 1.3081467628479004
- 1.3031377601623535
- 1.322997932434082
- 1.304891254901886
- 1.3133119964599609
- 1.3253067898750306
- 1.3204922151565552
- 1.318284306526184
- 1.307400267124176
- 1.311534311771393
train_accuracy:
- 0.046
- 0.113
- 0.0
- 0.162
- 0.177
- 0.166
- 0.178
- 0.166
- 0.236
- 0.236
- 0.0
- 0.0
- 0.0
- 0.257
- 0.231
- 0.0
- 0.249
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.263
- 0.287
- 0.217
- 0.0
- 0.276
- 0.0
- 0.24
- 0.256
- 0.286
- 0.312
- 0.26
- 0.297
- 0.295
- 0.293
- 0.296
- 0.295
- 0.297
- 0.257
- 0.311
- 0.309
- 0.0
- 0.292
- 0.287
- 0.33
- 0.289
- 0.303
- 0.33
- 0.0
- 0.328
- 0.0
- 0.313
- 0.301
- 0.0
- 0.302
- 0.274
- 0.294
- 0.0
- 0.0
- 0.0
- 0.285
- 0.0
- 0.33
- 0.285
- 0.0
- 0.333
- 0.0
- 0.313
- 0.0
- 0.303
- 0.356
- 0.334
- 0.292
- 0.344
- 0.0
- 0.0
- 0.337
- 0.0
- 0.0
- 0.0
- 0.311
- 0.295
- 0.289
- 0.317
- 0.344
- 0.0
- 0.288
- 0.343
- 0.317
- 0.0
- 0.33
- 0.342
- 0.314
- 0.331
- 0.311
- 0.342
- 0.323
- 0.349
train_loss:
- 3.736
- 3.339
- 3.125
- 2.654
- 2.547
- 2.192
- 2.38
- 2.584
- 2.489
- 2.386
- 1.92
- 2.08
- 1.791
- 2.171
- 1.699
- 1.677
- 1.803
- 1.761
- 1.717
- 1.685
- 1.451
- 1.595
- 1.564
- 1.519
- 1.477
- 1.403
- 1.444
- 1.254
- 1.353
- 1.535
- 1.156
- 1.36
- 1.237
- 1.299
- 1.048
- 1.145
- 0.997
- 1.152
- 1.065
- 1.055
- 1.029
- 0.941
- 0.991
- 0.926
- 0.844
- 0.956
- 0.87
- 0.826
- 0.824
- 0.862
- 0.81
- 0.828
- 0.757
- 0.74
- 0.728
- 0.751
- 0.688
- 0.688
- 0.664
- 0.611
- 0.642
- 0.585
- 0.596
- 0.581
- 0.546
- 0.599
- 0.556
- 0.555
- 0.508
- 0.535
- 0.527
- 0.497
- 0.47
- 0.492
- 0.474
- 0.461
- 0.469
- 0.456
- 0.416
- 0.43
- 0.424
- 0.429
- 0.42
- 0.412
- 0.391
- 0.377
- 0.358
- 0.379
- 0.381
- 0.368
- 0.353
- 0.364
- 0.325
- 0.347
- 0.329
- 0.313
- 0.322
- 0.32
- 0.328
- 0.309
unequal: 0
verbose: 1
