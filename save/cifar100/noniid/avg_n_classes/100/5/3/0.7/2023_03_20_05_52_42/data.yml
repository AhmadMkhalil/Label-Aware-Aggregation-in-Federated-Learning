avg_train_accuracy: 0.295
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0474
- 0.0985
- 0.1197
- 0.1328
- 0.1414
- 0.1548
- 0.1632
- 0.1714
- 0.1748
- 0.1809
- 0.1871
- 0.1947
- 0.2003
- 0.2057
- 0.2093
- 0.2187
- 0.2191
- 0.2225
- 0.227
- 0.232
- 0.2349
- 0.2344
- 0.2382
- 0.2418
- 0.2453
- 0.2478
- 0.2527
- 0.2469
- 0.2534
- 0.2555
- 0.2585
- 0.2556
- 0.2607
- 0.2639
- 0.2647
- 0.2682
- 0.2637
- 0.2671
- 0.2716
- 0.2711
- 0.2715
- 0.2733
- 0.2752
- 0.2734
- 0.2764
- 0.2716
- 0.2777
- 0.2776
- 0.2793
- 0.2821
- 0.2841
- 0.2868
- 0.2859
- 0.2855
- 0.2863
- 0.2861
- 0.288
- 0.2911
- 0.2877
- 0.2899
- 0.2859
- 0.2886
- 0.2893
- 0.2914
- 0.2932
- 0.2899
- 0.2909
- 0.2932
- 0.2933
- 0.2923
- 0.2925
- 0.2927
- 0.2951
- 0.2921
- 0.296
- 0.2937
- 0.2942
- 0.2958
- 0.2968
- 0.298
- 0.2961
- 0.2982
- 0.2981
- 0.2983
- 0.2992
- 0.2978
- 0.296
- 0.2962
- 0.2983
- 0.2966
- 0.3004
- 0.2985
- 0.2998
- 0.3003
- 0.2997
- 0.2985
- 0.2995
- 0.2985
- 0.302
- 0.2997
test_loss_list:
- 1.8133667182922364
- 1.7212241363525391
- 1.679584391117096
- 1.646098654270172
- 1.6251869344711303
- 1.6093010449409484
- 1.5790926313400269
- 1.5573406076431275
- 1.5403190326690674
- 1.5296088004112243
- 1.5227059102058411
- 1.5103834223747254
- 1.4929918193817138
- 1.4894391798973083
- 1.4713487100601197
- 1.4614494299888612
- 1.4607887768745422
- 1.4625702834129333
- 1.4534677624702455
- 1.4450698375701905
- 1.4395468354225158
- 1.43337735414505
- 1.43673348903656
- 1.4247161555290222
- 1.4264057779312134
- 1.4200366830825806
- 1.4093906807899474
- 1.3955794405937194
- 1.3922016096115113
- 1.4008404326438904
- 1.3904259514808655
- 1.3749589729309082
- 1.3739849376678466
- 1.3737070274353027
- 1.3849483561515807
- 1.3628456830978393
- 1.3579891991615296
- 1.3570897698402404
- 1.352711522579193
- 1.3523686242103576
- 1.3544614124298096
- 1.3517901587486267
- 1.360726897716522
- 1.3536414766311646
- 1.348662974834442
- 1.3425688552856445
- 1.333046431541443
- 1.3450953435897828
- 1.3381703472137452
- 1.3265989017486572
- 1.3333036994934082
- 1.3391591095924378
- 1.3358213353157042
- 1.3209194111824036
- 1.339391655921936
- 1.3338366317749024
- 1.331936707496643
- 1.3264796400070191
- 1.3300488352775575
- 1.32540221452713
- 1.3277130150794982
- 1.3196434879302978
- 1.3187828111648559
- 1.3328515934944152
- 1.3228674173355102
- 1.3211739325523377
- 1.3228738760948182
- 1.3189753627777099
- 1.3108857536315919
- 1.3104951286315918
- 1.302568917274475
- 1.3092714834213257
- 1.315816535949707
- 1.3026733708381653
- 1.306778302192688
- 1.3036750268936157
- 1.3179663062095641
- 1.3177865362167358
- 1.3136234521865844
- 1.3234610867500305
- 1.3052420282363892
- 1.299372944831848
- 1.2957406997680665
- 1.3061674332618713
- 1.319855079650879
- 1.3157891607284546
- 1.3098181653022767
- 1.3244931244850158
- 1.3196105074882507
- 1.3112356543540955
- 1.3215199303627014
- 1.3271709418296813
- 1.3097366189956665
- 1.3187573838233948
- 1.3302003479003905
- 1.3194749093055724
- 1.3062753248214722
- 1.3044101524353027
- 1.3031339502334596
- 1.306354422569275
train_accuracy:
- 0.052
- 0.101
- 0.129
- 0.123
- 0.17
- 0.204
- 0.0
- 0.191
- 0.0
- 0.195
- 0.221
- 0.256
- 0.0
- 0.0
- 0.249
- 0.0
- 0.219
- 0.222
- 0.248
- 0.0
- 0.229
- 0.252
- 0.0
- 0.274
- 0.247
- 0.0
- 0.26
- 0.0
- 0.0
- 0.298
- 0.259
- 0.26
- 0.314
- 0.313
- 0.294
- 0.0
- 0.342
- 0.288
- 0.273
- 0.301
- 0.0
- 0.297
- 0.262
- 0.0
- 0.0
- 0.297
- 0.0
- 0.0
- 0.3
- 0.312
- 0.282
- 0.33
- 0.304
- 0.276
- 0.324
- 0.0
- 0.0
- 0.0
- 0.326
- 0.311
- 0.0
- 0.0
- 0.318
- 0.328
- 0.323
- 0.315
- 0.296
- 0.319
- 0.314
- 0.0
- 0.356
- 0.308
- 0.361
- 0.293
- 0.0
- 0.357
- 0.295
- 0.343
- 0.316
- 0.34
- 0.327
- 0.336
- 0.306
- 0.0
- 0.342
- 0.33
- 0.0
- 0.358
- 0.382
- 0.0
- 0.367
- 0.343
- 0.353
- 0.315
- 0.315
- 0.363
- 0.0
- 0.37
- 0.365
- 0.295
train_loss:
- 2.931
- 3.003
- 2.804
- 2.686
- 2.562
- 2.765
- 2.117
- 2.071
- 1.992
- 2.186
- 2.109
- 2.07
- 1.812
- 1.941
- 1.713
- 1.905
- 1.798
- 1.982
- 1.743
- 1.683
- 1.631
- 1.611
- 1.744
- 1.546
- 1.659
- 1.447
- 1.409
- 1.251
- 1.356
- 1.453
- 1.319
- 1.16
- 1.258
- 1.233
- 1.283
- 1.048
- 1.017
- 1.085
- 1.067
- 1.047
- 0.999
- 1.016
- 1.061
- 0.954
- 0.948
- 0.911
- 0.798
- 0.938
- 0.864
- 0.777
- 0.804
- 0.844
- 0.798
- 0.755
- 0.79
- 0.733
- 0.72
- 0.713
- 0.667
- 0.638
- 0.643
- 0.59
- 0.605
- 0.623
- 0.592
- 0.585
- 0.574
- 0.578
- 0.534
- 0.545
- 0.516
- 0.502
- 0.49
- 0.491
- 0.465
- 0.464
- 0.486
- 0.461
- 0.439
- 0.442
- 0.437
- 0.417
- 0.416
- 0.392
- 0.392
- 0.382
- 0.392
- 0.38
- 0.362
- 0.366
- 0.339
- 0.333
- 0.37
- 0.335
- 0.329
- 0.348
- 0.341
- 0.321
- 0.324
- 0.301
unequal: 0
verbose: 1
