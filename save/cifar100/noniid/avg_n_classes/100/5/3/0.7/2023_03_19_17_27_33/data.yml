avg_train_accuracy: 0.35
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0461
- 0.0914
- 0.1236
- 0.1412
- 0.1515
- 0.1628
- 0.1739
- 0.1807
- 0.1864
- 0.1928
- 0.1939
- 0.2001
- 0.2078
- 0.2133
- 0.2157
- 0.2215
- 0.226
- 0.2289
- 0.2347
- 0.2352
- 0.2404
- 0.2426
- 0.2439
- 0.2455
- 0.2483
- 0.2504
- 0.25
- 0.2493
- 0.2548
- 0.2551
- 0.2611
- 0.2596
- 0.2631
- 0.265
- 0.2664
- 0.2657
- 0.2666
- 0.2713
- 0.2719
- 0.2703
- 0.2742
- 0.275
- 0.2766
- 0.2763
- 0.2803
- 0.2799
- 0.2826
- 0.2812
- 0.2858
- 0.2846
- 0.2845
- 0.2819
- 0.285
- 0.2856
- 0.2856
- 0.2861
- 0.2853
- 0.2883
- 0.2878
- 0.2887
- 0.2925
- 0.2912
- 0.2901
- 0.2867
- 0.29
- 0.2931
- 0.2919
- 0.2935
- 0.2957
- 0.2934
- 0.2957
- 0.2942
- 0.2929
- 0.2931
- 0.2948
- 0.2977
- 0.2971
- 0.2967
- 0.2949
- 0.2963
- 0.2953
- 0.3003
- 0.2975
- 0.2984
- 0.2958
- 0.2977
- 0.2985
- 0.2979
- 0.2989
- 0.3002
- 0.2987
- 0.2983
- 0.3007
- 0.2983
- 0.2997
- 0.3033
- 0.3013
- 0.3001
- 0.3003
- 0.3007
test_loss_list:
- 1.794186978340149
- 1.7016194677352905
- 1.6551613450050353
- 1.6268157196044921
- 1.606675546169281
- 1.5850544095039367
- 1.567125735282898
- 1.54269282579422
- 1.523631534576416
- 1.5118909502029418
- 1.4972682523727416
- 1.4928111934661865
- 1.4868810629844667
- 1.4717101669311523
- 1.4667396855354309
- 1.469906096458435
- 1.4594153332710267
- 1.448955774307251
- 1.4384901356697082
- 1.4460306763648987
- 1.4375959253311157
- 1.4307335805892945
- 1.42390460729599
- 1.4079876327514649
- 1.4054997301101684
- 1.405133810043335
- 1.388310534954071
- 1.379161410331726
- 1.3830018901824952
- 1.38248238325119
- 1.3747461771965026
- 1.3772316122055053
- 1.3855104517936707
- 1.374197292327881
- 1.3638111138343811
- 1.3575666809082032
- 1.3497891163825988
- 1.3479652380943299
- 1.3505073976516724
- 1.3524830889701844
- 1.3392390513420105
- 1.359623839855194
- 1.3483968567848206
- 1.3493619465827942
- 1.358687961101532
- 1.3535382270812988
- 1.346860179901123
- 1.3426297807693481
- 1.3372859621047974
- 1.3499628829956054
- 1.3344412422180176
- 1.3288528656959533
- 1.3156912088394166
- 1.3234396958351136
- 1.3158786845207215
- 1.3109987807273864
- 1.3158407926559448
- 1.32043514251709
- 1.3221129512786864
- 1.3235908508300782
- 1.3367148685455321
- 1.3229319548606873
- 1.3245064878463746
- 1.330801317691803
- 1.326066734790802
- 1.3316172075271606
- 1.3244185471534728
- 1.3184166431427002
- 1.317471559047699
- 1.3185090017318726
- 1.3177651143074036
- 1.346793100833893
- 1.326398205757141
- 1.3085244727134704
- 1.3167519617080687
- 1.327061882019043
- 1.322955186367035
- 1.3373138070106507
- 1.3267530226707458
- 1.315092990398407
- 1.3142354488372803
- 1.3180288195610046
- 1.320650429725647
- 1.327082314491272
- 1.3139546370506288
- 1.31735769033432
- 1.3200092387199402
- 1.302659397125244
- 1.309340660572052
- 1.314716455936432
- 1.324753999710083
- 1.3136649680137635
- 1.314874255657196
- 1.3157238125801087
- 1.3331662154197692
- 1.3141021966934203
- 1.3301525521278381
- 1.3230324578285217
- 1.319381365776062
- 1.3342502069473268
train_accuracy:
- 0.043
- 0.137
- 0.0
- 0.143
- 0.182
- 0.175
- 0.182
- 0.195
- 0.0
- 0.0
- 0.241
- 0.0
- 0.203
- 0.26
- 0.257
- 0.237
- 0.223
- 0.263
- 0.0
- 0.268
- 0.0
- 0.237
- 0.251
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.322
- 0.0
- 0.289
- 0.258
- 0.322
- 0.0
- 0.0
- 0.31
- 0.308
- 0.0
- 0.295
- 0.339
- 0.0
- 0.313
- 0.289
- 0.313
- 0.0
- 0.0
- 0.31
- 0.304
- 0.302
- 0.313
- 0.0
- 0.0
- 0.0
- 0.0
- 0.316
- 0.336
- 0.315
- 0.331
- 0.0
- 0.321
- 0.33
- 0.0
- 0.316
- 0.353
- 0.312
- 0.287
- 0.327
- 0.0
- 0.344
- 0.326
- 0.317
- 0.295
- 0.347
- 0.328
- 0.29
- 0.35
- 0.296
- 0.313
- 0.34
- 0.346
- 0.285
- 0.335
- 0.299
- 0.0
- 0.0
- 0.319
- 0.342
- 0.293
- 0.292
- 0.354
- 0.313
- 0.0
- 0.355
- 0.323
- 0.355
- 0.349
- 0.328
- 0.313
- 0.349
- 0.35
train_loss:
- 3.801
- 2.964
- 2.78
- 2.64
- 2.553
- 2.436
- 2.394
- 2.049
- 1.989
- 2.159
- 1.893
- 2.026
- 2.04
- 1.723
- 1.893
- 2.069
- 1.791
- 1.793
- 1.744
- 1.852
- 1.616
- 1.625
- 1.606
- 1.382
- 1.472
- 1.444
- 1.294
- 1.287
- 1.374
- 1.297
- 1.312
- 1.245
- 1.322
- 1.23
- 1.091
- 1.01
- 1.055
- 1.118
- 1.077
- 1.017
- 0.944
- 1.046
- 0.975
- 0.944
- 1.027
- 0.922
- 0.897
- 0.861
- 0.869
- 0.86
- 0.775
- 0.742
- 0.746
- 0.749
- 0.669
- 0.66
- 0.716
- 0.686
- 0.688
- 0.666
- 0.674
- 0.636
- 0.619
- 0.633
- 0.571
- 0.575
- 0.538
- 0.557
- 0.576
- 0.52
- 0.524
- 0.523
- 0.484
- 0.51
- 0.484
- 0.452
- 0.461
- 0.44
- 0.456
- 0.436
- 0.414
- 0.391
- 0.415
- 0.409
- 0.386
- 0.395
- 0.369
- 0.383
- 0.382
- 0.358
- 0.35
- 0.352
- 0.337
- 0.315
- 0.293
- 0.352
- 0.306
- 0.338
- 0.314
- 0.311
unequal: 0
verbose: 1
