avg_train_accuracy: 0.315
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0427
- 0.1013
- 0.1245
- 0.1423
- 0.1558
- 0.1603
- 0.1701
- 0.1785
- 0.1869
- 0.1907
- 0.1984
- 0.2019
- 0.2041
- 0.2129
- 0.2199
- 0.2235
- 0.2301
- 0.2316
- 0.2357
- 0.2401
- 0.2443
- 0.2464
- 0.2491
- 0.2514
- 0.2546
- 0.2534
- 0.2577
- 0.2593
- 0.2622
- 0.2668
- 0.2694
- 0.2682
- 0.2743
- 0.2737
- 0.2732
- 0.2756
- 0.2771
- 0.2794
- 0.2768
- 0.2819
- 0.2837
- 0.2831
- 0.2851
- 0.2845
- 0.2865
- 0.287
- 0.2905
- 0.2923
- 0.2879
- 0.2928
- 0.2907
- 0.2931
- 0.2959
- 0.2973
- 0.2952
- 0.2947
- 0.2955
- 0.2959
- 0.2972
- 0.2951
- 0.2971
- 0.2926
- 0.2987
- 0.2972
- 0.2987
- 0.2994
- 0.3009
- 0.3011
- 0.3015
- 0.3016
- 0.2991
- 0.3024
- 0.2987
- 0.3006
- 0.3012
- 0.3048
- 0.3022
- 0.3031
- 0.2994
- 0.3024
- 0.3048
- 0.3032
- 0.3042
- 0.3049
- 0.3075
- 0.3033
- 0.3023
- 0.3059
- 0.3039
- 0.3061
- 0.3093
- 0.3062
- 0.3087
- 0.3083
- 0.3029
- 0.3061
- 0.3064
- 0.3073
- 0.3102
- 0.3063
test_loss_list:
- 1.8037088060379027
- 1.70137460231781
- 1.667912027835846
- 1.6255670475959778
- 1.5997630620002747
- 1.5827697896957398
- 1.5547378063201904
- 1.5395037746429443
- 1.5275402116775512
- 1.507555401325226
- 1.5003480696678162
- 1.4938956212997436
- 1.4770135045051576
- 1.4763264083862304
- 1.4701192021369933
- 1.4628674983978271
- 1.441821186542511
- 1.4465519547462464
- 1.4369906663894654
- 1.4215733766555787
- 1.416687023639679
- 1.4105942559242248
- 1.4069809770584107
- 1.4005668377876281
- 1.398609368801117
- 1.3887042450904845
- 1.376597409248352
- 1.3631830430030822
- 1.358426411151886
- 1.364191746711731
- 1.3566383481025697
- 1.3556848382949829
- 1.355500521659851
- 1.3554535913467407
- 1.3462155652046204
- 1.3581837344169616
- 1.3415759515762329
- 1.3420409846305847
- 1.343565618991852
- 1.3434244632720946
- 1.3534411454200745
- 1.3459986352920532
- 1.3330509376525879
- 1.3277326536178589
- 1.3274646496772766
- 1.3273246955871583
- 1.3142724466323852
- 1.3160594749450683
- 1.3268553709983826
- 1.3212310886383056
- 1.3149166679382325
- 1.3288595581054687
- 1.3213218879699706
- 1.323424253463745
- 1.3321044754981994
- 1.3278580212593079
- 1.3115754055976867
- 1.3142653346061706
- 1.3034999346733094
- 1.2986111617088318
- 1.2974948859214783
- 1.2944229912757874
- 1.3009328293800353
- 1.2991584587097167
- 1.3016245460510254
- 1.2905751442909241
- 1.30955459356308
- 1.2973424792289734
- 1.2995575952529907
- 1.3023698830604553
- 1.3227691650390625
- 1.3131582236289978
- 1.3140970301628112
- 1.3070689845085144
- 1.2993786215782166
- 1.303681788444519
- 1.304162037372589
- 1.2952136182785035
- 1.3013191938400268
- 1.3065072965621949
- 1.3150365495681762
- 1.3004043650627137
- 1.3157709050178528
- 1.3079880261421204
- 1.309148108959198
- 1.3073568558692932
- 1.2976850652694703
- 1.3130379295349122
- 1.3112154626846313
- 1.2959318256378174
- 1.2968347787857055
- 1.2944566082954407
- 1.301657280921936
- 1.2896071553230286
- 1.2884564256668092
- 1.2869382190704346
- 1.2979055309295655
- 1.2879936051368714
- 1.2812719655036926
- 1.2831427717208863
train_accuracy:
- 0.068
- 0.0
- 0.143
- 0.0
- 0.155
- 0.172
- 0.0
- 0.0
- 0.202
- 0.202
- 0.225
- 0.206
- 0.0
- 0.205
- 0.23
- 0.235
- 0.253
- 0.258
- 0.0
- 0.0
- 0.0
- 0.258
- 0.258
- 0.264
- 0.277
- 0.0
- 0.306
- 0.271
- 0.0
- 0.273
- 0.269
- 0.28
- 0.32
- 0.303
- 0.0
- 0.31
- 0.283
- 0.316
- 0.284
- 0.299
- 0.328
- 0.286
- 0.0
- 0.0
- 0.313
- 0.326
- 0.0
- 0.328
- 0.324
- 0.0
- 0.0
- 0.324
- 0.316
- 0.348
- 0.334
- 0.336
- 0.321
- 0.328
- 0.295
- 0.0
- 0.0
- 0.0
- 0.323
- 0.0
- 0.327
- 0.348
- 0.335
- 0.0
- 0.343
- 0.36
- 0.351
- 0.336
- 0.0
- 0.307
- 0.324
- 0.347
- 0.366
- 0.338
- 0.359
- 0.0
- 0.353
- 0.343
- 0.319
- 0.334
- 0.329
- 0.305
- 0.342
- 0.355
- 0.31
- 0.353
- 0.0
- 0.353
- 0.323
- 0.379
- 0.0
- 0.318
- 0.308
- 0.366
- 0.0
- 0.315
train_loss:
- 3.316
- 2.977
- 3.107
- 2.328
- 2.505
- 2.438
- 2.1
- 2.299
- 2.236
- 1.901
- 2.085
- 2.03
- 1.748
- 2.16
- 1.848
- 1.823
- 1.603
- 1.961
- 1.72
- 1.488
- 1.61
- 1.625
- 1.556
- 1.532
- 1.45
- 1.282
- 1.284
- 1.253
- 1.187
- 1.318
- 1.114
- 1.258
- 1.203
- 1.193
- 1.082
- 1.223
- 1.0
- 1.083
- 1.042
- 1.039
- 1.084
- 0.974
- 0.883
- 0.834
- 0.893
- 0.918
- 0.826
- 0.834
- 0.825
- 0.788
- 0.721
- 0.852
- 0.753
- 0.743
- 0.766
- 0.693
- 0.624
- 0.7
- 0.643
- 0.637
- 0.592
- 0.59
- 0.622
- 0.559
- 0.566
- 0.55
- 0.569
- 0.541
- 0.509
- 0.512
- 0.512
- 0.505
- 0.498
- 0.507
- 0.489
- 0.464
- 0.455
- 0.449
- 0.447
- 0.41
- 0.427
- 0.43
- 0.412
- 0.394
- 0.397
- 0.401
- 0.38
- 0.376
- 0.365
- 0.362
- 0.359
- 0.352
- 0.324
- 0.349
- 0.338
- 0.326
- 0.322
- 0.323
- 0.321
- 0.308
unequal: 0
verbose: 1
