avg_train_accuracy: 0.325
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0382
- 0.0993
- 0.1216
- 0.1382
- 0.1514
- 0.1592
- 0.169
- 0.1795
- 0.1842
- 0.1921
- 0.1954
- 0.2035
- 0.2092
- 0.2137
- 0.2179
- 0.2213
- 0.2209
- 0.2259
- 0.2341
- 0.2377
- 0.2455
- 0.2434
- 0.2479
- 0.2521
- 0.2522
- 0.2513
- 0.2595
- 0.2592
- 0.2617
- 0.2644
- 0.2657
- 0.2661
- 0.2671
- 0.269
- 0.2715
- 0.2708
- 0.2725
- 0.2746
- 0.276
- 0.2772
- 0.2758
- 0.2801
- 0.28
- 0.2825
- 0.2826
- 0.2842
- 0.2829
- 0.2828
- 0.2874
- 0.2843
- 0.289
- 0.2842
- 0.2884
- 0.2911
- 0.2909
- 0.2937
- 0.2903
- 0.2922
- 0.2926
- 0.2914
- 0.2891
- 0.2936
- 0.2966
- 0.2973
- 0.2939
- 0.2953
- 0.2963
- 0.2949
- 0.2968
- 0.2988
- 0.2987
- 0.2948
- 0.2967
- 0.2968
- 0.3007
- 0.3015
- 0.3018
- 0.3025
- 0.3005
- 0.3006
- 0.303
- 0.3016
- 0.3033
- 0.3017
- 0.3037
- 0.3053
- 0.3059
- 0.3057
- 0.3066
- 0.3047
- 0.3051
- 0.3048
- 0.3067
- 0.3055
- 0.3075
- 0.3069
- 0.3075
- 0.3066
- 0.3095
- 0.3091
test_loss_list:
- 1.8079470348358155
- 1.7022233891487122
- 1.663452181816101
- 1.6306770634651184
- 1.6087635469436645
- 1.5854965829849244
- 1.5673872566223144
- 1.552098982334137
- 1.5403539299964906
- 1.5393335461616515
- 1.518270149230957
- 1.5154936337471008
- 1.491090784072876
- 1.4834058356285096
- 1.4718942379951476
- 1.453364851474762
- 1.4423924350738526
- 1.440147180557251
- 1.4442884159088134
- 1.4496714782714843
- 1.4294643163681031
- 1.4238140034675597
- 1.4061404275894165
- 1.3974053239822388
- 1.3866207098960877
- 1.3815880274772645
- 1.3696097803115845
- 1.3761874961853027
- 1.375178825855255
- 1.3852426481246949
- 1.3959785509109497
- 1.3834003758430482
- 1.3870578169822694
- 1.3702876329421998
- 1.3633984398841859
- 1.3730315470695496
- 1.357316906452179
- 1.3587873029708861
- 1.35004891872406
- 1.3487952828407288
- 1.341060357093811
- 1.35940012216568
- 1.3484969925880432
- 1.3598030614852905
- 1.3511441826820374
- 1.3581242322921754
- 1.3501071691513062
- 1.3444129610061646
- 1.338943705558777
- 1.3309178566932678
- 1.340047585964203
- 1.325706250667572
- 1.3272999024391174
- 1.3248448038101197
- 1.3346144652366638
- 1.326773819923401
- 1.3137310028076172
- 1.319441921710968
- 1.324245448112488
- 1.323330957889557
- 1.3125760650634766
- 1.316572766304016
- 1.315388295650482
- 1.3101253056526183
- 1.3094118213653565
- 1.3051193237304688
- 1.3004345870018006
- 1.300615348815918
- 1.305492081642151
- 1.3074613642692565
- 1.309380612373352
- 1.3126919555664063
- 1.3170747590065002
- 1.3150686883926392
- 1.3226999258995056
- 1.3160298657417298
- 1.3289130854606628
- 1.323339066505432
- 1.3264442348480225
- 1.3090887188911438
- 1.3117030715942384
- 1.3121135544776916
- 1.324721529483795
- 1.3107510924339294
- 1.313994619846344
- 1.311627984046936
- 1.3103002953529357
- 1.310836455821991
- 1.3067046451568602
- 1.305743577480316
- 1.3098737239837646
- 1.3106265664100647
- 1.2967304182052612
- 1.296082284450531
- 1.298347704410553
- 1.3001483368873596
- 1.3038975811004638
- 1.3064076924324035
- 1.293929455280304
- 1.2999667644500732
train_accuracy:
- 0.0
- 0.0
- 0.111
- 0.127
- 0.0
- 0.0
- 0.187
- 0.0
- 0.204
- 0.218
- 0.0
- 0.21
- 0.214
- 0.268
- 0.226
- 0.223
- 0.253
- 0.235
- 0.271
- 0.241
- 0.0
- 0.297
- 0.0
- 0.0
- 0.25
- 0.293
- 0.3
- 0.0
- 0.0
- 0.337
- 0.309
- 0.315
- 0.324
- 0.0
- 0.275
- 0.0
- 0.333
- 0.0
- 0.339
- 0.292
- 0.0
- 0.0
- 0.286
- 0.343
- 0.338
- 0.0
- 0.293
- 0.302
- 0.342
- 0.305
- 0.0
- 0.0
- 0.341
- 0.364
- 0.336
- 0.0
- 0.0
- 0.0
- 0.0
- 0.292
- 0.0
- 0.274
- 0.315
- 0.299
- 0.296
- 0.352
- 0.302
- 0.354
- 0.309
- 0.354
- 0.367
- 0.364
- 0.304
- 0.0
- 0.309
- 0.0
- 0.0
- 0.321
- 0.351
- 0.349
- 0.308
- 0.389
- 0.383
- 0.0
- 0.31
- 0.0
- 0.344
- 0.0
- 0.0
- 0.315
- 0.303
- 0.36
- 0.357
- 0.384
- 0.0
- 0.0
- 0.317
- 0.373
- 0.0
- 0.325
train_loss:
- 2.857
- 2.951
- 2.782
- 2.653
- 2.574
- 2.163
- 2.374
- 2.282
- 2.233
- 2.419
- 1.906
- 2.35
- 1.833
- 1.971
- 1.929
- 1.66
- 1.625
- 1.753
- 1.898
- 1.884
- 1.692
- 1.645
- 1.413
- 1.376
- 1.336
- 1.313
- 1.282
- 1.426
- 1.371
- 1.456
- 1.423
- 1.281
- 1.362
- 1.108
- 1.191
- 1.261
- 1.02
- 1.094
- 0.991
- 1.067
- 0.924
- 1.061
- 0.99
- 1.036
- 0.957
- 0.966
- 0.875
- 0.871
- 0.859
- 0.762
- 0.856
- 0.748
- 0.789
- 0.749
- 0.777
- 0.722
- 0.68
- 0.685
- 0.715
- 0.658
- 0.619
- 0.626
- 0.614
- 0.572
- 0.602
- 0.559
- 0.541
- 0.533
- 0.559
- 0.517
- 0.521
- 0.498
- 0.497
- 0.491
- 0.481
- 0.49
- 0.465
- 0.455
- 0.424
- 0.458
- 0.435
- 0.413
- 0.393
- 0.409
- 0.401
- 0.385
- 0.376
- 0.376
- 0.373
- 0.378
- 0.364
- 0.354
- 0.357
- 0.35
- 0.346
- 0.323
- 0.316
- 0.324
- 0.326
- 0.299
unequal: 0
verbose: 1
