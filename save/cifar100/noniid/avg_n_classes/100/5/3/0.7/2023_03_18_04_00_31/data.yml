avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0346
- 0.0928
- 0.1077
- 0.1312
- 0.1405
- 0.1554
- 0.1645
- 0.1723
- 0.1771
- 0.1856
- 0.1916
- 0.1973
- 0.2056
- 0.2066
- 0.2141
- 0.2167
- 0.2231
- 0.2282
- 0.2256
- 0.2344
- 0.2342
- 0.2384
- 0.2367
- 0.2392
- 0.2446
- 0.2472
- 0.2487
- 0.2518
- 0.2504
- 0.2519
- 0.2543
- 0.2565
- 0.2598
- 0.2607
- 0.2614
- 0.2589
- 0.2646
- 0.2641
- 0.2655
- 0.2643
- 0.27
- 0.2691
- 0.27
- 0.274
- 0.2728
- 0.2736
- 0.2736
- 0.2802
- 0.2765
- 0.2767
- 0.2747
- 0.2783
- 0.2775
- 0.2793
- 0.2843
- 0.2808
- 0.2856
- 0.2842
- 0.2854
- 0.2822
- 0.288
- 0.2851
- 0.2857
- 0.2871
- 0.2912
- 0.2901
- 0.2902
- 0.2884
- 0.2919
- 0.2908
- 0.2925
- 0.2928
- 0.293
- 0.2912
- 0.2933
- 0.2924
- 0.296
- 0.2945
- 0.2943
- 0.2941
- 0.2971
- 0.2958
- 0.2927
- 0.2955
- 0.2961
- 0.2979
- 0.2952
- 0.2968
- 0.2965
- 0.2976
- 0.2971
- 0.2968
- 0.2995
- 0.2978
- 0.2983
- 0.3013
- 0.2978
- 0.3003
- 0.3
- 0.3014
test_loss_list:
- 1.810084662437439
- 1.7071128273010254
- 1.6697837281227113
- 1.6327276968955993
- 1.6051418924331664
- 1.598831946849823
- 1.57955260515213
- 1.5729452466964722
- 1.5565754437446595
- 1.5280630922317504
- 1.5219658184051514
- 1.5097934341430663
- 1.51021409034729
- 1.4916378450393677
- 1.471834077835083
- 1.4660151743888854
- 1.4696209359169006
- 1.470958969593048
- 1.4490291905403136
- 1.4441617608070374
- 1.4360845685005188
- 1.4361578464508056
- 1.4207946109771727
- 1.4087383222579957
- 1.4052710962295532
- 1.4157938313484193
- 1.4115129899978638
- 1.3965740346908568
- 1.3981770420074462
- 1.3943753051757812
- 1.394216787815094
- 1.386634647846222
- 1.3965538215637208
- 1.3882217597961426
- 1.3856688618659974
- 1.380301640033722
- 1.3770393824577332
- 1.364415922164917
- 1.3783238244056701
- 1.3724149131774903
- 1.3669414854049682
- 1.3542269039154053
- 1.3655798649787902
- 1.362331485748291
- 1.3559856462478637
- 1.372472755908966
- 1.3513974118232728
- 1.3478947830200196
- 1.360252525806427
- 1.353842511177063
- 1.3531858372688292
- 1.35270498752594
- 1.340761466026306
- 1.3422931051254272
- 1.3399619793891906
- 1.3577850294113158
- 1.3429646229743957
- 1.3242020797729492
- 1.331917839050293
- 1.3368430137634277
- 1.3363967561721801
- 1.3267603993415833
- 1.3187593555450439
- 1.324937653541565
- 1.3253103494644165
- 1.3287030172348022
- 1.3207429265975952
- 1.3103262948989869
- 1.321170778274536
- 1.314786217212677
- 1.3203620672225953
- 1.3195949292182922
- 1.3241898274421693
- 1.327613317966461
- 1.3159311866760255
- 1.3252237486839293
- 1.3153793573379517
- 1.3208168959617614
- 1.3136866855621339
- 1.321796591281891
- 1.3345322656631469
- 1.3320566368103028
- 1.3163953304290772
- 1.3204970788955688
- 1.3237406587600709
- 1.3235240268707276
- 1.3428497314453125
- 1.3237590503692627
- 1.3364012408256531
- 1.329188995361328
- 1.3452411603927612
- 1.3179500603675842
- 1.326304144859314
- 1.3275366163253783
- 1.3160905456542968
- 1.3193006920814514
- 1.3222822093963622
- 1.3239651727676391
- 1.314289906024933
- 1.3195034408569335
train_accuracy:
- 0.0
- 0.0
- 0.121
- 0.0
- 0.0
- 0.0
- 0.169
- 0.173
- 0.198
- 0.206
- 0.182
- 0.235
- 0.206
- 0.208
- 0.253
- 0.187
- 0.243
- 0.0
- 0.247
- 0.0
- 0.268
- 0.22
- 0.241
- 0.249
- 0.252
- 0.0
- 0.269
- 0.0
- 0.263
- 0.0
- 0.273
- 0.317
- 0.312
- 0.0
- 0.288
- 0.301
- 0.278
- 0.285
- 0.289
- 0.275
- 0.307
- 0.0
- 0.277
- 0.308
- 0.271
- 0.294
- 0.352
- 0.266
- 0.319
- 0.0
- 0.313
- 0.295
- 0.287
- 0.295
- 0.282
- 0.0
- 0.0
- 0.32
- 0.307
- 0.0
- 0.0
- 0.305
- 0.319
- 0.327
- 0.0
- 0.307
- 0.0
- 0.0
- 0.33
- 0.0
- 0.0
- 0.318
- 0.321
- 0.338
- 0.0
- 0.336
- 0.323
- 0.365
- 0.324
- 0.0
- 0.309
- 0.36
- 0.0
- 0.309
- 0.321
- 0.0
- 0.335
- 0.312
- 0.306
- 0.0
- 0.299
- 0.318
- 0.325
- 0.319
- 0.0
- 0.347
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 2.911
- 2.614
- 2.455
- 2.39
- 2.266
- 2.825
- 2.42
- 2.64
- 2.305
- 1.991
- 2.158
- 2.109
- 2.288
- 1.771
- 1.748
- 1.918
- 2.065
- 1.991
- 1.586
- 1.714
- 1.698
- 1.665
- 1.437
- 1.395
- 1.554
- 1.614
- 1.484
- 1.283
- 1.377
- 1.365
- 1.321
- 1.294
- 1.403
- 1.219
- 1.222
- 1.215
- 1.141
- 1.059
- 1.187
- 1.074
- 1.054
- 0.963
- 1.088
- 0.992
- 0.955
- 1.011
- 0.853
- 0.903
- 0.943
- 0.856
- 0.84
- 0.831
- 0.752
- 0.804
- 0.787
- 0.8
- 0.713
- 0.697
- 0.678
- 0.667
- 0.653
- 0.614
- 0.641
- 0.637
- 0.627
- 0.623
- 0.576
- 0.578
- 0.563
- 0.54
- 0.534
- 0.521
- 0.515
- 0.526
- 0.51
- 0.522
- 0.486
- 0.463
- 0.469
- 0.468
- 0.434
- 0.427
- 0.449
- 0.418
- 0.398
- 0.406
- 0.385
- 0.407
- 0.387
- 0.379
- 0.368
- 0.382
- 0.36
- 0.34
- 0.369
- 0.346
- 0.348
- 0.339
- 0.338
- 0.332
unequal: 0
verbose: 1
