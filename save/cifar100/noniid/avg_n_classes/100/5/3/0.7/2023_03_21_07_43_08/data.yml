avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0482
- 0.0995
- 0.1145
- 0.1345
- 0.1518
- 0.1597
- 0.1728
- 0.1757
- 0.1855
- 0.1971
- 0.2004
- 0.204
- 0.2134
- 0.2157
- 0.2215
- 0.2222
- 0.229
- 0.2357
- 0.2327
- 0.2368
- 0.24
- 0.2467
- 0.2478
- 0.2495
- 0.2553
- 0.2582
- 0.257
- 0.2608
- 0.2622
- 0.2648
- 0.2665
- 0.2679
- 0.2709
- 0.2742
- 0.2735
- 0.2781
- 0.2752
- 0.2816
- 0.2795
- 0.2823
- 0.2815
- 0.2838
- 0.2868
- 0.2828
- 0.2858
- 0.2823
- 0.2872
- 0.2926
- 0.2915
- 0.29
- 0.2908
- 0.2949
- 0.3021
- 0.2954
- 0.2956
- 0.2955
- 0.2973
- 0.296
- 0.2974
- 0.2993
- 0.2979
- 0.2988
- 0.2977
- 0.2999
- 0.3025
- 0.3035
- 0.3034
- 0.3038
- 0.3045
- 0.3015
- 0.3003
- 0.3048
- 0.3068
- 0.3057
- 0.3059
- 0.3045
- 0.3017
- 0.3037
- 0.3095
- 0.307
- 0.3092
- 0.3062
- 0.3069
- 0.3085
- 0.3095
- 0.3116
- 0.3113
- 0.3086
- 0.3098
- 0.3093
- 0.3075
- 0.3088
- 0.3104
- 0.3104
- 0.3106
- 0.3111
- 0.3119
- 0.3104
- 0.3097
- 0.3128
test_loss_list:
- 1.811047921180725
- 1.7160773229599
- 1.6686624717712402
- 1.637331051826477
- 1.6055484056472777
- 1.586698293685913
- 1.5601324343681335
- 1.550490550994873
- 1.536422896385193
- 1.5222548866271972
- 1.512988827228546
- 1.4976717948913574
- 1.4766697788238525
- 1.4753951573371886
- 1.4634204387664795
- 1.445366201400757
- 1.442815251350403
- 1.4461008977890015
- 1.4409472846984863
- 1.4264844512939454
- 1.4102795767784118
- 1.4055942296981812
- 1.4077023720741273
- 1.3896750235557556
- 1.3939327478408814
- 1.388390393257141
- 1.3766322612762452
- 1.3686758470535278
- 1.3722055959701538
- 1.3688478112220763
- 1.3595805168151855
- 1.3728753852844238
- 1.3648373937606813
- 1.3734441423416137
- 1.3564648389816285
- 1.35195912361145
- 1.3453022050857544
- 1.3574165511131286
- 1.3496743083000182
- 1.347518858909607
- 1.3312940645217894
- 1.3374756169319153
- 1.3325058007240296
- 1.3253279209136963
- 1.3319156455993653
- 1.3334525156021118
- 1.325565071105957
- 1.3241822457313537
- 1.3229447174072266
- 1.3261901950836181
- 1.3235094332695008
- 1.3352601790428162
- 1.3229397177696227
- 1.3348860836029053
- 1.3286754512786865
- 1.3196823906898498
- 1.3276215291023254
- 1.3095168042182923
- 1.3107301831245421
- 1.3132136464118958
- 1.3263508486747742
- 1.3177102065086366
- 1.3316073679924012
- 1.326304123401642
- 1.3094269633293152
- 1.319757719039917
- 1.3143822145462036
- 1.3071075701713561
- 1.3066054749488831
- 1.3001965141296388
- 1.292269423007965
- 1.2966609954833985
- 1.2882999467849732
- 1.2955688309669495
- 1.298428349494934
- 1.2994910883903503
- 1.2936421179771422
- 1.3121790647506715
- 1.3059930109977722
- 1.294497444629669
- 1.2993211364746093
- 1.3057362866401672
- 1.2919106531143187
- 1.287466242313385
- 1.2878109478950501
- 1.2905223679542541
- 1.295166380405426
- 1.29817449092865
- 1.2950378060340881
- 1.288771734237671
- 1.3087763428688048
- 1.302191116809845
- 1.2889099836349487
- 1.2819949865341187
- 1.3048815250396728
- 1.2995997786521911
- 1.295343804359436
- 1.2997128200531005
- 1.308927631378174
- 1.303560755252838
train_accuracy:
- 0.052
- 0.093
- 0.108
- 0.113
- 0.15
- 0.204
- 0.0
- 0.168
- 0.0
- 0.158
- 0.199
- 0.186
- 0.254
- 0.0
- 0.0
- 0.197
- 0.196
- 0.283
- 0.0
- 0.281
- 0.0
- 0.222
- 0.0
- 0.0
- 0.324
- 0.281
- 0.265
- 0.252
- 0.0
- 0.0
- 0.236
- 0.0
- 0.247
- 0.323
- 0.328
- 0.25
- 0.0
- 0.268
- 0.302
- 0.0
- 0.0
- 0.265
- 0.0
- 0.349
- 0.287
- 0.314
- 0.0
- 0.0
- 0.271
- 0.27
- 0.0
- 0.342
- 0.312
- 0.322
- 0.287
- 0.319
- 0.276
- 0.0
- 0.0
- 0.322
- 0.33
- 0.334
- 0.291
- 0.0
- 0.0
- 0.278
- 0.368
- 0.312
- 0.355
- 0.282
- 0.0
- 0.0
- 0.333
- 0.0
- 0.34
- 0.302
- 0.309
- 0.298
- 0.299
- 0.0
- 0.0
- 0.371
- 0.34
- 0.364
- 0.303
- 0.318
- 0.0
- 0.0
- 0.0
- 0.343
- 0.362
- 0.333
- 0.383
- 0.0
- 0.0
- 0.311
- 0.346
- 0.355
- 0.3
- 0.0
train_loss:
- 3.334
- 3.006
- 2.455
- 2.663
- 2.24
- 2.488
- 2.118
- 2.296
- 2.214
- 2.19
- 2.113
- 2.044
- 1.782
- 1.935
- 1.882
- 1.655
- 1.783
- 1.944
- 1.66
- 1.461
- 1.48
- 1.612
- 1.521
- 1.385
- 1.493
- 1.43
- 1.256
- 1.215
- 1.293
- 1.303
- 1.114
- 1.36
- 1.201
- 1.316
- 1.119
- 1.125
- 1.053
- 1.198
- 1.069
- 1.006
- 0.895
- 0.981
- 1.015
- 0.848
- 0.937
- 0.893
- 0.854
- 0.854
- 0.878
- 0.779
- 0.779
- 0.846
- 0.813
- 0.794
- 0.749
- 0.689
- 0.713
- 0.647
- 0.677
- 0.637
- 0.636
- 0.641
- 0.624
- 0.602
- 0.551
- 0.592
- 0.56
- 0.544
- 0.543
- 0.507
- 0.509
- 0.508
- 0.475
- 0.465
- 0.467
- 0.456
- 0.434
- 0.458
- 0.414
- 0.438
- 0.415
- 0.405
- 0.398
- 0.4
- 0.396
- 0.376
- 0.384
- 0.365
- 0.364
- 0.373
- 0.338
- 0.349
- 0.352
- 0.349
- 0.32
- 0.334
- 0.33
- 0.318
- 0.288
- 0.29
unequal: 0
verbose: 1
