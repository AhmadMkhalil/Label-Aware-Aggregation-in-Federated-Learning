avg_train_accuracy: 0.32
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0304
- 0.0823
- 0.0289
- 0.1044
- 0.1158
- 0.131
- 0.1328
- 0.1419
- 0.1575
- 0.1595
- 0.1745
- 0.1737
- 0.1769
- 0.0319
- 0.1811
- 0.1938
- 0.029
- 0.0338
- 0.196
- 0.2071
- 0.0286
- 0.0305
- 0.0301
- 0.0315
- 0.1991
- 0.2069
- 0.0344
- 0.2111
- 0.2147
- 0.0347
- 0.2129
- 0.2084
- 0.2227
- 0.2222
- 0.2273
- 0.2258
- 0.2208
- 0.2341
- 0.2326
- 0.0332
- 0.222
- 0.2321
- 0.2415
- 0.0323
- 0.2467
- 0.2445
- 0.0336
- 0.2444
- 0.0316
- 0.2455
- 0.0397
- 0.0313
- 0.0334
- 0.0374
- 0.2532
- 0.2527
- 0.0336
- 0.0381
- 0.256
- 0.2651
- 0.043
- 0.2558
- 0.0351
- 0.0342
- 0.2559
- 0.2519
- 0.2618
- 0.0429
- 0.2555
- 0.2521
- 0.2571
- 0.2645
- 0.2713
- 0.2713
- 0.0388
- 0.2693
- 0.2588
- 0.2656
- 0.0403
- 0.0378
- 0.2596
- 0.2683
- 0.2713
- 0.0357
- 0.2704
- 0.2694
- 0.2725
- 0.0382
- 0.0386
- 0.2754
- 0.2686
- 0.0497
- 0.2814
- 0.0402
- 0.2777
- 0.2742
- 0.2777
- 0.2773
- 0.2854
- 0.2772
test_loss_list:
- 1.851124505996704
- 1.7899462699890136
- 3.5803003025054934
- 1.7346301198005676
- 1.7339315605163574
- 1.7064250779151917
- 1.722455801963806
- 1.7164745450019836
- 1.6960129141807556
- 1.6850363659858703
- 1.6751069116592407
- 1.683783884048462
- 1.6831489300727844
- 3.824845790863037
- 1.626443316936493
- 1.6083917546272277
- 3.711607141494751
- 3.7081958484649657
- 1.5490851235389709
- 1.540889241695404
- 3.559969673156738
- 3.4627938747406004
- 3.603542432785034
- 3.5613437938690184
- 1.4860098886489868
- 1.5032901191711425
- 3.450876760482788
- 1.4856394839286804
- 1.501221044063568
- 3.3932437896728516
- 1.4956011176109314
- 1.5260762476921081
- 1.5201700973510741
- 1.5187518143653869
- 1.5110822010040283
- 1.5283310294151307
- 1.5421875143051147
- 1.5295445799827576
- 1.5397471642494203
- 3.394195785522461
- 1.5252399301528932
- 1.4991912412643433
- 1.4995423007011413
- 3.392698655128479
- 1.4442144298553468
- 1.4715510892868042
- 3.3475002956390383
- 1.4444902729988098
- 3.3458664560317994
- 1.4507677221298219
- 3.276119031906128
- 3.3915970611572264
- 3.5384018325805666
- 3.3264899396896364
- 1.3882397294044495
- 1.4006879711151123
- 3.2141677808761595
- 3.1954623317718505
- 1.3855946278572082
- 1.4001634240150451
- 3.157500386238098
- 1.4012880373001098
- 3.1103740692138673
- 3.3032487726211546
- 1.4125802874565125
- 1.424306948184967
- 1.4126876950263978
- 3.093786153793335
- 1.4123337745666504
- 1.4502604842185973
- 1.4546848607063294
- 1.4427057957649232
- 1.4371167731285095
- 1.4472473454475403
- 3.11204487323761
- 1.4139065647125244
- 1.445916771888733
- 1.4444288873672486
- 3.093265700340271
- 3.2858847856521605
- 1.4450234746932984
- 1.4452084374427796
- 1.4376317739486695
- 3.3999584913253784
- 1.404464910030365
- 1.4183291363716126
- 1.420187966823578
- 3.211560468673706
- 3.0851905488967897
- 1.3687143349647521
- 1.4029321193695068
- 3.019444785118103
- 1.3416348433494567
- 3.197049469947815
- 1.3622542858123778
- 1.3899853420257569
- 1.3816728210449218
- 1.4017185139656068
- 1.382923083305359
- 1.4139269137382506
train_accuracy:
- 0.037
- 0.086
- 0.0
- 0.104
- 0.127
- 0.153
- 0.147
- 0.128
- 0.189
- 0.182
- 0.221
- 0.196
- 0.216
- 0.0
- 0.204
- 0.213
- 0.0
- 0.0
- 0.19
- 0.245
- 0.0
- 0.0
- 0.0
- 0.0
- 0.192
- 0.272
- 0.0
- 0.225
- 0.224
- 0.0
- 0.241
- 0.241
- 0.212
- 0.278
- 0.225
- 0.283
- 0.243
- 0.294
- 0.31
- 0.0
- 0.302
- 0.266
- 0.266
- 0.0
- 0.305
- 0.266
- 0.0
- 0.3
- 0.0
- 0.303
- 0.0
- 0.0
- 0.0
- 0.0
- 0.271
- 0.304
- 0.0
- 0.0
- 0.277
- 0.296
- 0.0
- 0.303
- 0.0
- 0.0
- 0.265
- 0.288
- 0.346
- 0.0
- 0.331
- 0.306
- 0.308
- 0.314
- 0.325
- 0.308
- 0.0
- 0.293
- 0.31
- 0.33
- 0.0
- 0.0
- 0.318
- 0.287
- 0.277
- 0.0
- 0.306
- 0.285
- 0.339
- 0.0
- 0.0
- 0.307
- 0.32
- 0.0
- 0.281
- 0.0
- 0.306
- 0.302
- 0.331
- 0.338
- 0.347
- 0.32
train_loss:
- 4.286
- 3.768
- 1.169
- 3.84
- 3.236
- 3.294
- 2.807
- 2.964
- 3.116
- 3.041
- 3.034
- 2.59
- 2.698
- 1.155
- 2.635
- 2.652
- 1.231
- 1.019
- 2.972
- 2.645
- 0.85
- 1.213
- 0.828
- 0.745
- 2.646
- 2.31
- 0.71
- 2.9
- 2.401
- 0.563
- 2.308
- 1.642
- 2.083
- 2.283
- 2.059
- 1.886
- 1.705
- 2.045
- 1.538
- 0.774
- 1.539
- 2.17
- 2.127
- 0.829
- 1.47
- 1.583
- 0.612
- 1.945
- 0.615
- 1.347
- 0.626
- 0.659
- 0.175
- 0.494
- 2.074
- 1.85
- 0.408
- 0.548
- 1.617
- 1.457
- 0.36
- 1.663
- 0.42
- 0.114
- 1.421
- 1.201
- 1.516
- 0.368
- 1.234
- 0.76
- 1.568
- 1.16
- 1.129
- 1.135
- 0.431
- 1.072
- 0.603
- 0.893
- 0.326
- 0.084
- 1.127
- 1.181
- 1.663
- 0.692
- 1.36
- 0.95
- 0.819
- 0.459
- 0.518
- 1.44
- 0.829
- 0.45
- 0.979
- 0.382
- 1.276
- 0.599
- 0.793
- 0.867
- 0.827
- 0.663
unequal: 0
verbose: 1
