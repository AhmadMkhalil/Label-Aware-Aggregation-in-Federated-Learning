avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0271
- 0.0642
- 0.0282
- 0.0892
- 0.0999
- 0.1174
- 0.1313
- 0.0256
- 0.0294
- 0.031
- 0.1337
- 0.1435
- 0.1496
- 0.1694
- 0.1711
- 0.1738
- 0.1762
- 0.0285
- 0.0279
- 0.1765
- 0.1899
- 0.1877
- 0.1954
- 0.2018
- 0.2019
- 0.0292
- 0.209
- 0.2085
- 0.032
- 0.2075
- 0.033
- 0.2073
- 0.216
- 0.0309
- 0.2215
- 0.0353
- 0.0297
- 0.2287
- 0.229
- 0.2267
- 0.2254
- 0.0362
- 0.2266
- 0.2318
- 0.2298
- 0.2385
- 0.2299
- 0.2322
- 0.0324
- 0.2406
- 0.0366
- 0.2448
- 0.2514
- 0.0381
- 0.0331
- 0.2436
- 0.0407
- 0.0324
- 0.0323
- 0.2574
- 0.2525
- 0.2507
- 0.2577
- 0.2562
- 0.2607
- 0.2534
- 0.2651
- 0.0423
- 0.2585
- 0.2569
- 0.0435
- 0.0378
- 0.2635
- 0.2692
- 0.2658
- 0.2662
- 0.264
- 0.0442
- 0.2659
- 0.2715
- 0.279
- 0.0467
- 0.2775
- 0.2638
- 0.2714
- 0.0433
- 0.265
- 0.0442
- 0.0386
- 0.2681
- 0.2731
- 0.0469
- 0.0464
- 0.2788
- 0.2838
- 0.2826
- 0.267
- 0.2798
- 0.2787
- 0.0462
test_loss_list:
- 3.1123642683029176
- 1.7965019845962524
- 3.6540874290466308
- 1.7505815029144287
- 1.7342208528518677
- 1.7202083778381347
- 1.7101031970977782
- 3.976172389984131
- 3.7204215812683104
- 3.8922722911834717
- 1.624574887752533
- 1.6366725707054137
- 1.6385224151611328
- 1.6406168198585511
- 1.637251386642456
- 1.6342889070510864
- 1.6423638916015626
- 3.7025373935699464
- 3.957316265106201
- 1.612962863445282
- 1.5969594240188598
- 1.6006722784042358
- 1.6048420095443725
- 1.6130908918380737
- 1.6102361273765564
- 3.632591323852539
- 1.5757896828651428
- 1.584256684780121
- 3.50559211730957
- 1.5494849133491515
- 3.355700340270996
- 1.5461792278289794
- 1.5528414011001588
- 3.5213885498046875
- 1.533410336971283
- 3.5642022609710695
- 3.625759744644165
- 1.44453200340271
- 1.4646180915832518
- 1.4986563420295715
- 1.5048267459869384
- 3.467560496330261
- 1.481450469493866
- 1.4895791435241699
- 1.515201029777527
- 1.50156067609787
- 1.5257586288452147
- 1.5334417867660521
- 3.431360778808594
- 1.4876350569725036
- 3.210777235031128
- 1.4338857340812683
- 1.4377989172935486
- 3.1737531328201296
- 3.335260043144226
- 1.431422266960144
- 3.2672913312911986
- 3.331517872810364
- 3.503960828781128
- 1.3827178359031678
- 1.4046529364585876
- 1.4240481281280517
- 1.42509489774704
- 1.44747216463089
- 1.4267493772506714
- 1.4594136786460876
- 1.4528431224822997
- 3.2256843566894533
- 1.42492023229599
- 1.4515310287475587
- 3.1846148204803466
- 3.2283833169937135
- 1.3956167125701904
- 1.4017505621910096
- 1.4257100820541382
- 1.443602225780487
- 1.4601596927642821
- 3.0969600296020507
- 1.413845591545105
- 1.4240053486824036
- 1.423931758403778
- 3.0476983976364136
- 1.4107405352592468
- 1.4537232160568236
- 1.45099844455719
- 3.117030210494995
- 1.4113467311859131
- 3.038841128349304
- 3.277707953453064
- 1.400664851665497
- 1.4029091548919679
- 3.0280447149276735
- 3.2025289869308473
- 1.3911962080001832
- 1.4102048015594482
- 1.415930004119873
- 1.4559150075912475
- 1.439429304599762
- 1.447309637069702
- 3.12472592830658
train_accuracy:
- 0.0
- 0.087
- 0.0
- 0.079
- 0.135
- 0.121
- 0.165
- 0.0
- 0.0
- 0.0
- 0.135
- 0.136
- 0.204
- 0.171
- 0.21
- 0.173
- 0.172
- 0.0
- 0.0
- 0.16
- 0.213
- 0.195
- 0.218
- 0.194
- 0.208
- 0.0
- 0.218
- 0.279
- 0.0
- 0.263
- 0.0
- 0.249
- 0.262
- 0.0
- 0.233
- 0.0
- 0.0
- 0.255
- 0.226
- 0.235
- 0.249
- 0.0
- 0.267
- 0.241
- 0.229
- 0.253
- 0.235
- 0.268
- 0.0
- 0.269
- 0.0
- 0.266
- 0.289
- 0.0
- 0.0
- 0.275
- 0.0
- 0.0
- 0.0
- 0.302
- 0.269
- 0.291
- 0.279
- 0.298
- 0.291
- 0.262
- 0.312
- 0.0
- 0.261
- 0.247
- 0.0
- 0.0
- 0.312
- 0.295
- 0.263
- 0.26
- 0.296
- 0.0
- 0.297
- 0.301
- 0.298
- 0.0
- 0.305
- 0.279
- 0.305
- 0.0
- 0.277
- 0.0
- 0.0
- 0.296
- 0.346
- 0.0
- 0.0
- 0.298
- 0.312
- 0.296
- 0.311
- 0.324
- 0.33
- 0.0
train_loss:
- 1.027
- 4.424
- 1.132
- 4.017
- 3.308
- 3.426
- 3.354
- 1.318
- 1.165
- 0.413
- 3.524
- 3.106
- 2.821
- 2.931
- 2.977
- 2.554
- 2.169
- 1.138
- 0.566
- 2.978
- 2.618
- 2.665
- 2.091
- 2.256
- 2.266
- 0.865
- 2.504
- 2.446
- 0.781
- 2.237
- 0.519
- 2.787
- 1.803
- 0.796
- 2.234
- 0.957
- 0.846
- 2.164
- 1.97
- 1.501
- 1.658
- 0.619
- 2.475
- 1.41
- 1.065
- 1.458
- 1.006
- 1.83
- 0.701
- 1.413
- 0.626
- 2.085
- 1.608
- 0.435
- 0.679
- 1.409
- 0.617
- 0.644
- 0.177
- 1.936
- 1.147
- 1.578
- 0.878
- 2.021
- 1.583
- 1.093
- 1.455
- 0.51
- 1.302
- 0.706
- 0.36
- 0.679
- 1.865
- 1.106
- 1.212
- 0.747
- 0.898
- 0.375
- 1.43
- 0.662
- 0.969
- 0.346
- 0.698
- 0.655
- 0.443
- 0.566
- 0.652
- 0.302
- 0.119
- 0.552
- 1.215
- 0.291
- 0.073
- 1.225
- 0.827
- 0.406
- 0.748
- 1.4
- 0.851
- 0.504
unequal: 0
verbose: 1
