avg_train_accuracy: 0.298
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041
- 0.0768
- 0.1045
- 0.1156
- 0.1226
- 0.1403
- 0.1456
- 0.0263
- 0.0291
- 0.0288
- 0.0289
- 0.149
- 0.0302
- 0.1659
- 0.1591
- 0.1695
- 0.03
- 0.1766
- 0.1818
- 0.1771
- 0.1836
- 0.2017
- 0.0312
- 0.1998
- 0.0318
- 0.2063
- 0.0315
- 0.2034
- 0.2102
- 0.2111
- 0.0315
- 0.2103
- 0.2155
- 0.2163
- 0.2158
- 0.0333
- 0.034
- 0.2195
- 0.2285
- 0.0331
- 0.0332
- 0.0307
- 0.2229
- 0.2281
- 0.2278
- 0.2368
- 0.0357
- 0.0337
- 0.2359
- 0.0337
- 0.2399
- 0.2455
- 0.2462
- 0.0355
- 0.2469
- 0.0347
- 0.248
- 0.2552
- 0.0352
- 0.2406
- 0.0362
- 0.25
- 0.2471
- 0.2689
- 0.2518
- 0.2543
- 0.2552
- 0.2681
- 0.0381
- 0.2614
- 0.2667
- 0.0375
- 0.2621
- 0.0391
- 0.0357
- 0.2645
- 0.2742
- 0.0397
- 0.2663
- 0.2715
- 0.272
- 0.2729
- 0.0442
- 0.2776
- 0.0473
- 0.0386
- 0.0382
- 0.0423
- 0.2703
- 0.2692
- 0.038
- 0.0415
- 0.0424
- 0.0407
- 0.2821
- 0.2798
- 0.271
- 0.0456
- 0.2814
- 0.2768
test_loss_list:
- 1.8269290685653687
- 1.7933708381652833
- 1.7541364240646362
- 1.7262764811515807
- 1.7456937742233276
- 1.7302038121223449
- 1.713851544857025
- 3.8518996810913086
- 3.7345689868927003
- 3.778776865005493
- 3.9251434326171877
- 1.5985858845710754
- 3.640814533233643
- 1.5877933764457703
- 1.601880919933319
- 1.6183220171928405
- 3.5436371040344237
- 1.5771507596969605
- 1.581897141933441
- 1.6086513233184814
- 1.607752299308777
- 1.5874414014816285
- 3.540698318481445
- 1.5477879309654237
- 3.5146020221710206
- 1.544188506603241
- 3.6666558456420897
- 1.5047588706016541
- 1.5116920232772828
- 1.5337488842010498
- 3.4360141515731812
- 1.5045979857444762
- 1.5135448503494262
- 1.5140199089050292
- 1.5231209325790405
- 3.4763785457611083
- 3.467777786254883
- 1.4585512900352477
- 1.4733087158203124
- 3.4258686828613283
- 3.56884051322937
- 3.6205473232269285
- 1.44942622423172
- 1.4611661195755006
- 1.4674728178977967
- 1.4829092717170715
- 3.3021758937835695
- 3.4455714321136472
- 1.4295580434799193
- 3.285315294265747
- 1.421347942352295
- 1.4317052149772644
- 1.4434285831451417
- 3.256224904060364
- 1.4341355347633362
- 3.318097586631775
- 1.4193785572052002
- 1.429618797302246
- 3.2157254362106324
- 1.4468141508102417
- 3.179972057342529
- 1.4212440705299378
- 1.4407087302207946
- 1.430767560005188
- 1.4504078936576843
- 1.4537512898445129
- 1.4565697503089905
- 1.443171124458313
- 3.2241159105300903
- 1.4405304980278015
- 1.4364672541618346
- 3.249009857177734
- 1.4125238919258118
- 3.213896131515503
- 3.17184600353241
- 1.3606068062782288
- 1.371258008480072
- 3.11380250453949
- 1.3745862030982972
- 1.3812052559852601
- 1.3993186950683594
- 1.4037690591812133
- 3.103997731208801
- 1.3834579133987426
- 3.0456042814254762
- 3.124012598991394
- 3.222950191497803
- 3.1354356670379637
- 1.3425256681442261
- 1.3576827669143676
- 3.0950331115722656
- 3.0304380655288696
- 3.136991791725159
- 3.218197937011719
- 1.3263418006896972
- 1.3515393185615538
- 1.3835013890266419
- 2.9931064224243165
- 1.3628278803825378
- 1.3841264700889588
train_accuracy:
- 0.025
- 0.08
- 0.099
- 0.127
- 0.112
- 0.136
- 0.192
- 0.0
- 0.0
- 0.0
- 0.0
- 0.153
- 0.0
- 0.179
- 0.15
- 0.162
- 0.0
- 0.243
- 0.18
- 0.209
- 0.216
- 0.213
- 0.0
- 0.181
- 0.0
- 0.206
- 0.0
- 0.183
- 0.232
- 0.225
- 0.0
- 0.228
- 0.182
- 0.227
- 0.26
- 0.0
- 0.0
- 0.233
- 0.221
- 0.0
- 0.0
- 0.0
- 0.224
- 0.213
- 0.248
- 0.219
- 0.0
- 0.0
- 0.253
- 0.0
- 0.295
- 0.261
- 0.252
- 0.0
- 0.293
- 0.0
- 0.278
- 0.265
- 0.0
- 0.255
- 0.0
- 0.305
- 0.253
- 0.287
- 0.263
- 0.289
- 0.295
- 0.305
- 0.0
- 0.282
- 0.281
- 0.0
- 0.299
- 0.0
- 0.0
- 0.29
- 0.277
- 0.0
- 0.265
- 0.284
- 0.268
- 0.289
- 0.0
- 0.296
- 0.0
- 0.0
- 0.0
- 0.0
- 0.282
- 0.289
- 0.0
- 0.0
- 0.0
- 0.0
- 0.299
- 0.293
- 0.299
- 0.0
- 0.29
- 0.298
train_loss:
- 4.238
- 3.822
- 3.555
- 3.459
- 3.206
- 2.976
- 3.17
- 1.276
- 1.412
- 1.48
- 0.978
- 3.136
- 0.821
- 3.37
- 2.91
- 2.386
- 0.806
- 3.167
- 2.701
- 2.247
- 2.537
- 2.602
- 0.818
- 2.448
- 0.561
- 2.591
- 1.048
- 2.178
- 2.248
- 1.787
- 0.802
- 2.279
- 1.728
- 2.537
- 2.431
- 0.813
- 0.878
- 2.014
- 1.527
- 0.489
- 0.176
- 0.869
- 2.309
- 1.296
- 2.116
- 1.132
- 0.473
- 0.901
- 1.999
- 0.569
- 2.321
- 1.435
- 1.577
- 0.568
- 1.933
- 0.507
- 2.018
- 1.274
- 0.411
- 1.635
- 0.515
- 1.648
- 1.722
- 1.113
- 1.322
- 1.958
- 1.347
- 0.955
- 0.482
- 1.541
- 0.738
- 0.464
- 1.267
- 0.565
- 0.569
- 1.262
- 1.21
- 0.377
- 1.272
- 1.612
- 0.84
- 0.975
- 0.421
- 1.09
- 0.285
- 0.57
- 0.508
- 0.346
- 0.981
- 1.327
- 0.306
- 0.464
- 0.453
- 0.067
- 0.975
- 0.681
- 1.004
- 0.296
- 0.759
- 0.39
unequal: 0
verbose: 1
