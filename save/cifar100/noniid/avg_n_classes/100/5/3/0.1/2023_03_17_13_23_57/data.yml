avg_train_accuracy: 0.0
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0362
- 0.0245
- 0.0845
- 0.0266
- 0.0252
- 0.0978
- 0.0254
- 0.0264
- 0.1119
- 0.1353
- 0.0307
- 0.1441
- 0.1517
- 0.1568
- 0.16
- 0.1731
- 0.177
- 0.0313
- 0.1757
- 0.1905
- 0.0291
- 0.1887
- 0.1964
- 0.0285
- 0.1998
- 0.1996
- 0.2101
- 0.0311
- 0.0311
- 0.0349
- 0.2066
- 0.2157
- 0.2165
- 0.0319
- 0.2067
- 0.0304
- 0.2156
- 0.2245
- 0.0311
- 0.2273
- 0.2223
- 0.2129
- 0.0349
- 0.0337
- 0.2268
- 0.0366
- 0.0354
- 0.2319
- 0.2383
- 0.246
- 0.0367
- 0.2399
- 0.2391
- 0.244
- 0.0331
- 0.2458
- 0.2443
- 0.0329
- 0.0331
- 0.2498
- 0.2516
- 0.2487
- 0.0366
- 0.2557
- 0.0403
- 0.2496
- 0.0375
- 0.2452
- 0.2567
- 0.2624
- 0.2578
- 0.263
- 0.255
- 0.2629
- 0.0358
- 0.2593
- 0.0363
- 0.2564
- 0.0405
- 0.249
- 0.0415
- 0.0402
- 0.2484
- 0.0402
- 0.263
- 0.2637
- 0.0451
- 0.2694
- 0.2619
- 0.0385
- 0.2736
- 0.0418
- 0.0452
- 0.2734
- 0.2721
- 0.2689
- 0.2751
- 0.0396
- 0.2803
- 0.0462
test_loss_list:
- 1.8310323095321654
- 3.7264892292022704
- 1.7460834789276123
- 3.7310749912261962
- 3.7723653221130373
- 1.6963117980957032
- 3.6447577381134035
- 3.655972900390625
- 1.668225667476654
- 1.664264588356018
- 3.761282844543457
- 1.6345778965950013
- 1.6294541764259338
- 1.64781010389328
- 1.6379423546791076
- 1.633594629764557
- 1.6196113896369935
- 3.678751802444458
- 1.6130136680603027
- 1.6082391571998595
- 3.5763132619857787
- 1.5604602098464966
- 1.5518271803855896
- 3.6247027778625487
- 1.5096279239654542
- 1.5293747878074646
- 1.5231207847595214
- 3.433279662132263
- 3.5257157135009765
- 3.697486095428467
- 1.4750513863563537
- 1.500286033153534
- 1.5076683139801026
- 3.3694776916503906
- 1.491374943256378
- 3.506349925994873
- 1.4874090814590455
- 1.476049075126648
- 3.4037715768814087
- 1.4668174266815186
- 1.4782122015953063
- 1.5148931670188903
- 3.3632678318023683
- 3.62502082824707
- 1.4668906092643739
- 3.280662727355957
- 3.458782043457031
- 1.4646110463142394
- 1.4819814777374267
- 1.4685591173171997
- 3.219910912513733
- 1.4766803979873657
- 1.4760251069068908
- 1.494989972114563
- 3.510636739730835
- 1.4468232893943787
- 1.4659039711952209
- 3.36747145652771
- 3.2975572109222413
- 1.417036807537079
- 1.4390693140029907
- 1.4575271916389465
- 3.1955643844604493
- 1.4187502670288086
- 3.062846055030823
- 1.4368877577781678
- 3.1728767728805543
- 1.4092286801338196
- 1.4222766160964966
- 1.4240982174873351
- 1.4499433422088623
- 1.448004732131958
- 1.4640335083007812
- 1.4576233458518981
- 3.2908648109436034
- 1.4482740354537964
- 3.352833585739136
- 1.4319991612434386
- 3.188765687942505
- 1.4128364276885987
- 3.0901179695129395
- 3.2350923824310303
- 1.4271864533424377
- 3.115660948753357
- 1.39075355052948
- 1.4011590480804443
- 2.990940294265747
- 1.3971117758750915
- 1.4235154032707213
- 3.19103187084198
- 1.3927731370925904
- 3.1680631160736086
- 3.0287947511672972
- 1.3640249395370483
- 1.396362898349762
- 1.4277842450141907
- 1.4209445452690124
- 3.169454855918884
- 1.399480767250061
- 3.071976442337036
train_accuracy:
- 0.042
- 0.0
- 0.121
- 0.0
- 0.0
- 0.111
- 0.0
- 0.0
- 0.098
- 0.142
- 0.0
- 0.164
- 0.197
- 0.175
- 0.176
- 0.17
- 0.164
- 0.0
- 0.165
- 0.241
- 0.0
- 0.21
- 0.229
- 0.0
- 0.219
- 0.186
- 0.222
- 0.0
- 0.0
- 0.0
- 0.224
- 0.199
- 0.209
- 0.0
- 0.216
- 0.0
- 0.262
- 0.247
- 0.0
- 0.179
- 0.23
- 0.241
- 0.0
- 0.0
- 0.247
- 0.0
- 0.0
- 0.275
- 0.224
- 0.243
- 0.0
- 0.233
- 0.227
- 0.267
- 0.0
- 0.298
- 0.239
- 0.0
- 0.0
- 0.276
- 0.292
- 0.296
- 0.0
- 0.305
- 0.0
- 0.287
- 0.0
- 0.257
- 0.244
- 0.309
- 0.293
- 0.234
- 0.238
- 0.315
- 0.0
- 0.264
- 0.0
- 0.25
- 0.0
- 0.249
- 0.0
- 0.0
- 0.222
- 0.0
- 0.254
- 0.325
- 0.0
- 0.269
- 0.265
- 0.0
- 0.253
- 0.0
- 0.0
- 0.336
- 0.281
- 0.298
- 0.291
- 0.0
- 0.312
- 0.0
train_loss:
- 4.292
- 1.303
- 4.066
- 1.041
- 1.517
- 3.895
- 0.917
- 1.199
- 3.682
- 3.244
- 1.144
- 3.306
- 2.958
- 2.52
- 2.858
- 2.958
- 2.947
- 0.868
- 2.815
- 2.662
- 1.001
- 2.784
- 2.836
- 1.01
- 2.55
- 2.288
- 2.384
- 0.794
- 0.917
- 0.283
- 2.75
- 2.017
- 2.052
- 0.685
- 2.32
- 0.825
- 2.429
- 2.387
- 0.605
- 2.044
- 1.831
- 1.439
- 0.608
- 0.18
- 2.274
- 0.379
- 0.106
- 2.309
- 1.617
- 1.836
- 0.403
- 1.599
- 1.49
- 1.85
- 0.784
- 1.959
- 1.392
- 0.573
- 0.827
- 1.738
- 1.752
- 1.246
- 0.457
- 1.739
- 0.295
- 1.246
- 0.527
- 1.523
- 1.409
- 1.224
- 1.339
- 1.261
- 1.093
- 1.093
- 0.61
- 1.161
- 0.39
- 1.028
- 0.481
- 0.784
- 0.303
- 0.104
- 0.676
- 0.403
- 1.404
- 1.135
- 0.287
- 1.888
- 0.656
- 0.449
- 1.037
- 0.312
- 0.52
- 1.089
- 0.686
- 1.174
- 1.339
- 0.355
- 0.991
- 0.238
unequal: 0
verbose: 1
