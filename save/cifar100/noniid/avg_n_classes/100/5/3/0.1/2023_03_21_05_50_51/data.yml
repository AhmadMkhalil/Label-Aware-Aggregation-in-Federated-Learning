avg_train_accuracy: 0.275
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.023
- 0.0638
- 0.0924
- 0.1139
- 0.1233
- 0.1438
- 0.1478
- 0.0291
- 0.1483
- 0.0325
- 0.0336
- 0.1588
- 0.0335
- 0.1563
- 0.1692
- 0.1786
- 0.178
- 0.1898
- 0.1887
- 0.1858
- 0.1993
- 0.2018
- 0.1964
- 0.1984
- 0.2091
- 0.2087
- 0.2018
- 0.0357
- 0.2079
- 0.2239
- 0.2249
- 0.037
- 0.2174
- 0.029
- 0.2268
- 0.2276
- 0.2243
- 0.0298
- 0.0351
- 0.2223
- 0.2314
- 0.0369
- 0.0322
- 0.0367
- 0.2281
- 0.2403
- 0.2388
- 0.2429
- 0.0343
- 0.2304
- 0.0336
- 0.033
- 0.2487
- 0.251
- 0.2546
- 0.2575
- 0.0419
- 0.0403
- 0.2445
- 0.2497
- 0.2531
- 0.0417
- 0.245
- 0.2599
- 0.0337
- 0.2606
- 0.2562
- 0.0343
- 0.0348
- 0.2628
- 0.2613
- 0.2599
- 0.0411
- 0.0424
- 0.2657
- 0.2598
- 0.2587
- 0.0451
- 0.0369
- 0.2551
- 0.2597
- 0.0348
- 0.2742
- 0.2659
- 0.2753
- 0.2664
- 0.0358
- 0.2718
- 0.269
- 0.2708
- 0.2631
- 0.0406
- 0.2704
- 0.2802
- 0.271
- 0.2708
- 0.2751
- 0.0451
- 0.2734
- 0.2703
test_loss_list:
- 3.130119090080261
- 1.7950360202789306
- 1.7697556734085083
- 1.7437143182754518
- 1.7298766469955444
- 1.7050581741333009
- 1.7155729603767396
- 3.814933910369873
- 1.6871192288398742
- 3.7542368030548094
- 3.9279234123229982
- 1.6421277737617492
- 3.549258270263672
- 1.6267467141151428
- 1.6243272995948792
- 1.616881046295166
- 1.6285095977783204
- 1.6335867881774901
- 1.628224003314972
- 1.6522371101379394
- 1.623455901145935
- 1.638987011909485
- 1.6509678769111633
- 1.6443017601966858
- 1.624752423763275
- 1.6469667339324952
- 1.668678741455078
- 3.4947283554077146
- 1.5845858025550843
- 1.5828296542167664
- 1.5787947583198547
- 3.3812677574157717
- 1.5780482125282287
- 3.6097576904296873
- 1.5248718762397766
- 1.5319809746742248
- 1.5361793303489686
- 3.680201921463013
- 3.4730317401885986
- 1.4630822443962097
- 1.4773156905174256
- 3.1239634799957274
- 3.404103183746338
- 3.3147566890716553
- 1.446562283039093
- 1.4520845580101014
- 1.4698953199386597
- 1.4880284905433654
- 3.3561651802062986
- 1.48891028881073
- 3.3204646158218383
- 3.453286600112915
- 1.4576390337944032
- 1.4766955637931825
- 1.4798557353019715
- 1.4842512583732606
- 3.174484453201294
- 3.3727492046356202
- 1.4675500416755676
- 1.4778261184692383
- 1.475059027671814
- 3.096279625892639
- 1.4683671879768372
- 1.461188063621521
- 3.455568904876709
- 1.4167333269119262
- 1.4563959240913391
- 3.393388113975525
- 3.256272220611572
- 1.3907388162612915
- 1.4276997113227845
- 1.4438159012794494
- 3.132116174697876
- 3.1104668760299683
- 1.3855976009368896
- 1.4232189774513244
- 1.4450249457359314
- 3.11209180355072
- 3.3316072988510133
- 1.3992797541618347
- 1.402938792705536
- 3.135407705307007
- 1.3919401741027833
- 1.4353317260742187
- 1.4167314648628235
- 1.443569061756134
- 3.1617367887496948
- 1.4158370614051818
- 1.42208304643631
- 1.4505084228515626
- 1.469434974193573
- 3.11691225528717
- 1.4478726530075072
- 1.425575635433197
- 1.4700607681274414
- 1.4795591592788697
- 1.4669701504707335
- 3.1299902057647704
- 1.4252282309532165
- 1.4474024677276611
train_accuracy:
- 0.0
- 0.074
- 0.108
- 0.117
- 0.127
- 0.165
- 0.185
- 0.0
- 0.146
- 0.0
- 0.0
- 0.143
- 0.0
- 0.179
- 0.179
- 0.197
- 0.206
- 0.202
- 0.212
- 0.203
- 0.216
- 0.205
- 0.214
- 0.191
- 0.208
- 0.223
- 0.216
- 0.0
- 0.217
- 0.256
- 0.248
- 0.0
- 0.215
- 0.0
- 0.253
- 0.265
- 0.218
- 0.0
- 0.0
- 0.214
- 0.269
- 0.0
- 0.0
- 0.0
- 0.267
- 0.271
- 0.279
- 0.243
- 0.0
- 0.255
- 0.0
- 0.0
- 0.279
- 0.285
- 0.276
- 0.301
- 0.0
- 0.0
- 0.216
- 0.28
- 0.304
- 0.0
- 0.244
- 0.297
- 0.0
- 0.287
- 0.272
- 0.0
- 0.0
- 0.297
- 0.316
- 0.276
- 0.0
- 0.0
- 0.279
- 0.276
- 0.292
- 0.0
- 0.0
- 0.258
- 0.274
- 0.0
- 0.32
- 0.324
- 0.331
- 0.286
- 0.0
- 0.325
- 0.283
- 0.318
- 0.3
- 0.0
- 0.31
- 0.305
- 0.315
- 0.304
- 0.302
- 0.0
- 0.325
- 0.275
train_loss:
- 1.071
- 4.414
- 3.672
- 3.47
- 3.376
- 3.165
- 2.75
- 1.065
- 3.279
- 1.056
- 0.399
- 2.971
- 0.591
- 3.292
- 2.834
- 2.873
- 2.581
- 2.406
- 2.455
- 2.265
- 2.474
- 2.106
- 1.942
- 2.387
- 2.493
- 1.941
- 1.704
- 0.696
- 2.29
- 1.937
- 2.106
- 0.492
- 1.936
- 1.002
- 1.906
- 2.089
- 1.53
- 1.248
- 0.72
- 1.448
- 1.471
- 0.371
- 0.947
- 0.469
- 2.053
- 1.836
- 1.238
- 1.709
- 0.663
- 1.989
- 0.538
- 0.224
- 1.778
- 1.373
- 1.441
- 1.273
- 0.425
- 0.125
- 1.499
- 1.503
- 1.186
- 0.327
- 2.423
- 1.312
- 0.897
- 1.529
- 0.847
- 0.607
- 0.832
- 1.389
- 1.064
- 0.843
- 0.458
- 0.515
- 1.483
- 0.712
- 0.482
- 0.271
- 0.708
- 1.34
- 1.868
- 0.481
- 1.278
- 0.964
- 0.761
- 1.478
- 0.443
- 0.95
- 0.918
- 0.563
- 0.391
- 0.388
- 0.477
- 0.749
- 0.348
- 0.23
- 0.519
- 0.553
- 0.529
- 1.037
unequal: 0
verbose: 1
