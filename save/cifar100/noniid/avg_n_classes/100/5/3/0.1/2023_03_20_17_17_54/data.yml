avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0459
- 0.0825
- 0.0317
- 0.0935
- 0.1088
- 0.0295
- 0.1121
- 0.1373
- 0.1424
- 0.1467
- 0.1435
- 0.1647
- 0.1735
- 0.1772
- 0.178
- 0.1894
- 0.1898
- 0.1977
- 0.1945
- 0.1965
- 0.2001
- 0.2046
- 0.2067
- 0.2092
- 0.2155
- 0.215
- 0.035
- 0.2149
- 0.2202
- 0.0304
- 0.2249
- 0.2246
- 0.0296
- 0.222
- 0.2205
- 0.0351
- 0.2262
- 0.0371
- 0.2275
- 0.0314
- 0.2236
- 0.2381
- 0.0329
- 0.033
- 0.2376
- 0.2366
- 0.2397
- 0.2392
- 0.0367
- 0.2415
- 0.0345
- 0.2325
- 0.2484
- 0.0367
- 0.2502
- 0.2473
- 0.2475
- 0.2478
- 0.2543
- 0.2584
- 0.0378
- 0.2585
- 0.2613
- 0.2653
- 0.2654
- 0.2604
- 0.0377
- 0.2561
- 0.0397
- 0.0383
- 0.2631
- 0.2607
- 0.26
- 0.2686
- 0.2703
- 0.2683
- 0.2751
- 0.2589
- 0.2692
- 0.0392
- 0.0356
- 0.2757
- 0.2755
- 0.2742
- 0.2758
- 0.2705
- 0.2684
- 0.0437
- 0.0411
- 0.0393
- 0.2698
- 0.0482
- 0.2765
- 0.2738
- 0.0553
- 0.2796
- 0.2807
- 0.2762
- 0.2821
- 0.0417
test_loss_list:
- 1.8228348779678345
- 1.775736322402954
- 3.7841425132751465
- 1.7300801825523378
- 1.7229126501083374
- 3.731974582672119
- 1.6771583318710328
- 1.6756202006340026
- 1.6655375266075134
- 1.671955087184906
- 1.6669337821006776
- 1.656951766014099
- 1.6503953385353087
- 1.6479640293121338
- 1.6499426293373107
- 1.6472007489204408
- 1.6591510057449341
- 1.6475828719139098
- 1.6473486590385438
- 1.6383690810203553
- 1.6553289127349853
- 1.648382077217102
- 1.6493328976631165
- 1.6424434447288514
- 1.6531828331947327
- 1.6494188618659973
- 3.6444063282012937
- 1.5728068614006043
- 1.5902264857292174
- 3.691564292907715
- 1.5173085713386536
- 1.5326110816001892
- 3.7087425804138183
- 1.5295460677146913
- 1.5594255113601685
- 3.52499174118042
- 1.5107243156433106
- 3.3590512752532957
- 1.5220066595077515
- 3.4960884380340578
- 1.4982719135284424
- 1.471502079963684
- 3.4845024967193603
- 3.4833916568756105
- 1.4196989989280702
- 1.4434698152542114
- 1.4675683569908142
- 1.4774536108970642
- 3.4116953563690187
- 1.4305495142936706
- 3.3764368867874146
- 1.4411061692237854
- 1.438555784225464
- 3.2975487422943117
- 1.4281413340568543
- 1.4594089770317078
- 1.4739209842681884
- 1.4850623726844787
- 1.4467045855522156
- 1.479638500213623
- 3.2710411405563353
- 1.4174756908416748
- 1.4509537291526795
- 1.4580509495735168
- 1.465813159942627
- 1.470199248790741
- 3.3119181108474733
- 1.4510624098777771
- 3.216165904998779
- 3.424640350341797
- 1.405787663459778
- 1.4383274412155151
- 1.4515684604644776
- 1.4495339155197144
- 1.4406795692443848
- 1.469109764099121
- 1.4684009981155395
- 1.4978159165382385
- 1.499247739315033
- 3.1795527601242064
- 3.444808044433594
- 1.4460677528381347
- 1.4510887694358825
- 1.4491033053398132
- 1.4650800013542176
- 1.4709258770942688
- 1.4914745807647705
- 3.1492520904541017
- 3.317302737236023
- 3.471441512107849
- 1.4611747789382934
- 2.9777821779251097
- 1.4255699586868287
- 1.4797296047210693
- 2.922997822761536
- 1.4583073997497558
- 1.4763650941848754
- 1.4944834423065185
- 1.4755066561698913
- 3.2356556940078733
train_accuracy:
- 0.055
- 0.074
- 0.0
- 0.087
- 0.075
- 0.0
- 0.119
- 0.147
- 0.15
- 0.147
- 0.191
- 0.181
- 0.18
- 0.183
- 0.217
- 0.204
- 0.2
- 0.205
- 0.206
- 0.241
- 0.206
- 0.21
- 0.233
- 0.221
- 0.216
- 0.206
- 0.0
- 0.234
- 0.231
- 0.0
- 0.262
- 0.213
- 0.0
- 0.275
- 0.258
- 0.0
- 0.233
- 0.0
- 0.218
- 0.0
- 0.274
- 0.247
- 0.0
- 0.0
- 0.242
- 0.256
- 0.244
- 0.246
- 0.0
- 0.246
- 0.0
- 0.294
- 0.288
- 0.0
- 0.283
- 0.266
- 0.266
- 0.242
- 0.255
- 0.254
- 0.0
- 0.278
- 0.259
- 0.309
- 0.267
- 0.274
- 0.0
- 0.301
- 0.0
- 0.0
- 0.28
- 0.269
- 0.314
- 0.265
- 0.3
- 0.275
- 0.267
- 0.284
- 0.301
- 0.0
- 0.0
- 0.296
- 0.318
- 0.29
- 0.3
- 0.325
- 0.315
- 0.0
- 0.0
- 0.0
- 0.307
- 0.0
- 0.316
- 0.341
- 0.0
- 0.269
- 0.257
- 0.258
- 0.307
- 0.0
train_loss:
- 4.278
- 3.765
- 0.979
- 3.938
- 3.489
- 1.203
- 3.487
- 3.284
- 3.056
- 3.095
- 2.827
- 2.996
- 2.918
- 2.657
- 2.711
- 2.612
- 2.62
- 2.64
- 2.313
- 2.419
- 2.26
- 2.294
- 2.329
- 2.063
- 2.018
- 1.974
- 0.869
- 2.407
- 2.201
- 1.257
- 2.398
- 1.768
- 0.839
- 1.974
- 1.342
- 0.627
- 2.088
- 0.436
- 1.653
- 0.799
- 2.16
- 2.257
- 0.974
- 0.857
- 1.877
- 1.814
- 1.297
- 0.984
- 0.504
- 1.797
- 0.687
- 1.736
- 1.61
- 0.405
- 2.039
- 1.289
- 1.299
- 1.434
- 1.442
- 1.107
- 0.65
- 1.995
- 0.922
- 1.175
- 1.3
- 1.204
- 0.517
- 1.641
- 0.491
- 0.094
- 1.163
- 1.099
- 1.143
- 0.889
- 0.825
- 0.893
- 0.7
- 0.991
- 0.623
- 0.529
- 0.121
- 1.417
- 1.054
- 0.772
- 0.899
- 1.268
- 0.775
- 0.422
- 0.109
- 0.073
- 1.033
- 0.25
- 0.829
- 0.75
- 0.247
- 0.86
- 0.417
- 0.304
- 0.849
- 0.801
unequal: 0
verbose: 1
