avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0437
- 0.05
- 0.0914
- 0.107
- 0.1237
- 0.1353
- 0.1397
- 0.143
- 0.1503
- 0.1436
- 0.1637
- 0.1627
- 0.1672
- 0.1688
- 0.172
- 0.1737
- 0.1773
- 0.1819
- 0.1789
- 0.1759
- 0.1842
- 0.1798
- 0.1892
- 0.1888
- 0.1811
- 0.1893
- 0.1915
- 0.1957
- 0.1944
- 0.1928
- 0.1989
- 0.1995
- 0.2035
- 0.2057
- 0.2066
- 0.2
- 0.1978
- 0.2014
- 0.2117
- 0.207
- 0.2093
- 0.2091
- 0.2065
- 0.2062
- 0.2063
- 0.2045
- 0.211
- 0.2064
- 0.2145
- 0.213
- 0.2111
- 0.2041
- 0.2133
- 0.2079
- 0.213
- 0.2094
- 0.225
- 0.2078
- 0.212
- 0.2177
- 0.2149
- 0.2147
- 0.2125
- 0.2183
- 0.2134
- 0.2169
- 0.2158
- 0.2168
- 0.2122
- 0.2246
- 0.2156
- 0.2184
- 0.2183
- 0.2112
- 0.2119
- 0.2177
- 0.2192
- 0.2122
- 0.2188
- 0.2149
- 0.2166
- 0.2182
- 0.2163
- 0.218
- 0.2202
- 0.2163
- 0.216
- 0.2184
- 0.2213
- 0.2193
- 0.2155
- 0.215
- 0.2357
- 0.2249
- 0.2164
- 0.2233
- 0.2156
- 0.2205
- 0.217
- 0.2202
test_loss_list:
- 1.8713764095306396
- 1.7995458507537843
- 1.7913724613189697
- 1.81858069896698
- 1.8369880294799805
- 1.8447800254821778
- 1.8529621934890748
- 1.830501012802124
- 1.8147202348709106
- 1.8096576738357544
- 1.7812441301345825
- 1.7819097709655762
- 1.7679995918273925
- 1.7691178512573242
- 1.7627268743515014
- 1.543071300983429
- 1.631158926486969
- 1.6665867614746093
- 1.6884887170791627
- 1.698087236881256
- 1.7068700838088988
- 1.7129456615447998
- 1.71542635679245
- 1.7189599609375
- 1.72128653049469
- 1.4924484062194825
- 1.5943473124504088
- 1.6437797617912293
- 1.6545370531082153
- 1.6536230087280273
- 1.6564503741264343
- 1.670944185256958
- 1.6700175642967223
- 1.6707017016410828
- 1.6829979562759398
- 1.6700310063362123
- 1.6592059326171875
- 1.646674165725708
- 1.461329321861267
- 1.556762261390686
- 1.591999568939209
- 1.6090843296051025
- 1.6117322969436645
- 1.6100726437568664
- 1.6083432292938233
- 1.6175393629074097
- 1.6124328207969665
- 1.6099044847488404
- 1.610669629573822
- 1.6159522485733033
- 1.6130115795135498
- 1.6115917563438416
- 1.6090462064743043
- 1.6243259000778199
- 1.6181817317008973
- 1.612914571762085
- 1.4625746154785155
- 1.5336126732826232
- 1.5605370020866394
- 1.570930004119873
- 1.5825473475456238
- 1.5815055108070373
- 1.5750702023506165
- 1.5826157426834107
- 1.5802573227882386
- 1.5836464619636537
- 1.590161817073822
- 1.5867015862464904
- 1.5804198789596557
- 1.469412305355072
- 1.507916944026947
- 1.532161500453949
- 1.5429931807518005
- 1.5523804903030396
- 1.5409612369537353
- 1.566497766971588
- 1.5676331949234008
- 1.5602170276641845
- 1.5680351233482361
- 1.5597832679748536
- 1.5652975749969482
- 1.5616493463516234
- 1.559675931930542
- 1.5590657210350036
- 1.555552794933319
- 1.5461753153800963
- 1.5388750696182252
- 1.5399104070663452
- 1.5461460041999817
- 1.547143063545227
- 1.5389307522773743
- 1.5311911940574645
- 1.4670504188537599
- 1.4878578114509582
- 1.5124325108528138
- 1.5213001298904418
- 1.537353012561798
- 1.5361301875114441
- 1.5312141036987306
- 1.5330562019348144
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.199
- 0.219
- 0.171
- 0.0
- 0.0
- 0.202
- 0.0
- 0.0
- 0.0
- 0.208
- 0.0
- 0.269
- 0.0
- 0.0
- 0.221
- 0.0
- 0.0
- 0.233
- 0.0
- 0.32
- 0.0
- 0.0
- 0.0
- 0.257
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.278
- 0.0
- 0.0
- 0.271
- 0.317
- 0.0
- 0.0
- 0.282
- 0.0
- 0.0
- 0.0
- 0.269
- 0.0
- 0.0
- 0.0
- 0.35
- 0.348
- 0.268
- 0.273
- 0.36
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.31
- 0.0
- 0.285
- 0.317
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.001
- 0.298
- 0.0
- 0.364
- 0.0
- 0.0
- 0.0
- 0.292
- 0.0
- 0.312
- 0.0
- 0.0
- 0.0
- 0.329
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.007
- 0.007
- 0.309
- 0.315
- 0.0
- 0.0
- 0.0
- 0.029
- 0.0
- 0.01
- 0.0
- 0.017
- 0.0
- 0.0
train_loss:
- 1.699
- 1.221
- 2.025
- 1.946
- 2.149
- 2.109
- 1.958
- 1.312
- 1.494
- 1.305
- 1.47
- 1.111
- 1.304
- 1.343
- 1.323
- 0.962
- 0.981
- 1.127
- 0.951
- 0.933
- 1.004
- 0.834
- 1.15
- 0.892
- 0.812
- 0.788
- 0.93
- 0.984
- 0.762
- 0.834
- 0.783
- 0.812
- 0.883
- 0.732
- 0.821
- 0.722
- 0.7
- 0.62
- 0.649
- 0.681
- 0.606
- 0.659
- 0.574
- 0.648
- 0.542
- 0.635
- 0.63
- 0.64
- 0.509
- 0.509
- 0.45
- 0.545
- 0.526
- 0.534
- 0.501
- 0.496
- 0.576
- 0.44
- 0.51
- 0.437
- 0.446
- 0.441
- 0.424
- 0.407
- 0.481
- 0.41
- 0.443
- 0.439
- 0.462
- 0.484
- 0.369
- 0.385
- 0.341
- 0.397
- 0.407
- 0.318
- 0.35
- 0.364
- 0.304
- 0.356
- 0.317
- 0.393
- 0.421
- 0.284
- 0.353
- 0.412
- 0.381
- 0.392
- 0.34
- 0.299
- 0.348
- 0.374
- 0.368
- 0.308
- 0.334
- 0.27
- 0.319
- 0.307
- 0.339
- 0.27
unequal: 0
verbose: 1
