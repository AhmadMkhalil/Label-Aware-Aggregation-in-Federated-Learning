avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0388
- 0.0829
- 0.0544
- 0.0401
- 0.1039
- 0.1259
- 0.1389
- 0.1523
- 0.1412
- 0.1652
- 0.1761
- 0.1767
- 0.176
- 0.1862
- 0.1754
- 0.1776
- 0.1924
- 0.194
- 0.1896
- 0.2045
- 0.1943
- 0.1933
- 0.207
- 0.1961
- 0.2107
- 0.2172
- 0.2093
- 0.2021
- 0.2192
- 0.2104
- 0.2125
- 0.224
- 0.2079
- 0.2213
- 0.233
- 0.2314
- 0.2239
- 0.2293
- 0.2231
- 0.2218
- 0.2194
- 0.232
- 0.2376
- 0.2266
- 0.2323
- 0.2419
- 0.2222
- 0.2423
- 0.2405
- 0.2303
- 0.2333
- 0.2416
- 0.2314
- 0.241
- 0.2475
- 0.2342
- 0.2523
- 0.2364
- 0.242
- 0.2381
- 0.2481
- 0.2532
- 0.2489
- 0.247
- 0.2486
- 0.2492
- 0.2537
- 0.2508
- 0.2445
- 0.2428
- 0.2508
- 0.248
- 0.2562
- 0.2567
- 0.2535
- 0.2461
- 0.2529
- 0.2472
- 0.2564
- 0.2469
- 0.254
- 0.2485
- 0.251
- 0.2463
- 0.2544
- 0.2489
- 0.243
- 0.2346
- 0.2617
- 0.2474
- 0.2511
- 0.2558
- 0.2573
- 0.2591
- 0.2519
- 0.2594
- 0.2492
- 0.2459
- 0.2558
- 0.2568
test_loss_list:
- 1.846888632774353
- 1.841885848045349
- 1.8269404649734498
- 2.0001199865341186
- 1.7371379852294921
- 1.7457049465179444
- 1.739826912879944
- 1.751950318813324
- 1.7646199560165405
- 1.7416276383399962
- 1.7467241430282592
- 1.7591063499450683
- 1.7593617033958435
- 1.7390257143974304
- 1.7551059222221375
- 1.5591296172142028
- 1.6075902271270752
- 1.6387185430526734
- 1.6577866315841674
- 1.6341645288467408
- 1.6692563962936402
- 1.6829123425483703
- 1.6537266945838929
- 1.6753872275352477
- 1.6447155261039734
- 1.661455671787262
- 1.6680803442001342
- 1.6883594942092897
- 1.6480991220474244
- 1.667734751701355
- 1.6567524552345276
- 1.635171320438385
- 1.6779040503501892
- 1.6531163763999939
- 1.6319936561584472
- 1.6356830310821533
- 1.6501284122467041
- 1.6292117595672608
- 1.6390768194198608
- 1.6310228872299195
- 1.6426341009140015
- 1.6219100904464723
- 1.6324974846839906
- 1.6418693137168885
- 1.6294834566116334
- 1.6209081602096558
- 1.6595442128181457
- 1.6257288098335265
- 1.6230832862854003
- 1.6393085408210755
- 1.628537006378174
- 1.620869448184967
- 1.6345646262168885
- 1.6316942501068115
- 1.639860498905182
- 1.665126543045044
- 1.638475432395935
- 1.6495315885543824
- 1.6448625278472901
- 1.6259569835662842
- 1.610293879508972
- 1.632824685573578
- 1.6363772892951964
- 1.635467517375946
- 1.6325387811660768
- 1.640680844783783
- 1.631172547340393
- 1.6367043113708497
- 1.6499363040924073
- 1.6431273460388183
- 1.618637411594391
- 1.626970181465149
- 1.617059895992279
- 1.6136790752410888
- 1.6432030248641967
- 1.6355871057510376
- 1.635486936569214
- 1.6226405930519103
- 1.6269964790344238
- 1.468246021270752
- 1.5073781037330627
- 1.5561837339401245
- 1.567536668777466
- 1.5660936975479125
- 1.561119966506958
- 1.5752125024795531
- 1.5916570496559144
- 1.4670481872558594
- 1.4719280123710632
- 1.507998797893524
- 1.510945417881012
- 1.5335185956954955
- 1.549959044456482
- 1.5566113162040711
- 1.5570379281044007
- 1.5514514565467834
- 1.5636346602439881
- 1.577807879447937
- 1.5548027324676514
- 1.564838330745697
train_accuracy:
- 0.0
- 0.116
- 0.0
- 0.0
- 0.0
- 0.175
- 0.0
- 0.201
- 0.183
- 0.229
- 0.258
- 0.215
- 0.0
- 0.228
- 0.0
- 0.0
- 0.229
- 0.285
- 0.0
- 0.241
- 0.0
- 0.254
- 0.0
- 0.0
- 0.245
- 0.246
- 0.0
- 0.256
- 0.255
- 0.0
- 0.0
- 0.28
- 0.241
- 0.272
- 0.258
- 0.33
- 0.264
- 0.299
- 0.0
- 0.0
- 0.0
- 0.343
- 0.294
- 0.0
- 0.0
- 0.353
- 0.0
- 0.309
- 0.323
- 0.0
- 0.0
- 0.0
- 0.308
- 0.322
- 0.33
- 0.0
- 0.369
- 0.0
- 0.317
- 0.0
- 0.369
- 0.374
- 0.307
- 0.383
- 0.374
- 0.305
- 0.339
- 0.338
- 0.28
- 0.272
- 0.0
- 0.0
- 0.279
- 0.324
- 0.269
- 0.0
- 0.377
- 0.252
- 0.376
- 0.0
- 0.0
- 0.0
- 0.386
- 0.0
- 0.282
- 0.0
- 0.0
- 0.0
- 0.398
- 0.312
- 0.365
- 0.387
- 0.311
- 0.361
- 0.357
- 0.0
- 0.332
- 0.329
- 0.33
- 0.0
train_loss:
- 2.029
- 1.82
- 1.116
- 0.974
- 1.646
- 3.125
- 2.393
- 2.8
- 1.526
- 2.214
- 2.648
- 2.448
- 1.497
- 1.965
- 1.287
- 0.92
- 1.787
- 1.564
- 1.347
- 1.65
- 1.069
- 1.038
- 1.549
- 0.845
- 1.622
- 1.557
- 1.171
- 1.019
- 1.489
- 0.936
- 1.248
- 1.262
- 0.909
- 1.101
- 1.301
- 1.036
- 0.897
- 1.156
- 0.837
- 0.979
- 0.84
- 0.987
- 0.909
- 0.863
- 0.794
- 0.853
- 0.819
- 0.864
- 0.827
- 0.676
- 0.653
- 0.732
- 0.667
- 0.554
- 0.702
- 0.694
- 0.642
- 0.534
- 0.549
- 0.846
- 0.737
- 0.56
- 0.569
- 0.545
- 0.584
- 0.574
- 0.488
- 0.494
- 0.418
- 0.608
- 0.55
- 0.549
- 0.504
- 0.38
- 0.322
- 0.601
- 0.356
- 0.506
- 0.336
- 0.573
- 0.314
- 0.517
- 0.359
- 0.428
- 0.336
- 0.382
- 0.468
- 0.632
- 0.297
- 0.401
- 0.417
- 0.256
- 0.315
- 0.261
- 0.37
- 0.303
- 0.479
- 0.398
- 0.264
- 0.282
unequal: 0
verbose: 1
