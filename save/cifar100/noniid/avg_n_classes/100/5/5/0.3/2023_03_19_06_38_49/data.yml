avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0356
- 0.0863
- 0.097
- 0.1081
- 0.1233
- 0.1175
- 0.1262
- 0.1332
- 0.1451
- 0.1419
- 0.1325
- 0.1459
- 0.1647
- 0.1702
- 0.1699
- 0.1733
- 0.1737
- 0.1901
- 0.1919
- 0.1925
- 0.1792
- 0.1854
- 0.2014
- 0.2026
- 0.2054
- 0.2139
- 0.2089
- 0.2076
- 0.1974
- 0.2169
- 0.2178
- 0.2205
- 0.2229
- 0.2122
- 0.2247
- 0.2165
- 0.2263
- 0.2127
- 0.2113
- 0.2237
- 0.2181
- 0.2163
- 0.2254
- 0.2359
- 0.236
- 0.2283
- 0.2265
- 0.2285
- 0.2292
- 0.2372
- 0.2222
- 0.2339
- 0.2081
- 0.2416
- 0.2447
- 0.2337
- 0.2405
- 0.244
- 0.2435
- 0.2436
- 0.2374
- 0.2466
- 0.241
- 0.2473
- 0.2209
- 0.2449
- 0.232
- 0.2435
- 0.2432
- 0.2493
- 0.2498
- 0.2482
- 0.252
- 0.2458
- 0.2389
- 0.2442
- 0.2438
- 0.2434
- 0.2481
- 0.2513
- 0.2391
- 0.2527
- 0.2481
- 0.2398
- 0.2495
- 0.252
- 0.2502
- 0.2427
- 0.2399
- 0.2469
- 0.2514
- 0.2582
- 0.253
- 0.2488
- 0.2541
- 0.2442
- 0.2528
- 0.2532
- 0.2487
- 0.2524
test_loss_list:
- 1.8649505853652955
- 1.8261668920516967
- 1.8295115184783937
- 1.8237727737426759
- 1.800610432624817
- 1.6724036312103272
- 1.711910798549652
- 1.7335027694702148
- 1.7185366559028625
- 1.7388082575798034
- 1.6483682942390443
- 1.6678551936149597
- 1.6723728036880494
- 1.675829291343689
- 1.6944159388542175
- 1.694835295677185
- 1.6830908751487732
- 1.6613028025627137
- 1.6728059482574462
- 1.667119300365448
- 1.5481129550933839
- 1.6018224000930785
- 1.6053886365890504
- 1.6199182343482972
- 1.6306011533737184
- 1.6253938889503479
- 1.6543345189094543
- 1.65644428730011
- 1.6758787894248963
- 1.6409472084045411
- 1.6377662849426269
- 1.6431490468978882
- 1.640108597278595
- 1.6492647671699523
- 1.6237452292442323
- 1.6449611163139344
- 1.6318166041374207
- 1.6394217205047608
- 1.658262424468994
- 1.6173299860954284
- 1.6316339516639708
- 1.6248230743408203
- 1.622331929206848
- 1.609494400024414
- 1.606130404472351
- 1.621226761341095
- 1.6099945735931396
- 1.6169766306877136
- 1.6030936455726623
- 1.599735405445099
- 1.4974570345878602
- 1.5137171268463134
- 1.4705633950233459
- 1.4556322240829467
- 1.508618838787079
- 1.5468084120750427
- 1.5361503052711487
- 1.5521745538711549
- 1.5783160734176636
- 1.5806452107429505
- 1.595407910346985
- 1.5840288138389587
- 1.4039926314353943
- 1.4882485103607177
- 1.4880151391029357
- 1.4506356120109558
- 1.5241873288154602
- 1.5236968684196472
- 1.5410391402244568
- 1.5569843339920044
- 1.5620415091514588
- 1.5548591256141662
- 1.5800276732444762
- 1.5855359864234924
- 1.5842234206199646
- 1.574383897781372
- 1.5598931980133057
- 1.5564535784721374
- 1.558303415775299
- 1.590327138900757
- 1.6094295978546143
- 1.5776872444152832
- 1.5716496372222901
- 1.5817159223556518
- 1.5668971562385559
- 1.5651726126670837
- 1.5670823979377746
- 1.5857537913322448
- 1.5944097185134887
- 1.56192129611969
- 1.5473979544639587
- 1.5585687804222106
- 1.5962750172615052
- 1.60010507106781
- 1.5737751388549805
- 1.5808999848365783
- 1.5716979598999024
- 1.5559253668785096
- 1.5635618042945862
- 1.5632202219963074
train_accuracy:
- 0.045
- 0.121
- 0.101
- 0.0
- 0.154
- 0.0
- 0.183
- 0.0
- 0.0
- 0.0
- 0.041
- 0.179
- 0.192
- 0.206
- 0.208
- 0.0
- 0.0
- 0.247
- 0.0
- 0.0
- 0.0
- 0.216
- 0.242
- 0.251
- 0.0
- 0.254
- 0.245
- 0.268
- 0.0
- 0.274
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.226
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.274
- 0.318
- 0.288
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.324
- 0.303
- 0.0
- 0.315
- 0.291
- 0.355
- 0.311
- 0.0
- 0.322
- 0.066
- 0.311
- 0.0
- 0.0
- 0.321
- 0.361
- 0.343
- 0.298
- 0.333
- 0.301
- 0.305
- 0.0
- 0.283
- 0.347
- 0.0
- 0.0
- 0.299
- 0.301
- 0.0
- 0.0
- 0.277
- 0.273
- 0.338
- 0.312
- 0.295
- 0.0
- 0.0
- 0.0
- 0.0
- 0.29
- 0.314
- 0.0
- 0.297
- 0.0
- 0.0
- 0.0
- 0.286
- 0.0
train_loss:
- 3.238
- 2.849
- 1.835
- 1.909
- 1.96
- 1.137
- 1.713
- 1.613
- 1.489
- 1.456
- 0.94
- 1.346
- 1.911
- 1.975
- 1.5
- 1.332
- 1.311
- 1.939
- 1.502
- 1.357
- 0.793
- 0.986
- 1.637
- 1.17
- 1.282
- 1.539
- 1.219
- 1.195
- 1.119
- 1.168
- 1.24
- 1.39
- 1.119
- 0.954
- 1.14
- 0.896
- 1.206
- 0.807
- 0.872
- 0.965
- 0.64
- 0.924
- 0.69
- 1.109
- 1.04
- 1.079
- 0.879
- 0.934
- 0.689
- 0.897
- 0.758
- 0.701
- 0.649
- 0.676
- 0.842
- 0.736
- 0.751
- 0.571
- 0.597
- 0.721
- 0.555
- 0.554
- 0.748
- 0.516
- 0.657
- 0.459
- 0.557
- 0.482
- 0.419
- 0.554
- 0.455
- 0.533
- 0.545
- 0.577
- 0.621
- 0.603
- 0.458
- 0.433
- 0.573
- 0.362
- 0.495
- 0.538
- 0.383
- 0.38
- 0.407
- 0.528
- 0.353
- 0.466
- 0.441
- 0.529
- 0.498
- 0.314
- 0.272
- 0.447
- 0.303
- 0.412
- 0.423
- 0.523
- 0.34
- 0.262
unequal: 0
verbose: 1
