avg_train_accuracy: 0.002
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0401
- 0.0902
- 0.1013
- 0.1137
- 0.0976
- 0.1378
- 0.1378
- 0.1351
- 0.1464
- 0.1533
- 0.161
- 0.1609
- 0.1723
- 0.1757
- 0.1741
- 0.146
- 0.1744
- 0.1839
- 0.1727
- 0.1839
- 0.1852
- 0.1953
- 0.202
- 0.2054
- 0.2062
- 0.1941
- 0.2009
- 0.2051
- 0.209
- 0.2131
- 0.219
- 0.2178
- 0.2165
- 0.2186
- 0.2117
- 0.2199
- 0.2189
- 0.2303
- 0.2312
- 0.2294
- 0.2306
- 0.2361
- 0.2233
- 0.225
- 0.2303
- 0.2218
- 0.2294
- 0.2302
- 0.2239
- 0.2336
- 0.2255
- 0.2386
- 0.2379
- 0.2288
- 0.2384
- 0.2281
- 0.2339
- 0.2439
- 0.242
- 0.2384
- 0.2346
- 0.2339
- 0.2455
- 0.245
- 0.2412
- 0.2484
- 0.2431
- 0.2455
- 0.2352
- 0.2345
- 0.2391
- 0.2492
- 0.2485
- 0.2381
- 0.249
- 0.2409
- 0.243
- 0.2427
- 0.2451
- 0.2327
- 0.2407
- 0.2446
- 0.2475
- 0.2448
- 0.2542
- 0.2416
- 0.2509
- 0.254
- 0.2544
- 0.2447
- 0.2441
- 0.2348
- 0.2415
- 0.2562
- 0.2466
- 0.258
- 0.2546
- 0.2539
- 0.2485
- 0.252
test_loss_list:
- 1.841896004676819
- 1.819467182159424
- 1.814321846961975
- 1.7987993812561036
- 1.6662728095054626
- 1.6974117803573607
- 1.7236103868484498
- 1.752261793613434
- 1.7260834622383117
- 1.7208819842338563
- 1.7190243887901306
- 1.7129917240142822
- 1.70175598859787
- 1.5602832293510438
- 1.6080799889564514
- 1.6350633335113525
- 1.5986917614936829
- 1.6153254723548889
- 1.5900608825683593
- 1.5863797497749328
- 1.625343542098999
- 1.6139851713180542
- 1.6271458959579468
- 1.64055428981781
- 1.6414585137367248
- 1.6785531449317932
- 1.6455268859863281
- 1.6276161289215088
- 1.6234323000907898
- 1.6120682048797608
- 1.608818266391754
- 1.6155613088607788
- 1.4242121410369872
- 1.4974646806716918
- 1.5481701612472534
- 1.5550434827804565
- 1.5572549104690552
- 1.5774135780334473
- 1.600362582206726
- 1.6081696963310241
- 1.6022123861312867
- 1.6157260942459106
- 1.6192940616607665
- 1.6032695603370666
- 1.5950020599365233
- 1.6204173398017883
- 1.5972005367279052
- 1.5920196557044983
- 1.6241388034820556
- 1.5972481966018677
- 1.6203855323791503
- 1.5801134395599366
- 1.5786728477478027
- 1.615884952545166
- 1.5950726127624513
- 1.585206868648529
- 1.5859161686897278
- 1.6086768555641173
- 1.6034472155570985
- 1.605133638381958
- 1.592775626182556
- 1.5965261960029602
- 1.575159695148468
- 1.5805249214172363
- 1.5866273832321167
- 1.4212962627410888
- 1.4833574271202088
- 1.5231568169593812
- 1.551712417602539
- 1.5628466391563416
- 1.5323427295684815
- 1.5328971791267394
- 1.5637516355514527
- 1.55717853307724
- 1.5556955170631408
- 1.5752217555046082
- 1.5599214339256287
- 1.5568721032142638
- 1.5466491532325746
- 1.4522450160980225
- 1.4439613342285156
- 1.4878588271141053
- 1.475842730998993
- 1.500189528465271
- 1.5185666298866272
- 1.523989164829254
- 1.5254353475570679
- 1.5310940170288085
- 1.5418099164962769
- 1.5508656477928162
- 1.5289824271202088
- 1.4475193691253663
- 1.4612436032295226
- 1.499008939266205
- 1.4965414643287658
- 1.517043981552124
- 1.5296715092658997
- 1.530961923599243
- 1.5207143545150756
- 1.497239155769348
train_accuracy:
- 0.0
- 0.123
- 0.0
- 0.144
- 0.013
- 0.18
- 0.0
- 0.213
- 0.201
- 0.0
- 0.235
- 0.21
- 0.233
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.256
- 0.255
- 0.0
- 0.273
- 0.267
- 0.273
- 0.0
- 0.273
- 0.0
- 0.258
- 0.273
- 0.0
- 0.262
- 0.0
- 0.298
- 0.283
- 0.306
- 0.268
- 0.319
- 0.316
- 0.293
- 0.286
- 0.318
- 0.0
- 0.267
- 0.0
- 0.0
- 0.308
- 0.31
- 0.0
- 0.319
- 0.307
- 0.322
- 0.292
- 0.0
- 0.0
- 0.0
- 0.332
- 0.342
- 0.0
- 0.0
- 0.324
- 0.321
- 0.332
- 0.293
- 0.0
- 0.138
- 0.327
- 0.334
- 0.0
- 0.314
- 0.0
- 0.0
- 0.34
- 0.315
- 0.0
- 0.0
- 0.331
- 0.321
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.316
- 0.323
- 0.0
- 0.343
- 0.0
- 0.0
- 0.0
- 0.0
- 0.009
- 0.347
- 0.0
- 0.358
- 0.336
- 0.0
- 0.0
- 0.002
train_loss:
- 3.088
- 2.715
- 1.881
- 1.828
- 1.139
- 3.078
- 2.106
- 1.502
- 1.574
- 1.62
- 1.911
- 1.583
- 2.021
- 0.935
- 1.397
- 0.742
- 1.071
- 1.737
- 0.689
- 1.12
- 1.076
- 1.586
- 1.654
- 1.394
- 1.557
- 1.141
- 1.181
- 1.0
- 1.1
- 1.107
- 1.277
- 1.177
- 0.874
- 1.218
- 0.941
- 1.019
- 0.919
- 1.299
- 1.171
- 0.872
- 1.252
- 1.121
- 0.736
- 0.9
- 0.849
- 0.868
- 0.73
- 0.861
- 0.772
- 0.743
- 0.636
- 0.853
- 0.844
- 0.668
- 0.702
- 0.843
- 0.653
- 0.638
- 0.683
- 0.699
- 0.582
- 0.664
- 0.604
- 0.523
- 0.536
- 0.634
- 0.584
- 0.621
- 0.59
- 0.471
- 0.56
- 0.496
- 0.397
- 0.542
- 0.497
- 0.53
- 0.35
- 0.603
- 0.359
- 0.562
- 0.463
- 0.416
- 0.347
- 0.419
- 0.404
- 0.497
- 0.358
- 0.422
- 0.389
- 0.396
- 0.449
- 0.551
- 0.377
- 0.318
- 0.371
- 0.293
- 0.292
- 0.386
- 0.435
- 0.388
unequal: 0
verbose: 1
