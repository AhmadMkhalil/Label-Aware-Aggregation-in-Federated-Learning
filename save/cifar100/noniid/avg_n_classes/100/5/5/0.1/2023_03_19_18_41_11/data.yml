avg_train_accuracy: 0.301
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0231
- 0.0602
- 0.027
- 0.0298
- 0.028
- 0.092
- 0.1051
- 0.1193
- 0.0361
- 0.0358
- 0.1307
- 0.0391
- 0.1402
- 0.1484
- 0.1503
- 0.1538
- 0.1592
- 0.0263
- 0.1569
- 0.1667
- 0.1782
- 0.0282
- 0.0293
- 0.1739
- 0.1821
- 0.0329
- 0.1762
- 0.0307
- 0.039
- 0.1756
- 0.1833
- 0.031
- 0.0315
- 0.183
- 0.0326
- 0.1954
- 0.0396
- 0.2009
- 0.0335
- 0.1975
- 0.0314
- 0.2003
- 0.0315
- 0.0411
- 0.2002
- 0.0404
- 0.0323
- 0.0321
- 0.0403
- 0.2001
- 0.0345
- 0.2023
- 0.2106
- 0.2104
- 0.2149
- 0.0337
- 0.2108
- 0.0338
- 0.0411
- 0.2156
- 0.0421
- 0.216
- 0.0433
- 0.2101
- 0.2123
- 0.0371
- 0.0356
- 0.2151
- 0.0437
- 0.2286
- 0.0465
- 0.0437
- 0.0369
- 0.2313
- 0.2323
- 0.0375
- 0.0363
- 0.0372
- 0.2275
- 0.2228
- 0.0351
- 0.0355
- 0.2233
- 0.037
- 0.2275
- 0.2223
- 0.2269
- 0.0423
- 0.2325
- 0.0448
- 0.2368
- 0.0355
- 0.2297
- 0.2316
- 0.0456
- 0.2343
- 0.2387
- 0.0378
- 0.229
- 0.2317
test_loss_list:
- 3.1150073623657226
- 1.8812305736541748
- 3.7877645301818847
- 3.800217561721802
- 3.8976698207855223
- 1.8285754203796387
- 1.8412791728973388
- 1.8560016679763793
- 3.498208589553833
- 3.82562123298645
- 1.7843009328842163
- 3.5037881088256837
- 1.792295174598694
- 1.8023167490959167
- 1.8320993852615357
- 1.8551828384399414
- 1.8553439664840699
- 3.9021731662750243
- 1.799824526309967
- 1.8259323716163636
- 1.8275736618041991
- 3.811105823516846
- 3.8769159603118895
- 1.7489918756484986
- 1.7423962116241456
- 3.624412794113159
- 1.7164158868789672
- 3.660738220214844
- 3.3728588247299194
- 1.6696954727172852
- 1.7043939518928528
- 3.703694667816162
- 3.5392010593414307
- 1.661251850128174
- 3.5191957902908326
- 1.6244409704208373
- 3.2975874376296996
- 1.603811354637146
- 3.4308088207244873
- 1.6121807026863098
- 3.5980742931365968
- 1.631453926563263
- 3.4481714153289795
- 3.2849915075302123
- 1.6003704857826233
- 3.1905977439880373
- 3.486462421417236
- 3.6965321636199953
- 3.312424063682556
- 1.5646682238578797
- 3.3646565294265747
- 1.5777630305290222
- 1.6160490560531615
- 1.6295614886283873
- 1.642291841506958
- 3.4556327724456786
- 1.614045214653015
- 3.3362040233612063
- 3.113552937507629
- 1.5539753031730652
- 3.2195821523666384
- 1.5815319848060607
- 3.1220955514907835
- 1.6162547278404236
- 1.625532350540161
- 3.4040440130233764
- 3.5999269771575926
- 1.6156077837944032
- 3.198546061515808
- 1.58378342628479
- 3.090685715675354
- 3.3998504495620727
- 3.348211336135864
- 1.5723584270477295
- 1.584818720817566
- 3.286294546127319
- 3.4972435283660888
- 3.3487909173965456
- 1.5373534774780273
- 1.5939392161369323
- 3.2404723882675173
- 3.2467429733276365
- 1.5564683699607849
- 3.198368730545044
- 1.5625802636146546
- 1.610744261741638
- 1.6262374234199524
- 3.168309226036072
- 1.5939991569519043
- 3.1688022375106812
- 1.5908392429351808
- 3.2609987592697145
- 1.5431956338882447
- 1.587192463874817
- 3.0910720300674437
- 1.5735775184631349
- 1.577554793357849
- 3.249615430831909
- 1.5995679926872253
- 1.6074685859680176
train_accuracy:
- 0.0
- 0.071
- 0.0
- 0.0
- 0.0
- 0.112
- 0.129
- 0.153
- 0.647
- 0.554
- 0.182
- 0.742
- 0.187
- 0.223
- 0.184
- 0.184
- 0.176
- 0.0
- 0.217
- 0.199
- 0.212
- 0.0
- 0.0
- 0.162
- 0.263
- 0.0
- 0.26
- 0.0
- 0.64
- 0.234
- 0.249
- 0.0
- 0.0
- 0.234
- 0.0
- 0.215
- 0.628
- 0.311
- 0.0
- 0.291
- 0.0
- 0.26
- 0.0
- 0.701
- 0.271
- 0.697
- 0.0
- 0.0
- 0.727
- 0.27
- 0.0
- 0.28
- 0.231
- 0.27
- 0.267
- 0.0
- 0.287
- 0.0
- 0.626
- 0.285
- 0.667
- 0.3
- 0.701
- 0.309
- 0.261
- 0.0
- 0.0
- 0.268
- 0.737
- 0.233
- 0.696
- 0.737
- 0.0
- 0.301
- 0.322
- 0.0
- 0.0
- 0.0
- 0.329
- 0.307
- 0.0
- 0.0
- 0.292
- 0.0
- 0.312
- 0.298
- 0.256
- 0.0
- 0.315
- 0.0
- 0.337
- 0.0
- 0.343
- 0.295
- 0.0
- 0.321
- 0.329
- 0.0
- 0.323
- 0.301
train_loss:
- 1.257
- 4.405
- 1.052
- 1.341
- 1.439
- 3.99
- 3.366
- 3.156
- 1.261
- 0.54
- 3.422
- 0.718
- 3.196
- 2.681
- 2.569
- 2.181
- 2.64
- 1.08
- 2.652
- 2.071
- 2.271
- 0.83
- 1.437
- 2.268
- 2.781
- 1.038
- 2.491
- 0.764
- 1.048
- 2.211
- 2.482
- 0.859
- 0.848
- 2.062
- 0.997
- 2.154
- 0.711
- 2.311
- 0.667
- 1.928
- 0.701
- 2.163
- 0.644
- 0.754
- 1.716
- 0.418
- 0.711
- 0.235
- 0.453
- 1.764
- 0.608
- 1.393
- 1.62
- 2.108
- 1.093
- 0.859
- 1.706
- 0.515
- 0.647
- 1.9
- 0.344
- 1.449
- 0.302
- 1.179
- 1.819
- 0.671
- 0.257
- 1.6
- 0.37
- 1.601
- 0.258
- 0.063
- 0.617
- 1.496
- 1.131
- 0.624
- 0.164
- 0.628
- 1.049
- 0.601
- 0.517
- 0.526
- 1.284
- 0.328
- 1.553
- 0.942
- 1.214
- 0.407
- 1.1
- 0.28
- 1.312
- 0.692
- 0.966
- 0.962
- 0.323
- 0.922
- 0.616
- 0.477
- 1.107
- 0.827
unequal: 0
verbose: 1
