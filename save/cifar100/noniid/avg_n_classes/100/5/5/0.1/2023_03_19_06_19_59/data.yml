avg_train_accuracy: 0.702
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0422
- 0.0351
- 0.0837
- 0.0281
- 0.0984
- 0.1041
- 0.0271
- 0.1223
- 0.1319
- 0.1361
- 0.1347
- 0.1403
- 0.0286
- 0.1381
- 0.0327
- 0.1461
- 0.1479
- 0.0343
- 0.1489
- 0.1643
- 0.0308
- 0.0299
- 0.1671
- 0.1645
- 0.0362
- 0.1729
- 0.0317
- 0.0328
- 0.1828
- 0.1877
- 0.0322
- 0.034
- 0.0275
- 0.1912
- 0.1929
- 0.0376
- 0.1861
- 0.1938
- 0.0288
- 0.1991
- 0.0373
- 0.0389
- 0.0279
- 0.2027
- 0.0305
- 0.0357
- 0.0353
- 0.0383
- 0.2022
- 0.1918
- 0.2052
- 0.0406
- 0.2042
- 0.2032
- 0.0335
- 0.0398
- 0.0385
- 0.0318
- 0.0384
- 0.0348
- 0.2023
- 0.044
- 0.2048
- 0.0409
- 0.0403
- 0.0401
- 0.2153
- 0.0431
- 0.0399
- 0.2154
- 0.2214
- 0.0427
- 0.217
- 0.0304
- 0.2203
- 0.2196
- 0.2198
- 0.2245
- 0.2161
- 0.2206
- 0.2103
- 0.0423
- 0.2338
- 0.0316
- 0.2258
- 0.0444
- 0.0419
- 0.2334
- 0.2308
- 0.2404
- 0.23
- 0.2369
- 0.2326
- 0.2357
- 0.2277
- 0.0484
- 0.0423
- 0.0449
- 0.0353
- 0.0423
test_loss_list:
- 1.8628590202331543
- 3.4402457809448244
- 1.8750221729278564
- 3.9417625713348388
- 1.8684406852722169
- 1.8931760501861572
- 3.8586012268066407
- 1.8431032514572143
- 1.867774519920349
- 1.8905954360961914
- 1.897261152267456
- 1.920396227836609
- 4.015203933715821
- 1.8866085624694824
- 3.778943281173706
- 1.8076487541198731
- 1.8572930002212524
- 3.5617686462402345
- 1.7915224456787109
- 1.7776778531074524
- 3.8522111892700197
- 4.083261709213257
- 1.748784999847412
- 1.789402232170105
- 3.5337578868865966
- 1.7344603204727174
- 3.709969816207886
- 3.620240640640259
- 1.6906875252723694
- 1.7201386642456056
- 3.656538152694702
- 3.5830969047546386
- 3.6352380466461183
- 1.638782651424408
- 1.6758068704605102
- 3.411085858345032
- 1.6755424976348876
- 1.6876850843429565
- 3.6085970878601072
- 1.6783884525299073
- 3.4094960737228392
- 3.3084515142440796
- 3.624430456161499
- 1.596696116924286
- 3.4659933376312257
- 3.365829267501831
- 3.52703595161438
- 3.328024635314941
- 1.6019363474845887
- 1.6586195373535155
- 1.6667640566825868
- 3.277938289642334
- 1.6785631632804872
- 1.7032180047035217
- 3.5437041759490966
- 3.267036828994751
- 3.4858672523498537
- 3.625478982925415
- 3.187156038284302
- 3.3259296941757204
- 1.5279514050483705
- 3.0261199045181275
- 1.5857758903503418
- 3.1007697105407717
- 3.2218123722076415
- 3.249873571395874
- 1.5209186220169066
- 3.026989517211914
- 3.2516555261611937
- 1.5596633768081665
- 1.5804547691345214
- 3.0396792221069338
- 1.5696295738220214
- 3.375203194618225
- 1.567258882522583
- 1.5862614989280701
- 1.607669801712036
- 1.6391002893447877
- 1.6745283150672912
- 1.6378475904464722
- 1.693454349040985
- 3.1808210802078247
- 1.6020901584625244
- 3.3123090839385987
- 1.6036634945869446
- 3.0777298736572267
- 3.1124762678146363
- 1.5041542363166809
- 1.550946879386902
- 1.5689703369140624
- 1.6130290031433105
- 1.607102358341217
- 1.627774965763092
- 1.6276969337463378
- 1.6665164065361022
- 3.1221049451828002
- 3.1346425867080687
- 3.125213212966919
- 3.3605331945419312
- 3.0900477838516234
train_accuracy:
- 0.065
- 0.6
- 0.082
- 0.0
- 0.117
- 0.102
- 0.0
- 0.126
- 0.139
- 0.136
- 0.139
- 0.144
- 0.0
- 0.141
- 0.0
- 0.201
- 0.164
- 0.685
- 0.167
- 0.227
- 0.0
- 0.0
- 0.159
- 0.179
- 0.65
- 0.252
- 0.0
- 0.0
- 0.266
- 0.194
- 0.0
- 0.0
- 0.0
- 0.275
- 0.262
- 0.726
- 0.229
- 0.256
- 0.0
- 0.218
- 0.0
- 0.78
- 0.0
- 0.27
- 0.0
- 0.0
- 0.0
- 0.681
- 0.294
- 0.28
- 0.249
- 0.0
- 0.282
- 0.293
- 0.0
- 0.754
- 0.731
- 0.0
- 0.697
- 0.0
- 0.291
- 0.0
- 0.268
- 0.749
- 0.717
- 0.754
- 0.241
- 0.0
- 0.0
- 0.237
- 0.302
- 0.0
- 0.303
- 0.0
- 0.263
- 0.307
- 0.245
- 0.284
- 0.285
- 0.282
- 0.283
- 0.729
- 0.259
- 0.0
- 0.289
- 0.0
- 0.771
- 0.351
- 0.32
- 0.255
- 0.259
- 0.27
- 0.338
- 0.27
- 0.254
- 0.748
- 0.0
- 0.779
- 0.0
- 0.702
train_loss:
- 4.054
- 1.229
- 3.54
- 1.19
- 3.182
- 2.5
- 1.194
- 3.39
- 2.629
- 2.291
- 2.299
- 1.901
- 1.24
- 1.997
- 0.966
- 3.063
- 1.64
- 1.378
- 1.62
- 2.796
- 0.952
- 0.428
- 2.478
- 1.36
- 0.957
- 2.904
- 0.697
- 1.026
- 2.608
- 1.862
- 0.612
- 0.855
- 1.29
- 2.293
- 2.284
- 0.849
- 1.549
- 1.901
- 0.859
- 1.91
- 0.625
- 0.877
- 0.805
- 2.083
- 0.54
- 0.632
- 0.178
- 0.732
- 1.638
- 1.098
- 1.448
- 0.414
- 1.21
- 0.802
- 0.373
- 0.726
- 0.201
- 0.876
- 1.248
- 0.459
- 1.021
- 0.269
- 2.301
- 0.442
- 0.775
- 0.424
- 1.582
- 0.313
- 0.078
- 1.453
- 1.713
- 0.282
- 0.975
- 0.666
- 1.214
- 0.655
- 0.82
- 1.407
- 0.989
- 1.756
- 1.17
- 0.523
- 1.009
- 0.558
- 1.131
- 0.366
- 0.827
- 0.895
- 1.163
- 0.681
- 1.046
- 0.514
- 0.554
- 0.435
- 0.775
- 0.474
- 0.469
- 0.32
- 0.832
- 0.696
unequal: 0
verbose: 1
