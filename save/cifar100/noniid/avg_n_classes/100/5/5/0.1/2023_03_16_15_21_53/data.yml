avg_train_accuracy: 0.307
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0417
- 0.0272
- 0.0863
- 0.0293
- 0.101
- 0.118
- 0.1268
- 0.1327
- 0.146
- 0.1495
- 0.0284
- 0.1544
- 0.0312
- 0.1615
- 0.0312
- 0.1619
- 0.0333
- 0.029
- 0.0353
- 0.0349
- 0.0334
- 0.0322
- 0.0318
- 0.1593
- 0.0347
- 0.034
- 0.0329
- 0.0326
- 0.1619
- 0.1578
- 0.0349
- 0.0304
- 0.1608
- 0.1775
- 0.1781
- 0.0378
- 0.1787
- 0.0315
- 0.1908
- 0.1859
- 0.0333
- 0.0333
- 0.1842
- 0.0333
- 0.035
- 0.1897
- 0.0376
- 0.1937
- 0.1916
- 0.1888
- 0.0365
- 0.2006
- 0.2056
- 0.2018
- 0.2109
- 0.0404
- 0.2106
- 0.2102
- 0.2154
- 0.0393
- 0.2144
- 0.0341
- 0.2193
- 0.0373
- 0.2118
- 0.0424
- 0.0339
- 0.0352
- 0.0377
- 0.2215
- 0.2208
- 0.0435
- 0.2293
- 0.0389
- 0.2301
- 0.2243
- 0.037
- 0.2228
- 0.0454
- 0.039
- 0.0375
- 0.0399
- 0.0373
- 0.2293
- 0.2235
- 0.2182
- 0.0439
- 0.2211
- 0.0477
- 0.0432
- 0.2191
- 0.0395
- 0.0445
- 0.227
- 0.0474
- 0.2268
- 0.0478
- 0.2265
- 0.0535
- 0.2271
test_loss_list:
- 1.8786693143844604
- 3.64465784072876
- 1.8600682735443115
- 3.6586420249938967
- 1.8351567554473878
- 1.8398485231399535
- 1.8466967391967772
- 1.8549118804931641
- 1.8617419958114625
- 1.8699419832229613
- 3.849135675430298
- 1.8137989091873168
- 3.7651115036010743
- 1.7738216352462768
- 3.833878631591797
- 1.7517875242233276
- 3.467634038925171
- 3.734304656982422
- 3.554790725708008
- 3.739084548950195
- 3.9772210025787356
- 3.7174645709991454
- 3.902385940551758
- 1.6440387439727784
- 3.487294569015503
- 3.4606781673431395
- 3.3676206493377685
- 3.529561824798584
- 1.6073765850067139
- 1.6710870528221131
- 3.349296178817749
- 3.6526369667053222
- 1.6149509692192077
- 1.6568901419639588
- 1.6817618632316589
- 3.3853843784332276
- 1.6505150556564332
- 3.4867835903167723
- 1.6488458633422851
- 1.661346173286438
- 3.397916145324707
- 3.4902735805511473
- 1.6091435074806213
- 3.2953725337982176
- 3.4319732761383057
- 1.6222095036506652
- 3.2349703550338744
- 1.642739713191986
- 1.6503420901298522
- 1.6805312395095826
- 3.372612352371216
- 1.6565779852867126
- 1.666115972995758
- 1.6824417304992676
- 1.6865435791015626
- 3.242730555534363
- 1.6307058644294739
- 1.672629463672638
- 1.668541214466095
- 3.2834387397766114
- 1.6545678210258483
- 3.2575323963165284
- 1.56564284324646
- 3.2137904357910156
- 1.6053251886367799
- 3.22625271320343
- 3.3611829566955564
- 3.4820711612701416
- 3.1336485958099365
- 1.5225578451156616
- 1.5534187316894532
- 3.040206093788147
- 1.5322918009757995
- 3.064073362350464
- 1.5480567073822022
- 1.562086102962494
- 3.238195610046387
- 1.5537892508506774
- 2.99042067527771
- 3.0441441249847414
- 3.2471668100357056
- 3.2243536901474
- 3.4078043031692506
- 1.5219648790359497
- 1.5621285152435302
- 1.607707531452179
- 3.181517324447632
- 1.5591067361831665
- 2.976366720199585
- 3.1845953989028932
- 1.5723937106132508
- 3.1610417795181274
- 3.1653729915618896
- 1.5268501162528991
- 2.975151925086975
- 1.5425280594825745
- 3.0230100774765014
- 1.566749632358551
- 2.929105463027954
- 1.5601423740386964
train_accuracy:
- 0.061
- 0.135
- 0.092
- 0.446
- 0.12
- 0.122
- 0.126
- 0.15
- 0.141
- 0.17
- 0.0
- 0.209
- 0.0
- 0.156
- 0.0
- 0.154
- 0.523
- 0.0
- 0.635
- 0.0
- 0.0
- 0.0
- 0.0
- 0.158
- 0.0
- 0.536
- 0.414
- 0.0
- 0.166
- 0.154
- 0.64
- 0.0
- 0.189
- 0.223
- 0.202
- 0.687
- 0.218
- 0.0
- 0.229
- 0.222
- 0.0
- 0.0
- 0.224
- 0.0
- 0.0
- 0.239
- 0.0
- 0.23
- 0.25
- 0.233
- 0.0
- 0.287
- 0.235
- 0.278
- 0.263
- 0.649
- 0.23
- 0.278
- 0.282
- 0.0
- 0.3
- 0.352
- 0.274
- 0.552
- 0.286
- 0.657
- 0.0
- 0.0
- 0.0
- 0.304
- 0.244
- 0.0
- 0.278
- 0.559
- 0.328
- 0.284
- 0.0
- 0.306
- 0.0
- 0.459
- 0.47
- 0.0
- 0.0
- 0.332
- 0.294
- 0.282
- 0.758
- 0.297
- 0.0
- 0.0
- 0.294
- 0.0
- 0.695
- 0.258
- 0.704
- 0.315
- 0.708
- 0.326
- 0.0
- 0.307
train_loss:
- 4.163
- 1.499
- 3.662
- 1.466
- 3.296
- 3.337
- 2.714
- 3.087
- 2.394
- 2.847
- 1.31
- 3.217
- 1.124
- 2.528
- 0.981
- 2.22
- 1.236
- 1.168
- 0.947
- 0.843
- 0.29
- 1.044
- 0.349
- 2.197
- 0.466
- 0.902
- 1.528
- 0.763
- 1.923
- 1.327
- 0.663
- 0.964
- 3.115
- 2.453
- 1.943
- 0.688
- 2.529
- 0.759
- 1.983
- 1.979
- 0.681
- 0.781
- 1.863
- 0.447
- 0.594
- 1.87
- 0.369
- 1.431
- 1.524
- 1.114
- 0.409
- 2.512
- 1.55
- 1.746
- 1.228
- 0.752
- 1.401
- 1.292
- 2.125
- 0.463
- 1.806
- 1.16
- 1.345
- 0.726
- 1.954
- 0.597
- 0.706
- 0.146
- 0.531
- 1.586
- 1.134
- 0.324
- 1.104
- 0.723
- 1.301
- 0.77
- 0.409
- 1.688
- 0.317
- 0.752
- 0.261
- 0.346
- 0.06
- 1.177
- 1.167
- 0.794
- 0.589
- 0.833
- 0.29
- 0.035
- 0.65
- 0.399
- 0.541
- 1.211
- 0.316
- 0.702
- 0.279
- 1.076
- 0.253
- 0.604
unequal: 0
verbose: 1
