avg_train_accuracy: 0.307
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0475
- 0.1015
- 0.1175
- 0.1238
- 0.1366
- 0.1417
- 0.1545
- 0.1641
- 0.1688
- 0.1748
- 0.1803
- 0.1758
- 0.1871
- 0.1774
- 0.1872
- 0.1935
- 0.195
- 0.2019
- 0.2078
- 0.2082
- 0.2042
- 0.2055
- 0.212
- 0.2166
- 0.2041
- 0.22
- 0.2192
- 0.2201
- 0.2151
- 0.2236
- 0.2268
- 0.222
- 0.223
- 0.2274
- 0.2305
- 0.2342
- 0.236
- 0.2369
- 0.2364
- 0.2318
- 0.2352
- 0.2348
- 0.2404
- 0.2426
- 0.2411
- 0.2429
- 0.2408
- 0.2441
- 0.245
- 0.2456
- 0.2405
- 0.2416
- 0.2465
- 0.2506
- 0.2329
- 0.2504
- 0.2468
- 0.2444
- 0.2484
- 0.2521
- 0.2476
- 0.2463
- 0.2475
- 0.2495
- 0.2495
- 0.2528
- 0.2438
- 0.2494
- 0.2505
- 0.2509
- 0.2475
- 0.2572
- 0.2503
- 0.2512
- 0.2537
- 0.2536
- 0.2575
- 0.2471
- 0.2526
- 0.2561
- 0.2507
- 0.2542
- 0.2494
- 0.2556
- 0.2548
- 0.2547
- 0.2571
- 0.2505
- 0.2576
- 0.2571
- 0.2559
- 0.2579
- 0.2564
- 0.2546
- 0.2497
- 0.2583
- 0.2576
- 0.2562
- 0.2588
- 0.2558
test_loss_list:
- 1.8423567628860473
- 1.8004133081436158
- 1.792646336555481
- 1.7710947561264039
- 1.7727872467041015
- 1.7580558919906617
- 1.7290732765197754
- 1.7197457504272462
- 1.7151270079612733
- 1.6900884771347047
- 1.6892276811599731
- 1.6837690043449403
- 1.6719298219680787
- 1.6700383734703064
- 1.6421709585189819
- 1.6376254391670226
- 1.6322488117218017
- 1.6356217241287232
- 1.6125364303588867
- 1.6179841232299805
- 1.6172831058502197
- 1.6053960967063903
- 1.5862609910964967
- 1.6042248511314392
- 1.6060674500465393
- 1.5707127809524537
- 1.57651513338089
- 1.5770298051834106
- 1.581374807357788
- 1.5837917280197145
- 1.5799905848503113
- 1.5776480865478515
- 1.5594007778167724
- 1.5629133582115173
- 1.569258360862732
- 1.5601025462150573
- 1.5964691853523254
- 1.5790098333358764
- 1.5931041407585145
- 1.5751116681098938
- 1.564582953453064
- 1.5628260564804077
- 1.5576169776916504
- 1.5745236825942994
- 1.5591686797142028
- 1.5690249252319335
- 1.5520293235778808
- 1.5473949670791627
- 1.5519726419448852
- 1.547329227924347
- 1.5385149240493774
- 1.52476909160614
- 1.5170215129852296
- 1.5198479580879212
- 1.527500479221344
- 1.5273142814636231
- 1.5256082248687743
- 1.5218379306793213
- 1.5108190560340882
- 1.5123033547401428
- 1.5041711354255676
- 1.5023944973945618
- 1.5194803714752196
- 1.490498411655426
- 1.504117307662964
- 1.5061177182197572
- 1.5005174779891968
- 1.4884916138648987
- 1.5079188776016235
- 1.512876751422882
- 1.5063604140281677
- 1.520642352104187
- 1.5105647134780884
- 1.503823161125183
- 1.509854907989502
- 1.51006493806839
- 1.503273024559021
- 1.5032232117652893
- 1.5093063163757323
- 1.5010251808166504
- 1.5079607462882996
- 1.5229361128807068
- 1.5045971012115478
- 1.5123573327064515
- 1.5029155278205872
- 1.48249183177948
- 1.4996714162826539
- 1.4979128122329712
- 1.5129849886894227
- 1.5117352294921875
- 1.4966864943504334
- 1.506051104068756
- 1.4994427490234374
- 1.4940794038772582
- 1.4935135626792908
- 1.4763843083381654
- 1.4863168263435365
- 1.4874461841583253
- 1.4998693656921387
- 1.491341471672058
train_accuracy:
- 0.073
- 0.13
- 0.125
- 0.142
- 0.165
- 0.0
- 0.175
- 0.0
- 0.0
- 0.0
- 0.229
- 0.188
- 0.214
- 0.202
- 0.0
- 0.202
- 0.0
- 0.0
- 0.0
- 0.228
- 0.0
- 0.22
- 0.239
- 0.267
- 0.0
- 0.27
- 0.0
- 0.236
- 0.235
- 0.283
- 0.253
- 0.0
- 0.0
- 0.251
- 0.263
- 0.267
- 0.261
- 0.0
- 0.0
- 0.293
- 0.26
- 0.0
- 0.311
- 0.299
- 0.263
- 0.292
- 0.321
- 0.315
- 0.318
- 0.0
- 0.0
- 0.0
- 0.312
- 0.314
- 0.0
- 0.317
- 0.0
- 0.0
- 0.278
- 0.323
- 0.0
- 0.283
- 0.0
- 0.0
- 0.0
- 0.293
- 0.0
- 0.313
- 0.0
- 0.0
- 0.0
- 0.306
- 0.317
- 0.289
- 0.0
- 0.0
- 0.335
- 0.0
- 0.324
- 0.309
- 0.291
- 0.292
- 0.315
- 0.297
- 0.289
- 0.305
- 0.289
- 0.0
- 0.299
- 0.31
- 0.0
- 0.302
- 0.332
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.311
- 0.307
train_loss:
- 3.476
- 2.623
- 2.388
- 1.922
- 2.549
- 1.887
- 2.247
- 2.066
- 1.947
- 1.622
- 1.873
- 1.646
- 1.784
- 1.266
- 1.532
- 1.58
- 1.534
- 1.481
- 1.337
- 1.434
- 1.271
- 1.22
- 1.239
- 1.579
- 0.994
- 1.279
- 1.049
- 1.214
- 1.011
- 1.154
- 1.063
- 0.918
- 1.031
- 1.119
- 1.048
- 1.096
- 1.078
- 0.959
- 0.914
- 0.902
- 0.753
- 0.775
- 0.879
- 0.765
- 0.812
- 0.859
- 0.774
- 0.723
- 0.703
- 0.684
- 0.771
- 0.722
- 0.706
- 0.613
- 0.661
- 0.624
- 0.614
- 0.627
- 0.632
- 0.648
- 0.603
- 0.551
- 0.588
- 0.576
- 0.498
- 0.488
- 0.605
- 0.539
- 0.511
- 0.452
- 0.503
- 0.455
- 0.497
- 0.553
- 0.447
- 0.419
- 0.422
- 0.511
- 0.365
- 0.486
- 0.447
- 0.353
- 0.497
- 0.413
- 0.484
- 0.435
- 0.337
- 0.409
- 0.286
- 0.353
- 0.39
- 0.354
- 0.325
- 0.417
- 0.423
- 0.412
- 0.274
- 0.382
- 0.271
- 0.412
unequal: 0
verbose: 1
