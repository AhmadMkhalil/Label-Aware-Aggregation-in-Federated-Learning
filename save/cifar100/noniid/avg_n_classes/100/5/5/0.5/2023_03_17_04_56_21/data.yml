avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0445
- 0.089
- 0.1066
- 0.1189
- 0.1226
- 0.1415
- 0.1448
- 0.157
- 0.1588
- 0.165
- 0.1663
- 0.1735
- 0.1745
- 0.1814
- 0.1841
- 0.19
- 0.1918
- 0.1916
- 0.1932
- 0.1973
- 0.1955
- 0.1988
- 0.2062
- 0.1994
- 0.2099
- 0.2123
- 0.212
- 0.214
- 0.216
- 0.2172
- 0.2166
- 0.2218
- 0.2281
- 0.2244
- 0.2277
- 0.2208
- 0.2302
- 0.2272
- 0.2258
- 0.2272
- 0.2276
- 0.2314
- 0.2296
- 0.2164
- 0.2309
- 0.2241
- 0.2384
- 0.2306
- 0.2335
- 0.2357
- 0.2374
- 0.2396
- 0.236
- 0.2334
- 0.2413
- 0.2295
- 0.2316
- 0.2461
- 0.2471
- 0.2438
- 0.2467
- 0.2486
- 0.2481
- 0.2386
- 0.2399
- 0.2466
- 0.253
- 0.2411
- 0.2391
- 0.2496
- 0.2499
- 0.2593
- 0.2514
- 0.247
- 0.2506
- 0.249
- 0.2448
- 0.2486
- 0.2498
- 0.2545
- 0.2556
- 0.2535
- 0.2534
- 0.2441
- 0.2513
- 0.2411
- 0.2553
- 0.2559
- 0.253
- 0.2471
- 0.2538
- 0.2504
- 0.2594
- 0.2551
- 0.2573
- 0.2584
- 0.259
- 0.2592
- 0.2584
- 0.2581
test_loss_list:
- 1.824993805885315
- 1.7819248199462892
- 1.762945156097412
- 1.7438252830505372
- 1.7339863276481629
- 1.7190846395492554
- 1.7170717096328736
- 1.7051429677009582
- 1.6913228607177735
- 1.6855770635604859
- 1.6779427218437195
- 1.6715703797340393
- 1.6718736958503724
- 1.6443210029602051
- 1.6471172761917114
- 1.6628966617584229
- 1.6498935174942018
- 1.6509425616264344
- 1.6442730164527892
- 1.6507181000709534
- 1.6436258411407472
- 1.6329722023010254
- 1.6208510375022889
- 1.616144003868103
- 1.5915268182754516
- 1.5932217288017272
- 1.5963171577453614
- 1.5939888072013855
- 1.583512156009674
- 1.5859522676467896
- 1.5973929023742677
- 1.5759061670303345
- 1.5753061819076537
- 1.5881835556030273
- 1.5836329388618469
- 1.5850441431999207
- 1.5910544037818908
- 1.5686395502090453
- 1.5633756685256959
- 1.5544509196281433
- 1.5450241088867187
- 1.5516798329353332
- 1.5582931184768676
- 1.5690592432022095
- 1.549005446434021
- 1.5594474005699157
- 1.5603623008728027
- 1.5580395030975343
- 1.5469907784461976
- 1.54119637966156
- 1.5557468962669372
- 1.5348182392120362
- 1.5440479636192321
- 1.5346331596374512
- 1.525673544406891
- 1.5325376033782958
- 1.5345167160034179
- 1.5348075342178344
- 1.5429630208015441
- 1.5276124048233033
- 1.546780652999878
- 1.5418061351776122
- 1.5217871594429015
- 1.5342552828788758
- 1.5251387548446655
- 1.5006351161003113
- 1.5166142463684082
- 1.5163456892967224
- 1.5060253715515137
- 1.4948453974723817
- 1.5123220682144165
- 1.361675705909729
- 1.4136431288719178
- 1.4529300832748413
- 1.452104570865631
- 1.469031105041504
- 1.479532380104065
- 1.4658736348152162
- 1.4903889060020448
- 1.5008036136627196
- 1.5009732246398926
- 1.4966546058654786
- 1.5180035901069642
- 1.5073851180076598
- 1.4836260294914245
- 1.4828479528427123
- 1.465847852230072
- 1.4836708950996398
- 1.4840891075134277
- 1.4792988038063049
- 1.486226737499237
- 1.4781231689453125
- 1.4872961616516114
- 1.5133856177330016
- 1.4995850396156312
- 1.4935781955718994
- 1.4991515231132508
- 1.5013311362266542
- 1.5135940837860107
- 1.4849656510353089
train_accuracy:
- 0.047
- 0.13
- 0.0
- 0.0
- 0.0
- 0.195
- 0.0
- 0.214
- 0.0
- 0.0
- 0.0
- 0.259
- 0.0
- 0.0
- 0.0
- 0.272
- 0.26
- 0.23
- 0.0
- 0.245
- 0.0
- 0.286
- 0.296
- 0.0
- 0.316
- 0.274
- 0.295
- 0.314
- 0.0
- 0.323
- 0.311
- 0.0
- 0.0
- 0.0
- 0.327
- 0.0
- 0.0
- 0.293
- 0.311
- 0.0
- 0.346
- 0.0
- 0.285
- 0.0
- 0.347
- 0.316
- 0.355
- 0.0
- 0.346
- 0.34
- 0.345
- 0.0
- 0.0
- 0.0
- 0.337
- 0.0
- 0.0
- 0.338
- 0.353
- 0.355
- 0.335
- 0.337
- 0.345
- 0.0
- 0.0
- 0.0
- 0.337
- 0.0
- 0.0
- 0.318
- 0.368
- 0.007
- 0.365
- 0.334
- 0.0
- 0.0
- 0.349
- 0.362
- 0.351
- 0.361
- 0.0
- 0.36
- 0.337
- 0.342
- 0.0
- 0.001
- 0.327
- 0.337
- 0.0
- 0.001
- 0.0
- 0.362
- 0.355
- 0.362
- 0.346
- 0.368
- 0.0
- 0.0
- 0.361
- 0.0
train_loss:
- 2.927
- 2.062
- 1.953
- 1.983
- 1.427
- 2.141
- 2.066
- 2.137
- 1.68
- 1.813
- 1.583
- 1.725
- 1.205
- 1.498
- 1.61
- 1.771
- 1.349
- 1.432
- 1.245
- 1.563
- 1.086
- 1.34
- 1.485
- 0.959
- 1.488
- 1.343
- 1.058
- 1.117
- 0.966
- 1.056
- 0.939
- 1.007
- 1.082
- 1.048
- 1.006
- 0.834
- 1.049
- 0.885
- 0.783
- 0.939
- 0.796
- 0.801
- 0.723
- 0.668
- 0.673
- 0.646
- 0.844
- 0.617
- 0.628
- 0.727
- 0.678
- 0.626
- 0.526
- 0.541
- 0.72
- 0.567
- 0.558
- 0.634
- 0.609
- 0.597
- 0.58
- 0.634
- 0.542
- 0.517
- 0.595
- 0.558
- 0.489
- 0.459
- 0.517
- 0.468
- 0.456
- 0.527
- 0.347
- 0.439
- 0.497
- 0.369
- 0.422
- 0.37
- 0.388
- 0.401
- 0.384
- 0.413
- 0.379
- 0.446
- 0.406
- 0.422
- 0.415
- 0.322
- 0.335
- 0.415
- 0.298
- 0.345
- 0.314
- 0.238
- 0.345
- 0.309
- 0.348
- 0.328
- 0.311
- 0.355
unequal: 0
verbose: 1
