avg_train_accuracy: 0.325
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0438
- 0.0915
- 0.1122
- 0.1195
- 0.1359
- 0.1444
- 0.1501
- 0.1512
- 0.1656
- 0.1696
- 0.1775
- 0.1814
- 0.1873
- 0.1865
- 0.1899
- 0.1914
- 0.195
- 0.1991
- 0.2052
- 0.2046
- 0.2066
- 0.2083
- 0.2135
- 0.2159
- 0.2178
- 0.2123
- 0.2172
- 0.2202
- 0.2232
- 0.2258
- 0.2252
- 0.2245
- 0.2266
- 0.2322
- 0.2309
- 0.2273
- 0.2302
- 0.2267
- 0.2383
- 0.2336
- 0.2299
- 0.2362
- 0.2268
- 0.2388
- 0.2378
- 0.2396
- 0.2416
- 0.239
- 0.2406
- 0.2389
- 0.2437
- 0.2447
- 0.2428
- 0.2453
- 0.248
- 0.2432
- 0.249
- 0.2434
- 0.2449
- 0.2496
- 0.2467
- 0.2487
- 0.2517
- 0.2494
- 0.2511
- 0.2495
- 0.2509
- 0.2498
- 0.2523
- 0.2499
- 0.2435
- 0.2499
- 0.2508
- 0.256
- 0.256
- 0.2554
- 0.2442
- 0.2512
- 0.2517
- 0.2558
- 0.2544
- 0.2559
- 0.2541
- 0.2541
- 0.2427
- 0.2508
- 0.2545
- 0.2546
- 0.2536
- 0.2485
- 0.2574
- 0.2602
- 0.2582
- 0.2558
- 0.2514
- 0.2571
- 0.2585
- 0.2578
- 0.2602
- 0.2567
test_loss_list:
- 1.8282103538513184
- 1.7819794511795044
- 1.7573819398880004
- 1.7610621666908264
- 1.7370946884155274
- 1.7209755492210388
- 1.7087604212760925
- 1.710265667438507
- 1.689992139339447
- 1.6858882308006287
- 1.697440161705017
- 1.6914689874649047
- 1.6835059356689452
- 1.6810716223716735
- 1.6713906979560853
- 1.6556220650672913
- 1.6343002605438233
- 1.6317660427093506
- 1.6229557704925537
- 1.6221740603446961
- 1.606649796962738
- 1.6038170742988587
- 1.6235309171676635
- 1.6157738065719605
- 1.6167926049232484
- 1.6083526825904846
- 1.5933673214912414
- 1.5782103490829469
- 1.5791786813735962
- 1.593553683757782
- 1.5907447624206543
- 1.5795173168182373
- 1.5740287804603577
- 1.5901977729797363
- 1.575610749721527
- 1.5661550116539003
- 1.5557552003860473
- 1.5522443389892577
- 1.5531349158287049
- 1.5525146412849427
- 1.5545723056793213
- 1.5576430916786195
- 1.5516391801834106
- 1.5398418164253236
- 1.535325300693512
- 1.5454542970657348
- 1.5456131172180176
- 1.540408730506897
- 1.5501014709472656
- 1.5550637984275817
- 1.5573083448410034
- 1.5459976315498352
- 1.5404401779174806
- 1.557429711818695
- 1.5560751509666444
- 1.5449127674102783
- 1.558483612537384
- 1.5431954407691955
- 1.5465019297599794
- 1.5322807097434998
- 1.5344796299934387
- 1.5202161979675293
- 1.5319357752799987
- 1.5315578651428223
- 1.5346882820129395
- 1.5253116726875304
- 1.514363443851471
- 1.508220772743225
- 1.5175660681724548
- 1.5261129426956177
- 1.5198817348480225
- 1.5078247570991516
- 1.504770452976227
- 1.4941626977920532
- 1.5073878455162049
- 1.5132132935523988
- 1.5066410160064698
- 1.4956960773468018
- 1.4966687774658203
- 1.5184142923355102
- 1.5198019981384276
- 1.5376928281784057
- 1.5317880153656005
- 1.5290072870254516
- 1.5286368870735167
- 1.5218985271453858
- 1.5114566326141357
- 1.5034821486473084
- 1.4979591727256776
- 1.4966373825073243
- 1.4891227269172669
- 1.5144387435913087
- 1.5074755668640136
- 1.5155477261543273
- 1.501650185585022
- 1.5001869845390319
- 1.5043404746055602
- 1.5084613251686096
- 1.5237000894546509
- 1.507368586063385
train_accuracy:
- 0.059
- 0.0
- 0.123
- 0.0
- 0.151
- 0.156
- 0.164
- 0.0
- 0.189
- 0.204
- 0.205
- 0.196
- 0.236
- 0.203
- 0.227
- 0.237
- 0.238
- 0.0
- 0.225
- 0.0
- 0.245
- 0.248
- 0.227
- 0.0
- 0.252
- 0.0
- 0.271
- 0.0
- 0.0
- 0.253
- 0.0
- 0.0
- 0.0
- 0.282
- 0.0
- 0.0
- 0.0
- 0.0
- 0.273
- 0.0
- 0.0
- 0.0
- 0.0
- 0.277
- 0.0
- 0.0
- 0.0
- 0.0
- 0.242
- 0.0
- 0.292
- 0.261
- 0.0
- 0.296
- 0.305
- 0.298
- 0.26
- 0.0
- 0.253
- 0.258
- 0.289
- 0.0
- 0.0
- 0.0
- 0.32
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.303
- 0.0
- 0.314
- 0.0
- 0.0
- 0.0
- 0.262
- 0.303
- 0.332
- 0.318
- 0.309
- 0.0
- 0.0
- 0.0
- 0.314
- 0.0
- 0.0
- 0.308
- 0.0
- 0.0
- 0.0
- 0.322
- 0.0
- 0.311
- 0.0
- 0.272
- 0.0
- 0.325
- 0.325
train_loss:
- 2.898
- 2.07
- 1.999
- 1.438
- 2.701
- 1.802
- 1.71
- 1.303
- 1.915
- 1.918
- 2.069
- 1.728
- 1.73
- 1.611
- 1.664
- 1.344
- 1.382
- 1.551
- 1.286
- 1.393
- 1.235
- 1.119
- 1.428
- 1.23
- 1.232
- 1.155
- 0.987
- 1.112
- 0.968
- 1.267
- 1.034
- 0.935
- 0.941
- 1.095
- 0.819
- 0.793
- 0.861
- 0.802
- 0.944
- 0.791
- 0.765
- 0.752
- 0.73
- 0.809
- 0.743
- 0.745
- 0.672
- 0.644
- 0.609
- 0.617
- 0.641
- 0.64
- 0.642
- 0.59
- 0.565
- 0.597
- 0.607
- 0.585
- 0.498
- 0.566
- 0.515
- 0.528
- 0.537
- 0.551
- 0.484
- 0.479
- 0.5
- 0.525
- 0.473
- 0.484
- 0.503
- 0.459
- 0.425
- 0.472
- 0.391
- 0.407
- 0.49
- 0.428
- 0.449
- 0.326
- 0.382
- 0.302
- 0.412
- 0.376
- 0.462
- 0.366
- 0.41
- 0.382
- 0.391
- 0.41
- 0.393
- 0.28
- 0.336
- 0.315
- 0.341
- 0.353
- 0.315
- 0.285
- 0.242
- 0.338
unequal: 0
verbose: 1
