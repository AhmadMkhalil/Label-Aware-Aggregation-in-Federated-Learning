avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0394
- 0.0922
- 0.115
- 0.1295
- 0.136
- 0.1485
- 0.1566
- 0.1648
- 0.1691
- 0.1759
- 0.1785
- 0.1816
- 0.1893
- 0.1926
- 0.1915
- 0.2019
- 0.1903
- 0.2026
- 0.2089
- 0.2107
- 0.209
- 0.2026
- 0.2057
- 0.2094
- 0.2124
- 0.2145
- 0.2079
- 0.2212
- 0.2216
- 0.2264
- 0.2272
- 0.2184
- 0.2243
- 0.2196
- 0.231
- 0.2402
- 0.2264
- 0.2344
- 0.2322
- 0.2393
- 0.236
- 0.2423
- 0.2376
- 0.2413
- 0.2388
- 0.2251
- 0.2366
- 0.2406
- 0.2291
- 0.2416
- 0.2403
- 0.2438
- 0.2311
- 0.2477
- 0.2455
- 0.2478
- 0.2529
- 0.2459
- 0.2456
- 0.2504
- 0.2479
- 0.2501
- 0.241
- 0.2493
- 0.2511
- 0.2507
- 0.2521
- 0.2536
- 0.2529
- 0.2552
- 0.2556
- 0.2517
- 0.2568
- 0.2548
- 0.2517
- 0.258
- 0.2491
- 0.2576
- 0.2526
- 0.2529
- 0.2529
- 0.2537
- 0.2517
- 0.2563
- 0.2526
- 0.2562
- 0.2447
- 0.259
- 0.256
- 0.256
- 0.2562
- 0.2575
- 0.2604
- 0.2608
- 0.2577
- 0.2573
- 0.2568
- 0.2619
- 0.2597
- 0.2482
test_loss_list:
- 1.8307502174377441
- 1.7811215972900392
- 1.7605431365966797
- 1.7563594055175782
- 1.7374704217910766
- 1.7111407279968263
- 1.7057278418540955
- 1.7139716720581055
- 1.7107422947883606
- 1.6918168306350707
- 1.6846287941932678
- 1.675442774295807
- 1.6620087075233458
- 1.6520718097686768
- 1.6382756423950195
- 1.634811315536499
- 1.6358168125152588
- 1.6062693667411805
- 1.601392776966095
- 1.5917258071899414
- 1.5931225657463073
- 1.5846835446357728
- 1.5801007008552552
- 1.5746474432945252
- 1.5734178066253661
- 1.5723723793029785
- 1.5827709722518921
- 1.579072744846344
- 1.584357635974884
- 1.5936707258224487
- 1.5934591102600097
- 1.579406623840332
- 1.5684791469573975
- 1.5619200825691224
- 1.5360336446762084
- 1.558358483314514
- 1.5520506882667542
- 1.5617814588546752
- 1.5488554406166077
- 1.5625973129272461
- 1.5552849292755127
- 1.545976996421814
- 1.5371625161170959
- 1.5413332319259643
- 1.5392184281349182
- 1.5381782627105713
- 1.5247601795196533
- 1.5218335342407228
- 1.5360128784179687
- 1.5198493814468383
- 1.513219039440155
- 1.5368596172332765
- 1.5397304368019105
- 1.5105498099327088
- 1.520756916999817
- 1.5164053463935852
- 1.5362336945533752
- 1.5262820267677306
- 1.5197427487373352
- 1.5137567353248595
- 1.5232921862602233
- 1.5465402245521545
- 1.531454496383667
- 1.5055595517158509
- 1.5098480296134948
- 1.5044943332672118
- 1.5170886945724487
- 1.5176110005378722
- 1.5138636207580567
- 1.5067239642143249
- 1.5079175758361816
- 1.506691722869873
- 1.5045537900924684
- 1.5024953198432922
- 1.4963029646873474
- 1.516158618927002
- 1.5037484192848205
- 1.5042111897468566
- 1.4915428924560548
- 1.4919250726699829
- 1.48533118724823
- 1.4899953508377075
- 1.4802979254722595
- 1.4867006754875183
- 1.4888931274414063
- 1.4919815731048585
- 1.4970548343658447
- 1.487333936691284
- 1.4943238615989685
- 1.5124559354782106
- 1.4992795491218567
- 1.4794368267059326
- 1.493453619480133
- 1.4755176401138306
- 1.5023835468292237
- 1.515100245475769
- 1.5068931293487549
- 1.5202886271476745
- 1.4946880674362182
- 1.4971282696723938
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.167
- 0.16
- 0.0
- 0.225
- 0.0
- 0.229
- 0.237
- 0.227
- 0.0
- 0.264
- 0.0
- 0.237
- 0.26
- 0.0
- 0.26
- 0.275
- 0.0
- 0.262
- 0.0
- 0.0
- 0.291
- 0.0
- 0.295
- 0.264
- 0.291
- 0.31
- 0.308
- 0.307
- 0.0
- 0.0
- 0.0
- 0.0
- 0.336
- 0.0
- 0.327
- 0.289
- 0.322
- 0.275
- 0.301
- 0.0
- 0.305
- 0.279
- 0.0
- 0.343
- 0.346
- 0.0
- 0.0
- 0.0
- 0.358
- 0.0
- 0.322
- 0.0
- 0.0
- 0.323
- 0.0
- 0.0
- 0.353
- 0.0
- 0.319
- 0.0
- 0.332
- 0.348
- 0.0
- 0.332
- 0.32
- 0.0
- 0.326
- 0.322
- 0.0
- 0.335
- 0.0
- 0.348
- 0.336
- 0.0
- 0.333
- 0.328
- 0.329
- 0.0
- 0.0
- 0.0
- 0.358
- 0.0
- 0.357
- 0.0
- 0.346
- 0.346
- 0.34
- 0.0
- 0.0
- 0.0
- 0.322
- 0.346
- 0.335
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 2.85
- 2.006
- 2.49
- 2.297
- 1.749
- 1.805
- 2.125
- 2.326
- 1.847
- 1.532
- 1.776
- 1.424
- 1.777
- 1.427
- 1.393
- 1.529
- 1.044
- 1.275
- 1.412
- 1.155
- 1.264
- 0.944
- 0.937
- 1.056
- 1.062
- 0.934
- 0.82
- 1.336
- 1.101
- 1.218
- 1.031
- 0.834
- 0.828
- 0.88
- 0.986
- 1.092
- 0.782
- 1.037
- 0.886
- 0.902
- 0.733
- 0.858
- 0.766
- 0.787
- 0.679
- 0.689
- 0.654
- 0.706
- 0.611
- 0.758
- 0.644
- 0.618
- 0.69
- 0.673
- 0.621
- 0.6
- 0.559
- 0.587
- 0.581
- 0.583
- 0.536
- 0.508
- 0.524
- 0.525
- 0.536
- 0.505
- 0.476
- 0.428
- 0.423
- 0.481
- 0.453
- 0.432
- 0.405
- 0.398
- 0.442
- 0.36
- 0.441
- 0.377
- 0.396
- 0.399
- 0.382
- 0.398
- 0.419
- 0.394
- 0.377
- 0.363
- 0.438
- 0.363
- 0.325
- 0.288
- 0.378
- 0.366
- 0.278
- 0.327
- 0.237
- 0.273
- 0.283
- 0.237
- 0.305
- 0.374
unequal: 0
verbose: 1
