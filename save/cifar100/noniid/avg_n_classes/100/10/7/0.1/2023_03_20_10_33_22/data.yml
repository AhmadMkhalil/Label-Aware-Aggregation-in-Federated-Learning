avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.036
- 0.0511
- 0.043
- 0.0517
- 0.0746
- 0.0488
- 0.0812
- 0.0485
- 0.0402
- 0.0498
- 0.0491
- 0.099
- 0.1081
- 0.0512
- 0.0522
- 0.0502
- 0.0469
- 0.0469
- 0.0472
- 0.0509
- 0.0553
- 0.1098
- 0.1154
- 0.0549
- 0.0528
- 0.0527
- 0.0547
- 0.12
- 0.0483
- 0.0521
- 0.0519
- 0.0496
- 0.1217
- 0.1229
- 0.1214
- 0.1258
- 0.0583
- 0.135
- 0.1372
- 0.0546
- 0.059
- 0.0593
- 0.0569
- 0.0605
- 0.0543
- 0.0589
- 0.0556
- 0.0614
- 0.0577
- 0.0543
- 0.055
- 0.0659
- 0.1384
- 0.0583
- 0.0593
- 0.1414
- 0.0633
- 0.0606
- 0.062
- 0.0627
- 0.0543
- 0.0533
- 0.0654
- 0.0588
- 0.0616
- 0.0636
- 0.0548
- 0.0617
- 0.1432
- 0.1444
- 0.0636
- 0.0643
- 0.0641
- 0.1482
- 0.0675
- 0.0604
- 0.1511
- 0.071
- 0.0602
- 0.0593
- 0.063
- 0.0635
- 0.0681
- 0.1537
- 0.1493
- 0.071
- 0.0624
- 0.1549
- 0.1536
- 0.0647
- 0.1562
- 0.0621
- 0.0604
- 0.1573
- 0.0755
- 0.1624
- 0.0712
- 0.0652
- 0.1594
- 0.0717
test_loss_list:
- 2.772626600265503
- 3.441992883682251
- 3.5806161975860595
- 3.676079397201538
- 2.4076710891723634
- 3.4371375751495363
- 2.595798888206482
- 3.5711965274810793
- 3.5516809749603273
- 3.3967010402679443
- 3.684645719528198
- 2.4699321746826173
- 2.6628430795669558
- 3.6423299884796143
- 3.386573247909546
- 3.34387246131897
- 3.3706192779541015
- 3.3546195697784422
- 3.422043676376343
- 3.532240924835205
- 3.2211200761795045
- 2.285382127761841
- 2.453741273880005
- 3.42702428817749
- 3.3423259925842284
- 3.1326607131958006
- 3.1333264923095703
- 2.2717090892791747
- 3.32807785987854
- 3.518598165512085
- 3.659251413345337
- 3.8216922378540037
- 2.404256386756897
- 2.5240800094604494
- 2.6323564529418944
- 2.6966266202926636
- 3.487236909866333
- 2.588687834739685
- 2.6590552806854246
- 3.4030345678329468
- 3.2176800107955934
- 3.4641074085235597
- 3.3795066690444946
- 3.3548239040374757
- 3.1966741132736205
- 3.1773828983306887
- 3.141071801185608
- 3.2731338500976563
- 3.3151247310638428
- 3.175764560699463
- 3.1350166034698486
- 3.154400281906128
- 2.165735893249512
- 3.1149393463134767
- 3.346880178451538
- 2.3040336990356445
- 3.0859386491775513
- 3.1174694204330446
- 3.167605094909668
- 3.0853642654418945
- 3.0869761180877684
- 3.4089348220825197
- 3.0479136323928833
- 2.953918151855469
- 3.043078007698059
- 3.025449776649475
- 3.0003171586990356
- 2.988491015434265
- 2.0808334589004516
- 2.273898205757141
- 3.0427107620239258
- 3.008205909729004
- 3.0560473728179933
- 2.2449579191207887
- 3.0392627811431883
- 3.021916399002075
- 2.2933175134658814
- 3.020741696357727
- 3.078337993621826
- 3.2545119428634646
- 2.9560644578933717
- 2.9523794984817506
- 2.9883065366744996
- 2.1635803747177125
- 2.3555564975738523
- 2.9696807193756105
- 3.003878631591797
- 2.278995614051819
- 2.399147515296936
- 3.0943284797668458
- 2.2754881477355955
- 3.0430641269683836
- 2.987228932380676
- 2.176954817771912
- 2.8536537313461303
- 2.2418809700012208
- 2.9510820865631104
- 2.9232146167755126
- 2.185137085914612
- 2.9435954475402832
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.216
- 0.0
- 0.257
- 0.0
- 0.0
- 0.0
- 0.0
- 0.294
- 0.302
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.336
- 0.312
- 0.0
- 0.0
- 0.0
- 0.0
- 0.383
- 0.0
- 0.0
- 0.0
- 0.0
- 0.35
- 0.409
- 0.409
- 0.43
- 0.0
- 0.4
- 0.423
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.442
- 0.0
- 0.0
- 0.427
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.405
- 0.451
- 0.0
- 0.0
- 0.0
- 0.483
- 0.0
- 0.0
- 0.46
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.487
- 0.428
- 0.0
- 0.0
- 0.439
- 0.447
- 0.0
- 0.472
- 0.0
- 0.0
- 0.496
- 0.0
- 0.47
- 0.0
- 0.0
- 0.441
- 0.0
train_loss:
- 1.801
- 1.589
- 1.486
- 1.083
- 3.4
- 1.281
- 2.4
- 1.804
- 2.115
- 1.307
- 0.644
- 2.621
- 2.042
- 1.691
- 1.132
- 1.767
- 1.686
- 1.872
- 1.314
- 1.16
- 1.346
- 2.334
- 1.491
- 1.256
- 1.546
- 1.084
- 1.322
- 2.095
- 1.252
- 0.658
- 0.566
- 0.469
- 1.754
- 1.397
- 1.139
- 0.935
- 1.168
- 1.74
- 1.168
- 0.958
- 1.195
- 0.434
- 0.977
- 0.623
- 1.271
- 1.191
- 0.742
- 0.692
- 0.495
- 1.442
- 0.549
- 0.614
- 1.479
- 0.853
- 0.392
- 1.404
- 0.696
- 0.907
- 0.492
- 0.692
- 1.016
- 0.434
- 0.841
- 0.628
- 0.683
- 0.584
- 1.069
- 0.556
- 1.356
- 1.129
- 0.586
- 0.588
- 0.408
- 1.116
- 0.391
- 0.6
- 1.114
- 0.372
- 0.917
- 0.34
- 0.589
- 0.753
- 0.344
- 1.029
- 0.789
- 0.429
- 0.521
- 0.767
- 0.765
- 0.726
- 0.778
- 0.931
- 0.534
- 0.839
- 0.384
- 0.67
- 0.684
- 0.437
- 0.759
- 0.534
unequal: 0
verbose: 1
