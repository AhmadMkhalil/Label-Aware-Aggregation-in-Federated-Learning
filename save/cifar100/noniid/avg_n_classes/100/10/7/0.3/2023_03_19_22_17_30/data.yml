avg_train_accuracy: 0.0
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0412
- 0.0552
- 0.0841
- 0.0918
- 0.0976
- 0.1044
- 0.1064
- 0.1147
- 0.099
- 0.0823
- 0.0951
- 0.0993
- 0.0885
- 0.1024
- 0.141
- 0.1196
- 0.1215
- 0.1258
- 0.1258
- 0.145
- 0.1392
- 0.1437
- 0.1357
- 0.1386
- 0.1339
- 0.1459
- 0.1483
- 0.1511
- 0.1497
- 0.1475
- 0.1822
- 0.1412
- 0.155
- 0.1551
- 0.1535
- 0.1418
- 0.1637
- 0.1522
- 0.1524
- 0.1607
- 0.154
- 0.1537
- 0.1603
- 0.1654
- 0.1715
- 0.2055
- 0.181
- 0.1713
- 0.1702
- 0.1991
- 0.1789
- 0.1878
- 0.1765
- 0.1758
- 0.1883
- 0.1621
- 0.2019
- 0.1779
- 0.201
- 0.1756
- 0.1818
- 0.193
- 0.1887
- 0.1794
- 0.2114
- 0.1821
- 0.1841
- 0.1975
- 0.197
- 0.1851
- 0.2089
- 0.1814
- 0.1907
- 0.1867
- 0.1928
- 0.1847
- 0.1884
- 0.1878
- 0.2244
- 0.1891
- 0.189
- 0.2224
- 0.2062
- 0.2009
- 0.1991
- 0.1974
- 0.1972
- 0.1825
- 0.1886
- 0.2039
- 0.1893
- 0.2171
- 0.2121
- 0.2134
- 0.1928
- 0.2164
- 0.2112
- 0.2078
- 0.2138
- 0.212
test_loss_list:
- 2.020878553390503
- 1.9301063156127929
- 2.004361100196838
- 2.0770402002334594
- 2.0635608291625975
- 2.0415892362594605
- 2.0493207788467407
- 2.203644847869873
- 1.9611927270889282
- 1.8219576835632325
- 1.8757854986190796
- 1.906593861579895
- 1.9335862970352173
- 1.9662838411331176
- 1.7779403829574585
- 1.895287938117981
- 1.9212800884246826
- 2.070196146965027
- 1.971428952217102
- 1.7839587116241455
- 1.8417436075210571
- 1.7355811309814453
- 1.9940763807296753
- 1.9493255758285521
- 1.9210878086090089
- 1.691325409412384
- 1.7779616832733154
- 1.7435607719421387
- 1.7730216407775878
- 2.002832236289978
- 1.649700813293457
- 1.7685127115249635
- 1.7459838676452637
- 1.8184481048583985
- 1.8046483993530273
- 1.752940707206726
- 1.7567307567596435
- 2.003687524795532
- 1.8885832023620606
- 1.8824878883361817
- 2.016103663444519
- 1.9001374959945678
- 1.8554359292984008
- 1.8562230634689332
- 1.874759087562561
- 1.664693841934204
- 1.778665246963501
- 1.8264820718765258
- 1.8259137344360352
- 1.6016046547889708
- 1.6798688197135925
- 1.672880175113678
- 1.7531363344192505
- 1.825194411277771
- 1.7333062601089477
- 1.8700737190246581
- 1.6644207787513734
- 1.7130145001411439
- 1.705148582458496
- 1.770842809677124
- 1.7768147706985473
- 1.7137897205352783
- 1.7166566443443299
- 1.7583281540870666
- 1.6135086059570312
- 1.8052748823165894
- 1.7706206798553468
- 1.70765154838562
- 1.7565142393112183
- 1.7935781383514404
- 1.671419222354889
- 1.8810635137557983
- 1.8464106702804566
- 1.7716395854949951
- 1.7520125007629395
- 1.7811408758163452
- 1.7804010438919067
- 1.7884159803390502
- 1.630139331817627
- 1.818057475090027
- 1.741505618095398
- 1.6207450342178344
- 1.7258215069770813
- 1.741325957775116
- 1.7640068006515504
- 1.7713556337356566
- 1.762081091403961
- 1.9096558618545532
- 1.93288010597229
- 1.7633058667182921
- 1.8098734331130981
- 1.6771854853630066
- 1.6682705402374267
- 1.6603251051902772
- 1.768389892578125
- 1.6947038269042969
- 1.7607750511169433
- 1.720409541130066
- 1.6949985384941102
- 1.7393325757980347
train_accuracy:
- 0.127
- 0.0
- 0.0
- 0.25
- 0.0
- 0.0
- 0.335
- 0.32
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.441
- 0.0
- 0.0
- 0.358
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.448
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.459
- 0.413
- 0.0
- 0.468
- 0.463
- 0.418
- 0.0
- 0.467
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.448
- 0.0
- 0.0
- 0.497
- 0.0
- 0.0
- 0.463
- 0.0
- 0.0
- 0.0
- 0.0
- 0.471
- 0.0
- 0.438
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.532
- 0.0
- 0.491
- 0.0
- 0.48
- 0.0
- 0.0
- 0.0
- 0.516
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.422
- 0.499
- 0.0
- 0.0
- 0.452
- 0.0
- 0.0
- 0.0
- 0.0
- 0.471
- 0.433
- 0.0
- 0.502
- 0.0
train_loss:
- 2.751
- 1.736
- 1.814
- 1.683
- 1.741
- 1.704
- 1.564
- 1.592
- 1.315
- 1.38
- 1.08
- 1.069
- 1.049
- 0.937
- 1.197
- 1.261
- 1.205
- 1.243
- 1.029
- 1.022
- 1.054
- 1.008
- 1.067
- 0.948
- 0.95
- 0.995
- 0.977
- 0.827
- 0.935
- 1.028
- 0.886
- 0.685
- 0.814
- 0.791
- 0.691
- 0.67
- 0.681
- 0.825
- 0.735
- 0.782
- 0.732
- 0.74
- 0.702
- 0.654
- 0.573
- 0.689
- 0.584
- 0.723
- 0.576
- 0.677
- 0.524
- 0.559
- 0.567
- 0.585
- 0.553
- 0.564
- 0.538
- 0.473
- 0.443
- 0.474
- 0.414
- 0.462
- 0.491
- 0.568
- 0.471
- 0.438
- 0.409
- 0.41
- 0.303
- 0.482
- 0.412
- 0.401
- 0.342
- 0.415
- 0.378
- 0.445
- 0.4
- 0.36
- 0.465
- 0.324
- 0.382
- 0.392
- 0.279
- 0.328
- 0.277
- 0.307
- 0.286
- 0.281
- 0.213
- 0.341
- 0.288
- 0.352
- 0.335
- 0.351
- 0.251
- 0.328
- 0.219
- 0.311
- 0.338
- 0.235
unequal: 0
verbose: 1
