avg_train_accuracy: 0.392
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0392
- 0.0927
- 0.1057
- 0.125
- 0.1321
- 0.1378
- 0.152
- 0.1581
- 0.1616
- 0.1715
- 0.1765
- 0.1819
- 0.1824
- 0.1852
- 0.1944
- 0.1958
- 0.1819
- 0.2014
- 0.2031
- 0.2046
- 0.2058
- 0.2006
- 0.2043
- 0.2119
- 0.2221
- 0.2198
- 0.2212
- 0.2225
- 0.2248
- 0.2269
- 0.2303
- 0.2333
- 0.2219
- 0.2334
- 0.236
- 0.2349
- 0.2383
- 0.2413
- 0.2401
- 0.2403
- 0.2453
- 0.2481
- 0.2426
- 0.2443
- 0.2452
- 0.2357
- 0.2469
- 0.2531
- 0.2516
- 0.2551
- 0.2485
- 0.2546
- 0.2532
- 0.2509
- 0.2568
- 0.2534
- 0.2586
- 0.257
- 0.2556
- 0.2552
- 0.2605
- 0.2624
- 0.2487
- 0.2577
- 0.2517
- 0.2615
- 0.2554
- 0.2611
- 0.2637
- 0.2674
- 0.2679
- 0.2633
- 0.2597
- 0.2671
- 0.263
- 0.2652
- 0.2559
- 0.2621
- 0.2672
- 0.2814
- 0.2732
- 0.2702
- 0.2711
- 0.2649
- 0.267
- 0.2697
- 0.2726
- 0.2676
- 0.2691
- 0.2626
- 0.2695
- 0.2717
- 0.2694
- 0.2716
- 0.2746
- 0.2731
- 0.2735
- 0.2745
- 0.2705
- 0.2748
test_loss_list:
- 1.8444726467132568
- 1.8578294515609741
- 1.8368479108810425
- 1.8638578367233276
- 1.8323382568359374
- 1.781266269683838
- 1.7498192405700683
- 1.745513117313385
- 1.7328992986679077
- 1.7231407642364502
- 1.767905821800232
- 1.725427885055542
- 1.7194959259033202
- 1.7201562595367432
- 1.7148139095306396
- 1.7248682522773742
- 1.6858075499534606
- 1.7151308917999268
- 1.6402051424980164
- 1.6353345036506652
- 1.6388921403884888
- 1.6024846649169922
- 1.619263424873352
- 1.670518250465393
- 1.6885141348838806
- 1.6547212934494018
- 1.6442251324653625
- 1.6205224299430847
- 1.6113164281845094
- 1.5982987022399902
- 1.6012245154380798
- 1.5900139212608337
- 1.556601357460022
- 1.5630703735351563
- 1.5618261170387269
- 1.5677463936805724
- 1.5738328385353089
- 1.6378924012184144
- 1.6030053901672363
- 1.5659899497032166
- 1.3867442774772645
- 1.4394069838523864
- 1.488522436618805
- 1.5003307938575745
- 1.5067122101783752
- 1.4931717085838319
- 1.508707673549652
- 1.5701884460449218
- 1.5499834036827087
- 1.6086706519126892
- 1.5717462611198425
- 1.5500850868225098
- 1.5133907055854798
- 1.5288881278038025
- 1.5379656219482423
- 1.5337611484527587
- 1.5181729578971863
- 1.5178922128677368
- 1.5842674350738526
- 1.5404918956756593
- 1.5279578018188475
- 1.5862830471992493
- 1.5237584614753723
- 1.5809724020957947
- 1.5054571866989135
- 1.5749771523475646
- 1.542132966518402
- 1.5860478472709656
- 1.6106199765205382
- 1.6337571668624877
- 1.5652411961555481
- 1.5602144813537597
- 1.5086503791809083
- 1.514292368888855
- 1.525036382675171
- 1.516243703365326
- 1.4758972501754761
- 1.4953455233573913
- 1.5579268097877503
- 1.3477819561958313
- 1.3868278098106384
- 1.3981253218650818
- 1.4380444955825806
- 1.423946750164032
- 1.4394634389877319
- 1.451823308467865
- 1.5131113171577453
- 1.4938170337677001
- 1.4879920649528504
- 1.4640478706359863
- 1.4601841211318969
- 1.4619602036476136
- 1.537811348438263
- 1.4974202728271484
- 1.503936529159546
- 1.4859847450256347
- 1.484179356098175
- 1.5479722094535828
- 1.4755602598190307
- 1.472609031200409
train_accuracy:
- 0.083
- 0.132
- 0.0
- 0.189
- 0.18
- 0.214
- 0.213
- 0.0
- 0.0
- 0.251
- 0.227
- 0.215
- 0.0
- 0.268
- 0.0
- 0.261
- 0.0
- 0.28
- 0.0
- 0.0
- 0.247
- 0.0
- 0.0
- 0.297
- 0.298
- 0.0
- 0.324
- 0.261
- 0.312
- 0.322
- 0.296
- 0.333
- 0.0
- 0.34
- 0.296
- 0.329
- 0.343
- 0.356
- 0.332
- 0.0
- 0.0
- 0.0
- 0.303
- 0.34
- 0.336
- 0.0
- 0.373
- 0.368
- 0.0
- 0.362
- 0.328
- 0.0
- 0.339
- 0.355
- 0.0
- 0.355
- 0.0
- 0.365
- 0.362
- 0.367
- 0.0
- 0.371
- 0.0
- 0.381
- 0.0
- 0.374
- 0.365
- 0.351
- 0.369
- 0.378
- 0.0
- 0.0
- 0.318
- 0.378
- 0.0
- 0.378
- 0.0
- 0.377
- 0.384
- 0.0
- 0.398
- 0.0
- 0.0
- 0.344
- 0.393
- 0.394
- 0.395
- 0.382
- 0.0
- 0.37
- 0.385
- 0.369
- 0.366
- 0.374
- 0.0
- 0.371
- 0.322
- 0.408
- 0.0
- 0.392
train_loss:
- 3.209
- 3.541
- 2.653
- 3.082
- 2.561
- 2.003
- 2.322
- 2.451
- 2.038
- 2.316
- 2.353
- 2.308
- 2.032
- 1.971
- 1.985
- 1.807
- 1.691
- 2.073
- 1.662
- 1.84
- 1.559
- 1.713
- 1.557
- 1.608
- 1.839
- 1.568
- 1.603
- 1.561
- 1.422
- 1.33
- 1.409
- 1.359
- 1.285
- 1.254
- 1.423
- 1.289
- 1.283
- 1.12
- 1.058
- 1.378
- 1.065
- 0.995
- 0.973
- 1.098
- 1.15
- 0.962
- 0.826
- 1.198
- 0.882
- 0.819
- 0.783
- 0.891
- 0.903
- 0.81
- 0.864
- 0.803
- 0.916
- 0.812
- 0.68
- 0.837
- 0.765
- 0.701
- 0.856
- 0.588
- 0.804
- 0.541
- 0.636
- 0.623
- 0.537
- 0.52
- 0.634
- 0.466
- 0.727
- 0.663
- 0.426
- 0.585
- 0.647
- 0.74
- 0.612
- 0.784
- 0.474
- 0.493
- 0.6
- 0.547
- 0.389
- 0.452
- 0.472
- 0.513
- 0.516
- 0.64
- 0.485
- 0.409
- 0.358
- 0.403
- 0.337
- 0.547
- 0.475
- 0.328
- 0.49
- 0.494
unequal: 0
verbose: 1
