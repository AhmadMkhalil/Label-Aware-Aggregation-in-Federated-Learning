avg_train_accuracy: 0.366
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.036
- 0.0476
- 0.0965
- 0.1169
- 0.1321
- 0.1433
- 0.1471
- 0.157
- 0.1671
- 0.1725
- 0.1679
- 0.1766
- 0.1781
- 0.1824
- 0.1853
- 0.2002
- 0.1994
- 0.1994
- 0.2035
- 0.2066
- 0.2087
- 0.209
- 0.2075
- 0.2047
- 0.1946
- 0.221
- 0.227
- 0.2231
- 0.2192
- 0.2121
- 0.2213
- 0.2332
- 0.2315
- 0.2311
- 0.2258
- 0.2362
- 0.2373
- 0.239
- 0.2361
- 0.2306
- 0.2377
- 0.2425
- 0.2443
- 0.2428
- 0.2485
- 0.2464
- 0.2368
- 0.25
- 0.2515
- 0.2503
- 0.2531
- 0.2549
- 0.2526
- 0.2521
- 0.2598
- 0.2501
- 0.25
- 0.2612
- 0.257
- 0.2571
- 0.2595
- 0.2667
- 0.2646
- 0.2564
- 0.2622
- 0.2624
- 0.2646
- 0.2623
- 0.2624
- 0.2639
- 0.2659
- 0.2658
- 0.2657
- 0.2579
- 0.2708
- 0.2675
- 0.2667
- 0.2697
- 0.264
- 0.2691
- 0.271
- 0.2719
- 0.2679
- 0.2703
- 0.2602
- 0.2741
- 0.2697
- 0.2746
- 0.2735
- 0.2694
- 0.2749
- 0.2736
- 0.2692
- 0.2717
- 0.2738
- 0.2767
- 0.2741
- 0.2726
- 0.2765
- 0.276
test_loss_list:
- 1.861743426322937
- 1.797969446182251
- 1.7360025310516358
- 1.7428532600402833
- 1.792571268081665
- 1.7760315608978272
- 1.7554158878326416
- 1.7923971319198608
- 1.8156315994262695
- 1.7788516235351564
- 1.5274993300437927
- 1.5980801916122436
- 1.6262316942214965
- 1.698519835472107
- 1.7255551505088806
- 1.68542870759964
- 1.729596781730652
- 1.698934473991394
- 1.675915901660919
- 1.6486848950386048
- 1.6086163640022277
- 1.663968951702118
- 1.6351027035713195
- 1.5996239352226258
- 1.5924197697639466
- 1.6274023747444153
- 1.6554014825820922
- 1.6300485634803772
- 1.6257403373718262
- 1.5877829480171204
- 1.5868494319915771
- 1.6271762204170228
- 1.618504912853241
- 1.6111572861671448
- 1.5992208886146546
- 1.5702322268486022
- 1.5726243805885316
- 1.6271790981292724
- 1.5748177981376648
- 1.418564088344574
- 1.4572207021713257
- 1.487730803489685
- 1.5131677889823913
- 1.5169661116600037
- 1.582138261795044
- 1.5596507668495179
- 1.5250131464004517
- 1.5175532150268554
- 1.5381702208518981
- 1.5210840463638307
- 1.530677525997162
- 1.5908823132514953
- 1.5632145833969116
- 1.5565516781806945
- 1.5603486585617066
- 1.5308089971542358
- 1.5233358931541443
- 1.520786895751953
- 1.592771179676056
- 1.5618877983093262
- 1.6156344938278198
- 1.6416381669044495
- 1.645961003303528
- 1.5814114212989807
- 1.5622526097297669
- 1.6219584727287293
- 1.5914806008338929
- 1.5790712141990662
- 1.5808133006095886
- 1.5804029679298401
- 1.617683141231537
- 1.5820966577529907
- 1.591112015247345
- 1.5621743369102479
- 1.5199890589714051
- 1.540268955230713
- 1.5418257570266725
- 1.5984507012367248
- 1.541412856578827
- 1.5927900719642638
- 1.6198148560523986
- 1.6312296175956726
- 1.5828799390792847
- 1.5622659254074096
- 1.5300405168533324
- 1.567071692943573
- 1.5403831148147582
- 1.5192191123962402
- 1.5133537817001343
- 1.4817300415039063
- 1.551666133403778
- 1.5889471316337584
- 1.5594329929351807
- 1.5262147068977356
- 1.5187689661979675
- 1.5897152400016785
- 1.539098083972931
- 1.4999085283279419
- 1.5619790267944336
- 1.5187893033027648
train_accuracy:
- 0.0
- 0.0
- 0.108
- 0.135
- 0.167
- 0.22
- 0.0
- 0.179
- 0.19
- 0.242
- 0.0
- 0.221
- 0.228
- 0.215
- 0.282
- 0.0
- 0.256
- 0.273
- 0.291
- 0.272
- 0.0
- 0.308
- 0.257
- 0.251
- 0.0
- 0.295
- 0.298
- 0.276
- 0.293
- 0.269
- 0.33
- 0.339
- 0.371
- 0.338
- 0.338
- 0.376
- 0.29
- 0.333
- 0.0
- 0.0
- 0.322
- 0.316
- 0.0
- 0.422
- 0.323
- 0.336
- 0.307
- 0.338
- 0.417
- 0.364
- 0.367
- 0.352
- 0.0
- 0.0
- 0.394
- 0.0
- 0.334
- 0.437
- 0.382
- 0.0
- 0.352
- 0.352
- 0.352
- 0.331
- 0.37
- 0.363
- 0.0
- 0.341
- 0.374
- 0.34
- 0.394
- 0.0
- 0.0
- 0.328
- 0.388
- 0.338
- 0.362
- 0.402
- 0.35
- 0.454
- 0.452
- 0.361
- 0.375
- 0.0
- 0.0
- 0.367
- 0.356
- 0.0
- 0.4
- 0.0
- 0.366
- 0.395
- 0.372
- 0.0
- 0.375
- 0.372
- 0.0
- 0.0
- 0.457
- 0.366
train_loss:
- 3.281
- 1.812
- 2.894
- 2.75
- 3.081
- 2.481
- 2.466
- 2.689
- 2.548
- 2.142
- 1.586
- 2.05
- 2.062
- 2.313
- 2.194
- 1.941
- 2.146
- 1.803
- 1.799
- 1.82
- 1.448
- 2.025
- 1.612
- 1.333
- 1.219
- 1.89
- 1.761
- 1.383
- 1.429
- 1.133
- 1.159
- 1.618
- 1.231
- 1.302
- 1.353
- 1.361
- 1.165
- 1.404
- 1.142
- 1.041
- 0.978
- 1.259
- 1.062
- 1.164
- 1.198
- 0.988
- 0.977
- 1.061
- 0.874
- 1.092
- 0.972
- 0.811
- 0.889
- 0.791
- 0.873
- 0.775
- 0.818
- 0.84
- 0.817
- 0.675
- 0.667
- 0.606
- 0.802
- 0.865
- 0.761
- 0.663
- 0.618
- 0.732
- 0.643
- 0.587
- 0.524
- 0.61
- 0.565
- 0.71
- 0.749
- 0.577
- 0.518
- 0.448
- 0.581
- 0.532
- 0.422
- 0.387
- 0.579
- 0.528
- 0.637
- 0.391
- 0.438
- 0.503
- 0.515
- 0.624
- 0.318
- 0.279
- 0.478
- 0.482
- 0.497
- 0.3
- 0.426
- 0.544
- 0.263
- 0.481
unequal: 0
verbose: 1
