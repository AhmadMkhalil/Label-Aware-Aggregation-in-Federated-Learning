avg_train_accuracy: 0.314
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0471
- 0.0986
- 0.1036
- 0.1124
- 0.1301
- 0.1411
- 0.1492
- 0.1546
- 0.1641
- 0.1662
- 0.175
- 0.1713
- 0.1811
- 0.1853
- 0.1905
- 0.193
- 0.2024
- 0.202
- 0.2009
- 0.1954
- 0.2089
- 0.2087
- 0.2067
- 0.2058
- 0.2127
- 0.2158
- 0.2096
- 0.2167
- 0.2214
- 0.2186
- 0.2236
- 0.2245
- 0.2295
- 0.2321
- 0.221
- 0.2296
- 0.2305
- 0.2331
- 0.2359
- 0.2388
- 0.2342
- 0.2412
- 0.2454
- 0.2408
- 0.2418
- 0.2428
- 0.2435
- 0.2308
- 0.2397
- 0.2431
- 0.2451
- 0.2526
- 0.2484
- 0.2433
- 0.2539
- 0.2521
- 0.2526
- 0.2521
- 0.2495
- 0.2536
- 0.2526
- 0.2555
- 0.257
- 0.2585
- 0.2608
- 0.2563
- 0.2572
- 0.2586
- 0.2595
- 0.2604
- 0.2614
- 0.2591
- 0.2606
- 0.2607
- 0.2501
- 0.2607
- 0.2541
- 0.2617
- 0.2634
- 0.2593
- 0.2622
- 0.263
- 0.2631
- 0.2638
- 0.2627
- 0.2613
- 0.2619
- 0.263
- 0.2581
- 0.2657
- 0.2653
- 0.2664
- 0.2617
- 0.2667
- 0.2648
- 0.2658
- 0.2618
- 0.2685
- 0.268
- 0.2682
test_loss_list:
- 1.8612551164627076
- 1.8784160375595094
- 1.8227706813812257
- 1.7761027812957764
- 1.7613915252685546
- 1.7544319701194764
- 1.7540192222595214
- 1.7484450626373291
- 1.7014231181144714
- 1.7037118697166442
- 1.7653976488113403
- 1.6987146067619323
- 1.686943678855896
- 1.6909607791900634
- 1.676307213306427
- 1.675365493297577
- 1.7247961401939391
- 1.753710777759552
- 1.7225024271011353
- 1.6650073194503785
- 1.652163188457489
- 1.6694336080551146
- 1.6559358406066895
- 1.6225923991203308
- 1.6341305446624756
- 1.6985308885574342
- 1.6226931977272034
- 1.6197657680511475
- 1.6238704872131349
- 1.6148098826408386
- 1.6089550042152405
- 1.6042238283157348
- 1.5991669178009034
- 1.671557493209839
- 1.6022749280929565
- 1.6004641556739807
- 1.67151353597641
- 1.683564648628235
- 1.714944634437561
- 1.6602874207496643
- 1.6541882014274598
- 1.6371563291549682
- 1.6939066553115845
- 1.6509753274917602
- 1.6276688528060914
- 1.6091257190704347
- 1.5992297863960265
- 1.579132993221283
- 1.5345794653892517
- 1.5041152739524841
- 1.5332985019683838
- 1.5306229019165039
- 1.544786856174469
- 1.5176813793182373
- 1.5844173192977906
- 1.5652126860618591
- 1.556456937789917
- 1.6065612983703614
- 1.643528904914856
- 1.6597016501426696
- 1.685509958267212
- 1.6307525777816771
- 1.6727329254150392
- 1.615633521080017
- 1.5867412304878235
- 1.5851134037971497
- 1.5564592814445495
- 1.55459796667099
- 1.611793875694275
- 1.5725435209274292
- 1.5631397771835327
- 1.5631252765655517
- 1.5454312324523927
- 1.5428046798706054
- 1.522161214351654
- 1.52260568857193
- 1.4916485857963562
- 1.4965907096862794
- 1.5718975472450256
- 1.552952570915222
- 1.5302714276313782
- 1.5393815016746522
- 1.5315983057022096
- 1.5339861369132997
- 1.5363054394721984
- 1.5579035782814026
- 1.5278361082077025
- 1.5232823061943055
- 1.5074685883522034
- 1.5699692511558532
- 1.603041605949402
- 1.5526161766052247
- 1.5040586042404174
- 1.565134813785553
- 1.5320409393310548
- 1.5267702651023864
- 1.4800352334976197
- 1.4933712911605834
- 1.5597247409820556
- 1.5917372465133668
train_accuracy:
- 0.045
- 0.156
- 0.0
- 0.177
- 0.0
- 0.199
- 0.179
- 0.232
- 0.269
- 0.191
- 0.265
- 0.0
- 0.258
- 0.0
- 0.0
- 0.306
- 0.281
- 0.299
- 0.231
- 0.278
- 0.331
- 0.233
- 0.0
- 0.303
- 0.283
- 0.248
- 0.0
- 0.312
- 0.34
- 0.335
- 0.333
- 0.0
- 0.361
- 0.334
- 0.0
- 0.0
- 0.355
- 0.366
- 0.281
- 0.275
- 0.0
- 0.384
- 0.331
- 0.379
- 0.328
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.362
- 0.38
- 0.0
- 0.346
- 0.297
- 0.376
- 0.368
- 0.342
- 0.298
- 0.412
- 0.0
- 0.306
- 0.409
- 0.36
- 0.347
- 0.391
- 0.0
- 0.374
- 0.366
- 0.32
- 0.35
- 0.305
- 0.306
- 0.0
- 0.3
- 0.376
- 0.326
- 0.319
- 0.303
- 0.0
- 0.394
- 0.419
- 0.0
- 0.327
- 0.42
- 0.427
- 0.341
- 0.0
- 0.432
- 0.364
- 0.391
- 0.0
- 0.389
- 0.326
- 0.0
- 0.0
- 0.318
- 0.335
- 0.314
train_loss:
- 4.02
- 3.415
- 2.381
- 2.128
- 2.48
- 2.626
- 2.298
- 2.218
- 1.964
- 2.297
- 2.441
- 1.87
- 2.088
- 2.006
- 1.999
- 1.971
- 2.065
- 2.017
- 1.829
- 1.554
- 1.949
- 1.556
- 1.613
- 1.512
- 1.359
- 1.641
- 1.487
- 1.435
- 1.444
- 1.419
- 1.474
- 1.484
- 1.33
- 1.496
- 1.125
- 1.055
- 1.16
- 1.229
- 1.316
- 1.194
- 1.085
- 0.956
- 1.152
- 1.064
- 0.996
- 0.926
- 1.075
- 0.872
- 1.137
- 0.94
- 0.884
- 1.21
- 0.94
- 1.06
- 0.849
- 0.89
- 0.89
- 0.722
- 0.764
- 0.748
- 0.76
- 0.754
- 0.66
- 0.836
- 0.817
- 0.649
- 0.71
- 0.584
- 0.493
- 0.716
- 0.697
- 0.624
- 0.754
- 0.616
- 0.744
- 0.637
- 0.736
- 0.6
- 0.511
- 0.587
- 0.569
- 0.518
- 0.504
- 0.555
- 0.491
- 0.484
- 0.494
- 0.489
- 0.606
- 0.398
- 0.314
- 0.482
- 0.569
- 0.269
- 0.387
- 0.432
- 0.558
- 0.404
- 0.266
- 0.241
unequal: 0
verbose: 1
