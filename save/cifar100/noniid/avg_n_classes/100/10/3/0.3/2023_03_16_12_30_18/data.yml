avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0416
- 0.0996
- 0.117
- 0.1305
- 0.1357
- 0.1505
- 0.1496
- 0.1639
- 0.1657
- 0.1742
- 0.1812
- 0.1832
- 0.1805
- 0.189
- 0.1798
- 0.1976
- 0.199
- 0.2019
- 0.1922
- 0.2011
- 0.2116
- 0.2018
- 0.2024
- 0.1955
- 0.2158
- 0.208
- 0.2178
- 0.2163
- 0.2133
- 0.2228
- 0.2173
- 0.2277
- 0.2203
- 0.2288
- 0.2368
- 0.2361
- 0.2399
- 0.2397
- 0.2415
- 0.2414
- 0.245
- 0.2411
- 0.2463
- 0.248
- 0.2504
- 0.2623
- 0.2472
- 0.2503
- 0.2494
- 0.2478
- 0.2514
- 0.2496
- 0.2477
- 0.2396
- 0.2506
- 0.2528
- 0.254
- 0.2534
- 0.2577
- 0.2569
- 0.2588
- 0.2571
- 0.2578
- 0.2593
- 0.257
- 0.2583
- 0.2566
- 0.2578
- 0.2624
- 0.2653
- 0.2622
- 0.2753
- 0.2655
- 0.2593
- 0.2515
- 0.2636
- 0.2583
- 0.2665
- 0.2642
- 0.2502
- 0.2613
- 0.2624
- 0.2621
- 0.2645
- 0.2594
- 0.2637
- 0.2677
- 0.2679
- 0.2649
- 0.2627
- 0.2557
- 0.2658
- 0.2699
- 0.2588
- 0.2653
- 0.2669
- 0.2676
- 0.2701
- 0.2671
- 0.2752
test_loss_list:
- 1.8592456436157228
- 1.8670876932144165
- 1.887040138244629
- 1.8428521585464477
- 1.8142433595657348
- 1.8423188734054565
- 1.8068260765075683
- 1.7490265941619874
- 1.7307296323776244
- 1.7138902401924134
- 1.7046494460105897
- 1.7513212275505066
- 1.7249672102928162
- 1.700167679786682
- 1.678541669845581
- 1.712669050693512
- 1.746955270767212
- 1.715338146686554
- 1.676194121837616
- 1.7250035333633422
- 1.7526095294952393
- 1.6668785881996155
- 1.619447362422943
- 1.6151945662498475
- 1.6629153490066528
- 1.6098230981826782
- 1.6593680477142334
- 1.637188091278076
- 1.6470177459716797
- 1.689697539806366
- 1.61592693567276
- 1.6006314849853516
- 1.5763072538375855
- 1.5714914321899414
- 1.5653588461875916
- 1.5711094093322755
- 1.639902822971344
- 1.6798920512199402
- 1.6912593531608582
- 1.7194851279258727
- 1.6564351892471314
- 1.631419084072113
- 1.609309356212616
- 1.670303120613098
- 1.6873159766197205
- 1.356009213924408
- 1.4683821487426758
- 1.50495676279068
- 1.5128821063041686
- 1.5358193659782409
- 1.5359185814857483
- 1.5388688254356384
- 1.553665246963501
- 1.4118312430381774
- 1.4393426513671874
- 1.4805280590057373
- 1.5602446246147155
- 1.4827503490447997
- 1.5694143080711365
- 1.5459153819084168
- 1.5336798238754272
- 1.60191725730896
- 1.558116796016693
- 1.6145219016075134
- 1.5767474627494813
- 1.568190062046051
- 1.5772732543945311
- 1.5546111822128297
- 1.6010219955444336
- 1.6362893319129943
- 1.6006941986083985
- 1.3582288527488708
- 1.4866203141212464
- 1.4827147936820984
- 1.466856348514557
- 1.5321431565284729
- 1.507582859992981
- 1.5628291392326354
- 1.5391999626159667
- 1.5246174001693726
- 1.5502533650398254
- 1.5342378973960877
- 1.4923975157737732
- 1.5183978819847106
- 1.4888114428520203
- 1.5601271724700927
- 1.5204681658744812
- 1.5775865006446839
- 1.5367856979370118
- 1.5992854309082032
- 1.5172064399719238
- 1.5061419820785522
- 1.5605242729187012
- 1.5044731140136718
- 1.5022611379623414
- 1.5684956073760987
- 1.5990395307540894
- 1.5502728176116944
- 1.5343398642539978
- 1.535081033706665
train_accuracy:
- 0.079
- 0.141
- 0.176
- 0.147
- 0.169
- 0.189
- 0.223
- 0.0
- 0.0
- 0.212
- 0.222
- 0.231
- 0.214
- 0.285
- 0.0
- 0.329
- 0.266
- 0.0
- 0.0
- 0.297
- 0.273
- 0.0
- 0.0
- 0.0
- 0.325
- 0.0
- 0.336
- 0.256
- 0.272
- 0.296
- 0.267
- 0.0
- 0.0
- 0.0
- 0.3
- 0.285
- 0.32
- 0.315
- 0.295
- 0.335
- 0.0
- 0.369
- 0.318
- 0.333
- 0.347
- 0.0
- 0.304
- 0.334
- 0.307
- 0.0
- 0.361
- 0.385
- 0.364
- 0.0
- 0.0
- 0.0
- 0.347
- 0.313
- 0.362
- 0.335
- 0.397
- 0.4
- 0.0
- 0.352
- 0.328
- 0.325
- 0.0
- 0.316
- 0.334
- 0.309
- 0.0
- 0.0
- 0.361
- 0.0
- 0.0
- 0.352
- 0.393
- 0.378
- 0.377
- 0.382
- 0.304
- 0.323
- 0.0
- 0.0
- 0.36
- 0.368
- 0.0
- 0.397
- 0.39
- 0.403
- 0.305
- 0.294
- 0.384
- 0.0
- 0.319
- 0.357
- 0.384
- 0.374
- 0.339
- 0.0
train_loss:
- 3.298
- 3.503
- 3.171
- 2.765
- 2.52
- 2.792
- 2.431
- 2.043
- 2.217
- 2.204
- 2.107
- 2.306
- 1.914
- 2.039
- 1.633
- 2.269
- 2.187
- 1.764
- 1.488
- 1.754
- 2.038
- 1.541
- 1.537
- 1.425
- 1.742
- 1.363
- 1.524
- 1.438
- 1.227
- 1.593
- 1.363
- 1.496
- 1.201
- 1.248
- 1.49
- 1.2
- 1.213
- 1.146
- 1.239
- 1.153
- 1.168
- 1.051
- 1.217
- 1.122
- 1.094
- 1.157
- 0.906
- 0.964
- 0.935
- 0.95
- 0.853
- 0.848
- 0.86
- 0.905
- 0.838
- 0.851
- 0.832
- 0.893
- 0.769
- 0.696
- 0.781
- 0.571
- 0.738
- 0.631
- 0.657
- 0.617
- 0.554
- 0.751
- 0.634
- 0.559
- 0.658
- 0.819
- 0.525
- 0.625
- 0.589
- 0.5
- 0.544
- 0.511
- 0.462
- 0.533
- 0.574
- 0.482
- 0.622
- 0.452
- 0.546
- 0.423
- 0.481
- 0.379
- 0.421
- 0.29
- 0.64
- 0.508
- 0.39
- 0.586
- 0.43
- 0.35
- 0.317
- 0.401
- 0.406
- 0.413
unequal: 0
verbose: 1
