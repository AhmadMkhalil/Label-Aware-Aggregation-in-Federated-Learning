avg_train_accuracy: 0.414
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0407
- 0.0921
- 0.1197
- 0.1272
- 0.1415
- 0.1363
- 0.158
- 0.1633
- 0.1692
- 0.1615
- 0.178
- 0.1857
- 0.1883
- 0.1894
- 0.1966
- 0.2004
- 0.1952
- 0.2065
- 0.2079
- 0.2118
- 0.2122
- 0.2115
- 0.2166
- 0.2212
- 0.2222
- 0.2226
- 0.2296
- 0.229
- 0.2297
- 0.233
- 0.2302
- 0.2326
- 0.2324
- 0.2348
- 0.2414
- 0.2396
- 0.2347
- 0.2434
- 0.2427
- 0.2417
- 0.2344
- 0.2481
- 0.2489
- 0.2364
- 0.2412
- 0.2491
- 0.2561
- 0.2544
- 0.2575
- 0.2461
- 0.2497
- 0.248
- 0.2553
- 0.2523
- 0.2494
- 0.256
- 0.2603
- 0.2571
- 0.2637
- 0.2571
- 0.2624
- 0.2622
- 0.2685
- 0.2681
- 0.2676
- 0.2601
- 0.2602
- 0.2654
- 0.2644
- 0.258
- 0.2682
- 0.2691
- 0.2687
- 0.2681
- 0.2703
- 0.2714
- 0.2712
- 0.272
- 0.2721
- 0.2691
- 0.2695
- 0.2732
- 0.2699
- 0.2738
- 0.2681
- 0.2691
- 0.2758
- 0.2775
- 0.2767
- 0.2774
- 0.2768
- 0.2691
- 0.275
- 0.2717
- 0.2775
- 0.2727
- 0.2794
- 0.2801
- 0.2738
- 0.2829
test_loss_list:
- 1.8589454126358032
- 1.8806528186798095
- 1.8407242059707642
- 1.8197637271881104
- 1.7981423139572144
- 1.7605411100387574
- 1.7481009197235107
- 1.7530283904075623
- 1.7946631908416748
- 1.7495051288604737
- 1.7069765377044677
- 1.759933180809021
- 1.7235296869277954
- 1.7064185571670532
- 1.756079342365265
- 1.7734025025367737
- 1.7012062549591065
- 1.6740175199508667
- 1.6807621359825133
- 1.6563766551017762
- 1.711509554386139
- 1.673443157672882
- 1.6499683856964111
- 1.6904393076896667
- 1.723062219619751
- 1.689042224884033
- 1.7149325895309449
- 1.6721141934394836
- 1.6354594945907592
- 1.6900657415390015
- 1.653677818775177
- 1.6211466789245605
- 1.6108855128288269
- 1.6677421379089354
- 1.6929714798927307
- 1.6479352331161499
- 1.616215434074402
- 1.669813482761383
- 1.6230280160903932
- 1.6170454144477844
- 1.5651533246040343
- 1.5576151132583618
- 1.555495662689209
- 1.5385106301307678
- 1.4895083451271056
- 1.5278046178817748
- 1.596525831222534
- 1.619037299156189
- 1.6520603799819946
- 1.5800786137580871
- 1.572231538295746
- 1.5667783498764039
- 1.5537041068077087
- 1.6271815228462219
- 1.5604858255386354
- 1.5394337105751037
- 1.5316472864151
- 1.5026508069038391
- 1.5076269626617431
- 1.4675930881500243
- 1.4922862911224366
- 1.5782467675209046
- 1.5873269748687744
- 1.6169273519515992
- 1.645137438774109
- 1.5497945904731751
- 1.5529769086837768
- 1.6026446628570556
- 1.5812963247299194
- 1.5284553480148315
- 1.5331523203849793
- 1.5976776766777039
- 1.6280476140975952
- 1.5704936838150025
- 1.5514594149589538
- 1.6032475233078003
- 1.6402084064483642
- 1.658526005744934
- 1.6738471674919129
- 1.5556478929519653
- 1.5439422917366028
- 1.53381783246994
- 1.528238582611084
- 1.58381831407547
- 1.5520382738113403
- 1.5228120493888855
- 1.5022153759002685
- 1.5064894080162048
- 1.505803532600403
- 1.5623917484283447
- 1.5208191800117492
- 1.493999845981598
- 1.4657341074943542
- 1.5494833612442016
- 1.5150706934928895
- 1.5894237971305847
- 1.588780550956726
- 1.5522736048698424
- 1.5567906928062438
- 1.60216961145401
train_accuracy:
- 0.058
- 0.11
- 0.147
- 0.0
- 0.191
- 0.167
- 0.226
- 0.246
- 0.245
- 0.0
- 0.237
- 0.252
- 0.235
- 0.0
- 0.269
- 0.315
- 0.228
- 0.285
- 0.0
- 0.309
- 0.314
- 0.305
- 0.32
- 0.298
- 0.342
- 0.355
- 0.335
- 0.293
- 0.371
- 0.328
- 0.0
- 0.0
- 0.0
- 0.369
- 0.338
- 0.33
- 0.34
- 0.352
- 0.0
- 0.348
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.374
- 0.351
- 0.353
- 0.377
- 0.0
- 0.367
- 0.347
- 0.0
- 0.353
- 0.358
- 0.382
- 0.0
- 0.378
- 0.334
- 0.395
- 0.382
- 0.35
- 0.382
- 0.368
- 0.376
- 0.0
- 0.346
- 0.408
- 0.387
- 0.0
- 0.402
- 0.361
- 0.388
- 0.0
- 0.0
- 0.355
- 0.402
- 0.362
- 0.382
- 0.0
- 0.42
- 0.363
- 0.0
- 0.368
- 0.381
- 0.0
- 0.406
- 0.374
- 0.364
- 0.386
- 0.0
- 0.0
- 0.0
- 0.367
- 0.402
- 0.408
- 0.382
- 0.404
- 0.403
- 0.414
train_loss:
- 3.339
- 3.476
- 2.776
- 2.583
- 2.509
- 1.942
- 2.412
- 2.214
- 2.528
- 1.976
- 2.134
- 2.41
- 2.089
- 1.914
- 2.062
- 2.164
- 1.7
- 1.904
- 1.74
- 1.773
- 1.911
- 1.729
- 1.616
- 1.716
- 1.661
- 1.411
- 1.725
- 1.527
- 1.458
- 1.4
- 1.403
- 1.331
- 1.259
- 1.278
- 1.321
- 1.116
- 1.196
- 1.075
- 1.284
- 1.061
- 1.193
- 1.194
- 1.144
- 1.009
- 1.086
- 0.991
- 1.018
- 0.936
- 0.839
- 0.996
- 0.877
- 0.891
- 0.844
- 0.707
- 0.871
- 0.787
- 0.842
- 0.812
- 0.824
- 0.806
- 0.697
- 0.666
- 0.638
- 0.702
- 0.6
- 0.879
- 0.701
- 0.524
- 0.593
- 0.714
- 0.606
- 0.469
- 0.439
- 0.562
- 0.664
- 0.484
- 0.4
- 0.349
- 0.332
- 0.744
- 0.574
- 0.659
- 0.455
- 0.45
- 0.569
- 0.482
- 0.514
- 0.463
- 0.577
- 0.331
- 0.435
- 0.574
- 0.521
- 0.3
- 0.373
- 0.316
- 0.325
- 0.389
- 0.337
- 0.224
unequal: 0
verbose: 1
