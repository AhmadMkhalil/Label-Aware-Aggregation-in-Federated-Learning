avg_train_accuracy: 0.427
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0442
- 0.086
- 0.1078
- 0.122
- 0.1219
- 0.1247
- 0.1477
- 0.1509
- 0.1606
- 0.1618
- 0.1418
- 0.1652
- 0.1722
- 0.1763
- 0.1842
- 0.1917
- 0.2006
- 0.2015
- 0.2061
- 0.2074
- 0.199
- 0.2035
- 0.2118
- 0.2113
- 0.2137
- 0.2041
- 0.202
- 0.2243
- 0.2219
- 0.2211
- 0.2221
- 0.2258
- 0.2293
- 0.2285
- 0.2259
- 0.2295
- 0.2318
- 0.2245
- 0.2385
- 0.2394
- 0.2402
- 0.2407
- 0.2411
- 0.2401
- 0.2476
- 0.2436
- 0.2461
- 0.2435
- 0.2446
- 0.245
- 0.2451
- 0.2533
- 0.2503
- 0.2532
- 0.2513
- 0.2569
- 0.2595
- 0.2539
- 0.2559
- 0.256
- 0.2553
- 0.2546
- 0.2483
- 0.2568
- 0.2592
- 0.2632
- 0.2604
- 0.2575
- 0.2577
- 0.2576
- 0.2526
- 0.256
- 0.2589
- 0.2634
- 0.2578
- 0.2605
- 0.2651
- 0.2643
- 0.2643
- 0.2666
- 0.2691
- 0.2615
- 0.2603
- 0.2666
- 0.267
- 0.2637
- 0.2688
- 0.2622
- 0.267
- 0.2659
- 0.2689
- 0.2711
- 0.2667
- 0.2718
- 0.2691
- 0.2625
- 0.2666
- 0.2691
- 0.269
- 0.2729
test_loss_list:
- 1.85241446018219
- 1.8300307989120483
- 1.8156419610977172
- 1.8503533029556274
- 1.7951391172409057
- 1.759759750366211
- 1.7324159812927247
- 1.694041886329651
- 1.762265076637268
- 1.711422073841095
- 1.572151792049408
- 1.6070141577720642
- 1.6341204619407654
- 1.6481434607505798
- 1.6442734837532043
- 1.6503939318656922
- 1.6545602416992187
- 1.651903133392334
- 1.7065864634513854
- 1.670879101753235
- 1.6282836818695068
- 1.6333497834205628
- 1.6848797297477722
- 1.612820930480957
- 1.6023958444595336
- 1.5878384017944336
- 1.5826025104522705
- 1.630328550338745
- 1.6172629737854003
- 1.6245549941062927
- 1.621336154937744
- 1.6729629349708557
- 1.6925448560714722
- 1.6686019420623779
- 1.6336882734298706
- 1.6192025208473206
- 1.6173504781723023
- 1.573884334564209
- 1.6263289475440978
- 1.5932636117935182
- 1.6490868544578552
- 1.672012746334076
- 1.6217480874061585
- 1.6118148183822631
- 1.6567446303367614
- 1.6283597445487976
- 1.6160724091529846
- 1.6142546248435974
- 1.6512209796905517
- 1.6068287873268128
- 1.5920465755462647
- 1.5656566190719605
- 1.5486384868621825
- 1.6174046421051025
- 1.5771470832824708
- 1.5522849225997926
- 1.6130141997337342
- 1.5842429113388061
- 1.6233309864997865
- 1.6551821517944336
- 1.609801151752472
- 1.6500911045074462
- 1.576293590068817
- 1.5513255953788758
- 1.6110001182556153
- 1.6308317160606385
- 1.6591994833946229
- 1.672059497833252
- 1.6122454380989075
- 1.5935806250572204
- 1.5443051648139954
- 1.5442466807365418
- 1.5412033700942993
- 1.5947394490242004
- 1.5159809541702272
- 1.513576054573059
- 1.5725584292411805
- 1.5395487260818481
- 1.6045565986633301
- 1.5493458461761476
- 1.6037769436836242
- 1.5256607246398926
- 1.5353736662864685
- 1.516699299812317
- 1.5824310898780822
- 1.6078691816329955
- 1.5620949387550354
- 1.5142264890670776
- 1.5772990489006042
- 1.5356061148643494
- 1.5209561681747437
- 1.5735255312919616
- 1.6065241050720216
- 1.5408898758888245
- 1.5337304282188415
- 1.5021770310401916
- 1.4916942644119262
- 1.4967024421691895
- 1.4789188694953919
- 1.5471984457969665
train_accuracy:
- 0.071
- 0.153
- 0.0
- 0.179
- 0.0
- 0.0
- 0.0
- 0.0
- 0.257
- 0.0
- 0.0
- 0.239
- 0.225
- 0.291
- 0.243
- 0.0
- 0.255
- 0.0
- 0.34
- 0.316
- 0.0
- 0.269
- 0.338
- 0.291
- 0.0
- 0.0
- 0.0
- 0.316
- 0.323
- 0.305
- 0.31
- 0.356
- 0.322
- 0.342
- 0.0
- 0.0
- 0.319
- 0.0
- 0.342
- 0.314
- 0.328
- 0.302
- 0.37
- 0.324
- 0.379
- 0.341
- 0.406
- 0.38
- 0.4
- 0.351
- 0.0
- 0.0
- 0.386
- 0.367
- 0.343
- 0.385
- 0.35
- 0.394
- 0.363
- 0.404
- 0.0
- 0.35
- 0.0
- 0.404
- 0.401
- 0.387
- 0.35
- 0.42
- 0.346
- 0.363
- 0.0
- 0.0
- 0.368
- 0.401
- 0.0
- 0.42
- 0.39
- 0.39
- 0.372
- 0.416
- 0.4
- 0.393
- 0.356
- 0.422
- 0.399
- 0.361
- 0.0
- 0.37
- 0.409
- 0.369
- 0.388
- 0.395
- 0.406
- 0.0
- 0.0
- 0.0
- 0.406
- 0.411
- 0.424
- 0.427
train_loss:
- 3.294
- 2.909
- 2.864
- 3.067
- 2.163
- 1.963
- 2.447
- 1.944
- 2.475
- 1.682
- 1.484
- 1.852
- 1.997
- 1.825
- 1.917
- 1.884
- 1.743
- 1.987
- 1.992
- 1.766
- 1.521
- 1.531
- 1.918
- 1.591
- 1.516
- 1.157
- 1.031
- 1.834
- 1.405
- 1.259
- 1.485
- 1.28
- 1.399
- 1.054
- 1.28
- 1.246
- 1.259
- 1.165
- 1.376
- 1.215
- 1.127
- 1.148
- 1.269
- 0.996
- 1.157
- 0.922
- 1.07
- 0.971
- 0.773
- 0.873
- 0.807
- 1.159
- 0.986
- 0.827
- 0.828
- 1.009
- 0.889
- 0.71
- 0.729
- 0.616
- 0.76
- 0.569
- 0.865
- 0.687
- 0.676
- 0.594
- 0.545
- 0.622
- 0.692
- 0.742
- 0.883
- 0.624
- 0.57
- 0.528
- 0.736
- 0.562
- 0.553
- 0.643
- 0.476
- 0.517
- 0.384
- 0.667
- 0.707
- 0.521
- 0.407
- 0.42
- 0.523
- 0.666
- 0.337
- 0.483
- 0.455
- 0.382
- 0.29
- 0.448
- 0.427
- 0.539
- 0.42
- 0.45
- 0.422
- 0.298
unequal: 0
verbose: 1
