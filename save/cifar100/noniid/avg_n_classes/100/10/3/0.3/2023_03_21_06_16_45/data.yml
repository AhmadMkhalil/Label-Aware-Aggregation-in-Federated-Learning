avg_train_accuracy: 0.385
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0429
- 0.0968
- 0.1141
- 0.1259
- 0.137
- 0.1481
- 0.1426
- 0.1611
- 0.1704
- 0.1732
- 0.1801
- 0.1832
- 0.1867
- 0.1921
- 0.1994
- 0.1934
- 0.1989
- 0.2053
- 0.2043
- 0.2121
- 0.2156
- 0.2141
- 0.2188
- 0.2222
- 0.2215
- 0.223
- 0.2278
- 0.2299
- 0.2217
- 0.2306
- 0.2325
- 0.2312
- 0.2215
- 0.2399
- 0.2343
- 0.2374
- 0.2428
- 0.2339
- 0.2367
- 0.2433
- 0.2356
- 0.2442
- 0.2422
- 0.2436
- 0.2449
- 0.2471
- 0.251
- 0.2443
- 0.2526
- 0.2573
- 0.255
- 0.2482
- 0.2552
- 0.2566
- 0.2604
- 0.2586
- 0.2598
- 0.2602
- 0.2562
- 0.2641
- 0.2582
- 0.2608
- 0.2616
- 0.2633
- 0.2585
- 0.2588
- 0.2642
- 0.2625
- 0.2638
- 0.2548
- 0.2666
- 0.2595
- 0.2636
- 0.261
- 0.2662
- 0.2609
- 0.2666
- 0.2594
- 0.2683
- 0.2694
- 0.2647
- 0.2694
- 0.2702
- 0.2692
- 0.266
- 0.2717
- 0.27
- 0.2739
- 0.21
- 0.2792
- 0.273
- 0.272
- 0.2648
- 0.2731
- 0.2754
- 0.2754
- 0.2761
- 0.2731
- 0.2765
- 0.2729
test_loss_list:
- 1.8514360666275025
- 1.817265396118164
- 1.7825400447845459
- 1.7820445442199706
- 1.7725058031082153
- 1.7599982833862304
- 1.7311028051376343
- 1.7715949201583863
- 1.8020957946777343
- 1.7720583057403565
- 1.8020063734054566
- 1.820286316871643
- 1.847251296043396
- 1.7977057743072509
- 1.8263722562789917
- 1.7458532667160034
- 1.713590030670166
- 1.7538720655441284
- 1.7065211415290833
- 1.6748952960968018
- 1.6678003406524657
- 1.658732943534851
- 1.6502951645851136
- 1.706196095943451
- 1.6861789512634278
- 1.6626643681526183
- 1.697156310081482
- 1.7420757341384887
- 1.6490528893470764
- 1.6931625366210938
- 1.6654874873161316
- 1.6466362810134887
- 1.6014756989479064
- 1.6612309741973876
- 1.6381778120994568
- 1.624996955394745
- 1.6760717821121216
- 1.5987548422813416
- 1.5896821355819701
- 1.581127440929413
- 1.5555795955657958
- 1.5627029609680176
- 1.6250982570648194
- 1.5826003670692443
- 1.577830355167389
- 1.6362802076339722
- 1.5945213174819945
- 1.5815428686141968
- 1.5720794796943665
- 1.6214587712287902
- 1.5873650813102722
- 1.5839505457878114
- 1.5650441527366639
- 1.544476101398468
- 1.6103204107284546
- 1.6415672349929809
- 1.662341685295105
- 1.6885377812385558
- 1.635967047214508
- 1.6803401350975036
- 1.629254937171936
- 1.6032283973693848
- 1.6632508301734925
- 1.6105588579177856
- 1.592781777381897
- 1.5845564675331116
- 1.5698884558677673
- 1.6426584243774414
- 1.5947503089904784
- 1.5313245248794556
- 1.5325165176391602
- 1.5245496821403504
- 1.5313451862335206
- 1.5601072525978088
- 1.5534347343444823
- 1.4950440621376038
- 1.5601001477241516
- 1.5007100629806518
- 1.551095495223999
- 1.5248540925979615
- 1.517385380268097
- 1.5861607003211975
- 1.5343010878562928
- 1.5172702431678773
- 1.5255836844444275
- 1.5234542894363403
- 1.5046564650535583
- 1.3997225880622863
- 1.5913213181495667
- 1.377263250350952
- 1.4732722973823547
- 1.462544310092926
- 1.4332135653495788
- 1.4442828440666198
- 1.473343997001648
- 1.461147050857544
- 1.475336856842041
- 1.4869687581062316
- 1.4750938081741334
- 1.5342445158958435
train_accuracy:
- 0.049
- 0.0
- 0.142
- 0.186
- 0.0
- 0.208
- 0.0
- 0.251
- 0.197
- 0.0
- 0.276
- 0.269
- 0.265
- 0.249
- 0.262
- 0.0
- 0.268
- 0.318
- 0.0
- 0.269
- 0.238
- 0.0
- 0.295
- 0.309
- 0.298
- 0.338
- 0.356
- 0.298
- 0.0
- 0.326
- 0.371
- 0.0
- 0.0
- 0.318
- 0.31
- 0.322
- 0.33
- 0.303
- 0.0
- 0.322
- 0.0
- 0.0
- 0.297
- 0.331
- 0.0
- 0.337
- 0.0
- 0.344
- 0.0
- 0.349
- 0.0
- 0.326
- 0.321
- 0.348
- 0.273
- 0.36
- 0.353
- 0.348
- 0.347
- 0.418
- 0.351
- 0.303
- 0.368
- 0.345
- 0.352
- 0.0
- 0.0
- 0.367
- 0.414
- 0.0
- 0.366
- 0.0
- 0.0
- 0.35
- 0.0
- 0.0
- 0.343
- 0.0
- 0.365
- 0.0
- 0.352
- 0.364
- 0.0
- 0.35
- 0.0
- 0.0
- 0.435
- 0.0
- 0.0
- 0.37
- 0.307
- 0.0
- 0.416
- 0.355
- 0.3
- 0.0
- 0.0
- 0.392
- 0.379
- 0.385
train_loss:
- 3.294
- 2.906
- 2.288
- 2.667
- 2.457
- 2.555
- 1.945
- 2.69
- 2.668
- 2.146
- 2.417
- 2.342
- 2.298
- 1.912
- 2.212
- 1.813
- 1.883
- 2.022
- 1.887
- 1.746
- 1.584
- 1.639
- 1.768
- 1.763
- 1.395
- 1.516
- 1.705
- 1.421
- 1.5
- 1.482
- 1.282
- 1.32
- 1.256
- 1.679
- 1.274
- 1.172
- 1.411
- 1.249
- 1.105
- 1.109
- 0.992
- 1.022
- 0.896
- 1.18
- 1.157
- 1.041
- 0.918
- 1.007
- 0.971
- 1.125
- 0.803
- 0.782
- 0.901
- 1.009
- 0.772
- 0.875
- 0.724
- 0.798
- 0.765
- 0.706
- 0.809
- 0.743
- 0.578
- 0.722
- 0.643
- 0.602
- 0.688
- 0.653
- 0.705
- 0.814
- 0.685
- 0.688
- 0.617
- 0.589
- 0.649
- 0.739
- 0.348
- 0.646
- 0.486
- 0.535
- 0.502
- 0.462
- 0.604
- 0.46
- 0.577
- 0.514
- 0.444
- 0.704
- 0.503
- 0.423
- 0.311
- 0.505
- 0.463
- 0.396
- 0.394
- 0.374
- 0.339
- 0.58
- 0.406
- 0.325
unequal: 0
verbose: 1
