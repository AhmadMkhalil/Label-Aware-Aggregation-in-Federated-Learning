avg_train_accuracy: 0.36
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0469
- 0.0963
- 0.1152
- 0.1248
- 0.1377
- 0.1483
- 0.1499
- 0.1643
- 0.1689
- 0.1742
- 0.1757
- 0.1786
- 0.1855
- 0.1913
- 0.192
- 0.1961
- 0.1953
- 0.201
- 0.204
- 0.2054
- 0.2071
- 0.2066
- 0.2118
- 0.2103
- 0.2035
- 0.2157
- 0.2187
- 0.2176
- 0.2218
- 0.219
- 0.2195
- 0.2268
- 0.2247
- 0.2275
- 0.2329
- 0.2284
- 0.2319
- 0.2301
- 0.2345
- 0.2315
- 0.2294
- 0.2389
- 0.2401
- 0.2369
- 0.229
- 0.2459
- 0.2425
- 0.2442
- 0.2467
- 0.2466
- 0.2401
- 0.2407
- 0.2473
- 0.245
- 0.2504
- 0.2483
- 0.2426
- 0.2549
- 0.2548
- 0.2534
- 0.2584
- 0.2559
- 0.2511
- 0.2573
- 0.2589
- 0.2566
- 0.2564
- 0.2619
- 0.2636
- 0.2647
- 0.2652
- 0.2549
- 0.2602
- 0.2546
- 0.2631
- 0.2542
- 0.2636
- 0.263
- 0.2627
- 0.2657
- 0.2697
- 0.2708
- 0.27
- 0.2666
- 0.2679
- 0.2676
- 0.2683
- 0.2721
- 0.2619
- 0.2702
- 0.2652
- 0.2607
- 0.2681
- 0.2732
- 0.2676
- 0.2699
- 0.2564
- 0.2698
- 0.2586
- 0.2692
test_loss_list:
- 1.8546429204940795
- 1.8176701307296752
- 1.790784478187561
- 1.7821711778640748
- 1.7784920167922973
- 1.7628855752944945
- 1.8094344663619994
- 1.8285515928268432
- 1.7895034217834473
- 1.7610894083976745
- 1.8009072208404542
- 1.7178274202346802
- 1.7618077611923217
- 1.7905454778671264
- 1.8072659015655517
- 1.7640465211868286
- 1.7383727979660035
- 1.7821694612503052
- 1.73212229013443
- 1.710473883152008
- 1.7462793040275573
- 1.710414628982544
- 1.7473974323272705
- 1.7055172085762025
- 1.6681705188751221
- 1.7085617756843567
- 1.6629033708572387
- 1.712496132850647
- 1.6682801508903504
- 1.6163850545883178
- 1.6217777061462402
- 1.6345745968818663
- 1.632707278728485
- 1.692040331363678
- 1.6529505157470703
- 1.6444217705726623
- 1.6515891861915588
- 1.6670038819313049
- 1.7074327611923217
- 1.737386212348938
- 1.6330207014083862
- 1.7028679466247558
- 1.7133200407028197
- 1.6729259872436524
- 1.6222085380554199
- 1.6462206935882568
- 1.616507613658905
- 1.672732264995575
- 1.624607207775116
- 1.6038418078422547
- 1.570558075904846
- 1.5382971954345703
- 1.5561950206756592
- 1.5226799654960632
- 1.6011717534065246
- 1.5725153851509095
- 1.5751127219200134
- 1.5490031027793885
- 1.5524050903320312
- 1.5567643666267394
- 1.6106191611289977
- 1.640205557346344
- 1.5566132020950318
- 1.5496424174308776
- 1.539985568523407
- 1.535753107070923
- 1.5350686454772948
- 1.5295235586166382
- 1.5369916868209839
- 1.602333083152771
- 1.6230296683311463
- 1.5703845024108887
- 1.526771125793457
- 1.5020593118667602
- 1.57570871591568
- 1.5354050993919373
- 1.5650916957855225
- 1.5435386466979981
- 1.5118411183357239
- 1.5270326495170594
- 1.5176766991615296
- 1.5719805359840393
- 1.6098930358886718
- 1.5654864144325256
- 1.6176662516593934
- 1.5712979626655579
- 1.5419095325469971
- 1.5245063829421996
- 1.4944395732879638
- 1.5123787426948547
- 1.5078732872009277
- 1.4901026511192321
- 1.4959457063674926
- 1.5688976955413818
- 1.6031393241882324
- 1.6238306331634522
- 1.5477616477012635
- 1.5815591096878052
- 1.5045615792274476
- 1.504764130115509
train_accuracy:
- 0.068
- 0.157
- 0.179
- 0.0
- 0.147
- 0.182
- 0.217
- 0.196
- 0.0
- 0.238
- 0.208
- 0.0
- 0.252
- 0.261
- 0.245
- 0.286
- 0.268
- 0.247
- 0.282
- 0.256
- 0.309
- 0.304
- 0.291
- 0.293
- 0.0
- 0.296
- 0.297
- 0.316
- 0.305
- 0.0
- 0.309
- 0.0
- 0.262
- 0.273
- 0.291
- 0.362
- 0.327
- 0.255
- 0.339
- 0.269
- 0.0
- 0.354
- 0.331
- 0.0
- 0.0
- 0.329
- 0.35
- 0.335
- 0.326
- 0.0
- 0.0
- 0.0
- 0.331
- 0.0
- 0.346
- 0.0
- 0.0
- 0.346
- 0.0
- 0.0
- 0.404
- 0.354
- 0.355
- 0.0
- 0.379
- 0.0
- 0.0
- 0.345
- 0.373
- 0.311
- 0.368
- 0.306
- 0.358
- 0.0
- 0.372
- 0.0
- 0.355
- 0.419
- 0.0
- 0.0
- 0.0
- 0.361
- 0.351
- 0.362
- 0.355
- 0.375
- 0.0
- 0.371
- 0.35
- 0.427
- 0.344
- 0.0
- 0.349
- 0.384
- 0.392
- 0.366
- 0.0
- 0.348
- 0.0
- 0.36
train_loss:
- 3.22
- 3.003
- 2.741
- 2.559
- 2.355
- 2.485
- 2.659
- 2.618
- 2.209
- 2.156
- 2.361
- 1.913
- 2.131
- 1.978
- 2.13
- 1.754
- 1.79
- 2.021
- 1.654
- 1.667
- 1.735
- 1.645
- 1.812
- 1.417
- 1.304
- 1.5
- 1.52
- 1.395
- 1.471
- 1.312
- 1.444
- 1.334
- 1.193
- 1.149
- 1.316
- 1.171
- 1.101
- 0.986
- 0.935
- 1.009
- 1.187
- 1.044
- 1.157
- 0.868
- 0.997
- 1.25
- 0.823
- 0.939
- 1.083
- 1.103
- 0.958
- 0.88
- 0.844
- 0.903
- 0.959
- 0.903
- 0.798
- 0.802
- 0.855
- 0.85
- 0.689
- 0.57
- 0.85
- 0.742
- 0.576
- 0.665
- 0.737
- 0.677
- 0.705
- 0.565
- 0.511
- 0.733
- 0.622
- 0.632
- 0.636
- 0.658
- 0.461
- 0.526
- 0.76
- 0.509
- 0.55
- 0.387
- 0.39
- 0.543
- 0.302
- 0.454
- 0.456
- 0.585
- 0.63
- 0.473
- 0.464
- 0.607
- 0.432
- 0.321
- 0.301
- 0.268
- 0.567
- 0.272
- 0.543
- 0.398
unequal: 0
verbose: 1
