avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0296
- 0.0896
- 0.1085
- 0.1221
- 0.1293
- 0.1431
- 0.149
- 0.1543
- 0.1678
- 0.1774
- 0.1853
- 0.1903
- 0.1942
- 0.1967
- 0.2006
- 0.2064
- 0.2134
- 0.2125
- 0.2162
- 0.2236
- 0.2184
- 0.222
- 0.2241
- 0.2265
- 0.2328
- 0.2334
- 0.2357
- 0.235
- 0.2347
- 0.2373
- 0.2247
- 0.2414
- 0.2356
- 0.244
- 0.2419
- 0.2508
- 0.2503
- 0.2472
- 0.2479
- 0.2461
- 0.2505
- 0.2536
- 0.2542
- 0.2537
- 0.2558
- 0.2587
- 0.2643
- 0.2556
- 0.2653
- 0.2597
- 0.2567
- 0.2659
- 0.2553
- 0.2626
- 0.2618
- 0.2644
- 0.2692
- 0.2677
- 0.2687
- 0.2689
- 0.2711
- 0.2671
- 0.2705
- 0.276
- 0.2731
- 0.2726
- 0.2711
- 0.2711
- 0.2696
- 0.2734
- 0.2714
- 0.2696
- 0.2669
- 0.2759
- 0.2759
- 0.2768
- 0.2747
- 0.276
- 0.2822
- 0.2816
- 0.2754
- 0.2813
- 0.2706
- 0.281
- 0.2761
- 0.279
- 0.281
- 0.28
- 0.2802
- 0.2843
- 0.2741
- 0.277
- 0.2798
- 0.2804
- 0.2835
- 0.2733
- 0.282
- 0.2853
- 0.2836
- 0.2771
test_loss_list:
- 1.8679975175857544
- 1.8196838903427124
- 1.8200867986679077
- 1.8031090450286866
- 1.7563719320297242
- 1.7449311709403992
- 1.7414230823516845
- 1.7133900499343873
- 1.7573356175422667
- 1.7891630792617799
- 1.8029544401168822
- 1.7654377365112304
- 1.744832923412323
- 1.7305282759666443
- 1.773752944469452
- 1.7268968176841737
- 1.6893579792976379
- 1.676078715324402
- 1.7247669053077699
- 1.7387478590011596
- 1.7647223353385926
- 1.771933388710022
- 1.723807725906372
- 1.7484425544738769
- 1.702616195678711
- 1.6827041864395142
- 1.664206006526947
- 1.7086311173439026
- 1.6840454316139222
- 1.6588518238067627
- 1.6122654008865356
- 1.6634313368797302
- 1.585647087097168
- 1.5868199968338013
- 1.6052588748931884
- 1.6565841078758239
- 1.6854629826545715
- 1.6464534902572632
- 1.6212216114997864
- 1.6114006781578063
- 1.6009544873237609
- 1.5659042239189147
- 1.5748801970481872
- 1.5638564348220825
- 1.5527998948097228
- 1.5738736581802368
- 1.6159052729606629
- 1.5827966523170471
- 1.560282928943634
- 1.5654339218139648
- 1.5160005354881287
- 1.571810245513916
- 1.5198265981674195
- 1.517823233604431
- 1.5293521976470947
- 1.5262243938446045
- 1.5157184958457948
- 1.5705577158927917
- 1.5433395504951477
- 1.5423906278610229
- 1.6010617756843566
- 1.5553950953483582
- 1.37610533952713
- 1.4124855852127076
- 1.459331841468811
- 1.5250417017936706
- 1.5005710887908936
- 1.5042200040817262
- 1.511347622871399
- 1.5659354686737061
- 1.5377463150024413
- 1.5341359162330628
- 1.4762204909324645
- 1.5510548305511476
- 1.5827094173431397
- 1.5406322288513183
- 1.536208667755127
- 1.3725133514404297
- 1.3955314898490905
- 1.4869893312454223
- 1.4874860525131226
- 1.4699347162246703
- 1.4603957724571228
- 1.516475706100464
- 1.4847674441337586
- 1.4787818217277526
- 1.4915850234031678
- 1.4880853581428528
- 1.5397488379478455
- 1.5693631482124328
- 1.4848218417167665
- 1.4858622574806213
- 1.4854962253570556
- 1.4908095812797546
- 1.5508807015419006
- 1.4749025201797485
- 1.545985836982727
- 1.558002324104309
- 1.5174303722381592
- 1.466622142791748
train_accuracy:
- 0.0
- 0.124
- 0.0
- 0.193
- 0.0
- 0.175
- 0.167
- 0.0
- 0.202
- 0.261
- 0.262
- 0.271
- 0.279
- 0.0
- 0.295
- 0.0
- 0.328
- 0.296
- 0.321
- 0.249
- 0.314
- 0.338
- 0.309
- 0.299
- 0.258
- 0.333
- 0.0
- 0.328
- 0.323
- 0.275
- 0.0
- 0.336
- 0.0
- 0.0
- 0.0
- 0.396
- 0.316
- 0.0
- 0.269
- 0.0
- 0.0
- 0.0
- 0.369
- 0.413
- 0.368
- 0.0
- 0.424
- 0.0
- 0.365
- 0.368
- 0.34
- 0.374
- 0.0
- 0.38
- 0.0
- 0.0
- 0.334
- 0.292
- 0.365
- 0.403
- 0.308
- 0.372
- 0.0
- 0.365
- 0.38
- 0.444
- 0.284
- 0.425
- 0.0
- 0.403
- 0.394
- 0.374
- 0.377
- 0.392
- 0.369
- 0.416
- 0.374
- 0.0
- 0.391
- 0.394
- 0.394
- 0.455
- 0.388
- 0.395
- 0.0
- 0.303
- 0.386
- 0.372
- 0.393
- 0.353
- 0.376
- 0.387
- 0.378
- 0.409
- 0.469
- 0.391
- 0.379
- 0.422
- 0.295
- 0.0
train_loss:
- 2.667
- 3.03
- 2.797
- 2.61
- 2.15
- 2.448
- 2.383
- 1.932
- 2.736
- 2.493
- 2.447
- 2.159
- 2.043
- 2.054
- 2.233
- 1.974
- 1.867
- 1.8
- 1.863
- 1.982
- 1.806
- 1.794
- 1.568
- 1.773
- 1.556
- 1.439
- 1.55
- 1.501
- 1.251
- 1.407
- 1.447
- 1.479
- 1.246
- 1.128
- 1.051
- 1.327
- 1.234
- 1.037
- 1.131
- 1.15
- 0.895
- 1.201
- 0.958
- 1.165
- 1.01
- 1.105
- 0.896
- 0.894
- 1.079
- 0.873
- 0.98
- 1.003
- 0.958
- 0.91
- 0.816
- 0.821
- 0.816
- 0.761
- 0.757
- 0.616
- 0.578
- 0.745
- 0.902
- 0.57
- 0.497
- 0.604
- 0.58
- 0.581
- 0.66
- 0.576
- 0.6
- 0.758
- 0.836
- 0.596
- 0.473
- 0.594
- 0.535
- 0.763
- 0.48
- 0.391
- 0.517
- 0.529
- 0.501
- 0.472
- 0.582
- 0.437
- 0.355
- 0.571
- 0.324
- 0.336
- 0.547
- 0.459
- 0.378
- 0.455
- 0.332
- 0.658
- 0.318
- 0.306
- 0.434
- 0.547
unequal: 0
verbose: 1
