avg_train_accuracy: 0.399
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.046
- 0.0967
- 0.1168
- 0.1272
- 0.1432
- 0.1419
- 0.1585
- 0.1593
- 0.1676
- 0.1717
- 0.173
- 0.1732
- 0.1775
- 0.1892
- 0.1886
- 0.198
- 0.1989
- 0.205
- 0.2022
- 0.2074
- 0.2047
- 0.2112
- 0.2057
- 0.2092
- 0.2172
- 0.2195
- 0.2309
- 0.2221
- 0.2276
- 0.2153
- 0.2264
- 0.2344
- 0.2284
- 0.232
- 0.2341
- 0.231
- 0.2303
- 0.2399
- 0.2416
- 0.2315
- 0.2443
- 0.2347
- 0.2438
- 0.2482
- 0.2408
- 0.2439
- 0.2513
- 0.256
- 0.2545
- 0.2558
- 0.2547
- 0.2556
- 0.2495
- 0.259
- 0.2546
- 0.2557
- 0.2593
- 0.2605
- 0.2643
- 0.2643
- 0.2606
- 0.2616
- 0.2655
- 0.2586
- 0.2651
- 0.2671
- 0.2668
- 0.2662
- 0.2676
- 0.2678
- 0.2664
- 0.2737
- 0.2684
- 0.2726
- 0.2654
- 0.272
- 0.2686
- 0.2709
- 0.2729
- 0.268
- 0.2727
- 0.2722
- 0.2654
- 0.2747
- 0.2761
- 0.2667
- 0.2739
- 0.2554
- 0.2738
- 0.2763
- 0.278
- 0.2742
- 0.271
- 0.2782
- 0.2777
- 0.2725
- 0.281
- 0.275
- 0.2752
- 0.2802
test_loss_list:
- 1.871222233772278
- 1.8842760944366455
- 1.8421874570846557
- 1.870486822128296
- 1.827995638847351
- 1.8046874713897705
- 1.7795772457122803
- 1.772878942489624
- 1.7465808987617493
- 1.7256876015663147
- 1.7208522701263427
- 1.7166931796073914
- 1.6753606796264648
- 1.673068606853485
- 1.651844427585602
- 1.6364026880264282
- 1.635717170238495
- 1.684009644985199
- 1.733223021030426
- 1.6804021167755128
- 1.6231792187690735
- 1.5998024892807008
- 1.5746471405029296
- 1.551429467201233
- 1.5694309282302856
- 1.588114984035492
- 1.639635739326477
- 1.5815663743019104
- 1.6440106678009032
- 1.6040517425537109
- 1.5925048613548278
- 1.5753265738487243
- 1.5919154143333436
- 1.6035864806175233
- 1.5884228229522706
- 1.5928068900108336
- 1.599134635925293
- 1.6546023797988891
- 1.619684042930603
- 1.572608127593994
- 1.545165810585022
- 1.5353453254699707
- 1.5343438148498536
- 1.5281621789932252
- 1.506647171974182
- 1.4851590204238891
- 1.5157299470901489
- 1.5907265973091125
- 1.5609984135627746
- 1.5541802906990052
- 1.5462448024749755
- 1.6107263588905334
- 1.5265683364868163
- 1.530102665424347
- 1.5319098019599915
- 1.5320243382453917
- 1.596999192237854
- 1.5588700890541076
- 1.6041610765457153
- 1.5644148921966552
- 1.5455505776405334
- 1.6037388396263124
- 1.6335275626182557
- 1.5993203949928283
- 1.6392381262779236
- 1.6487839889526368
- 1.6066538763046265
- 1.6447241759300233
- 1.587739007472992
- 1.5575305199623108
- 1.5492406392097473
- 1.6092555928230285
- 1.6276489067077637
- 1.644507474899292
- 1.5414462184906006
- 1.5427571725845337
- 1.503533592224121
- 1.5170165157318116
- 1.5753357815742492
- 1.5341563677787782
- 1.5113726925849915
- 1.579175090789795
- 1.54532053232193
- 1.595085837841034
- 1.6108950138092042
- 1.526682755947113
- 1.59049827337265
- 1.5300312113761902
- 1.5731265568733215
- 1.5334676957130433
- 1.5845407915115357
- 1.5478917932510377
- 1.4814441084861756
- 1.4910624623298645
- 1.4963642692565917
- 1.4669902873039247
- 1.4662556385993957
- 1.4742566895484925
- 1.5444454979896545
- 1.562208459377289
train_accuracy:
- 0.053
- 0.104
- 0.0
- 0.206
- 0.208
- 0.199
- 0.201
- 0.208
- 0.0
- 0.217
- 0.292
- 0.294
- 0.234
- 0.235
- 0.0
- 0.0
- 0.27
- 0.249
- 0.307
- 0.28
- 0.0
- 0.0
- 0.0
- 0.0
- 0.329
- 0.0
- 0.283
- 0.0
- 0.332
- 0.0
- 0.0
- 0.32
- 0.332
- 0.281
- 0.0
- 0.0
- 0.331
- 0.33
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.367
- 0.348
- 0.38
- 0.0
- 0.35
- 0.0
- 0.363
- 0.0
- 0.358
- 0.333
- 0.382
- 0.366
- 0.378
- 0.322
- 0.335
- 0.397
- 0.33
- 0.364
- 0.388
- 0.0
- 0.379
- 0.366
- 0.0
- 0.334
- 0.384
- 0.349
- 0.38
- 0.376
- 0.382
- 0.0
- 0.357
- 0.376
- 0.374
- 0.0
- 0.385
- 0.0
- 0.382
- 0.395
- 0.0
- 0.347
- 0.324
- 0.386
- 0.382
- 0.35
- 0.324
- 0.0
- 0.377
- 0.356
- 0.0
- 0.416
- 0.383
- 0.338
- 0.399
train_loss:
- 4.059
- 3.464
- 2.753
- 3.039
- 2.5
- 2.459
- 2.429
- 2.245
- 2.421
- 2.167
- 2.053
- 2.029
- 1.811
- 1.99
- 1.701
- 1.928
- 1.874
- 2.079
- 1.924
- 1.714
- 1.593
- 1.494
- 1.501
- 1.425
- 1.624
- 1.468
- 1.646
- 1.373
- 1.546
- 1.208
- 1.267
- 1.461
- 1.15
- 1.074
- 1.229
- 1.216
- 1.11
- 1.036
- 1.169
- 1.219
- 1.188
- 0.981
- 1.095
- 1.319
- 1.089
- 1.05
- 0.99
- 0.999
- 0.849
- 1.035
- 0.884
- 0.881
- 0.977
- 0.858
- 0.973
- 0.943
- 0.764
- 0.801
- 0.81
- 0.766
- 0.82
- 0.751
- 0.704
- 0.785
- 0.65
- 0.643
- 0.708
- 0.57
- 0.661
- 0.733
- 0.665
- 0.493
- 0.568
- 0.487
- 0.733
- 0.678
- 0.672
- 0.482
- 0.463
- 0.617
- 0.532
- 0.385
- 0.586
- 0.459
- 0.355
- 0.679
- 0.438
- 0.675
- 0.389
- 0.482
- 0.335
- 0.5
- 0.627
- 0.459
- 0.418
- 0.519
- 0.493
- 0.456
- 0.307
- 0.257
unequal: 0
verbose: 1
