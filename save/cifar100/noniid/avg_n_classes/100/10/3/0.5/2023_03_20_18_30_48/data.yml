avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0313
- 0.0844
- 0.1087
- 0.122
- 0.1361
- 0.1494
- 0.1625
- 0.1678
- 0.1752
- 0.1832
- 0.1862
- 0.1914
- 0.1976
- 0.199
- 0.2061
- 0.2079
- 0.2096
- 0.2152
- 0.2176
- 0.2208
- 0.2212
- 0.2298
- 0.2292
- 0.2321
- 0.2344
- 0.2353
- 0.2351
- 0.242
- 0.2431
- 0.2437
- 0.2453
- 0.2428
- 0.2477
- 0.2473
- 0.2475
- 0.2479
- 0.2552
- 0.2575
- 0.2518
- 0.2587
- 0.2583
- 0.2576
- 0.2602
- 0.2605
- 0.2605
- 0.2601
- 0.2642
- 0.2617
- 0.265
- 0.2654
- 0.268
- 0.2665
- 0.264
- 0.2685
- 0.272
- 0.27
- 0.2672
- 0.2663
- 0.2699
- 0.2722
- 0.2726
- 0.2709
- 0.2724
- 0.273
- 0.2736
- 0.2761
- 0.2714
- 0.2751
- 0.2716
- 0.2753
- 0.2742
- 0.2799
- 0.2771
- 0.2773
- 0.2796
- 0.2791
- 0.2828
- 0.2838
- 0.2843
- 0.2819
- 0.2809
- 0.2838
- 0.2825
- 0.2812
- 0.2811
- 0.2852
- 0.2878
- 0.2803
- 0.2839
- 0.291
- 0.2841
- 0.288
- 0.2856
- 0.2873
- 0.2898
- 0.2857
- 0.289
- 0.2874
- 0.2898
- 0.2899
test_loss_list:
- 1.8500358390808105
- 1.7614029264450073
- 1.7640886306762695
- 1.7608676958084106
- 1.7581313371658325
- 1.7384245920181274
- 1.728241024017334
- 1.7098230385780335
- 1.7593829441070556
- 1.6777594423294067
- 1.630217890739441
- 1.6412490725517273
- 1.6012890505790711
- 1.5822583746910095
- 1.5748298144340516
- 1.6054837894439697
- 1.569717309474945
- 1.5872757196426392
- 1.5956690788269043
- 1.5420979595184325
- 1.563075520992279
- 1.4917082977294922
- 1.5992253184318543
- 1.530468156337738
- 1.6189614605903626
- 1.5886053586006164
- 1.5379702496528624
- 1.557496976852417
- 1.5609116959571838
- 1.549038701057434
- 1.549086992740631
- 1.54794180393219
- 1.495280179977417
- 1.5224263453483582
- 1.534679400920868
- 1.4942950558662416
- 1.5240938091278076
- 1.5213096618652344
- 1.4404029369354248
- 1.478842282295227
- 1.5025161385536194
- 1.5082772254943848
- 1.5866860127449036
- 1.4974741888046266
- 1.454531750679016
- 1.4356005167961121
- 1.539772264957428
- 1.4575493931770325
- 1.4352422904968263
- 1.471873424053192
- 1.4772254943847656
- 1.4421293091773988
- 1.4748331570625306
- 1.4752982401847838
- 1.475880949497223
- 1.431086242198944
- 1.411424114704132
- 1.3810675740242004
- 1.3939088320732116
- 1.3930963587760925
- 1.383238513469696
- 1.3927607393264771
- 1.5006956577301025
- 1.4311613392829896
- 1.4094770336151123
- 1.3878250789642335
- 1.3908752274513245
- 1.4392483520507813
- 1.3984230184555053
- 1.3870616960525513
- 1.4226249647140503
- 1.4447042155265808
- 1.5107396531105042
- 1.4329163575172423
- 1.45408198595047
- 1.3996030688285828
- 1.3908269572257996
- 1.3871873664855956
- 1.377235143184662
- 1.3848923754692077
- 1.4193903374671937
- 1.3776038146018983
- 1.4184872341156005
- 1.362876524925232
- 1.4146702241897584
- 1.4308645725250244
- 1.3931524538993836
- 1.4229463243484497
- 1.3924384641647338
- 1.3448220896720886
- 1.4031122279167176
- 1.4132158041000367
- 1.428360562324524
- 1.4303166246414185
- 1.3648422002792358
- 1.4722378849983215
- 1.3922812151908874
- 1.382474067211151
- 1.4158589768409728
- 1.3915466284751892
train_accuracy:
- 0.05
- 0.0
- 0.129
- 0.179
- 0.195
- 0.204
- 0.208
- 0.0
- 0.232
- 0.22
- 0.223
- 0.25
- 0.287
- 0.243
- 0.251
- 0.231
- 0.255
- 0.284
- 0.265
- 0.278
- 0.235
- 0.268
- 0.289
- 0.293
- 0.261
- 0.0
- 0.0
- 0.29
- 0.327
- 0.307
- 0.316
- 0.0
- 0.0
- 0.339
- 0.346
- 0.0
- 0.0
- 0.298
- 0.0
- 0.306
- 0.323
- 0.304
- 0.307
- 0.0
- 0.349
- 0.348
- 0.314
- 0.331
- 0.336
- 0.313
- 0.319
- 0.0
- 0.305
- 0.318
- 0.0
- 0.345
- 0.0
- 0.379
- 0.325
- 0.308
- 0.324
- 0.0
- 0.318
- 0.348
- 0.0
- 0.0
- 0.364
- 0.359
- 0.357
- 0.0
- 0.332
- 0.362
- 0.357
- 0.342
- 0.339
- 0.37
- 0.0
- 0.348
- 0.337
- 0.344
- 0.378
- 0.378
- 0.326
- 0.0
- 0.377
- 0.0
- 0.349
- 0.346
- 0.376
- 0.0
- 0.0
- 0.331
- 0.378
- 0.0
- 0.357
- 0.342
- 0.352
- 0.34
- 0.341
- 0.0
train_loss:
- 3.54
- 2.47
- 2.99
- 2.817
- 2.664
- 2.544
- 2.53
- 2.464
- 2.489
- 2.035
- 2.081
- 2.085
- 1.912
- 1.86
- 1.805
- 1.958
- 1.722
- 1.834
- 1.758
- 1.621
- 1.706
- 1.412
- 1.728
- 1.443
- 1.643
- 1.483
- 1.314
- 1.406
- 1.437
- 1.439
- 1.276
- 1.313
- 1.254
- 1.269
- 1.221
- 1.105
- 1.163
- 1.182
- 1.053
- 1.087
- 1.067
- 1.04
- 1.044
- 0.96
- 0.942
- 0.916
- 0.927
- 0.888
- 0.841
- 0.819
- 0.825
- 0.831
- 0.777
- 0.796
- 0.795
- 0.738
- 0.716
- 0.69
- 0.687
- 0.625
- 0.696
- 0.685
- 0.646
- 0.697
- 0.636
- 0.604
- 0.626
- 0.589
- 0.555
- 0.587
- 0.525
- 0.493
- 0.52
- 0.552
- 0.451
- 0.548
- 0.503
- 0.491
- 0.475
- 0.476
- 0.446
- 0.447
- 0.437
- 0.472
- 0.392
- 0.419
- 0.391
- 0.415
- 0.391
- 0.41
- 0.333
- 0.333
- 0.364
- 0.315
- 0.422
- 0.296
- 0.363
- 0.386
- 0.322
- 0.349
unequal: 0
verbose: 1
