avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.039
- 0.0975
- 0.1179
- 0.1317
- 0.147
- 0.1533
- 0.1623
- 0.1719
- 0.177
- 0.1818
- 0.1833
- 0.1923
- 0.196
- 0.1936
- 0.2006
- 0.2047
- 0.2107
- 0.2122
- 0.2152
- 0.2217
- 0.2215
- 0.2284
- 0.2269
- 0.2285
- 0.2354
- 0.237
- 0.2352
- 0.2401
- 0.2392
- 0.2416
- 0.2408
- 0.2458
- 0.2477
- 0.2468
- 0.2495
- 0.2518
- 0.2522
- 0.2561
- 0.2536
- 0.257
- 0.2581
- 0.2596
- 0.2566
- 0.2601
- 0.2592
- 0.2634
- 0.2595
- 0.2655
- 0.2654
- 0.261
- 0.2641
- 0.2642
- 0.2662
- 0.2653
- 0.2673
- 0.2678
- 0.2691
- 0.2696
- 0.2709
- 0.2709
- 0.2698
- 0.272
- 0.2716
- 0.2757
- 0.2766
- 0.2739
- 0.2754
- 0.2771
- 0.2769
- 0.2741
- 0.2791
- 0.279
- 0.2774
- 0.275
- 0.2816
- 0.2826
- 0.2862
- 0.2826
- 0.2851
- 0.2817
- 0.2828
- 0.2814
- 0.2785
- 0.281
- 0.2802
- 0.2821
- 0.2869
- 0.2846
- 0.2829
- 0.2887
- 0.284
- 0.2855
- 0.2842
- 0.2887
- 0.2887
- 0.2913
- 0.2909
- 0.2911
- 0.2856
- 0.2882
test_loss_list:
- 1.8245779275894165
- 1.7872944068908692
- 1.7831879758834839
- 1.7248367977142334
- 1.6814884042739868
- 1.656536786556244
- 1.6733307790756227
- 1.6382246947288512
- 1.6579935574531555
- 1.6572821164131164
- 1.621219801902771
- 1.6371072101593018
- 1.5916379690170288
- 1.5732332730293275
- 1.5507162141799926
- 1.5748195838928223
- 1.5803018140792846
- 1.5383696603775023
- 1.514987246990204
- 1.6019727849960328
- 1.540542504787445
- 1.5536973142623902
- 1.4894636178016663
- 1.4880857372283935
- 1.5192744374275207
- 1.5288883686065673
- 1.4983596515655517
- 1.5819223260879516
- 1.5096964263916015
- 1.5173684453964233
- 1.479630982875824
- 1.5087815356254577
- 1.5231382155418396
- 1.4677064061164855
- 1.4439363312721252
- 1.4754423999786377
- 1.4514928221702577
- 1.4675989151000977
- 1.4411292934417725
- 1.4209664463996887
- 1.5187555432319642
- 1.4922954416275025
- 1.4974216103553772
- 1.4940776538848877
- 1.4948994731903076
- 1.4452218723297119
- 1.4808680152893066
- 1.4781906342506408
- 1.4374893069267274
- 1.3947068667411804
- 1.5045367193222046
- 1.4414055490493773
- 1.5287867927551269
- 1.563919358253479
- 1.4335642528533936
- 1.4628540062904358
- 1.4237818336486816
- 1.4572415804862977
- 1.527746591567993
- 1.4476282572746277
- 1.4294286227226258
- 1.4200745415687561
- 1.4250793504714965
- 1.414498782157898
- 1.4041979265213014
- 1.495399341583252
- 1.424989688396454
- 1.4088769245147705
- 1.4383434319496156
- 1.4560734486579896
- 1.4076063513755799
- 1.3900290155410766
- 1.3785637855529784
- 1.3544637513160707
- 1.3587410378456115
- 1.359669406414032
- 1.3566717958450318
- 1.4064325976371765
- 1.3772056770324708
- 1.4715124106407165
- 1.4486798405647279
- 1.514793231487274
- 1.4225949430465699
- 1.365839602947235
- 1.4143630528450013
- 1.3852361631393433
- 1.4185140347480774
- 1.384179139137268
- 1.416812801361084
- 1.3826358032226562
- 1.4808264803886413
- 1.4015602087974548
- 1.4237502455711364
- 1.3898730707168578
- 1.3773479175567627
- 1.3651366329193115
- 1.4060588669776917
- 1.3812576889991761
- 1.408112223148346
- 1.3761547803878784
train_accuracy:
- 0.046
- 0.15
- 0.0
- 0.0
- 0.0
- 0.0
- 0.192
- 0.177
- 0.263
- 0.218
- 0.23
- 0.281
- 0.233
- 0.253
- 0.226
- 0.291
- 0.269
- 0.263
- 0.0
- 0.264
- 0.309
- 0.0
- 0.27
- 0.277
- 0.35
- 0.29
- 0.305
- 0.366
- 0.288
- 0.374
- 0.301
- 0.313
- 0.34
- 0.299
- 0.331
- 0.348
- 0.309
- 0.317
- 0.0
- 0.33
- 0.336
- 0.0
- 0.304
- 0.0
- 0.0
- 0.334
- 0.311
- 0.35
- 0.36
- 0.0
- 0.365
- 0.0
- 0.38
- 0.351
- 0.0
- 0.375
- 0.398
- 0.376
- 0.42
- 0.343
- 0.0
- 0.347
- 0.387
- 0.0
- 0.366
- 0.344
- 0.342
- 0.363
- 0.372
- 0.341
- 0.37
- 0.372
- 0.0
- 0.0
- 0.0
- 0.381
- 0.0
- 0.392
- 0.0
- 0.372
- 0.0
- 0.366
- 0.393
- 0.0
- 0.0
- 0.0
- 0.443
- 0.0
- 0.372
- 0.0
- 0.367
- 0.424
- 0.383
- 0.365
- 0.0
- 0.371
- 0.428
- 0.0
- 0.384
- 0.0
train_loss:
- 3.087
- 3.149
- 2.934
- 2.507
- 2.367
- 2.297
- 2.492
- 2.105
- 2.301
- 2.309
- 2.033
- 2.124
- 1.888
- 1.816
- 1.739
- 2.01
- 1.915
- 1.628
- 1.643
- 1.903
- 1.529
- 1.663
- 1.393
- 1.468
- 1.556
- 1.521
- 1.366
- 1.537
- 1.292
- 1.298
- 1.234
- 1.285
- 1.275
- 1.185
- 1.091
- 1.172
- 1.062
- 1.136
- 1.047
- 1.002
- 1.058
- 1.031
- 1.018
- 0.999
- 0.972
- 0.878
- 0.863
- 0.897
- 0.879
- 0.833
- 0.834
- 0.788
- 0.821
- 0.761
- 0.787
- 0.742
- 0.72
- 0.661
- 0.69
- 0.686
- 0.622
- 0.607
- 0.621
- 0.581
- 0.627
- 0.615
- 0.606
- 0.548
- 0.576
- 0.548
- 0.555
- 0.51
- 0.563
- 0.523
- 0.531
- 0.478
- 0.487
- 0.448
- 0.446
- 0.427
- 0.414
- 0.402
- 0.487
- 0.475
- 0.386
- 0.395
- 0.383
- 0.437
- 0.372
- 0.375
- 0.314
- 0.417
- 0.358
- 0.375
- 0.386
- 0.331
- 0.306
- 0.342
- 0.343
- 0.319
unequal: 0
verbose: 1
