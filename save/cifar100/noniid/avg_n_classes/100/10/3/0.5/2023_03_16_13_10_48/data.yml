avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0409
- 0.0936
- 0.1111
- 0.1247
- 0.1363
- 0.1482
- 0.1537
- 0.1625
- 0.169
- 0.1771
- 0.1786
- 0.1864
- 0.1911
- 0.1952
- 0.1979
- 0.2054
- 0.2049
- 0.2102
- 0.2139
- 0.216
- 0.2196
- 0.2179
- 0.2224
- 0.2235
- 0.2292
- 0.2279
- 0.2323
- 0.2301
- 0.2363
- 0.2357
- 0.2399
- 0.2417
- 0.2419
- 0.245
- 0.2437
- 0.251
- 0.2498
- 0.2498
- 0.255
- 0.2512
- 0.2566
- 0.2594
- 0.2556
- 0.259
- 0.2563
- 0.2564
- 0.2615
- 0.264
- 0.264
- 0.2659
- 0.2654
- 0.264
- 0.2647
- 0.2663
- 0.2664
- 0.2674
- 0.2676
- 0.2681
- 0.2678
- 0.2702
- 0.2697
- 0.2706
- 0.2722
- 0.2731
- 0.2755
- 0.2729
- 0.2779
- 0.2737
- 0.2715
- 0.2758
- 0.2766
- 0.2748
- 0.2767
- 0.2802
- 0.2829
- 0.2797
- 0.2816
- 0.2786
- 0.2762
- 0.2781
- 0.28
- 0.28
- 0.2824
- 0.2828
- 0.2813
- 0.2818
- 0.2836
- 0.2799
- 0.2842
- 0.2852
- 0.2883
- 0.2882
- 0.2848
- 0.2842
- 0.2824
- 0.2806
- 0.2876
- 0.2916
- 0.2905
- 0.2897
test_loss_list:
- 1.8412775230407714
- 1.7819751071929932
- 1.7433075904846191
- 1.7495421075820923
- 1.7107012224197389
- 1.7077979063987732
- 1.7050872373580932
- 1.6617923521995543
- 1.6770254921913148
- 1.690370671749115
- 1.636348602771759
- 1.6414129829406738
- 1.6423230600357055
- 1.5988111305236816
- 1.6095519804954528
- 1.6140458750724793
- 1.5793789315223694
- 1.5531159877777099
- 1.5772085690498352
- 1.5479851841926575
- 1.5266688942909241
- 1.5689650082588196
- 1.5700305891036987
- 1.5728877902030944
- 1.5717190551757811
- 1.5739414691925049
- 1.526199493408203
- 1.554078996181488
- 1.5153550982475281
- 1.548480100631714
- 1.472936601638794
- 1.5125845432281495
- 1.5260772347450255
- 1.5295189428329468
- 1.5361599564552306
- 1.5346554923057556
- 1.5956105422973632
- 1.6267312240600587
- 1.5838823556900024
- 1.5299419713020326
- 1.536574249267578
- 1.5004169869422912
- 1.4501119089126586
- 1.480420367717743
- 1.4501829218864442
- 1.4814585590362548
- 1.4510627794265747
- 1.4430205607414246
- 1.4853368639945983
- 1.4392424845695495
- 1.486763060092926
- 1.4524393367767334
- 1.475357439517975
- 1.4027622938156128
- 1.5133467841148376
- 1.4509992790222168
- 1.4725434923171996
- 1.440655562877655
- 1.4644232058525086
- 1.4219516682624818
- 1.4613149404525756
- 1.4707433295249939
- 1.4757453751564027
- 1.4005113291740416
- 1.4555034995079041
- 1.4716841673851013
- 1.4181640863418579
- 1.4076100492477417
- 1.4484399366378784
- 1.4148951196670532
- 1.4428794693946838
- 1.5150995755195618
- 1.4320706295967103
- 1.454207830429077
- 1.4102714514732362
- 1.4150130152702332
- 1.3957070851325988
- 1.4289411902427673
- 1.5020681095123292
- 1.4352510237693787
- 1.4033730220794678
- 1.4330841875076294
- 1.3935371017456055
- 1.361897780895233
- 1.4204281401634216
- 1.4325584554672242
- 1.4047272968292237
- 1.4933600521087647
- 1.4295604538917541
- 1.4048181891441345
- 1.3967677450180054
- 1.385884521007538
- 1.4219422674179076
- 1.4322657585144043
- 1.4382333803176879
- 1.445246353149414
- 1.3784470605850219
- 1.3798637986183167
- 1.374992187023163
- 1.3715702390670776
train_accuracy:
- 0.071
- 0.133
- 0.137
- 0.131
- 0.0
- 0.216
- 0.0
- 0.229
- 0.221
- 0.0
- 0.249
- 0.245
- 0.202
- 0.0
- 0.277
- 0.319
- 0.0
- 0.317
- 0.336
- 0.0
- 0.227
- 0.293
- 0.287
- 0.287
- 0.297
- 0.0
- 0.0
- 0.305
- 0.361
- 0.251
- 0.0
- 0.296
- 0.308
- 0.37
- 0.378
- 0.38
- 0.32
- 0.316
- 0.287
- 0.0
- 0.296
- 0.0
- 0.0
- 0.0
- 0.336
- 0.311
- 0.403
- 0.339
- 0.323
- 0.35
- 0.329
- 0.425
- 0.311
- 0.407
- 0.334
- 0.0
- 0.0
- 0.325
- 0.352
- 0.414
- 0.344
- 0.351
- 0.357
- 0.353
- 0.363
- 0.353
- 0.441
- 0.0
- 0.0
- 0.429
- 0.0
- 0.357
- 0.413
- 0.359
- 0.359
- 0.337
- 0.0
- 0.423
- 0.317
- 0.365
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.366
- 0.357
- 0.0
- 0.369
- 0.442
- 0.374
- 0.366
- 0.372
- 0.336
- 0.321
- 0.0
- 0.327
- 0.0
train_loss:
- 3.105
- 2.778
- 2.672
- 2.855
- 2.476
- 2.573
- 2.541
- 2.15
- 2.356
- 2.275
- 2.077
- 2.094
- 2.117
- 1.872
- 2.05
- 1.896
- 1.668
- 1.741
- 1.824
- 1.636
- 1.566
- 1.663
- 1.655
- 1.665
- 1.529
- 1.495
- 1.376
- 1.484
- 1.37
- 1.325
- 1.245
- 1.359
- 1.285
- 1.22
- 1.254
- 1.184
- 1.231
- 1.221
- 1.121
- 1.076
- 1.07
- 0.993
- 0.962
- 1.089
- 1.015
- 0.963
- 0.934
- 0.879
- 0.876
- 0.905
- 0.807
- 0.782
- 0.809
- 0.813
- 0.781
- 0.767
- 0.753
- 0.769
- 0.745
- 0.722
- 0.659
- 0.672
- 0.638
- 0.673
- 0.609
- 0.6
- 0.644
- 0.611
- 0.608
- 0.538
- 0.559
- 0.519
- 0.534
- 0.494
- 0.522
- 0.493
- 0.515
- 0.475
- 0.449
- 0.487
- 0.457
- 0.421
- 0.449
- 0.448
- 0.45
- 0.389
- 0.414
- 0.399
- 0.388
- 0.414
- 0.355
- 0.406
- 0.368
- 0.365
- 0.357
- 0.359
- 0.406
- 0.33
- 0.382
- 0.332
unequal: 0
verbose: 1
