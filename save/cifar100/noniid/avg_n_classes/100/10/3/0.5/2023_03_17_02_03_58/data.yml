avg_train_accuracy: 0.345
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0509
- 0.1032
- 0.121
- 0.1332
- 0.142
- 0.1527
- 0.1601
- 0.1662
- 0.1704
- 0.1791
- 0.184
- 0.1845
- 0.1903
- 0.1948
- 0.1985
- 0.1995
- 0.2025
- 0.2062
- 0.2097
- 0.209
- 0.2122
- 0.214
- 0.2134
- 0.2146
- 0.2194
- 0.2218
- 0.2196
- 0.227
- 0.2315
- 0.2298
- 0.2301
- 0.2326
- 0.2346
- 0.2338
- 0.2353
- 0.238
- 0.2386
- 0.2402
- 0.241
- 0.2413
- 0.2419
- 0.2408
- 0.246
- 0.2492
- 0.2461
- 0.2455
- 0.2474
- 0.2477
- 0.2524
- 0.2507
- 0.2504
- 0.2516
- 0.2501
- 0.2504
- 0.2523
- 0.252
- 0.2544
- 0.2527
- 0.2544
- 0.2552
- 0.2551
- 0.2588
- 0.2604
- 0.2605
- 0.2632
- 0.2588
- 0.2586
- 0.2617
- 0.2593
- 0.263
- 0.2654
- 0.2669
- 0.263
- 0.2649
- 0.2611
- 0.2612
- 0.2666
- 0.2668
- 0.2644
- 0.2694
- 0.272
- 0.2694
- 0.2691
- 0.2675
- 0.2729
- 0.2723
- 0.2688
- 0.2653
- 0.271
- 0.2756
- 0.2783
- 0.2711
- 0.2706
- 0.2716
- 0.2775
- 0.2766
- 0.2784
- 0.2735
- 0.2754
- 0.2709
test_loss_list:
- 1.867385654449463
- 1.7941267585754395
- 1.8305402421951293
- 1.7333879923820497
- 1.6974586677551269
- 1.7088866019248963
- 1.6667480635643006
- 1.679853925704956
- 1.6388912439346313
- 1.579752631187439
- 1.6208380556106567
- 1.6405321097373962
- 1.6402763605117798
- 1.6328076028823852
- 1.589914813041687
- 1.609144697189331
- 1.613041479587555
- 1.6696081972122192
- 1.5927479267120361
- 1.603690776824951
- 1.6047555351257323
- 1.5536195373535155
- 1.5778772449493408
- 1.516076021194458
- 1.503023660182953
- 1.540718605518341
- 1.562370069026947
- 1.55957617521286
- 1.5603280806541442
- 1.570409734249115
- 1.5213972187042237
- 1.504337728023529
- 1.4873145318031311
- 1.480826141834259
- 1.4814334535598754
- 1.4735368752479554
- 1.465483901500702
- 1.4615513610839843
- 1.4980373620986938
- 1.4721321535110474
- 1.5023802137374878
- 1.4418766045570373
- 1.4883297538757325
- 1.5037818813323975
- 1.4747493529319764
- 1.5004690408706665
- 1.4625422835350037
- 1.4926479363441467
- 1.4995897173881532
- 1.5147859954833984
- 1.5286428761482238
- 1.487710840702057
- 1.5169455409049988
- 1.4690242624282837
- 1.560437226295471
- 1.4493162655830383
- 1.4356853175163269
- 1.4275157642364502
- 1.463492124080658
- 1.4825651717185975
- 1.482448329925537
- 1.4156857490539552
- 1.393432512283325
- 1.4445674300193787
- 1.39235102891922
- 1.446156256198883
- 1.4582868862152099
- 1.529270133972168
- 1.4527339506149293
- 1.4254559993743896
- 1.415746750831604
- 1.4611701893806457
- 1.4778847432136535
- 1.4302673816680909
- 1.5185859847068786
- 1.407156116962433
- 1.4505276155471802
- 1.4185384941101074
- 1.4577612113952636
- 1.414177689552307
- 1.4061217427253723
- 1.4114718961715698
- 1.3776732182502747
- 1.3941445207595826
- 1.4025756645202636
- 1.4050449132919312
- 1.3908637380599975
- 1.4923011422157288
- 1.4178497695922851
- 1.3752500772476197
- 1.3938040041923523
- 1.432793502807617
- 1.4504238891601562
- 1.4213083863258362
- 1.4160022234916687
- 1.4565961360931396
- 1.4285419154167176
- 1.414711492061615
- 1.4452784156799316
- 1.518903799057007
train_accuracy:
- 0.059
- 0.089
- 0.115
- 0.186
- 0.163
- 0.223
- 0.171
- 0.243
- 0.195
- 0.193
- 0.0
- 0.208
- 0.265
- 0.23
- 0.222
- 0.0
- 0.223
- 0.315
- 0.314
- 0.302
- 0.289
- 0.248
- 0.0
- 0.248
- 0.322
- 0.0
- 0.314
- 0.271
- 0.0
- 0.26
- 0.291
- 0.0
- 0.0
- 0.0
- 0.362
- 0.0
- 0.335
- 0.292
- 0.29
- 0.0
- 0.33
- 0.0
- 0.355
- 0.361
- 0.318
- 0.314
- 0.0
- 0.0
- 0.386
- 0.0
- 0.347
- 0.343
- 0.0
- 0.0
- 0.338
- 0.0
- 0.0
- 0.345
- 0.326
- 0.0
- 0.353
- 0.0
- 0.336
- 0.384
- 0.362
- 0.32
- 0.325
- 0.332
- 0.0
- 0.0
- 0.359
- 0.322
- 0.317
- 0.41
- 0.393
- 0.0
- 0.335
- 0.354
- 0.336
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.357
- 0.0
- 0.402
- 0.0
- 0.401
- 0.0
- 0.0
- 0.353
- 0.344
- 0.328
- 0.396
- 0.409
- 0.0
- 0.346
- 0.345
train_loss:
- 4.047
- 2.831
- 3.231
- 2.291
- 2.395
- 2.542
- 2.313
- 2.456
- 2.098
- 1.881
- 2.213
- 2.116
- 2.119
- 2.137
- 1.871
- 2.002
- 1.885
- 1.971
- 1.667
- 1.719
- 1.756
- 1.506
- 1.616
- 1.344
- 1.509
- 1.559
- 1.555
- 1.52
- 1.44
- 1.322
- 1.344
- 1.261
- 1.216
- 1.197
- 1.136
- 1.192
- 1.158
- 1.076
- 1.153
- 1.033
- 1.024
- 0.942
- 1.054
- 1.005
- 0.981
- 1.049
- 0.938
- 0.945
- 0.889
- 0.889
- 0.883
- 0.857
- 0.833
- 0.815
- 0.764
- 0.765
- 0.837
- 0.675
- 0.763
- 0.693
- 0.733
- 0.704
- 0.642
- 0.701
- 0.647
- 0.61
- 0.62
- 0.588
- 0.616
- 0.594
- 0.545
- 0.537
- 0.492
- 0.568
- 0.488
- 0.585
- 0.481
- 0.502
- 0.432
- 0.506
- 0.499
- 0.447
- 0.492
- 0.42
- 0.441
- 0.405
- 0.452
- 0.35
- 0.459
- 0.435
- 0.396
- 0.365
- 0.359
- 0.385
- 0.376
- 0.334
- 0.348
- 0.388
- 0.361
- 0.304
unequal: 0
verbose: 1
