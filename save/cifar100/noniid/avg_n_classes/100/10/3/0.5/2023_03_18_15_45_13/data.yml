avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0402
- 0.0976
- 0.1134
- 0.1295
- 0.1388
- 0.1495
- 0.1508
- 0.157
- 0.1674
- 0.1726
- 0.176
- 0.1782
- 0.1854
- 0.1888
- 0.1924
- 0.1956
- 0.199
- 0.197
- 0.2047
- 0.2091
- 0.2105
- 0.2128
- 0.2145
- 0.2169
- 0.2189
- 0.2167
- 0.2237
- 0.2249
- 0.2258
- 0.2265
- 0.2318
- 0.2303
- 0.2336
- 0.2315
- 0.2365
- 0.2403
- 0.2385
- 0.2399
- 0.2463
- 0.2434
- 0.2425
- 0.2441
- 0.2434
- 0.2465
- 0.2485
- 0.2526
- 0.2536
- 0.2513
- 0.2562
- 0.2539
- 0.2566
- 0.2566
- 0.2573
- 0.2573
- 0.2553
- 0.2554
- 0.2551
- 0.2625
- 0.2614
- 0.2609
- 0.267
- 0.2615
- 0.2654
- 0.2716
- 0.2697
- 0.2685
- 0.2674
- 0.2711
- 0.2707
- 0.2661
- 0.2676
- 0.2657
- 0.2689
- 0.2714
- 0.2707
- 0.2736
- 0.2705
- 0.2718
- 0.2709
- 0.274
- 0.2776
- 0.2772
- 0.2792
- 0.276
- 0.2824
- 0.2781
- 0.2777
- 0.2784
- 0.2764
- 0.2773
- 0.2754
- 0.2802
- 0.2794
- 0.2772
- 0.2801
- 0.2802
- 0.2778
- 0.28
- 0.2799
- 0.2779
test_loss_list:
- 1.8301514768600464
- 1.7702794790267944
- 1.7448016262054444
- 1.7558305597305297
- 1.7143444085121156
- 1.723880398273468
- 1.6905805277824402
- 1.6981047868728638
- 1.6922266006469726
- 1.6833244681358337
- 1.686451759338379
- 1.6458979415893555
- 1.6028132343292236
- 1.580285108089447
- 1.6126474404335023
- 1.5815111017227172
- 1.5609510254859924
- 1.5201845574378967
- 1.5297684121131896
- 1.5552635192871094
- 1.5771088004112244
- 1.5330808210372924
- 1.5596366262435912
- 1.566486315727234
- 1.5665426874160766
- 1.4999397110939026
- 1.595267994403839
- 1.532043068408966
- 1.5101027512550353
- 1.470311107635498
- 1.517650578022003
- 1.541392138004303
- 1.5009828543663024
- 1.478787558078766
- 1.468494246006012
- 1.5044276189804078
- 1.4719064354896545
- 1.5075093221664428
- 1.5732145643234252
- 1.5507934522628783
- 1.4881581854820252
- 1.4704590582847594
- 1.4524625086784362
- 1.4891942405700684
- 1.4500606083869934
- 1.4421462774276734
- 1.4758510875701905
- 1.446134502887726
- 1.4010963916778565
- 1.4577280282974243
- 1.429787712097168
- 1.4284112334251404
- 1.4292667412757873
- 1.5246260595321655
- 1.4985965490341187
- 1.4510787653923034
- 1.4774657773971558
- 1.4871128869056702
- 1.4329545211791992
- 1.4620152378082276
- 1.474464795589447
- 1.4315886521339416
- 1.4172646594047547
- 1.4123497939109801
- 1.4159620571136475
- 1.4594112277030944
- 1.4180346322059632
- 1.4539195442199706
- 1.4285785484313964
- 1.5078905463218688
- 1.4430661487579346
- 1.3976085472106934
- 1.408152756690979
- 1.4478873467445375
- 1.4212525224685668
- 1.4405650472640992
- 1.4567831182479858
- 1.4178442978858947
- 1.3988372230529784
- 1.4378532934188843
- 1.4006596207618713
- 1.3709578037261962
- 1.3802610063552856
- 1.382655966281891
- 1.383399784564972
- 1.3834785413742066
- 1.3838834691047668
- 1.4203556871414185
- 1.403339147567749
- 1.439030773639679
- 1.443908052444458
- 1.4082770204544068
- 1.4384299468994142
- 1.4452918076515198
- 1.4401089310646058
- 1.4035957264900207
- 1.4875262331962587
- 1.4552905082702636
- 1.5151215171813965
- 1.4331513404846192
train_accuracy:
- 0.06
- 0.142
- 0.0
- 0.186
- 0.0
- 0.206
- 0.0
- 0.0
- 0.241
- 0.276
- 0.265
- 0.255
- 0.264
- 0.271
- 0.251
- 0.0
- 0.0
- 0.0
- 0.0
- 0.289
- 0.266
- 0.323
- 0.328
- 0.311
- 0.347
- 0.321
- 0.333
- 0.0
- 0.0
- 0.0
- 0.338
- 0.0
- 0.0
- 0.0
- 0.0
- 0.324
- 0.367
- 0.0
- 0.333
- 0.33
- 0.345
- 0.347
- 0.0
- 0.0
- 0.348
- 0.358
- 0.388
- 0.0
- 0.0
- 0.356
- 0.0
- 0.0
- 0.346
- 0.348
- 0.0
- 0.349
- 0.375
- 0.403
- 0.381
- 0.0
- 0.0
- 0.0
- 0.389
- 0.416
- 0.0
- 0.361
- 0.401
- 0.0
- 0.378
- 0.372
- 0.394
- 0.0
- 0.0
- 0.369
- 0.4
- 0.387
- 0.362
- 0.37
- 0.37
- 0.394
- 0.376
- 0.401
- 0.36
- 0.0
- 0.387
- 0.384
- 0.0
- 0.394
- 0.392
- 0.384
- 0.366
- 0.0
- 0.382
- 0.38
- 0.0
- 0.429
- 0.417
- 0.367
- 0.392
- 0.0
train_loss:
- 3.122
- 2.804
- 2.583
- 2.755
- 2.394
- 2.529
- 2.201
- 2.459
- 2.389
- 2.295
- 2.192
- 1.894
- 1.942
- 1.866
- 1.94
- 1.766
- 1.726
- 1.523
- 1.628
- 1.805
- 1.694
- 1.568
- 1.617
- 1.629
- 1.515
- 1.257
- 1.66
- 1.305
- 1.388
- 1.202
- 1.338
- 1.348
- 1.261
- 1.232
- 1.141
- 1.169
- 1.129
- 1.114
- 1.199
- 1.054
- 1.109
- 1.033
- 1.054
- 1.052
- 0.902
- 0.914
- 0.928
- 0.907
- 0.812
- 0.921
- 0.866
- 0.836
- 0.77
- 0.882
- 0.845
- 0.803
- 0.783
- 0.767
- 0.754
- 0.672
- 0.66
- 0.74
- 0.648
- 0.613
- 0.593
- 0.596
- 0.686
- 0.554
- 0.576
- 0.58
- 0.596
- 0.564
- 0.553
- 0.483
- 0.51
- 0.562
- 0.522
- 0.536
- 0.474
- 0.485
- 0.492
- 0.49
- 0.463
- 0.451
- 0.438
- 0.395
- 0.448
- 0.384
- 0.371
- 0.409
- 0.412
- 0.366
- 0.37
- 0.379
- 0.366
- 0.405
- 0.313
- 0.335
- 0.294
- 0.379
unequal: 0
verbose: 1
