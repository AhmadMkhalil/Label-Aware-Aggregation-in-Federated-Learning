avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0456
- 0.0972
- 0.1089
- 0.1249
- 0.1346
- 0.142
- 0.1506
- 0.1561
- 0.1666
- 0.1692
- 0.1744
- 0.1763
- 0.1828
- 0.1886
- 0.1926
- 0.1949
- 0.1947
- 0.2011
- 0.2052
- 0.2049
- 0.2078
- 0.2123
- 0.218
- 0.2202
- 0.2232
- 0.2247
- 0.2287
- 0.227
- 0.2246
- 0.2301
- 0.2329
- 0.2293
- 0.2313
- 0.2346
- 0.2365
- 0.2354
- 0.233
- 0.2405
- 0.2408
- 0.239
- 0.2459
- 0.2456
- 0.2403
- 0.2437
- 0.2502
- 0.2512
- 0.2508
- 0.2481
- 0.25
- 0.249
- 0.2545
- 0.2536
- 0.2547
- 0.2533
- 0.2568
- 0.2591
- 0.2597
- 0.2557
- 0.255
- 0.2598
- 0.2593
- 0.2621
- 0.257
- 0.2599
- 0.2619
- 0.2608
- 0.2612
- 0.2623
- 0.2634
- 0.2601
- 0.2631
- 0.2652
- 0.2634
- 0.2648
- 0.2633
- 0.2681
- 0.2688
- 0.2654
- 0.2672
- 0.2667
- 0.2661
- 0.267
- 0.272
- 0.2719
- 0.2694
- 0.2718
- 0.2681
- 0.2697
- 0.2711
- 0.2726
- 0.2698
- 0.2702
- 0.2698
- 0.2708
- 0.2691
- 0.2726
- 0.269
- 0.2699
- 0.2723
- 0.2724
test_loss_list:
- 1.8348312282562256
- 1.796668701171875
- 1.7306825017929077
- 1.687271864414215
- 1.6498008584976196
- 1.6872367215156556
- 1.665376546382904
- 1.7403863263130188
- 1.777596402168274
- 1.7400824618339539
- 1.6826371383666991
- 1.613864402770996
- 1.6412538862228394
- 1.6058244347572326
- 1.588732192516327
- 1.6169322085380555
- 1.5554310750961304
- 1.5817970657348632
- 1.5605386400222778
- 1.5892238688468934
- 1.6004125356674195
- 1.5568655681610108
- 1.5327625894546508
- 1.6203746604919433
- 1.6630374145507814
- 1.6245257115364076
- 1.5641798186302185
- 1.5367525982856751
- 1.523029110431671
- 1.5567237663269042
- 1.512970986366272
- 1.4976655840873718
- 1.4809108090400696
- 1.5212106442451476
- 1.5915467143058777
- 1.571377799510956
- 1.57071035861969
- 1.6302624034881592
- 1.5878609800338745
- 1.5407605910301208
- 1.6149670839309693
- 1.5880499053001405
- 1.530782971382141
- 1.4993064427375793
- 1.5380704402923584
- 1.467166256904602
- 1.4655215334892273
- 1.4644959259033203
- 1.4658072400093078
- 1.5630051803588867
- 1.4991718173027038
- 1.4400205159187316
- 1.479372160434723
- 1.4532937502861023
- 1.4429238843917847
- 1.4766665840148925
- 1.4508979940414428
- 1.439457321166992
- 1.402169749736786
- 1.463622922897339
- 1.4343446707725525
- 1.425513527393341
- 1.4351585078239442
- 1.4246156096458436
- 1.468113467693329
- 1.4470774817466736
- 1.4123892283439636
- 1.4621693658828736
- 1.4242816424369813
- 1.4198606419563293
- 1.456954412460327
- 1.4734168815612794
- 1.481756854057312
- 1.4789534878730775
- 1.4605066180229187
- 1.4875151467323304
- 1.4964303636550904
- 1.518343880176544
- 1.5091765642166137
- 1.4587092638015746
- 1.4831851720809937
- 1.4510325193405151
- 1.4000033736228943
- 1.4533948850631715
- 1.4692213726043701
- 1.4312447834014892
- 1.4164096546173095
- 1.4536851525306702
- 1.4246526765823364
- 1.3866699576377868
- 1.4464846801757814
- 1.515745425224304
- 1.551939947605133
- 1.4555156898498536
- 1.4339268159866334
- 1.4228609228134155
- 1.51372798204422
- 1.4439246153831482
- 1.4652620887756347
- 1.4266033554077149
train_accuracy:
- 0.051
- 0.166
- 0.17
- 0.165
- 0.0
- 0.186
- 0.171
- 0.2
- 0.257
- 0.193
- 0.27
- 0.253
- 0.235
- 0.21
- 0.0
- 0.214
- 0.0
- 0.248
- 0.0
- 0.31
- 0.0
- 0.283
- 0.291
- 0.265
- 0.267
- 0.0
- 0.0
- 0.266
- 0.269
- 0.258
- 0.334
- 0.257
- 0.326
- 0.277
- 0.293
- 0.265
- 0.307
- 0.347
- 0.361
- 0.0
- 0.301
- 0.0
- 0.295
- 0.284
- 0.305
- 0.0
- 0.0
- 0.0
- 0.305
- 0.366
- 0.372
- 0.372
- 0.285
- 0.0
- 0.301
- 0.28
- 0.379
- 0.286
- 0.0
- 0.369
- 0.325
- 0.38
- 0.0
- 0.319
- 0.375
- 0.389
- 0.0
- 0.0
- 0.38
- 0.0
- 0.373
- 0.346
- 0.331
- 0.282
- 0.373
- 0.0
- 0.378
- 0.385
- 0.323
- 0.39
- 0.0
- 0.309
- 0.0
- 0.347
- 0.332
- 0.381
- 0.312
- 0.35
- 0.0
- 0.0
- 0.344
- 0.334
- 0.405
- 0.0
- 0.0
- 0.385
- 0.288
- 0.0
- 0.338
- 0.0
train_loss:
- 3.174
- 3.174
- 2.366
- 2.222
- 2.172
- 2.564
- 2.219
- 2.608
- 2.493
- 2.182
- 2.015
- 1.815
- 2.089
- 1.92
- 1.813
- 1.956
- 1.548
- 1.818
- 1.599
- 1.875
- 1.594
- 1.566
- 1.497
- 1.809
- 1.654
- 1.525
- 1.443
- 1.358
- 1.295
- 1.299
- 1.352
- 1.251
- 1.201
- 1.199
- 1.257
- 1.188
- 1.132
- 1.135
- 1.116
- 1.053
- 1.107
- 0.928
- 1.02
- 0.9
- 0.959
- 0.936
- 0.852
- 0.845
- 0.789
- 0.908
- 0.892
- 0.794
- 0.879
- 0.803
- 0.71
- 0.865
- 0.761
- 0.653
- 0.723
- 0.807
- 0.676
- 0.722
- 0.67
- 0.647
- 0.644
- 0.633
- 0.586
- 0.604
- 0.55
- 0.605
- 0.535
- 0.485
- 0.567
- 0.512
- 0.482
- 0.475
- 0.485
- 0.418
- 0.464
- 0.498
- 0.49
- 0.442
- 0.51
- 0.421
- 0.434
- 0.487
- 0.462
- 0.425
- 0.452
- 0.438
- 0.362
- 0.345
- 0.339
- 0.394
- 0.437
- 0.392
- 0.301
- 0.354
- 0.314
- 0.411
unequal: 0
verbose: 1
