avg_train_accuracy: 0.354
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0374
- 0.0996
- 0.1154
- 0.1346
- 0.143
- 0.1553
- 0.1637
- 0.1679
- 0.1738
- 0.1814
- 0.1849
- 0.1857
- 0.1908
- 0.1985
- 0.1967
- 0.2035
- 0.2072
- 0.2128
- 0.2143
- 0.2184
- 0.2209
- 0.222
- 0.2247
- 0.2244
- 0.2289
- 0.2372
- 0.2323
- 0.2338
- 0.2407
- 0.243
- 0.2451
- 0.243
- 0.2476
- 0.2471
- 0.2497
- 0.2525
- 0.2578
- 0.2575
- 0.2547
- 0.2546
- 0.2547
- 0.2588
- 0.2574
- 0.258
- 0.2624
- 0.2594
- 0.2613
- 0.2646
- 0.2645
- 0.2658
- 0.2624
- 0.2652
- 0.2656
- 0.2595
- 0.2658
- 0.2655
- 0.2679
- 0.2654
- 0.2675
- 0.2683
- 0.273
- 0.2696
- 0.2719
- 0.2719
- 0.2684
- 0.2708
- 0.2714
- 0.2744
- 0.2726
- 0.2709
- 0.2709
- 0.2723
- 0.2741
- 0.276
- 0.2735
- 0.2767
- 0.2768
- 0.2747
- 0.2723
- 0.2785
- 0.2788
- 0.2768
- 0.277
- 0.2818
- 0.2821
- 0.2848
- 0.2794
- 0.2803
- 0.2855
- 0.2816
- 0.2814
- 0.2805
- 0.2803
- 0.2807
- 0.283
- 0.2777
- 0.2856
- 0.2817
- 0.2815
- 0.2868
test_loss_list:
- 1.8272108507156373
- 1.7585843467712403
- 1.758925290107727
- 1.752598433494568
- 1.708853485584259
- 1.707865743637085
- 1.668117163181305
- 1.6417039513587952
- 1.6585393929481507
- 1.6637874579429626
- 1.6622870635986329
- 1.6286123919487
- 1.5867945194244384
- 1.5998168540000917
- 1.5729276394844056
- 1.5884261727333069
- 1.5537671875953674
- 1.5376442241668702
- 1.6220227766036988
- 1.5653316688537597
- 1.573798475265503
- 1.566174488067627
- 1.5257554149627686
- 1.504127004146576
- 1.4921804189682006
- 1.480628650188446
- 1.440923547744751
- 1.4230656385421754
- 1.4860102319717408
- 1.5044130206108093
- 1.5170837187767028
- 1.4804739785194396
- 1.4664133167266846
- 1.4553352546691896
- 1.4402361583709717
- 1.4755186104774476
- 1.4818902182579041
- 1.4539948320388794
- 1.439420120716095
- 1.4845158004760741
- 1.4539975118637085
- 1.430098190307617
- 1.4708239102363587
- 1.4778150606155396
- 1.484626634120941
- 1.4499751234054565
- 1.470666263103485
- 1.434305112361908
- 1.4254839086532594
- 1.403940770626068
- 1.411295256614685
- 1.4142453002929687
- 1.4548733282089232
- 1.4259671664237976
- 1.4501398038864135
- 1.425660219192505
- 1.4427512168884278
- 1.4586399102210998
- 1.5274544668197632
- 1.4927386164665222
- 1.485202305316925
- 1.4320705366134643
- 1.421539785861969
- 1.5149699306488038
- 1.4394275093078612
- 1.5254974627494813
- 1.5575213050842285
- 1.574888072013855
- 1.5987922382354736
- 1.5010869550704955
- 1.455279836654663
- 1.4891105890274048
- 1.4230544877052307
- 1.4046370387077332
- 1.5070446348190307
- 1.4809364771842957
- 1.477639272212982
- 1.4713235211372375
- 1.3921771883964538
- 1.4345586013793945
- 1.4141474175453186
- 1.4287384533882141
- 1.3977146577835082
- 1.38952712059021
- 1.3854800796508788
- 1.4242225885391235
- 1.4374215960502625
- 1.366213982105255
- 1.3705649089813232
- 1.4216248416900634
- 1.4400415754318237
- 1.3969178986549378
- 1.4288035035133362
- 1.4331279063224793
- 1.4455173087120057
- 1.4517913961410522
- 1.4079957795143128
- 1.429552881717682
- 1.4394922542572022
- 1.4475772047042847
train_accuracy:
- 0.056
- 0.128
- 0.0
- 0.197
- 0.0
- 0.203
- 0.214
- 0.0
- 0.22
- 0.297
- 0.258
- 0.0
- 0.245
- 0.258
- 0.239
- 0.272
- 0.28
- 0.247
- 0.272
- 0.0
- 0.329
- 0.0
- 0.292
- 0.28
- 0.0
- 0.311
- 0.314
- 0.0
- 0.275
- 0.387
- 0.322
- 0.0
- 0.353
- 0.346
- 0.336
- 0.302
- 0.0
- 0.293
- 0.0
- 0.395
- 0.323
- 0.359
- 0.348
- 0.366
- 0.345
- 0.302
- 0.0
- 0.336
- 0.0
- 0.34
- 0.408
- 0.0
- 0.392
- 0.0
- 0.322
- 0.365
- 0.374
- 0.327
- 0.415
- 0.357
- 0.365
- 0.372
- 0.356
- 0.379
- 0.41
- 0.414
- 0.421
- 0.369
- 0.363
- 0.33
- 0.418
- 0.383
- 0.389
- 0.363
- 0.364
- 0.335
- 0.0
- 0.0
- 0.0
- 0.369
- 0.338
- 0.366
- 0.0
- 0.335
- 0.373
- 0.351
- 0.367
- 0.36
- 0.377
- 0.0
- 0.0
- 0.415
- 0.0
- 0.0
- 0.377
- 0.425
- 0.376
- 0.348
- 0.348
- 0.354
train_loss:
- 3.161
- 2.799
- 2.946
- 2.746
- 2.391
- 2.634
- 2.263
- 2.201
- 2.377
- 2.322
- 2.205
- 1.986
- 1.978
- 2.048
- 1.805
- 1.964
- 1.681
- 1.686
- 1.951
- 1.591
- 1.696
- 1.672
- 1.534
- 1.43
- 1.432
- 1.428
- 1.273
- 1.195
- 1.46
- 1.427
- 1.375
- 1.189
- 1.188
- 1.206
- 1.114
- 1.264
- 1.182
- 1.082
- 1.04
- 1.028
- 1.033
- 0.996
- 1.015
- 0.957
- 0.984
- 0.975
- 0.941
- 0.878
- 0.856
- 0.826
- 0.77
- 0.777
- 0.775
- 0.819
- 0.826
- 0.726
- 0.776
- 0.704
- 0.723
- 0.739
- 0.678
- 0.708
- 0.619
- 0.619
- 0.619
- 0.567
- 0.58
- 0.543
- 0.564
- 0.644
- 0.587
- 0.532
- 0.558
- 0.508
- 0.46
- 0.469
- 0.431
- 0.492
- 0.524
- 0.457
- 0.454
- 0.46
- 0.511
- 0.433
- 0.404
- 0.401
- 0.455
- 0.49
- 0.42
- 0.39
- 0.387
- 0.431
- 0.366
- 0.358
- 0.327
- 0.364
- 0.361
- 0.356
- 0.332
- 0.313
unequal: 0
verbose: 1
