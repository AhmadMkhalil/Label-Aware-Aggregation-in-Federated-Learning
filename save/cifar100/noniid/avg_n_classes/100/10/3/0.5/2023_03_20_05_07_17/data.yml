avg_train_accuracy: 0.355
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0382
- 0.0931
- 0.1173
- 0.1304
- 0.1428
- 0.1484
- 0.1568
- 0.1608
- 0.1677
- 0.1731
- 0.1789
- 0.1833
- 0.186
- 0.1898
- 0.1927
- 0.1993
- 0.2032
- 0.2028
- 0.2064
- 0.2096
- 0.2148
- 0.2127
- 0.2152
- 0.2142
- 0.2119
- 0.222
- 0.2238
- 0.225
- 0.2192
- 0.229
- 0.228
- 0.2299
- 0.2292
- 0.2319
- 0.235
- 0.2371
- 0.2355
- 0.2379
- 0.2394
- 0.2368
- 0.241
- 0.2424
- 0.2449
- 0.2463
- 0.2475
- 0.2491
- 0.2476
- 0.2489
- 0.2544
- 0.2525
- 0.2505
- 0.2534
- 0.2497
- 0.2505
- 0.254
- 0.2574
- 0.261
- 0.2588
- 0.2625
- 0.2595
- 0.2576
- 0.263
- 0.2621
- 0.2594
- 0.2614
- 0.2657
- 0.264
- 0.2633
- 0.2609
- 0.2662
- 0.2659
- 0.2664
- 0.2631
- 0.2635
- 0.2675
- 0.2674
- 0.2651
- 0.2668
- 0.2697
- 0.2668
- 0.2714
- 0.2709
- 0.2685
- 0.2657
- 0.2689
- 0.2698
- 0.2679
- 0.2698
- 0.2684
- 0.2683
- 0.2716
- 0.2696
- 0.274
- 0.2762
- 0.2773
- 0.2716
- 0.2788
- 0.2744
- 0.2751
- 0.2783
test_loss_list:
- 1.835892038345337
- 1.7643016433715821
- 1.7341753339767456
- 1.7096949625015259
- 1.7271729516983032
- 1.662554452419281
- 1.6868839597702026
- 1.690347421169281
- 1.6522876977920533
- 1.663716266155243
- 1.666962778568268
- 1.6643521189689636
- 1.6207096934318543
- 1.587102041244507
- 1.607643985748291
- 1.574168357849121
- 1.597571632862091
- 1.598087031841278
- 1.6068757843971253
- 1.5687640714645386
- 1.5836887383460998
- 1.5426582860946656
- 1.5715298748016358
- 1.5443260884284973
- 1.5013283920288085
- 1.4611477279663085
- 1.5202332949638366
- 1.506595163345337
- 1.468647882938385
- 1.4718535685539245
- 1.4464454603195191
- 1.462015643119812
- 1.4415136742591859
- 1.49450617313385
- 1.5143375778198243
- 1.4829100799560546
- 1.4659555268287658
- 1.5024214172363282
- 1.5122016286849975
- 1.4840617728233338
- 1.4671500945091247
- 1.4597535610198975
- 1.490905363559723
- 1.4573328399658203
- 1.4448297381401063
- 1.443293912410736
- 1.408380262851715
- 1.4242571997642517
- 1.4182429432868957
- 1.4210955929756164
- 1.4342534065246582
- 1.5319692969322205
- 1.4644815635681152
- 1.4893893361091615
- 1.4911249232292176
- 1.4937409687042236
- 1.4512364101409911
- 1.4081936573982239
- 1.456002128124237
- 1.438031268119812
- 1.4748177790641785
- 1.4130976629257201
- 1.410132222175598
- 1.512718346118927
- 1.444565598964691
- 1.4721855306625367
- 1.4064990592002868
- 1.4454178142547607
- 1.4209519290924073
- 1.4525463485717773
- 1.4663200402259826
- 1.424463324546814
- 1.518614773750305
- 1.4535986495018005
- 1.426157262325287
- 1.512455129623413
- 1.4835811185836791
- 1.4840287232398988
- 1.483665895462036
- 1.4405222511291504
- 1.4642440962791443
- 1.5325262808799744
- 1.504846978187561
- 1.4961795139312744
- 1.4416103553771973
- 1.4192994523048401
- 1.414402232170105
- 1.5126313138008118
- 1.5479350471496582
- 1.4550339221954345
- 1.4757903504371643
- 1.4306899881362916
- 1.5221936678886414
- 1.4517046856880187
- 1.3951615858078004
- 1.4444926595687866
- 1.4190647673606873
- 1.4529096388816833
- 1.4542741775512695
- 1.4584261870384216
train_accuracy:
- 0.0
- 0.104
- 0.13
- 0.0
- 0.0
- 0.0
- 0.0
- 0.248
- 0.251
- 0.206
- 0.232
- 0.252
- 0.273
- 0.0
- 0.277
- 0.233
- 0.296
- 0.241
- 0.297
- 0.31
- 0.268
- 0.257
- 0.28
- 0.318
- 0.298
- 0.282
- 0.329
- 0.317
- 0.34
- 0.0
- 0.351
- 0.0
- 0.0
- 0.352
- 0.343
- 0.337
- 0.0
- 0.311
- 0.0
- 0.327
- 0.319
- 0.309
- 0.329
- 0.292
- 0.322
- 0.0
- 0.0
- 0.365
- 0.0
- 0.346
- 0.0
- 0.338
- 0.377
- 0.0
- 0.348
- 0.299
- 0.334
- 0.334
- 0.338
- 0.348
- 0.372
- 0.333
- 0.34
- 0.326
- 0.332
- 0.319
- 0.0
- 0.378
- 0.0
- 0.326
- 0.0
- 0.322
- 0.341
- 0.374
- 0.0
- 0.343
- 0.371
- 0.341
- 0.352
- 0.342
- 0.368
- 0.359
- 0.348
- 0.378
- 0.376
- 0.347
- 0.0
- 0.322
- 0.38
- 0.0
- 0.38
- 0.359
- 0.331
- 0.348
- 0.0
- 0.326
- 0.0
- 0.399
- 0.328
- 0.355
train_loss:
- 3.158
- 2.774
- 2.589
- 2.484
- 2.644
- 2.097
- 2.465
- 2.438
- 2.112
- 2.214
- 2.235
- 2.159
- 1.849
- 1.901
- 2.013
- 1.749
- 1.957
- 1.875
- 1.753
- 1.598
- 1.8
- 1.56
- 1.624
- 1.427
- 1.277
- 1.349
- 1.509
- 1.365
- 1.151
- 1.385
- 1.123
- 1.187
- 1.159
- 1.296
- 1.284
- 1.178
- 1.131
- 1.093
- 1.24
- 1.111
- 1.049
- 1.078
- 1.028
- 1.025
- 0.939
- 0.958
- 0.833
- 0.843
- 0.945
- 0.875
- 0.819
- 0.883
- 0.762
- 0.786
- 0.873
- 0.804
- 0.792
- 0.719
- 0.743
- 0.643
- 0.678
- 0.703
- 0.704
- 0.659
- 0.657
- 0.673
- 0.599
- 0.64
- 0.568
- 0.565
- 0.629
- 0.551
- 0.517
- 0.534
- 0.529
- 0.507
- 0.513
- 0.491
- 0.545
- 0.511
- 0.458
- 0.455
- 0.485
- 0.449
- 0.443
- 0.462
- 0.407
- 0.396
- 0.35
- 0.45
- 0.379
- 0.421
- 0.359
- 0.417
- 0.426
- 0.367
- 0.385
- 0.349
- 0.333
- 0.338
unequal: 0
verbose: 1
