avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0425
- 0.0954
- 0.1142
- 0.1279
- 0.1357
- 0.1454
- 0.1577
- 0.1618
- 0.1691
- 0.1699
- 0.1759
- 0.1765
- 0.1868
- 0.1877
- 0.1974
- 0.1978
- 0.2049
- 0.2047
- 0.2074
- 0.2105
- 0.2151
- 0.2175
- 0.2171
- 0.2162
- 0.224
- 0.2251
- 0.2261
- 0.2288
- 0.2323
- 0.2338
- 0.2345
- 0.2356
- 0.2353
- 0.2407
- 0.2386
- 0.2472
- 0.2451
- 0.2433
- 0.2463
- 0.246
- 0.2479
- 0.2502
- 0.2504
- 0.2511
- 0.2508
- 0.252
- 0.2549
- 0.2521
- 0.2541
- 0.258
- 0.255
- 0.259
- 0.257
- 0.2585
- 0.2582
- 0.2595
- 0.2612
- 0.2618
- 0.262
- 0.2645
- 0.2662
- 0.2681
- 0.2641
- 0.265
- 0.2683
- 0.2664
- 0.2668
- 0.2717
- 0.2727
- 0.2687
- 0.2679
- 0.2695
- 0.2722
- 0.2736
- 0.2748
- 0.2743
- 0.274
- 0.274
- 0.2763
- 0.2731
- 0.2729
- 0.2757
- 0.2772
- 0.2749
- 0.2756
- 0.2742
- 0.2759
- 0.276
- 0.2758
- 0.281
- 0.2778
- 0.2818
- 0.2791
- 0.2794
- 0.2803
- 0.2787
- 0.2799
- 0.2783
- 0.2823
- 0.278
test_loss_list:
- 1.824200234413147
- 1.835760178565979
- 1.7732494163513184
- 1.7658206605911255
- 1.6871061849594116
- 1.7130487060546875
- 1.7221381568908691
- 1.7325167012214662
- 1.737118537425995
- 1.6533725905418395
- 1.6342305660247802
- 1.6583007597923278
- 1.6256225419044494
- 1.6454421949386597
- 1.6580171608924865
- 1.6072872734069825
- 1.5751911616325378
- 1.5532981324195863
- 1.5491678547859191
- 1.54647784948349
- 1.5711781072616577
- 1.5418506121635438
- 1.5313367342948914
- 1.5641921043395997
- 1.5677810406684876
- 1.5780390453338624
- 1.5770143938064576
- 1.5784491682052613
- 1.5724278473854065
- 1.532835569381714
- 1.5513090920448303
- 1.553429238796234
- 1.50781183719635
- 1.5334746313095093
- 1.498564865589142
- 1.5197454905509948
- 1.5306202006340026
- 1.6016661739349365
- 1.5728770661354066
- 1.5082903146743774
- 1.534419298171997
- 1.531169753074646
- 1.5328999948501587
- 1.4914323997497558
- 1.470594458580017
- 1.5033755540847777
- 1.510638053417206
- 1.4360954570770263
- 1.4873373770713807
- 1.4959120297431945
- 1.457374074459076
- 1.4879872441291808
- 1.458874990940094
- 1.4419314289093017
- 1.5429697227478028
- 1.4694735407829285
- 1.4434221863746644
- 1.4796055340766907
- 1.4908043456077575
- 1.557241952419281
- 1.4772604084014893
- 1.491607518196106
- 1.457646517753601
- 1.4037141609191894
- 1.407512378692627
- 1.4098094916343689
- 1.459292073249817
- 1.434007966518402
- 1.4634503388404847
- 1.483128352165222
- 1.4324003648757935
- 1.470355336666107
- 1.4749058866500855
- 1.4441472840309144
- 1.4751349043846131
- 1.4833223700523377
- 1.4451007175445556
- 1.4121168780326843
- 1.455782527923584
- 1.3931696176528932
- 1.5074326610565185
- 1.4818299865722657
- 1.4315889596939086
- 1.4485662746429444
- 1.4156587409973145
- 1.5134637236595154
- 1.4369234776496886
- 1.4573007035255432
- 1.393555326461792
- 1.3949292659759522
- 1.398865644931793
- 1.386506757736206
- 1.3928453373908996
- 1.385571916103363
- 1.3899022817611695
- 1.4259361362457275
- 1.436015980243683
- 1.4190734887123109
- 1.4003749513626098
- 1.3792554140090942
train_accuracy:
- 0.041
- 0.181
- 0.202
- 0.15
- 0.0
- 0.211
- 0.244
- 0.191
- 0.203
- 0.0
- 0.0
- 0.309
- 0.0
- 0.0
- 0.283
- 0.261
- 0.254
- 0.279
- 0.0
- 0.331
- 0.0
- 0.298
- 0.366
- 0.0
- 0.344
- 0.316
- 0.31
- 0.299
- 0.325
- 0.366
- 0.312
- 0.0
- 0.363
- 0.0
- 0.0
- 0.383
- 0.32
- 0.34
- 0.349
- 0.0
- 0.299
- 0.306
- 0.32
- 0.0
- 0.363
- 0.363
- 0.381
- 0.36
- 0.334
- 0.335
- 0.341
- 0.334
- 0.317
- 0.0
- 0.405
- 0.374
- 0.355
- 0.358
- 0.34
- 0.346
- 0.0
- 0.0
- 0.0
- 0.0
- 0.344
- 0.384
- 0.424
- 0.355
- 0.369
- 0.394
- 0.0
- 0.431
- 0.374
- 0.0
- 0.414
- 0.401
- 0.0
- 0.0
- 0.405
- 0.0
- 0.361
- 0.377
- 0.389
- 0.353
- 0.354
- 0.372
- 0.0
- 0.361
- 0.367
- 0.0
- 0.354
- 0.366
- 0.35
- 0.382
- 0.382
- 0.0
- 0.369
- 0.419
- 0.411
- 0.0
train_loss:
- 3.163
- 3.569
- 2.677
- 2.829
- 2.228
- 2.601
- 2.528
- 2.466
- 2.387
- 1.969
- 2.078
- 2.219
- 1.957
- 2.159
- 2.016
- 1.878
- 1.823
- 1.766
- 1.695
- 1.675
- 1.857
- 1.635
- 1.52
- 1.675
- 1.586
- 1.611
- 1.627
- 1.544
- 1.492
- 1.315
- 1.519
- 1.389
- 1.243
- 1.372
- 1.271
- 1.255
- 1.208
- 1.264
- 1.118
- 1.125
- 1.212
- 1.14
- 1.101
- 1.01
- 1.04
- 1.026
- 0.975
- 0.896
- 0.911
- 0.881
- 0.896
- 0.911
- 0.766
- 0.864
- 0.811
- 0.798
- 0.769
- 0.738
- 0.826
- 0.742
- 0.777
- 0.676
- 0.682
- 0.73
- 0.639
- 0.659
- 0.66
- 0.617
- 0.562
- 0.564
- 0.62
- 0.61
- 0.527
- 0.564
- 0.527
- 0.499
- 0.57
- 0.528
- 0.481
- 0.558
- 0.44
- 0.447
- 0.483
- 0.426
- 0.48
- 0.381
- 0.504
- 0.4
- 0.456
- 0.426
- 0.439
- 0.403
- 0.435
- 0.378
- 0.391
- 0.353
- 0.34
- 0.364
- 0.402
- 0.388
unequal: 0
verbose: 1
