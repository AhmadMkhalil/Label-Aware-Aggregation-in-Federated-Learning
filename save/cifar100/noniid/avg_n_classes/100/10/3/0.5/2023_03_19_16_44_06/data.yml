avg_train_accuracy: 0.396
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0411
- 0.0965
- 0.1171
- 0.1249
- 0.1412
- 0.1476
- 0.158
- 0.1634
- 0.1704
- 0.1768
- 0.1811
- 0.1866
- 0.1918
- 0.1944
- 0.1985
- 0.2026
- 0.2068
- 0.2131
- 0.2148
- 0.2173
- 0.2167
- 0.219
- 0.2206
- 0.2241
- 0.228
- 0.2248
- 0.2293
- 0.2332
- 0.2322
- 0.2361
- 0.2374
- 0.2429
- 0.2385
- 0.2429
- 0.2449
- 0.2424
- 0.2479
- 0.2483
- 0.2524
- 0.2515
- 0.2545
- 0.2523
- 0.2558
- 0.2579
- 0.2544
- 0.258
- 0.2569
- 0.2596
- 0.2642
- 0.2626
- 0.2636
- 0.2633
- 0.2639
- 0.2665
- 0.2691
- 0.2661
- 0.2687
- 0.2664
- 0.2673
- 0.2689
- 0.271
- 0.2721
- 0.2707
- 0.2732
- 0.27
- 0.2757
- 0.2715
- 0.2738
- 0.2722
- 0.2768
- 0.2763
- 0.276
- 0.2789
- 0.2755
- 0.2761
- 0.2793
- 0.2785
- 0.277
- 0.28
- 0.2805
- 0.2791
- 0.2794
- 0.2835
- 0.2819
- 0.2823
- 0.2826
- 0.2819
- 0.286
- 0.2827
- 0.2833
- 0.2837
- 0.2876
- 0.2815
- 0.2863
- 0.286
- 0.2856
- 0.2892
- 0.2852
- 0.2929
- 0.2935
test_loss_list:
- 1.840240340232849
- 1.81084228515625
- 1.7641868352890016
- 1.7039164781570435
- 1.7200628209114075
- 1.7160441160202027
- 1.710893259048462
- 1.6627652215957642
- 1.6046074390411378
- 1.6386156463623047
- 1.6538347864151002
- 1.6627705693244934
- 1.6215681433677673
- 1.6447119617462158
- 1.6539809393882752
- 1.657396216392517
- 1.6014727401733397
- 1.6649035716056824
- 1.6397578358650207
- 1.5842176938056947
- 1.607950620651245
- 1.610367910861969
- 1.5561757040023805
- 1.570999312400818
- 1.5302309226989745
- 1.5097579789161681
- 1.4926065111160278
- 1.5222749638557433
- 1.493425805568695
- 1.5224098396301269
- 1.4893294191360473
- 1.4426729226112365
- 1.4230332779884338
- 1.4393809890747071
- 1.446666147708893
- 1.438136625289917
- 1.4409669852256775
- 1.4382948565483094
- 1.4731021666526793
- 1.450128161907196
- 1.4762203431129455
- 1.4960089015960694
- 1.4588051199913026
- 1.4891443848609924
- 1.4666201305389404
- 1.4529273509979248
- 1.4442654585838317
- 1.4700218772888183
- 1.4318430519104004
- 1.4653007507324218
- 1.539561026096344
- 1.4632090544700622
- 1.4484216690063476
- 1.4463725352287293
- 1.4823633122444153
- 1.486478440761566
- 1.5010820531845093
- 1.4491337776184081
- 1.4007370924949647
- 1.451394693851471
- 1.4173975777626038
- 1.4464169645309448
- 1.4644458389282227
- 1.4645471334457398
- 1.4760542345046996
- 1.4822129464149476
- 1.488647267818451
- 1.4332504868507385
- 1.4689747714996337
- 1.4771411609649658
- 1.4400730299949647
- 1.4291711688041686
- 1.4073611116409301
- 1.4386382293701172
- 1.448394901752472
- 1.4161271119117738
- 1.4173663330078126
- 1.4340705108642577
- 1.4442233228683472
- 1.4638348126411438
- 1.3861279463768006
- 1.4289585518836976
- 1.4403529357910156
- 1.4072682094573974
- 1.4020429921150208
- 1.4395053672790528
- 1.507568576335907
- 1.3902768445014955
- 1.395706684589386
- 1.4355533909797669
- 1.3931818580627442
- 1.4313252449035645
- 1.387202548980713
- 1.3819745206832885
- 1.4096423721313476
- 1.3862205648422241
- 1.3816083765029907
- 1.4150348567962647
- 1.3506830191612245
- 1.3617403316497803
train_accuracy:
- 0.047
- 0.132
- 0.0
- 0.148
- 0.146
- 0.221
- 0.248
- 0.0
- 0.0
- 0.201
- 0.23
- 0.238
- 0.221
- 0.297
- 0.0
- 0.277
- 0.0
- 0.286
- 0.236
- 0.314
- 0.278
- 0.237
- 0.289
- 0.238
- 0.0
- 0.288
- 0.338
- 0.25
- 0.292
- 0.265
- 0.309
- 0.0
- 0.0
- 0.333
- 0.0
- 0.303
- 0.289
- 0.401
- 0.381
- 0.341
- 0.357
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.34
- 0.362
- 0.0
- 0.0
- 0.366
- 0.0
- 0.383
- 0.0
- 0.0
- 0.0
- 0.414
- 0.334
- 0.0
- 0.371
- 0.0
- 0.378
- 0.0
- 0.0
- 0.393
- 0.377
- 0.333
- 0.369
- 0.387
- 0.385
- 0.0
- 0.324
- 0.0
- 0.0
- 0.4
- 0.0
- 0.376
- 0.399
- 0.333
- 0.3
- 0.421
- 0.0
- 0.299
- 0.0
- 0.3
- 0.346
- 0.398
- 0.0
- 0.336
- 0.382
- 0.382
- 0.405
- 0.304
- 0.0
- 0.411
- 0.0
- 0.0
- 0.0
- 0.0
- 0.396
train_loss:
- 3.612
- 3.181
- 2.682
- 2.244
- 2.649
- 2.622
- 2.538
- 2.229
- 1.93
- 2.308
- 2.193
- 2.13
- 1.904
- 2.007
- 1.943
- 1.882
- 1.846
- 1.995
- 1.758
- 1.57
- 1.678
- 1.642
- 1.511
- 1.637
- 1.436
- 1.393
- 1.413
- 1.453
- 1.287
- 1.436
- 1.249
- 1.174
- 1.096
- 1.151
- 1.105
- 1.109
- 1.18
- 1.089
- 1.129
- 1.082
- 1.059
- 1.069
- 0.955
- 0.992
- 0.973
- 0.95
- 0.888
- 0.955
- 0.819
- 0.896
- 0.917
- 0.808
- 0.807
- 0.758
- 0.802
- 0.756
- 0.706
- 0.771
- 0.724
- 0.713
- 0.683
- 0.667
- 0.612
- 0.678
- 0.643
- 0.584
- 0.595
- 0.674
- 0.54
- 0.555
- 0.605
- 0.516
- 0.479
- 0.571
- 0.528
- 0.485
- 0.502
- 0.544
- 0.457
- 0.457
- 0.515
- 0.513
- 0.425
- 0.44
- 0.388
- 0.366
- 0.395
- 0.473
- 0.375
- 0.377
- 0.449
- 0.369
- 0.439
- 0.416
- 0.356
- 0.372
- 0.353
- 0.347
- 0.407
- 0.363
unequal: 0
verbose: 1
