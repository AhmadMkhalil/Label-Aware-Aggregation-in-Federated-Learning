avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0421
- 0.0982
- 0.1127
- 0.1327
- 0.1421
- 0.152
- 0.1571
- 0.1666
- 0.169
- 0.1751
- 0.1796
- 0.1889
- 0.1903
- 0.1919
- 0.1974
- 0.2035
- 0.2055
- 0.2051
- 0.2104
- 0.2139
- 0.2162
- 0.2199
- 0.2228
- 0.2211
- 0.2258
- 0.2265
- 0.2291
- 0.2309
- 0.232
- 0.2324
- 0.234
- 0.2402
- 0.2411
- 0.2412
- 0.2433
- 0.2454
- 0.2456
- 0.245
- 0.2455
- 0.2489
- 0.2521
- 0.2522
- 0.2489
- 0.2553
- 0.256
- 0.2542
- 0.2565
- 0.2549
- 0.2611
- 0.2611
- 0.2604
- 0.2666
- 0.2658
- 0.2614
- 0.2625
- 0.2626
- 0.265
- 0.2663
- 0.2675
- 0.2633
- 0.2675
- 0.2721
- 0.2728
- 0.2739
- 0.2766
- 0.2756
- 0.2711
- 0.2751
- 0.2705
- 0.2759
- 0.282
- 0.2716
- 0.274
- 0.2757
- 0.2821
- 0.2817
- 0.2769
- 0.281
- 0.2853
- 0.2813
- 0.2895
- 0.2804
- 0.2792
- 0.2787
- 0.2837
- 0.2816
- 0.2833
- 0.2775
- 0.2837
- 0.2838
- 0.2872
- 0.2867
- 0.2912
- 0.2959
- 0.2949
- 0.2922
- 0.2911
- 0.2868
- 0.2927
- 0.2915
test_loss_list:
- 1.8422301530838012
- 1.7476018238067628
- 1.7224583101272584
- 1.7371252703666686
- 1.6713315773010253
- 1.625907907485962
- 1.6267204976081848
- 1.6504249930381776
- 1.5910061955451966
- 1.627457480430603
- 1.5676791334152222
- 1.5349939393997192
- 1.5447376036643983
- 1.5406399083137512
- 1.5399695062637329
- 1.527472541332245
- 1.5186086416244506
- 1.4847368216514587
- 1.4657132363319396
- 1.4813593530654907
- 1.485328278541565
- 1.5244966435432434
- 1.498654968738556
- 1.4581956601142883
- 1.4326139736175536
- 1.4224636197090148
- 1.4474306893348694
- 1.4509255719184875
- 1.491182370185852
- 1.434151186943054
- 1.4413339829444884
- 1.4097315979003906
- 1.4260470914840697
- 1.4745203685760497
- 1.4984973382949829
- 1.4250703477859497
- 1.397639470100403
- 1.4175008416175843
- 1.3894322562217711
- 1.4503618788719177
- 1.4286115550994873
- 1.392148766517639
- 1.4539142870903015
- 1.4299528098106384
- 1.4235175895690917
- 1.4554862117767333
- 1.3943806529045104
- 1.4014455008506774
- 1.3686145377159118
- 1.38824312210083
- 1.3932329440116882
- 1.3925674772262573
- 1.3644717836380005
- 1.4183980655670165
- 1.4399743890762329
- 1.4066177606582642
- 1.3994886660575867
- 1.4406085348129272
- 1.4599065828323363
- 1.458390655517578
- 1.4165681529045104
- 1.3638067483901977
- 1.3468910241127015
- 1.3710235452651978
- 1.3745969247817993
- 1.3753291249275208
- 1.422694652080536
- 1.3875194120407104
- 1.4269167375564575
- 1.3958763194084167
- 1.3475113248825072
- 1.4133394622802735
- 1.3926807308197022
- 1.4250411295890808
- 1.3576113557815552
- 1.371021556854248
- 1.3693017673492431
- 1.366512200832367
- 1.3380967807769775
- 1.3619089579582215
- 1.330575008392334
- 1.3987091565132141
- 1.4180636644363402
- 1.3817825412750244
- 1.3714540314674377
- 1.4127803421020508
- 1.3834262824058532
- 1.4213407945632934
- 1.3867614912986754
- 1.3826108407974242
- 1.3434060025215149
- 1.360284857749939
- 1.3308719635009765
- 1.3238632655143738
- 1.3206139159202577
- 1.3429522252082824
- 1.3469802021980286
- 1.3955189347267152
- 1.3336481714248658
- 1.3509706521034242
train_accuracy:
- 0.033
- 0.0
- 0.182
- 0.229
- 0.2
- 0.0
- 0.193
- 0.24
- 0.0
- 0.186
- 0.269
- 0.196
- 0.266
- 0.0
- 0.0
- 0.204
- 0.291
- 0.206
- 0.279
- 0.314
- 0.316
- 0.304
- 0.346
- 0.231
- 0.0
- 0.0
- 0.0
- 0.328
- 0.235
- 0.0
- 0.0
- 0.319
- 0.296
- 0.338
- 0.0
- 0.0
- 0.0
- 0.0
- 0.329
- 0.379
- 0.313
- 0.0
- 0.382
- 0.0
- 0.376
- 0.278
- 0.386
- 0.339
- 0.0
- 0.0
- 0.393
- 0.38
- 0.0
- 0.356
- 0.347
- 0.391
- 0.0
- 0.388
- 0.275
- 0.39
- 0.408
- 0.35
- 0.279
- 0.337
- 0.292
- 0.394
- 0.393
- 0.391
- 0.346
- 0.381
- 0.0
- 0.348
- 0.369
- 0.37
- 0.361
- 0.403
- 0.36
- 0.354
- 0.303
- 0.384
- 0.407
- 0.0
- 0.424
- 0.297
- 0.309
- 0.0
- 0.353
- 0.375
- 0.353
- 0.398
- 0.372
- 0.306
- 0.399
- 0.356
- 0.0
- 0.383
- 0.0
- 0.32
- 0.364
- 0.0
train_loss:
- 3.687
- 2.738
- 2.785
- 2.883
- 2.362
- 2.255
- 2.362
- 2.512
- 2.065
- 2.354
- 1.933
- 1.905
- 2.021
- 1.946
- 1.909
- 1.876
- 1.785
- 1.645
- 1.592
- 1.668
- 1.648
- 1.738
- 1.578
- 1.449
- 1.368
- 1.346
- 1.421
- 1.358
- 1.417
- 1.258
- 1.327
- 1.178
- 1.244
- 1.314
- 1.282
- 1.122
- 1.051
- 1.15
- 1.05
- 1.164
- 1.037
- 0.97
- 1.057
- 0.959
- 0.998
- 1.022
- 0.877
- 0.895
- 0.842
- 0.877
- 0.835
- 0.811
- 0.758
- 0.85
- 0.785
- 0.754
- 0.744
- 0.744
- 0.721
- 0.707
- 0.686
- 0.655
- 0.646
- 0.627
- 0.63
- 0.588
- 0.618
- 0.591
- 0.606
- 0.572
- 0.543
- 0.55
- 0.519
- 0.512
- 0.506
- 0.492
- 0.517
- 0.477
- 0.459
- 0.458
- 0.447
- 0.456
- 0.454
- 0.435
- 0.404
- 0.409
- 0.416
- 0.386
- 0.383
- 0.388
- 0.383
- 0.362
- 0.376
- 0.357
- 0.341
- 0.34
- 0.349
- 0.321
- 0.341
- 0.328
unequal: 0
verbose: 1
