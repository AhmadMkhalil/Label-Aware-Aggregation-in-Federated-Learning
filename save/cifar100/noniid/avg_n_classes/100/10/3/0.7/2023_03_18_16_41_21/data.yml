avg_train_accuracy: 0.367
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0411
- 0.0958
- 0.1111
- 0.1273
- 0.1381
- 0.1505
- 0.1554
- 0.1635
- 0.1713
- 0.1778
- 0.1807
- 0.1839
- 0.1903
- 0.1931
- 0.1995
- 0.2047
- 0.2067
- 0.2072
- 0.2093
- 0.212
- 0.2176
- 0.2194
- 0.2225
- 0.2205
- 0.2218
- 0.2252
- 0.2275
- 0.2276
- 0.233
- 0.2318
- 0.2327
- 0.2351
- 0.2375
- 0.2366
- 0.239
- 0.2407
- 0.2409
- 0.242
- 0.2416
- 0.2432
- 0.2442
- 0.2456
- 0.2493
- 0.2525
- 0.2499
- 0.2511
- 0.2523
- 0.2537
- 0.2496
- 0.2526
- 0.2563
- 0.2579
- 0.2555
- 0.2547
- 0.2549
- 0.2601
- 0.2588
- 0.2586
- 0.2609
- 0.2609
- 0.2605
- 0.2629
- 0.2596
- 0.2617
- 0.261
- 0.2617
- 0.2626
- 0.2655
- 0.2699
- 0.264
- 0.2636
- 0.2661
- 0.2674
- 0.2682
- 0.2697
- 0.2683
- 0.2684
- 0.2677
- 0.2678
- 0.2694
- 0.2687
- 0.2645
- 0.2673
- 0.2687
- 0.2701
- 0.2711
- 0.2706
- 0.2755
- 0.2783
- 0.2782
- 0.2766
- 0.2715
- 0.271
- 0.2726
- 0.279
- 0.2793
- 0.2814
- 0.2843
- 0.2831
- 0.2785
test_loss_list:
- 1.8264770078659058
- 1.7533421993255616
- 1.6982757759094238
- 1.6827779936790466
- 1.6639042973518372
- 1.6816970372200013
- 1.6496217441558838
- 1.624439103603363
- 1.6500613164901734
- 1.6490551328659058
- 1.5742461371421814
- 1.5674982643127442
- 1.524743299484253
- 1.5071692848205567
- 1.4915224313735962
- 1.5494807529449464
- 1.5283892893791198
- 1.5121414065361023
- 1.5096814608573914
- 1.5079445028305054
- 1.5026241827011109
- 1.496280508041382
- 1.531164367198944
- 1.5408688163757325
- 1.5088623404502868
- 1.5341141033172607
- 1.510351881980896
- 1.4891496181488038
- 1.4790830612182617
- 1.4789842200279235
- 1.4439417386054993
- 1.4529320359230042
- 1.4238287806510925
- 1.4098114156723023
- 1.4345157837867737
- 1.4377417540550232
- 1.4066987323760987
- 1.4290867352485657
- 1.4808522462844849
- 1.4936033129692077
- 1.4580695748329162
- 1.4101948833465576
- 1.4299093103408813
- 1.422805826663971
- 1.4283107805252075
- 1.4331192827224732
- 1.3978459453582763
- 1.4570373964309693
- 1.4758065819740296
- 1.4499522495269774
- 1.429067726135254
- 1.397037832736969
- 1.415135145187378
- 1.416568922996521
- 1.4126650667190552
- 1.3818540096282959
- 1.4000670862197877
- 1.4052622103691101
- 1.3803898668289185
- 1.396689486503601
- 1.3721895742416381
- 1.394169442653656
- 1.3998317766189574
- 1.4040534329414367
- 1.446611967086792
- 1.4153562021255492
- 1.4047328734397888
- 1.3748998928070069
- 1.359808611869812
- 1.425378487110138
- 1.4036259961128235
- 1.4017625498771666
- 1.3745712089538573
- 1.355623025894165
- 1.3849663710594178
- 1.3962423038482665
- 1.3914086484909058
- 1.4294393730163575
- 1.4038822388648986
- 1.4391598963737489
- 1.4140217876434327
- 1.4405966401100159
- 1.4113430190086365
- 1.402774715423584
- 1.4034714388847351
- 1.3643626761436463
- 1.4249697136878967
- 1.3729845237731935
- 1.35990234375
- 1.3766081309318543
- 1.3811851525306702
- 1.4261627340316771
- 1.439908754825592
- 1.407294249534607
- 1.3627538251876832
- 1.3790447902679444
- 1.3538385272026061
- 1.3433799743652344
- 1.3710581183433532
- 1.4176536202430725
train_accuracy:
- 0.065
- 0.132
- 0.0
- 0.177
- 0.185
- 0.245
- 0.248
- 0.259
- 0.19
- 0.0
- 0.0
- 0.288
- 0.0
- 0.235
- 0.25
- 0.0
- 0.299
- 0.245
- 0.265
- 0.352
- 0.0
- 0.28
- 0.289
- 0.298
- 0.345
- 0.285
- 0.336
- 0.302
- 0.318
- 0.289
- 0.354
- 0.311
- 0.322
- 0.368
- 0.328
- 0.38
- 0.0
- 0.332
- 0.33
- 0.324
- 0.313
- 0.378
- 0.322
- 0.333
- 0.336
- 0.347
- 0.0
- 0.346
- 0.354
- 0.0
- 0.305
- 0.328
- 0.358
- 0.0
- 0.349
- 0.327
- 0.32
- 0.354
- 0.347
- 0.316
- 0.316
- 0.349
- 0.0
- 0.342
- 0.0
- 0.356
- 0.398
- 0.403
- 0.0
- 0.357
- 0.388
- 0.0
- 0.0
- 0.0
- 0.359
- 0.367
- 0.365
- 0.366
- 0.378
- 0.324
- 0.328
- 0.352
- 0.351
- 0.0
- 0.0
- 0.362
- 0.372
- 0.0
- 0.38
- 0.0
- 0.38
- 0.364
- 0.366
- 0.354
- 0.0
- 0.411
- 0.381
- 0.403
- 0.409
- 0.367
train_loss:
- 3.025
- 3.006
- 2.552
- 2.676
- 2.528
- 2.656
- 2.379
- 2.259
- 2.382
- 2.29
- 1.96
- 2.044
- 1.856
- 1.776
- 1.755
- 1.975
- 1.829
- 1.731
- 1.716
- 1.656
- 1.595
- 1.611
- 1.682
- 1.625
- 1.488
- 1.534
- 1.391
- 1.418
- 1.348
- 1.314
- 1.239
- 1.261
- 1.174
- 1.146
- 1.147
- 1.198
- 1.08
- 1.116
- 1.143
- 1.114
- 1.064
- 0.981
- 1.037
- 0.978
- 0.976
- 0.956
- 0.864
- 0.963
- 0.928
- 0.846
- 0.845
- 0.784
- 0.815
- 0.785
- 0.777
- 0.704
- 0.753
- 0.708
- 0.686
- 0.659
- 0.623
- 0.646
- 0.66
- 0.611
- 0.637
- 0.597
- 0.572
- 0.585
- 0.543
- 0.543
- 0.603
- 0.564
- 0.518
- 0.51
- 0.526
- 0.486
- 0.515
- 0.456
- 0.49
- 0.474
- 0.454
- 0.449
- 0.439
- 0.43
- 0.409
- 0.429
- 0.415
- 0.423
- 0.398
- 0.386
- 0.37
- 0.359
- 0.364
- 0.371
- 0.358
- 0.347
- 0.344
- 0.336
- 0.325
- 0.296
unequal: 0
verbose: 1
