avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0415
- 0.096
- 0.1183
- 0.1271
- 0.1403
- 0.1511
- 0.1586
- 0.1645
- 0.1689
- 0.1736
- 0.1778
- 0.1836
- 0.1885
- 0.1885
- 0.1934
- 0.1956
- 0.2017
- 0.2004
- 0.2075
- 0.2091
- 0.2089
- 0.2137
- 0.2183
- 0.2185
- 0.2226
- 0.2207
- 0.2234
- 0.2277
- 0.2287
- 0.2331
- 0.2316
- 0.2298
- 0.2316
- 0.2344
- 0.2383
- 0.2421
- 0.2445
- 0.2427
- 0.242
- 0.2412
- 0.2471
- 0.2441
- 0.2443
- 0.2465
- 0.2503
- 0.249
- 0.2503
- 0.2515
- 0.2533
- 0.255
- 0.2516
- 0.2528
- 0.256
- 0.2554
- 0.256
- 0.2521
- 0.2565
- 0.2586
- 0.256
- 0.2612
- 0.2592
- 0.259
- 0.26
- 0.2608
- 0.2624
- 0.2621
- 0.2635
- 0.2676
- 0.265
- 0.2695
- 0.2704
- 0.2696
- 0.2691
- 0.2685
- 0.2701
- 0.2695
- 0.274
- 0.2741
- 0.2728
- 0.2795
- 0.2711
- 0.2726
- 0.268
- 0.2726
- 0.2687
- 0.2731
- 0.2741
- 0.2794
- 0.2797
- 0.2731
- 0.2717
- 0.2771
- 0.2735
- 0.2734
- 0.2729
- 0.2784
- 0.2789
- 0.2812
- 0.278
- 0.2782
test_loss_list:
- 1.8177826070785523
- 1.7542968273162842
- 1.7287076997756958
- 1.679092993736267
- 1.6674901270866394
- 1.6515961503982544
- 1.639239525794983
- 1.6218315410614013
- 1.5838859248161317
- 1.584730842113495
- 1.5531265211105347
- 1.5311273884773255
- 1.5464194321632385
- 1.5209320163726807
- 1.534840943813324
- 1.540349223613739
- 1.5407590079307556
- 1.5056626987457276
- 1.55165442943573
- 1.4922369384765626
- 1.5013419079780579
- 1.4633100819587708
- 1.452686882019043
- 1.4478400588035583
- 1.4394675040245055
- 1.466237018108368
- 1.4750876545906066
- 1.443944025039673
- 1.4583290433883667
- 1.4638127017021179
- 1.4610868668556214
- 1.4298469567298888
- 1.4461619186401367
- 1.4502649092674256
- 1.4217168593406677
- 1.402587959766388
- 1.4254274415969848
- 1.4309259295463561
- 1.4354215955734253
- 1.4700161933898925
- 1.4145729064941406
- 1.4654119420051575
- 1.4421293258666992
- 1.4723807621002196
- 1.4080644583702087
- 1.4609280705451966
- 1.4029578042030335
- 1.3839247226715088
- 1.3727696108818055
- 1.4005656123161316
- 1.45956077337265
- 1.420785059928894
- 1.412425515651703
- 1.4622090315818788
- 1.4689124703407288
- 1.5430991244316101
- 1.456518862247467
- 1.4348987412452698
- 1.3926277947425842
- 1.4027864670753478
- 1.4030039668083192
- 1.3982198357582092
- 1.3987379789352417
- 1.4480328202247619
- 1.4199111533164979
- 1.3771581912040711
- 1.3669170093536378
- 1.3583090019226074
- 1.4265939450263978
- 1.4039133501052856
- 1.4053539228439331
- 1.3964473056793212
- 1.364295437335968
- 1.3878866600990296
- 1.3616123485565186
- 1.3570927023887633
- 1.3811262321472169
- 1.3899367046356201
- 1.3617853832244873
- 1.3488770842552185
- 1.3723322677612304
- 1.3826812100410462
- 1.3942753314971923
- 1.396403160095215
- 1.4407202410697937
- 1.403560116291046
- 1.3647828817367553
- 1.3506959199905395
- 1.3731732845306397
- 1.4251004600524901
- 1.3875591349601746
- 1.383287706375122
- 1.4279112315177918
- 1.3944023776054382
- 1.4316626358032227
- 1.367691352367401
- 1.3843620586395264
- 1.3849638628959655
- 1.3813268589973449
- 1.384181854724884
train_accuracy:
- 0.052
- 0.132
- 0.0
- 0.181
- 0.168
- 0.203
- 0.213
- 0.0
- 0.0
- 0.226
- 0.245
- 0.0
- 0.266
- 0.289
- 0.244
- 0.265
- 0.275
- 0.263
- 0.275
- 0.27
- 0.251
- 0.299
- 0.284
- 0.0
- 0.0
- 0.0
- 0.305
- 0.0
- 0.363
- 0.285
- 0.0
- 0.318
- 0.311
- 0.274
- 0.0
- 0.0
- 0.318
- 0.335
- 0.367
- 0.389
- 0.0
- 0.345
- 0.334
- 0.301
- 0.37
- 0.0
- 0.35
- 0.366
- 0.0
- 0.0
- 0.353
- 0.317
- 0.333
- 0.344
- 0.401
- 0.32
- 0.0
- 0.316
- 0.0
- 0.312
- 0.4
- 0.0
- 0.391
- 0.304
- 0.376
- 0.306
- 0.317
- 0.379
- 0.31
- 0.346
- 0.386
- 0.0
- 0.0
- 0.327
- 0.404
- 0.0
- 0.347
- 0.408
- 0.322
- 0.0
- 0.362
- 0.381
- 0.362
- 0.425
- 0.413
- 0.357
- 0.4
- 0.0
- 0.321
- 0.368
- 0.403
- 0.0
- 0.0
- 0.385
- 0.329
- 0.42
- 0.36
- 0.0
- 0.0
- 0.0
train_loss:
- 3.034
- 2.985
- 2.821
- 2.459
- 2.556
- 2.472
- 2.397
- 2.3
- 2.062
- 2.162
- 1.93
- 1.903
- 2.016
- 1.789
- 1.873
- 1.819
- 1.779
- 1.588
- 1.893
- 1.593
- 1.632
- 1.531
- 1.436
- 1.409
- 1.4
- 1.469
- 1.448
- 1.314
- 1.387
- 1.342
- 1.344
- 1.164
- 1.248
- 1.236
- 1.131
- 1.112
- 1.145
- 1.146
- 1.103
- 1.141
- 0.987
- 1.105
- 1.016
- 1.037
- 0.945
- 0.997
- 0.856
- 0.844
- 0.824
- 0.87
- 0.896
- 0.832
- 0.793
- 0.835
- 0.814
- 0.812
- 0.743
- 0.719
- 0.672
- 0.698
- 0.682
- 0.654
- 0.665
- 0.666
- 0.617
- 0.59
- 0.576
- 0.558
- 0.6
- 0.551
- 0.534
- 0.544
- 0.513
- 0.504
- 0.477
- 0.463
- 0.479
- 0.474
- 0.454
- 0.44
- 0.456
- 0.446
- 0.435
- 0.418
- 0.432
- 0.427
- 0.395
- 0.378
- 0.374
- 0.386
- 0.399
- 0.368
- 0.373
- 0.373
- 0.342
- 0.35
- 0.331
- 0.325
- 0.326
- 0.314
unequal: 0
verbose: 1
