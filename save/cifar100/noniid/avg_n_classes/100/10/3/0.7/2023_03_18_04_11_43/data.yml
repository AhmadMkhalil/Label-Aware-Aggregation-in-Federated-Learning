avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0373
- 0.0933
- 0.1086
- 0.1268
- 0.1413
- 0.1521
- 0.1558
- 0.1636
- 0.1685
- 0.1713
- 0.174
- 0.1804
- 0.1858
- 0.1909
- 0.1933
- 0.1998
- 0.2009
- 0.2048
- 0.2081
- 0.2088
- 0.2115
- 0.2162
- 0.2194
- 0.2222
- 0.222
- 0.2241
- 0.2297
- 0.2284
- 0.2333
- 0.2334
- 0.2335
- 0.2368
- 0.2376
- 0.2374
- 0.2384
- 0.24
- 0.2444
- 0.2445
- 0.2466
- 0.2459
- 0.2488
- 0.2489
- 0.2523
- 0.255
- 0.2545
- 0.2527
- 0.2519
- 0.2553
- 0.2558
- 0.2602
- 0.2591
- 0.2564
- 0.2617
- 0.2648
- 0.2666
- 0.2621
- 0.2642
- 0.2655
- 0.2628
- 0.2624
- 0.2646
- 0.2651
- 0.2662
- 0.2675
- 0.2681
- 0.2681
- 0.2729
- 0.2732
- 0.2691
- 0.2685
- 0.2731
- 0.2727
- 0.2755
- 0.2692
- 0.2738
- 0.2749
- 0.2723
- 0.2772
- 0.2789
- 0.2825
- 0.2775
- 0.2774
- 0.2817
- 0.2845
- 0.2787
- 0.2828
- 0.2793
- 0.2877
- 0.2813
- 0.2871
- 0.2797
- 0.2824
- 0.2846
- 0.2791
- 0.2829
- 0.2851
- 0.2869
- 0.2759
- 0.2865
- 0.2902
test_loss_list:
- 1.8311603784561157
- 1.758734064102173
- 1.7038179659843444
- 1.6634162402153014
- 1.6934889650344849
- 1.6635388231277466
- 1.6433878016471863
- 1.6697982358932495
- 1.6036636114120484
- 1.5972988271713258
- 1.596186158657074
- 1.581389572620392
- 1.6176021337509154
- 1.5506520056724549
- 1.551420361995697
- 1.5828946876525878
- 1.5567210841178893
- 1.5390668201446533
- 1.5328301072120667
- 1.4957443523406981
- 1.4724656629562378
- 1.5942071771621704
- 1.5344189167022706
- 1.5608542037010193
- 1.4914988327026366
- 1.4585870122909546
- 1.4778335475921631
- 1.4749250102043152
- 1.475728027820587
- 1.4426476645469666
- 1.4616487646102905
- 1.5091216135025025
- 1.476000907421112
- 1.466646649837494
- 1.511484320163727
- 1.4462991523742676
- 1.4554762148857117
- 1.4533145999908448
- 1.4435270047187805
- 1.4473631644248963
- 1.4062522387504577
- 1.426203727722168
- 1.4247868609428407
- 1.3960838007926941
- 1.4240625858306886
- 1.4235577774047852
- 1.4231700921058654
- 1.3912876343727112
- 1.4159112071990967
- 1.3842720246315003
- 1.4478384041786194
- 1.3938765239715576
- 1.4097991752624512
- 1.381806972026825
- 1.36691654920578
- 1.3977597618103028
- 1.3714402103424073
- 1.3975886511802673
- 1.3986826753616333
- 1.402844989299774
- 1.4072565031051636
- 1.3955817890167237
- 1.3992250657081604
- 1.3986047315597534
- 1.4057989168167113
- 1.4034867644309998
- 1.3671377682685852
- 1.354509551525116
- 1.382919282913208
- 1.429169089794159
- 1.3711252284049988
- 1.4333741497993469
- 1.4084165382385254
- 1.4022550392150879
- 1.3662008142471314
- 1.3857223987579346
- 1.3883498692512513
- 1.3616180944442748
- 1.3795578718185424
- 1.354654574394226
- 1.3795762395858764
- 1.3813936471939088
- 1.3563457250595092
- 1.348628282546997
- 1.3741336536407471
- 1.3497089052200317
- 1.3767680430412292
- 1.3483084630966187
- 1.3740849375724793
- 1.3492861318588256
- 1.4129459595680236
- 1.387935347557068
- 1.3540530610084534
- 1.419866795539856
- 1.3638296127319336
- 1.3813457155227662
- 1.3565650820732116
- 1.4175209140777587
- 1.3567827820777894
- 1.3500500845909118
train_accuracy:
- 0.0
- 0.122
- 0.0
- 0.0
- 0.195
- 0.233
- 0.232
- 0.244
- 0.226
- 0.0
- 0.268
- 0.0
- 0.262
- 0.273
- 0.252
- 0.296
- 0.0
- 0.283
- 0.293
- 0.273
- 0.0
- 0.323
- 0.325
- 0.324
- 0.0
- 0.0
- 0.0
- 0.296
- 0.285
- 0.0
- 0.0
- 0.333
- 0.0
- 0.0
- 0.348
- 0.0
- 0.0
- 0.293
- 0.349
- 0.368
- 0.0
- 0.0
- 0.329
- 0.327
- 0.0
- 0.333
- 0.329
- 0.0
- 0.32
- 0.0
- 0.327
- 0.408
- 0.336
- 0.0
- 0.0
- 0.358
- 0.337
- 0.33
- 0.395
- 0.0
- 0.371
- 0.356
- 0.374
- 0.344
- 0.0
- 0.367
- 0.408
- 0.0
- 0.0
- 0.368
- 0.0
- 0.405
- 0.352
- 0.0
- 0.355
- 0.408
- 0.342
- 0.0
- 0.375
- 0.389
- 0.0
- 0.0
- 0.41
- 0.366
- 0.366
- 0.0
- 0.0
- 0.379
- 0.41
- 0.415
- 0.407
- 0.4
- 0.0
- 0.0
- 0.37
- 0.0
- 0.0
- 0.371
- 0.0
- 0.0
train_loss:
- 3.444
- 3.021
- 2.608
- 2.462
- 2.787
- 2.501
- 2.399
- 2.495
- 2.102
- 2.211
- 2.127
- 2.1
- 2.178
- 1.837
- 1.903
- 2.028
- 1.808
- 1.786
- 1.753
- 1.595
- 1.536
- 1.875
- 1.574
- 1.654
- 1.42
- 1.396
- 1.441
- 1.42
- 1.381
- 1.245
- 1.313
- 1.388
- 1.28
- 1.243
- 1.289
- 1.127
- 1.184
- 1.141
- 1.096
- 1.067
- 1.0
- 1.04
- 0.998
- 0.947
- 0.961
- 0.966
- 0.92
- 0.853
- 0.896
- 0.824
- 0.919
- 0.799
- 0.783
- 0.753
- 0.738
- 0.769
- 0.704
- 0.738
- 0.736
- 0.707
- 0.678
- 0.666
- 0.662
- 0.627
- 0.621
- 0.617
- 0.569
- 0.583
- 0.587
- 0.576
- 0.534
- 0.557
- 0.524
- 0.55
- 0.495
- 0.498
- 0.501
- 0.486
- 0.448
- 0.473
- 0.453
- 0.435
- 0.413
- 0.407
- 0.432
- 0.416
- 0.398
- 0.373
- 0.395
- 0.382
- 0.385
- 0.372
- 0.368
- 0.356
- 0.357
- 0.353
- 0.332
- 0.344
- 0.325
- 0.33
unequal: 0
verbose: 1
