avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0333
- 0.0944
- 0.1171
- 0.1336
- 0.1417
- 0.1528
- 0.1596
- 0.17
- 0.1755
- 0.1782
- 0.1831
- 0.1884
- 0.1944
- 0.1986
- 0.2001
- 0.2019
- 0.2069
- 0.2117
- 0.217
- 0.2178
- 0.2208
- 0.2219
- 0.2245
- 0.2252
- 0.2271
- 0.2302
- 0.2312
- 0.2341
- 0.2349
- 0.2386
- 0.2395
- 0.2419
- 0.2454
- 0.2462
- 0.2479
- 0.2502
- 0.2485
- 0.247
- 0.2513
- 0.2533
- 0.2535
- 0.2512
- 0.2571
- 0.257
- 0.2581
- 0.2599
- 0.2597
- 0.262
- 0.2602
- 0.2628
- 0.2618
- 0.2624
- 0.2646
- 0.2647
- 0.2666
- 0.2679
- 0.2693
- 0.2688
- 0.2674
- 0.2681
- 0.2755
- 0.2772
- 0.2726
- 0.2747
- 0.2787
- 0.2762
- 0.2763
- 0.2777
- 0.2798
- 0.2768
- 0.2742
- 0.2724
- 0.2763
- 0.2795
- 0.2858
- 0.2871
- 0.277
- 0.2823
- 0.2857
- 0.2893
- 0.2879
- 0.2852
- 0.2863
- 0.2924
- 0.2902
- 0.2835
- 0.2835
- 0.2907
- 0.2868
- 0.2923
- 0.2853
- 0.2819
- 0.289
- 0.2898
- 0.2904
- 0.2912
- 0.2885
- 0.2889
- 0.2949
- 0.2928
test_loss_list:
- 1.8084372520446776
- 1.7412429761886596
- 1.687940363883972
- 1.70759845495224
- 1.676314778327942
- 1.6574881601333618
- 1.609826512336731
- 1.5801722025871277
- 1.585419991016388
- 1.5526085519790649
- 1.5629139041900635
- 1.601260154247284
- 1.610075488090515
- 1.573977370262146
- 1.5595288825035096
- 1.5565456008911134
- 1.5521813535690308
- 1.5893247103691102
- 1.544690601825714
- 1.5598464798927307
- 1.4868853378295899
- 1.458889865875244
- 1.4736288833618163
- 1.4463481163978578
- 1.460782163143158
- 1.435417833328247
- 1.4532578992843628
- 1.4229807734489441
- 1.4827762389183043
- 1.43049560546875
- 1.4815119552612304
- 1.4603786492347717
- 1.4493861198425293
- 1.408231997489929
- 1.3909549927711486
- 1.413221755027771
- 1.420312488079071
- 1.4206542253494263
- 1.3883314275741576
- 1.4102730441093445
- 1.3844846367836
- 1.40075163602829
- 1.3736420273780823
- 1.395431351661682
- 1.3958642101287841
- 1.3668699598312377
- 1.392052195072174
- 1.398882348537445
- 1.5060391879081727
- 1.4325172972679139
- 1.4192853808403014
- 1.4086229491233826
- 1.3985046601295472
- 1.3900994443893433
- 1.3895813035964966
- 1.435755627155304
- 1.3706491804122924
- 1.4240487146377563
- 1.3949471068382264
- 1.3570539903640748
- 1.3397072434425354
- 1.3344962739944457
- 1.4063515543937684
- 1.3534134078025817
- 1.3411419486999512
- 1.3589181423187255
- 1.3681199717521668
- 1.3666402006149292
- 1.3683012461662292
- 1.4103445291519165
- 1.4294798564910889
- 1.391933183670044
- 1.376325569152832
- 1.369473831653595
- 1.3393072819709777
- 1.3578834748268127
- 1.4040198302268982
- 1.3708507919311523
- 1.3381867003440857
- 1.3251828503608705
- 1.3493936276435852
- 1.358894944190979
- 1.3641735482215882
- 1.3317839908599853
- 1.3579126143455504
- 1.4076380228996277
- 1.3773293900489807
- 1.3416150164604188
- 1.4006181025505067
- 1.3428396201133728
- 1.3985508489608764
- 1.3694464325904847
- 1.370596671104431
- 1.3697377252578735
- 1.363076877593994
- 1.3640060877799989
- 1.3590056681632996
- 1.4020587754249574
- 1.339519865512848
- 1.350915265083313
train_accuracy:
- 0.066
- 0.0
- 0.171
- 0.178
- 0.196
- 0.212
- 0.247
- 0.0
- 0.285
- 0.0
- 0.0
- 0.261
- 0.304
- 0.306
- 0.256
- 0.274
- 0.326
- 0.3
- 0.281
- 0.284
- 0.0
- 0.321
- 0.0
- 0.311
- 0.29
- 0.327
- 0.0
- 0.0
- 0.338
- 0.299
- 0.316
- 0.0
- 0.345
- 0.0
- 0.357
- 0.38
- 0.328
- 0.0
- 0.365
- 0.341
- 0.0
- 0.34
- 0.0
- 0.344
- 0.0
- 0.0
- 0.367
- 0.0
- 0.383
- 0.368
- 0.374
- 0.344
- 0.396
- 0.345
- 0.0
- 0.346
- 0.0
- 0.377
- 0.346
- 0.386
- 0.0
- 0.0
- 0.409
- 0.398
- 0.4
- 0.0
- 0.36
- 0.0
- 0.385
- 0.37
- 0.398
- 0.391
- 0.423
- 0.0
- 0.408
- 0.354
- 0.369
- 0.358
- 0.0
- 0.0
- 0.369
- 0.399
- 0.404
- 0.0
- 0.409
- 0.366
- 0.0
- 0.0
- 0.377
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.403
- 0.376
- 0.358
- 0.405
- 0.0
- 0.0
train_loss:
- 3.048
- 2.98
- 2.563
- 2.891
- 2.543
- 2.432
- 2.206
- 2.093
- 2.217
- 1.982
- 2.093
- 2.172
- 2.141
- 1.922
- 1.853
- 1.8
- 1.753
- 1.825
- 1.764
- 1.809
- 1.532
- 1.48
- 1.54
- 1.381
- 1.491
- 1.337
- 1.387
- 1.316
- 1.429
- 1.221
- 1.397
- 1.256
- 1.254
- 1.139
- 1.092
- 1.179
- 1.143
- 1.078
- 1.02
- 1.055
- 0.962
- 1.033
- 0.92
- 0.97
- 0.976
- 0.877
- 0.892
- 0.848
- 0.959
- 0.864
- 0.817
- 0.814
- 0.794
- 0.801
- 0.73
- 0.748
- 0.693
- 0.741
- 0.72
- 0.654
- 0.635
- 0.627
- 0.662
- 0.614
- 0.578
- 0.6
- 0.554
- 0.573
- 0.577
- 0.57
- 0.539
- 0.528
- 0.527
- 0.514
- 0.491
- 0.484
- 0.495
- 0.48
- 0.445
- 0.43
- 0.44
- 0.418
- 0.43
- 0.4
- 0.402
- 0.405
- 0.406
- 0.386
- 0.372
- 0.391
- 0.371
- 0.384
- 0.348
- 0.339
- 0.362
- 0.335
- 0.33
- 0.308
- 0.341
- 0.334
unequal: 0
verbose: 1
