avg_train_accuracy: 0.414
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.042
- 0.0958
- 0.1115
- 0.1232
- 0.1347
- 0.1428
- 0.1497
- 0.1555
- 0.163
- 0.1667
- 0.1725
- 0.1781
- 0.1854
- 0.1889
- 0.1941
- 0.1988
- 0.203
- 0.2053
- 0.2069
- 0.2088
- 0.2133
- 0.2151
- 0.2166
- 0.2194
- 0.2201
- 0.2236
- 0.227
- 0.2311
- 0.2321
- 0.2313
- 0.2373
- 0.237
- 0.2387
- 0.2411
- 0.2421
- 0.2443
- 0.244
- 0.2448
- 0.2448
- 0.2439
- 0.2453
- 0.2504
- 0.251
- 0.2513
- 0.2547
- 0.2555
- 0.2574
- 0.258
- 0.2618
- 0.2595
- 0.26
- 0.2615
- 0.2626
- 0.2603
- 0.2625
- 0.2628
- 0.2671
- 0.2612
- 0.2636
- 0.2658
- 0.2661
- 0.2623
- 0.2666
- 0.2682
- 0.2696
- 0.2686
- 0.2676
- 0.2742
- 0.272
- 0.2734
- 0.2672
- 0.2717
- 0.2696
- 0.269
- 0.272
- 0.2732
- 0.2778
- 0.2764
- 0.2733
- 0.2736
- 0.2761
- 0.2756
- 0.2756
- 0.2784
- 0.2797
- 0.2794
- 0.2755
- 0.2782
- 0.2756
- 0.2777
- 0.2802
- 0.2824
- 0.2781
- 0.2835
- 0.284
- 0.2864
- 0.2806
- 0.2767
- 0.2764
- 0.2801
test_loss_list:
- 1.8266914081573487
- 1.7341022491455078
- 1.7237912368774415
- 1.6767908692359925
- 1.666691210269928
- 1.6585325622558593
- 1.650844304561615
- 1.6052071976661682
- 1.603300747871399
- 1.5949775004386901
- 1.5579608845710755
- 1.6091005110740662
- 1.5830191898345947
- 1.5680248308181763
- 1.525462875366211
- 1.5337333250045777
- 1.5757703065872193
- 1.5533602452278137
- 1.5051837992668151
- 1.4806590628623963
- 1.4675426983833313
- 1.5268338584899903
- 1.5076155018806459
- 1.4660228872299195
- 1.447432279586792
- 1.5091343355178832
- 1.451990523338318
- 1.4611233758926392
- 1.4673770236968995
- 1.4363320398330688
- 1.4527136015892028
- 1.4630649757385255
- 1.4578644227981568
- 1.448269965648651
- 1.4488451743125916
- 1.4920156264305116
- 1.426388862133026
- 1.4323261666297913
- 1.47759024143219
- 1.4467786741256714
- 1.4849346804618835
- 1.4478371238708496
- 1.4767542552947999
- 1.4165698885917664
- 1.4667150497436523
- 1.406807610988617
- 1.4210926699638367
- 1.386173300743103
- 1.4455580663681031
- 1.429484076499939
- 1.4178218746185303
- 1.3812073183059692
- 1.4010746145248414
- 1.399234149456024
- 1.4036102056503297
- 1.3992397212982177
- 1.370178029537201
- 1.434611008167267
- 1.4125920367240905
- 1.3735853576660155
- 1.4317647051811218
- 1.4028575396537781
- 1.4021334910392762
- 1.367964277267456
- 1.3911442947387695
- 1.3959796833992004
- 1.3967042970657348
- 1.3545789742469787
- 1.3822221279144287
- 1.35875807762146
- 1.4782711625099183
- 1.3737443590164184
- 1.433087923526764
- 1.4546766471862793
- 1.3812273383140563
- 1.3940920519828797
- 1.358667526245117
- 1.3758881163597108
- 1.427108473777771
- 1.4031773114204407
- 1.4022471451759337
- 1.3807980799674988
- 1.37877525806427
- 1.3546886515617371
- 1.3757754898071288
- 1.3818484449386597
- 1.4322906255722045
- 1.3983918642997741
- 1.3886010813713074
- 1.3840981483459474
- 1.3462353444099426
- 1.3421054935455323
- 1.412487347126007
- 1.3521091747283935
- 1.3410427498817443
- 1.3339939379692078
- 1.405662226676941
- 1.4361365914344788
- 1.435173316001892
- 1.4022418832778931
train_accuracy:
- 0.057
- 0.123
- 0.157
- 0.0
- 0.204
- 0.241
- 0.0
- 0.193
- 0.0
- 0.0
- 0.0
- 0.269
- 0.279
- 0.0
- 0.289
- 0.0
- 0.0
- 0.0
- 0.0
- 0.271
- 0.0
- 0.0
- 0.342
- 0.0
- 0.343
- 0.321
- 0.0
- 0.0
- 0.333
- 0.0
- 0.351
- 0.325
- 0.326
- 0.0
- 0.352
- 0.334
- 0.342
- 0.0
- 0.0
- 0.347
- 0.308
- 0.362
- 0.356
- 0.0
- 0.389
- 0.39
- 0.388
- 0.0
- 0.398
- 0.0
- 0.0
- 0.353
- 0.384
- 0.311
- 0.388
- 0.383
- 0.414
- 0.387
- 0.375
- 0.374
- 0.384
- 0.406
- 0.401
- 0.403
- 0.37
- 0.367
- 0.37
- 0.0
- 0.378
- 0.0
- 0.39
- 0.0
- 0.397
- 0.377
- 0.0
- 0.373
- 0.312
- 0.0
- 0.406
- 0.421
- 0.0
- 0.416
- 0.436
- 0.405
- 0.414
- 0.384
- 0.0
- 0.407
- 0.323
- 0.421
- 0.0
- 0.0
- 0.408
- 0.0
- 0.0
- 0.0
- 0.403
- 0.398
- 0.396
- 0.414
train_loss:
- 3.398
- 2.717
- 2.813
- 2.449
- 2.571
- 2.493
- 2.395
- 2.132
- 2.232
- 2.179
- 1.944
- 2.227
- 2.038
- 1.941
- 1.774
- 1.9
- 1.954
- 1.777
- 1.592
- 1.596
- 1.51
- 1.717
- 1.538
- 1.468
- 1.406
- 1.581
- 1.346
- 1.423
- 1.401
- 1.247
- 1.318
- 1.303
- 1.252
- 1.227
- 1.178
- 1.273
- 1.099
- 1.107
- 1.208
- 1.091
- 1.11
- 1.057
- 1.038
- 0.948
- 0.989
- 0.886
- 0.871
- 0.85
- 0.943
- 0.886
- 0.828
- 0.772
- 0.809
- 0.797
- 0.774
- 0.753
- 0.72
- 0.762
- 0.708
- 0.669
- 0.711
- 0.685
- 0.686
- 0.606
- 0.631
- 0.63
- 0.592
- 0.576
- 0.576
- 0.535
- 0.587
- 0.551
- 0.545
- 0.517
- 0.498
- 0.508
- 0.493
- 0.475
- 0.474
- 0.478
- 0.451
- 0.452
- 0.439
- 0.43
- 0.405
- 0.416
- 0.403
- 0.413
- 0.386
- 0.367
- 0.383
- 0.353
- 0.348
- 0.368
- 0.349
- 0.331
- 0.342
- 0.329
- 0.325
- 0.34
unequal: 0
verbose: 1
