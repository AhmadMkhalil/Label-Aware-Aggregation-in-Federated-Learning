avg_train_accuracy: 0.328
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0352
- 0.0889
- 0.1076
- 0.1257
- 0.1402
- 0.1477
- 0.1572
- 0.1662
- 0.1703
- 0.1766
- 0.1813
- 0.1872
- 0.1897
- 0.1972
- 0.1992
- 0.2042
- 0.2041
- 0.2069
- 0.2095
- 0.216
- 0.2151
- 0.2185
- 0.219
- 0.2206
- 0.2228
- 0.2244
- 0.2261
- 0.2291
- 0.2334
- 0.2312
- 0.2322
- 0.2334
- 0.234
- 0.2365
- 0.2359
- 0.2401
- 0.2386
- 0.2445
- 0.2418
- 0.2413
- 0.2438
- 0.245
- 0.2499
- 0.2473
- 0.2491
- 0.2525
- 0.25
- 0.2528
- 0.2539
- 0.2551
- 0.2545
- 0.2565
- 0.256
- 0.2585
- 0.2625
- 0.2588
- 0.2597
- 0.2616
- 0.2628
- 0.2639
- 0.2658
- 0.2654
- 0.2671
- 0.2668
- 0.2682
- 0.268
- 0.2685
- 0.2711
- 0.2728
- 0.2726
- 0.2705
- 0.2708
- 0.2718
- 0.2779
- 0.2747
- 0.2777
- 0.2765
- 0.2704
- 0.2729
- 0.2735
- 0.2739
- 0.2754
- 0.2769
- 0.2801
- 0.2824
- 0.2807
- 0.2815
- 0.2828
- 0.2852
- 0.2826
- 0.2786
- 0.2817
- 0.2834
- 0.2857
- 0.2844
- 0.2853
- 0.2853
- 0.2826
- 0.2894
- 0.2842
test_loss_list:
- 1.8281621646881103
- 1.734428997039795
- 1.6924501371383667
- 1.6816863012313843
- 1.6648686838150024
- 1.6263179516792297
- 1.5999615836143493
- 1.577879285812378
- 1.5897739148139953
- 1.5929825448989867
- 1.5831574392318726
- 1.5755927562713623
- 1.5398085951805114
- 1.5191438341140746
- 1.503510253429413
- 1.5224372458457947
- 1.5287554359436035
- 1.5300402665138244
- 1.492102897167206
- 1.5041831517219544
- 1.5072410273551942
- 1.472217652797699
- 1.4587176275253295
- 1.4841279792785644
- 1.4836934041976928
- 1.4819764065742493
- 1.4857875728607177
- 1.4811269521713257
- 1.5240616059303285
- 1.535731794834137
- 1.4617702317237855
- 1.46248939037323
- 1.4675878596305847
- 1.5069635939598083
- 1.4751166439056396
- 1.5026965713500977
- 1.4406728196144103
- 1.414382677078247
- 1.4345095539093018
- 1.4425391030311585
- 1.4416239953041077
- 1.4071547651290894
- 1.3961816430091858
- 1.4192195677757262
- 1.4253087210655213
- 1.3903203868865968
- 1.4112061309814452
- 1.391025230884552
- 1.3806596732139587
- 1.4417204523086549
- 1.4668177032470704
- 1.4022875595092774
- 1.451605625152588
- 1.3956105852127074
- 1.4483415007591247
- 1.464601972103119
- 1.4401743578910828
- 1.3949121999740601
- 1.4125347781181334
- 1.3813347601890564
- 1.3965216779708862
- 1.4442878293991088
- 1.409683575630188
- 1.4032094144821168
- 1.4009433007240295
- 1.4008155298233032
- 1.399151804447174
- 1.368706192970276
- 1.3900057554244996
- 1.3952185225486755
- 1.433314483165741
- 1.4075498628616332
- 1.3727115273475647
- 1.3572981810569764
- 1.3782066869735718
- 1.391356725692749
- 1.386662254333496
- 1.4292533373832703
- 1.4506534361839294
- 1.4164124751091003
- 1.4066608452796936
- 1.404452691078186
- 1.4012189054489135
- 1.3632305765151977
- 1.3529360032081603
- 1.3776216793060303
- 1.3875235891342164
- 1.3804956221580504
- 1.355179913043976
- 1.3773457765579225
- 1.414053542613983
- 1.3955505657196046
- 1.4353295135498048
- 1.4022847771644593
- 1.3921988606452942
- 1.39080637216568
- 1.391011550426483
- 1.3947182559967042
- 1.3886754417419434
- 1.424470875263214
train_accuracy:
- 0.072
- 0.0
- 0.134
- 0.178
- 0.177
- 0.0
- 0.235
- 0.193
- 0.0
- 0.0
- 0.0
- 0.221
- 0.0
- 0.241
- 0.233
- 0.263
- 0.266
- 0.303
- 0.243
- 0.0
- 0.0
- 0.0
- 0.265
- 0.261
- 0.29
- 0.277
- 0.0
- 0.0
- 0.0
- 0.274
- 0.305
- 0.298
- 0.365
- 0.362
- 0.364
- 0.307
- 0.0
- 0.0
- 0.307
- 0.316
- 0.0
- 0.0
- 0.0
- 0.384
- 0.372
- 0.0
- 0.375
- 0.311
- 0.315
- 0.334
- 0.324
- 0.387
- 0.317
- 0.326
- 0.318
- 0.333
- 0.398
- 0.0
- 0.333
- 0.33
- 0.39
- 0.0
- 0.392
- 0.338
- 0.327
- 0.337
- 0.331
- 0.0
- 0.316
- 0.338
- 0.346
- 0.336
- 0.354
- 0.0
- 0.388
- 0.398
- 0.355
- 0.406
- 0.328
- 0.0
- 0.34
- 0.332
- 0.0
- 0.0
- 0.353
- 0.356
- 0.0
- 0.0
- 0.0
- 0.356
- 0.345
- 0.0
- 0.35
- 0.363
- 0.339
- 0.407
- 0.334
- 0.0
- 0.0
- 0.328
train_loss:
- 3.426
- 2.791
- 2.618
- 2.702
- 2.617
- 2.331
- 2.23
- 2.183
- 2.311
- 2.214
- 2.167
- 2.073
- 1.912
- 1.865
- 1.812
- 1.899
- 1.877
- 1.858
- 1.629
- 1.771
- 1.691
- 1.538
- 1.487
- 1.599
- 1.56
- 1.492
- 1.464
- 1.468
- 1.501
- 1.441
- 1.285
- 1.306
- 1.293
- 1.347
- 1.266
- 1.262
- 1.111
- 1.067
- 1.064
- 1.061
- 1.08
- 0.955
- 0.996
- 0.973
- 1.027
- 0.863
- 0.952
- 0.819
- 0.819
- 0.947
- 0.876
- 0.822
- 0.837
- 0.8
- 0.837
- 0.829
- 0.74
- 0.716
- 0.738
- 0.666
- 0.676
- 0.704
- 0.697
- 0.658
- 0.638
- 0.639
- 0.603
- 0.574
- 0.596
- 0.562
- 0.593
- 0.562
- 0.512
- 0.523
- 0.509
- 0.49
- 0.489
- 0.491
- 0.495
- 0.465
- 0.437
- 0.457
- 0.458
- 0.455
- 0.418
- 0.417
- 0.42
- 0.413
- 0.384
- 0.376
- 0.387
- 0.382
- 0.368
- 0.369
- 0.363
- 0.339
- 0.331
- 0.344
- 0.331
- 0.332
unequal: 0
verbose: 1
