avg_train_accuracy: 0.395
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0458
- 0.0951
- 0.1131
- 0.1306
- 0.1425
- 0.1468
- 0.156
- 0.1626
- 0.1671
- 0.1721
- 0.1776
- 0.1863
- 0.1879
- 0.1917
- 0.1958
- 0.2004
- 0.2016
- 0.2077
- 0.2109
- 0.2159
- 0.2131
- 0.2198
- 0.2228
- 0.2242
- 0.2274
- 0.2318
- 0.2319
- 0.2352
- 0.2337
- 0.2362
- 0.2368
- 0.2413
- 0.2425
- 0.2471
- 0.2462
- 0.2455
- 0.2488
- 0.2511
- 0.2488
- 0.2517
- 0.2528
- 0.2501
- 0.2529
- 0.2522
- 0.2533
- 0.2576
- 0.2609
- 0.2602
- 0.2587
- 0.2596
- 0.2636
- 0.2624
- 0.2641
- 0.2643
- 0.2655
- 0.2671
- 0.2674
- 0.2655
- 0.2662
- 0.2685
- 0.2698
- 0.2692
- 0.272
- 0.2685
- 0.2669
- 0.2691
- 0.2686
- 0.2755
- 0.2762
- 0.2736
- 0.2722
- 0.2715
- 0.2749
- 0.275
- 0.2781
- 0.278
- 0.2769
- 0.2759
- 0.2802
- 0.2804
- 0.2753
- 0.2782
- 0.2836
- 0.2821
- 0.2828
- 0.2809
- 0.2814
- 0.2827
- 0.2886
- 0.289
- 0.2793
- 0.2805
- 0.285
- 0.286
- 0.2868
- 0.2911
- 0.2912
- 0.2898
- 0.2869
- 0.2823
test_loss_list:
- 1.8236293983459473
- 1.7392266654968263
- 1.7215729188919067
- 1.6997097849845886
- 1.6749959897994995
- 1.6302379155158997
- 1.6290861082077026
- 1.5931031394004822
- 1.5958250594139098
- 1.5885727715492248
- 1.6168707036972045
- 1.5869583940505982
- 1.540268349647522
- 1.5442592740058898
- 1.5085017919540404
- 1.520430645942688
- 1.5581071972846985
- 1.5321888947486877
- 1.486405086517334
- 1.4940781807899475
- 1.4640206003189087
- 1.4778806018829345
- 1.4499118041992187
- 1.467072331905365
- 1.470786941051483
- 1.4706086611747742
- 1.4655683541297913
- 1.4700654935836792
- 1.4299881958961487
- 1.447306876182556
- 1.454401535987854
- 1.4990013289451598
- 1.470515022277832
- 1.4554453897476196
- 1.495836582183838
- 1.433501172065735
- 1.4029291939735413
- 1.4201569724082947
- 1.4616762733459472
- 1.4389542984962462
- 1.4298861312866211
- 1.465554518699646
- 1.4275544667243958
- 1.468812861442566
- 1.3986162209510804
- 1.37491605758667
- 1.3985397076606751
- 1.4001027846336365
- 1.4409930443763732
- 1.3825697851181031
- 1.4023147296905518
- 1.3709381628036499
- 1.3882762026786803
- 1.387058355808258
- 1.359584035873413
- 1.3807779479026794
- 1.3566188788414002
- 1.3775228023529054
- 1.380886993408203
- 1.3839259910583497
- 1.388231348991394
- 1.3843480563163757
- 1.3509827876091003
- 1.3437838768959045
- 1.4083719992637633
- 1.3844842195510865
- 1.38777898311615
- 1.3765866494178771
- 1.3468172097206115
- 1.3653922581672668
- 1.375808675289154
- 1.3848899126052856
- 1.3866704511642456
- 1.3909006857872008
- 1.3597182440757751
- 1.3811963152885438
- 1.3893900442123412
- 1.3910004854202271
- 1.3555489015579223
- 1.368359923362732
- 1.4194786834716797
- 1.3772477746009826
- 1.3413346266746522
- 1.361331560611725
- 1.3647603178024292
- 1.3669310021400451
- 1.3674947071075438
- 1.337189757823944
- 1.3253877973556518
- 1.3533654761314393
- 1.4035635328292846
- 1.380168604850769
- 1.3709335541725158
- 1.367890202999115
- 1.3653411197662353
- 1.3357253766059876
- 1.3267502117156982
- 1.3524354338645934
- 1.3593020939826965
- 1.396876413822174
train_accuracy:
- 0.0
- 0.116
- 0.144
- 0.178
- 0.181
- 0.0
- 0.201
- 0.233
- 0.0
- 0.242
- 0.23
- 0.255
- 0.0
- 0.255
- 0.0
- 0.0
- 0.26
- 0.269
- 0.0
- 0.295
- 0.274
- 0.278
- 0.0
- 0.285
- 0.318
- 0.323
- 0.299
- 0.282
- 0.298
- 0.28
- 0.0
- 0.304
- 0.344
- 0.326
- 0.357
- 0.0
- 0.355
- 0.325
- 0.362
- 0.366
- 0.329
- 0.293
- 0.0
- 0.345
- 0.0
- 0.0
- 0.0
- 0.0
- 0.374
- 0.353
- 0.34
- 0.302
- 0.0
- 0.34
- 0.394
- 0.0
- 0.388
- 0.308
- 0.357
- 0.0
- 0.0
- 0.0
- 0.324
- 0.347
- 0.316
- 0.0
- 0.385
- 0.334
- 0.0
- 0.364
- 0.324
- 0.0
- 0.327
- 0.339
- 0.392
- 0.392
- 0.362
- 0.342
- 0.373
- 0.328
- 0.345
- 0.346
- 0.0
- 0.367
- 0.37
- 0.376
- 0.392
- 0.0
- 0.0
- 0.0
- 0.0
- 0.358
- 0.363
- 0.322
- 0.39
- 0.371
- 0.398
- 0.386
- 0.389
- 0.395
train_loss:
- 3.032
- 2.765
- 2.793
- 2.717
- 2.582
- 2.289
- 2.408
- 2.143
- 2.286
- 2.169
- 2.328
- 2.078
- 1.878
- 1.992
- 1.768
- 1.852
- 2.012
- 1.8
- 1.614
- 1.705
- 1.535
- 1.626
- 1.502
- 1.552
- 1.522
- 1.524
- 1.454
- 1.431
- 1.284
- 1.347
- 1.303
- 1.372
- 1.291
- 1.271
- 1.243
- 1.145
- 1.125
- 1.12
- 1.204
- 1.076
- 1.097
- 1.126
- 1.009
- 1.077
- 0.915
- 0.928
- 0.934
- 0.929
- 0.969
- 0.826
- 0.854
- 0.803
- 0.851
- 0.799
- 0.756
- 0.756
- 0.705
- 0.747
- 0.708
- 0.689
- 0.695
- 0.705
- 0.627
- 0.597
- 0.667
- 0.63
- 0.622
- 0.586
- 0.57
- 0.576
- 0.562
- 0.558
- 0.551
- 0.54
- 0.507
- 0.514
- 0.498
- 0.49
- 0.464
- 0.455
- 0.457
- 0.433
- 0.449
- 0.44
- 0.422
- 0.43
- 0.41
- 0.385
- 0.39
- 0.374
- 0.382
- 0.384
- 0.369
- 0.343
- 0.35
- 0.337
- 0.344
- 0.33
- 0.335
- 0.327
unequal: 0
verbose: 1
