avg_train_accuracy: 0.391
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0492
- 0.0996
- 0.1204
- 0.1313
- 0.1421
- 0.149
- 0.1548
- 0.1616
- 0.1705
- 0.1769
- 0.1807
- 0.1859
- 0.1886
- 0.1944
- 0.1953
- 0.1998
- 0.2045
- 0.2083
- 0.2112
- 0.2113
- 0.2148
- 0.2163
- 0.2183
- 0.2217
- 0.2203
- 0.2257
- 0.2301
- 0.2285
- 0.2317
- 0.2343
- 0.2366
- 0.2382
- 0.239
- 0.241
- 0.243
- 0.2429
- 0.2479
- 0.2474
- 0.2481
- 0.2467
- 0.249
- 0.2488
- 0.2551
- 0.2518
- 0.2491
- 0.2523
- 0.257
- 0.2534
- 0.2558
- 0.2544
- 0.2582
- 0.2604
- 0.262
- 0.2589
- 0.2627
- 0.2653
- 0.2581
- 0.2604
- 0.2596
- 0.2643
- 0.2678
- 0.2647
- 0.2656
- 0.2622
- 0.267
- 0.2683
- 0.2672
- 0.2678
- 0.2678
- 0.2719
- 0.2683
- 0.2694
- 0.2709
- 0.2718
- 0.276
- 0.2765
- 0.27
- 0.2734
- 0.2686
- 0.2737
- 0.2731
- 0.2751
- 0.2817
- 0.2758
- 0.2758
- 0.2783
- 0.2787
- 0.2764
- 0.2717
- 0.2762
- 0.2782
- 0.2755
- 0.2792
- 0.2785
- 0.2828
- 0.2847
- 0.2854
- 0.2828
- 0.2779
- 0.2782
test_loss_list:
- 1.8287537050247193
- 1.7474466705322265
- 1.7575430393218994
- 1.6947270631790161
- 1.6790408992767334
- 1.6419497227668762
- 1.635276825428009
- 1.602775251865387
- 1.60884548664093
- 1.5979036378860474
- 1.6360575819015504
- 1.574944221973419
- 1.5732285857200623
- 1.6022468376159669
- 1.572278347015381
- 1.602297179698944
- 1.5682229709625244
- 1.5477428841590881
- 1.5310071229934692
- 1.5258264756202697
- 1.523617560863495
- 1.5519953489303588
- 1.5227078676223755
- 1.4728616523742675
- 1.4882811784744263
- 1.4839489626884461
- 1.4449470806121827
- 1.4667765736579894
- 1.4319671177864075
- 1.4575521230697632
- 1.4590867733955384
- 1.4600474095344544
- 1.4596602392196656
- 1.5029757738113403
- 1.4767998218536378
- 1.4644845962524413
- 1.4539230966567993
- 1.4546695494651793
- 1.5007290577888488
- 1.4362096095085144
- 1.44117520570755
- 1.4807609033584594
- 1.4452440094947816
- 1.4401797318458558
- 1.4747670793533325
- 1.4094359612464904
- 1.4127319598197936
- 1.421217122077942
- 1.4111549139022828
- 1.3840219235420228
- 1.4017585659027099
- 1.3774624109268188
- 1.3677344918251038
- 1.4341536235809327
- 1.3815072226524352
- 1.3666110992431642
- 1.4334753513336183
- 1.450364999771118
- 1.3860395979881286
- 1.4023904991149903
- 1.3655857014656068
- 1.4309347105026244
- 1.406047089099884
- 1.408600788116455
- 1.3631511187553407
- 1.3851319932937622
- 1.4322053074836731
- 1.3746737790107728
- 1.3853925943374634
- 1.3573590683937073
- 1.4189997911453247
- 1.39403422832489
- 1.3983057260513305
- 1.368931610584259
- 1.3539456343650818
- 1.3699331736564637
- 1.4263578844070435
- 1.367824535369873
- 1.4194921255111694
- 1.3971672010421754
- 1.3627577424049377
- 1.3522108745574952
- 1.3438953232765198
- 1.3704026961326599
- 1.3833372950553895
- 1.3875968146324158
- 1.3832916688919068
- 1.3882827734947205
- 1.428035011291504
- 1.4331137752532959
- 1.3961513090133666
- 1.431168863773346
- 1.3943920850753784
- 1.3891562747955322
- 1.3571856117248535
- 1.3435628342628478
- 1.366144416332245
- 1.3710672855377197
- 1.412423505783081
- 1.430333695411682
train_accuracy:
- 0.0
- 0.0
- 0.14
- 0.167
- 0.184
- 0.0
- 0.0
- 0.0
- 0.221
- 0.0
- 0.234
- 0.243
- 0.0
- 0.273
- 0.223
- 0.277
- 0.284
- 0.0
- 0.276
- 0.0
- 0.304
- 0.282
- 0.325
- 0.331
- 0.322
- 0.0
- 0.0
- 0.338
- 0.303
- 0.314
- 0.355
- 0.338
- 0.0
- 0.0
- 0.345
- 0.32
- 0.0
- 0.376
- 0.353
- 0.325
- 0.376
- 0.321
- 0.333
- 0.341
- 0.331
- 0.0
- 0.0
- 0.37
- 0.383
- 0.0
- 0.0
- 0.0
- 0.0
- 0.357
- 0.336
- 0.351
- 0.371
- 0.386
- 0.0
- 0.0
- 0.357
- 0.0
- 0.36
- 0.375
- 0.357
- 0.346
- 0.0
- 0.0
- 0.0
- 0.399
- 0.392
- 0.37
- 0.369
- 0.388
- 0.362
- 0.385
- 0.346
- 0.374
- 0.0
- 0.0
- 0.0
- 0.371
- 0.398
- 0.39
- 0.0
- 0.367
- 0.433
- 0.361
- 0.386
- 0.387
- 0.351
- 0.404
- 0.388
- 0.383
- 0.4
- 0.0
- 0.365
- 0.381
- 0.4
- 0.391
train_loss:
- 3.386
- 2.766
- 3.074
- 2.503
- 2.599
- 2.311
- 2.399
- 2.157
- 2.263
- 2.197
- 2.277
- 1.954
- 2.016
- 2.168
- 1.942
- 2.02
- 1.872
- 1.822
- 1.731
- 1.699
- 1.667
- 1.75
- 1.596
- 1.472
- 1.558
- 1.486
- 1.365
- 1.426
- 1.312
- 1.374
- 1.343
- 1.319
- 1.28
- 1.328
- 1.218
- 1.163
- 1.179
- 1.114
- 1.171
- 1.061
- 1.061
- 1.118
- 1.021
- 1.005
- 1.014
- 0.909
- 0.915
- 0.92
- 0.899
- 0.838
- 0.854
- 0.808
- 0.767
- 0.823
- 0.759
- 0.714
- 0.781
- 0.755
- 0.73
- 0.712
- 0.639
- 0.671
- 0.663
- 0.661
- 0.613
- 0.616
- 0.605
- 0.579
- 0.587
- 0.552
- 0.555
- 0.535
- 0.527
- 0.531
- 0.498
- 0.489
- 0.491
- 0.485
- 0.481
- 0.447
- 0.446
- 0.427
- 0.438
- 0.427
- 0.406
- 0.406
- 0.416
- 0.398
- 0.406
- 0.366
- 0.398
- 0.393
- 0.371
- 0.358
- 0.358
- 0.331
- 0.359
- 0.339
- 0.343
- 0.328
unequal: 0
verbose: 1
