avg_train_accuracy: 0.415
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033
- 0.0924
- 0.1152
- 0.1283
- 0.1387
- 0.1461
- 0.1574
- 0.166
- 0.1761
- 0.1766
- 0.1822
- 0.1905
- 0.1941
- 0.1944
- 0.2014
- 0.2035
- 0.2086
- 0.2109
- 0.2123
- 0.2157
- 0.2165
- 0.2185
- 0.2215
- 0.2254
- 0.2265
- 0.2277
- 0.2322
- 0.2317
- 0.2338
- 0.2366
- 0.2382
- 0.2402
- 0.2403
- 0.2416
- 0.2441
- 0.2427
- 0.2458
- 0.2495
- 0.2506
- 0.2518
- 0.2544
- 0.2548
- 0.257
- 0.2559
- 0.257
- 0.2585
- 0.2629
- 0.2633
- 0.2621
- 0.2627
- 0.263
- 0.265
- 0.2658
- 0.2646
- 0.2692
- 0.2658
- 0.2681
- 0.2683
- 0.2702
- 0.2673
- 0.2683
- 0.2731
- 0.2735
- 0.2734
- 0.2764
- 0.2764
- 0.2732
- 0.276
- 0.2735
- 0.2772
- 0.2775
- 0.2751
- 0.2765
- 0.2784
- 0.2756
- 0.2759
- 0.2802
- 0.2797
- 0.2789
- 0.2806
- 0.2812
- 0.2844
- 0.2823
- 0.2854
- 0.288
- 0.287
- 0.2877
- 0.2905
- 0.2935
- 0.2899
- 0.2878
- 0.2812
- 0.2874
- 0.2901
- 0.2952
- 0.2939
- 0.2919
- 0.2887
- 0.2916
- 0.2909
test_loss_list:
- 1.8433307361602784
- 1.7643953227996827
- 1.7308518266677857
- 1.7009139704704284
- 1.6738295578956603
- 1.6253185486793518
- 1.6173061990737916
- 1.6074292373657226
- 1.569703803062439
- 1.5463811779022216
- 1.5312194561958312
- 1.5138538932800294
- 1.532902843952179
- 1.5764364051818847
- 1.51598171710968
- 1.5230595588684082
- 1.5150572776794433
- 1.4799934482574464
- 1.4942216777801514
- 1.5336363196372986
- 1.5099129462242127
- 1.501862199306488
- 1.5418137407302857
- 1.5159461045265197
- 1.4924371719360352
- 1.448718945980072
- 1.4269986534118653
- 1.4458743166923522
- 1.4930038285255431
- 1.465271713733673
- 1.558308141231537
- 1.4904959464073182
- 1.435838270187378
- 1.4420182418823242
- 1.4465753698349
- 1.4885971689224242
- 1.5022911477088927
- 1.5155604267120362
- 1.5266799783706666
- 1.4422166848182678
- 1.4936250996589662
- 1.4633479237556457
- 1.4097815299034118
- 1.3878325867652892
- 1.4042195558547974
- 1.4088633751869202
- 1.3756731414794923
- 1.4411733531951905
- 1.4525220465660096
- 1.4675429821014405
- 1.4250351309776306
- 1.4121935033798219
- 1.37545325756073
- 1.3897017812728882
- 1.3578723573684692
- 1.3796268558502198
- 1.351968674659729
- 1.3815030479431152
- 1.4241496849060058
- 1.3716948175430297
- 1.3836224341392518
- 1.3874874091148377
- 1.353102433681488
- 1.3401970100402831
- 1.334201419353485
- 1.3591527938842773
- 1.3661349177360536
- 1.3407890367507935
- 1.4066590023040773
- 1.3535249781608583
- 1.370555477142334
- 1.376240270137787
- 1.3782729339599609
- 1.3739588689804076
- 1.416190733909607
- 1.4336413526535035
- 1.3648003506660462
- 1.3759938073158264
- 1.4121217489242555
- 1.3899486780166626
- 1.3493685913085938
- 1.3573002099990845
- 1.3667663621902466
- 1.3343949389457703
- 1.3247346305847167
- 1.3532294726371765
- 1.328567373752594
- 1.3212937426567077
- 1.3178895497322083
- 1.3482732343673707
- 1.3530784606933595
- 1.3909192538261415
- 1.3358299136161804
- 1.3558843636512756
- 1.328000295162201
- 1.3512666964530944
- 1.3610379886627197
- 1.3914803504943847
- 1.3340250062942505
- 1.3532992148399352
train_accuracy:
- 0.046
- 0.115
- 0.0
- 0.185
- 0.179
- 0.201
- 0.207
- 0.243
- 0.0
- 0.257
- 0.0
- 0.0
- 0.237
- 0.245
- 0.0
- 0.0
- 0.282
- 0.0
- 0.302
- 0.275
- 0.316
- 0.339
- 0.274
- 0.0
- 0.328
- 0.0
- 0.272
- 0.369
- 0.299
- 0.275
- 0.35
- 0.309
- 0.331
- 0.359
- 0.311
- 0.346
- 0.37
- 0.377
- 0.314
- 0.314
- 0.347
- 0.0
- 0.0
- 0.0
- 0.396
- 0.354
- 0.355
- 0.353
- 0.0
- 0.336
- 0.362
- 0.32
- 0.399
- 0.365
- 0.376
- 0.412
- 0.0
- 0.376
- 0.395
- 0.347
- 0.357
- 0.415
- 0.357
- 0.0
- 0.366
- 0.41
- 0.392
- 0.0
- 0.417
- 0.41
- 0.356
- 0.351
- 0.0
- 0.424
- 0.427
- 0.384
- 0.0
- 0.394
- 0.372
- 0.358
- 0.372
- 0.0
- 0.422
- 0.0
- 0.0
- 0.391
- 0.34
- 0.392
- 0.328
- 0.344
- 0.382
- 0.0
- 0.376
- 0.419
- 0.0
- 0.445
- 0.381
- 0.418
- 0.386
- 0.415
train_loss:
- 3.405
- 3.029
- 2.814
- 2.703
- 2.545
- 2.263
- 2.395
- 2.293
- 2.057
- 1.996
- 1.942
- 1.896
- 2.002
- 2.117
- 1.748
- 1.849
- 1.832
- 1.67
- 1.731
- 1.837
- 1.651
- 1.646
- 1.706
- 1.55
- 1.518
- 1.378
- 1.37
- 1.409
- 1.48
- 1.365
- 1.5
- 1.298
- 1.182
- 1.301
- 1.204
- 1.256
- 1.228
- 1.18
- 1.148
- 1.047
- 1.115
- 1.021
- 0.971
- 0.948
- 0.988
- 0.951
- 0.878
- 0.94
- 0.944
- 0.901
- 0.841
- 0.818
- 0.777
- 0.78
- 0.74
- 0.762
- 0.717
- 0.713
- 0.722
- 0.681
- 0.67
- 0.664
- 0.638
- 0.604
- 0.605
- 0.594
- 0.615
- 0.592
- 0.596
- 0.551
- 0.564
- 0.527
- 0.508
- 0.542
- 0.523
- 0.494
- 0.51
- 0.484
- 0.478
- 0.457
- 0.447
- 0.432
- 0.435
- 0.428
- 0.422
- 0.398
- 0.405
- 0.387
- 0.38
- 0.372
- 0.385
- 0.366
- 0.363
- 0.332
- 0.347
- 0.344
- 0.329
- 0.354
- 0.333
- 0.326
unequal: 0
verbose: 1
