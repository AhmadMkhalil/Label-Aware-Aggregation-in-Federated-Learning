avg_train_accuracy: 0.381
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0386
- 0.0889
- 0.109
- 0.1169
- 0.1292
- 0.1321
- 0.1363
- 0.1485
- 0.1589
- 0.0447
- 0.1585
- 0.0403
- 0.1727
- 0.1706
- 0.1749
- 0.0505
- 0.1782
- 0.1855
- 0.1796
- 0.1915
- 0.1885
- 0.1933
- 0.1956
- 0.0553
- 0.1916
- 0.0451
- 0.0521
- 0.197
- 0.2063
- 0.2059
- 0.0442
- 0.2028
- 0.2035
- 0.2105
- 0.2149
- 0.2171
- 0.2221
- 0.2185
- 0.0528
- 0.0463
- 0.2235
- 0.2245
- 0.2212
- 0.0592
- 0.2262
- 0.236
- 0.2353
- 0.2345
- 0.0536
- 0.232
- 0.0614
- 0.2341
- 0.2356
- 0.2367
- 0.238
- 0.2453
- 0.2415
- 0.2408
- 0.2366
- 0.0655
- 0.0529
- 0.2416
- 0.0713
- 0.0575
- 0.2467
- 0.2433
- 0.2406
- 0.2382
- 0.2495
- 0.2477
- 0.2431
- 0.2497
- 0.2501
- 0.2369
- 0.066
- 0.2471
- 0.0659
- 0.0699
- 0.2544
- 0.0709
- 0.2511
- 0.2492
- 0.248
- 0.2547
- 0.0739
- 0.2496
- 0.0817
- 0.074
- 0.2617
- 0.2598
- 0.2613
- 0.2605
- 0.075
- 0.2644
- 0.2586
- 0.2575
- 0.2575
- 0.2578
- 0.0835
- 0.263
test_loss_list:
- 1.8884457778930663
- 1.932570071220398
- 1.9234596681594849
- 1.9625261688232423
- 1.9715654754638672
- 1.987315993309021
- 1.9905418491363525
- 2.0054374980926513
- 1.9947052431106567
- 3.291048107147217
- 1.871333932876587
- 3.180859007835388
- 1.7708089447021484
- 1.8335324048995971
- 1.8547784662246705
- 3.1353223609924314
- 1.7300505757331848
- 1.76332368850708
- 1.8133702707290649
- 1.82347008228302
- 1.8408203411102295
- 1.8777078008651733
- 1.8673234367370606
- 3.1432837677001952
- 1.795023832321167
- 3.0502023458480836
- 3.0482946491241454
- 1.6136748433113097
- 1.6549751543998719
- 1.7121207547187804
- 3.0390844440460203
- 1.6645884442329406
- 1.7042136597633362
- 1.7439310145378113
- 1.7614704084396362
- 1.7675657320022582
- 1.7963346147537231
- 1.8084067821502685
- 3.121906876564026
- 2.9893527173995973
- 1.6302534389495849
- 1.6775975942611694
- 1.753332827091217
- 2.8841796588897703
- 1.6151854109764099
- 1.654384446144104
- 1.6835861039161681
- 1.7030557823181152
- 2.919362773895264
- 1.639732141494751
- 2.8338729190826415
- 1.596142737865448
- 1.6349189567565918
- 1.6808087396621705
- 1.7100164294242859
- 1.7015966796875
- 1.7278250169754028
- 1.7434953546524048
- 1.7721630215644837
- 2.859249472618103
- 2.825860848426819
- 1.6245599102973938
- 2.7328158235549926
- 2.880736541748047
- 1.5104032826423646
- 1.569457561969757
- 1.6338686513900758
- 1.647043116092682
- 1.6621359252929688
- 1.6701124382019044
- 1.7003661751747132
- 1.716632192134857
- 1.7193183922767639
- 1.7502043843269348
- 2.9066795396804808
- 1.6446162486076354
- 2.772836446762085
- 2.6051609706878662
- 1.5099918580055236
- 2.724204378128052
- 1.5050096940994262
- 1.5743369483947753
- 1.6157586908340453
- 1.6328748297691345
- 2.7657152700424192
- 1.632408242225647
- 2.7593217420578005
- 2.628462986946106
- 1.525042977333069
- 1.56606219291687
- 1.6147134017944336
- 1.6246715521812438
- 2.6267421054840088
- 1.52271080493927
- 1.574969961643219
- 1.6005025291442871
- 1.6179026079177856
- 1.6610395574569703
- 2.680476803779602
- 1.54423415184021
train_accuracy:
- 0.049
- 0.115
- 0.167
- 0.165
- 0.192
- 0.179
- 0.179
- 0.222
- 0.197
- 0.0
- 0.197
- 0.0
- 0.233
- 0.233
- 0.228
- 0.0
- 0.251
- 0.246
- 0.238
- 0.268
- 0.271
- 0.276
- 0.284
- 0.0
- 0.284
- 0.0
- 0.0
- 0.295
- 0.276
- 0.3
- 0.0
- 0.277
- 0.263
- 0.279
- 0.271
- 0.271
- 0.252
- 0.295
- 0.0
- 0.0
- 0.311
- 0.338
- 0.288
- 0.0
- 0.267
- 0.323
- 0.277
- 0.305
- 0.0
- 0.314
- 0.0
- 0.306
- 0.289
- 0.352
- 0.349
- 0.327
- 0.374
- 0.322
- 0.29
- 0.0
- 0.0
- 0.359
- 0.0
- 0.0
- 0.366
- 0.318
- 0.305
- 0.344
- 0.357
- 0.364
- 0.359
- 0.329
- 0.37
- 0.339
- 0.0
- 0.313
- 0.0
- 0.0
- 0.378
- 0.0
- 0.37
- 0.34
- 0.346
- 0.354
- 0.0
- 0.359
- 0.0
- 0.0
- 0.371
- 0.331
- 0.352
- 0.398
- 0.0
- 0.344
- 0.361
- 0.323
- 0.316
- 0.37
- 0.0
- 0.381
train_loss:
- 4.029
- 3.455
- 3.252
- 2.792
- 2.796
- 2.496
- 2.835
- 2.427
- 2.759
- 1.909
- 3.006
- 2.021
- 3.022
- 2.378
- 2.452
- 1.712
- 2.828
- 2.311
- 1.892
- 2.13
- 2.1
- 1.977
- 1.782
- 1.248
- 1.748
- 1.717
- 1.705
- 2.2
- 2.083
- 1.734
- 1.342
- 2.053
- 1.362
- 1.787
- 1.969
- 1.406
- 1.594
- 1.343
- 1.325
- 1.384
- 1.762
- 1.58
- 1.972
- 1.125
- 1.725
- 1.461
- 1.157
- 1.385
- 1.111
- 1.161
- 0.834
- 1.854
- 1.123
- 1.225
- 1.392
- 1.052
- 1.249
- 0.831
- 0.622
- 0.777
- 1.18
- 1.257
- 0.539
- 1.319
- 1.29
- 0.691
- 0.466
- 0.828
- 0.84
- 0.638
- 1.139
- 0.994
- 0.551
- 1.185
- 0.966
- 1.426
- 0.921
- 0.811
- 1.121
- 0.702
- 0.778
- 0.953
- 0.708
- 0.828
- 0.653
- 0.941
- 0.44
- 0.688
- 0.68
- 0.682
- 0.664
- 0.63
- 0.799
- 0.657
- 0.523
- 0.369
- 0.225
- 0.495
- 0.59
- 0.557
unequal: 0
verbose: 1
