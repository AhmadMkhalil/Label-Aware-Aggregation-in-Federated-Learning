avg_train_accuracy: 0.338
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0441
- 0.0882
- 0.0942
- 0.1132
- 0.1189
- 0.0459
- 0.1302
- 0.136
- 0.0399
- 0.1371
- 0.0471
- 0.0416
- 0.1444
- 0.0454
- 0.1506
- 0.162
- 0.1583
- 0.1582
- 0.1677
- 0.0474
- 0.1762
- 0.1679
- 0.1732
- 0.0523
- 0.0539
- 0.1829
- 0.0516
- 0.1873
- 0.0495
- 0.1898
- 0.1916
- 0.201
- 0.1939
- 0.1973
- 0.1978
- 0.2159
- 0.2083
- 0.2079
- 0.0538
- 0.2109
- 0.2145
- 0.2086
- 0.0585
- 0.2159
- 0.0626
- 0.217
- 0.0581
- 0.218
- 0.0634
- 0.2218
- 0.2195
- 0.0681
- 0.2249
- 0.0709
- 0.2259
- 0.2302
- 0.228
- 0.2366
- 0.2258
- 0.0677
- 0.2364
- 0.2424
- 0.2413
- 0.2359
- 0.2294
- 0.062
- 0.0685
- 0.0647
- 0.0638
- 0.2369
- 0.0647
- 0.2396
- 0.2441
- 0.0705
- 0.2444
- 0.2447
- 0.0722
- 0.2399
- 0.082
- 0.2438
- 0.2403
- 0.2538
- 0.2515
- 0.2482
- 0.0842
- 0.2551
- 0.2458
- 0.2422
- 0.2462
- 0.2475
- 0.088
- 0.0755
- 0.2514
- 0.093
- 0.2562
- 0.2503
- 0.0766
- 0.0855
- 0.2638
- 0.2551
test_loss_list:
- 1.8757954168319702
- 1.9255267238616944
- 1.949714994430542
- 1.9629334926605224
- 1.9685715103149415
- 3.2560227632522585
- 1.874931845664978
- 1.8919037914276122
- 3.3004348993301393
- 1.815857572555542
- 3.229728045463562
- 3.1629659795761107
- 1.7296097874641418
- 3.1307455110549927
- 1.7514591884613038
- 1.7782423210144043
- 1.8153738260269165
- 1.8442309713363647
- 1.8590884590148926
- 3.1967913579940794
- 1.7734635829925538
- 1.8233131790161132
- 1.8518229341506958
- 3.146254315376282
- 3.325973181724548
- 1.7096135640144348
- 2.960822458267212
- 1.6443509078025818
- 3.0099397993087766
- 1.6263078784942626
- 1.6914715480804443
- 1.7195981669425964
- 1.737596275806427
- 1.751247079372406
- 1.774879469871521
- 1.7720758247375488
- 1.8157221508026122
- 1.8058539390563966
- 2.9610823726654054
- 1.7132145810127257
- 1.7610495162010193
- 1.781809151172638
- 2.973574466705322
- 1.74010977268219
- 2.9105432748794557
- 1.7383358955383301
- 2.8862780952453613
- 1.6497833466529845
- 2.786359915733337
- 1.6393245482444763
- 1.6935699987411499
- 2.779360542297363
- 1.692586567401886
- 2.766544055938721
- 1.6889859056472778
- 1.7176773834228516
- 1.7570345330238342
- 1.7555282998085022
- 1.7954437923431397
- 2.917006802558899
- 1.6223476910591126
- 1.665762574672699
- 1.6989432740211488
- 1.7285952115058898
- 1.7299294233322144
- 2.8443618869781493
- 2.64579460144043
- 2.7502434921264647
- 2.9993736743927
- 1.5102962517738343
- 2.7010085773468018
- 1.5386272001266479
- 1.5588145422935487
- 2.690170979499817
- 1.5680361580848694
- 1.605479464530945
- 2.716379041671753
- 1.5985826563835144
- 2.5492233419418335
- 1.555748450756073
- 1.6252813196182252
- 1.6258106708526612
- 1.6437844085693358
- 1.68539124250412
- 2.6182771253585817
- 1.6184433794021607
- 1.661631634235382
- 1.688609743118286
- 1.7088123178482055
- 1.7266372299194337
- 2.621456837654114
- 2.7434442758560182
- 1.5510775327682496
- 2.4775259256362916
- 1.561664686203003
- 1.6229481983184815
- 2.5985644388198854
- 2.4865020608901975
- 1.4953749394416809
- 1.5485325121879578
train_accuracy:
- 0.059
- 0.101
- 0.141
- 0.129
- 0.174
- 0.0
- 0.173
- 0.214
- 0.0
- 0.198
- 0.0
- 0.0
- 0.215
- 0.0
- 0.201
- 0.223
- 0.227
- 0.219
- 0.23
- 0.0
- 0.256
- 0.256
- 0.239
- 0.0
- 0.0
- 0.239
- 0.0
- 0.26
- 0.0
- 0.249
- 0.257
- 0.264
- 0.295
- 0.246
- 0.316
- 0.303
- 0.327
- 0.243
- 0.0
- 0.268
- 0.325
- 0.281
- 0.0
- 0.287
- 0.0
- 0.34
- 0.0
- 0.309
- 0.0
- 0.295
- 0.327
- 0.0
- 0.305
- 0.0
- 0.302
- 0.328
- 0.316
- 0.308
- 0.287
- 0.0
- 0.357
- 0.324
- 0.301
- 0.32
- 0.325
- 0.0
- 0.0
- 0.0
- 0.0
- 0.363
- 0.0
- 0.334
- 0.329
- 0.0
- 0.341
- 0.321
- 0.0
- 0.324
- 0.0
- 0.323
- 0.329
- 0.334
- 0.348
- 0.332
- 0.0
- 0.388
- 0.376
- 0.384
- 0.387
- 0.384
- 0.0
- 0.0
- 0.376
- 0.0
- 0.387
- 0.337
- 0.0
- 0.0
- 0.343
- 0.338
train_loss:
- 4.027
- 3.458
- 3.321
- 3.154
- 2.822
- 1.831
- 3.34
- 2.832
- 1.888
- 2.917
- 1.31
- 2.128
- 3.046
- 1.181
- 3.001
- 2.628
- 2.287
- 1.889
- 2.255
- 1.55
- 2.211
- 1.641
- 1.812
- 1.483
- 0.691
- 2.805
- 1.251
- 2.642
- 1.267
- 2.409
- 1.63
- 2.184
- 2.199
- 2.101
- 1.802
- 1.998
- 1.515
- 1.786
- 1.193
- 1.627
- 1.395
- 1.864
- 0.888
- 1.57
- 0.65
- 1.865
- 1.179
- 1.451
- 0.639
- 1.478
- 1.115
- 0.575
- 1.623
- 0.471
- 1.252
- 1.717
- 1.216
- 1.22
- 1.719
- 1.272
- 1.589
- 0.967
- 1.147
- 1.366
- 1.093
- 1.031
- 0.776
- 1.0
- 0.365
- 1.378
- 0.686
- 1.588
- 0.953
- 0.597
- 1.368
- 0.692
- 0.504
- 0.676
- 0.56
- 1.293
- 0.963
- 1.106
- 0.861
- 0.782
- 0.51
- 1.117
- 0.603
- 1.071
- 0.558
- 0.36
- 0.429
- 0.942
- 1.099
- 0.314
- 0.559
- 0.818
- 0.674
- 0.41
- 0.823
- 0.602
unequal: 0
verbose: 1
