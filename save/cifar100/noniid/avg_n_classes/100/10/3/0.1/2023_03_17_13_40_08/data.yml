avg_train_accuracy: 0.375
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0487
- 0.0836
- 0.1074
- 0.1151
- 0.1231
- 0.1343
- 0.135
- 0.1447
- 0.145
- 0.0374
- 0.1515
- 0.1588
- 0.163
- 0.1729
- 0.0431
- 0.1683
- 0.0394
- 0.1772
- 0.0446
- 0.1817
- 0.0492
- 0.1823
- 0.1791
- 0.1844
- 0.1904
- 0.1924
- 0.0457
- 0.1872
- 0.2053
- 0.2028
- 0.203
- 0.1989
- 0.0508
- 0.2062
- 0.0476
- 0.2089
- 0.053
- 0.0507
- 0.0503
- 0.2145
- 0.2099
- 0.2173
- 0.0539
- 0.0523
- 0.2109
- 0.2177
- 0.2166
- 0.0566
- 0.2285
- 0.2238
- 0.2241
- 0.2179
- 0.0577
- 0.0567
- 0.2226
- 0.2315
- 0.0596
- 0.2305
- 0.0651
- 0.2283
- 0.2297
- 0.2315
- 0.0567
- 0.2338
- 0.2394
- 0.2319
- 0.2345
- 0.2307
- 0.2385
- 0.2377
- 0.243
- 0.2362
- 0.2406
- 0.2419
- 0.0682
- 0.2396
- 0.2447
- 0.2409
- 0.2468
- 0.2322
- 0.2425
- 0.2385
- 0.0729
- 0.0609
- 0.255
- 0.2538
- 0.0721
- 0.2576
- 0.0743
- 0.2507
- 0.0762
- 0.2559
- 0.2512
- 0.2524
- 0.0756
- 0.0724
- 0.2579
- 0.0834
- 0.2513
- 0.2562
test_loss_list:
- 1.8789855813980103
- 1.923174376487732
- 1.934118914604187
- 1.947787356376648
- 1.9854351806640624
- 1.9841829776763915
- 1.9944960594177246
- 2.0129284286499023
- 2.0178173351287843
- 3.3099009799957275
- 1.8816706180572509
- 1.9172722053527833
- 1.940386266708374
- 1.9391363525390626
- 3.2727812480926515
- 1.891965103149414
- 3.2693259954452514
- 1.7713074207305908
- 3.1659257078170775
- 1.7651103281974792
- 3.1208016157150267
- 1.6768623113632202
- 1.7451050400733947
- 1.7643311882019044
- 1.7753012084960937
- 1.8105370330810546
- 3.073361349105835
- 1.7218972396850587
- 1.7507044935226441
- 1.7726966190338134
- 1.8004866027832032
- 1.8331691932678222
- 3.043019061088562
- 1.7424434304237366
- 3.0096624994277956
- 1.6576952695846559
- 2.9329765701293944
- 3.254678111076355
- 3.374201946258545
- 1.6541929292678832
- 1.711760721206665
- 1.7363064885139465
- 3.0176626300811766
- 2.903080801963806
- 1.614333896636963
- 1.6632493233680725
- 1.6953248977661133
- 2.908183660507202
- 1.650564432144165
- 1.669649169445038
- 1.6958021664619445
- 1.7184886956214904
- 2.8453341197967528
- 2.938641600608826
- 1.6129391288757324
- 1.6411697697639465
- 2.9519432640075682
- 1.6276107549667358
- 2.8231799173355103
- 1.6794950485229492
- 1.686821894645691
- 1.715415790081024
- 2.8388666343688964
- 1.610173761844635
- 1.6070379638671874
- 1.6621190094947815
- 1.6828985452651977
- 1.7229772233963012
- 1.7031530499458314
- 1.7229085445404053
- 1.726402928829193
- 1.7668865180015565
- 1.7802759504318237
- 1.7779098629951477
- 2.8157075452804565
- 1.685368685722351
- 1.7032037115097045
- 1.7298395466804504
- 1.7310088896751403
- 1.7675847625732422
- 1.7529751920700074
- 1.7918620920181274
- 2.874871263504028
- 2.8138976001739504
- 1.588061830997467
- 1.6021274185180665
- 2.7375574493408203
- 1.6044562792778014
- 2.722889332771301
- 1.6378376269340515
- 2.6446669816970827
- 1.5408725976943969
- 1.6008684396743775
- 1.6277952814102172
- 2.7323665904998777
- 2.6212072563171387
- 1.5091495323181152
- 2.561823010444641
- 1.5448043417930604
- 1.5702972197532654
train_accuracy:
- 0.073
- 0.119
- 0.17
- 0.165
- 0.168
- 0.213
- 0.162
- 0.218
- 0.228
- 0.0
- 0.225
- 0.233
- 0.237
- 0.267
- 0.0
- 0.226
- 0.0
- 0.238
- 0.0
- 0.292
- 0.0
- 0.223
- 0.226
- 0.284
- 0.255
- 0.274
- 0.0
- 0.285
- 0.253
- 0.283
- 0.287
- 0.281
- 0.0
- 0.286
- 0.0
- 0.336
- 0.0
- 0.0
- 0.0
- 0.295
- 0.306
- 0.306
- 0.0
- 0.0
- 0.309
- 0.283
- 0.284
- 0.0
- 0.323
- 0.358
- 0.318
- 0.34
- 0.0
- 0.0
- 0.322
- 0.317
- 0.0
- 0.321
- 0.0
- 0.331
- 0.343
- 0.305
- 0.0
- 0.299
- 0.361
- 0.339
- 0.352
- 0.34
- 0.351
- 0.342
- 0.359
- 0.344
- 0.363
- 0.353
- 0.0
- 0.319
- 0.36
- 0.341
- 0.363
- 0.344
- 0.393
- 0.363
- 0.0
- 0.0
- 0.343
- 0.395
- 0.0
- 0.37
- 0.0
- 0.359
- 0.0
- 0.361
- 0.376
- 0.362
- 0.0
- 0.0
- 0.368
- 0.0
- 0.341
- 0.375
train_loss:
- 4.001
- 3.531
- 3.259
- 3.186
- 2.894
- 2.728
- 2.548
- 2.367
- 2.772
- 1.983
- 3.088
- 2.321
- 2.189
- 2.379
- 1.561
- 2.555
- 2.073
- 2.895
- 1.365
- 2.71
- 1.743
- 2.565
- 1.847
- 2.102
- 1.655
- 1.937
- 1.464
- 2.577
- 2.031
- 1.535
- 1.602
- 1.205
- 1.198
- 2.211
- 1.444
- 2.056
- 0.958
- 0.526
- 0.398
- 2.315
- 1.489
- 1.767
- 1.392
- 0.922
- 1.595
- 1.728
- 1.241
- 0.686
- 2.105
- 1.469
- 1.497
- 1.141
- 0.631
- 1.199
- 1.809
- 1.378
- 0.801
- 1.521
- 0.622
- 1.513
- 0.897
- 1.275
- 1.231
- 1.139
- 1.154
- 1.326
- 0.926
- 0.597
- 1.059
- 1.137
- 0.927
- 0.865
- 1.094
- 0.671
- 0.854
- 1.14
- 0.907
- 0.565
- 0.753
- 1.321
- 0.803
- 0.603
- 0.703
- 0.987
- 1.084
- 0.87
- 0.47
- 1.157
- 0.368
- 0.783
- 1.097
- 1.08
- 0.528
- 0.606
- 0.745
- 0.747
- 1.014
- 0.553
- 0.593
- 0.542
unequal: 0
verbose: 1
