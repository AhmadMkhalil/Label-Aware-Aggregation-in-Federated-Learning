avg_train_accuracy: 0.338
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0393
- 0.0828
- 0.0917
- 0.1058
- 0.0393
- 0.1155
- 0.1281
- 0.1419
- 0.1433
- 0.144
- 0.0519
- 0.1592
- 0.0393
- 0.1477
- 0.1611
- 0.0542
- 0.0465
- 0.1587
- 0.1737
- 0.0561
- 0.1798
- 0.1853
- 0.1818
- 0.0473
- 0.0589
- 0.1863
- 0.1896
- 0.1962
- 0.1939
- 0.0612
- 0.1922
- 0.0632
- 0.1992
- 0.0669
- 0.0477
- 0.203
- 0.2032
- 0.0676
- 0.2081
- 0.0477
- 0.0592
- 0.0499
- 0.2104
- 0.0735
- 0.2146
- 0.2138
- 0.0538
- 0.2098
- 0.2156
- 0.2149
- 0.0486
- 0.221
- 0.2189
- 0.0543
- 0.22
- 0.2247
- 0.2162
- 0.2239
- 0.2217
- 0.218
- 0.2273
- 0.2375
- 0.2348
- 0.2367
- 0.0802
- 0.236
- 0.2376
- 0.2356
- 0.2266
- 0.2315
- 0.2326
- 0.238
- 0.236
- 0.2331
- 0.2384
- 0.2352
- 0.0595
- 0.2496
- 0.2434
- 0.0672
- 0.2404
- 0.2468
- 0.2511
- 0.0691
- 0.0799
- 0.0778
- 0.0686
- 0.2551
- 0.2531
- 0.2584
- 0.0744
- 0.2554
- 0.0603
- 0.2482
- 0.2519
- 0.2465
- 0.2576
- 0.2533
- 0.2562
- 0.2546
test_loss_list:
- 1.8984215784072875
- 1.9369716453552246
- 1.9708342456817627
- 1.9704405641555787
- 3.3888665580749513
- 1.884675340652466
- 1.9093843698501587
- 1.9365066385269165
- 1.960466890335083
- 1.9874175691604614
- 3.23895471572876
- 1.8325526189804078
- 3.218494529724121
- 1.7578790092468262
- 1.7838698148727417
- 3.158714761734009
- 3.104632592201233
- 1.6747571873664855
- 1.716987600326538
- 3.049004988670349
- 1.6815911960601806
- 1.735811688899994
- 1.755800404548645
- 3.0839157056808473
- 2.981678671836853
- 1.6305355310440064
- 1.7036685132980347
- 1.7083171582221985
- 1.7465158677101136
- 2.9990115118026734
- 1.7214529728889465
- 3.0351008129119874
- 1.7088010668754579
- 2.9457644605636597
- 2.986922655105591
- 1.6153668832778931
- 1.6518075585365295
- 2.82581832408905
- 1.664148941040039
- 2.9976733779907225
- 3.002896952629089
- 2.908358998298645
- 1.5417423415184022
- 2.703146162033081
- 1.5671124029159547
- 1.6112775421142578
- 2.9016232538223266
- 1.5951631188392639
- 1.609361126422882
- 1.6351406598091125
- 2.9344960165023806
- 1.5761701440811158
- 1.6419335842132567
- 2.8283084297180174
- 1.5739832925796509
- 1.6270382118225097
- 1.675100440979004
- 1.67495281457901
- 1.7113073325157167
- 1.753000509738922
- 1.7326435375213622
- 1.728538761138916
- 1.733092293739319
- 1.7513841080665589
- 2.749372429847717
- 1.6259778761863708
- 1.661734368801117
- 1.6967215323448182
- 1.7315503787994384
- 1.7451370334625245
- 1.760075867176056
- 1.7543059062957764
- 1.7534122085571289
- 1.7802934074401855
- 1.7711157131195068
- 1.8022153663635254
- 2.883266406059265
- 1.6406087756156922
- 1.6750529837608337
- 2.7897234106063844
- 1.678162636756897
- 1.692468113899231
- 1.7018052530288696
- 2.7964670658111572
- 2.7326450729370118
- 2.870559883117676
- 2.8252268552780153
- 1.5536920785903932
- 1.598949613571167
- 1.6159846138954164
- 2.6397708368301394
- 1.5974282288551331
- 2.7362288856506347
- 1.504316222667694
- 1.5432093739509583
- 1.6271060991287232
- 1.5972969079017638
- 1.6381395745277405
- 1.6309827494621276
- 1.6479329514503478
train_accuracy:
- 0.05
- 0.132
- 0.098
- 0.18
- 0.0
- 0.151
- 0.195
- 0.174
- 0.2
- 0.208
- 0.0
- 0.21
- 0.0
- 0.172
- 0.202
- 0.0
- 0.0
- 0.181
- 0.261
- 0.0
- 0.205
- 0.24
- 0.26
- 0.0
- 0.0
- 0.222
- 0.253
- 0.254
- 0.259
- 0.0
- 0.256
- 0.0
- 0.289
- 0.0
- 0.0
- 0.294
- 0.247
- 0.0
- 0.294
- 0.0
- 0.0
- 0.0
- 0.285
- 0.0
- 0.305
- 0.266
- 0.0
- 0.263
- 0.311
- 0.326
- 0.0
- 0.289
- 0.3
- 0.0
- 0.348
- 0.312
- 0.32
- 0.334
- 0.285
- 0.265
- 0.345
- 0.33
- 0.342
- 0.351
- 0.0
- 0.362
- 0.36
- 0.345
- 0.345
- 0.283
- 0.324
- 0.354
- 0.297
- 0.374
- 0.322
- 0.304
- 0.0
- 0.347
- 0.337
- 0.0
- 0.343
- 0.36
- 0.349
- 0.0
- 0.0
- 0.0
- 0.0
- 0.3
- 0.366
- 0.365
- 0.0
- 0.404
- 0.0
- 0.291
- 0.364
- 0.307
- 0.427
- 0.332
- 0.387
- 0.338
train_loss:
- 3.955
- 3.501
- 3.069
- 2.946
- 2.032
- 3.527
- 2.954
- 2.9
- 2.586
- 2.213
- 1.805
- 2.879
- 1.962
- 2.859
- 2.688
- 1.267
- 1.873
- 2.529
- 2.629
- 1.028
- 2.797
- 2.274
- 2.357
- 1.54
- 1.056
- 2.516
- 2.257
- 1.942
- 1.89
- 0.843
- 1.818
- 0.599
- 2.409
- 0.548
- 1.642
- 1.744
- 1.743
- 0.548
- 1.489
- 1.286
- 0.59
- 1.284
- 2.259
- 0.433
- 2.144
- 1.902
- 0.98
- 1.731
- 1.909
- 1.385
- 1.157
- 1.521
- 1.624
- 0.878
- 1.514
- 1.284
- 0.96
- 1.783
- 1.141
- 1.57
- 1.402
- 1.311
- 1.023
- 0.967
- 0.665
- 1.466
- 1.215
- 0.824
- 0.645
- 1.015
- 0.891
- 1.016
- 0.785
- 0.767
- 0.764
- 1.318
- 0.964
- 1.168
- 0.639
- 0.594
- 0.882
- 1.43
- 0.887
- 0.552
- 0.712
- 0.14
- 0.448
- 0.966
- 0.648
- 0.638
- 0.422
- 0.939
- 1.176
- 0.808
- 1.148
- 1.109
- 0.633
- 0.606
- 0.424
- 0.791
unequal: 0
verbose: 1
