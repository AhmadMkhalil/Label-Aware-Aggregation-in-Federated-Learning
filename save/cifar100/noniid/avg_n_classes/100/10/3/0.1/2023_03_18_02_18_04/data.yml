avg_train_accuracy: 0.338
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0472
- 0.0418
- 0.0421
- 0.0865
- 0.1059
- 0.1183
- 0.0457
- 0.0448
- 0.1235
- 0.0441
- 0.0472
- 0.1267
- 0.1381
- 0.1423
- 0.0471
- 0.1593
- 0.1634
- 0.1631
- 0.1703
- 0.0499
- 0.0514
- 0.0502
- 0.052
- 0.1725
- 0.1748
- 0.0518
- 0.1844
- 0.1862
- 0.1875
- 0.0538
- 0.0504
- 0.1883
- 0.1954
- 0.1914
- 0.1996
- 0.1984
- 0.1968
- 0.053
- 0.2049
- 0.2032
- 0.2011
- 0.2131
- 0.2088
- 0.2141
- 0.2125
- 0.0574
- 0.057
- 0.2123
- 0.209
- 0.0576
- 0.2114
- 0.0632
- 0.2136
- 0.2286
- 0.0589
- 0.2199
- 0.0659
- 0.2237
- 0.2269
- 0.0627
- 0.059
- 0.2312
- 0.0667
- 0.235
- 0.2262
- 0.0653
- 0.0632
- 0.2341
- 0.2379
- 0.2386
- 0.0687
- 0.2393
- 0.2407
- 0.2419
- 0.241
- 0.2465
- 0.2478
- 0.2447
- 0.246
- 0.2475
- 0.2458
- 0.0747
- 0.242
- 0.0759
- 0.2489
- 0.2445
- 0.2531
- 0.0794
- 0.248
- 0.256
- 0.0884
- 0.0785
- 0.2597
- 0.0783
- 0.251
- 0.2515
- 0.2485
- 0.2534
- 0.2518
- 0.2553
test_loss_list:
- 1.8814503002166747
- 3.2347540426254273
- 3.323599896430969
- 1.8319314193725587
- 1.8589145040512085
- 1.87726731300354
- 3.2083022499084475
- 3.225559034347534
- 1.781481418609619
- 3.137598261833191
- 3.372550868988037
- 1.7428316831588746
- 1.7661604166030884
- 1.8057758712768555
- 3.212846837043762
- 1.74501793384552
- 1.7752278852462768
- 1.8149584865570068
- 1.8142044305801392
- 3.140680294036865
- 3.0156629371643064
- 3.2779407024383547
- 3.465222034454346
- 1.676387119293213
- 1.7381816816329956
- 3.0518723630905153
- 1.6919260621070862
- 1.744858317375183
- 1.7738200902938843
- 3.081540288925171
- 2.982254424095154
- 1.6271838402748109
- 1.6953629088401794
- 1.7238072371482849
- 1.7243261766433715
- 1.7480965781211852
- 1.7593829226493836
- 3.0246247243881226
- 1.6860136151313783
- 1.7309389448165893
- 1.7567810654640197
- 1.7516014456748963
- 1.784075713157654
- 1.7866391849517822
- 1.8192780828475952
- 2.998657393455505
- 2.9665405416488646
- 1.6412325191497803
- 1.7152203130722046
- 2.9809136486053465
- 1.6739343690872193
- 2.927321925163269
- 1.7194841003417969
- 1.7025527930259705
- 2.987696342468262
- 1.6646228623390198
- 2.9297634029388426
- 1.6887466359138488
- 1.7042681407928466
- 2.7716657066345216
- 2.7520460891723633
- 1.505558772087097
- 2.7201013946533203
- 1.5348757410049438
- 1.6043322587013245
- 2.771046099662781
- 2.6829270458221437
- 1.5518597483634948
- 1.5691965079307557
- 1.5992907977104187
- 2.741013836860657
- 1.555179133415222
- 1.6077616143226623
- 1.6158302426338196
- 1.6496231031417847
- 1.6448175311088562
- 1.6816914081573486
- 1.6937101221084594
- 1.7123509192466735
- 1.7202210545539856
- 1.7321790957450867
- 2.804035882949829
- 1.6589204597473144
- 2.648942217826843
- 1.5734110879898071
- 1.618571972846985
- 1.6202047729492188
- 2.652736420631409
- 1.6093888640403748
- 1.6196033096313476
- 2.659333291053772
- 2.7350541162490845
- 1.5585783839225769
- 2.5966416215896606
- 1.5015897560119629
- 1.527964940071106
- 1.5728386306762696
- 1.581424217224121
- 1.6332075333595275
- 1.6482305145263672
train_accuracy:
- 0.057
- 0.0
- 0.0
- 0.105
- 0.131
- 0.178
- 0.0
- 0.0
- 0.215
- 0.0
- 0.0
- 0.223
- 0.199
- 0.177
- 0.0
- 0.24
- 0.191
- 0.191
- 0.274
- 0.0
- 0.0
- 0.0
- 0.0
- 0.27
- 0.229
- 0.0
- 0.27
- 0.239
- 0.227
- 0.0
- 0.0
- 0.245
- 0.234
- 0.3
- 0.266
- 0.283
- 0.26
- 0.0
- 0.251
- 0.237
- 0.228
- 0.309
- 0.253
- 0.297
- 0.26
- 0.0
- 0.0
- 0.322
- 0.329
- 0.0
- 0.312
- 0.0
- 0.262
- 0.281
- 0.0
- 0.327
- 0.0
- 0.259
- 0.31
- 0.0
- 0.0
- 0.326
- 0.0
- 0.299
- 0.368
- 0.0
- 0.0
- 0.318
- 0.342
- 0.318
- 0.0
- 0.344
- 0.335
- 0.384
- 0.31
- 0.311
- 0.335
- 0.347
- 0.342
- 0.323
- 0.34
- 0.0
- 0.318
- 0.0
- 0.329
- 0.363
- 0.339
- 0.0
- 0.378
- 0.326
- 0.0
- 0.0
- 0.37
- 0.0
- 0.356
- 0.351
- 0.334
- 0.346
- 0.368
- 0.338
train_loss:
- 4.052
- 1.882
- 2.068
- 3.835
- 3.218
- 3.14
- 1.576
- 1.771
- 3.38
- 1.875
- 1.0
- 3.037
- 2.734
- 2.598
- 1.442
- 3.056
- 2.679
- 2.549
- 2.381
- 1.234
- 1.567
- 0.683
- 0.56
- 2.706
- 2.347
- 1.068
- 2.543
- 1.999
- 2.181
- 0.966
- 1.619
- 2.039
- 1.847
- 2.096
- 1.965
- 2.021
- 1.572
- 1.16
- 1.886
- 1.269
- 1.033
- 1.672
- 0.969
- 1.528
- 0.869
- 1.004
- 1.182
- 2.003
- 1.32
- 0.784
- 1.264
- 0.605
- 2.281
- 0.985
- 0.831
- 1.231
- 0.563
- 0.96
- 1.676
- 1.193
- 0.857
- 1.687
- 0.498
- 0.834
- 1.756
- 0.775
- 0.655
- 1.595
- 1.243
- 0.637
- 0.693
- 1.109
- 1.322
- 1.435
- 1.202
- 0.568
- 0.848
- 1.028
- 0.7
- 0.496
- 0.547
- 0.648
- 0.603
- 0.647
- 1.02
- 1.063
- 0.459
- 0.428
- 0.849
- 0.369
- 0.347
- 0.626
- 1.106
- 0.85
- 0.783
- 0.624
- 1.418
- 0.455
- 0.944
- 0.392
unequal: 0
verbose: 1
