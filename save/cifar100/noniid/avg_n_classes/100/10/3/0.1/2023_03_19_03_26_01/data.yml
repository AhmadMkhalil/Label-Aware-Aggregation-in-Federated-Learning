avg_train_accuracy: 0.32
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0258
- 0.0477
- 0.0663
- 0.0979
- 0.1028
- 0.116
- 0.0399
- 0.0436
- 0.1327
- 0.0443
- 0.0464
- 0.0537
- 0.141
- 0.1504
- 0.154
- 0.0537
- 0.1606
- 0.1636
- 0.1819
- 0.1813
- 0.1758
- 0.1804
- 0.0522
- 0.1831
- 0.1838
- 0.1877
- 0.1958
- 0.0539
- 0.1899
- 0.0483
- 0.1956
- 0.2024
- 0.2004
- 0.0592
- 0.0525
- 0.0525
- 0.0526
- 0.1963
- 0.2114
- 0.2127
- 0.2033
- 0.0549
- 0.207
- 0.06
- 0.2114
- 0.2176
- 0.226
- 0.0649
- 0.0578
- 0.2212
- 0.2233
- 0.2225
- 0.2274
- 0.2356
- 0.2282
- 0.0603
- 0.0566
- 0.2375
- 0.2367
- 0.239
- 0.2282
- 0.0656
- 0.0647
- 0.2273
- 0.2371
- 0.2399
- 0.0704
- 0.2448
- 0.2372
- 0.2355
- 0.2312
- 0.2414
- 0.2435
- 0.2381
- 0.2449
- 0.2456
- 0.0697
- 0.2459
- 0.243
- 0.0832
- 0.2474
- 0.0656
- 0.2529
- 0.0813
- 0.2524
- 0.2433
- 0.254
- 0.0794
- 0.2482
- 0.2561
- 0.0816
- 0.2568
- 0.2489
- 0.2563
- 0.2602
- 0.2467
- 0.257
- 0.2545
- 0.2571
- 0.2576
test_loss_list:
- 2.7861995983123777
- 3.3820996379852293
- 1.8330618810653687
- 1.8616500663757325
- 1.8992594861984253
- 1.921935477256775
- 3.250773301124573
- 3.511952419281006
- 1.8430123710632325
- 3.2443789196014405
- 3.4992285346984864
- 3.195404305458069
- 1.7663140964508057
- 1.8036272096633912
- 1.8307393074035645
- 3.1949294996261597
- 1.7812585639953613
- 1.8113292741775513
- 1.8273538827896119
- 1.8486488962173462
- 1.893695697784424
- 1.8990907287597656
- 3.0850262355804445
- 1.7960764122009278
- 1.839483666419983
- 1.8430175065994263
- 1.861647472381592
- 3.095207815170288
- 1.8147781467437745
- 3.0865848875045776
- 1.6853337049484254
- 1.7154092574119568
- 1.7425220346450805
- 3.0089552545547487
- 2.9394840478897093
- 2.8928873538970947
- 3.1372822618484495
- 1.5790887761116028
- 1.6077573704719543
- 1.6536134481430054
- 1.7084026479721068
- 2.9402616834640503
- 1.6504145383834838
- 2.956276545524597
- 1.5969185757637023
- 1.641274721622467
- 1.6593831086158752
- 2.7666018867492674
- 3.032719540596008
- 1.6068592619895936
- 1.6585143780708314
- 1.6731508350372315
- 1.6921504974365233
- 1.696803138256073
- 1.7242550110816957
- 2.8911722755432128
- 3.0801563692092895
- 1.6076610898971557
- 1.643165967464447
- 1.6702294802665711
- 1.7251698231697083
- 2.851034092903137
- 2.9669391393661497
- 1.6586995935440063
- 1.6756498622894287
- 1.6843265056610108
- 2.7953436756134034
- 1.5963296031951903
- 1.6601852297782898
- 1.7096323585510254
- 1.7321343946456909
- 1.6892542386054992
- 1.7116670250892638
- 1.7711903047561646
- 1.741672785282135
- 1.7745522546768189
- 2.8658558320999146
- 1.682799928188324
- 1.710982711315155
- 2.6950684070587156
- 1.6282502603530884
- 2.8248262500762937
- 1.5407127594947816
- 2.640184164047241
- 1.539633550643921
- 1.5996769046783448
- 1.6109774017333984
- 2.65702392578125
- 1.5566197752952575
- 1.5786636877059936
- 2.6590046072006226
- 1.5674169850349426
- 1.6147554397583008
- 1.6292913818359376
- 1.6637719821929933
- 1.6879155802726746
- 1.6816827845573425
- 1.7055416750907897
- 1.7308559107780457
- 1.7404412126541138
train_accuracy:
- 0.0
- 0.0
- 0.073
- 0.157
- 0.128
- 0.146
- 0.0
- 0.0
- 0.144
- 0.0
- 0.0
- 0.0
- 0.199
- 0.182
- 0.158
- 0.0
- 0.177
- 0.165
- 0.202
- 0.257
- 0.254
- 0.238
- 0.0
- 0.23
- 0.255
- 0.212
- 0.258
- 0.0
- 0.28
- 0.0
- 0.21
- 0.257
- 0.233
- 0.0
- 0.0
- 0.0
- 0.0
- 0.223
- 0.284
- 0.285
- 0.321
- 0.0
- 0.299
- 0.0
- 0.295
- 0.259
- 0.314
- 0.0
- 0.0
- 0.302
- 0.306
- 0.326
- 0.303
- 0.244
- 0.248
- 0.0
- 0.0
- 0.291
- 0.283
- 0.316
- 0.271
- 0.0
- 0.0
- 0.279
- 0.271
- 0.339
- 0.0
- 0.305
- 0.337
- 0.331
- 0.33
- 0.334
- 0.35
- 0.338
- 0.348
- 0.299
- 0.0
- 0.355
- 0.335
- 0.0
- 0.345
- 0.0
- 0.329
- 0.0
- 0.338
- 0.363
- 0.344
- 0.0
- 0.363
- 0.343
- 0.0
- 0.346
- 0.33
- 0.323
- 0.322
- 0.368
- 0.362
- 0.348
- 0.376
- 0.32
train_loss:
- 1.957
- 1.814
- 4.289
- 3.435
- 3.042
- 2.671
- 1.819
- 1.089
- 3.353
- 1.216
- 0.764
- 1.651
- 3.289
- 2.922
- 2.766
- 1.133
- 2.762
- 2.364
- 2.438
- 2.374
- 1.937
- 2.492
- 1.279
- 2.34
- 2.068
- 2.061
- 1.801
- 1.039
- 2.022
- 1.865
- 2.139
- 1.627
- 1.465
- 1.115
- 1.063
- 1.411
- 0.642
- 1.685
- 2.314
- 1.429
- 1.645
- 0.982
- 1.48
- 0.868
- 2.32
- 1.294
- 1.246
- 0.892
- 0.375
- 1.198
- 1.701
- 1.248
- 1.897
- 1.814
- 1.26
- 1.042
- 0.396
- 1.24
- 1.114
- 0.708
- 0.814
- 0.772
- 0.254
- 1.803
- 1.332
- 1.445
- 0.763
- 0.977
- 1.091
- 0.742
- 0.572
- 1.729
- 1.149
- 0.662
- 1.217
- 0.749
- 0.713
- 0.748
- 1.017
- 0.68
- 0.88
- 0.939
- 1.589
- 0.466
- 0.989
- 0.916
- 1.014
- 0.637
- 0.85
- 0.787
- 0.459
- 0.651
- 0.359
- 0.71
- 0.382
- 0.604
- 0.439
- 0.649
- 0.358
- 0.637
unequal: 0
verbose: 1
