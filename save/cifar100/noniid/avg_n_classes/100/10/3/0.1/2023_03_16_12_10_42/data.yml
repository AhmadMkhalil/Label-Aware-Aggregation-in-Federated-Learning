avg_train_accuracy: 0.305
avg_train_loss: 0.013
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0889
- 0.1062
- 0.1166
- 0.1218
- 0.13
- 0.146
- 0.1456
- 0.1493
- 0.0356
- 0.0426
- 0.0554
- 0.1494
- 0.1547
- 0.1597
- 0.1702
- 0.1673
- 0.0444
- 0.1719
- 0.1708
- 0.0432
- 0.1719
- 0.1782
- 0.1868
- 0.0601
- 0.1861
- 0.1942
- 0.1936
- 0.197
- 0.1998
- 0.0522
- 0.2038
- 0.2049
- 0.2101
- 0.0514
- 0.2098
- 0.063
- 0.2119
- 0.2143
- 0.0586
- 0.2164
- 0.0587
- 0.0653
- 0.2147
- 0.0507
- 0.217
- 0.2182
- 0.2216
- 0.2223
- 0.2225
- 0.0695
- 0.059
- 0.2286
- 0.2236
- 0.2254
- 0.0652
- 0.2294
- 0.0732
- 0.242
- 0.2367
- 0.2302
- 0.2315
- 0.0759
- 0.241
- 0.0846
- 0.2347
- 0.2258
- 0.2417
- 0.2279
- 0.0837
- 0.2444
- 0.2427
- 0.0674
- 0.2385
- 0.0837
- 0.0786
- 0.2483
- 0.0732
- 0.2469
- 0.2449
- 0.2456
- 0.2466
- 0.2457
- 0.2413
- 0.2435
- 0.2416
- 0.0761
- 0.0673
- 0.2464
- 0.2411
- 0.2447
- 0.2435
- 0.0695
- 0.0672
- 0.2462
- 0.0894
- 0.2611
- 0.2446
- 0.2515
- 0.249
test_loss_list:
- 1.888022541999817
- 1.938443841934204
- 1.9728112840652465
- 1.959974398612976
- 1.9777869510650634
- 1.9953579521179199
- 1.9868541765213013
- 2.021961317062378
- 2.0178682804107666
- 3.2722821044921875
- 3.2243210792541506
- 3.2065337562561034
- 1.6864228010177613
- 1.763308641910553
- 1.7932156038284301
- 1.8219042921066284
- 1.8466411113739014
- 3.122021689414978
- 1.7764999341964722
- 1.8105462074279786
- 3.144725413322449
- 1.7577140498161317
- 1.7717996120452881
- 1.7941111469268798
- 3.1010758781433108
- 1.6733570432662963
- 1.7166937065124512
- 1.7513090658187866
- 1.7790332174301147
- 1.7963253927230836
- 3.0293385648727416
- 1.6938138151168822
- 1.736901125907898
- 1.7395533394813538
- 3.0568445682525636
- 1.6764878296852113
- 2.949260940551758
- 1.600225727558136
- 1.6544956278800964
- 2.8648032665252687
- 1.606753375530243
- 2.859144287109375
- 2.894652967453003
- 1.583256769180298
- 2.9143957614898683
- 1.5532705903053283
- 1.6041158747673034
- 1.6351705980300903
- 1.6747979354858398
- 1.7019677782058715
- 2.8572149896621704
- 2.828162660598755
- 1.5567439103126526
- 1.617922523021698
- 1.667094614505768
- 2.871203927993774
- 1.575616843700409
- 2.7344405269622802
- 1.5319022798538209
- 1.6082144689559936
- 1.6398963475227355
- 1.6717038130760193
- 2.778042130470276
- 1.6132263803482056
- 2.7058135318756102
- 1.6200830221176148
- 1.6838238048553467
- 1.6888179183006287
- 1.7142193818092346
- 2.6960715150833128
- 1.6512677073478699
- 1.681467089653015
- 2.835565218925476
- 1.601917474269867
- 2.6111901140213014
- 2.8265114498138426
- 1.590113172531128
- 2.7446192693710327
- 1.6089806127548218
- 1.6205656981468202
- 1.6712848615646363
- 1.6809619736671448
- 1.7100466299057007
- 1.6959519147872926
- 1.7562201476097108
- 1.7323989295959472
- 2.8431282806396485
- 3.076234049797058
- 1.659378046989441
- 1.6931291174888612
- 1.7088739156723023
- 1.7470518994331359
- 2.7758244037628175
- 2.9571642589569094
- 1.5861722946166992
- 2.5061952829360963
- 1.5138556122779847
- 1.5716688346862793
- 1.6033585453033448
- 1.6247799372673035
train_accuracy:
- 0.053
- 0.113
- 0.116
- 0.157
- 0.162
- 0.146
- 0.199
- 0.152
- 0.173
- 0.0
- 0.0
- 0.0
- 0.226
- 0.195
- 0.221
- 0.2
- 0.202
- 0.0
- 0.218
- 0.241
- 0.0
- 0.204
- 0.229
- 0.264
- 0.0
- 0.285
- 0.259
- 0.277
- 0.202
- 0.248
- 0.0
- 0.266
- 0.303
- 0.304
- 0.0
- 0.306
- 0.0
- 0.278
- 0.265
- 0.0
- 0.303
- 0.0
- 0.0
- 0.259
- 0.0
- 0.277
- 0.302
- 0.28
- 0.287
- 0.245
- 0.0
- 0.0
- 0.285
- 0.234
- 0.328
- 0.0
- 0.309
- 0.0
- 0.311
- 0.329
- 0.295
- 0.327
- 0.0
- 0.318
- 0.0
- 0.326
- 0.312
- 0.327
- 0.325
- 0.0
- 0.31
- 0.33
- 0.0
- 0.355
- 0.0
- 0.0
- 0.314
- 0.0
- 0.298
- 0.311
- 0.293
- 0.323
- 0.338
- 0.359
- 0.304
- 0.342
- 0.0
- 0.0
- 0.358
- 0.373
- 0.345
- 0.359
- 0.0
- 0.0
- 0.369
- 0.0
- 0.352
- 0.326
- 0.315
- 0.305
train_loss:
- 4.041
- 3.52
- 2.974
- 3.201
- 3.058
- 2.661
- 2.889
- 2.339
- 2.725
- 2.038
- 2.178
- 1.724
- 3.148
- 2.409
- 2.701
- 2.634
- 2.069
- 1.564
- 2.061
- 1.516
- 1.637
- 1.652
- 2.45
- 2.318
- 1.228
- 2.465
- 2.011
- 1.953
- 2.156
- 1.468
- 1.415
- 2.074
- 2.062
- 1.859
- 1.396
- 1.979
- 0.963
- 1.821
- 1.842
- 1.179
- 1.996
- 0.846
- 0.911
- 1.76
- 1.131
- 1.601
- 1.478
- 1.072
- 1.281
- 1.829
- 0.741
- 1.066
- 1.233
- 1.449
- 1.261
- 1.033
- 1.705
- 0.609
- 1.252
- 0.992
- 0.956
- 0.8
- 0.536
- 0.774
- 0.363
- 1.416
- 0.847
- 0.82
- 0.745
- 0.437
- 1.09
- 0.665
- 0.928
- 1.704
- 0.388
- 0.122
- 0.879
- 0.646
- 1.475
- 0.787
- 0.933
- 0.582
- 0.366
- 0.79
- 0.817
- 0.589
- 0.684
- 0.252
- 1.405
- 0.736
- 0.689
- 0.651
- 1.024
- 0.326
- 0.724
- 0.48
- 0.729
- 0.343
- 0.79
- 1.306
unequal: 0
verbose: 1
