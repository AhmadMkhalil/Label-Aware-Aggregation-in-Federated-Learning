avg_train_accuracy: 0.335
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.046
- 0.0446
- 0.0373
- 0.0868
- 0.1078
- 0.121
- 0.0472
- 0.1281
- 0.1342
- 0.1323
- 0.0416
- 0.1473
- 0.1566
- 0.1596
- 0.042
- 0.1679
- 0.047
- 0.0457
- 0.167
- 0.168
- 0.1706
- 0.1759
- 0.1799
- 0.0504
- 0.1868
- 0.1939
- 0.0541
- 0.1936
- 0.0527
- 0.1979
- 0.1987
- 0.2089
- 0.2027
- 0.2025
- 0.2054
- 0.0561
- 0.0549
- 0.2093
- 0.056
- 0.2076
- 0.2146
- 0.2097
- 0.2132
- 0.0578
- 0.0576
- 0.0588
- 0.0581
- 0.2152
- 0.2196
- 0.0604
- 0.2166
- 0.2268
- 0.2191
- 0.063
- 0.2065
- 0.2278
- 0.064
- 0.2302
- 0.2281
- 0.2354
- 0.2329
- 0.2352
- 0.2364
- 0.234
- 0.2346
- 0.2366
- 0.2311
- 0.2344
- 0.0698
- 0.0652
- 0.2459
- 0.2417
- 0.2423
- 0.241
- 0.2441
- 0.2447
- 0.2371
- 0.2417
- 0.2424
- 0.2418
- 0.2422
- 0.0634
- 0.2429
- 0.2442
- 0.2565
- 0.0798
- 0.2546
- 0.2492
- 0.2551
- 0.2554
- 0.2501
- 0.2501
- 0.2432
- 0.2521
- 0.0812
- 0.0706
- 0.25
- 0.2564
- 0.0747
- 0.2482
test_loss_list:
- 1.8753502416610717
- 3.228263521194458
- 3.2047486400604246
- 1.8399083232879638
- 1.8616320514678955
- 1.877692232131958
- 3.197184691429138
- 1.849507794380188
- 1.8710395288467407
- 1.8956804895401
- 3.162728385925293
- 1.8212878227233886
- 1.8353465986251831
- 1.8573605966567994
- 3.1900733613967898
- 1.8247030830383302
- 3.2043827056884764
- 3.08220862865448
- 1.6976632165908814
- 1.7455287432670594
- 1.7853839373588563
- 1.812273588180542
- 1.8310389995574952
- 3.243492965698242
- 1.744641773700714
- 1.776185393333435
- 3.137541403770447
- 1.7563661336898804
- 3.0045462465286255
- 1.6519174623489379
- 1.7008882331848145
- 1.7153276181221009
- 1.7579731512069703
- 1.7922192978858948
- 1.78501300573349
- 2.9746529626846314
- 3.2571124172210695
- 1.7141559576988221
- 2.982717742919922
- 1.7227460408210755
- 1.7505176758766174
- 1.7862501382827758
- 1.7987713718414307
- 3.0066063976287842
- 3.254410409927368
- 3.3811722087860105
- 3.5140387058258056
- 1.665442898273468
- 1.7180687594413757
- 2.8629236459732055
- 1.6672642254829406
- 1.7143798136711121
- 1.7601939845085144
- 2.8612069654464722
- 1.7382215642929078
- 1.7301288104057313
- 2.87404260635376
- 1.6604481267929077
- 1.703716788291931
- 1.72125070810318
- 1.7324462628364563
- 1.7489644980430603
- 1.782870602607727
- 1.7822413229942322
- 1.7979233407974242
- 1.821505570411682
- 1.8601992082595826
- 1.8376764035224915
- 2.8892202520370485
- 3.117108426094055
- 1.7276778268814086
- 1.74006644487381
- 1.7738607931137085
- 1.817170693874359
- 1.8099772548675537
- 1.802107412815094
- 1.8529475450515747
- 1.8445173907279968
- 1.843079707622528
- 1.861470193862915
- 1.8746097707748413
- 2.8977989292144777
- 1.6452471137046814
- 1.724446678161621
- 1.711824119091034
- 2.714546627998352
- 1.6299974179267884
- 1.6430864930152893
- 1.6865594601631164
- 1.6932240080833436
- 1.7239409875869751
- 1.7382232213020326
- 1.7433216238021851
- 1.7597619891166687
- 2.7585104370117186
- 2.8297267246246336
- 1.621090180873871
- 1.6209948945045471
- 2.7692697858810424
- 1.6244497394561768
train_accuracy:
- 0.044
- 0.0
- 0.0
- 0.112
- 0.159
- 0.183
- 0.0
- 0.136
- 0.173
- 0.198
- 0.0
- 0.173
- 0.192
- 0.185
- 0.0
- 0.21
- 0.0
- 0.0
- 0.194
- 0.199
- 0.201
- 0.276
- 0.301
- 0.0
- 0.241
- 0.26
- 0.0
- 0.221
- 0.0
- 0.255
- 0.238
- 0.274
- 0.297
- 0.292
- 0.242
- 0.0
- 0.0
- 0.283
- 0.0
- 0.293
- 0.315
- 0.307
- 0.329
- 0.0
- 0.0
- 0.0
- 0.0
- 0.272
- 0.342
- 0.0
- 0.292
- 0.353
- 0.356
- 0.0
- 0.279
- 0.317
- 0.0
- 0.302
- 0.322
- 0.326
- 0.303
- 0.305
- 0.32
- 0.287
- 0.375
- 0.371
- 0.269
- 0.331
- 0.0
- 0.0
- 0.379
- 0.32
- 0.39
- 0.356
- 0.307
- 0.294
- 0.297
- 0.309
- 0.32
- 0.297
- 0.321
- 0.0
- 0.327
- 0.35
- 0.371
- 0.0
- 0.34
- 0.304
- 0.361
- 0.361
- 0.402
- 0.368
- 0.316
- 0.418
- 0.0
- 0.0
- 0.323
- 0.326
- 0.0
- 0.335
train_loss:
- 4.055
- 1.819
- 2.183
- 3.886
- 3.331
- 2.999
- 1.523
- 3.207
- 3.027
- 2.933
- 1.75
- 2.842
- 2.681
- 2.558
- 1.412
- 2.847
- 1.882
- 1.327
- 2.527
- 2.314
- 1.864
- 2.481
- 2.025
- 1.431
- 2.526
- 2.018
- 1.067
- 2.487
- 1.435
- 2.62
- 1.977
- 2.221
- 1.739
- 1.462
- 1.838
- 1.148
- 0.536
- 2.086
- 0.743
- 1.608
- 1.477
- 1.101
- 1.835
- 1.162
- 0.459
- 0.343
- 0.279
- 1.954
- 1.508
- 0.846
- 2.142
- 1.26
- 0.936
- 0.716
- 1.758
- 1.396
- 0.733
- 1.474
- 1.079
- 1.245
- 1.336
- 1.142
- 0.948
- 1.048
- 1.032
- 0.702
- 1.716
- 1.029
- 0.694
- 0.195
- 0.926
- 1.018
- 0.562
- 0.885
- 0.792
- 0.97
- 0.594
- 0.675
- 0.529
- 1.422
- 0.893
- 1.425
- 0.798
- 0.899
- 0.79
- 0.594
- 0.679
- 0.484
- 0.429
- 0.692
- 0.665
- 0.524
- 0.473
- 0.464
- 0.486
- 1.127
- 0.931
- 0.372
- 0.645
- 0.416
unequal: 0
verbose: 1
