avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0473
- 0.0993
- 0.1087
- 0.1248
- 0.1265
- 0.1383
- 0.1426
- 0.1536
- 0.1568
- 0.162
- 0.1673
- 0.1707
- 0.173
- 0.177
- 0.1735
- 0.1749
- 0.1752
- 0.182
- 0.1864
- 0.1544
- 0.1873
- 0.1876
- 0.1921
- 0.1907
- 0.1869
- 0.1923
- 0.1956
- 0.1908
- 0.1968
- 0.1972
- 0.2006
- 0.2019
- 0.2015
- 0.2062
- 0.2075
- 0.2013
- 0.2073
- 0.2081
- 0.2085
- 0.2082
- 0.2072
- 0.2069
- 0.2071
- 0.2067
- 0.2077
- 0.2111
- 0.2116
- 0.2113
- 0.2146
- 0.2124
- 0.2159
- 0.2163
- 0.2138
- 0.2186
- 0.2239
- 0.2225
- 0.2226
- 0.2221
- 0.2196
- 0.22
- 0.222
- 0.2214
- 0.2194
- 0.2184
- 0.2143
- 0.2233
- 0.2193
- 0.2248
- 0.224
- 0.2232
- 0.2196
- 0.2302
- 0.2286
- 0.228
- 0.2258
- 0.2191
- 0.2365
- 0.2249
- 0.2277
- 0.2267
- 0.2304
- 0.2246
- 0.2277
- 0.2299
- 0.226
- 0.2301
- 0.227
- 0.2343
- 0.2324
- 0.2323
- 0.2371
- 0.232
- 0.2385
- 0.2374
- 0.2286
- 0.2335
- 0.2335
- 0.2337
- 0.2312
- 0.2368
test_loss_list:
- 1.8789605712890625
- 1.9672973775863647
- 1.9616439962387084
- 2.1097387075424194
- 2.0191717910766602
- 1.9646242427825928
- 1.9814326763153076
- 1.9954764461517334
- 1.9982902193069458
- 1.9827277565002441
- 1.9756808185577392
- 2.0934278392791748
- 2.015712022781372
- 1.9896130418777467
- 1.9675513315200805
- 1.897940821647644
- 1.868048014640808
- 1.8205233001708985
- 1.884346718788147
- 1.7166551089286803
- 1.8286831665039063
- 1.8330506229400634
- 1.896124997138977
- 1.8930811023712157
- 1.8165624523162842
- 1.7818871784210204
- 1.8319206380844115
- 1.7920808744430543
- 1.830519585609436
- 1.859619255065918
- 1.8803592395782471
- 2.004854974746704
- 1.8512728357315062
- 1.9046841859817505
- 1.9330075645446778
- 1.8336101293563842
- 1.887846632003784
- 1.8428365755081177
- 1.8749629259109497
- 1.8242827987670898
- 1.7781156826019286
- 1.7687763833999635
- 1.8255288314819336
- 1.7925030779838562
- 1.7910538244247436
- 1.8060986614227295
- 1.8290584516525268
- 1.7394119381904602
- 1.7440572524070739
- 1.7695090389251709
- 1.7191939663887024
- 1.7949702954292297
- 1.712402138710022
- 1.6243086385726928
- 1.6951272225379943
- 1.5295027017593383
- 1.5897759675979615
- 1.6983486652374267
- 1.8447405195236206
- 1.7854846572875978
- 1.8049783277511597
- 1.8090519952774047
- 1.782949240207672
- 1.7020285320281983
- 1.6617177653312682
- 1.7330934286117554
- 1.7044558310508728
- 1.739606785774231
- 1.768428783416748
- 1.797131793498993
- 1.7386546564102172
- 1.5763867616653442
- 1.6244918966293336
- 1.6988955783843993
- 1.7102535390853881
- 1.5502800345420837
- 1.546885712146759
- 1.7801640558242797
- 1.6398533749580384
- 1.6111163115501403
- 1.6760935974121094
- 1.7156613492965698
- 1.6609043097496032
- 1.6454490613937378
- 1.6441407990455628
- 1.6910559248924255
- 1.7253480958938598
- 1.6425887846946716
- 1.8103026962280273
- 1.7005148553848266
- 1.6494249749183654
- 1.7156286430358887
- 1.7355707859992981
- 1.7648730301856994
- 1.8782179212570191
- 1.8160296082496643
- 1.7782421875
- 1.7094036388397216
- 1.7244355750083924
- 1.7425531196594237
train_accuracy:
- 0.0
- 0.181
- 0.223
- 0.234
- 0.241
- 0.244
- 0.292
- 0.0
- 0.328
- 0.0
- 0.0
- 0.326
- 0.382
- 0.358
- 0.354
- 0.0
- 0.0
- 0.0
- 0.361
- 0.0
- 0.364
- 0.0
- 0.0
- 0.347
- 0.0
- 0.36
- 0.0
- 0.0
- 0.0
- 0.411
- 0.444
- 0.399
- 0.373
- 0.425
- 0.0
- 0.0
- 0.411
- 0.0
- 0.437
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.406
- 0.407
- 0.426
- 0.0
- 0.0
- 0.0
- 0.402
- 0.41
- 0.434
- 0.0
- 0.451
- 0.0
- 0.0
- 0.447
- 0.392
- 0.0
- 0.384
- 0.0
- 0.451
- 0.433
- 0.468
- 0.412
- 0.0
- 0.423
- 0.0
- 0.455
- 0.421
- 0.0
- 0.443
- 0.0
- 0.0
- 0.0
- 0.464
- 0.447
- 0.449
- 0.0
- 0.0
- 0.451
- 0.437
- 0.409
- 0.0
- 0.0
- 0.0
- 0.0
- 0.448
- 0.443
- 0.0
- 0.473
- 0.45
- 0.453
- 0.445
- 0.0
- 0.0
- 0.0
- 0.476
- 0.0
train_loss:
- 2.457
- 2.63
- 2.013
- 2.65
- 1.964
- 1.868
- 2.092
- 1.968
- 1.974
- 1.959
- 1.868
- 1.828
- 1.852
- 1.736
- 1.632
- 1.418
- 1.461
- 1.487
- 1.379
- 1.281
- 1.245
- 1.249
- 1.327
- 1.353
- 1.244
- 1.244
- 1.192
- 1.184
- 1.142
- 1.102
- 1.122
- 1.024
- 0.992
- 0.916
- 0.87
- 1.094
- 0.871
- 0.782
- 0.974
- 0.906
- 1.073
- 0.791
- 0.954
- 0.779
- 0.843
- 0.953
- 0.606
- 0.966
- 0.798
- 0.685
- 0.938
- 0.753
- 0.755
- 0.762
- 0.582
- 0.885
- 0.633
- 0.509
- 0.514
- 0.554
- 0.524
- 0.49
- 0.583
- 0.698
- 0.728
- 0.502
- 0.48
- 0.542
- 0.397
- 0.443
- 0.556
- 0.749
- 0.433
- 0.475
- 0.514
- 0.71
- 0.526
- 0.355
- 0.47
- 0.563
- 0.403
- 0.487
- 0.409
- 0.491
- 0.529
- 0.45
- 0.419
- 0.432
- 0.24
- 0.426
- 0.418
- 0.38
- 0.347
- 0.282
- 0.204
- 0.291
- 0.285
- 0.462
- 0.324
- 0.298
unequal: 0
verbose: 1
