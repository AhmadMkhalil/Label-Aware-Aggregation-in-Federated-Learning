avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0869
- 0.1018
- 0.1141
- 0.1226
- 0.1339
- 0.1386
- 0.1437
- 0.1495
- 0.1548
- 0.1592
- 0.1612
- 0.1661
- 0.1716
- 0.1728
- 0.1769
- 0.1804
- 0.1824
- 0.185
- 0.1865
- 0.1885
- 0.1953
- 0.1925
- 0.1941
- 0.1977
- 0.1998
- 0.2
- 0.2033
- 0.2032
- 0.206
- 0.2118
- 0.2109
- 0.2154
- 0.2167
- 0.2171
- 0.2211
- 0.2222
- 0.2195
- 0.2217
- 0.2241
- 0.2245
- 0.227
- 0.2283
- 0.225
- 0.235
- 0.2328
- 0.2341
- 0.2326
- 0.2313
- 0.231
- 0.2372
- 0.2317
- 0.2378
- 0.2347
- 0.2427
- 0.2415
- 0.2269
- 0.2359
- 0.2328
- 0.2424
- 0.2368
- 0.2455
- 0.2462
- 0.2508
- 0.2492
- 0.2452
- 0.2457
- 0.2486
- 0.2546
- 0.2565
- 0.2554
- 0.2524
- 0.2507
- 0.2386
- 0.2467
- 0.2467
- 0.2508
- 0.2588
- 0.2658
- 0.2454
- 0.2567
- 0.2517
- 0.2519
- 0.2642
- 0.2598
- 0.2565
- 0.2536
- 0.2484
- 0.2591
- 0.2669
- 0.2523
- 0.2634
- 0.2712
- 0.2661
- 0.2592
- 0.2681
- 0.2804
- 0.2664
- 0.2655
- 0.2646
test_loss_list:
- 1.8599391078948975
- 1.7927520370483399
- 1.773210768699646
- 1.7467936658859253
- 1.7311463260650635
- 1.7474552273750306
- 1.6769268965721131
- 1.6681007289886474
- 1.6306476259231568
- 1.6342219662666322
- 1.6742955899238587
- 1.682631778717041
- 1.6761661076545715
- 1.6643281745910645
- 1.6566457986831664
- 1.6149926352500916
- 1.5944887256622315
- 1.5880934357643128
- 1.549226200580597
- 1.5548765182495117
- 1.5252240538597106
- 1.5792705059051513
- 1.5907592701911926
- 1.5902107810974122
- 1.5870691061019897
- 1.5810228657722474
- 1.5861054158210754
- 1.5344802689552308
- 1.6330786561965942
- 1.5843037915229798
- 1.581459276676178
- 1.5307667636871338
- 1.5197079801559448
- 1.509767575263977
- 1.492811026573181
- 1.4702154803276062
- 1.4835519456863404
- 1.522830250263214
- 1.5384319257736205
- 1.472220652103424
- 1.5132010769844055
- 1.4938401746749879
- 1.4827459788322448
- 1.5081231808662414
- 1.4534310579299927
- 1.4643460869789124
- 1.4739475464820861
- 1.5121108889579773
- 1.4767547535896302
- 1.511885278224945
- 1.486309278011322
- 1.5062804985046387
- 1.4858012628555297
- 1.5146692061424256
- 1.482704656124115
- 1.4697643089294434
- 1.544337182044983
- 1.4848381876945496
- 1.5595175290107728
- 1.4857009387016296
- 1.4994717979431151
- 1.4630697536468507
- 1.458417615890503
- 1.4547508788108825
- 1.4535719537734986
- 1.474140932559967
- 1.4875773906707763
- 1.4501431703567504
- 1.4410895586013794
- 1.438416335582733
- 1.4399400925636292
- 1.4439133405685425
- 1.4748407626152038
- 1.5344802951812744
- 1.4983683609962464
- 1.4915411806106567
- 1.496390118598938
- 1.4462066173553467
- 1.4142217254638672
- 1.5147199201583863
- 1.4445184445381165
- 1.4812168431282045
- 1.4839360523223877
- 1.4348588013648986
- 1.4705897712707519
- 1.4783862805366517
- 1.4843873262405396
- 1.5213733530044555
- 1.4503374743461608
- 1.4336188864707946
- 1.5115201783180237
- 1.4539459824562073
- 1.4363471698760986
- 1.4756618523597718
- 1.4678023481369018
- 1.4347595596313476
- 1.403250150680542
- 1.4556192898750304
- 1.4668333745002746
- 1.4758855700492859
train_accuracy:
- 0.095
- 0.181
- 0.21
- 0.207
- 0.218
- 0.287
- 0.0
- 0.254
- 0.276
- 0.307
- 0.33
- 0.332
- 0.331
- 0.344
- 0.342
- 0.0
- 0.352
- 0.0
- 0.0
- 0.0
- 0.0
- 0.374
- 0.325
- 0.379
- 0.398
- 0.399
- 0.382
- 0.0
- 0.0
- 0.356
- 0.0
- 0.0
- 0.392
- 0.414
- 0.401
- 0.0
- 0.0
- 0.415
- 0.0
- 0.0
- 0.429
- 0.0
- 0.0
- 0.396
- 0.0
- 0.412
- 0.0
- 0.423
- 0.0
- 0.428
- 0.0
- 0.408
- 0.391
- 0.0
- 0.431
- 0.424
- 0.392
- 0.0
- 0.403
- 0.403
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.429
- 0.424
- 0.0
- 0.397
- 0.425
- 0.0
- 0.431
- 0.4
- 0.445
- 0.443
- 0.0
- 0.415
- 0.0
- 0.425
- 0.0
- 0.0
- 0.0
- 0.416
- 0.0
- 0.406
- 0.44
- 0.45
- 0.419
- 0.447
- 0.0
- 0.428
- 0.0
- 0.0
- 0.435
- 0.0
- 0.423
- 0.0
- 0.0
- 0.425
- 0.0
train_loss:
- 2.849
- 2.093
- 2.163
- 2.049
- 1.946
- 2.074
- 1.656
- 1.743
- 1.525
- 1.661
- 1.722
- 1.676
- 1.647
- 1.588
- 1.529
- 1.369
- 1.35
- 1.288
- 1.189
- 1.241
- 1.093
- 1.305
- 1.252
- 1.226
- 1.193
- 1.182
- 1.142
- 1.044
- 1.157
- 1.067
- 1.013
- 0.959
- 0.928
- 0.885
- 0.888
- 0.795
- 0.837
- 0.88
- 0.859
- 0.757
- 0.828
- 0.748
- 0.747
- 0.79
- 0.684
- 0.685
- 0.657
- 0.704
- 0.658
- 0.686
- 0.648
- 0.648
- 0.589
- 0.608
- 0.558
- 0.591
- 0.631
- 0.556
- 0.567
- 0.54
- 0.53
- 0.517
- 0.483
- 0.451
- 0.482
- 0.493
- 0.475
- 0.485
- 0.444
- 0.434
- 0.436
- 0.416
- 0.428
- 0.421
- 0.429
- 0.403
- 0.4
- 0.377
- 0.366
- 0.379
- 0.383
- 0.366
- 0.351
- 0.35
- 0.337
- 0.335
- 0.327
- 0.32
- 0.331
- 0.315
- 0.299
- 0.299
- 0.308
- 0.271
- 0.304
- 0.278
- 0.29
- 0.273
- 0.266
- 0.263
unequal: 0
verbose: 1
