avg_train_accuracy: 0.495
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0292
- 0.0841
- 0.0976
- 0.1148
- 0.1232
- 0.1318
- 0.1407
- 0.1448
- 0.1494
- 0.1553
- 0.1567
- 0.1609
- 0.1652
- 0.1683
- 0.1742
- 0.1753
- 0.178
- 0.1782
- 0.1823
- 0.1867
- 0.1887
- 0.1913
- 0.1923
- 0.192
- 0.1965
- 0.1962
- 0.1957
- 0.2023
- 0.2043
- 0.1971
- 0.2059
- 0.2094
- 0.2043
- 0.2109
- 0.215
- 0.2088
- 0.2124
- 0.2151
- 0.2216
- 0.2219
- 0.2221
- 0.2225
- 0.2228
- 0.2192
- 0.2258
- 0.2277
- 0.2312
- 0.2338
- 0.2308
- 0.2238
- 0.23
- 0.2319
- 0.2344
- 0.2296
- 0.2293
- 0.2358
- 0.2376
- 0.2371
- 0.237
- 0.2384
- 0.234
- 0.2402
- 0.2464
- 0.2346
- 0.2361
- 0.2404
- 0.2403
- 0.2466
- 0.2429
- 0.2452
- 0.2478
- 0.2502
- 0.2542
- 0.2473
- 0.2499
- 0.2569
- 0.2567
- 0.255
- 0.2499
- 0.2528
- 0.257
- 0.2617
- 0.2491
- 0.2502
- 0.2494
- 0.2551
- 0.2496
- 0.257
- 0.2466
- 0.2621
- 0.2572
- 0.2537
- 0.2422
- 0.2453
- 0.2564
- 0.258
- 0.2658
- 0.2506
- 0.2563
- 0.2587
test_loss_list:
- 1.8488119268417358
- 1.779825315475464
- 1.7664861822128295
- 1.784083137512207
- 1.7518924713134765
- 1.7345370721817017
- 1.760018424987793
- 1.7203166937828065
- 1.7929389762878418
- 1.713639588356018
- 1.6640718650817872
- 1.6852288413047791
- 1.7400257039070128
- 1.6625110268592835
- 1.6793511390686036
- 1.6308666205406188
- 1.7019193291664123
- 1.672638852596283
- 1.5897089314460755
- 1.5851758432388305
- 1.5775415778160096
- 1.6055199241638183
- 1.575179512500763
- 1.6621163749694825
- 1.5952490735054017
- 1.5983383393287658
- 1.6032360672950745
- 1.5651280760765076
- 1.5586021542549133
- 1.63448251247406
- 1.5341267657279969
- 1.5354811477661132
- 1.6275437808036803
- 1.5546322441101075
- 1.5061099457740783
- 1.5571412777900695
- 1.5630515313148499
- 1.5282781600952149
- 1.517171721458435
- 1.5119277620315552
- 1.5018726420402526
- 1.5106963396072388
- 1.5410556316375732
- 1.5484528350830078
- 1.5191957807540895
- 1.4983867573738099
- 1.4939239716529846
- 1.5369914078712463
- 1.5205212044715881
- 1.5887885665893555
- 1.5599994993209838
- 1.5121374106407166
- 1.4878431940078736
- 1.5246433520317078
- 1.5375363421440125
- 1.499715416431427
- 1.4925825810432434
- 1.524412236213684
- 1.5395562863349914
- 1.5007454347610474
- 1.5194683837890626
- 1.4869007277488708
- 1.4596424627304077
- 1.5592606258392334
- 1.5325396466255188
- 1.487191607952118
- 1.510850989818573
- 1.4820914697647094
- 1.507424511909485
- 1.5206738877296448
- 1.4846335387229919
- 1.4751127195358276
- 1.47120032787323
- 1.5053160524368285
- 1.474693078994751
- 1.4472464513778687
- 1.4624052834510803
- 1.4717931985855102
- 1.5115435218811035
- 1.526149709224701
- 1.4970944738388061
- 1.4583474493026733
- 1.4998144674301148
- 1.5091119170188905
- 1.5160149598121644
- 1.4882648921012878
- 1.524933614730835
- 1.4811347460746764
- 1.565750653743744
- 1.4631304192543029
- 1.5076663064956666
- 1.5158752155303956
- 1.5466051173210145
- 1.5592448282241822
- 1.4897176718711853
- 1.5027835249900818
- 1.4486543488502504
- 1.5362564826011658
- 1.508385910987854
- 1.5036593103408813
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.221
- 0.0
- 0.0
- 0.263
- 0.0
- 0.279
- 0.0
- 0.0
- 0.259
- 0.333
- 0.0
- 0.291
- 0.35
- 0.0
- 0.292
- 0.0
- 0.307
- 0.296
- 0.0
- 0.0
- 0.0
- 0.309
- 0.0
- 0.0
- 0.0
- 0.0
- 0.328
- 0.0
- 0.348
- 0.0
- 0.45
- 0.0
- 0.36
- 0.371
- 0.0
- 0.346
- 0.395
- 0.0
- 0.348
- 0.0
- 0.352
- 0.348
- 0.373
- 0.0
- 0.423
- 0.0
- 0.375
- 0.355
- 0.389
- 0.0
- 0.381
- 0.435
- 0.378
- 0.382
- 0.0
- 0.394
- 0.0
- 0.0
- 0.426
- 0.0
- 0.0
- 0.371
- 0.0
- 0.369
- 0.436
- 0.397
- 0.392
- 0.0
- 0.0
- 0.38
- 0.443
- 0.0
- 0.0
- 0.0
- 0.0
- 0.381
- 0.374
- 0.386
- 0.367
- 0.385
- 0.364
- 0.406
- 0.0
- 0.0
- 0.477
- 0.394
- 0.49
- 0.387
- 0.0
- 0.0
- 0.4
- 0.0
- 0.388
- 0.0
- 0.409
- 0.381
- 0.495
train_loss:
- 2.603
- 2.116
- 2.168
- 2.269
- 1.964
- 1.866
- 1.965
- 1.824
- 2.031
- 1.714
- 1.661
- 1.756
- 1.804
- 1.538
- 1.569
- 1.476
- 1.65
- 1.491
- 1.26
- 1.298
- 1.314
- 1.336
- 1.231
- 1.362
- 1.189
- 1.235
- 1.195
- 1.096
- 1.029
- 1.205
- 0.978
- 1.019
- 1.093
- 0.977
- 0.875
- 0.966
- 0.948
- 0.903
- 0.864
- 0.841
- 0.84
- 0.807
- 0.856
- 0.803
- 0.772
- 0.761
- 0.71
- 0.731
- 0.664
- 0.769
- 0.675
- 0.685
- 0.63
- 0.67
- 0.648
- 0.629
- 0.605
- 0.6
- 0.584
- 0.578
- 0.562
- 0.556
- 0.515
- 0.539
- 0.527
- 0.512
- 0.506
- 0.467
- 0.477
- 0.471
- 0.473
- 0.454
- 0.426
- 0.426
- 0.422
- 0.412
- 0.399
- 0.402
- 0.395
- 0.381
- 0.382
- 0.376
- 0.388
- 0.362
- 0.355
- 0.363
- 0.332
- 0.359
- 0.333
- 0.35
- 0.308
- 0.311
- 0.328
- 0.302
- 0.323
- 0.301
- 0.308
- 0.297
- 0.292
- 0.27
unequal: 0
verbose: 1
