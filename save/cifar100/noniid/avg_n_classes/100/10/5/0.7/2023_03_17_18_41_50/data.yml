avg_train_accuracy: 0.439
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0365
- 0.0918
- 0.1062
- 0.117
- 0.1265
- 0.1354
- 0.1419
- 0.1449
- 0.1517
- 0.1542
- 0.1585
- 0.1595
- 0.1608
- 0.1641
- 0.1699
- 0.1724
- 0.1751
- 0.1797
- 0.1802
- 0.1809
- 0.184
- 0.1832
- 0.1877
- 0.1867
- 0.1911
- 0.1889
- 0.194
- 0.1951
- 0.1967
- 0.2007
- 0.2019
- 0.2012
- 0.2063
- 0.2047
- 0.2062
- 0.2111
- 0.2085
- 0.2051
- 0.2099
- 0.2152
- 0.2227
- 0.2141
- 0.2187
- 0.2194
- 0.2217
- 0.2212
- 0.2266
- 0.2213
- 0.2248
- 0.2246
- 0.2259
- 0.2261
- 0.2235
- 0.2306
- 0.2308
- 0.2331
- 0.2349
- 0.2332
- 0.2312
- 0.2339
- 0.2394
- 0.2301
- 0.2354
- 0.2348
- 0.2388
- 0.2489
- 0.2483
- 0.248
- 0.2529
- 0.2511
- 0.2498
- 0.2377
- 0.2459
- 0.2511
- 0.2332
- 0.2373
- 0.2491
- 0.259
- 0.2525
- 0.2417
- 0.2479
- 0.247
- 0.2449
- 0.2493
- 0.2534
- 0.2592
- 0.2578
- 0.2637
- 0.265
- 0.261
- 0.2682
- 0.2635
- 0.2683
- 0.2655
- 0.2647
- 0.2748
- 0.2585
- 0.2606
- 0.2597
- 0.2639
test_loss_list:
- 1.8382301902770997
- 1.8211532878875731
- 1.7864019346237183
- 1.7658901453018188
- 1.7339372253417968
- 1.8011680126190186
- 1.7388637351989746
- 1.6947545576095582
- 1.6684323072433471
- 1.6492867326736451
- 1.641053431034088
- 1.6659952783584595
- 1.6656725215911865
- 1.6265389609336853
- 1.612330961227417
- 1.6969664120674133
- 1.6590510368347169
- 1.6104163503646851
- 1.5936405992507934
- 1.6161770749092101
- 1.6150146150588989
- 1.5502217626571655
- 1.5586229038238526
- 1.5916017007827759
- 1.5625775384902953
- 1.6508926939964295
- 1.6277798557281493
- 1.616597146987915
- 1.5671460676193236
- 1.5450793242454528
- 1.5742800426483154
- 1.588922791481018
- 1.5854035139083862
- 1.5442910170555115
- 1.5312545609474182
- 1.5210315895080566
- 1.5515540838241577
- 1.558061957359314
- 1.5620121932029725
- 1.5179762172698974
- 1.4855834889411925
- 1.5838432097434998
- 1.5640513253211976
- 1.560453886985779
- 1.5217017722129822
- 1.510728852748871
- 1.5049237537384033
- 1.5387578296661377
- 1.5044233226776123
- 1.4988838744163513
- 1.5247945284843445
- 1.5342535519599914
- 1.5984822177886964
- 1.4923075127601624
- 1.4852165842056275
- 1.4808568358421326
- 1.4804197072982788
- 1.5190319585800172
- 1.4909850311279298
- 1.515802299976349
- 1.4907401371002198
- 1.5067552781105042
- 1.52044287443161
- 1.523815336227417
- 1.4914901876449584
- 1.4500715398788453
- 1.4636250090599061
- 1.4654477095603944
- 1.4382557320594787
- 1.4534027433395387
- 1.4608352017402648
- 1.5402980208396913
- 1.4824422311782837
- 1.4658985114097596
- 1.5481231570243836
- 1.5715123367309571
- 1.4616950702667237
- 1.4595614099502563
- 1.4961065030097962
- 1.5649558877944947
- 1.4877619338035584
- 1.510125262737274
- 1.500675492286682
- 1.501050820350647
- 1.4705466580390931
- 1.4615881800651551
- 1.4529592132568359
- 1.4493870830535889
- 1.456371784210205
- 1.4597734689712525
- 1.4297156143188476
- 1.4493045711517334
- 1.450708532333374
- 1.4525560641288757
- 1.4476564407348633
- 1.4273312282562256
- 1.4830486702919006
- 1.4760013389587403
- 1.485776822566986
- 1.4904668283462525
train_accuracy:
- 0.0
- 0.185
- 0.218
- 0.244
- 0.214
- 0.283
- 0.245
- 0.24
- 0.0
- 0.281
- 0.337
- 0.328
- 0.0
- 0.0
- 0.0
- 0.365
- 0.372
- 0.313
- 0.0
- 0.0
- 0.31
- 0.0
- 0.317
- 0.0
- 0.0
- 0.312
- 0.41
- 0.375
- 0.368
- 0.0
- 0.344
- 0.343
- 0.367
- 0.34
- 0.0
- 0.0
- 0.343
- 0.0
- 0.398
- 0.0
- 0.0
- 0.0
- 0.437
- 0.367
- 0.0
- 0.356
- 0.45
- 0.371
- 0.0
- 0.411
- 0.353
- 0.423
- 0.434
- 0.0
- 0.0
- 0.0
- 0.0
- 0.409
- 0.0
- 0.425
- 0.366
- 0.457
- 0.0
- 0.0
- 0.433
- 0.467
- 0.0
- 0.0
- 0.471
- 0.0
- 0.0
- 0.397
- 0.47
- 0.371
- 0.453
- 0.0
- 0.379
- 0.428
- 0.0
- 0.42
- 0.0
- 0.0
- 0.433
- 0.0
- 0.423
- 0.378
- 0.0
- 0.383
- 0.439
- 0.431
- 0.0
- 0.0
- 0.435
- 0.482
- 0.0
- 0.0
- 0.45
- 0.0
- 0.406
- 0.439
train_loss:
- 2.565
- 2.502
- 2.123
- 1.983
- 1.967
- 2.159
- 1.804
- 1.789
- 1.701
- 1.639
- 1.574
- 1.702
- 1.632
- 1.447
- 1.397
- 1.617
- 1.461
- 1.326
- 1.265
- 1.383
- 1.326
- 1.082
- 1.173
- 1.22
- 1.088
- 1.233
- 1.111
- 1.137
- 1.014
- 1.001
- 1.043
- 1.013
- 1.016
- 0.971
- 0.901
- 0.895
- 0.912
- 0.927
- 0.868
- 0.832
- 0.749
- 0.869
- 0.791
- 0.769
- 0.718
- 0.711
- 0.675
- 0.718
- 0.689
- 0.64
- 0.664
- 0.651
- 0.679
- 0.594
- 0.589
- 0.599
- 0.581
- 0.573
- 0.569
- 0.548
- 0.523
- 0.539
- 0.53
- 0.531
- 0.508
- 0.47
- 0.469
- 0.448
- 0.437
- 0.447
- 0.432
- 0.444
- 0.415
- 0.406
- 0.438
- 0.423
- 0.396
- 0.389
- 0.39
- 0.38
- 0.371
- 0.38
- 0.354
- 0.363
- 0.35
- 0.326
- 0.337
- 0.322
- 0.312
- 0.319
- 0.308
- 0.312
- 0.292
- 0.297
- 0.298
- 0.284
- 0.301
- 0.29
- 0.276
- 0.267
unequal: 0
verbose: 1
