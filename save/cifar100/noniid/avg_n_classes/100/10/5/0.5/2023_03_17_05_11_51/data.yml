avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0366
- 0.0899
- 0.1079
- 0.1162
- 0.1278
- 0.1332
- 0.1401
- 0.1462
- 0.1495
- 0.155
- 0.1593
- 0.161
- 0.1639
- 0.1686
- 0.1729
- 0.1714
- 0.1745
- 0.1761
- 0.1797
- 0.1815
- 0.1825
- 0.1865
- 0.1854
- 0.1898
- 0.1875
- 0.1916
- 0.193
- 0.1942
- 0.198
- 0.1987
- 0.199
- 0.1999
- 0.2008
- 0.2046
- 0.2073
- 0.2045
- 0.2085
- 0.2064
- 0.2123
- 0.2134
- 0.213
- 0.2158
- 0.2102
- 0.2123
- 0.21
- 0.2135
- 0.2203
- 0.2196
- 0.2174
- 0.2205
- 0.2205
- 0.2212
- 0.2224
- 0.222
- 0.2241
- 0.2278
- 0.2303
- 0.2346
- 0.2282
- 0.2302
- 0.2356
- 0.2319
- 0.2317
- 0.2335
- 0.2328
- 0.2337
- 0.2334
- 0.2292
- 0.2317
- 0.2275
- 0.232
- 0.2387
- 0.2353
- 0.2427
- 0.2452
- 0.2414
- 0.2461
- 0.2461
- 0.2775
- 0.2399
- 0.2428
- 0.2433
- 0.2495
- 0.2508
- 0.249
- 0.2508
- 0.2418
- 0.2502
- 0.2521
- 0.2502
- 0.2532
- 0.2516
- 0.2508
- 0.2483
- 0.2534
- 0.2543
- 0.2585
- 0.2494
- 0.2554
- 0.2588
test_loss_list:
- 1.884983491897583
- 1.8987643718719482
- 1.8905714559555054
- 1.8141320657730102
- 1.8510410356521607
- 1.8180181550979615
- 1.8596236944198608
- 1.8332179880142212
- 1.820068793296814
- 1.76550621509552
- 1.7850519466400145
- 1.7965027570724488
- 1.743919746875763
- 1.7135539698600768
- 1.7582708430290221
- 1.6976536703109741
- 1.6829608106613159
- 1.729957206249237
- 1.6962846088409425
- 1.7358931112289429
- 1.648916573524475
- 1.7779174113273621
- 1.6498334074020387
- 1.6382240653038025
- 1.6289914917945862
- 1.6790198493003845
- 1.6997303175926208
- 1.6453721046447753
- 1.6988519883155824
- 1.6326592183113098
- 1.6706604743003846
- 1.7627416276931762
- 1.6173897290229797
- 1.6677467560768127
- 1.6274393939971923
- 1.6510126996040344
- 1.610598692893982
- 1.656307988166809
- 1.6006169986724854
- 1.6452597856521607
- 1.6139299035072328
- 1.5881909656524658
- 1.7185407853126526
- 1.7525932431221007
- 1.5857900810241699
- 1.544489448070526
- 1.5261255073547364
- 1.606431119441986
- 1.6316479563713073
- 1.6275209045410157
- 1.641309380531311
- 1.7291502833366394
- 1.6780469632148742
- 1.6075278949737548
- 1.6267507338523866
- 1.5665746307373047
- 1.6200408482551574
- 1.5836703038215638
- 1.6234755468368531
- 1.5900943779945373
- 1.5703117060661316
- 1.5681734347343446
- 1.5426587629318238
- 1.5333453869819642
- 1.574383292198181
- 1.6080531430244447
- 1.6107382798194885
- 1.601515188217163
- 1.5376060104370117
- 1.662480366230011
- 1.554980628490448
- 1.5341767406463622
- 1.5909063935279846
- 1.5336124539375304
- 1.4908199048042297
- 1.5646836423873902
- 1.5299891638755798
- 1.524584732055664
- 1.4187843489646912
- 1.5760577154159545
- 1.5660153555870056
- 1.574533121585846
- 1.5286221170425416
- 1.5281011748313904
- 1.5273618412017822
- 1.5111328864097595
- 1.553316867351532
- 1.5058161878585816
- 1.5111712884902955
- 1.5449145317077637
- 1.5071480011940002
- 1.5555379152297975
- 1.5673100805282594
- 1.5709086561203003
- 1.5175043392181395
- 1.5053127384185792
- 1.5057523798942567
- 1.543023979663849
- 1.5060150456428527
- 1.4932387089729309
train_accuracy:
- 0.0
- 0.0
- 0.267
- 0.0
- 0.0
- 0.331
- 0.254
- 0.247
- 0.297
- 0.356
- 0.263
- 0.0
- 0.382
- 0.291
- 0.301
- 0.303
- 0.0
- 0.0
- 0.34
- 0.345
- 0.0
- 0.0
- 0.0
- 0.338
- 0.0
- 0.327
- 0.384
- 0.0
- 0.0
- 0.0
- 0.378
- 0.0
- 0.0
- 0.35
- 0.0
- 0.0
- 0.0
- 0.0
- 0.423
- 0.0
- 0.0
- 0.429
- 0.435
- 0.0
- 0.419
- 0.353
- 0.412
- 0.0
- 0.436
- 0.406
- 0.0
- 0.407
- 0.405
- 0.0
- 0.391
- 0.374
- 0.407
- 0.427
- 0.439
- 0.0
- 0.396
- 0.0
- 0.438
- 0.453
- 0.469
- 0.0
- 0.0
- 0.0
- 0.0
- 0.411
- 0.374
- 0.0
- 0.388
- 0.0
- 0.399
- 0.0
- 0.0
- 0.446
- 0.0
- 0.443
- 0.435
- 0.0
- 0.0
- 0.0
- 0.443
- 0.0
- 0.439
- 0.0
- 0.408
- 0.445
- 0.0
- 0.443
- 0.0
- 0.428
- 0.399
- 0.0
- 0.0
- 0.445
- 0.0
- 0.0
train_loss:
- 2.89
- 2.567
- 2.411
- 1.834
- 2.121
- 1.867
- 1.986
- 1.987
- 1.86
- 1.603
- 1.837
- 1.606
- 1.565
- 1.532
- 1.535
- 1.549
- 1.388
- 1.506
- 1.33
- 1.356
- 1.179
- 1.427
- 1.175
- 1.272
- 1.162
- 1.227
- 1.169
- 1.128
- 1.118
- 1.044
- 1.125
- 1.114
- 0.957
- 1.047
- 0.945
- 0.979
- 0.94
- 0.865
- 0.88
- 0.856
- 0.855
- 0.824
- 0.859
- 0.818
- 0.814
- 0.761
- 0.712
- 0.793
- 0.701
- 0.749
- 0.686
- 0.634
- 0.627
- 0.697
- 0.621
- 0.655
- 0.564
- 0.57
- 0.599
- 0.521
- 0.591
- 0.522
- 0.604
- 0.512
- 0.534
- 0.496
- 0.532
- 0.496
- 0.523
- 0.446
- 0.469
- 0.515
- 0.459
- 0.44
- 0.507
- 0.42
- 0.434
- 0.413
- 0.473
- 0.385
- 0.368
- 0.378
- 0.385
- 0.4
- 0.347
- 0.367
- 0.386
- 0.343
- 0.368
- 0.329
- 0.356
- 0.31
- 0.297
- 0.301
- 0.373
- 0.328
- 0.299
- 0.319
- 0.333
- 0.286
unequal: 0
verbose: 1
