avg_train_accuracy: 0.439
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0394
- 0.0992
- 0.119
- 0.1246
- 0.1419
- 0.1516
- 0.1632
- 0.1687
- 0.1813
- 0.1776
- 0.1878
- 0.1915
- 0.2047
- 0.2063
- 0.2118
- 0.2092
- 0.2216
- 0.2207
- 0.228
- 0.2339
- 0.2378
- 0.2409
- 0.2407
- 0.2464
- 0.2401
- 0.2481
- 0.2544
- 0.253
- 0.2624
- 0.2605
- 0.262
- 0.2652
- 0.2708
- 0.2693
- 0.2722
- 0.2759
- 0.2732
- 0.2728
- 0.2742
- 0.2818
- 0.2729
- 0.2774
- 0.2767
- 0.2886
- 0.285
- 0.2769
- 0.2876
- 0.2884
- 0.2884
- 0.2864
- 0.2875
- 0.2967
- 0.294
- 0.2918
- 0.293
- 0.2978
- 0.2958
- 0.2983
- 0.2967
- 0.2934
- 0.3004
- 0.3007
- 0.3057
- 0.2989
- 0.2998
- 0.3043
- 0.3011
- 0.2995
- 0.302
- 0.2991
- 0.308
- 0.3072
- 0.3054
- 0.3105
- 0.31
- 0.3051
- 0.3046
- 0.3056
- 0.3116
- 0.3132
- 0.3096
- 0.3077
- 0.3158
- 0.3113
- 0.3113
- 0.3058
- 0.304
- 0.315
- 0.3186
- 0.3127
- 0.3084
- 0.3122
- 0.3157
- 0.3111
- 0.3174
- 0.3118
- 0.3125
- 0.3196
- 0.3202
- 0.3181
test_loss_list:
- 1.794081721305847
- 1.6976561546325684
- 1.6597149825096131
- 1.6198373699188233
- 1.5973708510398865
- 1.5572951173782348
- 1.520799653530121
- 1.5014505648612977
- 1.4994691658020018
- 1.4724418783187867
- 1.4747848176956178
- 1.4509511804580688
- 1.4497414135932922
- 1.4572687101364137
- 1.4521093153953553
- 1.436015465259552
- 1.4258468127250672
- 1.4330614066123963
- 1.432935779094696
- 1.4309636497497558
- 1.4327535676956176
- 1.4240740966796874
- 1.4265549993515014
- 1.418521327972412
- 1.3916516542434691
- 1.3932804226875306
- 1.388170566558838
- 1.3912179827690125
- 1.3835830664634705
- 1.392708978652954
- 1.3923534393310546
- 1.3929325890541078
- 1.3873563265800477
- 1.3896887159347535
- 1.3973930048942567
- 1.3900385618209838
- 1.3915809345245362
- 1.3552897262573242
- 1.3616429090499877
- 1.3575566053390502
- 1.3250003361701965
- 1.309409854412079
- 1.3195337653160095
- 1.3183063650131226
- 1.324635672569275
- 1.3021304535865783
- 1.3145703315734862
- 1.318275043964386
- 1.3280765652656554
- 1.3282850694656372
- 1.329768543243408
- 1.3306336998939514
- 1.3389021968841552
- 1.3422158193588256
- 1.3488616847991943
- 1.338086528778076
- 1.3014928674697877
- 1.3109677243232727
- 1.3200124526023864
- 1.2904949045181275
- 1.293863160610199
- 1.3142212438583374
- 1.3023142576217652
- 1.3170684003829956
- 1.3152141022682189
- 1.319799404144287
- 1.321682984828949
- 1.2840152263641358
- 1.2995389771461487
- 1.3157520174980164
- 1.3125301504135132
- 1.3122302103042602
- 1.2765913367271424
- 1.2893334197998048
- 1.3010860085487366
- 1.2574259376525878
- 1.2515597224235535
- 1.2727636122703552
- 1.281011974811554
- 1.278668930530548
- 1.2888656091690063
- 1.2987969875335694
- 1.2916826963424684
- 1.3059931468963624
- 1.3063335847854614
- 1.2790923714637756
- 1.2627777552604675
- 1.264869086742401
- 1.2750756788253783
- 1.2868357682228089
- 1.2594728183746338
- 1.2700874376296998
- 1.27462655544281
- 1.2506789827346803
- 1.230926103591919
- 1.228739664554596
- 1.249408051967621
- 1.2639346075057984
- 1.2657099771499634
- 1.2850881052017211
train_accuracy:
- 0.0
- 0.078
- 0.145
- 0.17
- 0.186
- 0.0
- 0.139
- 0.0
- 0.235
- 0.0
- 0.17
- 0.176
- 0.253
- 0.255
- 0.258
- 0.0
- 0.178
- 0.235
- 0.252
- 0.229
- 0.269
- 0.231
- 0.264
- 0.261
- 0.32
- 0.246
- 0.263
- 0.231
- 0.228
- 0.354
- 0.255
- 0.26
- 0.262
- 0.239
- 0.265
- 0.343
- 0.243
- 0.27
- 0.339
- 0.311
- 0.293
- 0.0
- 0.226
- 0.309
- 0.374
- 0.0
- 0.256
- 0.281
- 0.326
- 0.254
- 0.281
- 0.391
- 0.342
- 0.34
- 0.341
- 0.326
- 0.279
- 0.309
- 0.353
- 0.0
- 0.414
- 0.349
- 0.304
- 0.322
- 0.281
- 0.354
- 0.295
- 0.304
- 0.323
- 0.284
- 0.327
- 0.344
- 0.407
- 0.401
- 0.311
- 0.289
- 0.279
- 0.314
- 0.388
- 0.36
- 0.314
- 0.304
- 0.368
- 0.323
- 0.326
- 0.296
- 0.0
- 0.405
- 0.376
- 0.376
- 0.347
- 0.362
- 0.313
- 0.0
- 0.0
- 0.407
- 0.332
- 0.334
- 0.325
- 0.439
train_loss:
- 3.449
- 3.808
- 3.539
- 2.764
- 3.206
- 2.609
- 2.642
- 2.487
- 2.823
- 2.303
- 2.864
- 2.289
- 2.777
- 2.423
- 2.519
- 2.027
- 2.355
- 2.321
- 2.206
- 2.169
- 1.963
- 2.26
- 1.956
- 2.076
- 1.644
- 1.825
- 2.123
- 1.915
- 1.905
- 1.68
- 1.801
- 1.676
- 1.813
- 1.464
- 1.587
- 1.587
- 1.594
- 1.368
- 1.34
- 1.471
- 1.462
- 1.16
- 1.3
- 1.467
- 1.164
- 1.054
- 1.316
- 1.307
- 1.14
- 1.108
- 1.037
- 1.072
- 1.055
- 0.886
- 0.972
- 1.099
- 1.088
- 0.979
- 0.741
- 0.945
- 0.944
- 0.765
- 0.849
- 0.909
- 0.865
- 0.823
- 0.9
- 0.942
- 0.784
- 0.619
- 0.762
- 0.707
- 0.739
- 0.685
- 0.626
- 0.8
- 0.701
- 0.59
- 0.578
- 0.71
- 0.519
- 0.511
- 0.644
- 0.573
- 0.498
- 0.615
- 0.591
- 0.59
- 0.59
- 0.468
- 0.621
- 0.442
- 0.516
- 0.558
- 0.594
- 0.504
- 0.447
- 0.461
- 0.39
- 0.332
unequal: 0
verbose: 1
