avg_train_accuracy: 0.37
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0414
- 0.1071
- 0.1232
- 0.1375
- 0.1503
- 0.1587
- 0.1667
- 0.1747
- 0.1868
- 0.1834
- 0.1918
- 0.1994
- 0.2015
- 0.2094
- 0.2185
- 0.2215
- 0.2262
- 0.2286
- 0.2293
- 0.234
- 0.2335
- 0.2375
- 0.2411
- 0.2426
- 0.2521
- 0.2479
- 0.2442
- 0.256
- 0.256
- 0.258
- 0.2654
- 0.262
- 0.2696
- 0.2647
- 0.2702
- 0.267
- 0.2756
- 0.2719
- 0.2768
- 0.2799
- 0.2754
- 0.2788
- 0.2781
- 0.2776
- 0.287
- 0.2916
- 0.2886
- 0.2867
- 0.2874
- 0.293
- 0.2954
- 0.2896
- 0.2932
- 0.2934
- 0.2988
- 0.2929
- 0.2954
- 0.2958
- 0.294
- 0.2984
- 0.2952
- 0.3019
- 0.2984
- 0.3036
- 0.3027
- 0.3064
- 0.2999
- 0.3046
- 0.3024
- 0.3082
- 0.3019
- 0.3047
- 0.3029
- 0.3018
- 0.3108
- 0.3078
- 0.3054
- 0.3116
- 0.2959
- 0.3111
- 0.3135
- 0.3126
- 0.313
- 0.3129
- 0.3111
- 0.3105
- 0.3144
- 0.3153
- 0.3177
- 0.3148
- 0.3145
- 0.3155
- 0.3133
- 0.3161
- 0.3174
- 0.3157
- 0.3182
- 0.3211
- 0.3177
- 0.3182
test_loss_list:
- 1.79475887298584
- 1.6979096364974975
- 1.6493052291870116
- 1.6306063270568847
- 1.6170997548103332
- 1.5731388974189757
- 1.5579558682441712
- 1.5452709937095641
- 1.541390872001648
- 1.5112820744514466
- 1.5072187972068787
- 1.5067358541488647
- 1.4991642880439757
- 1.495541911125183
- 1.4850937747955322
- 1.480643734931946
- 1.4758872342109681
- 1.4755884909629822
- 1.4729456973075867
- 1.4763201189041137
- 1.4388725972175598
- 1.4299037122726441
- 1.3953109979629517
- 1.4040969920158386
- 1.4019583559036255
- 1.4174071598052977
- 1.3829023599624635
- 1.3814626145362854
- 1.357951304912567
- 1.3624229216575623
- 1.371894314289093
- 1.3479426074028016
- 1.3407743644714356
- 1.3225889158248902
- 1.3006719255447388
- 1.3226936912536622
- 1.328545832633972
- 1.2956465268135071
- 1.3133350777626038
- 1.3160797595977782
- 1.3293000912666322
- 1.2921138501167297
- 1.3125550389289855
- 1.281470239162445
- 1.294142608642578
- 1.2625697946548462
- 1.2587558269500732
- 1.2456310319900512
- 1.2403082728385926
- 1.2705922746658325
- 1.2426421451568603
- 1.2420929384231567
- 1.2581272292137147
- 1.2830024027824403
- 1.2833185815811157
- 1.2882805418968202
- 1.2573818635940552
- 1.2736794447898865
- 1.2501962351799012
- 1.2317577362060548
- 1.2677077794075011
- 1.2680577278137206
- 1.245142674446106
- 1.2622994184494019
- 1.2761530256271363
- 1.2800296187400817
- 1.2488388013839722
- 1.2322334456443786
- 1.2661397671699524
- 1.2699162793159484
- 1.2437180638313294
- 1.2629281949996949
- 1.2371783089637756
- 1.2740480017662048
- 1.2679800033569335
- 1.2748846983909607
- 1.2446593260765075
- 1.2588300585746766
- 1.2592150497436523
- 1.2628313136100768
- 1.2372670888900756
- 1.219113142490387
- 1.245740656852722
- 1.2322933292388916
- 1.2635485124588013
- 1.2616458058357238
- 1.2676637625694276
- 1.2793533945083617
- 1.2842400598526
- 1.2939668369293214
- 1.2585841393470765
- 1.2753764963150025
- 1.2838972449302672
- 1.2394924569129944
- 1.2637831139564515
- 1.2718643712997437
- 1.2755256175994873
- 1.2843432855606078
- 1.2955402374267577
- 1.2990363812446595
train_accuracy:
- 0.051
- 0.078
- 0.154
- 0.191
- 0.181
- 0.208
- 0.214
- 0.189
- 0.204
- 0.173
- 0.195
- 0.237
- 0.229
- 0.193
- 0.235
- 0.231
- 0.243
- 0.225
- 0.232
- 0.237
- 0.273
- 0.248
- 0.0
- 0.293
- 0.27
- 0.223
- 0.0
- 0.317
- 0.319
- 0.281
- 0.252
- 0.247
- 0.303
- 0.316
- 0.322
- 0.251
- 0.277
- 0.0
- 0.299
- 0.348
- 0.286
- 0.277
- 0.312
- 0.307
- 0.29
- 0.0
- 0.296
- 0.317
- 0.316
- 0.325
- 0.0
- 0.287
- 0.36
- 0.304
- 0.331
- 0.345
- 0.0
- 0.342
- 0.334
- 0.359
- 0.353
- 0.344
- 0.339
- 0.376
- 0.373
- 0.304
- 0.37
- 0.0
- 0.273
- 0.308
- 0.0
- 0.389
- 0.331
- 0.291
- 0.281
- 0.339
- 0.393
- 0.357
- 0.332
- 0.296
- 0.326
- 0.331
- 0.38
- 0.0
- 0.334
- 0.309
- 0.334
- 0.402
- 0.344
- 0.32
- 0.298
- 0.395
- 0.378
- 0.387
- 0.317
- 0.322
- 0.373
- 0.322
- 0.349
- 0.37
train_loss:
- 4.285
- 3.723
- 3.564
- 3.37
- 3.223
- 2.727
- 3.114
- 2.948
- 2.893
- 2.39
- 2.683
- 2.541
- 2.66
- 2.51
- 2.522
- 2.35
- 2.372
- 2.265
- 2.122
- 2.135
- 1.937
- 2.153
- 1.739
- 2.026
- 2.001
- 1.677
- 1.674
- 1.793
- 1.503
- 1.831
- 1.441
- 1.566
- 1.682
- 1.598
- 1.338
- 1.495
- 1.655
- 1.37
- 1.329
- 1.496
- 1.374
- 1.337
- 1.406
- 1.34
- 1.268
- 1.194
- 1.118
- 1.102
- 1.024
- 1.211
- 1.002
- 0.929
- 1.28
- 0.975
- 0.966
- 1.055
- 1.001
- 0.955
- 0.892
- 0.882
- 0.875
- 0.767
- 0.759
- 0.871
- 0.849
- 0.841
- 0.829
- 0.784
- 0.671
- 0.814
- 0.726
- 0.632
- 0.717
- 0.719
- 0.662
- 0.566
- 0.691
- 0.562
- 0.594
- 0.76
- 0.629
- 0.578
- 0.545
- 0.631
- 0.554
- 0.522
- 0.502
- 0.484
- 0.505
- 0.454
- 0.545
- 0.389
- 0.44
- 0.498
- 0.436
- 0.43
- 0.455
- 0.359
- 0.395
- 0.389
unequal: 0
verbose: 1
