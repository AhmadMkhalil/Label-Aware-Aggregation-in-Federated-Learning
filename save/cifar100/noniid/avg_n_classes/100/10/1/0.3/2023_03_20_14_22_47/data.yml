avg_train_accuracy: 0.314
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0494
- 0.0907
- 0.1147
- 0.1308
- 0.1429
- 0.1547
- 0.1598
- 0.1776
- 0.1728
- 0.1781
- 0.1866
- 0.1988
- 0.2014
- 0.2076
- 0.2097
- 0.2139
- 0.2253
- 0.2246
- 0.2217
- 0.2286
- 0.2311
- 0.233
- 0.2373
- 0.2429
- 0.2378
- 0.2493
- 0.2493
- 0.2546
- 0.2551
- 0.2591
- 0.2588
- 0.255
- 0.2534
- 0.267
- 0.2659
- 0.267
- 0.267
- 0.2702
- 0.2719
- 0.2742
- 0.2778
- 0.2724
- 0.2748
- 0.2719
- 0.2807
- 0.2859
- 0.2793
- 0.2838
- 0.2877
- 0.2885
- 0.2904
- 0.2859
- 0.288
- 0.2882
- 0.2922
- 0.2901
- 0.2917
- 0.2977
- 0.294
- 0.2992
- 0.2984
- 0.2967
- 0.2989
- 0.3005
- 0.2989
- 0.3011
- 0.3047
- 0.3045
- 0.305
- 0.3081
- 0.3042
- 0.304
- 0.3003
- 0.3051
- 0.3049
- 0.3087
- 0.3138
- 0.3089
- 0.3043
- 0.3088
- 0.3066
- 0.3124
- 0.3128
- 0.3087
- 0.3164
- 0.3089
- 0.3174
- 0.3181
- 0.3146
- 0.3136
- 0.315
- 0.3175
- 0.3205
- 0.3168
- 0.3117
- 0.3214
- 0.3186
- 0.3153
- 0.3177
- 0.3166
test_loss_list:
- 1.7874660682678223
- 1.689001305103302
- 1.6562770318984985
- 1.605522038936615
- 1.5919263100624084
- 1.5763264894485474
- 1.5386384701728821
- 1.5258101892471314
- 1.5334923648834229
- 1.5234809851646423
- 1.5267709469795228
- 1.5154871821403504
- 1.505208101272583
- 1.4990711045265197
- 1.4602973699569701
- 1.4253127574920654
- 1.4268036651611329
- 1.4310022354125977
- 1.4445337343215943
- 1.4430090284347534
- 1.4359896564483643
- 1.4009312629699706
- 1.4081760954856872
- 1.4104604506492615
- 1.3762673783302306
- 1.3771217942237854
- 1.387261974811554
- 1.3892687225341798
- 1.3572245812416077
- 1.3550267004966736
- 1.3650515842437745
- 1.3441144609451294
- 1.315158598423004
- 1.3343138027191161
- 1.3410397386550903
- 1.3455712294578552
- 1.312794497013092
- 1.2989645147323607
- 1.3273756051063537
- 1.3216494941711425
- 1.3335733962059022
- 1.2975473856925965
- 1.2901144695281983
- 1.3157706618309022
- 1.312707929611206
- 1.3144308471679687
- 1.296036455631256
- 1.2997893357276917
- 1.3081395745277404
- 1.3143600463867187
- 1.313556864261627
- 1.2947619795799254
- 1.3120708990097045
- 1.3156381678581237
- 1.3195053672790527
- 1.3246335625648498
- 1.3275146293640137
- 1.3281826424598693
- 1.333058249950409
- 1.3354566645622254
- 1.3381419134140016
- 1.3422979402542115
- 1.3464663791656495
- 1.3440795302391053
- 1.355499095916748
- 1.3458850240707398
- 1.3495426774024963
- 1.349091830253601
- 1.3511595988273621
- 1.3530185675621034
- 1.355299606323242
- 1.3559935069084168
- 1.317384159564972
- 1.2837297701835633
- 1.2616902780532837
- 1.2900719547271728
- 1.293710572719574
- 1.3085084915161134
- 1.2735671210289001
- 1.29558274269104
- 1.261922426223755
- 1.2755010437965393
- 1.2838219547271728
- 1.2623409819602966
- 1.268205201625824
- 1.2894100213050843
- 1.2843542504310608
- 1.2990498089790343
- 1.3080723357200623
- 1.3053810238838195
- 1.3134605312347412
- 1.3143354535102845
- 1.3178812527656556
- 1.3291813850402832
- 1.3275748991966247
- 1.3285503673553467
- 1.3368017435073853
- 1.3429258108139037
- 1.3377508544921874
- 1.2987457752227782
train_accuracy:
- 0.038
- 0.08
- 0.124
- 0.0
- 0.147
- 0.173
- 0.156
- 0.193
- 0.146
- 0.174
- 0.171
- 0.224
- 0.168
- 0.176
- 0.236
- 0.243
- 0.201
- 0.185
- 0.219
- 0.225
- 0.254
- 0.228
- 0.255
- 0.276
- 0.0
- 0.288
- 0.3
- 0.26
- 0.265
- 0.239
- 0.285
- 0.268
- 0.237
- 0.318
- 0.257
- 0.283
- 0.0
- 0.3
- 0.295
- 0.309
- 0.291
- 0.271
- 0.0
- 0.287
- 0.257
- 0.288
- 0.281
- 0.286
- 0.263
- 0.32
- 0.289
- 0.299
- 0.346
- 0.339
- 0.303
- 0.304
- 0.285
- 0.279
- 0.29
- 0.335
- 0.299
- 0.303
- 0.301
- 0.355
- 0.311
- 0.287
- 0.306
- 0.308
- 0.313
- 0.355
- 0.289
- 0.318
- 0.292
- 0.0
- 0.305
- 0.305
- 0.33
- 0.309
- 0.0
- 0.332
- 0.334
- 0.3
- 0.296
- 0.0
- 0.315
- 0.304
- 0.334
- 0.322
- 0.356
- 0.308
- 0.344
- 0.327
- 0.326
- 0.304
- 0.357
- 0.317
- 0.311
- 0.351
- 0.315
- 0.314
train_loss:
- 3.442
- 3.822
- 3.526
- 2.862
- 3.191
- 3.131
- 2.592
- 3.057
- 2.922
- 2.77
- 2.598
- 2.662
- 2.601
- 2.538
- 2.163
- 2.196
- 2.415
- 2.286
- 2.118
- 2.121
- 2.261
- 1.834
- 2.077
- 2.043
- 1.783
- 2.079
- 1.817
- 1.865
- 1.585
- 1.84
- 1.711
- 1.411
- 1.454
- 1.675
- 1.767
- 1.483
- 1.394
- 1.275
- 1.324
- 1.472
- 1.351
- 1.42
- 1.141
- 1.349
- 1.318
- 1.251
- 1.118
- 1.294
- 1.064
- 1.109
- 1.112
- 0.958
- 1.172
- 1.076
- 0.896
- 0.981
- 1.042
- 0.929
- 0.821
- 0.884
- 0.959
- 0.945
- 0.765
- 0.818
- 0.768
- 0.877
- 0.762
- 0.748
- 0.651
- 0.692
- 0.757
- 0.71
- 0.861
- 0.803
- 0.738
- 0.502
- 0.629
- 0.517
- 0.755
- 0.5
- 0.613
- 0.578
- 0.531
- 0.652
- 0.507
- 0.531
- 0.408
- 0.466
- 0.447
- 0.482
- 0.421
- 0.349
- 0.507
- 0.416
- 0.471
- 0.388
- 0.421
- 0.352
- 0.328
- 0.571
unequal: 0
verbose: 1
