avg_train_accuracy: 0.335
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0422
- 0.0929
- 0.1247
- 0.1351
- 0.1513
- 0.164
- 0.1653
- 0.1726
- 0.176
- 0.1906
- 0.2009
- 0.2023
- 0.2176
- 0.2169
- 0.2174
- 0.2178
- 0.2248
- 0.2265
- 0.2335
- 0.239
- 0.2432
- 0.2491
- 0.2491
- 0.2551
- 0.2481
- 0.2559
- 0.2568
- 0.2636
- 0.2588
- 0.2594
- 0.2622
- 0.2671
- 0.2704
- 0.2642
- 0.2704
- 0.2711
- 0.2711
- 0.2762
- 0.278
- 0.2816
- 0.2782
- 0.2808
- 0.2859
- 0.2827
- 0.2876
- 0.2874
- 0.2793
- 0.2949
- 0.2925
- 0.2889
- 0.295
- 0.2975
- 0.299
- 0.2971
- 0.2959
- 0.3018
- 0.2944
- 0.2959
- 0.2945
- 0.295
- 0.2983
- 0.2972
- 0.3057
- 0.2995
- 0.3025
- 0.3038
- 0.3058
- 0.305
- 0.305
- 0.312
- 0.3076
- 0.3131
- 0.309
- 0.3101
- 0.3069
- 0.3104
- 0.3111
- 0.3155
- 0.3156
- 0.3155
- 0.3126
- 0.3135
- 0.3169
- 0.3144
- 0.3177
- 0.3169
- 0.3164
- 0.3199
- 0.312
- 0.3144
- 0.3193
- 0.3183
- 0.3177
- 0.3178
- 0.3165
- 0.3164
- 0.3188
- 0.323
- 0.3241
- 0.3215
test_loss_list:
- 1.7978241491317748
- 1.6935510587692262
- 1.6486501955986024
- 1.6247550392150878
- 1.5990691471099854
- 1.585836546421051
- 1.5742748403549194
- 1.5377618789672851
- 1.4968323850631713
- 1.4867151284217834
- 1.4535799312591553
- 1.433840823173523
- 1.4326885914802552
- 1.4384923934936524
- 1.4063850450515747
- 1.3949549460411073
- 1.4063328337669372
- 1.4063379240036011
- 1.4014205813407898
- 1.4031828713417054
- 1.406294083595276
- 1.4045751619338989
- 1.4023740601539612
- 1.404540159702301
- 1.3707063102722168
- 1.3732252144813537
- 1.373242597579956
- 1.3722850847244263
- 1.3494077277183534
- 1.3163033056259155
- 1.3352177238464356
- 1.3390755033493043
- 1.3457506752014161
- 1.3236956930160522
- 1.324060893058777
- 1.3386299729347229
- 1.3450343251228332
- 1.3412855887413024
- 1.3510650825500488
- 1.3462859511375427
- 1.3120960688591004
- 1.320733416080475
- 1.3306137752532958
- 1.289955539703369
- 1.3035252571105957
- 1.3189480686187744
- 1.2876714587211608
- 1.2988627743721008
- 1.3008717131614684
- 1.2803650283813477
- 1.2911773443222045
- 1.290842649936676
- 1.3017128086090088
- 1.310397322177887
- 1.3179280257225037
- 1.310402798652649
- 1.280735354423523
- 1.294440472126007
- 1.2714315700531005
- 1.2413349223136902
- 1.2692226433753968
- 1.2424726033210753
- 1.220743191242218
- 1.232540376186371
- 1.2464603066444397
- 1.227845060825348
- 1.250412449836731
- 1.2549707102775574
- 1.272974259853363
- 1.269901740550995
- 1.2864164566993714
- 1.2737301111221313
- 1.2971676588058472
- 1.2995356369018554
- 1.3037210512161255
- 1.2722903203964233
- 1.2777416372299195
- 1.2761119842529296
- 1.2869935417175293
- 1.2893835592269898
- 1.3067867755889893
- 1.2644164657592774
- 1.264881362915039
- 1.2499740314483643
- 1.257309010028839
- 1.2696526002883912
- 1.2404550123214722
- 1.2542935299873352
- 1.2454455757141114
- 1.2244752740859985
- 1.2398581624031066
- 1.2561732745170593
- 1.2634214901924132
- 1.2646831250190735
- 1.2789255261421204
- 1.2352761435508728
- 1.2566133522987366
- 1.2641656661033631
- 1.2642286252975463
- 1.2785103249549865
train_accuracy:
- 0.037
- 0.121
- 0.158
- 0.159
- 0.17
- 0.183
- 0.177
- 0.0
- 0.0
- 0.198
- 0.182
- 0.182
- 0.26
- 0.245
- 0.221
- 0.239
- 0.262
- 0.285
- 0.299
- 0.261
- 0.27
- 0.27
- 0.28
- 0.245
- 0.226
- 0.256
- 0.235
- 0.321
- 0.241
- 0.307
- 0.303
- 0.332
- 0.29
- 0.334
- 0.334
- 0.273
- 0.235
- 0.34
- 0.269
- 0.256
- 0.337
- 0.291
- 0.295
- 0.0
- 0.317
- 0.29
- 0.288
- 0.308
- 0.3
- 0.313
- 0.3
- 0.391
- 0.298
- 0.31
- 0.328
- 0.257
- 0.0
- 0.276
- 0.31
- 0.0
- 0.277
- 0.257
- 0.0
- 0.273
- 0.371
- 0.0
- 0.364
- 0.313
- 0.253
- 0.321
- 0.371
- 0.354
- 0.32
- 0.388
- 0.266
- 0.0
- 0.313
- 0.337
- 0.335
- 0.359
- 0.323
- 0.29
- 0.398
- 0.0
- 0.327
- 0.334
- 0.282
- 0.3
- 0.388
- 0.0
- 0.312
- 0.314
- 0.36
- 0.396
- 0.324
- 0.324
- 0.342
- 0.343
- 0.302
- 0.335
train_loss:
- 4.263
- 3.743
- 3.582
- 3.382
- 3.278
- 3.088
- 2.986
- 2.508
- 2.43
- 2.861
- 2.347
- 2.198
- 2.721
- 2.56
- 2.183
- 2.028
- 2.264
- 2.331
- 2.298
- 2.156
- 2.134
- 2.091
- 2.055
- 2.024
- 1.769
- 1.939
- 1.886
- 1.807
- 1.584
- 1.509
- 1.637
- 1.559
- 1.569
- 1.451
- 1.542
- 1.358
- 1.348
- 1.529
- 1.381
- 1.393
- 1.214
- 1.341
- 1.272
- 1.269
- 1.28
- 1.125
- 1.051
- 1.172
- 1.42
- 1.06
- 1.012
- 1.102
- 0.997
- 0.975
- 0.95
- 0.864
- 0.948
- 1.024
- 0.889
- 1.076
- 0.869
- 1.0
- 0.896
- 0.72
- 0.758
- 0.776
- 0.721
- 0.856
- 0.738
- 0.765
- 0.627
- 0.805
- 0.62
- 0.679
- 0.591
- 0.722
- 0.605
- 0.666
- 0.586
- 0.56
- 0.479
- 0.678
- 0.535
- 0.608
- 0.541
- 0.489
- 0.579
- 0.524
- 0.586
- 0.543
- 0.454
- 0.385
- 0.526
- 0.414
- 0.361
- 0.601
- 0.378
- 0.45
- 0.415
- 0.349
unequal: 0
verbose: 1
