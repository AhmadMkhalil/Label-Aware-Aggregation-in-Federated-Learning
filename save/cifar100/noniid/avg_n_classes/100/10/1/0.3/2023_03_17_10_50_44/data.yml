avg_train_accuracy: 0.371
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0476
- 0.0936
- 0.1092
- 0.1242
- 0.1336
- 0.1466
- 0.1572
- 0.1667
- 0.1733
- 0.1829
- 0.1891
- 0.193
- 0.1964
- 0.2036
- 0.2093
- 0.2155
- 0.2195
- 0.2234
- 0.2256
- 0.2278
- 0.2318
- 0.238
- 0.2365
- 0.238
- 0.2398
- 0.2438
- 0.2473
- 0.2519
- 0.2546
- 0.2546
- 0.2618
- 0.2662
- 0.2682
- 0.2732
- 0.2709
- 0.2758
- 0.2774
- 0.2801
- 0.2803
- 0.2842
- 0.2823
- 0.2797
- 0.2919
- 0.2897
- 0.2903
- 0.2931
- 0.2942
- 0.2958
- 0.2981
- 0.298
- 0.2941
- 0.2941
- 0.2945
- 0.3
- 0.305
- 0.2962
- 0.3021
- 0.3057
- 0.3022
- 0.3049
- 0.3072
- 0.3093
- 0.3081
- 0.3118
- 0.311
- 0.31
- 0.305
- 0.3036
- 0.3112
- 0.308
- 0.3129
- 0.3188
- 0.3125
- 0.3084
- 0.3144
- 0.3154
- 0.314
- 0.3098
- 0.3164
- 0.316
- 0.313
- 0.3198
- 0.3196
- 0.3158
- 0.3155
- 0.3231
- 0.3205
- 0.3173
- 0.3237
- 0.3231
- 0.3208
- 0.3216
- 0.3239
- 0.3238
- 0.3242
- 0.321
- 0.3253
- 0.3235
- 0.3246
- 0.3225
test_loss_list:
- 1.8053980207443237
- 1.6861031699180602
- 1.6270446872711182
- 1.5849465107917786
- 1.5817667317390443
- 1.5676777935028077
- 1.5562845849990845
- 1.550316014289856
- 1.5099301886558534
- 1.5104682302474977
- 1.504691092967987
- 1.5000511312484741
- 1.5012313389778138
- 1.4914539980888366
- 1.4504204201698303
- 1.4540299081802368
- 1.4157376098632812
- 1.4274384045600892
- 1.4276237440109254
- 1.3961937522888184
- 1.4050004649162293
- 1.4058478999137878
- 1.3749759554862977
- 1.359501175880432
- 1.3741982984542847
- 1.3785593676567078
- 1.3825509452819824
- 1.3792901873588561
- 1.3415927171707154
- 1.3586336994171142
- 1.3544355940818786
- 1.3589437127113342
- 1.3587991523742675
- 1.3593261885643004
- 1.3612557530403138
- 1.3613378858566285
- 1.3600544500350953
- 1.3630453538894653
- 1.3650035810470582
- 1.3635834503173827
- 1.362219247817993
- 1.3692684912681579
- 1.3567209291458129
- 1.3648407196998595
- 1.3173056483268737
- 1.3256340622901917
- 1.3290668869018554
- 1.2898628640174865
- 1.306135265827179
- 1.2762312150001527
- 1.2929500555992126
- 1.2666031432151794
- 1.2766358613967896
- 1.2902615404129028
- 1.283233766555786
- 1.2980149006843567
- 1.2628407573699951
- 1.276739137172699
- 1.2835828113555907
- 1.2912294363975525
- 1.2963739275932311
- 1.3080367016792298
- 1.302832577228546
- 1.3088646745681762
- 1.3157256150245666
- 1.3106795048713684
- 1.2757833290100098
- 1.25714736700058
- 1.26417795419693
- 1.2826311564445496
- 1.2850524497032165
- 1.2780067467689513
- 1.3019880914688111
- 1.2616591024398804
- 1.2771258234977723
- 1.279882662296295
- 1.2925807690620423
- 1.2664634966850281
- 1.2754927682876587
- 1.2761123991012573
- 1.286144995689392
- 1.2861305785179138
- 1.2879212975502015
- 1.3035207533836364
- 1.3060848593711853
- 1.30636159658432
- 1.3062326431274414
- 1.3074976181983948
- 1.3047023010253906
- 1.3159294891357423
- 1.3256408190727234
- 1.3247701144218444
- 1.3185735583305358
- 1.3198071789741517
- 1.3271142220497132
- 1.3318246626853942
- 1.3314439010620118
- 1.3330066061019898
- 1.3373381662368775
- 1.3471621751785279
train_accuracy:
- 0.06
- 0.126
- 0.0
- 0.14
- 0.153
- 0.15
- 0.189
- 0.149
- 0.0
- 0.149
- 0.223
- 0.194
- 0.221
- 0.244
- 0.208
- 0.241
- 0.219
- 0.208
- 0.237
- 0.237
- 0.232
- 0.22
- 0.241
- 0.231
- 0.228
- 0.237
- 0.245
- 0.233
- 0.254
- 0.261
- 0.28
- 0.252
- 0.302
- 0.301
- 0.29
- 0.251
- 0.285
- 0.298
- 0.279
- 0.281
- 0.322
- 0.254
- 0.279
- 0.312
- 0.334
- 0.269
- 0.331
- 0.0
- 0.311
- 0.301
- 0.331
- 0.0
- 0.295
- 0.294
- 0.35
- 0.274
- 0.323
- 0.337
- 0.313
- 0.321
- 0.328
- 0.324
- 0.271
- 0.334
- 0.312
- 0.324
- 0.326
- 0.304
- 0.315
- 0.315
- 0.328
- 0.291
- 0.34
- 0.348
- 0.349
- 0.353
- 0.331
- 0.303
- 0.332
- 0.331
- 0.336
- 0.348
- 0.338
- 0.336
- 0.302
- 0.299
- 0.339
- 0.339
- 0.358
- 0.318
- 0.339
- 0.34
- 0.349
- 0.349
- 0.356
- 0.342
- 0.354
- 0.381
- 0.352
- 0.371
train_loss:
- 4.289
- 3.19
- 3.0
- 2.91
- 3.285
- 3.219
- 3.046
- 3.025
- 2.488
- 2.77
- 2.823
- 2.666
- 2.587
- 2.515
- 2.306
- 2.351
- 2.218
- 2.265
- 2.287
- 1.941
- 2.03
- 2.255
- 1.768
- 1.661
- 1.946
- 1.996
- 1.893
- 1.952
- 1.705
- 1.77
- 1.785
- 1.736
- 1.605
- 1.818
- 1.592
- 1.702
- 1.477
- 1.485
- 1.295
- 1.326
- 1.509
- 1.289
- 1.474
- 1.452
- 1.373
- 1.264
- 1.34
- 1.214
- 1.19
- 1.051
- 1.144
- 1.222
- 1.129
- 0.948
- 1.029
- 0.911
- 1.101
- 1.003
- 0.96
- 0.994
- 0.903
- 0.82
- 0.889
- 0.697
- 0.886
- 0.879
- 0.882
- 0.851
- 0.791
- 0.739
- 0.692
- 0.767
- 0.681
- 0.727
- 0.65
- 0.575
- 0.523
- 0.734
- 0.632
- 0.631
- 0.516
- 0.612
- 0.502
- 0.446
- 0.456
- 0.585
- 0.487
- 0.487
- 0.524
- 0.464
- 0.464
- 0.447
- 0.437
- 0.414
- 0.397
- 0.429
- 0.46
- 0.355
- 0.362
- 0.312
unequal: 0
verbose: 1
