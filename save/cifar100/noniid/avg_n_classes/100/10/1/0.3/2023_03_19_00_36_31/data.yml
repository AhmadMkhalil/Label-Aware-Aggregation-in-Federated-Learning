avg_train_accuracy: 0.362
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0494
- 0.101
- 0.118
- 0.1354
- 0.1522
- 0.1643
- 0.1659
- 0.1747
- 0.1897
- 0.1935
- 0.1941
- 0.2068
- 0.209
- 0.211
- 0.2178
- 0.2251
- 0.2261
- 0.233
- 0.2332
- 0.2374
- 0.2368
- 0.2439
- 0.247
- 0.253
- 0.249
- 0.2555
- 0.2577
- 0.2562
- 0.2563
- 0.2612
- 0.265
- 0.2642
- 0.268
- 0.2701
- 0.265
- 0.2717
- 0.2754
- 0.2776
- 0.2786
- 0.2809
- 0.2802
- 0.2878
- 0.2878
- 0.288
- 0.2898
- 0.2835
- 0.2879
- 0.2948
- 0.2937
- 0.2948
- 0.2934
- 0.2916
- 0.2942
- 0.2949
- 0.2959
- 0.2923
- 0.297
- 0.2995
- 0.3017
- 0.302
- 0.3017
- 0.2955
- 0.3047
- 0.3046
- 0.2958
- 0.2992
- 0.3091
- 0.3085
- 0.3075
- 0.3045
- 0.3126
- 0.3085
- 0.3076
- 0.3047
- 0.3075
- 0.3075
- 0.3121
- 0.3056
- 0.3021
- 0.3141
- 0.3176
- 0.3186
- 0.3106
- 0.3122
- 0.3174
- 0.3166
- 0.3134
- 0.3154
- 0.3166
- 0.3121
- 0.3092
- 0.3152
- 0.3173
- 0.3204
- 0.3183
- 0.3177
- 0.3141
- 0.3148
- 0.3193
- 0.3189
test_loss_list:
- 1.79370943069458
- 1.692132863998413
- 1.6583909726142883
- 1.633244228363037
- 1.6032447910308838
- 1.5871092104911804
- 1.5514280986785889
- 1.53717933177948
- 1.530766041278839
- 1.5250301337242127
- 1.4885103273391724
- 1.481337878704071
- 1.4778249979019165
- 1.4400192093849182
- 1.4124788212776185
- 1.4229163217544556
- 1.4303696656227112
- 1.426148965358734
- 1.4231008052825929
- 1.4280363655090331
- 1.4006116938591004
- 1.3976229858398437
- 1.3663578748703002
- 1.3765842008590699
- 1.3499687266349794
- 1.3533836793899536
- 1.3626222729682922
- 1.3390621852874756
- 1.3237501740455628
- 1.3032934617996217
- 1.3258562064170838
- 1.332610366344452
- 1.341709384918213
- 1.3417843651771546
- 1.3553911709785462
- 1.3482821822166442
- 1.3493206977844239
- 1.3563934922218324
- 1.3159812331199645
- 1.3248875260353088
- 1.3255498170852662
- 1.328154320716858
- 1.3279377365112304
- 1.331467936038971
- 1.3308819103240968
- 1.297336630821228
- 1.2743199968338013
- 1.2882715249061585
- 1.3005861687660216
- 1.3060638308525085
- 1.3087067818641662
- 1.3186619782447815
- 1.315362162590027
- 1.319328932762146
- 1.3231945443153381
- 1.2880528092384338
- 1.270381546020508
- 1.2796022748947145
- 1.2533766317367554
- 1.2678603863716125
- 1.280242190361023
- 1.2550363039970398
- 1.2639017057418824
- 1.2689520812034607
- 1.2652227401733398
- 1.2307863092422486
- 1.2485247468948364
- 1.2294464921951294
- 1.2583815836906433
- 1.237874562740326
- 1.244050395488739
- 1.2615144920349122
- 1.2737185621261597
- 1.2833809447288513
- 1.2518999290466308
- 1.2278919672966004
- 1.252176389694214
- 1.2721811366081237
- 1.253650097846985
- 1.2486823534965514
- 1.2532158493995667
- 1.2672896194458008
- 1.2705880284309388
- 1.271078884601593
- 1.2855678343772887
- 1.2882080245018006
- 1.2859860253334046
- 1.2963292360305787
- 1.2938450002670288
- 1.2669328546524048
- 1.2513497972488403
- 1.2235883116722106
- 1.2515097737312317
- 1.2536710834503173
- 1.2645013284683229
- 1.2680876755714416
- 1.255380048751831
- 1.2631390547752381
- 1.2658479642868041
- 1.2778003311157227
train_accuracy:
- 0.044
- 0.09
- 0.141
- 0.122
- 0.178
- 0.191
- 0.124
- 0.187
- 0.158
- 0.21
- 0.0
- 0.237
- 0.234
- 0.246
- 0.0
- 0.249
- 0.247
- 0.264
- 0.216
- 0.223
- 0.249
- 0.254
- 0.287
- 0.256
- 0.292
- 0.246
- 0.219
- 0.286
- 0.0
- 0.0
- 0.26
- 0.296
- 0.265
- 0.314
- 0.288
- 0.225
- 0.301
- 0.271
- 0.0
- 0.237
- 0.306
- 0.3
- 0.327
- 0.322
- 0.345
- 0.0
- 0.0
- 0.3
- 0.304
- 0.335
- 0.347
- 0.333
- 0.314
- 0.261
- 0.321
- 0.266
- 0.0
- 0.283
- 0.331
- 0.351
- 0.317
- 0.335
- 0.359
- 0.311
- 0.0
- 0.0
- 0.356
- 0.0
- 0.342
- 0.0
- 0.334
- 0.338
- 0.322
- 0.324
- 0.335
- 0.286
- 0.293
- 0.346
- 0.337
- 0.355
- 0.298
- 0.342
- 0.329
- 0.333
- 0.327
- 0.368
- 0.367
- 0.362
- 0.372
- 0.296
- 0.323
- 0.344
- 0.297
- 0.375
- 0.326
- 0.367
- 0.357
- 0.378
- 0.314
- 0.362
train_loss:
- 4.275
- 3.792
- 3.493
- 3.315
- 3.274
- 3.139
- 2.604
- 2.913
- 2.805
- 2.822
- 2.365
- 2.629
- 2.506
- 2.282
- 2.162
- 2.415
- 2.374
- 2.192
- 2.285
- 2.196
- 2.023
- 2.028
- 1.982
- 2.023
- 1.608
- 2.071
- 1.913
- 1.679
- 1.588
- 1.713
- 1.687
- 1.648
- 1.704
- 1.554
- 1.366
- 1.585
- 1.545
- 1.359
- 1.56
- 1.495
- 1.407
- 1.419
- 1.343
- 1.306
- 1.204
- 1.288
- 1.086
- 1.129
- 1.229
- 1.2
- 1.038
- 1.023
- 1.122
- 0.995
- 0.889
- 0.957
- 1.166
- 0.995
- 0.921
- 0.856
- 0.929
- 0.876
- 0.872
- 0.895
- 0.839
- 0.826
- 0.664
- 0.807
- 0.695
- 0.82
- 0.648
- 0.581
- 0.626
- 0.879
- 0.703
- 0.76
- 0.604
- 0.672
- 0.581
- 0.616
- 0.736
- 0.518
- 0.621
- 0.548
- 0.633
- 0.478
- 0.461
- 0.565
- 0.438
- 0.568
- 0.606
- 0.513
- 0.487
- 0.41
- 0.455
- 0.377
- 0.446
- 0.386
- 0.407
- 0.445
unequal: 0
verbose: 1
