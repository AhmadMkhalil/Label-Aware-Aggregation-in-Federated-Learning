avg_train_accuracy: 0.341
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0375
- 0.0886
- 0.1184
- 0.1309
- 0.1405
- 0.1609
- 0.1698
- 0.174
- 0.1806
- 0.1937
- 0.1956
- 0.2014
- 0.2104
- 0.2106
- 0.2154
- 0.2238
- 0.23
- 0.2298
- 0.2332
- 0.2373
- 0.2457
- 0.2549
- 0.2563
- 0.26
- 0.2523
- 0.2619
- 0.2585
- 0.2693
- 0.2683
- 0.2611
- 0.2595
- 0.266
- 0.2753
- 0.2698
- 0.2732
- 0.2783
- 0.2821
- 0.2834
- 0.2953
- 0.2879
- 0.2917
- 0.2868
- 0.2964
- 0.2996
- 0.2984
- 0.3027
- 0.3003
- 0.3025
- 0.3053
- 0.3025
- 0.3045
- 0.3067
- 0.3083
- 0.3051
- 0.301
- 0.3004
- 0.3088
- 0.3074
- 0.3095
- 0.3082
- 0.3022
- 0.3132
- 0.3025
- 0.3104
- 0.314
- 0.3121
- 0.3091
- 0.3209
- 0.3154
- 0.3171
- 0.3179
- 0.3257
- 0.3135
- 0.3179
- 0.3146
- 0.3159
- 0.3181
- 0.3253
- 0.3173
- 0.323
- 0.3156
- 0.3243
- 0.3273
- 0.3231
- 0.3238
- 0.3246
- 0.3283
- 0.3246
- 0.3191
- 0.3232
- 0.3203
- 0.3194
- 0.3236
- 0.3197
- 0.327
- 0.3261
- 0.3207
- 0.3285
- 0.3221
- 0.3257
test_loss_list:
- 1.808909673690796
- 1.7129513549804687
- 1.6749566388130188
- 1.6420622372627258
- 1.592619490623474
- 1.5737306833267213
- 1.5673063254356385
- 1.5226707530021668
- 1.517829384803772
- 1.5090205430984498
- 1.5034301829338075
- 1.502589294910431
- 1.493416233062744
- 1.488338632583618
- 1.4842786073684693
- 1.4450518584251404
- 1.443711748123169
- 1.4168529319763183
- 1.4130192947387696
- 1.4157550239562988
- 1.4167244482040404
- 1.4114948320388794
- 1.404878604412079
- 1.413356351852417
- 1.4165727043151854
- 1.4077229905128479
- 1.414777672290802
- 1.4080031752586364
- 1.3591543292999269
- 1.348632950782776
- 1.3338749527931213
- 1.308967342376709
- 1.3224273538589477
- 1.3124762153625489
- 1.298524672985077
- 1.3063255620002747
- 1.311126277446747
- 1.3254914712905883
- 1.3063933777809142
- 1.3262252473831178
- 1.3249922227859496
- 1.2994047284126282
- 1.2994221663475036
- 1.299662606716156
- 1.3114254212379455
- 1.310864748954773
- 1.321936421394348
- 1.3232352542877197
- 1.3287824630737304
- 1.3269124293327332
- 1.3303750443458557
- 1.3302804350852966
- 1.3344885277748109
- 1.3379772043228149
- 1.2970678663253785
- 1.3097155785560608
- 1.311523096561432
- 1.3189036631584168
- 1.3159412360191345
- 1.3276464104652406
- 1.2988665986061096
- 1.2958770346641542
- 1.2756966495513915
- 1.2756276035308838
- 1.286295647621155
- 1.2534891223907472
- 1.2360227489471436
- 1.2488504290580749
- 1.230136444568634
- 1.2510952734947205
- 1.2649908423423768
- 1.2651721405982972
- 1.290676348209381
- 1.2437752413749694
- 1.2710610342025757
- 1.2388789463043213
- 1.2610098123550415
- 1.2612558555603028
- 1.2765170121192932
- 1.2751398372650147
- 1.255518615245819
- 1.263638472557068
- 1.2666219282150268
- 1.2361075925827025
- 1.2547975015640258
- 1.2674882841110229
- 1.2691253519058228
- 1.2705298900604247
- 1.244609649181366
- 1.2564755725860595
- 1.267171185016632
- 1.2514292979240418
- 1.2586903285980224
- 1.2366406893730164
- 1.248876805305481
- 1.2603108930587767
- 1.231485595703125
- 1.2421746921539307
- 1.2602625036239623
- 1.264207000732422
train_accuracy:
- 0.039
- 0.078
- 0.116
- 0.161
- 0.134
- 0.161
- 0.193
- 0.18
- 0.214
- 0.189
- 0.197
- 0.205
- 0.221
- 0.185
- 0.225
- 0.231
- 0.234
- 0.225
- 0.247
- 0.25
- 0.249
- 0.255
- 0.322
- 0.274
- 0.265
- 0.272
- 0.25
- 0.276
- 0.0
- 0.275
- 0.289
- 0.275
- 0.281
- 0.304
- 0.296
- 0.255
- 0.295
- 0.323
- 0.282
- 0.305
- 0.291
- 0.0
- 0.346
- 0.286
- 0.291
- 0.299
- 0.303
- 0.318
- 0.292
- 0.278
- 0.314
- 0.32
- 0.312
- 0.303
- 0.0
- 0.368
- 0.316
- 0.317
- 0.38
- 0.365
- 0.325
- 0.372
- 0.315
- 0.32
- 0.315
- 0.328
- 0.302
- 0.324
- 0.365
- 0.332
- 0.32
- 0.37
- 0.316
- 0.362
- 0.318
- 0.326
- 0.339
- 0.315
- 0.346
- 0.338
- 0.341
- 0.33
- 0.335
- 0.0
- 0.346
- 0.337
- 0.341
- 0.301
- 0.0
- 0.35
- 0.375
- 0.338
- 0.375
- 0.0
- 0.325
- 0.346
- 0.0
- 0.376
- 0.369
- 0.341
train_loss:
- 4.323
- 3.822
- 3.558
- 3.401
- 2.78
- 3.186
- 3.023
- 2.697
- 2.904
- 2.882
- 2.703
- 2.633
- 2.56
- 2.552
- 2.406
- 2.183
- 2.505
- 1.946
- 2.245
- 2.239
- 2.189
- 2.111
- 2.089
- 1.993
- 1.988
- 1.839
- 1.82
- 1.812
- 1.756
- 1.441
- 1.363
- 1.506
- 1.559
- 1.264
- 1.489
- 1.618
- 1.526
- 1.583
- 1.594
- 1.4
- 1.415
- 1.225
- 1.476
- 1.437
- 1.248
- 1.29
- 1.156
- 1.165
- 1.104
- 1.289
- 0.995
- 1.008
- 1.048
- 0.962
- 1.057
- 0.977
- 1.094
- 0.803
- 0.966
- 0.848
- 0.811
- 0.938
- 1.018
- 0.909
- 0.745
- 0.895
- 0.806
- 0.877
- 0.834
- 0.73
- 0.73
- 0.724
- 0.668
- 0.712
- 0.557
- 0.662
- 0.57
- 0.599
- 0.547
- 0.543
- 0.609
- 0.529
- 0.448
- 0.733
- 0.518
- 0.441
- 0.469
- 0.513
- 0.619
- 0.442
- 0.44
- 0.492
- 0.348
- 0.531
- 0.37
- 0.439
- 0.598
- 0.354
- 0.351
- 0.339
unequal: 0
verbose: 1
