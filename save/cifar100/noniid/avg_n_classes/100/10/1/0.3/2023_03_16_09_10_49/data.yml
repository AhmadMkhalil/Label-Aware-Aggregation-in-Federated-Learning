avg_train_accuracy: 0.379
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0529
- 0.1057
- 0.1213
- 0.1348
- 0.1531
- 0.1571
- 0.1748
- 0.1778
- 0.18
- 0.1891
- 0.1997
- 0.2006
- 0.2087
- 0.2096
- 0.2178
- 0.2224
- 0.2236
- 0.2278
- 0.2294
- 0.2346
- 0.234
- 0.2395
- 0.2439
- 0.2486
- 0.2502
- 0.2516
- 0.255
- 0.2557
- 0.2566
- 0.2616
- 0.2623
- 0.2659
- 0.265
- 0.2623
- 0.2663
- 0.2734
- 0.2746
- 0.2756
- 0.2786
- 0.2774
- 0.2793
- 0.2853
- 0.2846
- 0.2799
- 0.2877
- 0.2836
- 0.2905
- 0.2873
- 0.2926
- 0.2958
- 0.2908
- 0.2918
- 0.2938
- 0.2933
- 0.291
- 0.2927
- 0.2981
- 0.2994
- 0.2984
- 0.2971
- 0.3005
- 0.2999
- 0.3011
- 0.302
- 0.3029
- 0.3001
- 0.3025
- 0.3026
- 0.3036
- 0.3074
- 0.3001
- 0.3081
- 0.3111
- 0.3023
- 0.3099
- 0.3129
- 0.3086
- 0.314
- 0.312
- 0.3091
- 0.3122
- 0.3109
- 0.3128
- 0.3143
- 0.3151
- 0.3153
- 0.3172
- 0.3158
- 0.3135
- 0.3147
- 0.3173
- 0.317
- 0.3143
- 0.3207
- 0.3185
- 0.3198
- 0.3185
- 0.3191
- 0.3209
- 0.3153
test_loss_list:
- 1.7948255586624144
- 1.6954862451553345
- 1.661842725276947
- 1.6371126866340637
- 1.6150748229026795
- 1.6053015470504761
- 1.5846079969406128
- 1.5778516578674315
- 1.5407329201698303
- 1.528089337348938
- 1.5257123279571534
- 1.5241200780868531
- 1.5161088633537292
- 1.5116101241111755
- 1.494964714050293
- 1.4961867833137512
- 1.4964248776435851
- 1.4898551797866821
- 1.4502990698814393
- 1.4467945528030395
- 1.4117127895355224
- 1.4189100742340088
- 1.3819122004508972
- 1.397056541442871
- 1.4000893282890319
- 1.4046394371986388
- 1.4090204453468322
- 1.409189326763153
- 1.3719189453125
- 1.377389919757843
- 1.3805599308013916
- 1.3465339922904969
- 1.364744484424591
- 1.338451430797577
- 1.3528017544746398
- 1.3513082122802735
- 1.3567026567459106
- 1.3670887207984925
- 1.359129467010498
- 1.36961820602417
- 1.3685218739509581
- 1.3655729746818543
- 1.3685943722724914
- 1.3332206678390504
- 1.337550115585327
- 1.3536997270584106
- 1.348141770362854
- 1.3572260379791259
- 1.3541117763519288
- 1.3518848991394044
- 1.356016674041748
- 1.3622049713134765
- 1.362826464176178
- 1.368756194114685
- 1.3309394478797913
- 1.2993739104270936
- 1.3126678347587586
- 1.3170398473739624
- 1.3241992783546448
- 1.286365897655487
- 1.2636564826965333
- 1.2822051644325256
- 1.293863091468811
- 1.3039883041381837
- 1.3114590239524841
- 1.321449604034424
- 1.3324238801002501
- 1.3329628825187683
- 1.329456627368927
- 1.332585153579712
- 1.2964229965209961
- 1.3025146865844726
- 1.310239531993866
- 1.322004759311676
- 1.321322305202484
- 1.319578459262848
- 1.33553120136261
- 1.3347500467300415
- 1.3498182463645936
- 1.3458455443382262
- 1.3458114957809448
- 1.3455198431015014
- 1.3094154906272888
- 1.26785151720047
- 1.2980025625228881
- 1.3109965634346008
- 1.3124049305915833
- 1.2743511819839477
- 1.2932457542419433
- 1.2981350684165955
- 1.3129809641838073
- 1.3148097062110902
- 1.2762820029258728
- 1.2900181460380553
- 1.3022745847702026
- 1.3022123742103577
- 1.3077649235725404
- 1.3121551442146302
- 1.3215411305427551
- 1.3289065146446228
train_accuracy:
- 0.052
- 0.099
- 0.125
- 0.196
- 0.209
- 0.146
- 0.131
- 0.195
- 0.0
- 0.215
- 0.185
- 0.182
- 0.208
- 0.226
- 0.194
- 0.233
- 0.227
- 0.212
- 0.0
- 0.224
- 0.0
- 0.231
- 0.259
- 0.255
- 0.241
- 0.239
- 0.281
- 0.224
- 0.257
- 0.291
- 0.238
- 0.239
- 0.259
- 0.294
- 0.287
- 0.247
- 0.242
- 0.251
- 0.309
- 0.274
- 0.277
- 0.252
- 0.304
- 0.263
- 0.273
- 0.29
- 0.277
- 0.269
- 0.324
- 0.303
- 0.285
- 0.303
- 0.281
- 0.272
- 0.0
- 0.0
- 0.337
- 0.28
- 0.34
- 0.0
- 0.286
- 0.314
- 0.304
- 0.345
- 0.306
- 0.29
- 0.301
- 0.313
- 0.313
- 0.305
- 0.351
- 0.328
- 0.297
- 0.291
- 0.338
- 0.299
- 0.298
- 0.296
- 0.339
- 0.296
- 0.359
- 0.312
- 0.0
- 0.344
- 0.325
- 0.31
- 0.334
- 0.311
- 0.31
- 0.318
- 0.303
- 0.313
- 0.328
- 0.326
- 0.366
- 0.322
- 0.3
- 0.32
- 0.331
- 0.379
train_loss:
- 4.241
- 3.721
- 3.457
- 3.372
- 3.248
- 3.135
- 3.024
- 2.923
- 2.441
- 2.868
- 2.698
- 2.518
- 2.617
- 2.433
- 2.649
- 2.367
- 2.334
- 2.269
- 1.95
- 2.286
- 1.939
- 2.01
- 1.955
- 1.975
- 1.964
- 1.938
- 1.768
- 1.791
- 1.59
- 1.863
- 1.836
- 1.474
- 1.591
- 1.313
- 1.567
- 1.713
- 1.588
- 1.38
- 1.604
- 1.312
- 1.334
- 1.377
- 1.224
- 1.239
- 1.282
- 1.135
- 1.118
- 1.228
- 0.984
- 1.276
- 1.123
- 0.918
- 1.031
- 1.057
- 0.997
- 0.868
- 0.941
- 1.015
- 0.969
- 0.923
- 0.968
- 0.833
- 0.923
- 0.754
- 0.679
- 0.6
- 0.755
- 0.795
- 0.697
- 0.716
- 0.846
- 0.71
- 0.634
- 0.568
- 0.575
- 0.62
- 0.559
- 0.527
- 0.495
- 0.571
- 0.507
- 0.504
- 0.687
- 0.762
- 0.509
- 0.468
- 0.442
- 0.645
- 0.44
- 0.486
- 0.404
- 0.408
- 0.588
- 0.43
- 0.388
- 0.443
- 0.406
- 0.366
- 0.319
- 0.369
unequal: 0
verbose: 1
