avg_train_accuracy: 0.38
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0393
- 0.0956
- 0.1175
- 0.1355
- 0.1472
- 0.1618
- 0.1648
- 0.1714
- 0.1823
- 0.1852
- 0.1927
- 0.195
- 0.2039
- 0.2061
- 0.2089
- 0.209
- 0.2162
- 0.2219
- 0.2269
- 0.2312
- 0.233
- 0.2294
- 0.2362
- 0.2416
- 0.2482
- 0.2498
- 0.2499
- 0.2523
- 0.2554
- 0.259
- 0.2553
- 0.2566
- 0.2565
- 0.2596
- 0.2567
- 0.2636
- 0.2658
- 0.2685
- 0.2707
- 0.275
- 0.2648
- 0.2761
- 0.2666
- 0.2692
- 0.2739
- 0.284
- 0.2848
- 0.2808
- 0.2825
- 0.2864
- 0.2854
- 0.2829
- 0.2882
- 0.2897
- 0.285
- 0.2934
- 0.2927
- 0.2919
- 0.2958
- 0.2952
- 0.2961
- 0.295
- 0.2952
- 0.2961
- 0.301
- 0.2939
- 0.2982
- 0.302
- 0.305
- 0.3044
- 0.304
- 0.3004
- 0.299
- 0.2969
- 0.3008
- 0.3037
- 0.3005
- 0.3037
- 0.3005
- 0.2982
- 0.3093
- 0.2999
- 0.3133
- 0.3116
- 0.3105
- 0.3096
- 0.3115
- 0.3087
- 0.3122
- 0.3081
- 0.3065
- 0.3105
- 0.3092
- 0.3104
- 0.3068
- 0.3165
- 0.3144
- 0.3115
- 0.31
- 0.315
test_loss_list:
- 1.801922516822815
- 1.6811720848083496
- 1.6390116214752197
- 1.6187133121490478
- 1.5964841961860656
- 1.5827733635902406
- 1.5792327189445496
- 1.5660144090652466
- 1.5473609066009522
- 1.5061873149871827
- 1.5037284040451049
- 1.470061252117157
- 1.4672318482398987
- 1.4750208020210267
- 1.4715224647521972
- 1.4676461791992188
- 1.4621082520484925
- 1.461571762561798
- 1.457457547187805
- 1.451505150794983
- 1.4543380689620973
- 1.4146335411071778
- 1.382151026725769
- 1.3923521375656127
- 1.3933291411399842
- 1.3521658730506898
- 1.3651268577575684
- 1.3698289203643799
- 1.368657615184784
- 1.3757759094238282
- 1.3508066892623902
- 1.3612711215019226
- 1.3688066101074219
- 1.364697003364563
- 1.339177074432373
- 1.340419430732727
- 1.3493461632728576
- 1.3505402612686157
- 1.3569250416755676
- 1.3537438893318177
- 1.3298123288154602
- 1.3311594486236573
- 1.3102838802337646
- 1.2924763703346251
- 1.2710445284843446
- 1.2604675745964051
- 1.2771313762664795
- 1.2921295642852784
- 1.3089633417129516
- 1.3068007159233093
- 1.3122350454330445
- 1.2904456639289856
- 1.290214102268219
- 1.3025743627548219
- 1.2814228129386902
- 1.2799967575073241
- 1.2924991011619569
- 1.2992460179328917
- 1.293990023136139
- 1.3029968857765197
- 1.305891318321228
- 1.3100048255920411
- 1.316468050479889
- 1.2792259025573731
- 1.2953153586387633
- 1.2691498279571534
- 1.238702416419983
- 1.2583077239990235
- 1.2667923498153686
- 1.277203826904297
- 1.2881713032722473
- 1.297209794521332
- 1.2734496903419494
- 1.2503119468688966
- 1.2624602818489075
- 1.2380295825004577
- 1.2606494164466857
- 1.24649733543396
- 1.2341739869117736
- 1.2257744240760804
- 1.2474401879310608
- 1.2382634329795836
- 1.2446134662628174
- 1.257778422832489
- 1.2668248772621156
- 1.2434782147407533
- 1.2549739909172057
- 1.2760932993888856
- 1.265811047554016
- 1.2839216566085816
- 1.2983972835540771
- 1.283434591293335
- 1.2950473284721375
- 1.2995025777816773
- 1.3007924747467041
- 1.3034707069396974
- 1.3071299338340758
- 1.3120992684364319
- 1.31634281873703
- 1.3128343963623046
train_accuracy:
- 0.028
- 0.0
- 0.123
- 0.143
- 0.152
- 0.171
- 0.169
- 0.182
- 0.195
- 0.209
- 0.21
- 0.215
- 0.195
- 0.237
- 0.251
- 0.249
- 0.249
- 0.227
- 0.263
- 0.291
- 0.265
- 0.254
- 0.0
- 0.272
- 0.302
- 0.235
- 0.276
- 0.281
- 0.247
- 0.294
- 0.255
- 0.285
- 0.243
- 0.31
- 0.271
- 0.269
- 0.294
- 0.307
- 0.312
- 0.307
- 0.0
- 0.334
- 0.323
- 0.33
- 0.0
- 0.274
- 0.346
- 0.34
- 0.341
- 0.328
- 0.255
- 0.0
- 0.334
- 0.348
- 0.254
- 0.34
- 0.327
- 0.351
- 0.346
- 0.325
- 0.369
- 0.325
- 0.335
- 0.268
- 0.262
- 0.0
- 0.333
- 0.345
- 0.359
- 0.347
- 0.377
- 0.326
- 0.348
- 0.341
- 0.337
- 0.332
- 0.331
- 0.0
- 0.0
- 0.36
- 0.356
- 0.268
- 0.373
- 0.315
- 0.347
- 0.387
- 0.343
- 0.324
- 0.381
- 0.253
- 0.351
- 0.33
- 0.343
- 0.327
- 0.327
- 0.388
- 0.376
- 0.339
- 0.384
- 0.38
train_loss:
- 4.272
- 3.116
- 3.586
- 3.347
- 3.291
- 3.096
- 2.961
- 2.933
- 2.961
- 2.44
- 2.79
- 2.276
- 2.656
- 2.413
- 2.51
- 2.472
- 2.357
- 2.276
- 2.293
- 2.18
- 2.257
- 1.981
- 1.806
- 1.971
- 2.047
- 1.844
- 1.984
- 1.904
- 1.873
- 1.808
- 1.597
- 1.676
- 1.638
- 1.644
- 1.538
- 1.597
- 1.414
- 1.483
- 1.449
- 1.313
- 1.296
- 1.466
- 1.233
- 1.305
- 1.284
- 1.116
- 1.381
- 1.12
- 0.974
- 1.197
- 1.146
- 0.989
- 1.203
- 0.998
- 0.958
- 1.133
- 0.932
- 0.928
- 0.99
- 0.866
- 1.048
- 0.969
- 0.775
- 0.978
- 0.842
- 0.9
- 0.784
- 0.756
- 0.787
- 0.699
- 0.749
- 0.655
- 0.727
- 0.705
- 0.71
- 0.623
- 0.676
- 0.68
- 0.652
- 0.649
- 0.626
- 0.582
- 0.5
- 0.537
- 0.651
- 0.565
- 0.534
- 0.561
- 0.616
- 0.461
- 0.393
- 0.474
- 0.404
- 0.365
- 0.495
- 0.471
- 0.428
- 0.416
- 0.398
- 0.395
unequal: 0
verbose: 1
