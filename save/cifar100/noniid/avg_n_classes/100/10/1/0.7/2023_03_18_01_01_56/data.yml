avg_train_accuracy: 0.348
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0443
- 0.0961
- 0.1172
- 0.1353
- 0.1503
- 0.1599
- 0.1691
- 0.1771
- 0.1866
- 0.1938
- 0.1995
- 0.204
- 0.2101
- 0.2173
- 0.2225
- 0.2271
- 0.233
- 0.2353
- 0.2393
- 0.242
- 0.2454
- 0.252
- 0.2525
- 0.2526
- 0.259
- 0.2608
- 0.2618
- 0.2644
- 0.2684
- 0.2681
- 0.2744
- 0.273
- 0.274
- 0.2725
- 0.279
- 0.2804
- 0.285
- 0.285
- 0.2847
- 0.2885
- 0.2868
- 0.2878
- 0.2916
- 0.297
- 0.2963
- 0.2942
- 0.3
- 0.2941
- 0.3017
- 0.3003
- 0.3017
- 0.3026
- 0.3042
- 0.3032
- 0.3063
- 0.3042
- 0.3063
- 0.3071
- 0.3055
- 0.3098
- 0.3103
- 0.3104
- 0.3084
- 0.3096
- 0.3119
- 0.3128
- 0.3128
- 0.313
- 0.3157
- 0.3165
- 0.3125
- 0.3164
- 0.3163
- 0.3129
- 0.3168
- 0.3181
- 0.321
- 0.3178
- 0.3189
- 0.3217
- 0.3232
- 0.3212
- 0.3228
- 0.3239
- 0.3247
- 0.3257
- 0.3253
- 0.3262
- 0.3245
- 0.3221
- 0.3235
- 0.3213
- 0.3242
- 0.3248
- 0.3294
- 0.329
- 0.3296
- 0.3331
- 0.3321
- 0.3259
test_loss_list:
- 1.7856191968917847
- 1.6561536526679992
- 1.6036681675910949
- 1.5613312911987305
- 1.5545873069763183
- 1.5132337880134583
- 1.4860986542701722
- 1.4669250965118408
- 1.4439904332160949
- 1.45500239610672
- 1.4278278875350952
- 1.4044595527648926
- 1.4194762659072877
- 1.4264051413536072
- 1.42224463224411
- 1.3834481501579285
- 1.390953209400177
- 1.360609736442566
- 1.375180070400238
- 1.341635627746582
- 1.3576450514793397
- 1.3653143191337584
- 1.3643277835845948
- 1.329314489364624
- 1.3078116035461427
- 1.2953407883644104
- 1.2799777007102966
- 1.2742696571350098
- 1.266260063648224
- 1.2625339674949645
- 1.2564425849914551
- 1.2843909645080567
- 1.2616335463523864
- 1.2540211415290832
- 1.2761307168006897
- 1.2461076116561889
- 1.2703037881851196
- 1.2427063155174256
- 1.2317848515510559
- 1.225517075061798
- 1.2546873307228088
- 1.2308033561706544
- 1.2232314538955689
- 1.2095777845382691
- 1.211100571155548
- 1.2113513803482057
- 1.2040916728973388
- 1.2365937399864197
- 1.2099770021438598
- 1.2055240154266358
- 1.2308567762374878
- 1.2420602440834045
- 1.2108948159217834
- 1.2380881571769715
- 1.2117230892181396
- 1.201695246696472
- 1.1926067328453065
- 1.2225587821006776
- 1.2024490213394166
- 1.1943871998786926
- 1.1870692014694213
- 1.2135602474212646
- 1.1989307522773742
- 1.2219585251808167
- 1.1944857954978942
- 1.1883975863456726
- 1.2153953218460083
- 1.1887897849082947
- 1.1864643645286561
- 1.1842555809020996
- 1.210863959789276
- 1.194970157146454
- 1.1841951513290405
- 1.2141558670997619
- 1.1880285549163818
- 1.1842713165283203
- 1.1772406196594238
- 1.210196990966797
- 1.2232567882537841
- 1.1944073414802552
- 1.1860821437835694
- 1.1827001547813416
- 1.2046124863624572
- 1.189105260372162
- 1.17802419424057
- 1.1786318516731262
- 1.1806192755699159
- 1.1758432912826537
- 1.1789184761047364
- 1.2047769665718078
- 1.2121033048629761
- 1.2323784685134889
- 1.1958171391487122
- 1.1865250277519226
- 1.1775130677223205
- 1.179199869632721
- 1.1755227494239806
- 1.1774741005897522
- 1.178495705127716
- 1.2091208720207214
train_accuracy:
- 0.05
- 0.123
- 0.083
- 0.108
- 0.125
- 0.143
- 0.182
- 0.142
- 0.194
- 0.174
- 0.174
- 0.257
- 0.219
- 0.204
- 0.231
- 0.238
- 0.212
- 0.254
- 0.221
- 0.251
- 0.3
- 0.212
- 0.266
- 0.263
- 0.229
- 0.247
- 0.25
- 0.265
- 0.324
- 0.267
- 0.29
- 0.285
- 0.251
- 0.287
- 0.275
- 0.277
- 0.291
- 0.32
- 0.331
- 0.298
- 0.32
- 0.297
- 0.285
- 0.32
- 0.275
- 0.32
- 0.315
- 0.339
- 0.295
- 0.3
- 0.279
- 0.345
- 0.321
- 0.344
- 0.271
- 0.287
- 0.0
- 0.338
- 0.318
- 0.339
- 0.296
- 0.345
- 0.319
- 0.322
- 0.329
- 0.366
- 0.37
- 0.313
- 0.362
- 0.366
- 0.333
- 0.0
- 0.299
- 0.334
- 0.324
- 0.332
- 0.337
- 0.352
- 0.318
- 0.393
- 0.369
- 0.0
- 0.36
- 0.358
- 0.363
- 0.376
- 0.353
- 0.387
- 0.364
- 0.338
- 0.368
- 0.396
- 0.342
- 0.345
- 0.357
- 0.0
- 0.308
- 0.0
- 0.362
- 0.348
train_loss:
- 3.9
- 3.49
- 3.278
- 3.158
- 3.248
- 2.907
- 2.785
- 2.744
- 2.638
- 2.791
- 2.517
- 2.478
- 2.575
- 2.479
- 2.437
- 2.234
- 2.359
- 2.139
- 2.196
- 2.041
- 2.079
- 2.03
- 2.023
- 1.859
- 1.796
- 1.738
- 1.715
- 1.685
- 1.646
- 1.573
- 1.556
- 1.646
- 1.477
- 1.434
- 1.487
- 1.401
- 1.46
- 1.33
- 1.346
- 1.282
- 1.325
- 1.207
- 1.185
- 1.219
- 1.173
- 1.112
- 1.071
- 1.127
- 1.059
- 1.059
- 1.043
- 1.03
- 0.98
- 0.971
- 0.893
- 0.899
- 0.882
- 0.888
- 0.827
- 0.822
- 0.837
- 0.844
- 0.75
- 0.784
- 0.764
- 0.722
- 0.709
- 0.727
- 0.682
- 0.653
- 0.684
- 0.621
- 0.629
- 0.614
- 0.594
- 0.573
- 0.572
- 0.569
- 0.55
- 0.531
- 0.512
- 0.512
- 0.525
- 0.479
- 0.484
- 0.472
- 0.442
- 0.455
- 0.436
- 0.45
- 0.429
- 0.411
- 0.425
- 0.418
- 0.417
- 0.392
- 0.369
- 0.377
- 0.358
- 0.359
unequal: 0
verbose: 1
