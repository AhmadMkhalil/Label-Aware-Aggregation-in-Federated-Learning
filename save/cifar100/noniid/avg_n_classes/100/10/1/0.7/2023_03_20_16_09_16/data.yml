avg_train_accuracy: 0.336
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0482
- 0.0977
- 0.1181
- 0.1395
- 0.1527
- 0.1635
- 0.1716
- 0.1766
- 0.1897
- 0.1961
- 0.2009
- 0.2068
- 0.2089
- 0.2157
- 0.2225
- 0.2263
- 0.2303
- 0.23
- 0.2318
- 0.2378
- 0.2397
- 0.243
- 0.2429
- 0.2461
- 0.2503
- 0.2509
- 0.2576
- 0.2582
- 0.2606
- 0.2615
- 0.2673
- 0.2687
- 0.2708
- 0.2731
- 0.2771
- 0.2801
- 0.2804
- 0.2864
- 0.2812
- 0.2845
- 0.2885
- 0.2859
- 0.2888
- 0.2887
- 0.2934
- 0.2952
- 0.2927
- 0.2933
- 0.2967
- 0.2973
- 0.3003
- 0.3008
- 0.3012
- 0.305
- 0.3048
- 0.3053
- 0.3064
- 0.3045
- 0.3059
- 0.3103
- 0.3062
- 0.3102
- 0.3095
- 0.3114
- 0.3125
- 0.3126
- 0.3192
- 0.3163
- 0.3129
- 0.3093
- 0.3172
- 0.3124
- 0.3118
- 0.3166
- 0.3204
- 0.3192
- 0.3175
- 0.32
- 0.3204
- 0.3217
- 0.3205
- 0.3198
- 0.3203
- 0.3199
- 0.32
- 0.3222
- 0.3195
- 0.3207
- 0.3219
- 0.3258
- 0.3258
- 0.3249
- 0.3262
- 0.3264
- 0.3207
- 0.3254
- 0.3228
- 0.3259
- 0.3264
- 0.3248
test_loss_list:
- 1.7960436534881592
- 1.6669355297088624
- 1.607877917289734
- 1.5664321351051331
- 1.554566161632538
- 1.5180393600463866
- 1.4905318546295165
- 1.4670856285095215
- 1.4761679792404174
- 1.4443720054626465
- 1.4247418332099915
- 1.407722101211548
- 1.3945642232894897
- 1.383922426700592
- 1.4014434504508972
- 1.376290876865387
- 1.3611677479743958
- 1.3462801313400268
- 1.3371373343467712
- 1.3295815944671632
- 1.3211654782295228
- 1.3155857825279236
- 1.338645374774933
- 1.3180620098114013
- 1.3004938793182372
- 1.294801070690155
- 1.31632887840271
- 1.2966592073440553
- 1.3176229476928711
- 1.3255366063117981
- 1.3312871265411377
- 1.2976940965652466
- 1.2756710648536682
- 1.2649588394165039
- 1.2877083706855774
- 1.2666269159317016
- 1.2526126217842102
- 1.2468616604804992
- 1.2428300166130066
- 1.2377890896797181
- 1.2340778994560242
- 1.2610628962516786
- 1.2391806793212892
- 1.25977157831192
- 1.2679179167747499
- 1.2747675800323486
- 1.283514232635498
- 1.2506975769996642
- 1.2316053414344788
- 1.2195835423469543
- 1.2166174125671387
- 1.213884997367859
- 1.2403902220726013
- 1.252037582397461
- 1.2237264394760132
- 1.2159624934196471
- 1.2045179557800294
- 1.2060161876678466
- 1.2288578987121581
- 1.207478928565979
- 1.2058588886260986
- 1.1987007784843444
- 1.1971291589736939
- 1.1953399801254272
- 1.1937470388412477
- 1.1955371069908143
- 1.1895425009727478
- 1.1912814617156982
- 1.2201428461074828
- 1.2382398891448974
- 1.2063840961456298
- 1.1987065958976746
- 1.2264830493927001
- 1.2030123949050904
- 1.194236662387848
- 1.1886385154724122
- 1.1932859706878662
- 1.1878962731361389
- 1.1873160433769225
- 1.1879259634017945
- 1.2151937580108643
- 1.197184500694275
- 1.2193916392326356
- 1.2302071166038513
- 1.241674132347107
- 1.2104842042922974
- 1.2362759447097778
- 1.206069073677063
- 1.2027567625045776
- 1.1905586576461793
- 1.1894470238685608
- 1.2177658653259278
- 1.2250857377052307
- 1.2025928044319152
- 1.2257873106002808
- 1.2046305513381959
- 1.2304225063323975
- 1.2022925400733948
- 1.1976324677467347
- 1.2258721351623536
train_accuracy:
- 0.052
- 0.0
- 0.118
- 0.146
- 0.136
- 0.159
- 0.175
- 0.153
- 0.174
- 0.17
- 0.229
- 0.197
- 0.204
- 0.184
- 0.269
- 0.224
- 0.229
- 0.261
- 0.222
- 0.226
- 0.263
- 0.223
- 0.228
- 0.231
- 0.26
- 0.0
- 0.246
- 0.267
- 0.256
- 0.243
- 0.255
- 0.0
- 0.264
- 0.249
- 0.264
- 0.271
- 0.254
- 0.0
- 0.26
- 0.279
- 0.297
- 0.296
- 0.0
- 0.287
- 0.269
- 0.298
- 0.282
- 0.271
- 0.289
- 0.33
- 0.307
- 0.289
- 0.318
- 0.283
- 0.304
- 0.294
- 0.271
- 0.0
- 0.34
- 0.298
- 0.283
- 0.292
- 0.352
- 0.3
- 0.311
- 0.349
- 0.296
- 0.34
- 0.305
- 0.329
- 0.327
- 0.322
- 0.331
- 0.333
- 0.307
- 0.355
- 0.327
- 0.312
- 0.329
- 0.299
- 0.304
- 0.358
- 0.364
- 0.33
- 0.303
- 0.314
- 0.312
- 0.318
- 0.336
- 0.0
- 0.332
- 0.36
- 0.305
- 0.318
- 0.34
- 0.349
- 0.335
- 0.322
- 0.322
- 0.336
train_loss:
- 3.947
- 3.506
- 3.314
- 3.125
- 3.264
- 2.9
- 2.802
- 2.728
- 2.876
- 2.564
- 2.499
- 2.441
- 2.361
- 2.34
- 2.431
- 2.204
- 2.148
- 2.14
- 2.096
- 2.049
- 1.993
- 1.927
- 2.047
- 1.876
- 1.821
- 1.781
- 1.892
- 1.705
- 1.781
- 1.729
- 1.68
- 1.552
- 1.511
- 1.496
- 1.538
- 1.407
- 1.377
- 1.379
- 1.313
- 1.311
- 1.263
- 1.311
- 1.234
- 1.253
- 1.236
- 1.205
- 1.142
- 1.098
- 1.074
- 1.004
- 1.002
- 0.959
- 1.017
- 0.988
- 0.936
- 0.905
- 0.859
- 0.852
- 0.874
- 0.821
- 0.779
- 0.799
- 0.772
- 0.722
- 0.753
- 0.703
- 0.73
- 0.712
- 0.711
- 0.681
- 0.643
- 0.639
- 0.648
- 0.599
- 0.594
- 0.56
- 0.583
- 0.553
- 0.548
- 0.519
- 0.526
- 0.501
- 0.511
- 0.49
- 0.494
- 0.479
- 0.458
- 0.463
- 0.434
- 0.429
- 0.418
- 0.421
- 0.431
- 0.401
- 0.403
- 0.395
- 0.36
- 0.37
- 0.366
- 0.351
unequal: 0
verbose: 1
