avg_train_accuracy: 0.312
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0374
- 0.0946
- 0.1238
- 0.1407
- 0.1481
- 0.1668
- 0.1732
- 0.184
- 0.19
- 0.1959
- 0.2003
- 0.2065
- 0.2098
- 0.2152
- 0.2241
- 0.2271
- 0.2295
- 0.2327
- 0.2364
- 0.24
- 0.2414
- 0.2458
- 0.2493
- 0.2554
- 0.2543
- 0.2589
- 0.2607
- 0.2645
- 0.265
- 0.2679
- 0.2703
- 0.2717
- 0.2762
- 0.2749
- 0.2784
- 0.2784
- 0.2816
- 0.2827
- 0.2853
- 0.286
- 0.2904
- 0.2858
- 0.2882
- 0.2922
- 0.2909
- 0.2947
- 0.2987
- 0.2978
- 0.3027
- 0.3003
- 0.3024
- 0.3022
- 0.3016
- 0.3029
- 0.3051
- 0.3029
- 0.3076
- 0.306
- 0.3051
- 0.3073
- 0.3104
- 0.3081
- 0.3111
- 0.3123
- 0.3143
- 0.3136
- 0.3106
- 0.315
- 0.3206
- 0.3216
- 0.317
- 0.315
- 0.3201
- 0.3193
- 0.3232
- 0.3225
- 0.3252
- 0.3183
- 0.3168
- 0.3216
- 0.3226
- 0.321
- 0.3251
- 0.3268
- 0.3237
- 0.3231
- 0.3266
- 0.3242
- 0.3262
- 0.3262
- 0.3243
- 0.3239
- 0.3249
- 0.3292
- 0.325
- 0.3268
- 0.3273
- 0.3283
- 0.3237
- 0.3279
test_loss_list:
- 1.8033775281906128
- 1.6714739179611207
- 1.6091142225265502
- 1.5881244874000549
- 1.5448248076438904
- 1.5078926706314086
- 1.4821284890174866
- 1.4614528012275696
- 1.4698517203330994
- 1.4417044568061828
- 1.4204979467391967
- 1.4028809666633606
- 1.3930333518981934
- 1.4090133833885192
- 1.3780390286445618
- 1.3919513940811157
- 1.3617842507362365
- 1.34705979347229
- 1.3332491779327393
- 1.357566592693329
- 1.3289489340782166
- 1.3145731019973754
- 1.30699880361557
- 1.3297670245170594
- 1.3080339622497559
- 1.3242145299911499
- 1.3002610778808594
- 1.2806768274307252
- 1.2738046407699586
- 1.2672578263282777
- 1.2641776061058045
- 1.2609852838516236
- 1.2833659982681274
- 1.260508828163147
- 1.2494597959518432
- 1.2766428804397583
- 1.2502992963790893
- 1.2380853080749512
- 1.2640083885192872
- 1.2750145602226257
- 1.2786831426620484
- 1.284261529445648
- 1.2483767676353454
- 1.2332722663879394
- 1.221113097667694
- 1.2123871922492981
- 1.205825262069702
- 1.2024862718582154
- 1.200123472213745
- 1.1997463297843933
- 1.2285805344581604
- 1.2063326454162597
- 1.2032908129692077
- 1.201130120754242
- 1.1967921209335328
- 1.194726049900055
- 1.1932903504371644
- 1.2172363805770874
- 1.197763123512268
- 1.2232802844047546
- 1.1980611205101013
- 1.1909872889518738
- 1.1885565137863159
- 1.1857485699653625
- 1.2157258534431457
- 1.193178505897522
- 1.1920831394195557
- 1.1840552282333374
- 1.1817874026298523
- 1.1795784425735474
- 1.177462658882141
- 1.2089757966995238
- 1.1897196102142333
- 1.185391011238098
- 1.1798130416870116
- 1.1808658814430237
- 1.1761506462097169
- 1.207646803855896
- 1.2232053136825563
- 1.195225908756256
- 1.183645088672638
- 1.1826610279083252
- 1.1798684668540955
- 1.1801081323623657
- 1.1820300841331481
- 1.2069953536987306
- 1.1859292602539062
- 1.1835284781455995
- 1.177854082584381
- 1.1836384677886962
- 1.2076788330078125
- 1.2149470949172974
- 1.1946964240074158
- 1.1839025688171387
- 1.2116962361335755
- 1.1885064816474915
- 1.2133871841430663
- 1.1909741711616517
- 1.2193942260742188
- 1.190093150138855
train_accuracy:
- 0.049
- 0.067
- 0.151
- 0.115
- 0.134
- 0.171
- 0.178
- 0.212
- 0.21
- 0.0
- 0.249
- 0.195
- 0.248
- 0.19
- 0.244
- 0.277
- 0.0
- 0.0
- 0.265
- 0.241
- 0.0
- 0.287
- 0.205
- 0.281
- 0.0
- 0.272
- 0.298
- 0.306
- 0.324
- 0.287
- 0.247
- 0.275
- 0.31
- 0.342
- 0.309
- 0.327
- 0.223
- 0.348
- 0.268
- 0.281
- 0.342
- 0.325
- 0.285
- 0.342
- 0.35
- 0.227
- 0.319
- 0.35
- 0.283
- 0.362
- 0.366
- 0.342
- 0.309
- 0.0
- 0.254
- 0.309
- 0.326
- 0.323
- 0.321
- 0.314
- 0.346
- 0.302
- 0.376
- 0.374
- 0.294
- 0.376
- 0.297
- 0.0
- 0.262
- 0.383
- 0.387
- 0.371
- 0.381
- 0.382
- 0.316
- 0.376
- 0.342
- 0.334
- 0.394
- 0.0
- 0.384
- 0.4
- 0.26
- 0.394
- 0.387
- 0.316
- 0.388
- 0.273
- 0.296
- 0.271
- 0.33
- 0.32
- 0.39
- 0.321
- 0.39
- 0.392
- 0.312
- 0.386
- 0.404
- 0.312
train_loss:
- 4.327
- 3.502
- 3.286
- 3.38
- 3.005
- 2.897
- 2.789
- 2.697
- 2.87
- 2.559
- 2.483
- 2.424
- 2.362
- 2.507
- 2.298
- 2.372
- 2.14
- 2.091
- 2.077
- 2.158
- 1.971
- 1.941
- 1.881
- 2.006
- 1.769
- 1.897
- 1.736
- 1.716
- 1.67
- 1.629
- 1.578
- 1.522
- 1.595
- 1.489
- 1.431
- 1.509
- 1.4
- 1.396
- 1.385
- 1.371
- 1.378
- 1.318
- 1.247
- 1.188
- 1.18
- 1.143
- 1.111
- 1.098
- 1.062
- 1.03
- 1.078
- 0.983
- 0.949
- 0.932
- 0.897
- 0.914
- 0.877
- 0.939
- 0.846
- 0.884
- 0.826
- 0.794
- 0.763
- 0.758
- 0.783
- 0.728
- 0.708
- 0.712
- 0.691
- 0.683
- 0.654
- 0.662
- 0.618
- 0.597
- 0.577
- 0.591
- 0.588
- 0.591
- 0.575
- 0.55
- 0.548
- 0.506
- 0.488
- 0.466
- 0.469
- 0.503
- 0.465
- 0.451
- 0.449
- 0.461
- 0.448
- 0.44
- 0.42
- 0.394
- 0.431
- 0.394
- 0.393
- 0.403
- 0.368
- 0.397
unequal: 0
verbose: 1
