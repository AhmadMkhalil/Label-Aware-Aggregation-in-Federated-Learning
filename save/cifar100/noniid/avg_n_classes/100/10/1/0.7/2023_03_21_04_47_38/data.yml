avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0491
- 0.0923
- 0.1098
- 0.1328
- 0.1448
- 0.1545
- 0.1686
- 0.1722
- 0.1832
- 0.1937
- 0.2018
- 0.2043
- 0.2153
- 0.2131
- 0.2207
- 0.2242
- 0.2309
- 0.2331
- 0.2375
- 0.2413
- 0.2465
- 0.2453
- 0.2515
- 0.2549
- 0.2551
- 0.2592
- 0.26
- 0.2641
- 0.2626
- 0.2667
- 0.2687
- 0.2698
- 0.2743
- 0.2735
- 0.2763
- 0.2813
- 0.2798
- 0.2826
- 0.28
- 0.2864
- 0.2844
- 0.2846
- 0.288
- 0.2881
- 0.2931
- 0.2925
- 0.2887
- 0.2899
- 0.2937
- 0.292
- 0.2921
- 0.2968
- 0.2974
- 0.2975
- 0.2988
- 0.2971
- 0.3006
- 0.3028
- 0.3027
- 0.3032
- 0.3031
- 0.3073
- 0.3073
- 0.306
- 0.308
- 0.3075
- 0.3092
- 0.3123
- 0.3112
- 0.3095
- 0.3135
- 0.3104
- 0.3144
- 0.3159
- 0.3151
- 0.3156
- 0.3144
- 0.3125
- 0.3148
- 0.3169
- 0.3191
- 0.3186
- 0.3207
- 0.3204
- 0.3194
- 0.3244
- 0.3222
- 0.3239
- 0.3196
- 0.3181
- 0.3226
- 0.3252
- 0.3231
- 0.3278
- 0.3275
- 0.3286
- 0.3243
- 0.3248
- 0.328
- 0.3296
test_loss_list:
- 1.7947177076339722
- 1.6692808985710144
- 1.612474319934845
- 1.5645304799079895
- 1.5325066924095154
- 1.502819321155548
- 1.478442919254303
- 1.456391236782074
- 1.467590982913971
- 1.4627524662017821
- 1.4257975506782532
- 1.403101692199707
- 1.385897808074951
- 1.37454110622406
- 1.3895374608039857
- 1.3638347840309144
- 1.3767591261863708
- 1.3481281185150147
- 1.3645974445343017
- 1.3367894864082337
- 1.3490719842910766
- 1.3542739367485046
- 1.3601650524139404
- 1.326599006652832
- 1.3019777584075927
- 1.3193260407447815
- 1.296189136505127
- 1.3129580545425414
- 1.288330307006836
- 1.30677166223526
- 1.311632785797119
- 1.2811454010009766
- 1.2617207169532776
- 1.2505201125144958
- 1.2449982500076293
- 1.2401411485671998
- 1.2359847331047058
- 1.2329045701026917
- 1.2615586972236634
- 1.2400069808959961
- 1.2320605397224427
- 1.2233268690109254
- 1.2223597717285157
- 1.2177332735061646
- 1.213492248058319
- 1.213839247226715
- 1.2113220691680908
- 1.2408734488487243
- 1.2492726039886475
- 1.2235384273529053
- 1.213604326248169
- 1.2069360995292664
- 1.2026750421524048
- 1.2010987186431885
- 1.1965724182128907
- 1.2265422940254211
- 1.2070039772987367
- 1.2276640272140502
- 1.207747721672058
- 1.1991160774230958
- 1.22594806432724
- 1.2022987127304077
- 1.1971716070175171
- 1.1983120465278625
- 1.2186703085899353
- 1.2016699481010438
- 1.192385845184326
- 1.188066701889038
- 1.2185938954353333
- 1.1969950914382934
- 1.1899920582771302
- 1.217782826423645
- 1.19671311378479
- 1.188991255760193
- 1.1892583250999451
- 1.188154182434082
- 1.1851437520980834
- 1.1907070016860961
- 1.2144078731536865
- 1.195025086402893
- 1.1879082751274108
- 1.186073613166809
- 1.1848038935661316
- 1.1818976950645448
- 1.2108258247375487
- 1.1875895380973815
- 1.1820660853385925
- 1.1839170670509338
- 1.2099145698547362
- 1.2243792510032654
- 1.200265109539032
- 1.1883647179603576
- 1.1902673721313477
- 1.1841223692893983
- 1.1851017546653748
- 1.183265242576599
- 1.2101704859733582
- 1.1916856026649476
- 1.1872369790077208
- 1.1872238254547118
train_accuracy:
- 0.0
- 0.093
- 0.13
- 0.126
- 0.161
- 0.191
- 0.0
- 0.18
- 0.158
- 0.164
- 0.184
- 0.187
- 0.223
- 0.19
- 0.206
- 0.232
- 0.254
- 0.262
- 0.246
- 0.0
- 0.289
- 0.24
- 0.244
- 0.256
- 0.241
- 0.263
- 0.231
- 0.264
- 0.296
- 0.287
- 0.275
- 0.317
- 0.285
- 0.295
- 0.261
- 0.288
- 0.324
- 0.275
- 0.29
- 0.322
- 0.349
- 0.284
- 0.259
- 0.304
- 0.294
- 0.339
- 0.325
- 0.31
- 0.34
- 0.291
- 0.296
- 0.301
- 0.289
- 0.32
- 0.347
- 0.299
- 0.303
- 0.353
- 0.367
- 0.303
- 0.331
- 0.0
- 0.304
- 0.0
- 0.316
- 0.361
- 0.0
- 0.363
- 0.316
- 0.331
- 0.322
- 0.328
- 0.356
- 0.0
- 0.38
- 0.305
- 0.376
- 0.379
- 0.324
- 0.318
- 0.36
- 0.309
- 0.333
- 0.328
- 0.338
- 0.0
- 0.369
- 0.342
- 0.368
- 0.375
- 0.307
- 0.34
- 0.323
- 0.336
- 0.347
- 0.327
- 0.347
- 0.354
- 0.376
- 0.0
train_loss:
- 3.915
- 3.502
- 3.305
- 3.147
- 3.022
- 2.92
- 2.789
- 2.734
- 2.867
- 2.761
- 2.53
- 2.421
- 2.354
- 2.329
- 2.477
- 2.209
- 2.338
- 2.086
- 2.217
- 2.017
- 2.116
- 2.057
- 2.005
- 1.848
- 1.799
- 1.878
- 1.722
- 1.785
- 1.622
- 1.686
- 1.666
- 1.524
- 1.468
- 1.48
- 1.415
- 1.398
- 1.375
- 1.332
- 1.41
- 1.279
- 1.253
- 1.215
- 1.203
- 1.197
- 1.131
- 1.089
- 1.108
- 1.137
- 1.121
- 1.024
- 0.983
- 0.98
- 0.937
- 0.925
- 0.909
- 0.947
- 0.881
- 0.91
- 0.841
- 0.797
- 0.864
- 0.791
- 0.764
- 0.723
- 0.786
- 0.718
- 0.68
- 0.696
- 0.705
- 0.661
- 0.64
- 0.635
- 0.629
- 0.618
- 0.593
- 0.582
- 0.554
- 0.549
- 0.55
- 0.534
- 0.525
- 0.504
- 0.49
- 0.488
- 0.48
- 0.481
- 0.453
- 0.446
- 0.446
- 0.422
- 0.437
- 0.418
- 0.404
- 0.401
- 0.384
- 0.383
- 0.398
- 0.365
- 0.371
- 0.361
unequal: 0
verbose: 1
