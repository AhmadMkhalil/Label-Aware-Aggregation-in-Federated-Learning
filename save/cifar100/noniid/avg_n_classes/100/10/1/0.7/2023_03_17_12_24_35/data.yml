avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0434
- 0.0916
- 0.1137
- 0.1334
- 0.1498
- 0.1644
- 0.1721
- 0.1806
- 0.1929
- 0.1964
- 0.203
- 0.2107
- 0.2133
- 0.2174
- 0.225
- 0.2301
- 0.2348
- 0.2404
- 0.2383
- 0.2446
- 0.2464
- 0.2497
- 0.2551
- 0.2557
- 0.258
- 0.26
- 0.2606
- 0.2636
- 0.2694
- 0.271
- 0.2716
- 0.2742
- 0.2724
- 0.2752
- 0.2766
- 0.28
- 0.2846
- 0.2838
- 0.2871
- 0.2886
- 0.2893
- 0.2889
- 0.2895
- 0.2918
- 0.2937
- 0.2936
- 0.2975
- 0.2978
- 0.3001
- 0.2985
- 0.3005
- 0.302
- 0.2988
- 0.3015
- 0.3031
- 0.3036
- 0.3043
- 0.3042
- 0.3034
- 0.3097
- 0.3065
- 0.3071
- 0.3062
- 0.3116
- 0.3088
- 0.3094
- 0.3108
- 0.3093
- 0.3133
- 0.3129
- 0.314
- 0.318
- 0.317
- 0.3164
- 0.3139
- 0.3134
- 0.3187
- 0.317
- 0.3198
- 0.3195
- 0.3209
- 0.3184
- 0.3218
- 0.3199
- 0.3197
- 0.3169
- 0.3223
- 0.3225
- 0.3255
- 0.3275
- 0.3245
- 0.3229
- 0.324
- 0.3251
- 0.3289
- 0.3281
- 0.3247
- 0.3247
- 0.3261
- 0.3268
test_loss_list:
- 1.786611328125
- 1.6629561853408814
- 1.6115279579162598
- 1.5672646069526672
- 1.5554279208183288
- 1.51307071685791
- 1.4860100221633912
- 1.463957540988922
- 1.471390299797058
- 1.470475254058838
- 1.4385902094841003
- 1.409266586303711
- 1.391340742111206
- 1.4073787474632262
- 1.3790962886810303
- 1.3926833033561707
- 1.3630986642837524
- 1.3431912469863891
- 1.3306297540664673
- 1.3228280758857727
- 1.3415613126754762
- 1.3477999186515808
- 1.3194254302978516
- 1.3019096088409423
- 1.293037452697754
- 1.286469612121582
- 1.2799098324775695
- 1.3037214589118957
- 1.2759867906570435
- 1.298458902835846
- 1.3064607048034669
- 1.277250711917877
- 1.2614709281921386
- 1.2521125316619872
- 1.2470325207710267
- 1.2405999684333802
- 1.2354289484024048
- 1.2349299216270446
- 1.2327703619003296
- 1.256787016391754
- 1.231274151802063
- 1.2289473628997802
- 1.2531964206695556
- 1.227876353263855
- 1.2186337280273438
- 1.2171660447120667
- 1.2118460869789123
- 1.2084874963760377
- 1.2052507162094117
- 1.206209888458252
- 1.2032740592956543
- 1.2001059460639953
- 1.2305059838294983
- 1.2409347891807556
- 1.2491508555412292
- 1.2577580904960632
- 1.2259479331970216
- 1.2153378009796143
- 1.2031642556190492
- 1.1953975415229798
- 1.224323673248291
- 1.2035666799545288
- 1.1998106241226196
- 1.192751567363739
- 1.224496145248413
- 1.201250307559967
- 1.2227514672279358
- 1.2375116777420043
- 1.2102855014801026
- 1.1995497226715088
- 1.1919962239265443
- 1.1897069239616394
- 1.1881507515907288
- 1.187488956451416
- 1.2175313067436218
- 1.2301843881607055
- 1.2037519669532777
- 1.2241461014747619
- 1.198108332157135
- 1.1895775747299195
- 1.1836456537246705
- 1.2210473346710204
- 1.1949448275566101
- 1.1881953239440919
- 1.1850253748893738
- 1.217576048374176
- 1.2261766028404235
- 1.2000193405151367
- 1.1917328524589539
- 1.1886892676353455
- 1.1849090456962585
- 1.1861250853538514
- 1.1834093618392945
- 1.2136616468429566
- 1.1944787144660949
- 1.1877159118652343
- 1.2157922410964965
- 1.1972662496566773
- 1.1940345191955566
- 1.1865590190887452
train_accuracy:
- 0.053
- 0.106
- 0.0
- 0.133
- 0.145
- 0.134
- 0.135
- 0.169
- 0.19
- 0.19
- 0.248
- 0.202
- 0.215
- 0.216
- 0.221
- 0.285
- 0.243
- 0.234
- 0.234
- 0.252
- 0.243
- 0.244
- 0.271
- 0.0
- 0.267
- 0.28
- 0.0
- 0.271
- 0.277
- 0.279
- 0.287
- 0.289
- 0.274
- 0.301
- 0.291
- 0.255
- 0.362
- 0.0
- 0.299
- 0.284
- 0.297
- 0.291
- 0.315
- 0.303
- 0.309
- 0.312
- 0.326
- 0.321
- 0.338
- 0.338
- 0.341
- 0.0
- 0.318
- 0.294
- 0.295
- 0.295
- 0.298
- 0.298
- 0.325
- 0.33
- 0.357
- 0.0
- 0.336
- 0.307
- 0.304
- 0.397
- 0.338
- 0.312
- 0.299
- 0.373
- 0.325
- 0.338
- 0.371
- 0.331
- 0.373
- 0.326
- 0.38
- 0.355
- 0.387
- 0.389
- 0.405
- 0.358
- 0.327
- 0.399
- 0.353
- 0.325
- 0.397
- 0.314
- 0.0
- 0.398
- 0.373
- 0.0
- 0.406
- 0.358
- 0.404
- 0.402
- 0.309
- 0.389
- 0.358
- 0.0
train_loss:
- 3.895
- 3.484
- 3.25
- 3.108
- 3.242
- 2.889
- 2.775
- 2.697
- 2.847
- 2.749
- 2.474
- 2.445
- 2.362
- 2.484
- 2.239
- 2.367
- 2.159
- 2.086
- 2.048
- 2.01
- 2.118
- 2.037
- 1.867
- 1.812
- 1.761
- 1.704
- 1.732
- 1.801
- 1.653
- 1.707
- 1.654
- 1.504
- 1.496
- 1.437
- 1.422
- 1.379
- 1.383
- 1.354
- 1.294
- 1.376
- 1.267
- 1.22
- 1.274
- 1.153
- 1.122
- 1.114
- 1.087
- 1.014
- 1.059
- 1.015
- 0.988
- 0.98
- 1.014
- 0.977
- 0.94
- 0.913
- 0.892
- 0.851
- 0.82
- 0.812
- 0.868
- 0.778
- 0.755
- 0.745
- 0.776
- 0.729
- 0.741
- 0.701
- 0.656
- 0.674
- 0.623
- 0.61
- 0.631
- 0.603
- 0.603
- 0.585
- 0.555
- 0.561
- 0.562
- 0.528
- 0.51
- 0.536
- 0.491
- 0.489
- 0.459
- 0.493
- 0.47
- 0.45
- 0.436
- 0.419
- 0.429
- 0.393
- 0.401
- 0.407
- 0.403
- 0.393
- 0.391
- 0.384
- 0.378
- 0.357
unequal: 0
verbose: 1
