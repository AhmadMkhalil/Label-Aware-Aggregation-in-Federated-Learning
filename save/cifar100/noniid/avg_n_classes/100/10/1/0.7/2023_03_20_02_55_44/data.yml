avg_train_accuracy: 0.389
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0491
- 0.1003
- 0.1249
- 0.1374
- 0.1481
- 0.1587
- 0.1698
- 0.1755
- 0.1843
- 0.1911
- 0.1992
- 0.2048
- 0.2125
- 0.2181
- 0.2191
- 0.2267
- 0.2325
- 0.2361
- 0.2378
- 0.2374
- 0.2404
- 0.244
- 0.2475
- 0.2496
- 0.2534
- 0.2535
- 0.2593
- 0.257
- 0.2583
- 0.2615
- 0.2627
- 0.2625
- 0.2659
- 0.2697
- 0.2711
- 0.2712
- 0.2716
- 0.2771
- 0.2769
- 0.2765
- 0.2794
- 0.2795
- 0.2809
- 0.2835
- 0.2862
- 0.2849
- 0.2898
- 0.2916
- 0.2929
- 0.2923
- 0.2971
- 0.2943
- 0.2957
- 0.2985
- 0.2963
- 0.2983
- 0.3014
- 0.3009
- 0.3028
- 0.3025
- 0.304
- 0.3036
- 0.3066
- 0.3086
- 0.3058
- 0.3043
- 0.3106
- 0.3108
- 0.3119
- 0.3072
- 0.314
- 0.3098
- 0.3132
- 0.3106
- 0.3172
- 0.3162
- 0.309
- 0.3168
- 0.3137
- 0.3146
- 0.3168
- 0.3172
- 0.316
- 0.32
- 0.3199
- 0.3223
- 0.3204
- 0.3167
- 0.3215
- 0.3173
- 0.321
- 0.3193
- 0.3188
- 0.3197
- 0.323
- 0.3199
- 0.3243
- 0.3246
- 0.3261
- 0.3231
test_loss_list:
- 1.7797793626785279
- 1.6560604667663574
- 1.6011379837989808
- 1.5847866249084472
- 1.5439088201522828
- 1.51654367685318
- 1.5131775045394897
- 1.483353111743927
- 1.4607656121253967
- 1.4423779296875
- 1.4267144346237182
- 1.410601599216461
- 1.3987046051025391
- 1.4173082184791566
- 1.3900602769851684
- 1.3717456841468811
- 1.357379584312439
- 1.3485733556747437
- 1.3415366005897522
- 1.3328565335273743
- 1.3243030428886413
- 1.347058527469635
- 1.3220982074737548
- 1.309721758365631
- 1.3315131282806396
- 1.3382860326766968
- 1.3093064379692079
- 1.2950042986869812
- 1.2872521495819091
- 1.310818555355072
- 1.2881822037696837
- 1.277355010509491
- 1.2667809176445006
- 1.293738112449646
- 1.2660019612312317
- 1.260920774936676
- 1.286166355609894
- 1.2565369820594787
- 1.2820136642456055
- 1.2550872039794922
- 1.2465157651901244
- 1.2428193140029906
- 1.2686239171028137
- 1.278959460258484
- 1.2835695052146912
- 1.2537400603294373
- 1.237967619895935
- 1.228125867843628
- 1.228386278152466
- 1.2207920360565185
- 1.216196825504303
- 1.2476937007904052
- 1.2618965125083923
- 1.2328638696670533
- 1.2217846632003784
- 1.2155379223823548
- 1.2416375088691711
- 1.2204914951324464
- 1.2131498837471009
- 1.2113535046577453
- 1.2066212177276612
- 1.2046306180953978
- 1.2009896087646483
- 1.2006446671485902
- 1.2031312251091004
- 1.2049766898155212
- 1.1989773535728454
- 1.2006489109992982
- 1.1976301050186158
- 1.1987569332122803
- 1.1982363390922546
- 1.2287768030166626
- 1.2366181015968323
- 1.2114097857475281
- 1.2028182339668274
- 1.2005765771865844
- 1.2321144580841064
- 1.2041523933410645
- 1.2302486491203308
- 1.2094597554206847
- 1.2337852334976196
- 1.207277956008911
- 1.2055988931655883
- 1.1972325658798217
- 1.1956020617485046
- 1.1934835529327392
- 1.1989999938011169
- 1.2268497991561889
- 1.19980938911438
- 1.232554395198822
- 1.2055793142318725
- 1.2034190857410432
- 1.2014510488510133
- 1.1983037614822387
- 1.195520555973053
- 1.198922780752182
- 1.195406310558319
- 1.1957299029827118
- 1.1951473212242127
- 1.200660320520401
train_accuracy:
- 0.064
- 0.12
- 0.144
- 0.143
- 0.162
- 0.186
- 0.181
- 0.0
- 0.183
- 0.209
- 0.202
- 0.23
- 0.214
- 0.249
- 0.224
- 0.223
- 0.0
- 0.238
- 0.245
- 0.222
- 0.235
- 0.248
- 0.238
- 0.257
- 0.256
- 0.263
- 0.256
- 0.262
- 0.268
- 0.306
- 0.319
- 0.281
- 0.258
- 0.298
- 0.284
- 0.277
- 0.271
- 0.0
- 0.27
- 0.301
- 0.318
- 0.274
- 0.286
- 0.281
- 0.326
- 0.32
- 0.3
- 0.291
- 0.288
- 0.33
- 0.358
- 0.279
- 0.337
- 0.0
- 0.311
- 0.319
- 0.374
- 0.312
- 0.363
- 0.281
- 0.349
- 0.312
- 0.368
- 0.367
- 0.371
- 0.0
- 0.324
- 0.0
- 0.365
- 0.356
- 0.382
- 0.334
- 0.355
- 0.0
- 0.0
- 0.36
- 0.307
- 0.33
- 0.367
- 0.356
- 0.322
- 0.323
- 0.361
- 0.387
- 0.312
- 0.312
- 0.364
- 0.356
- 0.365
- 0.33
- 0.329
- 0.382
- 0.387
- 0.4
- 0.314
- 0.363
- 0.399
- 0.322
- 0.387
- 0.389
train_loss:
- 4.283
- 3.454
- 3.26
- 3.365
- 2.978
- 2.858
- 3.036
- 2.709
- 2.623
- 2.529
- 2.504
- 2.476
- 2.386
- 2.507
- 2.25
- 2.24
- 2.162
- 2.118
- 2.068
- 2.042
- 1.988
- 2.075
- 1.913
- 1.867
- 1.971
- 1.916
- 1.74
- 1.698
- 1.662
- 1.746
- 1.589
- 1.539
- 1.548
- 1.585
- 1.469
- 1.415
- 1.476
- 1.386
- 1.434
- 1.308
- 1.262
- 1.215
- 1.326
- 1.264
- 1.228
- 1.146
- 1.105
- 1.099
- 1.052
- 1.04
- 1.013
- 1.074
- 1.006
- 0.963
- 0.942
- 0.898
- 0.932
- 0.877
- 0.842
- 0.801
- 0.793
- 0.791
- 0.766
- 0.756
- 0.721
- 0.686
- 0.696
- 0.702
- 0.663
- 0.664
- 0.642
- 0.649
- 0.651
- 0.64
- 0.614
- 0.577
- 0.588
- 0.567
- 0.551
- 0.557
- 0.526
- 0.51
- 0.515
- 0.486
- 0.482
- 0.473
- 0.459
- 0.475
- 0.458
- 0.437
- 0.42
- 0.43
- 0.403
- 0.406
- 0.395
- 0.382
- 0.371
- 0.376
- 0.377
- 0.361
unequal: 0
verbose: 1
