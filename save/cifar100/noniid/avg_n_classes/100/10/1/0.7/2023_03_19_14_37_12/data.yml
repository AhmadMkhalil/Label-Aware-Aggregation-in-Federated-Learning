avg_train_accuracy: 0.32
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0424
- 0.1004
- 0.1219
- 0.1413
- 0.1532
- 0.1649
- 0.1741
- 0.1848
- 0.1863
- 0.1965
- 0.2027
- 0.207
- 0.2117
- 0.2156
- 0.2239
- 0.2254
- 0.2281
- 0.2328
- 0.237
- 0.2389
- 0.243
- 0.2493
- 0.2509
- 0.2535
- 0.2531
- 0.2562
- 0.2613
- 0.266
- 0.2639
- 0.268
- 0.2671
- 0.2703
- 0.2698
- 0.2754
- 0.2781
- 0.2779
- 0.2804
- 0.2839
- 0.2877
- 0.2871
- 0.2876
- 0.2885
- 0.2897
- 0.2904
- 0.2947
- 0.2958
- 0.2952
- 0.2974
- 0.2974
- 0.3004
- 0.3025
- 0.2962
- 0.3025
- 0.3068
- 0.305
- 0.308
- 0.3023
- 0.307
- 0.3103
- 0.3082
- 0.3136
- 0.311
- 0.3136
- 0.3142
- 0.3171
- 0.3168
- 0.3159
- 0.3169
- 0.3187
- 0.3143
- 0.3181
- 0.3233
- 0.3207
- 0.323
- 0.3248
- 0.3228
- 0.3227
- 0.3203
- 0.3237
- 0.3232
- 0.3255
- 0.3244
- 0.3268
- 0.3264
- 0.3229
- 0.3258
- 0.3288
- 0.3312
- 0.3242
- 0.3276
- 0.3257
- 0.3289
- 0.3279
- 0.3314
- 0.3318
- 0.3326
- 0.3316
- 0.3334
- 0.3342
- 0.3316
test_loss_list:
- 1.800490369796753
- 1.6966976881027223
- 1.6573732948303224
- 1.626965775489807
- 1.5739565443992616
- 1.531945288181305
- 1.5029284596443175
- 1.47642254114151
- 1.458193769454956
- 1.4670527005195617
- 1.4372341418266297
- 1.414848289489746
- 1.4005606627464295
- 1.4178208136558532
- 1.3887338042259216
- 1.373245873451233
- 1.3909559369087219
- 1.3930923533439636
- 1.362656602859497
- 1.3784765243530273
- 1.349394943714142
- 1.3274414682388305
- 1.317738289833069
- 1.3077717733383178
- 1.3304029631614684
- 1.3073393654823304
- 1.2920198917388916
- 1.2828083276748656
- 1.3060304021835327
- 1.2836457538604735
- 1.2707304859161377
- 1.2613041281700135
- 1.2539092087745667
- 1.2499900460243225
- 1.2445774269104004
- 1.2440131545066833
- 1.2354282212257386
- 1.2627669429779054
- 1.2393440794944763
- 1.2321301221847534
- 1.2243486142158508
- 1.2535348534584045
- 1.2289902663230896
- 1.221360330581665
- 1.2175820875167847
- 1.211598846912384
- 1.2402354383468628
- 1.2489653873443602
- 1.2275259137153625
- 1.2097437191009521
- 1.2036865544319153
- 1.2378827357292175
- 1.2097411561012268
- 1.2321448469161986
- 1.2454553174972534
- 1.211604070663452
- 1.2120218515396117
- 1.2254222893714906
- 1.2004831194877625
- 1.1961352801322938
- 1.1897576355934143
- 1.1872464990615845
- 1.1852389454841614
- 1.2111335754394532
- 1.1906982707977294
- 1.2187429761886597
- 1.2337216973304748
- 1.2006194472312928
- 1.189983868598938
- 1.2204120683670043
- 1.1966506886482238
- 1.1847940802574157
- 1.213600766658783
- 1.1893907380104065
- 1.1842549777030944
- 1.21077303647995
- 1.1909747767448424
- 1.214190182685852
- 1.1914947485923768
- 1.2120010089874267
- 1.188833224773407
- 1.1877230167388917
- 1.1783177161216736
- 1.1774405813217164
- 1.2048133516311645
- 1.1860690188407899
- 1.1787839818000794
- 1.178343186378479
- 1.207246651649475
- 1.1815895247459411
- 1.2120446681976318
- 1.190138306617737
- 1.1813040637969972
- 1.1757073712348938
- 1.1759211611747742
- 1.1744201707839965
- 1.1757513880729675
- 1.1786342978477478
- 1.1731934881210326
- 1.2064603137969971
train_accuracy:
- 0.056
- 0.068
- 0.117
- 0.139
- 0.0
- 0.157
- 0.165
- 0.197
- 0.18
- 0.196
- 0.222
- 0.197
- 0.202
- 0.222
- 0.191
- 0.241
- 0.22
- 0.228
- 0.255
- 0.213
- 0.296
- 0.252
- 0.304
- 0.257
- 0.316
- 0.314
- 0.241
- 0.261
- 0.265
- 0.273
- 0.342
- 0.0
- 0.289
- 0.0
- 0.283
- 0.0
- 0.316
- 0.359
- 0.323
- 0.293
- 0.33
- 0.32
- 0.342
- 0.284
- 0.352
- 0.328
- 0.318
- 0.289
- 0.284
- 0.318
- 0.294
- 0.289
- 0.31
- 0.322
- 0.293
- 0.356
- 0.367
- 0.342
- 0.0
- 0.301
- 0.313
- 0.294
- 0.363
- 0.311
- 0.307
- 0.304
- 0.31
- 0.364
- 0.333
- 0.361
- 0.325
- 0.0
- 0.307
- 0.33
- 0.315
- 0.312
- 0.314
- 0.327
- 0.0
- 0.318
- 0.316
- 0.308
- 0.0
- 0.306
- 0.319
- 0.321
- 0.384
- 0.321
- 0.311
- 0.378
- 0.33
- 0.0
- 0.343
- 0.0
- 0.0
- 0.323
- 0.37
- 0.312
- 0.335
- 0.32
train_loss:
- 4.246
- 3.78
- 3.523
- 3.331
- 3.043
- 2.915
- 2.827
- 2.731
- 2.676
- 2.777
- 2.525
- 2.433
- 2.359
- 2.485
- 2.301
- 2.183
- 2.298
- 2.31
- 2.137
- 2.193
- 1.97
- 1.92
- 1.872
- 1.845
- 1.925
- 1.776
- 1.737
- 1.705
- 1.813
- 1.6
- 1.621
- 1.592
- 1.544
- 1.493
- 1.45
- 1.407
- 1.41
- 1.438
- 1.315
- 1.285
- 1.241
- 1.296
- 1.258
- 1.192
- 1.141
- 1.134
- 1.171
- 1.147
- 1.064
- 1.043
- 1.028
- 1.073
- 0.983
- 1.007
- 0.985
- 0.949
- 0.889
- 0.941
- 0.855
- 0.846
- 0.814
- 0.804
- 0.764
- 0.807
- 0.734
- 0.733
- 0.74
- 0.704
- 0.676
- 0.699
- 0.661
- 0.632
- 0.65
- 0.632
- 0.591
- 0.596
- 0.578
- 0.579
- 0.535
- 0.555
- 0.535
- 0.537
- 0.516
- 0.512
- 0.501
- 0.476
- 0.483
- 0.438
- 0.478
- 0.439
- 0.421
- 0.41
- 0.436
- 0.412
- 0.391
- 0.378
- 0.375
- 0.386
- 0.369
- 0.352
unequal: 0
verbose: 1
