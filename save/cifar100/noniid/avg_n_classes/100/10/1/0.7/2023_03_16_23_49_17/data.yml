avg_train_accuracy: 0.336
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0429
- 0.1017
- 0.1264
- 0.1397
- 0.1512
- 0.1646
- 0.1737
- 0.1789
- 0.1849
- 0.1933
- 0.2014
- 0.202
- 0.2111
- 0.2183
- 0.2215
- 0.2221
- 0.2252
- 0.233
- 0.2381
- 0.2346
- 0.2455
- 0.2475
- 0.2524
- 0.2494
- 0.2556
- 0.2593
- 0.2603
- 0.263
- 0.2669
- 0.2679
- 0.2715
- 0.2743
- 0.2787
- 0.2778
- 0.2816
- 0.2823
- 0.2812
- 0.2844
- 0.2882
- 0.2875
- 0.2894
- 0.2888
- 0.2928
- 0.2917
- 0.2931
- 0.2968
- 0.2979
- 0.2972
- 0.2998
- 0.3047
- 0.3005
- 0.3045
- 0.3014
- 0.307
- 0.3091
- 0.3089
- 0.3074
- 0.3119
- 0.3092
- 0.3079
- 0.3133
- 0.3125
- 0.3146
- 0.3143
- 0.3144
- 0.3156
- 0.3128
- 0.3133
- 0.3197
- 0.3177
- 0.3178
- 0.3184
- 0.3205
- 0.3182
- 0.3183
- 0.3209
- 0.3249
- 0.326
- 0.3221
- 0.3233
- 0.3242
- 0.3267
- 0.3246
- 0.3305
- 0.3296
- 0.3289
- 0.3245
- 0.3302
- 0.3314
- 0.3328
- 0.3347
- 0.3314
- 0.3289
- 0.3283
- 0.3324
- 0.3323
- 0.3338
- 0.329
- 0.3317
- 0.3318
test_loss_list:
- 1.7862966299057006
- 1.6766125297546386
- 1.639085319042206
- 1.5849108695983887
- 1.5416850185394286
- 1.508588089942932
- 1.486946861743927
- 1.4647199368476869
- 1.4478237128257752
- 1.4309267234802245
- 1.441380388736725
- 1.4455199694633485
- 1.410140438079834
- 1.3887847924232484
- 1.3741532778739929
- 1.3612994050979614
- 1.3501684617996217
- 1.3655387711524964
- 1.3751689457893372
- 1.345276529788971
- 1.3540983486175537
- 1.3597811841964722
- 1.3616188430786134
- 1.3289224100112915
- 1.3387750697135925
- 1.306398856639862
- 1.2902779841423035
- 1.2798576283454894
- 1.2980919408798217
- 1.3058691310882569
- 1.2775373101234435
- 1.262939646244049
- 1.2833917212486268
- 1.258280510902405
- 1.2443840646743773
- 1.2694264316558839
- 1.2789248991012574
- 1.2490605568885804
- 1.2355407094955444
- 1.2582841086387635
- 1.2319188070297242
- 1.223410234451294
- 1.2138677215576172
- 1.2108086729049683
- 1.2084879636764527
- 1.2034055161476136
- 1.2308072137832642
- 1.2125842547416688
- 1.2063010692596436
- 1.2003298854827882
- 1.1941900753974914
- 1.2227552700042725
- 1.23536395072937
- 1.2078047370910645
- 1.1942739582061768
- 1.191051869392395
- 1.2197119760513306
- 1.1911518692970275
- 1.2203923749923706
- 1.1953624725341796
- 1.1836686158180236
- 1.1851819777488708
- 1.1841406321525574
- 1.2085234260559081
- 1.2183376407623292
- 1.1922598338127137
- 1.2203064560890198
- 1.2268118727207185
- 1.195683434009552
- 1.2165467512607575
- 1.2258212053775788
- 1.1951907098293304
- 1.2169623935222627
- 1.1926225054264068
- 1.1829897737503052
- 1.1765331709384919
- 1.1714413475990295
- 1.1696343159675597
- 1.1966056489944459
- 1.1811800146102904
- 1.1726865661144257
- 1.1690235817432404
- 1.1723393893241882
- 1.1692774832248687
- 1.1702050125598908
- 1.167626954317093
- 1.1704213500022889
- 1.1681547999382018
- 1.1684833586215972
- 1.1663840842247009
- 1.1671982312202454
- 1.1680176603794097
- 1.16710196018219
- 1.1953377640247345
- 1.1747720336914063
- 1.1725192177295685
- 1.1688590598106385
- 1.2012066268920898
- 1.179259738922119
- 1.175661803483963
train_accuracy:
- 0.034
- 0.118
- 0.171
- 0.19
- 0.191
- 0.176
- 0.199
- 0.229
- 0.178
- 0.194
- 0.196
- 0.197
- 0.257
- 0.245
- 0.181
- 0.264
- 0.214
- 0.293
- 0.305
- 0.308
- 0.275
- 0.276
- 0.301
- 0.257
- 0.3
- 0.289
- 0.0
- 0.0
- 0.323
- 0.266
- 0.265
- 0.346
- 0.283
- 0.0
- 0.311
- 0.356
- 0.274
- 0.291
- 0.284
- 0.297
- 0.0
- 0.278
- 0.285
- 0.293
- 0.338
- 0.288
- 0.297
- 0.355
- 0.369
- 0.347
- 0.329
- 0.348
- 0.301
- 0.311
- 0.346
- 0.305
- 0.34
- 0.287
- 0.344
- 0.0
- 0.0
- 0.316
- 0.387
- 0.389
- 0.336
- 0.316
- 0.314
- 0.374
- 0.383
- 0.386
- 0.307
- 0.352
- 0.362
- 0.328
- 0.0
- 0.305
- 0.334
- 0.362
- 0.318
- 0.311
- 0.0
- 0.316
- 0.399
- 0.36
- 0.349
- 0.352
- 0.0
- 0.321
- 0.345
- 0.337
- 0.326
- 0.358
- 0.352
- 0.34
- 0.362
- 0.334
- 0.352
- 0.33
- 0.38
- 0.336
train_loss:
- 3.894
- 3.768
- 3.518
- 3.126
- 3.007
- 2.886
- 2.784
- 2.68
- 2.625
- 2.577
- 2.749
- 2.611
- 2.389
- 2.312
- 2.227
- 2.218
- 2.172
- 2.311
- 2.235
- 2.02
- 2.12
- 2.06
- 1.997
- 1.819
- 1.931
- 1.749
- 1.71
- 1.657
- 1.806
- 1.714
- 1.571
- 1.522
- 1.582
- 1.418
- 1.478
- 1.485
- 1.46
- 1.315
- 1.282
- 1.37
- 1.278
- 1.165
- 1.189
- 1.149
- 1.08
- 1.078
- 1.156
- 1.086
- 0.99
- 0.968
- 1.014
- 1.012
- 0.968
- 0.934
- 0.916
- 0.868
- 0.912
- 0.859
- 0.864
- 0.781
- 0.804
- 0.772
- 0.73
- 0.774
- 0.765
- 0.719
- 0.705
- 0.652
- 0.696
- 0.674
- 0.658
- 0.645
- 0.592
- 0.633
- 0.584
- 0.556
- 0.567
- 0.54
- 0.55
- 0.505
- 0.507
- 0.494
- 0.491
- 0.458
- 0.468
- 0.468
- 0.448
- 0.434
- 0.415
- 0.445
- 0.418
- 0.408
- 0.403
- 0.416
- 0.365
- 0.388
- 0.389
- 0.374
- 0.365
- 0.366
unequal: 0
verbose: 1
