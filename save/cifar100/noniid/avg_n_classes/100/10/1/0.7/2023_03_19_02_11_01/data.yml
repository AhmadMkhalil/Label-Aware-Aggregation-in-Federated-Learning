avg_train_accuracy: 0.332
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0423
- 0.0934
- 0.1201
- 0.1365
- 0.153
- 0.1584
- 0.1698
- 0.1784
- 0.1842
- 0.1901
- 0.2008
- 0.2026
- 0.2089
- 0.217
- 0.2203
- 0.224
- 0.2256
- 0.2354
- 0.2357
- 0.2387
- 0.2431
- 0.2469
- 0.2489
- 0.2513
- 0.2542
- 0.2587
- 0.2593
- 0.2645
- 0.2684
- 0.2703
- 0.2673
- 0.2701
- 0.2743
- 0.2768
- 0.2766
- 0.2813
- 0.2843
- 0.2865
- 0.2866
- 0.2855
- 0.2873
- 0.2916
- 0.2911
- 0.2935
- 0.2961
- 0.2931
- 0.2937
- 0.2962
- 0.2992
- 0.3028
- 0.2997
- 0.3038
- 0.3006
- 0.3062
- 0.3037
- 0.307
- 0.3048
- 0.3087
- 0.3085
- 0.3102
- 0.3092
- 0.3109
- 0.3083
- 0.3114
- 0.3114
- 0.31
- 0.3111
- 0.3121
- 0.3095
- 0.3135
- 0.3152
- 0.3126
- 0.3111
- 0.3128
- 0.3197
- 0.3202
- 0.3135
- 0.3174
- 0.3178
- 0.3186
- 0.3157
- 0.3175
- 0.3183
- 0.317
- 0.3176
- 0.3212
- 0.3189
- 0.3225
- 0.3207
- 0.3211
- 0.325
- 0.3251
- 0.3229
- 0.3219
- 0.3278
- 0.3244
- 0.3223
- 0.324
- 0.3246
- 0.3294
test_loss_list:
- 1.7967254400253296
- 1.6644846773147584
- 1.629379391670227
- 1.5739667701721192
- 1.5328872394561768
- 1.5088387894630433
- 1.5076757311820983
- 1.5030032563209534
- 1.4660673308372498
- 1.4432450819015503
- 1.451039822101593
- 1.4238387513160706
- 1.4033508968353272
- 1.383887641429901
- 1.3724738693237304
- 1.357926049232483
- 1.3495033264160157
- 1.3421792888641357
- 1.3283121466636658
- 1.3214635419845582
- 1.3136057901382445
- 1.306046576499939
- 1.3038191103935242
- 1.3247377705574035
- 1.3016176843643188
- 1.3204754066467286
- 1.325645582675934
- 1.295132486820221
- 1.3079842257499694
- 1.2833547163009644
- 1.2725062203407287
- 1.2933442187309265
- 1.2701526737213136
- 1.2850984597206117
- 1.2621625351905823
- 1.2793416738510133
- 1.28756911277771
- 1.2937409472465515
- 1.2994917774200438
- 1.2660268092155456
- 1.2463343286514281
- 1.2667247104644774
- 1.242440812587738
- 1.223453860282898
- 1.2197687792778016
- 1.2135026454925537
- 1.2097623014450074
- 1.2128079557418823
- 1.204874231815338
- 1.2050538849830628
- 1.2048071265220641
- 1.1973656463623046
- 1.2231214666366577
- 1.2055707240104676
- 1.199964394569397
- 1.198094129562378
- 1.2227028155326842
- 1.202515528202057
- 1.19211847782135
- 1.1899621438980104
- 1.1853409385681153
- 1.1847961258888244
- 1.2111777138710023
- 1.1920563745498658
- 1.2142351531982423
- 1.2337579154968261
- 1.1996749711036683
- 1.1916771984100343
- 1.1905873370170594
- 1.1868278551101685
- 1.2132578372955323
- 1.2222149467468262
- 1.197637505531311
- 1.1883074760437011
- 1.1838233494758605
- 1.1813864374160767
- 1.2067949151992798
- 1.1858782196044921
- 1.1841182374954224
- 1.1775153255462647
- 1.2041033959388734
- 1.186771593093872
- 1.214198818206787
- 1.219324598312378
- 1.2274065041542053
- 1.235718297958374
- 1.2389595293998719
- 1.2055727005004884
- 1.1930822348594665
- 1.1840550541877746
- 1.1766821193695067
- 1.1769069290161134
- 1.178035604953766
- 1.1758751797676086
- 1.1726412463188172
- 1.1738879513740539
- 1.2040282845497132
- 1.1815831923484803
- 1.177610695362091
- 1.1753159332275391
train_accuracy:
- 0.0
- 0.09
- 0.158
- 0.147
- 0.158
- 0.0
- 0.17
- 0.17
- 0.179
- 0.217
- 0.168
- 0.167
- 0.197
- 0.0
- 0.248
- 0.259
- 0.0
- 0.254
- 0.243
- 0.0
- 0.275
- 0.237
- 0.0
- 0.243
- 0.275
- 0.285
- 0.263
- 0.299
- 0.287
- 0.274
- 0.263
- 0.261
- 0.315
- 0.324
- 0.32
- 0.317
- 0.295
- 0.323
- 0.343
- 0.281
- 0.0
- 0.313
- 0.354
- 0.342
- 0.251
- 0.311
- 0.304
- 0.305
- 0.293
- 0.359
- 0.359
- 0.323
- 0.312
- 0.301
- 0.312
- 0.298
- 0.364
- 0.303
- 0.37
- 0.346
- 0.33
- 0.315
- 0.357
- 0.309
- 0.317
- 0.367
- 0.305
- 0.386
- 0.378
- 0.363
- 0.378
- 0.322
- 0.34
- 0.335
- 0.36
- 0.304
- 0.374
- 0.324
- 0.312
- 0.384
- 0.372
- 0.0
- 0.377
- 0.345
- 0.326
- 0.388
- 0.357
- 0.383
- 0.349
- 0.369
- 0.0
- 0.362
- 0.372
- 0.0
- 0.392
- 0.332
- 0.357
- 0.382
- 0.332
- 0.332
train_loss:
- 3.907
- 3.515
- 3.553
- 3.138
- 3.008
- 2.903
- 3.039
- 2.936
- 2.651
- 2.565
- 2.705
- 2.449
- 2.355
- 2.347
- 2.254
- 2.216
- 2.159
- 2.097
- 2.09
- 2.018
- 1.987
- 1.912
- 1.888
- 1.981
- 1.786
- 1.904
- 1.865
- 1.693
- 1.78
- 1.61
- 1.566
- 1.62
- 1.498
- 1.598
- 1.453
- 1.533
- 1.471
- 1.435
- 1.386
- 1.292
- 1.22
- 1.279
- 1.202
- 1.202
- 1.163
- 1.151
- 1.073
- 1.071
- 1.044
- 1.025
- 1.029
- 0.98
- 1.033
- 0.943
- 0.929
- 0.862
- 0.927
- 0.884
- 0.832
- 0.815
- 0.805
- 0.815
- 0.789
- 0.774
- 0.77
- 0.766
- 0.707
- 0.692
- 0.66
- 0.627
- 0.657
- 0.643
- 0.624
- 0.632
- 0.592
- 0.575
- 0.597
- 0.553
- 0.54
- 0.567
- 0.538
- 0.513
- 0.512
- 0.502
- 0.485
- 0.461
- 0.446
- 0.444
- 0.461
- 0.442
- 0.43
- 0.419
- 0.415
- 0.398
- 0.398
- 0.384
- 0.39
- 0.38
- 0.362
- 0.356
unequal: 0
verbose: 1
