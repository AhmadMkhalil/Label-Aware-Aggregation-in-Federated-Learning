avg_train_accuracy: 0.33
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.049
- 0.0994
- 0.1262
- 0.141
- 0.1477
- 0.1588
- 0.1664
- 0.1835
- 0.1886
- 0.1965
- 0.2016
- 0.2049
- 0.2113
- 0.2199
- 0.2254
- 0.2273
- 0.2334
- 0.2378
- 0.2445
- 0.2447
- 0.2463
- 0.2486
- 0.2531
- 0.2549
- 0.2621
- 0.261
- 0.2612
- 0.2665
- 0.2705
- 0.2725
- 0.2702
- 0.2761
- 0.2768
- 0.2779
- 0.2826
- 0.2864
- 0.2862
- 0.2877
- 0.285
- 0.2911
- 0.2903
- 0.2942
- 0.2944
- 0.2983
- 0.2971
- 0.2983
- 0.2984
- 0.2995
- 0.3006
- 0.3045
- 0.3039
- 0.3074
- 0.3071
- 0.3061
- 0.3084
- 0.3089
- 0.3142
- 0.3096
- 0.3118
- 0.3126
- 0.3141
- 0.3135
- 0.3129
- 0.3173
- 0.3137
- 0.318
- 0.3168
- 0.3182
- 0.3167
- 0.3201
- 0.3195
- 0.3144
- 0.3193
- 0.3172
- 0.3163
- 0.3206
- 0.3186
- 0.3228
- 0.3246
- 0.3251
- 0.3238
- 0.321
- 0.3247
- 0.3234
- 0.3285
- 0.3273
- 0.3222
- 0.3243
- 0.3286
- 0.326
- 0.3259
- 0.3249
- 0.3264
- 0.3288
- 0.3304
- 0.3266
- 0.3282
- 0.3291
- 0.3293
- 0.3312
test_loss_list:
- 1.8026173973083497
- 1.6986754941940307
- 1.632618441581726
- 1.5857478404045104
- 1.5507512211799621
- 1.5459648418426513
- 1.538791823387146
- 1.5280484890937804
- 1.5193986916542053
- 1.4790081453323365
- 1.4777878069877624
- 1.4420769834518432
- 1.448218479156494
- 1.4451353693008422
- 1.4078806233406067
- 1.4191344809532165
- 1.3856867909431458
- 1.3977637791633606
- 1.3935361003875733
- 1.3980946159362793
- 1.3639449429512025
- 1.3380095767974853
- 1.3200865125656127
- 1.3408418107032776
- 1.3429900264739991
- 1.3163737678527831
- 1.2957760524749755
- 1.283983793258667
- 1.2751757431030273
- 1.2993777060508729
- 1.3086865091323852
- 1.3160656952857972
- 1.2804762840270996
- 1.264201476573944
- 1.2843055725097656
- 1.2572565221786498
- 1.2442070579528808
- 1.2360578680038452
- 1.2641898274421692
- 1.2779658269882201
- 1.2854097700119018
- 1.2887504005432129
- 1.292575602531433
- 1.254223382472992
- 1.2352971148490905
- 1.2231081867218017
- 1.2522635269165039
- 1.2609681868553162
- 1.2320664858818053
- 1.2513679885864257
- 1.2282891702651977
- 1.248038911819458
- 1.2207773518562317
- 1.248584530353546
- 1.2212363171577454
- 1.2077184867858888
- 1.2015201044082642
- 1.2322600984573364
- 1.2427334928512572
- 1.2129075312614441
- 1.2043983459472656
- 1.230257499217987
- 1.203291153907776
- 1.2302524161338806
- 1.242530312538147
- 1.2444033908843994
- 1.2550791549682616
- 1.2241942834854127
- 1.2470298218727112
- 1.2097041416168213
- 1.2332929372787476
- 1.2136277270317077
- 1.2288814568519593
- 1.240195631980896
- 1.2101667046546936
- 1.2297260451316834
- 1.2052788949012756
- 1.228209924697876
- 1.1999486434459685
- 1.2244013714790345
- 1.232256259918213
- 1.2014340710639955
- 1.2278031611442566
- 1.2017614102363587
- 1.2248548579216003
- 1.2379158711433411
- 1.2096043300628663
- 1.1928081941604614
- 1.220467563867569
- 1.2272585535049438
- 1.205375382900238
- 1.1900417971611024
- 1.2175012278556823
- 1.225515124797821
- 1.2298414254188537
- 1.208303439617157
- 1.1940317463874817
- 1.2212328362464904
- 1.2310748672485352
- 1.2055466651916504
train_accuracy:
- 0.058
- 0.1
- 0.0
- 0.0
- 0.0
- 0.15
- 0.196
- 0.189
- 0.181
- 0.163
- 0.162
- 0.0
- 0.2
- 0.18
- 0.191
- 0.225
- 0.269
- 0.267
- 0.251
- 0.242
- 0.0
- 0.301
- 0.247
- 0.211
- 0.301
- 0.222
- 0.231
- 0.279
- 0.269
- 0.267
- 0.236
- 0.223
- 0.0
- 0.259
- 0.285
- 0.248
- 0.241
- 0.255
- 0.29
- 0.256
- 0.262
- 0.362
- 0.269
- 0.275
- 0.0
- 0.29
- 0.311
- 0.283
- 0.306
- 0.291
- 0.273
- 0.306
- 0.317
- 0.298
- 0.265
- 0.0
- 0.0
- 0.28
- 0.299
- 0.285
- 0.261
- 0.26
- 0.288
- 0.292
- 0.298
- 0.295
- 0.283
- 0.294
- 0.396
- 0.284
- 0.294
- 0.319
- 0.292
- 0.295
- 0.0
- 0.322
- 0.32
- 0.296
- 0.297
- 0.304
- 0.311
- 0.293
- 0.306
- 0.0
- 0.295
- 0.297
- 0.0
- 0.324
- 0.286
- 0.291
- 0.287
- 0.335
- 0.337
- 0.41
- 0.295
- 0.401
- 0.0
- 0.297
- 0.299
- 0.33
train_loss:
- 4.28
- 3.787
- 3.203
- 3.046
- 2.933
- 3.171
- 3.024
- 2.979
- 2.9
- 2.549
- 2.702
- 2.424
- 2.545
- 2.526
- 2.245
- 2.325
- 2.168
- 2.22
- 2.251
- 2.171
- 1.943
- 1.929
- 1.872
- 2.026
- 1.941
- 1.744
- 1.677
- 1.694
- 1.571
- 1.795
- 1.673
- 1.667
- 1.497
- 1.455
- 1.545
- 1.438
- 1.35
- 1.318
- 1.413
- 1.351
- 1.363
- 1.354
- 1.292
- 1.209
- 1.141
- 1.126
- 1.158
- 1.114
- 1.063
- 1.076
- 1.015
- 0.952
- 1.021
- 0.955
- 0.917
- 0.913
- 0.878
- 0.971
- 0.893
- 0.811
- 0.847
- 0.824
- 0.84
- 0.751
- 0.692
- 0.835
- 0.722
- 0.703
- 0.633
- 0.689
- 0.694
- 0.616
- 0.691
- 0.575
- 0.662
- 0.621
- 0.598
- 0.57
- 0.547
- 0.558
- 0.534
- 0.564
- 0.525
- 0.58
- 0.494
- 0.477
- 0.514
- 0.495
- 0.471
- 0.465
- 0.471
- 0.47
- 0.418
- 0.417
- 0.398
- 0.438
- 0.393
- 0.379
- 0.337
- 0.378
unequal: 0
verbose: 1
