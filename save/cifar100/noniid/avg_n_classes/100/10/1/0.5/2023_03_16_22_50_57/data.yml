avg_train_accuracy: 0.371
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0432
- 0.0961
- 0.1088
- 0.1377
- 0.1474
- 0.1547
- 0.1617
- 0.1738
- 0.1786
- 0.1907
- 0.1962
- 0.2006
- 0.2007
- 0.2171
- 0.2215
- 0.2258
- 0.2267
- 0.2291
- 0.2343
- 0.2402
- 0.2441
- 0.2441
- 0.2464
- 0.2499
- 0.25
- 0.256
- 0.2613
- 0.2596
- 0.2641
- 0.2597
- 0.2655
- 0.2685
- 0.2725
- 0.2739
- 0.2746
- 0.2772
- 0.2814
- 0.2811
- 0.2828
- 0.2849
- 0.2848
- 0.2864
- 0.2886
- 0.2887
- 0.2916
- 0.2878
- 0.2918
- 0.2919
- 0.2949
- 0.2953
- 0.2938
- 0.2972
- 0.2952
- 0.2975
- 0.3024
- 0.3004
- 0.302
- 0.3041
- 0.3024
- 0.3017
- 0.3048
- 0.304
- 0.3034
- 0.3033
- 0.306
- 0.3069
- 0.3083
- 0.3097
- 0.3077
- 0.3094
- 0.3087
- 0.3078
- 0.3094
- 0.3099
- 0.3084
- 0.3113
- 0.3137
- 0.3148
- 0.3145
- 0.3145
- 0.3143
- 0.3158
- 0.3136
- 0.3156
- 0.3149
- 0.3186
- 0.3185
- 0.3171
- 0.315
- 0.3172
- 0.317
- 0.3181
- 0.3233
- 0.3223
- 0.3231
- 0.3207
- 0.3198
- 0.3194
- 0.3199
- 0.319
test_loss_list:
- 1.8017614316940307
- 1.6743634843826294
- 1.6387352967262268
- 1.5824449229240418
- 1.5714484143257141
- 1.5251190590858459
- 1.5249736142158508
- 1.521705994606018
- 1.4843511486053467
- 1.4836797952651977
- 1.4492617344856262
- 1.4251561331748963
- 1.4356309127807618
- 1.4361638832092285
- 1.402415988445282
- 1.3801889133453369
- 1.3621471905708313
- 1.3572180223464967
- 1.3689698839187623
- 1.342368848323822
- 1.3566441345214844
- 1.334707317352295
- 1.3205582571029664
- 1.341644856929779
- 1.3179316186904908
- 1.3009863901138305
- 1.316208128929138
- 1.3274716091156007
- 1.2964343214035035
- 1.3149339032173157
- 1.2893358564376831
- 1.3078888821601868
- 1.3129519414901734
- 1.3185830521583557
- 1.3200541925430298
- 1.2857583165168762
- 1.2660630416870118
- 1.2808679628372193
- 1.2906976771354675
- 1.295375816822052
- 1.298966841697693
- 1.2687419271469116
- 1.2477911257743834
- 1.2355218601226807
- 1.2555825734138488
- 1.2381149196624757
- 1.2561520719528199
- 1.2347898888587951
- 1.2537420272827149
- 1.2284332537651061
- 1.2191898012161255
- 1.24496577501297
- 1.2536903810501099
- 1.2282507348060607
- 1.2114748358726501
- 1.2078444314002992
- 1.2063993000984192
- 1.2305983805656433
- 1.2078206872940063
- 1.201990990638733
- 1.1953968477249146
- 1.2242256855964662
- 1.236756112575531
- 1.2169092249870301
- 1.2055348014831544
- 1.1977272677421569
- 1.202960901260376
- 1.1977716732025145
- 1.2200025725364685
- 1.2011874318122864
- 1.2336822152137756
- 1.207957456111908
- 1.2342333722114562
- 1.2417374134063721
- 1.2478530812263489
- 1.2485734581947328
- 1.2190625882148742
- 1.2086100959777832
- 1.2296546196937561
- 1.243584427833557
- 1.251228506565094
- 1.2580869317054748
- 1.2613966178894043
- 1.218256938457489
- 1.2473032402992248
- 1.2502322793006897
- 1.2578345704078675
- 1.224190239906311
- 1.2109259462356567
- 1.2320343470573425
- 1.2079589772224426
- 1.2275805234909059
- 1.207826805114746
- 1.1927052164077758
- 1.2220257639884948
- 1.232161889076233
- 1.2392610907554626
- 1.2118765115737915
- 1.2419949507713317
- 1.2439603924751281
train_accuracy:
- 0.055
- 0.089
- 0.105
- 0.0
- 0.165
- 0.197
- 0.15
- 0.169
- 0.221
- 0.238
- 0.0
- 0.159
- 0.23
- 0.255
- 0.211
- 0.259
- 0.0
- 0.213
- 0.174
- 0.242
- 0.279
- 0.26
- 0.256
- 0.241
- 0.192
- 0.281
- 0.278
- 0.26
- 0.292
- 0.285
- 0.297
- 0.245
- 0.285
- 0.292
- 0.209
- 0.293
- 0.285
- 0.271
- 0.324
- 0.308
- 0.288
- 0.275
- 0.0
- 0.298
- 0.313
- 0.248
- 0.297
- 0.0
- 0.307
- 0.309
- 0.252
- 0.347
- 0.326
- 0.31
- 0.259
- 0.302
- 0.275
- 0.304
- 0.0
- 0.301
- 0.326
- 0.314
- 0.316
- 0.301
- 0.313
- 0.0
- 0.326
- 0.315
- 0.319
- 0.295
- 0.311
- 0.354
- 0.314
- 0.342
- 0.364
- 0.351
- 0.364
- 0.358
- 0.261
- 0.314
- 0.337
- 0.322
- 0.326
- 0.309
- 0.334
- 0.328
- 0.308
- 0.307
- 0.349
- 0.262
- 0.343
- 0.334
- 0.34
- 0.336
- 0.337
- 0.365
- 0.308
- 0.345
- 0.328
- 0.371
train_loss:
- 4.319
- 3.416
- 3.607
- 3.088
- 3.272
- 2.905
- 3.099
- 2.987
- 2.658
- 2.839
- 2.491
- 2.452
- 2.614
- 2.581
- 2.301
- 2.224
- 2.189
- 2.079
- 2.331
- 2.064
- 2.187
- 1.912
- 1.879
- 1.957
- 1.8
- 1.808
- 1.914
- 1.867
- 1.736
- 1.78
- 1.618
- 1.709
- 1.678
- 1.631
- 1.57
- 1.484
- 1.385
- 1.488
- 1.476
- 1.407
- 1.36
- 1.262
- 1.215
- 1.235
- 1.243
- 1.114
- 1.147
- 1.068
- 1.117
- 1.056
- 1.105
- 1.04
- 1.042
- 1.005
- 0.922
- 0.912
- 0.861
- 0.916
- 0.846
- 0.792
- 0.917
- 0.856
- 0.779
- 0.759
- 0.736
- 0.679
- 0.711
- 0.639
- 0.795
- 0.635
- 0.628
- 0.653
- 0.655
- 0.572
- 0.664
- 0.554
- 0.642
- 0.582
- 0.629
- 0.542
- 0.523
- 0.531
- 0.552
- 0.55
- 0.505
- 0.481
- 0.506
- 0.504
- 0.464
- 0.508
- 0.49
- 0.449
- 0.441
- 0.441
- 0.41
- 0.432
- 0.402
- 0.449
- 0.373
- 0.368
unequal: 0
verbose: 1
