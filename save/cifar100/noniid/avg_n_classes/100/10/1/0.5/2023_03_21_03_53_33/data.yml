avg_train_accuracy: 0.403
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0573
- 0.1036
- 0.1198
- 0.1374
- 0.1506
- 0.1572
- 0.1646
- 0.1744
- 0.1853
- 0.1946
- 0.1979
- 0.2057
- 0.21
- 0.2157
- 0.2209
- 0.2273
- 0.2324
- 0.2338
- 0.2398
- 0.2406
- 0.2407
- 0.2494
- 0.2507
- 0.2466
- 0.251
- 0.2535
- 0.2606
- 0.2571
- 0.2601
- 0.2625
- 0.2717
- 0.2713
- 0.2729
- 0.2799
- 0.2784
- 0.2808
- 0.2764
- 0.2854
- 0.2808
- 0.286
- 0.29
- 0.29
- 0.2902
- 0.2949
- 0.2926
- 0.2975
- 0.3011
- 0.3016
- 0.299
- 0.3002
- 0.2981
- 0.299
- 0.3025
- 0.3018
- 0.3058
- 0.3057
- 0.3081
- 0.3126
- 0.3078
- 0.3098
- 0.3098
- 0.3095
- 0.3115
- 0.309
- 0.3115
- 0.3082
- 0.3133
- 0.3128
- 0.3125
- 0.3165
- 0.3142
- 0.3141
- 0.3158
- 0.3196
- 0.3184
- 0.3209
- 0.3189
- 0.3197
- 0.3213
- 0.3196
- 0.3209
- 0.3207
- 0.3185
- 0.3232
- 0.3208
- 0.3217
- 0.3232
- 0.3212
- 0.3223
- 0.3258
- 0.3251
- 0.3225
- 0.3207
- 0.3251
- 0.3245
- 0.3245
- 0.3267
- 0.328
- 0.3255
- 0.3263
test_loss_list:
- 1.794189133644104
- 1.6667681980133056
- 1.6355660772323608
- 1.61109365940094
- 1.593413872718811
- 1.5450224590301513
- 1.5425010180473329
- 1.5381577491760254
- 1.4904539680480957
- 1.458528184890747
- 1.4708805561065674
- 1.4339953541755677
- 1.4424014377593994
- 1.4124172854423522
- 1.4246762132644653
- 1.4261090755462646
- 1.3865703344345093
- 1.3983343315124512
- 1.3622321248054505
- 1.3475327277183533
- 1.3657534527778625
- 1.3694979381561279
- 1.3746388912200929
- 1.341171681880951
- 1.3189665412902831
- 1.3022845125198363
- 1.2918494653701782
- 1.3183538961410521
- 1.3271682476997375
- 1.2970687770843505
- 1.3100943398475646
- 1.3170900392532348
- 1.2813310837745666
- 1.3026867246627807
- 1.3087508392333984
- 1.3124722504615784
- 1.3213966989517212
- 1.31635591506958
- 1.2800914359092712
- 1.2944841551780701
- 1.2984258651733398
- 1.301120219230652
- 1.2637541890144348
- 1.277358765602112
- 1.2886488676071166
- 1.288529522418976
- 1.2454479479789733
- 1.227157118320465
- 1.2215930342674255
- 1.2463655805587768
- 1.2251768398284912
- 1.2085562086105346
- 1.2335137391090394
- 1.243814148902893
- 1.212058675289154
- 1.2405188012123107
- 1.2071617686748504
- 1.2046523404121399
- 1.1989249396324158
- 1.2220894479751587
- 1.2381384205818176
- 1.2398706817626952
- 1.2443916130065917
- 1.2553910422325134
- 1.2197997665405274
- 1.257346978187561
- 1.207919454574585
- 1.235071530342102
- 1.2069842791557313
- 1.2312838578224181
- 1.193882316350937
- 1.1841964900493622
- 1.2197162413597107
- 1.1877791035175322
- 1.1832138419151306
- 1.2088437032699586
- 1.1878580284118652
- 1.1808822870254516
- 1.1767347264289856
- 1.2058739805221557
- 1.1834638953208922
- 1.1800578022003174
- 1.2077805662155152
- 1.182832763195038
- 1.206774376630783
- 1.1871959924697877
- 1.1721224248409272
- 1.2026778984069824
- 1.1843670535087585
- 1.2054636693000793
- 1.1827709531784059
- 1.1832708883285523
- 1.2070346474647522
- 1.187695906162262
- 1.2082843780517578
- 1.2223005628585815
- 1.1893507874011993
- 1.1830406308174133
- 1.1735150611400604
- 1.171214896440506
train_accuracy:
- 0.068
- 0.124
- 0.144
- 0.131
- 0.19
- 0.197
- 0.161
- 0.214
- 0.192
- 0.194
- 0.184
- 0.251
- 0.256
- 0.22
- 0.207
- 0.23
- 0.249
- 0.214
- 0.0
- 0.25
- 0.319
- 0.264
- 0.241
- 0.271
- 0.316
- 0.0
- 0.29
- 0.235
- 0.26
- 0.247
- 0.263
- 0.294
- 0.377
- 0.366
- 0.338
- 0.304
- 0.342
- 0.318
- 0.373
- 0.325
- 0.307
- 0.381
- 0.0
- 0.294
- 0.372
- 0.334
- 0.0
- 0.341
- 0.308
- 0.286
- 0.0
- 0.312
- 0.35
- 0.393
- 0.293
- 0.334
- 0.333
- 0.354
- 0.362
- 0.362
- 0.33
- 0.37
- 0.359
- 0.343
- 0.348
- 0.372
- 0.0
- 0.376
- 0.299
- 0.322
- 0.0
- 0.0
- 0.406
- 0.367
- 0.353
- 0.335
- 0.326
- 0.409
- 0.381
- 0.379
- 0.0
- 0.342
- 0.322
- 0.342
- 0.339
- 0.35
- 0.356
- 0.373
- 0.382
- 0.356
- 0.387
- 0.314
- 0.343
- 0.38
- 0.358
- 0.355
- 0.419
- 0.0
- 0.0
- 0.403
train_loss:
- 4.269
- 3.385
- 3.559
- 3.41
- 3.243
- 2.865
- 3.011
- 2.919
- 2.605
- 2.586
- 2.736
- 2.409
- 2.623
- 2.302
- 2.388
- 2.399
- 2.197
- 2.3
- 2.043
- 2.016
- 2.19
- 2.107
- 1.997
- 1.906
- 1.776
- 1.736
- 1.689
- 1.882
- 1.766
- 1.571
- 1.762
- 1.697
- 1.544
- 1.538
- 1.555
- 1.58
- 1.434
- 1.44
- 1.371
- 1.412
- 1.375
- 1.301
- 1.285
- 1.249
- 1.168
- 1.184
- 1.211
- 1.109
- 1.029
- 1.111
- 0.991
- 1.014
- 0.985
- 0.986
- 1.018
- 0.911
- 0.887
- 0.824
- 0.857
- 0.861
- 0.891
- 0.849
- 0.845
- 0.778
- 0.805
- 0.753
- 0.732
- 0.652
- 0.674
- 0.624
- 0.691
- 0.642
- 0.643
- 0.678
- 0.633
- 0.62
- 0.571
- 0.552
- 0.589
- 0.507
- 0.581
- 0.523
- 0.537
- 0.513
- 0.472
- 0.482
- 0.509
- 0.467
- 0.442
- 0.472
- 0.504
- 0.442
- 0.413
- 0.406
- 0.436
- 0.367
- 0.426
- 0.387
- 0.364
- 0.391
unequal: 0
verbose: 1
