avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.047
- 0.101
- 0.1225
- 0.1376
- 0.1526
- 0.1579
- 0.1681
- 0.1769
- 0.1841
- 0.1914
- 0.1976
- 0.2015
- 0.2101
- 0.213
- 0.2199
- 0.2269
- 0.2285
- 0.2343
- 0.2316
- 0.2403
- 0.2442
- 0.2503
- 0.2499
- 0.2508
- 0.2497
- 0.2571
- 0.2614
- 0.2621
- 0.2671
- 0.2669
- 0.2682
- 0.2744
- 0.2726
- 0.2772
- 0.2753
- 0.2827
- 0.2813
- 0.2849
- 0.2844
- 0.2878
- 0.2874
- 0.2906
- 0.2931
- 0.2923
- 0.2944
- 0.299
- 0.2945
- 0.2996
- 0.3032
- 0.2992
- 0.3032
- 0.3052
- 0.3013
- 0.3017
- 0.3056
- 0.307
- 0.3102
- 0.309
- 0.3087
- 0.3129
- 0.3118
- 0.311
- 0.3138
- 0.3141
- 0.3138
- 0.3155
- 0.3131
- 0.3125
- 0.3167
- 0.3155
- 0.3162
- 0.3173
- 0.3165
- 0.3176
- 0.3156
- 0.3175
- 0.3185
- 0.3197
- 0.3198
- 0.318
- 0.3196
- 0.3192
- 0.3232
- 0.3236
- 0.3221
- 0.3237
- 0.3234
- 0.325
- 0.3207
- 0.321
- 0.3233
- 0.3272
- 0.3269
- 0.3262
- 0.328
- 0.3268
- 0.3261
- 0.3297
- 0.3322
- 0.3315
test_loss_list:
- 1.8036761665344239
- 1.6769208407402039
- 1.638506872653961
- 1.582762451171875
- 1.5729230976104736
- 1.5290720796585082
- 1.5090899896621703
- 1.478260200023651
- 1.4588955593109132
- 1.4441995310783386
- 1.460226330757141
- 1.4316351652145385
- 1.441884183883667
- 1.4429146432876587
- 1.408601267337799
- 1.4142750668525697
- 1.4192688417434693
- 1.4189845538139343
- 1.4162899851799011
- 1.3783357858657836
- 1.3508869481086732
- 1.3326864647865295
- 1.3200308871269226
- 1.3412414383888245
- 1.352036099433899
- 1.3512910842895507
- 1.3212967324256897
- 1.3017683982849122
- 1.285335829257965
- 1.3084198975563048
- 1.3188526368141174
- 1.3218944907188415
- 1.2914015698432921
- 1.2717127323150634
- 1.2950583124160766
- 1.2981401801109314
- 1.2720223093032836
- 1.254512655735016
- 1.2734485626220704
- 1.2824462509155274
- 1.2949050092697143
- 1.2567024874687194
- 1.2397545218467712
- 1.261093418598175
- 1.2357551741600037
- 1.2580509543418885
- 1.2691803312301635
- 1.2379195070266724
- 1.2222572350502015
- 1.2431604743003846
- 1.256472508907318
- 1.229061496257782
- 1.2150190997123718
- 1.206902539730072
- 1.2092010760307312
- 1.1982994341850282
- 1.1970919895172119
- 1.2322678232192994
- 1.2124605751037598
- 1.2300056028366089
- 1.243679814338684
- 1.2141583395004272
- 1.2021022367477416
- 1.232166016101837
- 1.2055248594284058
- 1.2260075092315674
- 1.2058699035644531
- 1.225397388935089
- 1.2019295358657838
- 1.2309460973739623
- 1.1987635612487793
- 1.2268545269966125
- 1.1986704874038696
- 1.2243679118156434
- 1.2437620520591737
- 1.2428591561317444
- 1.2099058628082275
- 1.1973153781890868
- 1.227327859401703
- 1.2029158663749695
- 1.1918531465530395
- 1.2196211194992066
- 1.2293977618217469
- 1.236956181526184
- 1.208485414981842
- 1.196687433719635
- 1.1925141525268554
- 1.2154762721061707
- 1.200089931488037
- 1.2253799486160277
- 1.2331308603286744
- 1.2012130761146544
- 1.1963524293899537
- 1.2232203674316406
- 1.1911271405220032
- 1.2266383719444276
- 1.1965623021125793
- 1.189321506023407
- 1.1828797554969788
- 1.1860300707817077
train_accuracy:
- 0.045
- 0.096
- 0.173
- 0.118
- 0.126
- 0.171
- 0.168
- 0.16
- 0.183
- 0.239
- 0.249
- 0.227
- 0.195
- 0.193
- 0.0
- 0.205
- 0.196
- 0.233
- 0.245
- 0.0
- 0.281
- 0.283
- 0.293
- 0.27
- 0.303
- 0.243
- 0.244
- 0.276
- 0.246
- 0.298
- 0.265
- 0.28
- 0.29
- 0.279
- 0.295
- 0.309
- 0.331
- 0.249
- 0.244
- 0.317
- 0.331
- 0.321
- 0.339
- 0.313
- 0.324
- 0.352
- 0.335
- 0.339
- 0.324
- 0.293
- 0.349
- 0.314
- 0.0
- 0.259
- 0.341
- 0.0
- 0.0
- 0.326
- 0.309
- 0.283
- 0.388
- 0.0
- 0.271
- 0.328
- 0.0
- 0.346
- 0.318
- 0.405
- 0.354
- 0.275
- 0.381
- 0.361
- 0.349
- 0.346
- 0.272
- 0.342
- 0.339
- 0.283
- 0.322
- 0.344
- 0.334
- 0.328
- 0.339
- 0.359
- 0.396
- 0.405
- 0.372
- 0.33
- 0.356
- 0.282
- 0.353
- 0.277
- 0.372
- 0.359
- 0.426
- 0.35
- 0.36
- 0.356
- 0.277
- 0.0
train_loss:
- 4.266
- 3.429
- 3.587
- 3.061
- 3.271
- 2.832
- 2.705
- 2.664
- 2.595
- 2.487
- 2.684
- 2.308
- 2.548
- 2.582
- 2.219
- 2.444
- 2.332
- 2.243
- 2.164
- 2.029
- 1.945
- 1.91
- 1.962
- 2.022
- 1.909
- 2.014
- 1.733
- 1.653
- 1.641
- 1.797
- 1.733
- 1.613
- 1.54
- 1.439
- 1.547
- 1.567
- 1.382
- 1.337
- 1.422
- 1.355
- 1.364
- 1.257
- 1.21
- 1.243
- 1.191
- 1.17
- 1.188
- 1.092
- 1.077
- 1.085
- 1.082
- 0.983
- 0.902
- 0.939
- 0.912
- 0.913
- 0.832
- 0.861
- 0.766
- 0.85
- 0.886
- 0.824
- 0.739
- 0.77
- 0.804
- 0.738
- 0.739
- 0.707
- 0.732
- 0.688
- 0.676
- 0.631
- 0.642
- 0.585
- 0.602
- 0.603
- 0.591
- 0.548
- 0.59
- 0.54
- 0.51
- 0.486
- 0.498
- 0.525
- 0.512
- 0.518
- 0.506
- 0.468
- 0.458
- 0.457
- 0.412
- 0.437
- 0.438
- 0.434
- 0.432
- 0.385
- 0.416
- 0.39
- 0.375
- 0.38
unequal: 0
verbose: 1
