avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0409
- 0.1028
- 0.126
- 0.1383
- 0.1512
- 0.1576
- 0.1687
- 0.1752
- 0.1808
- 0.1898
- 0.1984
- 0.2005
- 0.2072
- 0.2118
- 0.2154
- 0.2182
- 0.2249
- 0.2255
- 0.231
- 0.2376
- 0.2388
- 0.239
- 0.2427
- 0.2462
- 0.2452
- 0.2518
- 0.2537
- 0.2536
- 0.2599
- 0.2584
- 0.2597
- 0.2663
- 0.2624
- 0.2698
- 0.2702
- 0.2685
- 0.2719
- 0.2766
- 0.2731
- 0.2768
- 0.2798
- 0.2829
- 0.2813
- 0.2816
- 0.2844
- 0.2811
- 0.2888
- 0.2846
- 0.2887
- 0.2893
- 0.2939
- 0.296
- 0.2924
- 0.2943
- 0.2945
- 0.2991
- 0.2983
- 0.3009
- 0.3009
- 0.3034
- 0.3014
- 0.3051
- 0.3069
- 0.3072
- 0.3085
- 0.3077
- 0.3114
- 0.3106
- 0.3088
- 0.3095
- 0.3122
- 0.312
- 0.3122
- 0.3118
- 0.3127
- 0.3093
- 0.3139
- 0.319
- 0.3137
- 0.3119
- 0.3128
- 0.319
- 0.319
- 0.318
- 0.3196
- 0.3184
- 0.3176
- 0.3174
- 0.3168
- 0.32
- 0.3213
- 0.3244
- 0.3218
- 0.3208
- 0.3164
- 0.322
- 0.3252
- 0.3232
- 0.3222
- 0.3257
test_loss_list:
- 1.794160475730896
- 1.6757666373252869
- 1.6098082423210145
- 1.5911380791664123
- 1.5761585998535157
- 1.533251528739929
- 1.5009363317489623
- 1.4753179597854613
- 1.458083815574646
- 1.4434974884986878
- 1.4476731991767884
- 1.4549469685554504
- 1.4534280943870543
- 1.4152164363861084
- 1.4234123301506043
- 1.390488591194153
- 1.3996316361427308
- 1.3681966853141785
- 1.3785964369773864
- 1.3840708065032958
- 1.3537049913406372
- 1.3356264185905458
- 1.318361563682556
- 1.3099503207206726
- 1.299977295398712
- 1.3264625287055969
- 1.3340087366104125
- 1.3086258387565612
- 1.3271267199516297
- 1.2971856117248535
- 1.3132709932327271
- 1.286396930217743
- 1.273839192390442
- 1.2643373656272887
- 1.2589926242828369
- 1.2879348039627074
- 1.2591730618476868
- 1.25189532995224
- 1.2499510049819946
- 1.2715176582336425
- 1.2868921875953674
- 1.2559517693519593
- 1.2754385924339295
- 1.2503822922706604
- 1.2720569276809692
- 1.2477195262908936
- 1.265811243057251
- 1.2374627542495729
- 1.2623282980918884
- 1.261905221939087
- 1.237633774280548
- 1.2571196603775023
- 1.2704680848121643
- 1.230672628879547
- 1.2226906251907348
- 1.2410062193870544
- 1.2193246221542358
- 1.2367534685134887
- 1.2146094131469727
- 1.207213170528412
- 1.2022718119621276
- 1.1966064405441283
- 1.227729151248932
- 1.2319476318359375
- 1.2080327320098876
- 1.1933802342414856
- 1.2271276712417603
- 1.233651270866394
- 1.2403806400299073
- 1.2510989141464233
- 1.217370846271515
- 1.2042610597610475
- 1.1938608360290528
- 1.221323640346527
- 1.2348163151741027
- 1.2079585242271422
- 1.194328429698944
- 1.1829802894592285
- 1.2173793625831604
- 1.2278474879264831
- 1.2347992944717407
- 1.204947257041931
- 1.2272259569168091
- 1.1995558381080627
- 1.185316286087036
- 1.1850349378585816
- 1.2156154417991638
- 1.1942280316352845
- 1.192799437046051
- 1.189630401134491
- 1.2122223687171936
- 1.2179123973846435
- 1.2267598032951355
- 1.234441282749176
- 1.2516325044631957
- 1.2422861552238464
- 1.2495036387443543
- 1.2164449048042298
- 1.1982772469520568
- 1.1862948608398438
train_accuracy:
- 0.024
- 0.126
- 0.117
- 0.137
- 0.143
- 0.181
- 0.224
- 0.184
- 0.167
- 0.133
- 0.18
- 0.22
- 0.191
- 0.191
- 0.204
- 0.224
- 0.227
- 0.237
- 0.258
- 0.251
- 0.257
- 0.262
- 0.198
- 0.238
- 0.0
- 0.236
- 0.225
- 0.269
- 0.272
- 0.255
- 0.272
- 0.307
- 0.234
- 0.281
- 0.289
- 0.246
- 0.308
- 0.286
- 0.286
- 0.33
- 0.336
- 0.308
- 0.263
- 0.292
- 0.282
- 0.0
- 0.244
- 0.259
- 0.325
- 0.336
- 0.337
- 0.335
- 0.355
- 0.342
- 0.293
- 0.356
- 0.0
- 0.335
- 0.329
- 0.347
- 0.295
- 0.262
- 0.351
- 0.302
- 0.346
- 0.337
- 0.313
- 0.342
- 0.33
- 0.322
- 0.0
- 0.0
- 0.0
- 0.346
- 0.36
- 0.337
- 0.302
- 0.0
- 0.351
- 0.344
- 0.352
- 0.313
- 0.34
- 0.34
- 0.287
- 0.334
- 0.355
- 0.293
- 0.363
- 0.355
- 0.33
- 0.296
- 0.358
- 0.283
- 0.318
- 0.355
- 0.39
- 0.0
- 0.377
- 0.0
train_loss:
- 3.741
- 3.771
- 3.208
- 3.39
- 3.216
- 2.828
- 2.766
- 2.652
- 2.578
- 2.499
- 2.786
- 2.627
- 2.559
- 2.374
- 2.466
- 2.202
- 2.379
- 2.134
- 2.266
- 2.169
- 1.957
- 1.854
- 1.918
- 1.822
- 1.78
- 1.846
- 1.876
- 1.646
- 1.847
- 1.65
- 1.769
- 1.612
- 1.491
- 1.506
- 1.381
- 1.505
- 1.421
- 1.384
- 1.308
- 1.436
- 1.413
- 1.219
- 1.304
- 1.173
- 1.327
- 1.178
- 1.234
- 1.069
- 1.11
- 1.197
- 1.001
- 1.102
- 1.04
- 1.027
- 0.906
- 1.077
- 0.951
- 0.976
- 0.862
- 0.873
- 0.912
- 0.836
- 0.829
- 0.838
- 0.813
- 0.776
- 0.727
- 0.75
- 0.74
- 0.67
- 0.686
- 0.635
- 0.616
- 0.738
- 0.62
- 0.58
- 0.631
- 0.645
- 0.606
- 0.579
- 0.595
- 0.542
- 0.545
- 0.538
- 0.559
- 0.482
- 0.474
- 0.527
- 0.47
- 0.453
- 0.446
- 0.45
- 0.456
- 0.404
- 0.389
- 0.453
- 0.391
- 0.438
- 0.392
- 0.401
unequal: 0
verbose: 1
