avg_train_accuracy: 0.365
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0409
- 0.1
- 0.1132
- 0.1368
- 0.1453
- 0.1578
- 0.1714
- 0.1776
- 0.1828
- 0.1911
- 0.1944
- 0.2013
- 0.2092
- 0.2142
- 0.2166
- 0.2224
- 0.2249
- 0.2299
- 0.2309
- 0.2324
- 0.2388
- 0.2409
- 0.2423
- 0.2461
- 0.2461
- 0.2452
- 0.2526
- 0.256
- 0.2582
- 0.2578
- 0.2622
- 0.2651
- 0.2664
- 0.2652
- 0.27
- 0.2746
- 0.2698
- 0.2735
- 0.2782
- 0.2809
- 0.2779
- 0.2801
- 0.2807
- 0.2839
- 0.283
- 0.2828
- 0.2882
- 0.2876
- 0.2908
- 0.2863
- 0.2928
- 0.2917
- 0.296
- 0.2965
- 0.298
- 0.2971
- 0.2992
- 0.2999
- 0.2998
- 0.2985
- 0.3
- 0.3034
- 0.2989
- 0.3047
- 0.3006
- 0.3024
- 0.3023
- 0.3032
- 0.3007
- 0.3059
- 0.3096
- 0.309
- 0.3043
- 0.3092
- 0.3064
- 0.3076
- 0.3118
- 0.313
- 0.3096
- 0.3091
- 0.3073
- 0.313
- 0.3116
- 0.3151
- 0.3174
- 0.3118
- 0.3137
- 0.3152
- 0.3155
- 0.3159
- 0.3151
- 0.3136
- 0.3149
- 0.3159
- 0.3163
- 0.3208
- 0.3154
- 0.317
- 0.3178
- 0.317
test_loss_list:
- 1.8120746755599975
- 1.6982249593734742
- 1.6341093850135804
- 1.607257478237152
- 1.5589546704292296
- 1.5543807578086852
- 1.5448621225357055
- 1.5299324798583984
- 1.524123077392578
- 1.5153529953956604
- 1.478410129547119
- 1.4437613773345948
- 1.4145981454849244
- 1.3999116706848145
- 1.3865018582344055
- 1.4028044199943543
- 1.3795574688911438
- 1.3628406047821044
- 1.3795396208763122
- 1.388965926170349
- 1.3567468404769898
- 1.3673766374588012
- 1.3788740181922912
- 1.3786351847648621
- 1.3435854721069336
- 1.3237114000320434
- 1.306456732749939
- 1.2985738611221314
- 1.2900267553329468
- 1.3191169786453247
- 1.325130407810211
- 1.3310852670669555
- 1.3000967335700988
- 1.2829625940322875
- 1.2773985242843628
- 1.2622163581848145
- 1.2589391946792603
- 1.2813123369216919
- 1.2945481848716736
- 1.2695694184303283
- 1.2609402823448181
- 1.2785722494125367
- 1.2890408420562744
- 1.2567606091499328
- 1.281064329147339
- 1.25512145280838
- 1.2332098436355592
- 1.2632883834838866
- 1.2390195775032042
- 1.2323435473442077
- 1.2550982594490052
- 1.235032765865326
- 1.222327206134796
- 1.246826810836792
- 1.2244436931610108
- 1.2175541853904723
- 1.2157545375823975
- 1.2093514394760132
- 1.240537760257721
- 1.2515339541435242
- 1.2632689905166625
- 1.2648910999298095
- 1.2363027930259705
- 1.2530523943901062
- 1.260198826789856
- 1.2315010833740234
- 1.2164735794067383
- 1.2396658539772034
- 1.21843736410141
- 1.2400994110107422
- 1.2133529329299926
- 1.2060824394226075
- 1.2415821576118469
- 1.206428337097168
- 1.2324470329284667
- 1.2452172303199769
- 1.2532726740837097
- 1.2557708621025085
- 1.2206937551498414
- 1.2119401788711548
- 1.2046150088310241
- 1.1939860272407532
- 1.1974526238441467
- 1.1947083401679992
- 1.1849690055847169
- 1.2219311356544496
- 1.2001776361465455
- 1.1918655490875245
- 1.2166792416572572
- 1.199696536064148
- 1.22541241645813
- 1.238705723285675
- 1.2438819026947021
- 1.2108272218704224
- 1.2398924779891969
- 1.2043761444091796
- 1.2316394805908204
- 1.2097214341163636
- 1.2324024200439454
- 1.2424718022346497
train_accuracy:
- 0.037
- 0.098
- 0.128
- 0.16
- 0.155
- 0.179
- 0.131
- 0.186
- 0.154
- 0.198
- 0.214
- 0.218
- 0.218
- 0.216
- 0.249
- 0.258
- 0.0
- 0.237
- 0.21
- 0.255
- 0.26
- 0.269
- 0.224
- 0.274
- 0.261
- 0.223
- 0.303
- 0.277
- 0.311
- 0.281
- 0.296
- 0.295
- 0.0
- 0.303
- 0.274
- 0.279
- 0.253
- 0.289
- 0.257
- 0.329
- 0.307
- 0.263
- 0.292
- 0.293
- 0.317
- 0.329
- 0.265
- 0.314
- 0.319
- 0.267
- 0.263
- 0.258
- 0.319
- 0.34
- 0.283
- 0.0
- 0.0
- 0.258
- 0.332
- 0.333
- 0.263
- 0.34
- 0.268
- 0.334
- 0.269
- 0.281
- 0.283
- 0.349
- 0.353
- 0.349
- 0.313
- 0.272
- 0.328
- 0.304
- 0.296
- 0.355
- 0.341
- 0.353
- 0.32
- 0.0
- 0.273
- 0.348
- 0.0
- 0.268
- 0.329
- 0.346
- 0.347
- 0.0
- 0.352
- 0.0
- 0.352
- 0.348
- 0.277
- 0.366
- 0.34
- 0.0
- 0.365
- 0.322
- 0.349
- 0.365
train_loss:
- 4.316
- 3.766
- 3.187
- 3.419
- 2.925
- 3.125
- 2.995
- 2.962
- 2.826
- 2.737
- 2.527
- 2.404
- 2.411
- 2.295
- 2.224
- 2.368
- 2.14
- 2.051
- 2.255
- 2.161
- 1.916
- 2.111
- 1.975
- 2.006
- 1.793
- 1.749
- 1.697
- 1.699
- 1.623
- 1.694
- 1.735
- 1.69
- 1.544
- 1.441
- 1.364
- 1.442
- 1.386
- 1.425
- 1.371
- 1.312
- 1.202
- 1.343
- 1.298
- 1.193
- 1.231
- 1.102
- 1.122
- 1.2
- 1.102
- 1.077
- 1.039
- 1.03
- 1.039
- 0.995
- 0.942
- 0.901
- 0.885
- 0.873
- 0.883
- 0.836
- 0.882
- 0.802
- 0.814
- 0.769
- 0.727
- 0.727
- 0.709
- 0.778
- 0.692
- 0.686
- 0.722
- 0.661
- 0.632
- 0.625
- 0.595
- 0.592
- 0.642
- 0.564
- 0.658
- 0.547
- 0.498
- 0.593
- 0.524
- 0.518
- 0.537
- 0.523
- 0.486
- 0.463
- 0.487
- 0.462
- 0.428
- 0.443
- 0.443
- 0.445
- 0.408
- 0.442
- 0.391
- 0.395
- 0.345
- 0.389
unequal: 0
verbose: 1
