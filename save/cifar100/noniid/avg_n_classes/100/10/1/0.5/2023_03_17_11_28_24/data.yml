avg_train_accuracy: 0.33
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0328
- 0.0965
- 0.1199
- 0.134
- 0.1488
- 0.1579
- 0.1672
- 0.1759
- 0.1796
- 0.1912
- 0.198
- 0.2046
- 0.2073
- 0.2148
- 0.2207
- 0.2222
- 0.2285
- 0.2301
- 0.2325
- 0.2345
- 0.2376
- 0.2433
- 0.2469
- 0.2501
- 0.2517
- 0.2569
- 0.2557
- 0.2638
- 0.2615
- 0.262
- 0.2634
- 0.2676
- 0.2706
- 0.2751
- 0.2755
- 0.2814
- 0.2812
- 0.2825
- 0.2841
- 0.2837
- 0.2853
- 0.2895
- 0.2885
- 0.2943
- 0.2929
- 0.2883
- 0.2968
- 0.2944
- 0.299
- 0.2977
- 0.296
- 0.2994
- 0.2994
- 0.2996
- 0.2993
- 0.3034
- 0.3004
- 0.3009
- 0.3048
- 0.3084
- 0.3056
- 0.3075
- 0.3077
- 0.3095
- 0.3077
- 0.3129
- 0.3088
- 0.3107
- 0.3126
- 0.3136
- 0.314
- 0.3127
- 0.315
- 0.3123
- 0.3129
- 0.3138
- 0.3224
- 0.3193
- 0.3179
- 0.3183
- 0.3155
- 0.3217
- 0.3207
- 0.32
- 0.3187
- 0.3207
- 0.321
- 0.3194
- 0.3223
- 0.3233
- 0.3216
- 0.324
- 0.3217
- 0.3184
- 0.3246
- 0.3216
- 0.3256
- 0.3249
- 0.3252
- 0.3286
test_loss_list:
- 1.7986625146865844
- 1.6902088880538941
- 1.6227921390533446
- 1.6037421011924744
- 1.58710932970047
- 1.5366949677467345
- 1.537564606666565
- 1.5313610434532166
- 1.5268763065338136
- 1.479192225933075
- 1.47863126039505
- 1.4772300601005555
- 1.4403454279899597
- 1.4084376692771912
- 1.3898590922355651
- 1.377232551574707
- 1.3936278271675109
- 1.4005099105834962
- 1.4045964288711548
- 1.404893774986267
- 1.4072181320190429
- 1.3704018306732177
- 1.3759004116058349
- 1.3793028330802917
- 1.3446609258651734
- 1.3203744626045226
- 1.306790313720703
- 1.3266792249679566
- 1.3050669813156128
- 1.3227963089942931
- 1.2946268510818482
- 1.2829550981521607
- 1.3001911807060242
- 1.3071908235549927
- 1.3137893438339234
- 1.3174822044372558
- 1.323818998336792
- 1.3338764238357543
- 1.3318206286430359
- 1.290872564315796
- 1.2659334444999695
- 1.2879949951171874
- 1.2984086966514587
- 1.297845025062561
- 1.3022814536094665
- 1.2749777507781983
- 1.2509549760818481
- 1.2389472484588624
- 1.2597809195518495
- 1.27457524061203
- 1.248024547100067
- 1.229667181968689
- 1.2609913802146913
- 1.2618015837669372
- 1.2731994962692261
- 1.276009349822998
- 1.250224893093109
- 1.2716495728492736
- 1.2762785482406616
- 1.238474316596985
- 1.258375723361969
- 1.2302592635154723
- 1.2532469296455384
- 1.261010229587555
- 1.2708450150489807
- 1.2686830735206605
- 1.2449514985084533
- 1.22810866355896
- 1.2122712659835815
- 1.243201994895935
- 1.2464700746536255
- 1.2564421582221985
- 1.2231471562385559
- 1.2484335136413574
- 1.225667996406555
- 1.2418894004821777
- 1.2518170976638794
- 1.2623002672195434
- 1.2250955963134766
- 1.2524716210365296
- 1.2216200280189513
- 1.2441317343711853
- 1.2536489391326904
- 1.22338698387146
- 1.213485097885132
- 1.2030700087547301
- 1.231397933959961
- 1.2117075848579406
- 1.2025355744361876
- 1.194822175502777
- 1.222877995967865
- 1.2009365034103394
- 1.2285760736465454
- 1.2117012095451356
- 1.2258126473426818
- 1.2065517020225525
- 1.2058122634887696
- 1.1974792528152465
- 1.193622682094574
- 1.2259453344345093
train_accuracy:
- 0.039
- 0.089
- 0.124
- 0.148
- 0.146
- 0.147
- 0.185
- 0.143
- 0.204
- 0.177
- 0.212
- 0.193
- 0.259
- 0.234
- 0.22
- 0.0
- 0.199
- 0.276
- 0.249
- 0.303
- 0.208
- 0.293
- 0.202
- 0.291
- 0.242
- 0.0
- 0.0
- 0.31
- 0.0
- 0.257
- 0.0
- 0.284
- 0.241
- 0.297
- 0.237
- 0.304
- 0.302
- 0.323
- 0.324
- 0.364
- 0.0
- 0.328
- 0.314
- 0.292
- 0.279
- 0.342
- 0.0
- 0.0
- 0.314
- 0.305
- 0.373
- 0.35
- 0.349
- 0.305
- 0.315
- 0.299
- 0.345
- 0.301
- 0.345
- 0.32
- 0.275
- 0.344
- 0.356
- 0.364
- 0.361
- 0.366
- 0.274
- 0.329
- 0.354
- 0.368
- 0.334
- 0.32
- 0.37
- 0.362
- 0.306
- 0.314
- 0.343
- 0.287
- 0.278
- 0.321
- 0.328
- 0.315
- 0.319
- 0.0
- 0.382
- 0.331
- 0.331
- 0.318
- 0.354
- 0.334
- 0.375
- 0.371
- 0.307
- 0.291
- 0.385
- 0.0
- 0.317
- 0.0
- 0.307
- 0.33
train_loss:
- 4.244
- 3.748
- 3.203
- 3.385
- 3.204
- 2.862
- 3.001
- 2.892
- 2.816
- 2.591
- 2.753
- 2.629
- 2.331
- 2.333
- 2.221
- 2.167
- 2.375
- 2.269
- 2.237
- 2.183
- 2.116
- 1.864
- 2.098
- 1.926
- 1.8
- 1.811
- 1.672
- 1.785
- 1.615
- 1.741
- 1.584
- 1.55
- 1.688
- 1.61
- 1.525
- 1.505
- 1.427
- 1.404
- 1.378
- 1.272
- 1.329
- 1.253
- 1.263
- 1.334
- 1.189
- 1.135
- 1.092
- 1.049
- 1.14
- 1.008
- 1.038
- 1.053
- 0.935
- 1.092
- 1.024
- 1.007
- 0.937
- 0.86
- 0.876
- 0.824
- 0.87
- 0.853
- 0.761
- 0.812
- 0.728
- 0.761
- 0.738
- 0.692
- 0.735
- 0.664
- 0.678
- 0.644
- 0.681
- 0.622
- 0.624
- 0.611
- 0.587
- 0.551
- 0.611
- 0.517
- 0.589
- 0.532
- 0.48
- 0.539
- 0.505
- 0.524
- 0.481
- 0.51
- 0.472
- 0.471
- 0.415
- 0.448
- 0.405
- 0.429
- 0.429
- 0.442
- 0.389
- 0.371
- 0.424
- 0.343
unequal: 0
verbose: 1
