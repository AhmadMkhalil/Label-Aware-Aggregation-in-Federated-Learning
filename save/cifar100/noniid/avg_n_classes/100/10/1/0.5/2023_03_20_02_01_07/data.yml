avg_train_accuracy: 0.295
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0479
- 0.1053
- 0.1262
- 0.1442
- 0.1583
- 0.1655
- 0.1764
- 0.1823
- 0.1895
- 0.1949
- 0.1983
- 0.2051
- 0.2108
- 0.2177
- 0.2209
- 0.2244
- 0.2304
- 0.2338
- 0.243
- 0.2394
- 0.2488
- 0.2503
- 0.252
- 0.2566
- 0.2625
- 0.2588
- 0.2625
- 0.2643
- 0.264
- 0.2673
- 0.2718
- 0.279
- 0.2743
- 0.2777
- 0.2822
- 0.2763
- 0.2865
- 0.2854
- 0.2904
- 0.2888
- 0.2917
- 0.29
- 0.2902
- 0.2932
- 0.2965
- 0.2931
- 0.2949
- 0.2963
- 0.3035
- 0.2985
- 0.3023
- 0.3058
- 0.3048
- 0.308
- 0.303
- 0.3084
- 0.3076
- 0.3109
- 0.3107
- 0.3126
- 0.3123
- 0.3106
- 0.3113
- 0.3115
- 0.3071
- 0.3113
- 0.3134
- 0.3114
- 0.3189
- 0.3147
- 0.3141
- 0.314
- 0.3185
- 0.3159
- 0.3159
- 0.319
- 0.3207
- 0.3185
- 0.3194
- 0.3179
- 0.3182
- 0.3256
- 0.3204
- 0.3215
- 0.3231
- 0.3213
- 0.3233
- 0.3251
- 0.3222
- 0.3246
- 0.3272
- 0.3242
- 0.3261
- 0.323
- 0.3296
- 0.329
- 0.3297
- 0.328
- 0.3265
- 0.3256
test_loss_list:
- 1.79391517162323
- 1.6842275762557983
- 1.643965060710907
- 1.612832646369934
- 1.564566810131073
- 1.5190285801887513
- 1.4931555414199829
- 1.4704704880714417
- 1.4491997241973877
- 1.4618581056594848
- 1.435727424621582
- 1.4157542181015015
- 1.399052746295929
- 1.4150617957115172
- 1.388205692768097
- 1.4017157745361328
- 1.4057469534873963
- 1.3715510416030883
- 1.3796692085266113
- 1.3555517101287842
- 1.3677402281761168
- 1.3374468731880187
- 1.3519889569282533
- 1.3192984986305236
- 1.3050342416763305
- 1.3276517271995545
- 1.3339874577522277
- 1.309171540737152
- 1.3263220953941346
- 1.3316070246696472
- 1.3348546433448791
- 1.3303329849243164
- 1.336062376499176
- 1.3408498406410216
- 1.298828022480011
- 1.3148897552490235
- 1.3164834308624267
- 1.282226312160492
- 1.2960704278945923
- 1.2655428838729859
- 1.2790202283859253
- 1.2548368406295776
- 1.2444970607757568
- 1.263036434650421
- 1.232289752960205
- 1.2279792737960815
- 1.252550811767578
- 1.2658412098884582
- 1.2665822196006775
- 1.2422172665596007
- 1.256509370803833
- 1.262590091228485
- 1.2370878076553344
- 1.2528777241706848
- 1.262169451713562
- 1.2697433638572693
- 1.2332732200622558
- 1.2509834337234498
- 1.2637511920928954
- 1.2671767497062683
- 1.2728733396530152
- 1.274429783821106
- 1.238840901851654
- 1.2252501320838929
- 1.2458552742004394
- 1.25506117105484
- 1.2609160447120666
- 1.2677104783058166
- 1.2278864097595215
- 1.2126964807510376
- 1.2038290357589723
- 1.192534146308899
- 1.1934869575500489
- 1.1884347796440125
- 1.2215026140213012
- 1.2012660002708435
- 1.2265760159492494
- 1.202245682477951
- 1.2284400391578674
- 1.2033476829528809
- 1.2321485042572022
- 1.2032668495178223
- 1.1982225286960602
- 1.216586856842041
- 1.2294936871528626
- 1.2038646626472473
- 1.2022646498680114
- 1.2235936045646667
- 1.1982610368728637
- 1.2242030382156373
- 1.233482301235199
- 1.23986759185791
- 1.2447856855392456
- 1.2156514072418212
- 1.1997187733650208
- 1.1923549175262451
- 1.188315713405609
- 1.2196489453315735
- 1.2296487402915954
- 1.2358831000328063
train_accuracy:
- 0.051
- 0.099
- 0.089
- 0.154
- 0.122
- 0.154
- 0.146
- 0.165
- 0.221
- 0.198
- 0.229
- 0.18
- 0.0
- 0.202
- 0.261
- 0.194
- 0.196
- 0.211
- 0.229
- 0.238
- 0.245
- 0.0
- 0.225
- 0.256
- 0.0
- 0.257
- 0.249
- 0.234
- 0.262
- 0.241
- 0.249
- 0.292
- 0.258
- 0.284
- 0.313
- 0.279
- 0.289
- 0.0
- 0.292
- 0.284
- 0.283
- 0.0
- 0.254
- 0.261
- 0.0
- 0.332
- 0.305
- 0.316
- 0.298
- 0.306
- 0.326
- 0.326
- 0.315
- 0.322
- 0.277
- 0.315
- 0.301
- 0.339
- 0.332
- 0.326
- 0.342
- 0.316
- 0.326
- 0.334
- 0.334
- 0.302
- 0.287
- 0.276
- 0.0
- 0.279
- 0.294
- 0.317
- 0.323
- 0.335
- 0.329
- 0.338
- 0.31
- 0.295
- 0.345
- 0.0
- 0.307
- 0.335
- 0.0
- 0.352
- 0.339
- 0.353
- 0.323
- 0.297
- 0.357
- 0.342
- 0.327
- 0.343
- 0.338
- 0.335
- 0.0
- 0.339
- 0.342
- 0.354
- 0.341
- 0.295
train_loss:
- 4.293
- 3.758
- 3.51
- 3.349
- 2.92
- 2.892
- 2.737
- 2.657
- 2.602
- 2.793
- 2.448
- 2.369
- 2.327
- 2.553
- 2.259
- 2.414
- 2.369
- 2.122
- 2.269
- 1.985
- 2.081
- 1.9
- 2.145
- 1.882
- 1.801
- 1.928
- 1.886
- 1.673
- 1.731
- 1.723
- 1.656
- 1.749
- 1.593
- 1.561
- 1.465
- 1.516
- 1.451
- 1.443
- 1.395
- 1.31
- 1.363
- 1.229
- 1.197
- 1.274
- 1.185
- 1.124
- 1.141
- 1.179
- 1.133
- 1.026
- 1.059
- 1.029
- 0.973
- 0.974
- 0.944
- 0.95
- 0.912
- 0.918
- 0.875
- 0.825
- 0.843
- 0.811
- 0.793
- 0.775
- 0.732
- 0.705
- 0.738
- 0.669
- 0.748
- 0.721
- 0.651
- 0.691
- 0.637
- 0.618
- 0.576
- 0.606
- 0.546
- 0.578
- 0.559
- 0.531
- 0.557
- 0.523
- 0.559
- 0.522
- 0.484
- 0.517
- 0.473
- 0.455
- 0.447
- 0.453
- 0.416
- 0.44
- 0.416
- 0.422
- 0.462
- 0.4
- 0.397
- 0.372
- 0.357
- 0.37
unequal: 0
verbose: 1
