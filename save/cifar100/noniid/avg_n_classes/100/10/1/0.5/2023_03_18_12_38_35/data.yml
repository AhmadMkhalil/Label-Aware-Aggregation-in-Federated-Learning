avg_train_accuracy: 0.349
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0504
- 0.0991
- 0.1125
- 0.1307
- 0.1428
- 0.1526
- 0.1592
- 0.1706
- 0.1789
- 0.185
- 0.192
- 0.1942
- 0.2
- 0.2106
- 0.2138
- 0.2191
- 0.2193
- 0.2229
- 0.2287
- 0.231
- 0.2344
- 0.2388
- 0.2361
- 0.2424
- 0.2444
- 0.2477
- 0.2504
- 0.2503
- 0.2542
- 0.2535
- 0.2586
- 0.261
- 0.2605
- 0.2676
- 0.265
- 0.266
- 0.267
- 0.268
- 0.2716
- 0.2705
- 0.2771
- 0.2825
- 0.2796
- 0.2773
- 0.2807
- 0.2813
- 0.2841
- 0.2851
- 0.2863
- 0.2886
- 0.2898
- 0.2875
- 0.2914
- 0.2887
- 0.2933
- 0.2921
- 0.2888
- 0.2903
- 0.2995
- 0.2988
- 0.298
- 0.2998
- 0.2995
- 0.2995
- 0.3001
- 0.2978
- 0.3005
- 0.301
- 0.3042
- 0.3052
- 0.304
- 0.3035
- 0.3036
- 0.3066
- 0.3057
- 0.3062
- 0.3051
- 0.3089
- 0.304
- 0.3095
- 0.3117
- 0.3095
- 0.3112
- 0.3079
- 0.3103
- 0.3126
- 0.3149
- 0.3162
- 0.3163
- 0.31
- 0.3153
- 0.3135
- 0.3131
- 0.3133
- 0.3165
- 0.3166
- 0.3158
- 0.3113
- 0.3172
- 0.3183
test_loss_list:
- 1.7957033014297485
- 1.6840854597091675
- 1.630114393234253
- 1.6142471432685852
- 1.5688724398612977
- 1.534779875278473
- 1.5364937853813172
- 1.5328229475021362
- 1.4958993983268738
- 1.4980812931060792
- 1.5006007361412048
- 1.463010756969452
- 1.4373862957954406
- 1.4170431351661683
- 1.4302282524108887
- 1.4022420954704284
- 1.3858461141586305
- 1.3664731431007384
- 1.3917147207260132
- 1.3648787999153138
- 1.3484824252128602
- 1.3364089798927308
- 1.3602588558197022
- 1.3318435978889465
- 1.3551666378974914
- 1.3638103437423705
- 1.3353492999076844
- 1.3488401794433593
- 1.3528673648834229
- 1.357981481552124
- 1.3239472794532776
- 1.332417414188385
- 1.3052105545997619
- 1.2893233871459961
- 1.282125515937805
- 1.268974347114563
- 1.3020800209045411
- 1.2720906472206115
- 1.2936591839790343
- 1.2715804529190065
- 1.2916901969909669
- 1.2689212799072265
- 1.2643401718139649
- 1.2546250867843627
- 1.248138337135315
- 1.2408874821662903
- 1.2362216186523438
- 1.2704408144950867
- 1.2818322730064393
- 1.2871456789970397
- 1.2907573914527892
- 1.2968974542617797
- 1.2585503435134888
- 1.2764207077026368
- 1.2834050703048705
- 1.2871548318862915
- 1.2616157054901123
- 1.24289981842041
- 1.2263048720359802
- 1.2209574151039124
- 1.2486527252197266
- 1.2574112510681152
- 1.2623893022537231
- 1.240252091884613
- 1.2582185554504395
- 1.2679084587097167
- 1.2702398681640625
- 1.2806785941123962
- 1.281979374885559
- 1.2842789101600647
- 1.290555784702301
- 1.2941405630111695
- 1.2546561121940614
- 1.235740945339203
- 1.258123791217804
- 1.2332783913612366
- 1.2184622836112977
- 1.2117734909057618
- 1.2113245248794555
- 1.2045753693580628
- 1.2045876026153564
- 1.2330621218681335
- 1.242322871685028
- 1.2565201115608216
- 1.2275748705863954
- 1.2108517098426819
- 1.2096482396125794
- 1.2002589535713195
- 1.199294445514679
- 1.2051886701583863
- 1.226344187259674
- 1.2098694133758545
- 1.2316283941268922
- 1.2152490186691285
- 1.2390791773796082
- 1.21259920835495
- 1.2327845692634583
- 1.249022843837738
- 1.252308943271637
- 1.2585006666183471
train_accuracy:
- 0.032
- 0.0
- 0.153
- 0.111
- 0.097
- 0.152
- 0.159
- 0.175
- 0.169
- 0.178
- 0.178
- 0.247
- 0.254
- 0.0
- 0.215
- 0.217
- 0.234
- 0.235
- 0.239
- 0.226
- 0.0
- 0.293
- 0.245
- 0.0
- 0.296
- 0.263
- 0.0
- 0.241
- 0.21
- 0.255
- 0.252
- 0.25
- 0.254
- 0.255
- 0.256
- 0.278
- 0.247
- 0.283
- 0.234
- 0.0
- 0.259
- 0.292
- 0.286
- 0.0
- 0.272
- 0.285
- 0.282
- 0.283
- 0.297
- 0.29
- 0.271
- 0.322
- 0.328
- 0.29
- 0.329
- 0.301
- 0.336
- 0.3
- 0.34
- 0.323
- 0.32
- 0.329
- 0.311
- 0.322
- 0.346
- 0.336
- 0.299
- 0.307
- 0.322
- 0.314
- 0.327
- 0.299
- 0.0
- 0.297
- 0.314
- 0.385
- 0.0
- 0.306
- 0.307
- 0.352
- 0.343
- 0.336
- 0.336
- 0.313
- 0.0
- 0.306
- 0.348
- 0.291
- 0.0
- 0.306
- 0.311
- 0.344
- 0.35
- 0.306
- 0.392
- 0.0
- 0.346
- 0.345
- 0.343
- 0.349
train_loss:
- 4.296
- 3.404
- 3.207
- 3.432
- 2.973
- 2.844
- 3.093
- 2.972
- 2.611
- 2.786
- 2.682
- 2.484
- 2.328
- 2.277
- 2.518
- 2.165
- 2.183
- 2.161
- 2.264
- 1.977
- 1.956
- 1.961
- 2.062
- 1.835
- 1.99
- 1.964
- 1.672
- 1.86
- 1.899
- 1.762
- 1.619
- 1.665
- 1.539
- 1.483
- 1.498
- 1.429
- 1.525
- 1.431
- 1.491
- 1.314
- 1.352
- 1.267
- 1.18
- 1.124
- 1.153
- 1.153
- 1.136
- 1.138
- 1.104
- 1.127
- 1.07
- 1.125
- 1.017
- 1.03
- 1.06
- 0.966
- 0.945
- 0.866
- 0.813
- 0.903
- 0.838
- 0.851
- 0.841
- 0.795
- 0.863
- 0.787
- 0.733
- 0.703
- 0.676
- 0.64
- 0.666
- 0.673
- 0.762
- 0.618
- 0.656
- 0.601
- 0.527
- 0.643
- 0.619
- 0.567
- 0.506
- 0.51
- 0.531
- 0.546
- 0.502
- 0.529
- 0.485
- 0.442
- 0.471
- 0.531
- 0.44
- 0.453
- 0.431
- 0.441
- 0.412
- 0.403
- 0.412
- 0.395
- 0.358
- 0.396
unequal: 0
verbose: 1
