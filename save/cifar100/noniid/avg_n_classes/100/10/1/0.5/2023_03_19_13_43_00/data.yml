avg_train_accuracy: 0.4
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0406
- 0.099
- 0.115
- 0.1295
- 0.1455
- 0.1604
- 0.1724
- 0.1757
- 0.1883
- 0.1975
- 0.198
- 0.209
- 0.2158
- 0.2169
- 0.225
- 0.2279
- 0.2334
- 0.2332
- 0.2417
- 0.2438
- 0.2469
- 0.2542
- 0.2555
- 0.2557
- 0.2547
- 0.2585
- 0.2621
- 0.2644
- 0.2652
- 0.2685
- 0.2714
- 0.2708
- 0.2721
- 0.2782
- 0.2746
- 0.2771
- 0.2794
- 0.2851
- 0.2832
- 0.2882
- 0.2842
- 0.2901
- 0.2906
- 0.2885
- 0.2874
- 0.2937
- 0.2938
- 0.2985
- 0.2969
- 0.2974
- 0.3008
- 0.2997
- 0.3013
- 0.3029
- 0.3042
- 0.3031
- 0.3032
- 0.3044
- 0.3083
- 0.3063
- 0.3051
- 0.3082
- 0.3099
- 0.3092
- 0.3106
- 0.3117
- 0.3135
- 0.3103
- 0.3131
- 0.313
- 0.3172
- 0.3122
- 0.3149
- 0.3139
- 0.3122
- 0.3185
- 0.3148
- 0.3188
- 0.3207
- 0.3183
- 0.3198
- 0.3141
- 0.3169
- 0.3204
- 0.3213
- 0.3181
- 0.3225
- 0.3221
- 0.32
- 0.3193
- 0.3169
- 0.3205
- 0.3219
- 0.3204
- 0.3226
- 0.322
- 0.3229
- 0.3247
- 0.3249
- 0.3252
test_loss_list:
- 1.7989868354797363
- 1.6719869518280028
- 1.6212625074386597
- 1.6031399416923522
- 1.5601991629600525
- 1.549424250125885
- 1.5410811805725098
- 1.5329746770858765
- 1.4876491618156433
- 1.4886222052574158
- 1.456034927368164
- 1.455903675556183
- 1.4273357939720155
- 1.402423725128174
- 1.4139713478088378
- 1.3867774033546447
- 1.3994906902313233
- 1.4001746845245362
- 1.3666972494125367
- 1.3795215034484862
- 1.351443727016449
- 1.3629510927200317
- 1.3661084914207458
- 1.3725214862823487
- 1.337830765247345
- 1.3158369731903077
- 1.3023515057563781
- 1.2898312830924987
- 1.3161841750144958
- 1.294423201084137
- 1.3100163269042968
- 1.321217849254608
- 1.32805597782135
- 1.3217027711868286
- 1.291065719127655
- 1.2772797679901122
- 1.2590252041816712
- 1.2794103527069092
- 1.2932360529899598
- 1.2586498212814332
- 1.2818906998634338
- 1.2505063390731812
- 1.2712759733200074
- 1.2501034617424012
- 1.2751334929466247
- 1.2791258406639099
- 1.2455306506156922
- 1.2621173787117004
- 1.2728348135948182
- 1.2418499350547791
- 1.2606981229782104
- 1.2342351078987122
- 1.2240518856048583
- 1.2423035025596618
- 1.2542831516265869
- 1.2663830757141112
- 1.27628746509552
- 1.2420874071121215
- 1.2536203360557556
- 1.2265092635154724
- 1.2170071053504943
- 1.2382243657112122
- 1.244557466506958
- 1.2197632265090943
- 1.2444010305404662
- 1.2523150992393495
- 1.2175311183929443
- 1.2111324167251587
- 1.2012491369247436
- 1.2221883463859557
- 1.2380129957199097
- 1.2139636611938476
- 1.204514307975769
- 1.234538769721985
- 1.2054128289222716
- 1.199851484298706
- 1.2207036805152893
- 1.2357229924201965
- 1.2438667988777161
- 1.2503460621833802
- 1.2643244433403016
- 1.2662823152542115
- 1.224896354675293
- 1.213221445083618
- 1.2035791206359863
- 1.1961757731437683
- 1.1916816473007201
- 1.217963216304779
- 1.229582631587982
- 1.2403087854385375
- 1.210622684955597
- 1.1971702146530152
- 1.2250210309028626
- 1.197486035823822
- 1.1929045772552491
- 1.192094554901123
- 1.2241909885406494
- 1.2321204662322998
- 1.20300066947937
- 1.2333937454223634
train_accuracy:
- 0.044
- 0.088
- 0.096
- 0.151
- 0.126
- 0.193
- 0.159
- 0.178
- 0.187
- 0.179
- 0.187
- 0.225
- 0.27
- 0.204
- 0.249
- 0.255
- 0.229
- 0.229
- 0.0
- 0.299
- 0.237
- 0.249
- 0.288
- 0.292
- 0.231
- 0.0
- 0.273
- 0.271
- 0.253
- 0.289
- 0.301
- 0.281
- 0.316
- 0.325
- 0.295
- 0.297
- 0.305
- 0.299
- 0.367
- 0.296
- 0.315
- 0.266
- 0.291
- 0.329
- 0.332
- 0.305
- 0.297
- 0.307
- 0.306
- 0.3
- 0.317
- 0.35
- 0.376
- 0.34
- 0.314
- 0.318
- 0.312
- 0.318
- 0.323
- 0.332
- 0.338
- 0.338
- 0.366
- 0.0
- 0.329
- 0.319
- 0.357
- 0.382
- 0.338
- 0.325
- 0.315
- 0.328
- 0.0
- 0.319
- 0.0
- 0.354
- 0.404
- 0.332
- 0.347
- 0.392
- 0.36
- 0.348
- 0.332
- 0.32
- 0.342
- 0.342
- 0.324
- 0.33
- 0.362
- 0.364
- 0.329
- 0.343
- 0.329
- 0.0
- 0.396
- 0.395
- 0.33
- 0.357
- 0.348
- 0.4
train_loss:
- 4.272
- 3.387
- 3.232
- 3.428
- 2.989
- 3.149
- 3.075
- 2.946
- 2.673
- 2.795
- 2.474
- 2.698
- 2.346
- 2.345
- 2.445
- 2.159
- 2.376
- 2.349
- 2.041
- 2.22
- 1.973
- 2.102
- 2.023
- 2.009
- 1.795
- 1.752
- 1.7
- 1.708
- 1.74
- 1.546
- 1.634
- 1.679
- 1.59
- 1.62
- 1.514
- 1.436
- 1.376
- 1.462
- 1.417
- 1.312
- 1.347
- 1.26
- 1.31
- 1.161
- 1.205
- 1.232
- 1.093
- 1.125
- 1.107
- 1.034
- 1.089
- 1.0
- 1.02
- 1.013
- 0.99
- 0.925
- 0.885
- 0.844
- 0.897
- 0.826
- 0.802
- 0.838
- 0.875
- 0.784
- 0.745
- 0.764
- 0.755
- 0.74
- 0.697
- 0.713
- 0.671
- 0.665
- 0.629
- 0.62
- 0.635
- 0.603
- 0.617
- 0.585
- 0.545
- 0.556
- 0.523
- 0.52
- 0.567
- 0.52
- 0.504
- 0.502
- 0.486
- 0.447
- 0.445
- 0.454
- 0.444
- 0.483
- 0.413
- 0.452
- 0.416
- 0.424
- 0.391
- 0.389
- 0.416
- 0.385
unequal: 0
verbose: 1
