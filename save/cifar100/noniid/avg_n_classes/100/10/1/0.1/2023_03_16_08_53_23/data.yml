avg_train_accuracy: 0.276
avg_train_loss: 0.012
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0431
- 0.0867
- 0.1034
- 0.114
- 0.1245
- 0.1287
- 0.1338
- 0.1417
- 0.0457
- 0.1454
- 0.1638
- 0.1604
- 0.1682
- 0.0487
- 0.1636
- 0.1698
- 0.186
- 0.1825
- 0.199
- 0.209
- 0.2075
- 0.2111
- 0.2125
- 0.222
- 0.2134
- 0.2212
- 0.2272
- 0.2199
- 0.2225
- 0.0555
- 0.2336
- 0.2185
- 0.2287
- 0.2269
- 0.2243
- 0.2245
- 0.2367
- 0.2408
- 0.2402
- 0.2365
- 0.2481
- 0.2397
- 0.2478
- 0.2519
- 0.2592
- 0.2597
- 0.2633
- 0.2657
- 0.2607
- 0.0665
- 0.269
- 0.2683
- 0.2448
- 0.2634
- 0.2717
- 0.2572
- 0.2696
- 0.2706
- 0.2743
- 0.27
- 0.2809
- 0.27
- 0.2807
- 0.286
- 0.2761
- 0.0744
- 0.2833
- 0.274
- 0.2795
- 0.2685
- 0.2859
- 0.2816
- 0.279
- 0.2846
- 0.2832
- 0.0764
- 0.2852
- 0.2846
- 0.0783
- 0.2867
- 0.2913
- 0.2911
- 0.2906
- 0.2861
- 0.2933
- 0.2875
- 0.2906
- 0.2883
- 0.287
- 0.292
- 0.2933
- 0.2981
- 0.2943
- 0.2985
- 0.3007
- 0.2984
- 0.2947
- 0.2982
- 0.0867
- 0.2957
test_loss_list:
- 1.8085620832443237
- 1.722224431037903
- 1.698378381729126
- 1.6863785147666932
- 1.669895474910736
- 1.682236840724945
- 1.6904031944274902
- 1.6495326781272888
- 3.113175029754639
- 1.535132098197937
- 1.5338604378700256
- 1.5396991658210755
- 1.541275281906128
- 2.995348892211914
- 1.4955782508850097
- 1.4950425577163697
- 1.4852372694015503
- 1.5132784342765808
- 1.4724141812324525
- 1.4660470366477967
- 1.4709490847587585
- 1.4609365129470826
- 1.4684587383270264
- 1.455971004962921
- 1.4851937007904052
- 1.4760121536254882
- 1.4730073952674865
- 1.4657670545578003
- 1.472447166442871
- 2.7870138835906983
- 1.3508305191993712
- 1.3998000717163086
- 1.3877959275245666
- 1.4215583395957947
- 1.4442276239395142
- 1.4381604814529418
- 1.4208594965934753
- 1.4060056138038635
- 1.4089863443374633
- 1.4255742239952087
- 1.416566207408905
- 1.4373864245414734
- 1.4083720993995668
- 1.4101741981506348
- 1.395611696243286
- 1.3883339428901673
- 1.4005921506881713
- 1.4005972409248353
- 1.4239245891571044
- 2.6685449123382567
- 1.2845960116386415
- 1.3059345555305482
- 1.404739053249359
- 1.3419740319252014
- 1.33043119430542
- 1.3713752985000611
- 1.347487976551056
- 1.3479539728164673
- 1.350941128730774
- 1.3576971864700318
- 1.34446631193161
- 1.376460416316986
- 1.3567491102218627
- 1.3733171892166138
- 1.3823859643936158
- 2.5933801174163817
- 1.2734778881073
- 1.2964983439445497
- 1.3010851454734802
- 1.3400610613822936
- 1.312473168373108
- 1.3171905159950257
- 1.3350880861282348
- 1.329014437198639
- 1.3381263065338134
- 2.543334069252014
- 1.2701934313774108
- 1.2770445513725281
- 2.5155502700805665
- 1.2660087609291077
- 1.2655452632904052
- 1.2766961550712586
- 1.2879310941696167
- 1.3268030762672425
- 1.3064421463012694
- 1.3535307049751282
- 1.3221672439575196
- 1.3439050269126893
- 1.32981342792511
- 1.3322271800041199
- 1.3415732717514037
- 1.345092031955719
- 1.3525105381011964
- 1.3432457971572875
- 1.3440038871765136
- 1.3578040051460265
- 1.3603382754325866
- 1.3625986766815186
- 2.464940810203552
- 1.2701155185699462
train_accuracy:
- 0.061
- 0.069
- 0.112
- 0.113
- 0.13
- 0.15
- 0.156
- 0.132
- 0.0
- 0.145
- 0.156
- 0.173
- 0.191
- 0.0
- 0.189
- 0.162
- 0.156
- 0.154
- 0.222
- 0.191
- 0.193
- 0.228
- 0.237
- 0.213
- 0.22
- 0.22
- 0.228
- 0.215
- 0.217
- 0.0
- 0.229
- 0.205
- 0.25
- 0.232
- 0.232
- 0.244
- 0.234
- 0.241
- 0.269
- 0.257
- 0.214
- 0.209
- 0.263
- 0.241
- 0.249
- 0.282
- 0.276
- 0.27
- 0.278
- 0.0
- 0.275
- 0.284
- 0.234
- 0.278
- 0.301
- 0.245
- 0.294
- 0.266
- 0.299
- 0.305
- 0.271
- 0.259
- 0.291
- 0.318
- 0.265
- 0.0
- 0.291
- 0.283
- 0.315
- 0.283
- 0.347
- 0.303
- 0.316
- 0.271
- 0.298
- 0.0
- 0.306
- 0.267
- 0.0
- 0.32
- 0.304
- 0.285
- 0.295
- 0.292
- 0.33
- 0.312
- 0.293
- 0.326
- 0.32
- 0.324
- 0.316
- 0.322
- 0.267
- 0.3
- 0.323
- 0.314
- 0.317
- 0.292
- 0.0
- 0.276
train_loss:
- 4.226
- 3.776
- 3.62
- 3.208
- 3.15
- 2.756
- 2.468
- 3.278
- 1.881
- 3.518
- 3.154
- 2.745
- 2.896
- 1.419
- 2.677
- 2.736
- 2.867
- 2.343
- 2.851
- 2.625
- 2.81
- 2.264
- 2.398
- 2.4
- 1.908
- 2.21
- 1.968
- 2.492
- 1.882
- 1.318
- 2.535
- 1.733
- 2.202
- 1.655
- 1.652
- 1.232
- 2.22
- 2.119
- 2.105
- 1.512
- 2.299
- 1.79
- 1.659
- 1.366
- 1.821
- 1.774
- 1.677
- 1.775
- 1.293
- 1.167
- 1.688
- 1.503
- 1.856
- 1.209
- 1.191
- 1.473
- 0.932
- 1.333
- 1.282
- 1.522
- 1.509
- 0.96
- 1.409
- 1.066
- 0.903
- 0.959
- 1.02
- 1.16
- 0.954
- 0.58
- 1.276
- 1.138
- 1.184
- 1.478
- 0.856
- 0.784
- 0.743
- 0.96
- 0.572
- 1.277
- 0.945
- 1.149
- 0.689
- 0.821
- 0.87
- 0.495
- 0.675
- 0.912
- 0.96
- 0.671
- 0.389
- 0.547
- 1.339
- 0.788
- 0.45
- 0.479
- 0.468
- 0.37
- 0.737
- 1.215
unequal: 0
verbose: 1
