avg_train_accuracy: 0.285
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0413
- 0.0924
- 0.1067
- 0.1199
- 0.127
- 0.1396
- 0.1403
- 0.1523
- 0.157
- 0.1619
- 0.169
- 0.1744
- 0.1811
- 0.187
- 0.049
- 0.1867
- 0.1893
- 0.1947
- 0.2032
- 0.2043
- 0.2053
- 0.2066
- 0.2089
- 0.2072
- 0.0523
- 0.2226
- 0.2271
- 0.2198
- 0.227
- 0.228
- 0.2242
- 0.2386
- 0.24
- 0.2488
- 0.0572
- 0.0576
- 0.0566
- 0.2531
- 0.0653
- 0.2505
- 0.0642
- 0.2376
- 0.2573
- 0.2534
- 0.2494
- 0.2618
- 0.265
- 0.0701
- 0.2606
- 0.2601
- 0.2591
- 0.2559
- 0.2556
- 0.2626
- 0.2662
- 0.0719
- 0.2679
- 0.2618
- 0.2595
- 0.2711
- 0.2749
- 0.2769
- 0.2794
- 0.2727
- 0.276
- 0.2783
- 0.286
- 0.2875
- 0.0812
- 0.2843
- 0.2821
- 0.2894
- 0.2849
- 0.2895
- 0.2911
- 0.281
- 0.2816
- 0.2941
- 0.2891
- 0.2899
- 0.282
- 0.0853
- 0.079
- 0.2954
- 0.2925
- 0.2979
- 0.2928
- 0.2927
- 0.2905
- 0.2935
- 0.0901
- 0.3067
- 0.2948
- 0.2835
- 0.303
- 0.2995
- 0.2989
- 0.304
- 0.2907
- 0.2991
test_loss_list:
- 1.8276938486099243
- 1.7384126996994018
- 1.7049456596374513
- 1.666626706123352
- 1.6690141463279724
- 1.6472537589073182
- 1.6318073821067811
- 1.6283710169792176
- 1.6093360519409179
- 1.6029151844978333
- 1.6036961388587951
- 1.5995316195487976
- 1.5801829767227173
- 1.5778821635246276
- 3.1018119859695434
- 1.4532933354377746
- 1.4709737873077393
- 1.4640333223342896
- 1.471391134262085
- 1.4816982007026673
- 1.4685669660568237
- 1.4811138772964478
- 1.483998486995697
- 1.4901720237731935
- 2.983673667907715
- 1.3764220595359802
- 1.3749607801437378
- 1.4080098390579223
- 1.4020839524269104
- 1.4157668924331666
- 1.429858512878418
- 1.4111309051513672
- 1.420720443725586
- 1.3960454511642455
- 2.8409510135650633
- 3.058308734893799
- 3.194347438812256
- 1.3113107347488404
- 2.7266576004028322
- 1.3073848295211792
- 2.6540966844558715
- 1.346192889213562
- 1.3136593222618103
- 1.3436990571022034
- 1.3478300762176514
- 1.3393845200538634
- 1.3470902729034424
- 2.5946753311157225
- 1.2966230154037475
- 1.3257638120651245
- 1.3325809288024901
- 1.3644624900817872
- 1.3470996046066284
- 1.3508234810829163
- 1.3453107643127442
- 2.55136905670166
- 1.2938521790504456
- 1.3118358087539672
- 1.3526814365386963
- 1.3224451780319213
- 1.3209597039222718
- 1.3260800552368164
- 1.3282144999504089
- 1.3544167399406433
- 1.3447797727584838
- 1.3261083030700684
- 1.3249687600135802
- 1.3333389973640442
- 2.4793540477752685
- 1.2726753306388856
- 1.2928658866882323
- 1.2918025541305542
- 1.2992297410964966
- 1.3082170248031617
- 1.30666526556015
- 1.3201563358306885
- 1.3318899917602538
- 1.3137252044677734
- 1.3381480646133423
- 1.3342793202400207
- 1.3479798102378846
- 2.45587251663208
- 2.6741808795928956
- 1.2520004892349244
- 1.27046391248703
- 1.2672795605659486
- 1.2891327738761902
- 1.2940197706222534
- 1.3042488074302674
- 1.3250057673454285
- 2.4064125537872316
- 1.2339735341072082
- 1.267092490196228
- 1.3047319531440735
- 1.2859744215011597
- 1.2963093256950378
- 1.2979623746871949
- 1.3006547689437866
- 1.3121044540405273
- 1.306230251789093
train_accuracy:
- 0.063
- 0.074
- 0.07
- 0.114
- 0.134
- 0.109
- 0.139
- 0.12
- 0.191
- 0.164
- 0.194
- 0.176
- 0.18
- 0.192
- 0.0
- 0.159
- 0.192
- 0.23
- 0.188
- 0.187
- 0.262
- 0.189
- 0.189
- 0.187
- 0.0
- 0.255
- 0.211
- 0.207
- 0.207
- 0.238
- 0.22
- 0.239
- 0.225
- 0.282
- 0.0
- 0.0
- 0.0
- 0.233
- 0.0
- 0.215
- 0.0
- 0.213
- 0.243
- 0.247
- 0.264
- 0.236
- 0.263
- 0.0
- 0.282
- 0.267
- 0.289
- 0.227
- 0.252
- 0.248
- 0.253
- 0.0
- 0.251
- 0.241
- 0.251
- 0.258
- 0.26
- 0.266
- 0.251
- 0.269
- 0.251
- 0.259
- 0.282
- 0.287
- 0.0
- 0.268
- 0.346
- 0.285
- 0.315
- 0.269
- 0.282
- 0.265
- 0.291
- 0.279
- 0.281
- 0.291
- 0.283
- 0.0
- 0.0
- 0.276
- 0.286
- 0.289
- 0.279
- 0.27
- 0.31
- 0.275
- 0.0
- 0.29
- 0.284
- 0.303
- 0.304
- 0.289
- 0.277
- 0.297
- 0.322
- 0.285
train_loss:
- 4.253
- 3.828
- 3.61
- 3.479
- 3.263
- 3.347
- 3.225
- 3.021
- 3.07
- 3.121
- 2.668
- 2.813
- 2.974
- 2.462
- 1.882
- 2.938
- 2.83
- 2.42
- 2.214
- 2.675
- 2.099
- 2.446
- 2.525
- 2.327
- 1.392
- 2.808
- 2.528
- 2.003
- 2.53
- 2.118
- 1.671
- 1.989
- 2.093
- 2.091
- 1.169
- 0.509
- 0.416
- 2.101
- 0.586
- 2.327
- 0.526
- 1.807
- 1.773
- 1.269
- 1.816
- 2.036
- 1.58
- 0.662
- 1.645
- 1.248
- 1.183
- 1.042
- 2.011
- 1.805
- 1.58
- 0.623
- 1.508
- 1.232
- 0.881
- 1.722
- 1.107
- 1.468
- 0.859
- 1.075
- 1.68
- 1.408
- 1.592
- 0.883
- 0.634
- 0.777
- 1.666
- 0.584
- 1.195
- 0.43
- 0.865
- 1.242
- 1.175
- 0.488
- 0.911
- 0.662
- 1.303
- 0.588
- 0.157
- 1.181
- 1.382
- 0.514
- 0.95
- 0.757
- 0.997
- 0.876
- 0.458
- 0.552
- 0.834
- 0.788
- 0.668
- 0.684
- 0.744
- 0.499
- 1.071
- 0.565
unequal: 0
verbose: 1
