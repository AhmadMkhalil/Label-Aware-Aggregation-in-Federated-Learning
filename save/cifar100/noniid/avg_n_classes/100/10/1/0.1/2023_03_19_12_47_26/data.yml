avg_train_accuracy: 0.334
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0465
- 0.0797
- 0.1098
- 0.1164
- 0.1219
- 0.0445
- 0.0485
- 0.1388
- 0.1379
- 0.1532
- 0.1582
- 0.167
- 0.1766
- 0.1762
- 0.1813
- 0.1923
- 0.0539
- 0.1926
- 0.203
- 0.1965
- 0.2094
- 0.0538
- 0.2016
- 0.211
- 0.2237
- 0.2125
- 0.2042
- 0.2211
- 0.228
- 0.233
- 0.2306
- 0.0618
- 0.2333
- 0.2329
- 0.2348
- 0.2381
- 0.2422
- 0.2325
- 0.2376
- 0.2437
- 0.2485
- 0.2455
- 0.244
- 0.2487
- 0.2521
- 0.2604
- 0.2542
- 0.2554
- 0.2678
- 0.2614
- 0.2627
- 0.0659
- 0.2711
- 0.2768
- 0.2685
- 0.2757
- 0.2708
- 0.2715
- 0.271
- 0.2722
- 0.2821
- 0.2768
- 0.0765
- 0.2852
- 0.0781
- 0.071
- 0.2737
- 0.2894
- 0.2865
- 0.2805
- 0.2926
- 0.2818
- 0.287
- 0.2896
- 0.2869
- 0.2866
- 0.2956
- 0.2921
- 0.2899
- 0.2941
- 0.2891
- 0.087
- 0.3015
- 0.2963
- 0.3047
- 0.2979
- 0.0932
- 0.2982
- 0.3037
- 0.3025
- 0.2917
- 0.2997
- 0.0953
- 0.3031
- 0.2873
- 0.2996
- 0.0985
- 0.3109
- 0.3125
- 0.298
test_loss_list:
- 1.8045883655548096
- 1.7332262802124023
- 1.7042767667770387
- 1.6664863801002503
- 1.6435581493377684
- 3.100453176498413
- 3.3431383323669435
- 1.54881267786026
- 1.5571289944648743
- 1.5466343212127684
- 1.5477595329284668
- 1.543924973011017
- 1.5289047503471374
- 1.5414425039291382
- 1.5347742223739624
- 1.5264758849143982
- 2.901843032836914
- 1.4232931637763977
- 1.4326399636268616
- 1.4489025235176087
- 1.467583291530609
- 2.8192897748947146
- 1.4025911974906922
- 1.4020237302780152
- 1.394752106666565
- 1.4173057198524475
- 1.4509452033042907
- 1.435023329257965
- 1.4273022079467774
- 1.4135470724105834
- 1.4221225309371948
- 2.723303632736206
- 1.3546271133422851
- 1.3666565322875976
- 1.3696217560768127
- 1.3704843783378602
- 1.385564534664154
- 1.3914488005638121
- 1.3999367928504944
- 1.4029179406166077
- 1.3860023784637452
- 1.3992748475074768
- 1.4109970927238464
- 1.4084801435470582
- 1.4062721037864685
- 1.3961839652061463
- 1.402166829109192
- 1.3994514012336732
- 1.3919192457199097
- 1.3874904370307923
- 1.3980512595176697
- 2.581524066925049
- 1.2782311034202576
- 1.2924607992172241
- 1.3147022366523742
- 1.313897557258606
- 1.3252665400505066
- 1.3315358638763428
- 1.3267090106010437
- 1.3350644946098327
- 1.3243774604797363
- 1.3415057754516602
- 2.56116762638092
- 1.253978123664856
- 2.5286116933822633
- 2.70028151512146
- 1.2765093016624451
- 1.2477165508270263
- 1.2772714948654176
- 1.2969260025024414
- 1.2836909341812133
- 1.3131457257270813
- 1.31955429315567
- 1.3142721486091613
- 1.3239406251907349
- 1.3315497207641602
- 1.3128913378715514
- 1.3379897499084472
- 1.3424810528755189
- 1.3408172392845155
- 1.3417602372169495
- 2.4406559610366823
- 1.2377024269104004
- 1.2577044177055359
- 1.2573635530471803
- 1.280450966358185
- 2.372137088775635
- 1.2402898645401002
- 1.2567696738243104
- 1.2561718392372132
- 1.281650309562683
- 1.2783267903327942
- 2.3352945852279663
- 1.2450923562049865
- 1.288745939731598
- 1.2713090014457702
- 2.342094612121582
- 1.2396255469322204
- 1.2386477756500245
- 1.271270158290863
train_accuracy:
- 0.077
- 0.09
- 0.096
- 0.127
- 0.073
- 0.0
- 0.0
- 0.128
- 0.097
- 0.149
- 0.178
- 0.166
- 0.16
- 0.189
- 0.174
- 0.181
- 0.0
- 0.168
- 0.203
- 0.151
- 0.196
- 0.0
- 0.169
- 0.208
- 0.221
- 0.171
- 0.181
- 0.233
- 0.233
- 0.199
- 0.227
- 0.0
- 0.216
- 0.252
- 0.266
- 0.219
- 0.245
- 0.237
- 0.265
- 0.227
- 0.206
- 0.287
- 0.218
- 0.24
- 0.265
- 0.279
- 0.268
- 0.281
- 0.292
- 0.29
- 0.277
- 0.0
- 0.295
- 0.256
- 0.277
- 0.293
- 0.235
- 0.299
- 0.301
- 0.275
- 0.295
- 0.261
- 0.0
- 0.28
- 0.0
- 0.0
- 0.32
- 0.297
- 0.315
- 0.261
- 0.302
- 0.324
- 0.304
- 0.285
- 0.293
- 0.275
- 0.352
- 0.305
- 0.282
- 0.321
- 0.31
- 0.0
- 0.295
- 0.278
- 0.329
- 0.34
- 0.0
- 0.304
- 0.329
- 0.306
- 0.32
- 0.318
- 0.0
- 0.315
- 0.261
- 0.289
- 0.0
- 0.343
- 0.311
- 0.334
train_loss:
- 4.276
- 3.789
- 3.62
- 3.494
- 3.428
- 1.935
- 1.002
- 3.738
- 3.052
- 3.19
- 3.235
- 2.914
- 2.893
- 2.824
- 2.856
- 2.932
- 1.394
- 2.921
- 2.674
- 2.299
- 2.542
- 1.087
- 2.307
- 2.621
- 2.691
- 1.855
- 1.478
- 2.277
- 2.231
- 2.32
- 2.353
- 1.047
- 2.072
- 1.965
- 2.38
- 1.58
- 1.713
- 2.243
- 1.983
- 1.454
- 1.37
- 1.67
- 1.118
- 1.281
- 1.657
- 2.02
- 1.488
- 1.356
- 1.899
- 1.424
- 1.862
- 1.042
- 1.349
- 1.865
- 1.305
- 1.266
- 1.137
- 1.046
- 1.521
- 1.301
- 0.885
- 0.928
- 0.816
- 2.121
- 0.541
- 0.233
- 1.792
- 0.813
- 1.101
- 0.817
- 0.663
- 0.893
- 1.063
- 1.141
- 0.766
- 0.812
- 0.869
- 0.654
- 1.181
- 0.663
- 1.489
- 0.685
- 1.057
- 0.758
- 0.709
- 0.599
- 0.473
- 1.699
- 1.174
- 1.06
- 0.676
- 0.78
- 0.466
- 0.914
- 0.856
- 0.69
- 0.387
- 1.057
- 0.551
- 0.349
unequal: 0
verbose: 1
