avg_train_accuracy: 0.273
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0353
- 0.0727
- 0.0857
- 0.1187
- 0.1153
- 0.1363
- 0.1248
- 0.1442
- 0.1537
- 0.1669
- 0.1599
- 0.0461
- 0.1645
- 0.1777
- 0.0491
- 0.1843
- 0.0524
- 0.1851
- 0.0556
- 0.1758
- 0.1795
- 0.0573
- 0.057
- 0.1972
- 0.1959
- 0.2059
- 0.2134
- 0.2166
- 0.061
- 0.2213
- 0.2184
- 0.2159
- 0.2118
- 0.0609
- 0.222
- 0.2335
- 0.2349
- 0.2254
- 0.2248
- 0.2397
- 0.2338
- 0.2382
- 0.2217
- 0.2351
- 0.2485
- 0.0654
- 0.2435
- 0.2408
- 0.2439
- 0.2528
- 0.255
- 0.2455
- 0.2433
- 0.0679
- 0.2517
- 0.2477
- 0.2639
- 0.253
- 0.2631
- 0.2569
- 0.2654
- 0.268
- 0.2642
- 0.2695
- 0.2616
- 0.2596
- 0.263
- 0.2646
- 0.2626
- 0.2693
- 0.262
- 0.2721
- 0.2672
- 0.2713
- 0.2844
- 0.2757
- 0.2813
- 0.2801
- 0.285
- 0.2824
- 0.2848
- 0.2828
- 0.285
- 0.2882
- 0.2758
- 0.2861
- 0.2885
- 0.2939
- 0.2943
- 0.2977
- 0.2916
- 0.2904
- 0.2874
- 0.2969
- 0.0799
- 0.302
- 0.3
- 0.2959
- 0.0901
- 0.2978
test_loss_list:
- 1.8234634065628053
- 1.7655825328826904
- 1.730626139640808
- 1.6834789443016052
- 1.6849210786819457
- 1.659887855052948
- 1.672327151298523
- 1.6496390652656556
- 1.6442055296897888
- 1.6250987076759338
- 1.614487566947937
- 3.0648508405685426
- 1.501949679851532
- 1.5099643397331237
- 3.118701295852661
- 1.454201216697693
- 3.036851906776428
- 1.4553532433509826
- 2.912418875694275
- 1.4461627793312073
- 1.4692694067955017
- 2.883564443588257
- 3.0975925588607787
- 1.4154931449890136
- 1.4324220418930054
- 1.4295240354537964
- 1.4220942950248718
- 1.4330957651138305
- 2.7546098709106444
- 1.3688601970672607
- 1.3981950211524963
- 1.405496916770935
- 1.436540710926056
- 2.73555814743042
- 1.3726349234580995
- 1.3722752690315247
- 1.3757045197486877
- 1.4005783224105834
- 1.4089934396743775
- 1.3854862976074218
- 1.4059602451324462
- 1.406808476448059
- 1.4391078209877015
- 1.4264134788513183
- 1.408155264854431
- 2.6508892822265624
- 1.3214012002944946
- 1.3499144291877747
- 1.3609262228012085
- 1.3479273772239686
- 1.3526634502410888
- 1.3882730937004089
- 1.3968126392364502
- 2.6321841716766357
- 1.3238946032524108
- 1.3485183095932007
- 1.327106215953827
- 1.3401125645637513
- 1.343038718700409
- 1.3637205934524537
- 1.3493060159683228
- 1.3625002336502074
- 1.3673319697380066
- 1.3682576942443847
- 1.3773376512527467
- 1.4050109934806825
- 1.3721810746192933
- 1.3697744393348694
- 1.4041269755363464
- 1.384510600566864
- 1.3958271837234497
- 1.3771310591697692
- 1.382580623626709
- 1.3827105617523194
- 1.3673598623275758
- 1.38830313205719
- 1.3687987279891969
- 1.377404706478119
- 1.3726158571243285
- 1.3749652528762817
- 1.3736104345321656
- 1.3752491927146913
- 1.3778316807746886
- 1.3706445837020873
- 1.4210704255104065
- 1.3949402594566345
- 1.3953650617599487
- 1.3883259057998658
- 1.3700198316574097
- 1.3695721459388732
- 1.4039141893386842
- 1.3972566676139833
- 1.393283772468567
- 1.3837139892578125
- 2.5025597047805785
- 1.249059908390045
- 1.2725110936164856
- 1.2850473260879516
- 2.430623016357422
- 1.2570816802978515
train_accuracy:
- 0.036
- 0.076
- 0.081
- 0.098
- 0.099
- 0.115
- 0.129
- 0.128
- 0.142
- 0.155
- 0.169
- 0.0
- 0.158
- 0.166
- 0.0
- 0.176
- 0.0
- 0.163
- 0.0
- 0.17
- 0.199
- 0.0
- 0.0
- 0.191
- 0.172
- 0.227
- 0.198
- 0.261
- 0.0
- 0.228
- 0.191
- 0.254
- 0.251
- 0.0
- 0.249
- 0.247
- 0.239
- 0.225
- 0.24
- 0.265
- 0.264
- 0.242
- 0.24
- 0.265
- 0.261
- 0.0
- 0.219
- 0.261
- 0.279
- 0.295
- 0.238
- 0.269
- 0.266
- 0.0
- 0.283
- 0.269
- 0.31
- 0.273
- 0.262
- 0.288
- 0.308
- 0.318
- 0.287
- 0.326
- 0.236
- 0.252
- 0.267
- 0.266
- 0.246
- 0.302
- 0.295
- 0.28
- 0.327
- 0.3
- 0.275
- 0.259
- 0.269
- 0.352
- 0.299
- 0.34
- 0.301
- 0.295
- 0.282
- 0.33
- 0.263
- 0.265
- 0.281
- 0.282
- 0.319
- 0.301
- 0.269
- 0.34
- 0.334
- 0.339
- 0.0
- 0.283
- 0.35
- 0.286
- 0.0
- 0.273
train_loss:
- 4.355
- 3.927
- 3.714
- 3.531
- 3.415
- 3.187
- 3.27
- 2.966
- 2.845
- 2.97
- 3.108
- 1.946
- 3.336
- 2.62
- 1.326
- 2.882
- 1.012
- 2.887
- 0.901
- 3.21
- 2.871
- 0.866
- 0.434
- 2.591
- 2.551
- 2.286
- 2.298
- 2.671
- 0.837
- 2.708
- 2.168
- 2.24
- 1.776
- 0.743
- 2.59
- 2.06
- 2.016
- 1.535
- 2.436
- 2.373
- 1.812
- 2.013
- 1.503
- 1.679
- 1.832
- 0.817
- 2.142
- 2.012
- 1.483
- 1.577
- 1.615
- 1.317
- 0.954
- 0.679
- 2.038
- 1.259
- 1.565
- 1.577
- 1.925
- 1.206
- 1.215
- 1.265
- 0.931
- 0.973
- 1.744
- 1.169
- 1.489
- 0.96
- 1.105
- 0.965
- 1.165
- 0.951
- 1.145
- 1.356
- 1.379
- 1.076
- 0.832
- 1.053
- 1.581
- 0.95
- 0.987
- 1.144
- 1.128
- 0.773
- 0.794
- 0.954
- 0.794
- 0.648
- 1.046
- 0.596
- 0.548
- 0.812
- 0.894
- 0.687
- 0.842
- 0.695
- 0.951
- 0.764
- 0.448
- 0.632
unequal: 0
verbose: 1
