avg_train_accuracy: 0.311
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0429
- 0.0784
- 0.0998
- 0.1099
- 0.1364
- 0.1398
- 0.1449
- 0.1475
- 0.1615
- 0.1682
- 0.1725
- 0.1787
- 0.0462
- 0.1759
- 0.0482
- 0.0535
- 0.179
- 0.1945
- 0.1997
- 0.1955
- 0.2
- 0.1964
- 0.2032
- 0.2049
- 0.2105
- 0.219
- 0.2223
- 0.225
- 0.2287
- 0.2206
- 0.2296
- 0.2351
- 0.2297
- 0.2352
- 0.2414
- 0.2371
- 0.24
- 0.2402
- 0.2422
- 0.2439
- 0.2472
- 0.253
- 0.248
- 0.258
- 0.2448
- 0.2547
- 0.2568
- 0.2508
- 0.2719
- 0.27
- 0.2632
- 0.2677
- 0.0594
- 0.2573
- 0.2713
- 0.2684
- 0.0678
- 0.0662
- 0.2584
- 0.2719
- 0.2723
- 0.2745
- 0.2745
- 0.2673
- 0.2782
- 0.2706
- 0.2793
- 0.2721
- 0.2698
- 0.2834
- 0.2818
- 0.0752
- 0.2796
- 0.2837
- 0.2802
- 0.2739
- 0.2887
- 0.2907
- 0.2886
- 0.2866
- 0.2779
- 0.0815
- 0.2959
- 0.2875
- 0.293
- 0.297
- 0.2994
- 0.293
- 0.3003
- 0.0893
- 0.2975
- 0.3024
- 0.3021
- 0.3036
- 0.2994
- 0.2911
- 0.3001
- 0.3009
- 0.2879
- 0.3026
test_loss_list:
- 1.810660433769226
- 1.7689370536804199
- 1.7228262901306153
- 1.6866108894348144
- 1.665607328414917
- 1.664384021759033
- 1.6571561551094056
- 1.6608077359199525
- 1.6223307371139526
- 1.6089377474784852
- 1.6261261129379272
- 1.6097953367233275
- 3.1475156021118162
- 1.495508804321289
- 3.0741945362091063
- 3.3192468738555907
- 1.4629156541824342
- 1.4455290532112122
- 1.4745647716522217
- 1.4790817499160767
- 1.4787905859947204
- 1.4914576315879822
- 1.4716576290130616
- 1.4766695404052734
- 1.461095986366272
- 1.4750810766220093
- 1.4631738185882568
- 1.4541697764396668
- 1.4494072318077087
- 1.482672734260559
- 1.4637208557128907
- 1.4594973850250244
- 1.4741511368751525
- 1.4738299608230592
- 1.454538733959198
- 1.4636025762557983
- 1.4614800786972046
- 1.472193500995636
- 1.4706734919548035
- 1.4633821415901185
- 1.4541711807250977
- 1.4548582696914674
- 1.45790146112442
- 1.4553181433677673
- 1.4820746064186097
- 1.4662463212013244
- 1.46261465549469
- 1.477564935684204
- 1.4392074847221374
- 1.4323134732246399
- 1.4519008803367615
- 1.4481893491744995
- 2.8188096570968626
- 1.3314480328559875
- 1.3219044232368469
- 1.348237192630768
- 2.7336377477645875
- 2.9397234439849855
- 1.3245574045181274
- 1.3024115943908692
- 1.338509783744812
- 1.324359760284424
- 1.3274046421051025
- 1.3577689456939697
- 1.3527391171455383
- 1.3782828855514526
- 1.3486094379425049
- 1.3675382661819457
- 1.39278480052948
- 1.3760864853858947
- 1.3640204453468323
- 2.6165938997268676
- 1.2818684339523316
- 1.3031448388099671
- 1.3306235361099243
- 1.3522529911994934
- 1.318741660118103
- 1.3192341470718383
- 1.3413790655136109
- 1.33497013092041
- 1.3839764046669005
- 2.539957251548767
- 1.2465436720848084
- 1.284424045085907
- 1.3095406222343444
- 1.2909329152107238
- 1.2947510027885436
- 1.321080892086029
- 1.3090773844718933
- 2.4471305656433104
- 1.2475918817520142
- 1.2844149231910706
- 1.2877917098999023
- 1.2796759843826293
- 1.3139632320404053
- 1.3284474277496339
- 1.3206508088111877
- 1.324899582862854
- 1.3497543787956239
- 1.3289663147926332
train_accuracy:
- 0.024
- 0.062
- 0.085
- 0.119
- 0.146
- 0.107
- 0.143
- 0.15
- 0.191
- 0.188
- 0.122
- 0.227
- 0.0
- 0.203
- 0.0
- 0.0
- 0.199
- 0.216
- 0.199
- 0.243
- 0.147
- 0.214
- 0.249
- 0.191
- 0.257
- 0.258
- 0.244
- 0.266
- 0.252
- 0.251
- 0.273
- 0.269
- 0.224
- 0.276
- 0.25
- 0.263
- 0.259
- 0.261
- 0.228
- 0.236
- 0.253
- 0.312
- 0.27
- 0.298
- 0.289
- 0.263
- 0.312
- 0.268
- 0.26
- 0.311
- 0.32
- 0.328
- 0.0
- 0.295
- 0.283
- 0.322
- 0.0
- 0.0
- 0.288
- 0.321
- 0.287
- 0.317
- 0.31
- 0.324
- 0.287
- 0.283
- 0.279
- 0.337
- 0.319
- 0.314
- 0.275
- 0.0
- 0.333
- 0.281
- 0.287
- 0.311
- 0.285
- 0.299
- 0.31
- 0.342
- 0.286
- 0.0
- 0.297
- 0.351
- 0.385
- 0.342
- 0.307
- 0.312
- 0.308
- 0.0
- 0.348
- 0.296
- 0.38
- 0.312
- 0.287
- 0.288
- 0.376
- 0.286
- 0.291
- 0.311
train_loss:
- 4.256
- 3.434
- 3.695
- 3.513
- 3.389
- 2.927
- 2.929
- 2.526
- 3.182
- 2.868
- 2.574
- 2.956
- 1.867
- 2.813
- 1.199
- 0.687
- 3.275
- 2.672
- 2.392
- 2.776
- 2.316
- 2.489
- 2.422
- 2.712
- 2.712
- 2.28
- 2.278
- 2.023
- 2.325
- 1.851
- 1.98
- 1.986
- 2.267
- 1.682
- 2.288
- 1.733
- 1.815
- 1.563
- 2.003
- 1.946
- 1.543
- 1.499
- 1.487
- 1.563
- 1.149
- 1.706
- 1.006
- 2.031
- 1.654
- 1.389
- 1.321
- 1.34
- 1.322
- 1.274
- 1.154
- 1.034
- 0.82
- 0.378
- 1.965
- 0.948
- 1.344
- 1.689
- 1.234
- 0.754
- 1.087
- 0.687
- 1.064
- 0.815
- 0.507
- 1.354
- 1.676
- 0.825
- 1.608
- 1.238
- 0.804
- 1.092
- 1.511
- 0.986
- 0.604
- 0.924
- 0.921
- 0.685
- 0.743
- 0.669
- 1.003
- 0.989
- 0.512
- 1.113
- 0.401
- 0.59
- 0.698
- 0.885
- 0.816
- 0.377
- 0.603
- 0.816
- 0.611
- 0.504
- 0.783
- 0.368
unequal: 0
verbose: 1
