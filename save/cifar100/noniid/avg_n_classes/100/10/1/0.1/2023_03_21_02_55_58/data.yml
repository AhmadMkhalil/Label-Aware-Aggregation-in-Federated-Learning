avg_train_accuracy: 0.319
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0431
- 0.0798
- 0.1062
- 0.1155
- 0.1381
- 0.1373
- 0.1495
- 0.1511
- 0.1483
- 0.1556
- 0.1476
- 0.1591
- 0.1722
- 0.1922
- 0.1851
- 0.1952
- 0.1851
- 0.1892
- 0.212
- 0.2045
- 0.2076
- 0.2116
- 0.2121
- 0.2197
- 0.2267
- 0.2135
- 0.2241
- 0.2226
- 0.2325
- 0.2237
- 0.2235
- 0.2293
- 0.2326
- 0.2321
- 0.2351
- 0.2443
- 0.2479
- 0.2482
- 0.2562
- 0.2511
- 0.2432
- 0.2423
- 0.2522
- 0.2493
- 0.2531
- 0.2571
- 0.2581
- 0.0567
- 0.2642
- 0.2575
- 0.258
- 0.2554
- 0.2647
- 0.2643
- 0.2737
- 0.2793
- 0.2684
- 0.269
- 0.27
- 0.2729
- 0.0679
- 0.2757
- 0.2725
- 0.2693
- 0.2803
- 0.2818
- 0.2714
- 0.2824
- 0.2817
- 0.2823
- 0.281
- 0.2837
- 0.2858
- 0.2881
- 0.284
- 0.2795
- 0.2664
- 0.2889
- 0.2824
- 0.2813
- 0.2959
- 0.2873
- 0.2786
- 0.2858
- 0.2931
- 0.2939
- 0.2986
- 0.2855
- 0.299
- 0.3023
- 0.2964
- 0.2957
- 0.2891
- 0.3014
- 0.2995
- 0.2934
- 0.2963
- 0.2912
- 0.2942
- 0.3018
test_loss_list:
- 1.8099808073043824
- 1.7408769035339355
- 1.721563277244568
- 1.6947085332870484
- 1.6486600875854491
- 1.6565523910522462
- 1.6447503185272216
- 1.658754470348358
- 1.6527378726005555
- 1.6600001430511475
- 1.6812254881858826
- 1.6371211791038514
- 1.6104395151138307
- 1.5912520790100098
- 1.5935223722457885
- 1.580977110862732
- 1.6223711681365967
- 1.599699728488922
- 1.5588103890419007
- 1.5588046717643738
- 1.5718445873260498
- 1.5651403522491456
- 1.5711226081848144
- 1.5387998127937317
- 1.5339607524871826
- 1.5442453670501708
- 1.5484709286689757
- 1.5525478267669677
- 1.5397373962402343
- 1.55961571931839
- 1.569438121318817
- 1.5428498029708861
- 1.527453863620758
- 1.5514108848571777
- 1.5439066243171693
- 1.5390742373466493
- 1.5157837176322937
- 1.5250327324867248
- 1.5185250735282898
- 1.5314744544029235
- 1.5541498780250549
- 1.5726719737052917
- 1.544863657951355
- 1.5344293189048768
- 1.531567850112915
- 1.5211167192459107
- 1.527289879322052
- 2.936305603981018
- 1.3061037683486938
- 1.3513722276687623
- 1.3719478917121888
- 1.3833505415916443
- 1.3731761193275451
- 1.398111891746521
- 1.3842942428588867
- 1.3623223733901977
- 1.387880766391754
- 1.3942925763130187
- 1.4198504757881165
- 1.4157832765579224
- 2.813034634590149
- 1.2849480414390564
- 1.3219934511184692
- 1.3476435780525207
- 1.3268406009674072
- 1.329778482913971
- 1.3638854432106018
- 1.354029438495636
- 1.3595044112205505
- 1.3622367906570434
- 1.37680734872818
- 1.3612516021728516
- 1.3854359436035155
- 1.3729005002975463
- 1.3898051691055298
- 1.414443964958191
- 1.4387210822105407
- 1.3716857409477234
- 1.3934235072135925
- 1.4158605527877808
- 1.380718321800232
- 1.4180107092857361
- 1.4417915320396424
- 1.4125318479537965
- 1.3977433824539185
- 1.404981644153595
- 1.3926077747344972
- 1.420238881111145
- 1.3966925287246703
- 1.3935931515693665
- 1.400346953868866
- 1.4039227390289306
- 1.4189083337783814
- 1.410059609413147
- 1.4194760751724242
- 1.4282466578483581
- 1.422670567035675
- 1.439276475906372
- 1.4229930448532104
- 1.4045829153060914
train_accuracy:
- 0.058
- 0.084
- 0.123
- 0.125
- 0.154
- 0.147
- 0.143
- 0.136
- 0.185
- 0.175
- 0.16
- 0.164
- 0.169
- 0.216
- 0.179
- 0.227
- 0.202
- 0.217
- 0.213
- 0.214
- 0.251
- 0.213
- 0.246
- 0.224
- 0.198
- 0.234
- 0.244
- 0.244
- 0.24
- 0.217
- 0.273
- 0.249
- 0.225
- 0.294
- 0.256
- 0.266
- 0.291
- 0.304
- 0.256
- 0.284
- 0.259
- 0.251
- 0.303
- 0.321
- 0.262
- 0.318
- 0.243
- 0.0
- 0.29
- 0.271
- 0.251
- 0.244
- 0.261
- 0.252
- 0.286
- 0.28
- 0.305
- 0.266
- 0.296
- 0.283
- 0.0
- 0.342
- 0.34
- 0.34
- 0.286
- 0.262
- 0.306
- 0.337
- 0.318
- 0.302
- 0.349
- 0.283
- 0.327
- 0.298
- 0.306
- 0.295
- 0.306
- 0.331
- 0.326
- 0.378
- 0.31
- 0.272
- 0.3
- 0.377
- 0.354
- 0.297
- 0.271
- 0.283
- 0.293
- 0.349
- 0.301
- 0.312
- 0.305
- 0.342
- 0.319
- 0.308
- 0.313
- 0.391
- 0.318
- 0.319
train_loss:
- 4.25
- 3.829
- 3.384
- 3.598
- 3.417
- 3.319
- 3.098
- 2.705
- 2.943
- 2.487
- 2.182
- 3.114
- 3.114
- 2.884
- 2.53
- 2.695
- 2.155
- 2.66
- 2.731
- 2.662
- 2.187
- 2.203
- 2.074
- 2.295
- 2.707
- 2.295
- 1.818
- 1.869
- 1.927
- 1.45
- 1.897
- 1.707
- 2.318
- 1.607
- 2.136
- 1.657
- 2.258
- 1.679
- 1.493
- 1.373
- 0.965
- 0.785
- 1.622
- 1.55
- 1.941
- 1.165
- 2.187
- 1.855
- 2.027
- 1.956
- 1.382
- 1.064
- 1.863
- 1.286
- 1.41
- 1.669
- 1.328
- 1.2
- 1.073
- 1.038
- 1.284
- 1.721
- 0.941
- 0.704
- 1.363
- 1.176
- 1.162
- 0.797
- 0.947
- 0.877
- 1.159
- 1.137
- 0.724
- 0.764
- 0.515
- 0.408
- 1.698
- 0.848
- 0.475
- 0.944
- 0.54
- 1.06
- 0.912
- 0.723
- 0.666
- 0.639
- 0.776
- 1.223
- 0.552
- 0.547
- 0.433
- 0.878
- 0.538
- 0.524
- 0.609
- 0.541
- 0.352
- 0.752
- 0.37
- 0.644
unequal: 0
verbose: 1
