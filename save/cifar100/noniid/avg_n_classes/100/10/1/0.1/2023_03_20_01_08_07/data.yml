avg_train_accuracy: 0.344
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0372
- 0.0721
- 0.098
- 0.1022
- 0.1203
- 0.136
- 0.1495
- 0.147
- 0.1532
- 0.1593
- 0.1659
- 0.1744
- 0.1716
- 0.1858
- 0.1876
- 0.1812
- 0.1913
- 0.1954
- 0.2006
- 0.2063
- 0.2027
- 0.2153
- 0.2272
- 0.2171
- 0.2168
- 0.2198
- 0.2304
- 0.2253
- 0.2282
- 0.2289
- 0.24
- 0.2306
- 0.2412
- 0.2466
- 0.0545
- 0.2419
- 0.0593
- 0.2401
- 0.2383
- 0.0604
- 0.2537
- 0.2499
- 0.2516
- 0.2535
- 0.2519
- 0.2498
- 0.2568
- 0.2658
- 0.2638
- 0.0683
- 0.2613
- 0.2717
- 0.2674
- 0.2646
- 0.2684
- 0.2702
- 0.2696
- 0.2706
- 0.2655
- 0.2712
- 0.2823
- 0.2823
- 0.2743
- 0.2847
- 0.2844
- 0.287
- 0.0725
- 0.0671
- 0.287
- 0.2854
- 0.2908
- 0.0742
- 0.2868
- 0.2869
- 0.2915
- 0.2926
- 0.2835
- 0.2914
- 0.2959
- 0.2841
- 0.2934
- 0.2949
- 0.2974
- 0.2835
- 0.2979
- 0.2862
- 0.2898
- 0.2995
- 0.2968
- 0.3058
- 0.2987
- 0.2922
- 0.298
- 0.2947
- 0.2965
- 0.3125
- 0.2963
- 0.3162
- 0.3049
- 0.311
test_loss_list:
- 2.8657820558547975
- 1.7521295690536498
- 1.6954873561859132
- 1.6918695306777953
- 1.6644849967956543
- 1.6138483715057372
- 1.602513747215271
- 1.606541907787323
- 1.591696741580963
- 1.5849567174911499
- 1.5841345691680908
- 1.5672158646583556
- 1.5759676790237427
- 1.552624225616455
- 1.5578812551498413
- 1.5771542119979858
- 1.5552706956863402
- 1.5557522535324098
- 1.5629678821563722
- 1.5361723279953003
- 1.5443492913246155
- 1.5321106100082398
- 1.5095569944381715
- 1.5207045984268188
- 1.5299659609794616
- 1.5147119545936585
- 1.5073343753814696
- 1.523992896080017
- 1.509477059841156
- 1.5112228083610535
- 1.5154604601860047
- 1.5221679425239563
- 1.5258956503868104
- 1.4985786032676698
- 2.873276324272156
- 1.364461557865143
- 2.8096540784835815
- 1.3563090991973876
- 1.3906208157539368
- 2.7722600650787355
- 1.314507830142975
- 1.3583374571800233
- 1.3697565007209778
- 1.3643388509750367
- 1.3816136717796326
- 1.396949713230133
- 1.3853287982940674
- 1.375009422302246
- 1.4037595176696778
- 2.6274331331253054
- 1.3111602330207826
- 1.3076177477836608
- 1.3306412982940674
- 1.3458017778396607
- 1.3667348170280456
- 1.3490681838989258
- 1.3580900406837464
- 1.3742692017555236
- 1.3806128478050232
- 1.376483085155487
- 1.3654471802711488
- 1.3744698572158813
- 1.386456205844879
- 1.3706606149673461
- 1.3680112266540527
- 1.380350306034088
- 2.566106429100037
- 2.782597131729126
- 1.2740448808670044
- 1.288523428440094
- 1.294491047859192
- 2.510509510040283
- 1.2643112421035767
- 1.2835236120223998
- 1.286745719909668
- 1.305574791431427
- 1.3253514075279236
- 1.3248263096809387
- 1.3265463280677796
- 1.3564388394355773
- 1.3577407336235046
- 1.3255822134017945
- 1.3293656826019287
- 1.3787694931030274
- 1.3537418532371521
- 1.371672616004944
- 1.3461036944389344
- 1.3410497212409973
- 1.36810200214386
- 1.3566484785079955
- 1.3545622372627257
- 1.3649044799804688
- 1.3681779384613038
- 1.3711226511001586
- 1.3678940057754516
- 1.3502959299087525
- 1.3731700420379638
- 1.3339589929580689
- 1.3776185941696166
- 1.3563568711280822
train_accuracy:
- 0.0
- 0.058
- 0.097
- 0.069
- 0.128
- 0.158
- 0.154
- 0.165
- 0.13
- 0.191
- 0.149
- 0.158
- 0.176
- 0.206
- 0.202
- 0.151
- 0.187
- 0.21
- 0.212
- 0.193
- 0.196
- 0.202
- 0.252
- 0.208
- 0.199
- 0.219
- 0.238
- 0.209
- 0.262
- 0.242
- 0.233
- 0.207
- 0.251
- 0.235
- 0.0
- 0.263
- 0.0
- 0.232
- 0.262
- 0.0
- 0.274
- 0.27
- 0.264
- 0.252
- 0.292
- 0.287
- 0.227
- 0.272
- 0.277
- 0.0
- 0.228
- 0.279
- 0.284
- 0.265
- 0.287
- 0.285
- 0.235
- 0.245
- 0.237
- 0.255
- 0.277
- 0.294
- 0.281
- 0.302
- 0.29
- 0.319
- 0.0
- 0.0
- 0.269
- 0.241
- 0.292
- 0.0
- 0.251
- 0.283
- 0.292
- 0.289
- 0.255
- 0.297
- 0.284
- 0.291
- 0.31
- 0.346
- 0.309
- 0.287
- 0.32
- 0.281
- 0.264
- 0.328
- 0.287
- 0.319
- 0.309
- 0.282
- 0.325
- 0.283
- 0.325
- 0.295
- 0.28
- 0.343
- 0.319
- 0.344
train_loss:
- 1.794
- 4.451
- 3.71
- 3.283
- 3.449
- 3.368
- 3.308
- 3.262
- 3.258
- 2.931
- 3.094
- 2.986
- 2.558
- 2.807
- 2.793
- 2.675
- 2.283
- 2.442
- 2.641
- 2.637
- 2.377
- 2.527
- 2.4
- 2.262
- 2.062
- 2.455
- 2.089
- 2.01
- 2.236
- 2.158
- 2.194
- 1.741
- 1.783
- 1.971
- 1.663
- 1.85
- 0.983
- 1.928
- 1.372
- 0.821
- 2.163
- 1.349
- 1.478
- 1.815
- 1.905
- 1.362
- 1.875
- 1.27
- 1.296
- 0.9
- 1.724
- 1.364
- 1.358
- 1.137
- 1.093
- 1.11
- 2.131
- 1.628
- 1.603
- 1.238
- 1.817
- 1.02
- 1.002
- 1.068
- 1.502
- 0.849
- 0.906
- 0.292
- 1.724
- 1.511
- 0.938
- 0.568
- 1.566
- 1.185
- 1.218
- 0.787
- 0.896
- 0.771
- 0.891
- 0.543
- 0.594
- 1.052
- 0.71
- 1.216
- 0.524
- 0.89
- 1.157
- 0.837
- 0.718
- 0.59
- 0.673
- 0.869
- 1.206
- 0.651
- 1.045
- 0.535
- 0.95
- 0.691
- 0.912
- 0.583
unequal: 0
verbose: 1
