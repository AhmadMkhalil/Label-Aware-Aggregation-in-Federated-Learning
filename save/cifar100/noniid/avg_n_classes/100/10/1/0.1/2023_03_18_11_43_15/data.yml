avg_train_accuracy: 0.292
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0369
- 0.0741
- 0.0404
- 0.0866
- 0.1025
- 0.1153
- 0.1279
- 0.1445
- 0.0467
- 0.1424
- 0.1566
- 0.159
- 0.1591
- 0.0523
- 0.1643
- 0.1782
- 0.1768
- 0.0554
- 0.1891
- 0.1952
- 0.1975
- 0.2017
- 0.1994
- 0.204
- 0.2097
- 0.0585
- 0.2032
- 0.2064
- 0.2155
- 0.214
- 0.059
- 0.0582
- 0.057
- 0.2264
- 0.2156
- 0.2241
- 0.0642
- 0.2304
- 0.2234
- 0.0649
- 0.2287
- 0.0669
- 0.2355
- 0.2405
- 0.2361
- 0.2331
- 0.2351
- 0.235
- 0.2316
- 0.2358
- 0.2432
- 0.2468
- 0.243
- 0.251
- 0.2529
- 0.2649
- 0.2585
- 0.255
- 0.2568
- 0.2654
- 0.2671
- 0.2599
- 0.2568
- 0.2709
- 0.2728
- 0.2649
- 0.2817
- 0.2753
- 0.2732
- 0.2714
- 0.2735
- 0.2727
- 0.2755
- 0.2804
- 0.2876
- 0.2767
- 0.2686
- 0.2807
- 0.2756
- 0.2833
- 0.2772
- 0.268
- 0.2917
- 0.2803
- 0.2873
- 0.2864
- 0.2854
- 0.0828
- 0.289
- 0.2832
- 0.283
- 0.2828
- 0.2915
- 0.2937
- 0.2958
- 0.2931
- 0.2942
- 0.2932
- 0.0871
- 0.3035
test_loss_list:
- 1.8113858413696289
- 1.747545714378357
- 3.1960881567001342
- 1.6667385387420655
- 1.6676670289039612
- 1.6381011390686036
- 1.6203207659721375
- 1.6096244955062866
- 3.005368084907532
- 1.5342456650733949
- 1.5314458990097046
- 1.530650999546051
- 1.5408481287956237
- 2.982133069038391
- 1.4885694289207458
- 1.4876367568969726
- 1.4914833569526673
- 2.8799950313568115
- 1.437582678794861
- 1.4569010901451112
- 1.4420223641395569
- 1.4519873571395874
- 1.4550835609436035
- 1.4676967215538026
- 1.4602020263671875
- 2.812914752960205
- 1.4039373993873596
- 1.4230496072769165
- 1.419621913433075
- 1.4482753896713256
- 2.793845491409302
- 3.0050713443756103
- 3.165623984336853
- 1.367805871963501
- 1.393099057674408
- 1.393374228477478
- 2.6720249176025392
- 1.34941978931427
- 1.3703836655616761
- 2.615725345611572
- 1.3579846334457397
- 2.6392682075500487
- 1.3516125202178955
- 1.3632074737548827
- 1.3800247740745544
- 1.404849934577942
- 1.388405475616455
- 1.4033408951759339
- 1.3855569672584533
- 1.4125603532791138
- 1.401979115009308
- 1.4006605100631715
- 1.4134225511550904
- 1.3822889447212219
- 1.4025488305091858
- 1.3835542583465577
- 1.381905722618103
- 1.4080947589874269
- 1.3963618087768555
- 1.3864527225494385
- 1.3819455003738403
- 1.3986572933197021
- 1.4129230570793152
- 1.3812225842475891
- 1.3764660549163819
- 1.4193790078163147
- 1.3877046394348145
- 1.381839702129364
- 1.3971477127075196
- 1.4044124221801757
- 1.388219027519226
- 1.4133947277069092
- 1.4050571298599244
- 1.4109825229644775
- 1.3880924201011657
- 1.4231126952171325
- 1.467815978527069
- 1.4234774494171143
- 1.4069283437728881
- 1.4218804478645324
- 1.4347178316116334
- 1.4486378145217895
- 1.3894260287284852
- 1.4194550514221191
- 1.4212158298492432
- 1.4185471105575562
- 1.4370416069030763
- 2.4926409196853636
- 1.2733437705039978
- 1.2887307024002075
- 1.3174254965782166
- 1.3211273789405822
- 1.3159786987304687
- 1.3042809534072877
- 1.3192225122451782
- 1.329384708404541
- 1.3328219842910767
- 1.327069537639618
- 2.4212269163131714
- 1.2522679996490478
train_accuracy:
- 0.025
- 0.049
- 0.0
- 0.094
- 0.1
- 0.11
- 0.179
- 0.159
- 0.0
- 0.181
- 0.121
- 0.174
- 0.103
- 0.0
- 0.179
- 0.164
- 0.188
- 0.0
- 0.232
- 0.189
- 0.255
- 0.17
- 0.243
- 0.202
- 0.257
- 0.0
- 0.228
- 0.191
- 0.258
- 0.193
- 0.0
- 0.0
- 0.0
- 0.26
- 0.192
- 0.211
- 0.0
- 0.261
- 0.246
- 0.0
- 0.211
- 0.0
- 0.28
- 0.206
- 0.238
- 0.22
- 0.271
- 0.27
- 0.214
- 0.233
- 0.303
- 0.28
- 0.222
- 0.241
- 0.277
- 0.307
- 0.267
- 0.229
- 0.289
- 0.26
- 0.306
- 0.283
- 0.296
- 0.361
- 0.289
- 0.242
- 0.329
- 0.338
- 0.263
- 0.294
- 0.275
- 0.299
- 0.27
- 0.255
- 0.317
- 0.248
- 0.239
- 0.28
- 0.28
- 0.305
- 0.259
- 0.332
- 0.325
- 0.317
- 0.327
- 0.334
- 0.291
- 0.0
- 0.297
- 0.329
- 0.322
- 0.318
- 0.258
- 0.318
- 0.332
- 0.324
- 0.35
- 0.271
- 0.0
- 0.292
train_loss:
- 4.33
- 3.889
- 1.933
- 4.02
- 3.513
- 3.499
- 3.353
- 3.212
- 1.583
- 3.224
- 3.03
- 3.143
- 2.636
- 1.298
- 3.185
- 2.898
- 2.858
- 1.1
- 2.955
- 2.71
- 2.562
- 2.361
- 2.194
- 2.489
- 1.89
- 1.054
- 1.864
- 2.184
- 2.344
- 1.816
- 0.874
- 0.388
- 0.323
- 2.954
- 2.096
- 1.679
- 0.602
- 1.822
- 2.29
- 0.525
- 1.612
- 0.406
- 2.545
- 2.174
- 1.324
- 0.956
- 1.981
- 1.927
- 2.224
- 1.033
- 1.448
- 1.631
- 1.83
- 1.877
- 1.392
- 2.027
- 1.648
- 1.531
- 1.287
- 1.719
- 1.663
- 1.129
- 1.275
- 1.814
- 1.28
- 1.276
- 1.392
- 1.489
- 1.406
- 1.043
- 1.613
- 1.088
- 0.65
- 1.11
- 1.045
- 0.788
- 0.529
- 0.728
- 1.274
- 1.124
- 1.192
- 1.314
- 0.948
- 0.567
- 0.84
- 0.883
- 0.91
- 0.853
- 0.796
- 0.37
- 0.705
- 0.362
- 0.758
- 1.196
- 0.724
- 0.421
- 1.066
- 1.107
- 0.598
- 0.949
unequal: 0
verbose: 1
