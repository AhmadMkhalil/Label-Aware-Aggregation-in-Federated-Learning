avg_train_accuracy: 0.188
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0128
- 0.0252
- 0.0309
- 0.0269
- 0.0404
- 0.0379
- 0.0334
- 0.0307
- 0.0292
- 0.0319
- 0.0414
- 0.0383
- 0.0333
- 0.0376
- 0.042
- 0.0546
- 0.0422
- 0.0374
- 0.0484
- 0.0635
- 0.0461
- 0.0699
- 0.0689
- 0.0804
- 0.0756
- 0.0983
- 0.1512
- 0.1179
- 0.1024
- 0.1534
- 0.162
- 0.1351
- 0.1736
- 0.1682
- 0.1401
- 0.1291
- 0.0856
- 0.1246
- 0.1701
- 0.1201
- 0.0713
- 0.1225
- 0.0706
- 0.1208
- 0.1223
- 0.1389
- 0.1862
- 0.1631
- 0.1444
- 0.1406
- 0.153
- 0.1416
- 0.1949
- 0.1436
- 0.1616
- 0.1686
- 0.16
- 0.1435
- 0.1511
- 0.0902
- 0.0808
- 0.1256
- 0.1658
- 0.0938
- 0.223
- 0.1499
- 0.2076
- 0.1828
- 0.2055
- 0.1719
- 0.2314
- 0.1845
- 0.2205
- 0.1889
- 0.2338
- 0.2336
- 0.2215
- 0.1842
- 0.1773
- 0.1578
- 0.2205
- 0.2155
- 0.1789
- 0.1722
- 0.1255
- 0.099
- 0.1644
- 0.1838
- 0.1228
- 0.0764
- 0.206
- 0.1854
- 0.1753
- 0.1783
- 0.1324
- 0.1771
- 0.1606
- 0.187
- 0.1805
- 0.2204
test_loss_list:
- 1.9202868461608886
- 1.9301393413543702
- 1.906635184288025
- 1.8123321342468262
- 1.7755180835723876
- 1.8070550632476807
- 1.978049750328064
- 2.0045625591278076
- 2.056313977241516
- 1.8100472068786622
- 1.7298718309402465
- 1.9348884916305542
- 2.250517234802246
- 2.014578800201416
- 1.7466556596755982
- 1.7205684995651245
- 1.9163582992553712
- 2.0534375381469725
- 1.7374340724945068
- 1.6758767509460448
- 1.8589961004257203
- 1.6762060332298279
- 1.6763488864898681
- 1.6439928340911865
- 1.6296432399749756
- 1.595615692138672
- 1.5002892541885375
- 1.5858803462982178
- 1.579749791622162
- 1.5024838399887086
- 1.500156307220459
- 1.505995099544525
- 1.457239158153534
- 1.4721440887451172
- 1.5313989901542664
- 1.5368298316001892
- 1.734147582054138
- 1.5628589797019958
- 1.4597220873832704
- 1.5745963072776794
- 1.8767253923416138
- 1.5472508215904235
- 1.8136702156066895
- 1.5522179436683654
- 1.5584438681602477
- 1.512749433517456
- 1.429080913066864
- 1.4835204529762267
- 1.5199988460540772
- 1.54601092338562
- 1.519346148967743
- 1.542014377117157
- 1.4362069487571716
- 1.5706720280647277
- 1.5148617243766784
- 1.46702392578125
- 1.4592558789253234
- 1.5014989852905274
- 1.4930412220954894
- 1.7226134490966798
- 1.7394472646713257
- 1.5525687479972838
- 1.455489182472229
- 1.7127651166915894
- 1.3776552724838256
- 1.5323201704025269
- 1.3932636404037475
- 1.446488962173462
- 1.4007483673095704
- 1.4755047941207886
- 1.3887784719467162
- 1.4639520049095154
- 1.3928446197509765
- 1.4367327308654785
- 1.3868772411346435
- 1.4190579223632813
- 1.4276573467254638
- 1.46324875831604
- 1.4579023694992066
- 1.5126178121566773
- 1.3806041288375854
- 1.4156792449951172
- 1.4953841066360474
- 1.5019479417800903
- 1.6868858695030213
- 1.7815149784088136
- 1.4535212421417236
- 1.4334451842308045
- 1.6655498075485229
- 1.9523350667953492
- 1.3921835613250733
- 1.4517233991622924
- 1.500009500980377
- 1.4801601600646972
- 1.658075499534607
- 1.4592408418655396
- 1.515006308555603
- 1.428350100517273
- 1.46313880443573
- 1.3725061655044555
train_accuracy:
- 0.0
- 0.0
- 0.621
- 0.101
- 0.035
- 0.562
- 0.355
- 0.0
- 0.79
- 0.672
- 0.276
- 0.516
- 0.617
- 0.185
- 0.004
- 0.649
- 0.452
- 0.138
- 0.402
- 0.053
- 0.242
- 0.043
- 0.358
- 0.666
- 0.69
- 0.07
- 0.63
- 0.392
- 0.112
- 0.165
- 0.141
- 0.115
- 0.168
- 0.517
- 0.461
- 0.811
- 0.654
- 0.595
- 0.595
- 0.681
- 0.66
- 0.506
- 0.688
- 0.494
- 0.447
- 0.761
- 0.162
- 0.115
- 0.318
- 0.105
- 0.16
- 0.586
- 0.663
- 0.131
- 0.654
- 0.174
- 0.271
- 0.773
- 0.129
- 0.829
- 0.69
- 0.398
- 0.685
- 0.505
- 0.192
- 0.663
- 0.725
- 0.581
- 0.182
- 0.127
- 0.204
- 0.762
- 0.524
- 0.141
- 0.211
- 0.218
- 0.195
- 0.239
- 0.604
- 0.137
- 0.246
- 0.301
- 0.142
- 0.123
- 0.442
- 0.31
- 0.231
- 0.135
- 0.398
- 0.763
- 0.764
- 0.159
- 0.682
- 0.656
- 0.748
- 0.288
- 0.168
- 0.42
- 0.504
- 0.188
train_loss:
- 1.825
- 1.565
- 1.436
- 1.647
- 1.434
- 1.28
- 0.419
- 0.43
- 0.386
- 1.266
- 1.508
- 0.415
- 0.305
- 0.369
- 1.304
- 1.151
- 0.316
- 0.207
- 1.133
- 1.014
- 0.472
- 1.297
- 1.056
- 0.99
- 1.31
- 1.162
- 1.716
- 0.85
- 0.868
- 1.605
- 1.554
- 1.117
- 1.809
- 1.469
- 1.013
- 0.707
- 0.164
- 0.686
- 1.337
- 0.259
- 0.145
- 0.925
- 0.248
- 0.883
- 0.827
- 0.726
- 1.328
- 0.653
- 0.7
- 0.601
- 0.704
- 0.588
- 1.109
- 0.471
- 0.592
- 0.529
- 0.636
- 0.71
- 0.669
- 0.119
- 0.165
- 0.499
- 0.559
- 0.197
- 1.378
- 0.188
- 0.995
- 0.612
- 0.917
- 0.534
- 1.109
- 0.485
- 0.673
- 0.643
- 0.966
- 0.878
- 0.639
- 0.422
- 0.232
- 0.364
- 0.706
- 0.58
- 0.389
- 0.349
- 0.177
- 0.152
- 0.45
- 0.307
- 0.205
- 0.127
- 0.541
- 0.407
- 0.266
- 0.314
- 0.131
- 0.289
- 0.303
- 0.429
- 0.326
- 0.474
unequal: 0
verbose: 1
