avg_train_accuracy: 0.611
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.011
- 0.0177
- 0.0207
- 0.0368
- 0.0415
- 0.0341
- 0.0397
- 0.0971
- 0.0429
- 0.0309
- 0.0249
- 0.0506
- 0.0261
- 0.0833
- 0.0758
- 0.1248
- 0.131
- 0.1343
- 0.1093
- 0.1388
- 0.1159
- 0.0426
- 0.0804
- 0.0424
- 0.0674
- 0.1481
- 0.055
- 0.1494
- 0.0846
- 0.0954
- 0.1586
- 0.0792
- 0.0988
- 0.105
- 0.1095
- 0.0555
- 0.0884
- 0.1325
- 0.1074
- 0.0855
- 0.1027
- 0.1805
- 0.1777
- 0.1056
- 0.1333
- 0.1739
- 0.1553
- 0.1014
- 0.1066
- 0.1223
- 0.0742
- 0.0928
- 0.1345
- 0.0918
- 0.112
- 0.1121
- 0.143
- 0.1249
- 0.1232
- 0.1434
- 0.081
- 0.1474
- 0.1448
- 0.0921
- 0.1298
- 0.0894
- 0.127
- 0.1305
- 0.1372
- 0.1911
- 0.1591
- 0.1925
- 0.1296
- 0.1049
- 0.1345
- 0.0992
- 0.0674
- 0.0621
- 0.0626
- 0.0549
- 0.0455
- 0.1027
- 0.073
- 0.0636
- 0.0584
- 0.1817
- 0.1553
- 0.1116
- 0.1393
- 0.2287
- 0.1431
- 0.1712
- 0.1181
- 0.2025
- 0.164
- 0.2008
- 0.2032
- 0.1512
- 0.1365
- 0.1447
test_loss_list:
- 2.0683270406723024
- 2.014556746482849
- 1.9767963886260986
- 1.745002408027649
- 1.7470425748825074
- 1.7790098524093627
- 1.756616268157959
- 1.6244810318946838
- 1.8614819288253783
- 2.0893391704559328
- 2.133878078460693
- 1.6569601273536683
- 2.0469684267044066
- 1.6054223299026489
- 1.671664569377899
- 1.5691049885749817
- 1.5639550709724426
- 1.5809900164604187
- 1.5765388107299805
- 1.5439052391052246
- 1.5738004279136657
- 1.9328996515274048
- 1.6311575651168824
- 1.8211301231384278
- 1.6684099292755128
- 1.4943629431724548
- 1.7630434942245483
- 1.484802894592285
- 1.6578627228736877
- 1.5833842134475709
- 1.4807302474975585
- 1.7837529182434082
- 1.620299415588379
- 1.5751899290084839
- 1.5388922476768494
- 1.8788374805450438
- 1.6246571326255799
- 1.5145283079147338
- 1.5726877188682555
- 1.7054917478561402
- 1.580138099193573
- 1.4297519850730895
- 1.459365713596344
- 1.6345548152923584
- 1.527489011287689
- 1.45005304813385
- 1.4941798520088196
- 1.6519230580329896
- 1.5622830271720887
- 1.5477411293983458
- 1.7372896003723144
- 1.6362323689460754
- 1.5502274656295776
- 1.6741138124465942
- 1.5460074758529663
- 1.5705942988395691
- 1.5043828630447387
- 1.5477535915374756
- 1.5612914919853211
- 1.5092605614662171
- 1.7962574243545533
- 1.5046880841255188
- 1.4971330761909485
- 1.6969671726226807
- 1.5206860089302063
- 1.7015313577651978
- 1.5621787476539613
- 1.5793021297454835
- 1.509060444831848
- 1.4212847089767455
- 1.495536732673645
- 1.431140661239624
- 1.6041241478919983
- 1.673447253704071
- 1.5132712626457214
- 1.6621272206306457
- 1.844076805114746
- 1.9341361474990846
- 1.9094202184677125
- 2.0115380668640137
- 2.1756107330322267
- 1.6113381671905518
- 1.841897120475769
- 1.9973049831390381
- 1.981093440055847
- 1.395606245994568
- 1.4989825749397279
- 1.685975215435028
- 1.5166080927848815
- 1.3778313827514648
- 1.5762018728256226
- 1.4485817074775695
- 1.6045430374145508
- 1.3805409216880797
- 1.4779955387115478
- 1.4014819145202637
- 1.416052165031433
- 1.5376217365264893
- 1.5677741026878358
- 1.5042048811912536
train_accuracy:
- 0.0
- 0.0
- 0.281
- 0.726
- 0.003
- 0.692
- 0.28
- 0.103
- 0.077
- 0.046
- 0.22
- 0.275
- 0.501
- 0.074
- 0.047
- 0.117
- 0.102
- 0.119
- 0.074
- 0.528
- 0.486
- 0.676
- 0.593
- 0.644
- 0.642
- 0.13
- 0.804
- 0.557
- 0.415
- 0.071
- 0.149
- 0.504
- 0.053
- 0.422
- 0.412
- 0.38
- 0.062
- 0.592
- 0.074
- 0.404
- 0.061
- 0.161
- 0.15
- 0.628
- 0.812
- 0.161
- 0.154
- 0.639
- 0.517
- 0.105
- 0.41
- 0.524
- 0.585
- 0.137
- 0.73
- 0.498
- 0.522
- 0.568
- 0.573
- 0.592
- 0.316
- 0.492
- 0.513
- 0.753
- 0.411
- 0.451
- 0.106
- 0.115
- 0.119
- 0.17
- 0.141
- 0.427
- 0.471
- 0.117
- 0.575
- 0.653
- 0.395
- 0.674
- 0.458
- 0.609
- 0.415
- 0.71
- 0.645
- 0.676
- 0.554
- 0.164
- 0.627
- 0.698
- 0.654
- 0.275
- 0.665
- 0.141
- 0.26
- 0.241
- 0.671
- 0.237
- 0.226
- 0.483
- 0.556
- 0.611
train_loss:
- 0.661
- 1.822
- 1.634
- 2.731
- 1.543
- 1.402
- 1.45
- 2.401
- 0.408
- 0.347
- 0.359
- 1.492
- 0.396
- 2.185
- 1.191
- 1.934
- 2.063
- 1.85
- 1.182
- 1.763
- 0.458
- 0.313
- 0.993
- 0.386
- 0.94
- 1.669
- 0.272
- 1.606
- 0.423
- 0.997
- 1.504
- 0.228
- 0.817
- 0.954
- 0.951
- 0.248
- 0.847
- 0.871
- 0.738
- 0.292
- 0.831
- 1.272
- 1.208
- 0.313
- 0.801
- 1.138
- 0.734
- 0.273
- 0.752
- 0.645
- 0.199
- 0.565
- 0.587
- 0.267
- 0.685
- 0.5
- 0.584
- 0.623
- 0.618
- 0.647
- 0.139
- 0.527
- 0.64
- 0.209
- 0.611
- 0.174
- 0.59
- 0.473
- 0.495
- 0.863
- 0.529
- 0.816
- 0.222
- 0.214
- 0.479
- 0.204
- 0.141
- 0.131
- 0.158
- 0.141
- 0.105
- 0.503
- 0.113
- 0.091
- 0.125
- 0.779
- 0.409
- 0.143
- 0.43
- 0.974
- 0.196
- 0.414
- 0.21
- 0.712
- 0.346
- 0.574
- 0.624
- 0.191
- 0.214
- 0.389
unequal: 0
verbose: 1
