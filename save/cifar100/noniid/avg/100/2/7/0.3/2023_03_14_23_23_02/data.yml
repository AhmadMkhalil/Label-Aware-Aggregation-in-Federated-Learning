avg_train_accuracy: 0.518
avg_train_loss: 0.001
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0168
- 0.0268
- 0.018
- 0.0226
- 0.0247
- 0.0325
- 0.0701
- 0.0607
- 0.0573
- 0.0347
- 0.0559
- 0.0617
- 0.1043
- 0.1241
- 0.0873
- 0.0584
- 0.0966
- 0.0829
- 0.0596
- 0.1258
- 0.1476
- 0.1512
- 0.0996
- 0.0789
- 0.0936
- 0.1181
- 0.0668
- 0.053
- 0.1671
- 0.0843
- 0.0585
- 0.0917
- 0.0636
- 0.1579
- 0.1254
- 0.1355
- 0.0892
- 0.0817
- 0.1706
- 0.1326
- 0.0775
- 0.1294
- 0.0774
- 0.1827
- 0.1842
- 0.1048
- 0.1386
- 0.0905
- 0.117
- 0.082
- 0.1775
- 0.1636
- 0.1453
- 0.1458
- 0.133
- 0.1435
- 0.0893
- 0.1851
- 0.1722
- 0.1313
- 0.1416
- 0.1555
- 0.1465
- 0.1051
- 0.2005
- 0.123
- 0.1542
- 0.1581
- 0.0955
- 0.1406
- 0.1623
- 0.0955
- 0.2101
- 0.1316
- 0.1362
- 0.1991
- 0.21
- 0.1782
- 0.1775
- 0.1659
- 0.1605
- 0.1666
- 0.1895
- 0.1148
- 0.168
- 0.218
- 0.1864
- 0.116
- 0.2218
- 0.1872
- 0.1098
- 0.098
- 0.1306
- 0.0924
- 0.1061
- 0.1593
- 0.1597
- 0.1815
- 0.1217
- 0.098
test_loss_list:
- 1.9563701915740968
- 1.8030093145370483
- 2.028933162689209
- 2.1324648904800414
- 1.9182634449005127
- 1.7781027746200562
- 1.6754132080078126
- 1.6933885383605958
- 1.702167181968689
- 1.969388303756714
- 1.7273196458816529
- 1.712823781967163
- 1.6008393120765687
- 1.5910617351531982
- 1.6820888662338256
- 1.7639600324630738
- 1.582504870891571
- 1.6334531617164612
- 1.7649446821212769
- 1.5273194789886475
- 1.5208098149299623
- 1.5300098419189454
- 1.614329628944397
- 1.6572643113136292
- 1.6264110589027405
- 1.5551144194602966
- 1.798118987083435
- 1.7744481658935547
- 1.449271433353424
- 1.7277425718307495
- 1.9129924964904785
- 1.6059236550331115
- 1.7826496839523316
- 1.4563295555114746
- 1.555672767162323
- 1.528125593662262
- 1.6880484056472778
- 1.6839126777648925
- 1.4321487283706664
- 1.5194511747360229
- 1.7521218347549439
- 1.522942955493927
- 1.7299649238586425
- 1.4145799827575685
- 1.4327722215652465
- 1.6743649315834046
- 1.485851547718048
- 1.7218930912017822
- 1.5313401913642883
- 1.7599807977676392
- 1.4209571599960327
- 1.466381905078888
- 1.4853421306610108
- 1.5082165932655334
- 1.5162761974334718
- 1.5045633029937744
- 1.7045724868774415
- 1.4174746131896974
- 1.4317158555984497
- 1.5293893003463745
- 1.4894806742668152
- 1.4687993121147156
- 1.5048704171180725
- 1.6401878881454468
- 1.389274878501892
- 1.6071830630302428
- 1.4678899478912353
- 1.4667224025726318
- 1.7495163583755493
- 1.5043508219718933
- 1.4596940803527831
- 1.6908127999305724
- 1.3770677757263183
- 1.5745789074897767
- 1.5503561186790467
- 1.3922132277488708
- 1.4025055480003357
- 1.458588182926178
- 1.4581352996826171
- 1.507823703289032
- 1.5137462401390076
- 1.4679934763908387
- 1.4133742785453796
- 1.6915072655677796
- 1.4657823371887206
- 1.3689613914489747
- 1.4297311663627625
- 1.6877076506614686
- 1.3653500080108643
- 1.421564176082611
- 1.6587588620185851
- 1.7309608602523803
- 1.5545626068115235
- 1.7933183479309083
- 1.6723974704742433
- 1.4667388892173767
- 1.4889413547515868
- 1.4432584714889527
- 1.6165358543395996
- 1.7167329692840576
train_accuracy:
- 0.0
- 0.677
- 0.003
- 0.001
- 0.615
- 0.365
- 0.078
- 0.041
- 0.778
- 0.492
- 0.585
- 0.05
- 0.572
- 0.156
- 0.318
- 0.726
- 0.249
- 0.061
- 0.774
- 0.146
- 0.152
- 0.189
- 0.181
- 0.05
- 0.064
- 0.409
- 0.263
- 0.463
- 0.193
- 0.268
- 0.597
- 0.062
- 0.279
- 0.167
- 0.102
- 0.11
- 0.238
- 0.571
- 0.19
- 0.786
- 0.734
- 0.556
- 0.29
- 0.202
- 0.544
- 0.178
- 0.378
- 0.432
- 0.607
- 0.486
- 0.679
- 0.183
- 0.114
- 0.58
- 0.094
- 0.113
- 0.772
- 0.195
- 0.722
- 0.657
- 0.106
- 0.773
- 0.51
- 0.708
- 0.211
- 0.631
- 0.405
- 0.564
- 0.48
- 0.108
- 0.458
- 0.352
- 0.22
- 0.668
- 0.1
- 0.252
- 0.241
- 0.758
- 0.18
- 0.615
- 0.643
- 0.193
- 0.415
- 0.393
- 0.692
- 0.21
- 0.484
- 0.517
- 0.612
- 0.463
- 0.839
- 0.691
- 0.667
- 0.542
- 0.131
- 0.172
- 0.147
- 0.55
- 0.215
- 0.518
train_loss:
- 1.755
- 2.814
- 0.442
- 0.42
- 1.424
- 1.438
- 2.361
- 1.389
- 1.315
- 0.309
- 1.248
- 1.174
- 2.09
- 1.895
- 1.013
- 0.363
- 1.229
- 1.194
- 0.31
- 1.802
- 1.793
- 1.619
- 0.375
- 0.884
- 0.843
- 1.051
- 0.263
- 0.295
- 1.573
- 0.256
- 0.222
- 0.85
- 0.228
- 1.491
- 0.705
- 0.871
- 0.207
- 0.235
- 1.519
- 0.739
- 0.179
- 0.807
- 0.21
- 1.389
- 1.239
- 0.178
- 0.807
- 0.171
- 0.703
- 0.142
- 1.226
- 0.702
- 0.624
- 0.56
- 0.567
- 0.518
- 0.179
- 1.016
- 0.725
- 0.472
- 0.694
- 0.647
- 0.449
- 0.148
- 0.948
- 0.178
- 0.593
- 0.411
- 0.141
- 0.537
- 0.608
- 0.125
- 0.771
- 0.178
- 0.344
- 0.802
- 0.869
- 0.38
- 0.483
- 0.344
- 0.304
- 0.492
- 0.512
- 0.106
- 0.458
- 0.621
- 0.437
- 0.13
- 0.608
- 0.455
- 0.151
- 0.144
- 0.355
- 0.085
- 0.157
- 0.383
- 0.285
- 0.411
- 0.125
- 0.121
unequal: 0
verbose: 1
