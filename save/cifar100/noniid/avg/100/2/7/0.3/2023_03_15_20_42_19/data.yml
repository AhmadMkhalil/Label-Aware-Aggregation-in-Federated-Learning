avg_train_accuracy: 0.61
avg_train_loss: 0.001
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0207
- 0.0205
- 0.0204
- 0.0214
- 0.0573
- 0.0485
- 0.0511
- 0.0342
- 0.0476
- 0.0777
- 0.047
- 0.0378
- 0.1056
- 0.0468
- 0.0652
- 0.0462
- 0.0389
- 0.11
- 0.0834
- 0.0851
- 0.0905
- 0.0864
- 0.0987
- 0.0903
- 0.1015
- 0.0938
- 0.0941
- 0.0752
- 0.0864
- 0.0967
- 0.149
- 0.1567
- 0.1305
- 0.088
- 0.0555
- 0.1019
- 0.1091
- 0.165
- 0.0953
- 0.0788
- 0.0964
- 0.1161
- 0.1464
- 0.1152
- 0.1407
- 0.0697
- 0.1161
- 0.1423
- 0.1311
- 0.1862
- 0.1429
- 0.1424
- 0.1857
- 0.1084
- 0.1414
- 0.0829
- 0.0527
- 0.1756
- 0.1576
- 0.1919
- 0.1601
- 0.19
- 0.1826
- 0.1942
- 0.1759
- 0.1493
- 0.201
- 0.2081
- 0.208
- 0.1665
- 0.1572
- 0.1129
- 0.1453
- 0.2215
- 0.1675
- 0.1622
- 0.1579
- 0.2168
- 0.2211
- 0.2134
- 0.1785
- 0.2217
- 0.1898
- 0.2344
- 0.1773
- 0.1087
- 0.1421
- 0.0966
- 0.1459
- 0.2063
- 0.1349
- 0.1178
- 0.1973
- 0.2173
- 0.1549
- 0.1694
- 0.2182
- 0.1303
- 0.2102
- 0.1497
test_loss_list:
- 1.9518623495101928
- 2.1742834758758547
- 2.1958492612838745
- 1.7864635181427002
- 1.7152871227264403
- 1.7925939846038819
- 1.76430242061615
- 1.9698111391067505
- 1.7718454217910766
- 1.6344468760490418
- 1.9031554317474366
- 1.7693071222305299
- 1.5752044034004211
- 1.8776277542114257
- 1.7207464289665222
- 1.8651538562774659
- 2.020248656272888
- 1.55019362449646
- 1.6473101258277894
- 1.6590301918983459
- 1.5878408908843995
- 1.6608115768432616
- 1.5577331519126891
- 1.6329329562187196
- 1.5886251091957093
- 1.6262413597106933
- 1.581894826889038
- 1.7132718992233276
- 1.6546905064582824
- 1.600038161277771
- 1.469187355041504
- 1.4921570062637328
- 1.5653695416450502
- 1.672759747505188
- 1.8367438554763793
- 1.5985239887237548
- 1.5690144634246825
- 1.4618760251998901
- 1.7033997225761413
- 1.7217132425308228
- 1.601863353252411
- 1.5788409233093261
- 1.4604793858528138
- 1.5337533354759216
- 1.5092206168174744
- 1.8367501497268677
- 1.5530388021469117
- 1.502959611415863
- 1.5049921560287476
- 1.4248568940162658
- 1.5398053979873658
- 1.5043798351287843
- 1.4347438955307006
- 1.632399332523346
- 1.5250157642364501
- 1.716693603992462
- 2.005697250366211
- 1.4333727359771729
- 1.4992809176445008
- 1.4364305281639098
- 1.475787968635559
- 1.4301939463615418
- 1.422664589881897
- 1.42720463514328
- 1.4483482789993287
- 1.5207539129257202
- 1.4052524280548095
- 1.414431812763214
- 1.4145249772071837
- 1.4751796483993531
- 1.4710229897499085
- 1.6356874537467956
- 1.5240596842765808
- 1.3623360109329223
- 1.4649422645568848
- 1.487391347885132
- 1.4853437805175782
- 1.3798074197769166
- 1.395402762889862
- 1.403060359954834
- 1.4892120122909547
- 1.4033112812042237
- 1.4652037286758424
- 1.3883246564865113
- 1.5415957641601563
- 1.7929155015945435
- 1.5996795201301575
- 1.7399202060699464
- 1.547474308013916
- 1.3914896368980407
- 1.6501535511016845
- 1.6600517654418945
- 1.3980834150314332
- 1.3903031182289123
- 1.559439926147461
- 1.4890731143951417
- 1.3586811566352843
- 1.6256222414970398
- 1.39017671585083
- 1.618165247440338
train_accuracy:
- 0.086
- 0.204
- 0.0
- 0.01
- 0.057
- 0.374
- 0.029
- 0.141
- 0.856
- 0.081
- 0.731
- 0.521
- 0.126
- 0.374
- 0.634
- 0.256
- 0.574
- 0.709
- 0.639
- 0.553
- 0.049
- 0.042
- 0.098
- 0.693
- 0.828
- 0.611
- 0.105
- 0.171
- 0.088
- 0.101
- 0.633
- 0.621
- 0.478
- 0.083
- 0.765
- 0.366
- 0.071
- 0.199
- 0.322
- 0.577
- 0.621
- 0.325
- 0.133
- 0.612
- 0.603
- 0.549
- 0.128
- 0.149
- 0.629
- 0.223
- 0.652
- 0.128
- 0.199
- 0.112
- 0.48
- 0.533
- 0.439
- 0.696
- 0.113
- 0.188
- 0.601
- 0.456
- 0.505
- 0.18
- 0.548
- 0.117
- 0.208
- 0.2
- 0.234
- 0.365
- 0.584
- 0.491
- 0.155
- 0.544
- 0.175
- 0.619
- 0.208
- 0.199
- 0.529
- 0.192
- 0.67
- 0.254
- 0.504
- 0.275
- 0.131
- 0.193
- 0.518
- 0.44
- 0.096
- 0.225
- 0.539
- 0.13
- 0.218
- 0.212
- 0.441
- 0.253
- 0.504
- 0.681
- 0.54
- 0.61
train_loss:
- 1.703
- 0.47
- 0.513
- 2.81
- 2.592
- 1.364
- 1.32
- 0.318
- 1.322
- 2.359
- 0.334
- 0.458
- 2.104
- 0.27
- 1.146
- 0.352
- 0.25
- 2.137
- 1.111
- 1.099
- 1.103
- 1.046
- 1.103
- 0.955
- 0.998
- 0.908
- 0.923
- 0.259
- 0.849
- 1.066
- 1.524
- 1.67
- 0.834
- 0.318
- 0.222
- 0.724
- 0.9
- 1.35
- 0.216
- 0.201
- 0.805
- 0.709
- 0.886
- 0.613
- 0.755
- 0.134
- 0.61
- 0.581
- 0.769
- 1.192
- 0.705
- 0.679
- 0.989
- 0.193
- 0.52
- 0.17
- 0.128
- 1.131
- 0.693
- 1.122
- 0.678
- 1.009
- 0.594
- 0.876
- 0.623
- 0.499
- 0.823
- 0.77
- 0.761
- 0.242
- 0.445
- 0.152
- 0.35
- 0.803
- 0.379
- 0.446
- 0.389
- 0.776
- 0.556
- 0.673
- 0.356
- 0.617
- 0.456
- 0.74
- 0.378
- 0.134
- 0.191
- 0.166
- 0.325
- 0.572
- 0.162
- 0.165
- 0.512
- 0.464
- 0.173
- 0.343
- 0.493
- 0.118
- 0.497
- 0.14
unequal: 0
verbose: 1
