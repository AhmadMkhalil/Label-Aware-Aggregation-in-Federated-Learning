avg_train_accuracy: 0.372
avg_train_loss: 0.001
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0142
- 0.0217
- 0.0222
- 0.0293
- 0.0674
- 0.055
- 0.044
- 0.0534
- 0.0518
- 0.0653
- 0.0782
- 0.0609
- 0.0322
- 0.0526
- 0.1275
- 0.0762
- 0.0921
- 0.0814
- 0.1741
- 0.1598
- 0.1216
- 0.1753
- 0.1234
- 0.1535
- 0.1316
- 0.0745
- 0.0472
- 0.1199
- 0.0563
- 0.1555
- 0.1248
- 0.1614
- 0.1747
- 0.1795
- 0.1388
- 0.1353
- 0.0857
- 0.1042
- 0.1406
- 0.0797
- 0.1907
- 0.0955
- 0.1313
- 0.188
- 0.1014
- 0.0742
- 0.101
- 0.1368
- 0.1345
- 0.1283
- 0.1474
- 0.0846
- 0.0689
- 0.1257
- 0.1374
- 0.0839
- 0.0786
- 0.0543
- 0.0508
- 0.0922
- 0.1225
- 0.199
- 0.2008
- 0.1644
- 0.1618
- 0.1101
- 0.1241
- 0.1969
- 0.1227
- 0.0956
- 0.0572
- 0.1853
- 0.1601
- 0.1461
- 0.1757
- 0.1046
- 0.0885
- 0.0648
- 0.0668
- 0.1249
- 0.1556
- 0.1392
- 0.2065
- 0.1175
- 0.1191
- 0.077
- 0.0628
- 0.1163
- 0.1478
- 0.1478
- 0.1502
- 0.0945
- 0.1614
- 0.1533
- 0.2126
- 0.2158
- 0.1632
- 0.1726
- 0.1967
- 0.106
test_loss_list:
- 1.9581958293914794
- 1.9435027074813842
- 1.8861586141586304
- 1.85767324924469
- 1.6955486631393433
- 1.72400954246521
- 1.8093182849884033
- 1.7165774011611938
- 1.7057042908668518
- 1.7066156339645386
- 1.6141647338867187
- 1.684946184158325
- 1.8708288717269896
- 1.7246570348739625
- 1.541151258945465
- 1.6698202919960021
- 1.5979313659667969
- 1.6364261436462402
- 1.5056918668746948
- 1.5332554149627686
- 1.5726656532287597
- 1.4820594811439514
- 1.5703131198883056
- 1.515481379032135
- 1.5440903854370118
- 1.797920126914978
- 1.9067584657669068
- 1.5257282853126526
- 1.8368189668655395
- 1.455408263206482
- 1.5386687517166138
- 1.4754001021385192
- 1.4713537573814393
- 1.4666599082946776
- 1.5320235776901245
- 1.5141916036605836
- 1.6579910016059876
- 1.5879042196273803
- 1.4983211278915405
- 1.7764724349975587
- 1.4104320669174195
- 1.668311700820923
- 1.5093329954147339
- 1.4161707615852357
- 1.6689792346954346
- 1.7590824747085572
- 1.6156176805496216
- 1.482877869606018
- 1.509886260032654
- 1.537358331680298
- 1.5030348014831543
- 1.8153836250305175
- 1.843889970779419
- 1.5432299232482911
- 1.5460089993476869
- 1.814251914024353
- 1.7821902656555175
- 1.9703302574157715
- 1.9144981336593627
- 1.6415072298049926
- 1.5538841557502747
- 1.3924144864082337
- 1.4092179656028747
- 1.4723737335205078
- 1.4739932751655578
- 1.6461638069152833
- 1.549922811985016
- 1.4000457453727722
- 1.5918522024154662
- 1.71319411277771
- 1.9883093166351318
- 1.4096420073509217
- 1.4817744922637939
- 1.5250685715675354
- 1.4321596717834473
- 1.715450246334076
- 1.7700611448287964
- 1.9904512023925782
- 1.9541178512573243
- 1.5350467896461486
- 1.467630615234375
- 1.5008585667610168
- 1.3820944976806642
- 1.6252300357818603
- 1.6060146045684816
- 1.8199235820770263
- 1.9778802585601807
- 1.6187280774116517
- 1.502322027683258
- 1.5143846321105956
- 1.5055824422836304
- 1.8041657972335816
- 1.4721580743789673
- 1.486640956401825
- 1.3754772233963013
- 1.3908862018585204
- 1.5193496656417846
- 1.480129997730255
- 1.4266069555282592
- 1.7574596881866456
train_accuracy:
- 0.0
- 0.017
- 0.0
- 0.34
- 0.04
- 0.029
- 0.763
- 0.703
- 0.452
- 0.06
- 0.091
- 0.603
- 0.862
- 0.021
- 0.089
- 0.052
- 0.386
- 0.049
- 0.136
- 0.142
- 0.517
- 0.635
- 0.079
- 0.116
- 0.82
- 0.325
- 0.56
- 0.125
- 0.161
- 0.134
- 0.673
- 0.576
- 0.164
- 0.158
- 0.128
- 0.31
- 0.558
- 0.055
- 0.689
- 0.634
- 0.171
- 0.42
- 0.44
- 0.185
- 0.324
- 0.524
- 0.072
- 0.132
- 0.737
- 0.59
- 0.111
- 0.455
- 0.266
- 0.512
- 0.744
- 0.362
- 0.847
- 0.42
- 0.46
- 0.075
- 0.405
- 0.737
- 0.204
- 0.144
- 0.356
- 0.576
- 0.515
- 0.196
- 0.45
- 0.229
- 0.566
- 0.19
- 0.494
- 0.391
- 0.605
- 0.59
- 0.52
- 0.644
- 0.569
- 0.734
- 0.567
- 0.41
- 0.209
- 0.491
- 0.486
- 0.48
- 0.403
- 0.096
- 0.121
- 0.541
- 0.661
- 0.732
- 0.702
- 0.159
- 0.222
- 0.217
- 0.453
- 0.155
- 0.188
- 0.372
train_loss:
- 1.775
- 1.732
- 1.563
- 1.407
- 2.419
- 1.543
- 1.306
- 1.46
- 1.315
- 1.294
- 1.285
- 1.285
- 0.391
- 1.192
- 2.001
- 1.06
- 1.191
- 1.055
- 2.61
- 1.722
- 1.009
- 1.741
- 0.928
- 1.538
- 1.064
- 0.279
- 0.233
- 0.978
- 0.271
- 1.499
- 0.928
- 1.411
- 1.287
- 1.395
- 0.816
- 0.752
- 0.277
- 0.676
- 0.765
- 0.176
- 1.238
- 0.213
- 0.843
- 1.181
- 0.211
- 0.255
- 0.606
- 0.741
- 0.609
- 0.641
- 0.646
- 0.12
- 0.152
- 0.579
- 0.501
- 0.119
- 0.19
- 0.171
- 0.155
- 0.509
- 0.581
- 1.017
- 0.922
- 0.569
- 0.542
- 0.179
- 0.547
- 0.827
- 0.213
- 0.162
- 0.104
- 0.866
- 0.441
- 0.392
- 0.56
- 0.129
- 0.117
- 0.074
- 0.097
- 0.525
- 0.416
- 0.483
- 0.707
- 0.15
- 0.213
- 0.107
- 0.088
- 0.426
- 0.371
- 0.386
- 0.413
- 0.073
- 0.384
- 0.434
- 0.607
- 0.578
- 0.325
- 0.372
- 0.358
- 0.08
unequal: 0
verbose: 1
