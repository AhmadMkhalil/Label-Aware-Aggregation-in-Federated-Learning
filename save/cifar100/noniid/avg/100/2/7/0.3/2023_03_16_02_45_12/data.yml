avg_train_accuracy: 0.668
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0182
- 0.0186
- 0.02
- 0.0279
- 0.0218
- 0.0391
- 0.042
- 0.0251
- 0.0421
- 0.0327
- 0.0411
- 0.034
- 0.041
- 0.0317
- 0.0803
- 0.0608
- 0.0967
- 0.066
- 0.0647
- 0.1313
- 0.0852
- 0.093
- 0.0996
- 0.0878
- 0.0906
- 0.0942
- 0.1063
- 0.0897
- 0.1636
- 0.1581
- 0.0815
- 0.1002
- 0.1199
- 0.1602
- 0.1545
- 0.1777
- 0.1314
- 0.1492
- 0.0924
- 0.1169
- 0.1229
- 0.0725
- 0.1178
- 0.1972
- 0.1121
- 0.0844
- 0.1406
- 0.1301
- 0.0953
- 0.0828
- 0.1115
- 0.2062
- 0.1543
- 0.2247
- 0.175
- 0.1623
- 0.16
- 0.211
- 0.1678
- 0.1578
- 0.1598
- 0.1648
- 0.1687
- 0.1637
- 0.1153
- 0.1457
- 0.1604
- 0.16
- 0.1593
- 0.1682
- 0.1614
- 0.2187
- 0.1843
- 0.1493
- 0.1494
- 0.1546
- 0.1262
- 0.0921
- 0.1306
- 0.1579
- 0.15
- 0.1506
- 0.1704
- 0.1753
- 0.1654
- 0.2142
- 0.1439
- 0.2229
- 0.1674
- 0.2252
- 0.221
- 0.1899
- 0.1518
- 0.1564
- 0.1427
- 0.1403
- 0.1764
- 0.2164
- 0.1846
- 0.1532
test_loss_list:
- 1.9356296730041505
- 1.9189155769348145
- 2.025315356254578
- 2.227667088508606
- 1.9699632930755615
- 1.7132105684280396
- 1.7743991899490357
- 1.913896222114563
- 1.7691028118133545
- 1.9696449995040894
- 1.7661966371536255
- 1.9969818639755248
- 1.749385313987732
- 1.9788170433044434
- 1.6063896751403808
- 1.7770249032974244
- 1.5665064644813538
- 1.6974732780456543
- 1.6508686542510986
- 1.5162727189064027
- 1.638582844734192
- 1.593824999332428
- 1.5788911700248718
- 1.6352736926078797
- 1.6515583753585816
- 1.6463273882865905
- 1.590219373703003
- 1.6491843152046204
- 1.4660617637634277
- 1.492708487510681
- 1.7159852504730224
- 1.6423788952827454
- 1.5485702657699585
- 1.4778213930130004
- 1.472509491443634
- 1.433103837966919
- 1.522782130241394
- 1.4590472269058228
- 1.6803576946258545
- 1.5323490715026855
- 1.5207552671432496
- 1.8086392545700074
- 1.5491619873046876
- 1.3945967030525208
- 1.5940620136260986
- 1.7541793203353881
- 1.4575447845458984
- 1.4866308164596558
- 1.7064433693885803
- 1.7356723690032958
- 1.5615608859062196
- 1.3590089344978333
- 1.4622788906097413
- 1.38101313829422
- 1.453147029876709
- 1.4713905358314514
- 1.4577073287963866
- 1.372676932811737
- 1.4427831625938417
- 1.4863428831100465
- 1.4825273871421814
- 1.4393870520591736
- 1.439608941078186
- 1.4498571968078613
- 1.6607578921318054
- 1.4556534433364867
- 1.4412430810928345
- 1.44968825340271
- 1.4654432821273804
- 1.439392967224121
- 1.4714717173576355
- 1.3555371427536012
- 1.4140901422500611
- 1.4954959511756898
- 1.4920733332633973
- 1.4952906489372253
- 1.631171896457672
- 1.718678250312805
- 1.5431642317771912
- 1.457409179210663
- 1.489091420173645
- 1.5052746844291687
- 1.4374493598937987
- 1.4350530219078064
- 1.482573983669281
- 1.3610288071632386
- 1.5752866315841674
- 1.3515161776542663
- 1.4454878854751587
- 1.3356748938560485
- 1.3623646378517151
- 1.4248156023025513
- 1.5129628038406373
- 1.4953786826133728
- 1.5421006274223328
- 1.5183260393142701
- 1.4277438068389892
- 1.3603521037101745
- 1.4452580213546753
- 1.540614185333252
train_accuracy:
- 0.478
- 0.254
- 0.259
- 0.345
- 0.562
- 0.044
- 0.015
- 0.115
- 0.017
- 0.007
- 0.289
- 0.485
- 0.004
- 0.647
- 0.052
- 0.259
- 0.088
- 0.178
- 0.039
- 0.132
- 0.467
- 0.079
- 0.062
- 0.634
- 0.066
- 0.82
- 0.066
- 0.688
- 0.165
- 0.141
- 0.291
- 0.796
- 0.093
- 0.666
- 0.116
- 0.61
- 0.571
- 0.527
- 0.466
- 0.769
- 0.785
- 0.509
- 0.094
- 0.198
- 0.56
- 0.64
- 0.669
- 0.654
- 0.606
- 0.685
- 0.608
- 0.215
- 0.117
- 0.256
- 0.154
- 0.119
- 0.702
- 0.209
- 0.406
- 0.712
- 0.691
- 0.147
- 0.654
- 0.119
- 0.657
- 0.485
- 0.136
- 0.611
- 0.63
- 0.436
- 0.12
- 0.221
- 0.187
- 0.564
- 0.793
- 0.134
- 0.599
- 0.739
- 0.689
- 0.69
- 0.673
- 0.115
- 0.308
- 0.722
- 0.412
- 0.222
- 0.792
- 0.228
- 0.585
- 0.253
- 0.24
- 0.186
- 0.323
- 0.147
- 0.5
- 0.705
- 0.133
- 0.367
- 0.598
- 0.668
train_loss:
- 1.798
- 1.727
- 0.558
- 0.394
- 1.512
- 2.697
- 1.429
- 0.458
- 1.375
- 0.365
- 1.345
- 0.289
- 1.255
- 0.263
- 2.213
- 0.335
- 2.173
- 0.356
- 1.119
- 1.954
- 0.996
- 1.198
- 1.003
- 1.072
- 0.972
- 0.901
- 0.906
- 0.921
- 1.749
- 1.517
- 0.248
- 0.733
- 0.899
- 1.36
- 1.058
- 1.434
- 0.905
- 0.867
- 0.23
- 0.677
- 0.779
- 0.155
- 0.721
- 1.291
- 0.234
- 0.162
- 0.794
- 0.743
- 0.168
- 0.178
- 0.657
- 1.186
- 0.678
- 1.551
- 0.645
- 0.668
- 0.604
- 1.005
- 0.585
- 0.534
- 0.514
- 0.599
- 0.549
- 0.532
- 0.147
- 0.597
- 0.508
- 0.526
- 0.483
- 0.472
- 0.412
- 0.717
- 0.557
- 0.198
- 0.381
- 0.384
- 0.161
- 0.153
- 0.463
- 0.443
- 0.348
- 0.342
- 0.493
- 0.354
- 0.314
- 0.753
- 0.143
- 0.597
- 0.193
- 0.624
- 0.587
- 0.352
- 0.165
- 0.321
- 0.168
- 0.318
- 0.371
- 0.536
- 0.298
- 0.169
unequal: 0
verbose: 1
