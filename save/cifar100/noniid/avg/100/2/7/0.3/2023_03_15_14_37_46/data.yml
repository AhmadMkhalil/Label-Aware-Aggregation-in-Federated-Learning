avg_train_accuracy: 0.239
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0143
- 0.0186
- 0.0228
- 0.0495
- 0.0691
- 0.0823
- 0.0545
- 0.0616
- 0.0526
- 0.0764
- 0.042
- 0.0521
- 0.0991
- 0.0854
- 0.088
- 0.0919
- 0.0565
- 0.0785
- 0.0861
- 0.0955
- 0.0505
- 0.0873
- 0.0575
- 0.0464
- 0.0782
- 0.0846
- 0.0604
- 0.1682
- 0.0816
- 0.0643
- 0.087
- 0.0675
- 0.0981
- 0.0994
- 0.1659
- 0.1386
- 0.0766
- 0.1779
- 0.1093
- 0.1087
- 0.1324
- 0.0927
- 0.117
- 0.119
- 0.1237
- 0.0764
- 0.1101
- 0.1249
- 0.096
- 0.073
- 0.1021
- 0.1192
- 0.091
- 0.1218
- 0.0861
- 0.0704
- 0.1056
- 0.0854
- 0.0727
- 0.1086
- 0.0843
- 0.1856
- 0.1971
- 0.1979
- 0.1154
- 0.1481
- 0.2024
- 0.1536
- 0.1507
- 0.1451
- 0.1535
- 0.1541
- 0.2003
- 0.1278
- 0.1601
- 0.1646
- 0.0938
- 0.1029
- 0.2011
- 0.1725
- 0.1718
- 0.1216
- 0.0945
- 0.2121
- 0.1269
- 0.1161
- 0.0744
- 0.1356
- 0.0972
- 0.1412
- 0.1592
- 0.2313
- 0.1893
- 0.1912
- 0.2163
- 0.1448
- 0.1772
- 0.1653
- 0.1743
- 0.2117
test_loss_list:
- 1.9621798086166382
- 1.9482850313186646
- 1.868149423599243
- 1.7241200971603394
- 1.6971256160736083
- 1.6501879382133484
- 1.7142228627204894
- 1.6737788200378418
- 1.7427192521095276
- 1.6212126064300536
- 1.834118447303772
- 1.7206165075302124
- 1.5667954206466674
- 1.6427549648284911
- 1.6190990138053893
- 1.6139633989334106
- 1.8160529851913452
- 1.5935564708709717
- 1.618074791431427
- 1.573483476638794
- 1.892838954925537
- 1.6261060690879823
- 1.7966865825653076
- 1.9837067365646361
- 1.5971518111228944
- 1.6346742463111879
- 1.781369128227234
- 1.4486923837661743
- 1.6824670696258546
- 1.819223074913025
- 1.6466765308380127
- 1.7777391147613526
- 1.603379020690918
- 1.5795998787879943
- 1.4626888275146483
- 1.511336052417755
- 1.7388113498687745
- 1.439857144355774
- 1.60526620388031
- 1.6080738377571107
- 1.5193088364601135
- 1.6424153089523315
- 1.5179702854156494
- 1.52545166015625
- 1.519750394821167
- 1.7443178749084474
- 1.590997004508972
- 1.5457962465286255
- 1.6637285470962524
- 1.751029872894287
- 1.5820390677452087
- 1.5401177644729613
- 1.6922630167007446
- 1.5364678478240967
- 1.7369168567657471
- 1.8046279764175415
- 1.5926395344734192
- 1.7799245166778563
- 1.7999122333526612
- 1.5961590027809143
- 1.7093867540359498
- 1.3952166247367859
- 1.4048625636100769
- 1.4238118147850036
- 1.6733301997184753
- 1.5173763227462769
- 1.4120259761810303
- 1.4712938809394835
- 1.4653261351585387
- 1.466421790122986
- 1.4764175701141358
- 1.4814765286445617
- 1.3926153707504272
- 1.5717755150794983
- 1.4778103494644166
- 1.4568441605567932
- 1.786459288597107
- 1.7026735353469848
- 1.3661574554443359
- 1.4448376679420472
- 1.4532364892959595
- 1.6212541246414185
- 1.7454923677444458
- 1.3681373238563537
- 1.5946755695343018
- 1.6611482214927673
- 1.9083537721633912
- 1.5199334239959716
- 1.7662581968307496
- 1.5082895159721375
- 1.4777275323867798
- 1.3631462454795837
- 1.446719717979431
- 1.4150908088684082
- 1.3754101991653442
- 1.5541931295394897
- 1.4514020442962647
- 1.4761185574531555
- 1.4587322187423706
- 1.3817559885978699
train_accuracy:
- 0.506
- 0.0
- 0.0
- 0.051
- 0.665
- 0.084
- 0.175
- 0.074
- 0.548
- 0.373
- 0.723
- 0.046
- 0.099
- 0.08
- 0.434
- 0.077
- 0.279
- 0.837
- 0.562
- 0.423
- 0.34
- 0.556
- 0.518
- 0.322
- 0.424
- 0.57
- 0.62
- 0.175
- 0.59
- 0.344
- 0.042
- 0.475
- 0.084
- 0.613
- 0.15
- 0.703
- 0.23
- 0.2
- 0.449
- 0.079
- 0.522
- 0.295
- 0.726
- 0.704
- 0.436
- 0.693
- 0.105
- 0.48
- 0.789
- 0.448
- 0.553
- 0.769
- 0.425
- 0.697
- 0.608
- 0.694
- 0.101
- 0.508
- 0.669
- 0.734
- 0.67
- 0.644
- 0.548
- 0.223
- 0.279
- 0.123
- 0.196
- 0.513
- 0.35
- 0.121
- 0.593
- 0.636
- 0.676
- 0.743
- 0.133
- 0.692
- 0.54
- 0.18
- 0.201
- 0.58
- 0.157
- 0.339
- 0.515
- 0.555
- 0.464
- 0.445
- 0.591
- 0.537
- 0.602
- 0.735
- 0.6
- 0.288
- 0.352
- 0.509
- 0.603
- 0.728
- 0.175
- 0.143
- 0.468
- 0.239
train_loss:
- 1.864
- 1.641
- 1.559
- 2.542
- 2.403
- 2.441
- 1.366
- 0.497
- 1.19
- 1.364
- 0.388
- 1.213
- 1.953
- 1.207
- 1.213
- 1.103
- 0.279
- 1.086
- 1.112
- 1.093
- 0.268
- 1.003
- 0.289
- 0.219
- 0.888
- 0.803
- 0.259
- 1.741
- 0.324
- 0.259
- 0.945
- 0.261
- 0.809
- 0.796
- 1.615
- 0.844
- 0.256
- 1.308
- 0.235
- 0.703
- 0.954
- 0.226
- 0.78
- 0.694
- 0.641
- 0.154
- 0.743
- 0.741
- 0.22
- 0.137
- 0.668
- 0.631
- 0.246
- 0.646
- 0.154
- 0.148
- 0.618
- 0.149
- 0.195
- 0.74
- 0.158
- 1.071
- 1.099
- 1.042
- 0.158
- 0.575
- 1.001
- 0.252
- 0.485
- 0.55
- 0.469
- 0.475
- 0.811
- 0.152
- 0.584
- 0.592
- 0.107
- 0.166
- 0.748
- 0.548
- 0.419
- 0.127
- 0.14
- 0.783
- 0.169
- 0.143
- 0.085
- 0.454
- 0.084
- 0.409
- 0.453
- 0.969
- 0.439
- 0.422
- 0.658
- 0.163
- 0.391
- 0.352
- 0.378
- 0.591
unequal: 0
verbose: 1
