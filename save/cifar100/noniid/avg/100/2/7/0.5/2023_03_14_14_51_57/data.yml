avg_train_accuracy: 0.539
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0161
- 0.0271
- 0.0233
- 0.0468
- 0.0259
- 0.0598
- 0.0556
- 0.0688
- 0.0546
- 0.1217
- 0.0886
- 0.071
- 0.1102
- 0.0987
- 0.1461
- 0.1205
- 0.162
- 0.1292
- 0.1525
- 0.1522
- 0.1329
- 0.11
- 0.1124
- 0.1127
- 0.1113
- 0.1214
- 0.1101
- 0.1489
- 0.1316
- 0.1825
- 0.1517
- 0.1583
- 0.163
- 0.1652
- 0.1831
- 0.1198
- 0.1343
- 0.1953
- 0.1727
- 0.1807
- 0.116
- 0.1717
- 0.1887
- 0.1981
- 0.1593
- 0.1989
- 0.197
- 0.1736
- 0.2012
- 0.1671
- 0.1928
- 0.182
- 0.1669
- 0.1933
- 0.1717
- 0.2201
- 0.2062
- 0.1842
- 0.1921
- 0.1744
- 0.2212
- 0.1816
- 0.2039
- 0.2025
- 0.2269
- 0.1902
- 0.1732
- 0.1684
- 0.2162
- 0.2146
- 0.1808
- 0.2058
- 0.2088
- 0.1801
- 0.1873
- 0.2051
- 0.1775
- 0.1826
- 0.2167
- 0.2133
- 0.2159
- 0.1923
- 0.1834
- 0.1736
- 0.1344
- 0.2274
- 0.2025
- 0.2028
- 0.2076
- 0.2011
- 0.206
- 0.217
- 0.2123
- 0.1836
- 0.1711
- 0.209
- 0.217
- 0.1992
- 0.193
- 0.1783
test_loss_list:
- 1.8796832513809205
- 1.824256978034973
- 1.7820776510238647
- 1.7038049745559691
- 1.8760155200958253
- 1.680568618774414
- 1.6929987907409667
- 1.6280503749847413
- 1.6952040481567383
- 1.5565668654441833
- 1.5865498495101928
- 1.6514003562927246
- 1.5671474504470826
- 1.5781257343292237
- 1.4941389107704162
- 1.5372433042526246
- 1.477894003391266
- 1.5168956637382507
- 1.4823872804641725
- 1.4697180962562562
- 1.5156816029548645
- 1.5659134578704834
- 1.545750424861908
- 1.5333863806724548
- 1.5525503063201904
- 1.533326539993286
- 1.5683676886558533
- 1.4672953987121582
- 1.526558804512024
- 1.4206919622421266
- 1.4646076273918152
- 1.4438422584533692
- 1.4392915892601013
- 1.4387073874473573
- 1.412663414478302
- 1.571022868156433
- 1.5220546317100525
- 1.3737711262702943
- 1.4298999428749084
- 1.409123191833496
- 1.599460368156433
- 1.4234591102600098
- 1.4023605632781981
- 1.366181366443634
- 1.4475555634498596
- 1.3809347534179688
- 1.3770703625679017
- 1.431483449935913
- 1.3738266229629517
- 1.4418765211105347
- 1.3775882244110107
- 1.4110151314735413
- 1.4612559747695923
- 1.3766685247421264
- 1.4252779769897461
- 1.350080292224884
- 1.3804331827163696
- 1.3883096194267273
- 1.381204469203949
- 1.427262349128723
- 1.3457293558120726
- 1.4248376512527465
- 1.3677231025695802
- 1.375451817512512
- 1.3376087164878845
- 1.4089848184585572
- 1.4432307910919189
- 1.4186953139305114
- 1.3375221014022827
- 1.3525224018096924
- 1.4130075573921204
- 1.3522568464279174
- 1.34672354221344
- 1.4175951528549193
- 1.4032964897155762
- 1.3633773946762084
- 1.4265884923934937
- 1.4041947627067566
- 1.3545726466178893
- 1.343850712776184
- 1.3472228169441223
- 1.3995641994476318
- 1.4225346040725708
- 1.4421002316474913
- 1.6130783438682557
- 1.3189459180831908
- 1.3750794863700866
- 1.3638712024688722
- 1.3675230193138121
- 1.3819453835487365
- 1.3700385546684266
- 1.3546623468399048
- 1.3560758471488952
- 1.435102391242981
- 1.461619927883148
- 1.3724864220619202
- 1.3654441857337951
- 1.4148962807655334
- 1.4178786420822143
- 1.4626827907562256
train_accuracy:
- 0.463
- 0.426
- 0.015
- 0.34
- 0.318
- 0.031
- 0.051
- 0.05
- 0.003
- 0.093
- 0.039
- 0.449
- 0.428
- 0.068
- 0.142
- 0.036
- 0.273
- 0.313
- 0.129
- 0.144
- 0.129
- 0.602
- 0.092
- 0.423
- 0.065
- 0.432
- 0.497
- 0.595
- 0.244
- 0.413
- 0.346
- 0.027
- 0.177
- 0.164
- 0.167
- 0.51
- 0.698
- 0.307
- 0.485
- 0.17
- 0.218
- 0.161
- 0.545
- 0.077
- 0.067
- 0.216
- 0.204
- 0.435
- 0.205
- 0.465
- 0.105
- 0.461
- 0.697
- 0.517
- 0.362
- 0.328
- 0.4
- 0.692
- 0.131
- 0.508
- 0.461
- 0.312
- 0.214
- 0.372
- 0.254
- 0.631
- 0.606
- 0.706
- 0.233
- 0.607
- 0.606
- 0.175
- 0.208
- 0.144
- 0.515
- 0.317
- 0.607
- 0.349
- 0.58
- 0.239
- 0.434
- 0.501
- 0.447
- 0.657
- 0.502
- 0.277
- 0.712
- 0.375
- 0.259
- 0.208
- 0.224
- 0.658
- 0.719
- 0.491
- 0.167
- 0.613
- 0.344
- 0.557
- 0.518
- 0.539
train_loss:
- 2.075
- 1.846
- 1.127
- 1.756
- 0.411
- 1.644
- 0.968
- 1.588
- 0.911
- 2.065
- 0.9
- 0.843
- 1.383
- 0.847
- 1.866
- 0.82
- 1.75
- 0.786
- 1.206
- 1.175
- 0.68
- 0.702
- 0.714
- 0.688
- 0.655
- 0.633
- 0.62
- 0.997
- 0.604
- 1.444
- 0.614
- 1.017
- 0.962
- 0.934
- 0.991
- 0.181
- 0.565
- 1.299
- 0.514
- 0.846
- 0.181
- 0.835
- 0.783
- 1.192
- 0.452
- 0.757
- 0.727
- 0.462
- 0.688
- 0.418
- 0.806
- 0.49
- 0.437
- 0.697
- 0.444
- 0.927
- 0.679
- 0.439
- 0.631
- 0.384
- 0.636
- 0.368
- 0.581
- 0.581
- 0.786
- 0.35
- 0.312
- 0.35
- 0.738
- 0.335
- 0.343
- 0.554
- 0.501
- 0.318
- 0.333
- 0.472
- 0.282
- 0.31
- 0.467
- 0.448
- 0.434
- 0.272
- 0.305
- 0.281
- 0.093
- 0.593
- 0.243
- 0.379
- 0.407
- 0.234
- 0.365
- 0.41
- 0.289
- 0.203
- 0.198
- 0.387
- 0.339
- 0.248
- 0.205
- 0.177
unequal: 0
verbose: 1
