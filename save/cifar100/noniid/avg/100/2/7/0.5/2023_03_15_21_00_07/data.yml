avg_train_accuracy: 0.281
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0145
- 0.0231
- 0.0479
- 0.0867
- 0.0581
- 0.0782
- 0.0648
- 0.0474
- 0.0581
- 0.0666
- 0.0955
- 0.0811
- 0.1145
- 0.1258
- 0.1317
- 0.1309
- 0.1048
- 0.1324
- 0.1393
- 0.1421
- 0.1492
- 0.1201
- 0.1497
- 0.1581
- 0.088
- 0.0796
- 0.1323
- 0.1305
- 0.1144
- 0.1156
- 0.1221
- 0.1212
- 0.1853
- 0.1545
- 0.1693
- 0.1393
- 0.181
- 0.14
- 0.1331
- 0.1937
- 0.185
- 0.1554
- 0.1784
- 0.1348
- 0.1356
- 0.1349
- 0.1378
- 0.1421
- 0.2034
- 0.2036
- 0.197
- 0.1974
- 0.1956
- 0.1941
- 0.1707
- 0.1972
- 0.1376
- 0.1846
- 0.1742
- 0.1593
- 0.1597
- 0.1933
- 0.1757
- 0.1691
- 0.2172
- 0.2059
- 0.2091
- 0.1919
- 0.1722
- 0.1751
- 0.1341
- 0.1061
- 0.1344
- 0.1849
- 0.2063
- 0.1817
- 0.2021
- 0.1948
- 0.2231
- 0.2006
- 0.1711
- 0.2109
- 0.19
- 0.2097
- 0.1502
- 0.1588
- 0.2104
- 0.1815
- 0.2093
- 0.1893
- 0.1398
- 0.1705
- 0.1658
- 0.1672
- 0.2017
- 0.1784
- 0.2011
- 0.1859
- 0.233
- 0.2069
test_loss_list:
- 1.8804675149917602
- 1.8570017004013062
- 1.7302613353729248
- 1.6532767415046692
- 1.6637633681297301
- 1.640915243625641
- 1.6744918060302734
- 1.7973117208480835
- 1.7031169033050537
- 1.7033164405822754
- 1.5858568263053894
- 1.6149617719650269
- 1.5433442306518554
- 1.5234609150886536
- 1.5077750706672668
- 1.502571952342987
- 1.5709629273414611
- 1.4994877409934997
- 1.5007667183876037
- 1.4967470455169678
- 1.4908669686317444
- 1.5614901518821716
- 1.476458365917206
- 1.4770953679084777
- 1.614615902900696
- 1.7236224603652954
- 1.4984353041648866
- 1.5092473912239075
- 1.5644629573822022
- 1.5687140774726869
- 1.5131050968170165
- 1.5355402374267577
- 1.399363775253296
- 1.4497657895088196
- 1.4133092212677
- 1.4890673518180848
- 1.4156832456588746
- 1.4923890042304992
- 1.4867326641082763
- 1.3880376052856445
- 1.4099590277671814
- 1.4510436415672303
- 1.4156406927108764
- 1.5019998145103455
- 1.5162020230293274
- 1.5146363258361817
- 1.5076869320869446
- 1.4859170126914978
- 1.3659668159484863
- 1.3624887776374817
- 1.392370240688324
- 1.3871597790718078
- 1.3863418912887573
- 1.379847936630249
- 1.4432880067825318
- 1.3713017988204956
- 1.5306207370758056
- 1.4053758525848388
- 1.4078002405166625
- 1.4621670746803284
- 1.450480580329895
- 1.3731060671806334
- 1.428063452243805
- 1.4435372972488403
- 1.3366078066825866
- 1.3729317808151245
- 1.3502924609184266
- 1.3911033749580384
- 1.423455035686493
- 1.4264403891563415
- 1.5705674505233764
- 1.7055473136901855
- 1.5573141694068908
- 1.393455879688263
- 1.3469583153724671
- 1.4146754598617555
- 1.377880220413208
- 1.3944807243347168
- 1.320683274269104
- 1.374188120365143
- 1.4554031109809875
- 1.3561005043983458
- 1.4071238732337952
- 1.3692268109321595
- 1.5104185461997985
- 1.4880021715164184
- 1.3606961560249329
- 1.423618905544281
- 1.3745123600959779
- 1.4147185730934142
- 1.5704995584487915
- 1.4720029878616332
- 1.4976835799217225
- 1.4712601757049562
- 1.3886546659469605
- 1.4308225059509276
- 1.3589189314842225
- 1.4164120316505433
- 1.3182507252693176
- 1.3676504158973695
train_accuracy:
- 0.115
- 0.332
- 0.011
- 0.065
- 0.064
- 0.046
- 0.441
- 0.312
- 0.386
- 0.067
- 0.05
- 0.627
- 0.087
- 0.469
- 0.105
- 0.344
- 0.051
- 0.373
- 0.408
- 0.108
- 0.171
- 0.055
- 0.118
- 0.298
- 0.036
- 0.309
- 0.072
- 0.298
- 0.394
- 0.488
- 0.346
- 0.198
- 0.136
- 0.279
- 0.414
- 0.414
- 0.27
- 0.085
- 0.301
- 0.133
- 0.212
- 0.126
- 0.136
- 0.636
- 0.087
- 0.355
- 0.358
- 0.231
- 0.25
- 0.225
- 0.311
- 0.416
- 0.145
- 0.309
- 0.382
- 0.137
- 0.36
- 0.427
- 0.548
- 0.082
- 0.412
- 0.32
- 0.106
- 0.332
- 0.245
- 0.224
- 0.255
- 0.261
- 0.469
- 0.375
- 0.248
- 0.296
- 0.372
- 0.299
- 0.235
- 0.166
- 0.299
- 0.379
- 0.157
- 0.182
- 0.336
- 0.177
- 0.508
- 0.4
- 0.091
- 0.149
- 0.32
- 0.184
- 0.461
- 0.503
- 0.32
- 0.617
- 0.606
- 0.273
- 0.158
- 0.125
- 0.223
- 0.167
- 0.202
- 0.281
train_loss:
- 1.994
- 1.139
- 1.772
- 2.31
- 0.988
- 1.504
- 0.926
- 0.348
- 0.873
- 0.837
- 1.385
- 0.812
- 1.388
- 1.36
- 1.277
- 1.263
- 0.702
- 1.205
- 1.174
- 1.173
- 1.115
- 0.63
- 1.085
- 1.09
- 0.253
- 0.195
- 1.037
- 0.588
- 0.558
- 0.609
- 0.622
- 0.577
- 1.411
- 0.56
- 0.907
- 0.516
- 1.241
- 0.234
- 0.574
- 1.21
- 0.862
- 0.494
- 0.795
- 0.217
- 0.449
- 0.433
- 0.463
- 0.51
- 1.067
- 0.786
- 0.721
- 0.748
- 0.684
- 0.66
- 0.43
- 0.706
- 0.144
- 0.637
- 0.427
- 0.375
- 0.396
- 0.617
- 0.363
- 0.349
- 0.821
- 0.58
- 0.579
- 0.364
- 0.333
- 0.34
- 0.113
- 0.084
- 0.303
- 0.499
- 0.562
- 0.33
- 0.507
- 0.296
- 0.695
- 0.304
- 0.258
- 0.453
- 0.323
- 0.462
- 0.136
- 0.28
- 0.445
- 0.271
- 0.396
- 0.24
- 0.107
- 0.244
- 0.21
- 0.222
- 0.356
- 0.249
- 0.425
- 0.256
- 0.516
- 0.258
unequal: 0
verbose: 1
