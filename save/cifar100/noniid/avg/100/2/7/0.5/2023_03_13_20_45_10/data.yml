avg_train_accuracy: 0.067
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0128
- 0.0561
- 0.0567
- 0.0429
- 0.0431
- 0.0438
- 0.0442
- 0.0486
- 0.0763
- 0.0989
- 0.1134
- 0.1117
- 0.1167
- 0.0895
- 0.1355
- 0.1587
- 0.1337
- 0.1119
- 0.1012
- 0.1321
- 0.1546
- 0.1641
- 0.1615
- 0.1646
- 0.1677
- 0.1681
- 0.1864
- 0.1785
- 0.1611
- 0.154
- 0.1728
- 0.1799
- 0.1873
- 0.1911
- 0.1575
- 0.1854
- 0.1916
- 0.1539
- 0.1119
- 0.135
- 0.1394
- 0.1449
- 0.2135
- 0.2084
- 0.1994
- 0.2089
- 0.1724
- 0.2163
- 0.2051
- 0.1771
- 0.1264
- 0.2202
- 0.1809
- 0.2032
- 0.2272
- 0.2176
- 0.2035
- 0.1824
- 0.1295
- 0.1935
- 0.2112
- 0.1833
- 0.218
- 0.2161
- 0.1908
- 0.2131
- 0.2112
- 0.1859
- 0.2085
- 0.1952
- 0.2172
- 0.2185
- 0.1958
- 0.2125
- 0.1903
- 0.2216
- 0.203
- 0.1762
- 0.2227
- 0.2211
- 0.2306
- 0.239
- 0.2408
- 0.2386
- 0.1858
- 0.2328
- 0.2215
- 0.225
- 0.2394
- 0.1999
- 0.2122
- 0.1564
- 0.1428
- 0.1676
- 0.1338
- 0.1602
- 0.2149
- 0.1927
- 0.217
- 0.2274
test_loss_list:
- 1.874382004737854
- 1.7563810014724732
- 1.7201402759552002
- 1.728746395111084
- 1.7429651880264283
- 1.7411171627044677
- 1.7397667217254638
- 1.745851616859436
- 1.6394506812095642
- 1.604434847831726
- 1.570765371322632
- 1.555599479675293
- 1.5515123224258422
- 1.5880719494819642
- 1.500030083656311
- 1.4949710202217101
- 1.5069930243492127
- 1.5465480518341064
- 1.593974461555481
- 1.518329598903656
- 1.466802659034729
- 1.4469740247726441
- 1.4607321786880494
- 1.4528015065193176
- 1.4505495429039001
- 1.4407362127304078
- 1.4081470441818238
- 1.427511396408081
- 1.446134216785431
- 1.4610782885551452
- 1.4171014547348022
- 1.4098379063606261
- 1.4034132528305054
- 1.4017327070236205
- 1.44088130235672
- 1.4008044767379761
- 1.3975989389419556
- 1.4666193008422852
- 1.5586730027198792
- 1.4863335180282593
- 1.4884589314460754
- 1.469344780445099
- 1.3552093625068664
- 1.3710136032104492
- 1.3873917698860168
- 1.3586727333068849
- 1.4173925018310547
- 1.342396490573883
- 1.3728730463981629
- 1.4269107294082641
- 1.5560997319221497
- 1.3353544282913208
- 1.41510596036911
- 1.3805143928527832
- 1.3493263483047486
- 1.3500720405578612
- 1.359967749118805
- 1.3987788319587708
- 1.553862018585205
- 1.3789591693878174
- 1.3544005250930786
- 1.40225200176239
- 1.3449457025527953
- 1.332358729839325
- 1.3940244007110596
- 1.3475556540489197
- 1.3545644235610963
- 1.4136337590217591
- 1.3715063548088073
- 1.3817959928512573
- 1.358295111656189
- 1.3465475869178771
- 1.397533347606659
- 1.3638953375816345
- 1.4106476378440858
- 1.3363717317581176
- 1.3751559042930603
- 1.4416000628471375
- 1.3297574877738954
- 1.3419431400299073
- 1.330908682346344
- 1.3119748091697694
- 1.311992962360382
- 1.333070352077484
- 1.4349124693870545
- 1.3168589687347412
- 1.3450981616973876
- 1.3358933925628662
- 1.3071590781211853
- 1.3957716560363769
- 1.3689464664459228
- 1.5357934308052064
- 1.559980366230011
- 1.4998294472694398
- 1.6642538404464722
- 1.5159703159332276
- 1.360728418827057
- 1.4185013914108275
- 1.364566810131073
- 1.3464766883850097
train_accuracy:
- 0.333
- 0.046
- 0.106
- 0.227
- 0.304
- 0.567
- 0.002
- 0.177
- 0.037
- 0.059
- 0.078
- 0.012
- 0.124
- 0.04
- 0.009
- 0.199
- 0.035
- 0.221
- 0.222
- 0.536
- 0.149
- 0.159
- 0.297
- 0.39
- 0.164
- 0.006
- 0.199
- 0.167
- 0.074
- 0.188
- 0.255
- 0.255
- 0.14
- 0.28
- 0.112
- 0.3
- 0.463
- 0.127
- 0.089
- 0.439
- 0.101
- 0.105
- 0.216
- 0.209
- 0.508
- 0.324
- 0.369
- 0.241
- 0.338
- 0.539
- 0.508
- 0.182
- 0.515
- 0.565
- 0.43
- 0.224
- 0.031
- 0.572
- 0.315
- 0.136
- 0.221
- 0.141
- 0.196
- 0.184
- 0.134
- 0.142
- 0.274
- 0.52
- 0.291
- 0.03
- 0.248
- 0.218
- 0.28
- 0.198
- 0.428
- 0.197
- 0.324
- 0.605
- 0.526
- 0.163
- 0.225
- 0.194
- 0.184
- 0.28
- 0.599
- 0.416
- 0.536
- 0.388
- 0.123
- 0.2
- 0.337
- 0.325
- 0.113
- 0.125
- 0.652
- 0.553
- 0.434
- 0.123
- 0.455
- 0.067
train_loss:
- 2.076
- 2.568
- 1.185
- 1.106
- 1.026
- 1.048
- 0.981
- 0.921
- 1.52
- 1.474
- 1.455
- 1.419
- 1.349
- 0.826
- 1.327
- 1.776
- 0.802
- 0.749
- 0.689
- 1.167
- 1.158
- 1.144
- 1.128
- 1.094
- 1.049
- 1.054
- 1.04
- 1.014
- 0.623
- 0.643
- 0.932
- 0.959
- 0.933
- 0.875
- 0.555
- 0.835
- 0.844
- 0.563
- 0.222
- 0.51
- 0.49
- 0.461
- 1.101
- 0.75
- 0.703
- 0.818
- 0.495
- 0.985
- 0.437
- 0.388
- 0.177
- 0.97
- 0.426
- 0.606
- 0.851
- 0.62
- 0.457
- 0.398
- 0.148
- 0.575
- 0.563
- 0.36
- 0.559
- 0.598
- 0.36
- 0.546
- 0.515
- 0.339
- 0.512
- 0.338
- 0.472
- 0.481
- 0.296
- 0.438
- 0.282
- 0.495
- 0.33
- 0.263
- 0.456
- 0.43
- 0.421
- 0.567
- 0.54
- 0.515
- 0.156
- 0.385
- 0.366
- 0.384
- 0.401
- 0.23
- 0.342
- 0.099
- 0.119
- 0.213
- 0.087
- 0.207
- 0.338
- 0.223
- 0.317
- 0.312
unequal: 0
verbose: 1
