avg_train_accuracy: 0.331
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.014
- 0.0163
- 0.0301
- 0.0527
- 0.0703
- 0.0722
- 0.0796
- 0.0949
- 0.08
- 0.0654
- 0.1323
- 0.1311
- 0.1476
- 0.1372
- 0.1425
- 0.1278
- 0.1132
- 0.1392
- 0.1534
- 0.1288
- 0.1206
- 0.1463
- 0.1826
- 0.1229
- 0.1552
- 0.111
- 0.1193
- 0.1302
- 0.1256
- 0.1652
- 0.1183
- 0.1103
- 0.0833
- 0.0978
- 0.1939
- 0.1858
- 0.189
- 0.1595
- 0.1752
- 0.2005
- 0.1605
- 0.1081
- 0.0951
- 0.1196
- 0.1697
- 0.127
- 0.1867
- 0.148
- 0.1825
- 0.1992
- 0.2113
- 0.1749
- 0.1216
- 0.1929
- 0.1732
- 0.2158
- 0.2051
- 0.1855
- 0.204
- 0.2201
- 0.1958
- 0.1881
- 0.207
- 0.1814
- 0.2034
- 0.1334
- 0.1503
- 0.1587
- 0.1198
- 0.2139
- 0.1885
- 0.2137
- 0.1775
- 0.2144
- 0.1892
- 0.1787
- 0.2115
- 0.1902
- 0.2052
- 0.1865
- 0.1853
- 0.2087
- 0.2144
- 0.1823
- 0.183
- 0.1673
- 0.2059
- 0.2111
- 0.2206
- 0.1938
- 0.2159
- 0.196
- 0.1782
- 0.207
- 0.1646
- 0.1655
- 0.2079
- 0.2123
- 0.1799
- 0.1732
test_loss_list:
- 2.0142370462417603
- 1.8952569246292115
- 1.773590121269226
- 1.7136823511123658
- 1.6753887748718261
- 1.663566551208496
- 1.6424183535575867
- 1.5980832529067994
- 1.6183010244369507
- 1.6896798086166382
- 1.5455148220062256
- 1.5342368268966675
- 1.5270841026306152
- 1.5343849277496338
- 1.5224633526802063
- 1.5096009516716002
- 1.5338366508483887
- 1.4897267198562623
- 1.4706603002548218
- 1.5199882411956787
- 1.5290434861183166
- 1.4772972464561462
- 1.4402532649040223
- 1.5190224242210388
- 1.4551897072792053
- 1.5738281464576722
- 1.5342750096321105
- 1.5163368940353394
- 1.536814076900482
- 1.4295672607421874
- 1.5477684617042542
- 1.5504771971702576
- 1.6888342428207397
- 1.6032334089279174
- 1.3846064758300782
- 1.4106396198272706
- 1.3956986212730407
- 1.438014566898346
- 1.4161840057373047
- 1.3705997967720032
- 1.4413357281684875
- 1.5917799973487854
- 1.6572106528282164
- 1.5648869228363038
- 1.4141732811927796
- 1.5479142546653748
- 1.3851695442199707
- 1.4672709369659425
- 1.3898996233940124
- 1.3662396049499512
- 1.3570906043052673
- 1.4197512125968934
- 1.5374418520927429
- 1.3647717595100404
- 1.4097344017028808
- 1.3440304493904114
- 1.3615069723129272
- 1.389728193283081
- 1.3694557189941405
- 1.3438259911537171
- 1.3693353366851806
- 1.3901864957809449
- 1.3433824348449708
- 1.4008980369567872
- 1.3551548933982849
- 1.543016357421875
- 1.4844073486328124
- 1.4413133001327514
- 1.5806104993820191
- 1.3322179746627807
- 1.4006893038749695
- 1.3324111032485961
- 1.416364562511444
- 1.3358206415176392
- 1.3879814839363098
- 1.4249224805831908
- 1.3409160590171814
- 1.3962606739997865
- 1.3572678637504578
- 1.3940929055213929
- 1.392482795715332
- 1.3431477999687196
- 1.3359416437149048
- 1.4051300978660584
- 1.40308744430542
- 1.4436711764335632
- 1.3577454161643983
- 1.3447134566307068
- 1.3420634627342225
- 1.409430980682373
- 1.337392122745514
- 1.3796231722831727
- 1.4205488085746765
- 1.3665399885177612
- 1.4611085915565492
- 1.4692031979560851
- 1.3558342099189757
- 1.3453394198417663
- 1.4397152614593507
- 1.4454243540763856
train_accuracy:
- 0.0
- 0.002
- 0.056
- 0.029
- 0.519
- 0.049
- 0.044
- 0.112
- 0.452
- 0.172
- 0.107
- 0.102
- 0.127
- 0.615
- 0.147
- 0.495
- 0.112
- 0.16
- 0.199
- 0.26
- 0.061
- 0.488
- 0.362
- 0.066
- 0.126
- 0.621
- 0.486
- 0.449
- 0.633
- 0.589
- 0.265
- 0.629
- 0.694
- 0.042
- 0.237
- 0.149
- 0.192
- 0.104
- 0.135
- 0.097
- 0.293
- 0.445
- 0.64
- 0.403
- 0.615
- 0.24
- 0.594
- 0.524
- 0.289
- 0.486
- 0.294
- 0.519
- 0.646
- 0.115
- 0.313
- 0.287
- 0.239
- 0.182
- 0.179
- 0.245
- 0.184
- 0.185
- 0.166
- 0.144
- 0.145
- 0.633
- 0.57
- 0.107
- 0.52
- 0.364
- 0.145
- 0.429
- 0.371
- 0.17
- 0.451
- 0.574
- 0.64
- 0.416
- 0.331
- 0.451
- 0.35
- 0.543
- 0.217
- 0.307
- 0.133
- 0.658
- 0.345
- 0.235
- 0.172
- 0.317
- 0.471
- 0.153
- 0.573
- 0.494
- 0.507
- 0.465
- 0.535
- 0.323
- 0.325
- 0.331
train_loss:
- 0.575
- 1.993
- 1.819
- 1.757
- 1.724
- 1.612
- 1.553
- 1.522
- 0.959
- 0.874
- 1.949
- 1.428
- 1.846
- 1.296
- 1.274
- 0.785
- 0.778
- 1.198
- 1.218
- 0.729
- 0.706
- 1.131
- 1.534
- 0.28
- 1.038
- 0.239
- 0.669
- 0.643
- 0.613
- 1.003
- 0.235
- 0.568
- 0.197
- 0.586
- 1.374
- 0.947
- 0.948
- 0.567
- 0.887
- 0.891
- 0.55
- 0.169
- 0.168
- 0.487
- 0.834
- 0.176
- 0.798
- 0.447
- 0.781
- 0.801
- 1.041
- 0.464
- 0.151
- 0.766
- 0.454
- 0.988
- 0.697
- 0.412
- 0.681
- 0.884
- 0.42
- 0.376
- 0.689
- 0.405
- 0.586
- 0.133
- 0.327
- 0.374
- 0.129
- 0.806
- 0.368
- 0.582
- 0.339
- 0.545
- 0.371
- 0.296
- 0.505
- 0.294
- 0.47
- 0.35
- 0.334
- 0.511
- 0.496
- 0.301
- 0.286
- 0.282
- 0.445
- 0.421
- 0.423
- 0.235
- 0.42
- 0.297
- 0.281
- 0.401
- 0.132
- 0.244
- 0.401
- 0.39
- 0.231
- 0.234
unequal: 0
verbose: 1
