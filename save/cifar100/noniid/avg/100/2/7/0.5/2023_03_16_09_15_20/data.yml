avg_train_accuracy: 0.255
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0164
- 0.0622
- 0.027
- 0.057
- 0.0741
- 0.0778
- 0.0669
- 0.1181
- 0.1229
- 0.1253
- 0.1255
- 0.0975
- 0.1239
- 0.1559
- 0.13
- 0.1178
- 0.1401
- 0.1168
- 0.112
- 0.1142
- 0.1436
- 0.1261
- 0.1175
- 0.1137
- 0.1533
- 0.1693
- 0.1405
- 0.1289
- 0.0896
- 0.1835
- 0.1257
- 0.1218
- 0.1929
- 0.1943
- 0.1546
- 0.1424
- 0.1359
- 0.1771
- 0.1578
- 0.1895
- 0.1595
- 0.1474
- 0.1793
- 0.1193
- 0.1003
- 0.1811
- 0.1169
- 0.1842
- 0.1587
- 0.1919
- 0.1761
- 0.2095
- 0.1725
- 0.1707
- 0.2041
- 0.2119
- 0.1782
- 0.1605
- 0.1948
- 0.2019
- 0.1773
- 0.126
- 0.219
- 0.2206
- 0.1922
- 0.2242
- 0.2151
- 0.1921
- 0.2301
- 0.2201
- 0.1662
- 0.1733
- 0.1284
- 0.1486
- 0.2251
- 0.1534
- 0.1662
- 0.2044
- 0.2279
- 0.2014
- 0.197
- 0.2151
- 0.1779
- 0.2197
- 0.2215
- 0.195
- 0.1791
- 0.2141
- 0.2353
- 0.2278
- 0.2279
- 0.2006
- 0.1876
- 0.1906
- 0.1434
- 0.1698
- 0.1667
- 0.2145
- 0.1999
- 0.2197
test_loss_list:
- 1.8771312189102174
- 1.7563129329681397
- 1.835388617515564
- 1.7039579010009767
- 1.670805149078369
- 1.6706068563461303
- 1.6482897782325745
- 1.5881850218772888
- 1.5715173196792602
- 1.5590149831771851
- 1.5635926628112793
- 1.5970855069160461
- 1.5339632391929627
- 1.5066007614135741
- 1.5344299840927125
- 1.534297547340393
- 1.5062514543533325
- 1.5547630548477174
- 1.5586856245994567
- 1.5517226338386536
- 1.4826035833358764
- 1.5354550933837892
- 1.537583875656128
- 1.546213343143463
- 1.4708234930038453
- 1.452610068321228
- 1.4976058864593507
- 1.5176966166496277
- 1.6621266293525696
- 1.4175369715690613
- 1.5511188292503357
- 1.549481542110443
- 1.3988498115539552
- 1.3976677823066712
- 1.4687132883071898
- 1.4860255527496338
- 1.5141032314300538
- 1.4262014198303223
- 1.4639229631423951
- 1.3881854009628296
- 1.455580632686615
- 1.473346812725067
- 1.4087257146835328
- 1.5802971172332763
- 1.6902216672897339
- 1.39649311542511
- 1.5852968549728395
- 1.390365002155304
- 1.4547628116607667
- 1.3862153506278991
- 1.417163667678833
- 1.3619388771057128
- 1.4291693139076234
- 1.4198947072029113
- 1.3640906524658203
- 1.3598816013336181
- 1.425794632434845
- 1.4557183694839477
- 1.375309534072876
- 1.3722057223320008
- 1.428489854335785
- 1.572491385936737
- 1.3446207165718078
- 1.3560721254348755
- 1.3973929119110107
- 1.342671525478363
- 1.3517900395393372
- 1.396892158985138
- 1.3205483174324035
- 1.348814013004303
- 1.4437528467178344
- 1.4335521268844604
- 1.6109404063224793
- 1.5034195494651794
- 1.3271420836448669
- 1.4970877265930176
- 1.4562572145462036
- 1.365916678905487
- 1.3354149460792542
- 1.3721772384643556
- 1.3949123477935792
- 1.3580340552330017
- 1.4566341495513917
- 1.3424366593360901
- 1.3391006803512573
- 1.4115573620796205
- 1.4435985016822814
- 1.3592202591896057
- 1.323234121799469
- 1.3394289016723633
- 1.3343110108375549
- 1.4023567056655883
- 1.4251780200004578
- 1.4139247584342955
- 1.569750280380249
- 1.467267897129059
- 1.4790240573883056
- 1.3530986094474793
- 1.3968511772155763
- 1.3481767272949219
train_accuracy:
- 0.541
- 0.044
- 0.657
- 0.488
- 0.259
- 0.388
- 0.246
- 0.097
- 0.107
- 0.226
- 0.117
- 0.137
- 0.494
- 0.021
- 0.463
- 0.436
- 0.37
- 0.069
- 0.568
- 0.553
- 0.116
- 0.371
- 0.484
- 0.056
- 0.092
- 0.187
- 0.093
- 0.06
- 0.723
- 0.277
- 0.254
- 0.066
- 0.207
- 0.165
- 0.373
- 0.119
- 0.488
- 0.119
- 0.233
- 0.197
- 0.326
- 0.46
- 0.418
- 0.719
- 0.4
- 0.461
- 0.618
- 0.506
- 0.527
- 0.227
- 0.401
- 0.179
- 0.569
- 0.192
- 0.382
- 0.254
- 0.387
- 0.585
- 0.449
- 0.148
- 0.492
- 0.552
- 0.159
- 0.24
- 0.132
- 0.227
- 0.281
- 0.19
- 0.196
- 0.241
- 0.143
- 0.456
- 0.344
- 0.499
- 0.189
- 0.308
- 0.094
- 0.388
- 0.211
- 0.177
- 0.125
- 0.149
- 0.404
- 0.413
- 0.292
- 0.136
- 0.545
- 0.165
- 0.309
- 0.121
- 0.189
- 0.184
- 0.171
- 0.571
- 0.436
- 0.255
- 0.479
- 0.345
- 0.544
- 0.255
train_loss:
- 2.019
- 2.537
- 0.449
- 1.766
- 1.728
- 1.628
- 1.068
- 2.085
- 1.547
- 1.453
- 1.385
- 0.845
- 1.367
- 1.797
- 0.82
- 0.836
- 1.302
- 0.768
- 0.772
- 0.72
- 1.156
- 0.742
- 0.646
- 0.695
- 1.09
- 1.144
- 0.632
- 0.63
- 0.252
- 1.486
- 0.279
- 0.579
- 1.435
- 0.959
- 0.631
- 0.564
- 0.549
- 0.959
- 0.552
- 0.846
- 0.499
- 0.598
- 0.869
- 0.178
- 0.158
- 0.884
- 0.174
- 0.788
- 0.463
- 0.848
- 0.444
- 1.091
- 0.498
- 0.501
- 0.725
- 0.71
- 0.46
- 0.437
- 0.736
- 0.671
- 0.397
- 0.127
- 0.906
- 0.596
- 0.4
- 0.844
- 0.611
- 0.371
- 0.814
- 0.583
- 0.185
- 0.325
- 0.137
- 0.369
- 0.74
- 0.151
- 0.301
- 0.47
- 0.707
- 0.374
- 0.323
- 0.473
- 0.288
- 0.503
- 0.483
- 0.305
- 0.257
- 0.408
- 0.601
- 0.443
- 0.406
- 0.248
- 0.245
- 0.287
- 0.094
- 0.272
- 0.225
- 0.397
- 0.265
- 0.39
unequal: 0
verbose: 1
