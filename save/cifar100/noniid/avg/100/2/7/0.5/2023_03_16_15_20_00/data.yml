avg_train_accuracy: 0.186
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0156
- 0.0199
- 0.0292
- 0.0267
- 0.0311
- 0.0497
- 0.1014
- 0.0713
- 0.0672
- 0.0713
- 0.124
- 0.1377
- 0.139
- 0.0808
- 0.1241
- 0.1436
- 0.1249
- 0.0866
- 0.0915
- 0.1054
- 0.1439
- 0.1539
- 0.1435
- 0.094
- 0.1399
- 0.1296
- 0.164
- 0.1702
- 0.1842
- 0.1197
- 0.1192
- 0.1188
- 0.1943
- 0.1652
- 0.1528
- 0.1693
- 0.1837
- 0.1918
- 0.188
- 0.1665
- 0.1923
- 0.1971
- 0.1668
- 0.1999
- 0.2069
- 0.1977
- 0.1836
- 0.1336
- 0.1476
- 0.1198
- 0.1815
- 0.2163
- 0.2051
- 0.1812
- 0.1713
- 0.164
- 0.161
- 0.2008
- 0.2192
- 0.2171
- 0.2124
- 0.1543
- 0.2051
- 0.1507
- 0.1309
- 0.1934
- 0.1463
- 0.198
- 0.1888
- 0.2166
- 0.2113
- 0.2172
- 0.2125
- 0.1864
- 0.2176
- 0.1688
- 0.1615
- 0.1627
- 0.2278
- 0.2138
- 0.1919
- 0.2199
- 0.2164
- 0.1958
- 0.1767
- 0.218
- 0.2221
- 0.223
- 0.2207
- 0.2015
- 0.1699
- 0.2053
- 0.2162
- 0.2165
- 0.2209
- 0.2304
- 0.2049
- 0.2216
- 0.2235
- 0.2288
test_loss_list:
- 1.89203125
- 1.9653559732437134
- 1.7915239715576172
- 1.8840079402923584
- 1.8694922590255738
- 1.7061659240722655
- 1.6182690811157228
- 1.665782985687256
- 1.6505895829200745
- 1.6612914943695067
- 1.5542957639694215
- 1.541693341732025
- 1.5406453919410705
- 1.6357538151741027
- 1.5320023536682128
- 1.4857182240486144
- 1.5178759837150573
- 1.6573781275749206
- 1.627305634021759
- 1.5888209462165832
- 1.4772802114486694
- 1.4599139714241027
- 1.4789307594299317
- 1.636701407432556
- 1.4755217981338502
- 1.5170880222320557
- 1.4318217062950134
- 1.4320560026168823
- 1.4017466163635255
- 1.544443588256836
- 1.5373778247833252
- 1.5352279710769654
- 1.3936074161529541
- 1.4259132933616638
- 1.4555267548561097
- 1.431969904899597
- 1.4054403042793273
- 1.3997302770614624
- 1.4158713150024413
- 1.4406860494613647
- 1.386611394882202
- 1.3733123898506165
- 1.416346673965454
- 1.3657522344589232
- 1.352595157623291
- 1.3735330724716186
- 1.3954574942588807
- 1.5337262988090514
- 1.4772047185897828
- 1.5861471033096313
- 1.388771824836731
- 1.340100953578949
- 1.3672708821296693
- 1.4090879559516907
- 1.4329168486595154
- 1.4345549035072327
- 1.4404557275772094
- 1.3543692874908446
- 1.329540240764618
- 1.341265835762024
- 1.3544189500808717
- 1.4621994042396544
- 1.347196388244629
- 1.4956991577148437
- 1.587034194469452
- 1.3631727504730224
- 1.5124325799942016
- 1.3712627172470093
- 1.3835076069831849
- 1.3303225088119506
- 1.354866485595703
- 1.3320522713661194
- 1.3366043972969055
- 1.4084207653999328
- 1.3211596703529358
- 1.4583837604522705
- 1.4586350798606873
- 1.4620413732528688
- 1.3098125076293945
- 1.3466858220100404
- 1.3809604811668397
- 1.3271687483787538
- 1.3413139486312866
- 1.3929169988632202
- 1.4521030688285828
- 1.3373325061798096
- 1.3225355291366576
- 1.3384250164031983
- 1.3579716396331787
- 1.3812822413444519
- 1.4500265884399415
- 1.3458389282226562
- 1.3435263442993164
- 1.3477514481544495
- 1.346327691078186
- 1.3255231380462646
- 1.3907911586761474
- 1.3437003684043884
- 1.317462465763092
- 1.3365441513061525
train_accuracy:
- 0.007
- 0.005
- 0.015
- 0.225
- 0.253
- 0.352
- 0.108
- 0.608
- 0.085
- 0.344
- 0.126
- 0.14
- 0.06
- 0.007
- 0.324
- 0.433
- 0.204
- 0.283
- 0.513
- 0.25
- 0.18
- 0.123
- 0.227
- 0.218
- 0.459
- 0.488
- 0.463
- 0.143
- 0.429
- 0.479
- 0.428
- 0.359
- 0.413
- 0.508
- 0.368
- 0.419
- 0.186
- 0.159
- 0.249
- 0.184
- 0.396
- 0.176
- 0.415
- 0.234
- 0.21
- 0.286
- 0.326
- 0.603
- 0.735
- 0.569
- 0.514
- 0.296
- 0.396
- 0.129
- 0.363
- 0.403
- 0.489
- 0.365
- 0.208
- 0.293
- 0.471
- 0.513
- 0.202
- 0.589
- 0.249
- 0.375
- 0.183
- 0.384
- 0.622
- 0.549
- 0.561
- 0.203
- 0.175
- 0.602
- 0.291
- 0.454
- 0.368
- 0.504
- 0.245
- 0.479
- 0.475
- 0.356
- 0.231
- 0.15
- 0.52
- 0.182
- 0.117
- 0.191
- 0.226
- 0.207
- 0.5
- 0.438
- 0.186
- 0.357
- 0.223
- 0.405
- 0.209
- 0.169
- 0.174
- 0.186
train_loss:
- 2.038
- 0.483
- 1.824
- 0.426
- 1.008
- 1.659
- 2.217
- 0.905
- 0.954
- 0.928
- 1.986
- 1.926
- 1.361
- 0.32
- 1.259
- 1.312
- 0.721
- 0.274
- 0.704
- 0.724
- 1.23
- 1.14
- 0.723
- 0.204
- 1.091
- 0.63
- 1.09
- 1.023
- 1.036
- 0.22
- 0.616
- 0.6
- 1.387
- 0.597
- 0.555
- 0.91
- 0.892
- 0.902
- 0.829
- 0.484
- 0.899
- 0.828
- 0.491
- 0.83
- 0.815
- 0.736
- 0.461
- 0.168
- 0.428
- 0.146
- 0.688
- 1.008
- 0.675
- 0.465
- 0.411
- 0.442
- 0.396
- 0.678
- 0.895
- 0.614
- 0.627
- 0.16
- 0.598
- 0.126
- 0.131
- 0.595
- 0.123
- 0.593
- 0.333
- 0.585
- 0.511
- 0.561
- 0.54
- 0.321
- 0.518
- 0.127
- 0.274
- 0.258
- 0.715
- 0.335
- 0.302
- 0.462
- 0.472
- 0.296
- 0.257
- 0.444
- 0.453
- 0.404
- 0.399
- 0.26
- 0.121
- 0.414
- 0.395
- 0.255
- 0.368
- 0.377
- 0.236
- 0.362
- 0.361
- 0.345
unequal: 0
verbose: 1
