avg_train_accuracy: 0.588
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0129
- 0.0235
- 0.0245
- 0.0354
- 0.0318
- 0.0325
- 0.0443
- 0.047
- 0.036
- 0.047
- 0.0713
- 0.1258
- 0.0835
- 0.0853
- 0.1117
- 0.1296
- 0.1048
- 0.1039
- 0.1353
- 0.139
- 0.1053
- 0.0979
- 0.1039
- 0.1691
- 0.1717
- 0.1154
- 0.1452
- 0.1602
- 0.1288
- 0.1672
- 0.134
- 0.1369
- 0.169
- 0.1793
- 0.15
- 0.1746
- 0.1652
- 0.1795
- 0.1852
- 0.1567
- 0.1453
- 0.1496
- 0.1422
- 0.1846
- 0.16
- 0.1866
- 0.1947
- 0.2037
- 0.1763
- 0.1989
- 0.1917
- 0.1913
- 0.2071
- 0.1963
- 0.1638
- 0.1543
- 0.1459
- 0.2101
- 0.2158
- 0.1881
- 0.2004
- 0.1409
- 0.1496
- 0.2039
- 0.217
- 0.1717
- 0.1652
- 0.1681
- 0.2053
- 0.2212
- 0.2145
- 0.1932
- 0.2112
- 0.2122
- 0.1963
- 0.2095
- 0.1853
- 0.174
- 0.1724
- 0.1701
- 0.1735
- 0.2084
- 0.2187
- 0.1885
- 0.1834
- 0.2139
- 0.2113
- 0.2234
- 0.227
- 0.2192
- 0.2311
- 0.2207
- 0.2302
- 0.2093
- 0.2018
- 0.1527
- 0.1604
- 0.1732
- 0.2307
- 0.2246
test_loss_list:
- 1.9312037420272827
- 1.8169373226165773
- 1.9074937152862548
- 1.7523321294784546
- 1.9135762643814087
- 2.0057527923583987
- 1.7228074598312377
- 1.7444425439834594
- 1.84061607837677
- 1.7848314619064332
- 1.6300565814971923
- 1.5650897121429443
- 1.6135118579864502
- 1.6084291052818298
- 1.555943775177002
- 1.5255574154853822
- 1.5478497457504272
- 1.571986701488495
- 1.5010896182060243
- 1.4897320032119752
- 1.5562936997413634
- 1.5736698174476624
- 1.551724102497101
- 1.4524156188964843
- 1.440526111125946
- 1.5516615772247315
- 1.4742790651321411
- 1.448463830947876
- 1.4928073692321777
- 1.4361395668983459
- 1.496268198490143
- 1.4878970623016357
- 1.4344609379768372
- 1.426682472229004
- 1.4610448956489563
- 1.4187980604171753
- 1.4386502289772034
- 1.4160621213912963
- 1.3938804841041565
- 1.4520343494415284
- 1.469540593624115
- 1.4555663681030273
- 1.4731539916992187
- 1.3883717942237854
- 1.444528501033783
- 1.400305938720703
- 1.383491246700287
- 1.3790453934669495
- 1.439317684173584
- 1.3949577832221984
- 1.3754125761985778
- 1.3848264598846436
- 1.3502032589912414
- 1.3817908620834352
- 1.4434682679176332
- 1.470560941696167
- 1.4807317852973938
- 1.3556498026847839
- 1.3537796592712403
- 1.384732735157013
- 1.365613558292389
- 1.4930689978599547
- 1.4776864743232727
- 1.3567242670059203
- 1.343117938041687
- 1.4286372113227843
- 1.4297798824310304
- 1.4394460487365723
- 1.3521752071380615
- 1.3405880880355836
- 1.34807959318161
- 1.3923576474189758
- 1.3634933829307556
- 1.3489503383636474
- 1.3833983206748963
- 1.3513392090797425
- 1.4082829284667968
- 1.4390676212310791
- 1.4566551065444946
- 1.4499843215942383
- 1.453103175163269
- 1.3717947006225586
- 1.344373562335968
- 1.4116763949394227
- 1.4090029859542847
- 1.353079204559326
- 1.3575917196273803
- 1.333857455253601
- 1.3354373002052307
- 1.3486546659469605
- 1.3303473663330079
- 1.361286370754242
- 1.3443114018440248
- 1.380455870628357
- 1.3817176699638367
- 1.5355432105064393
- 1.491852774620056
- 1.4909211564064027
- 1.329852180480957
- 1.352974112033844
train_accuracy:
- 0.008
- 0.004
- 0.62
- 0.337
- 0.16
- 0.071
- 0.397
- 0.274
- 0.004
- 0.455
- 0.041
- 0.362
- 0.156
- 0.046
- 0.171
- 0.099
- 0.067
- 0.365
- 0.424
- 0.107
- 0.074
- 0.258
- 0.492
- 0.388
- 0.103
- 0.065
- 0.13
- 0.141
- 0.063
- 0.443
- 0.536
- 0.632
- 0.127
- 0.253
- 0.095
- 0.396
- 0.448
- 0.586
- 0.1
- 0.351
- 0.365
- 0.622
- 0.088
- 0.491
- 0.655
- 0.155
- 0.191
- 0.207
- 0.491
- 0.123
- 0.172
- 0.356
- 0.184
- 0.392
- 0.016
- 0.646
- 0.649
- 0.214
- 0.073
- 0.186
- 0.114
- 0.346
- 0.32
- 0.186
- 0.106
- 0.419
- 0.458
- 0.493
- 0.534
- 0.222
- 0.131
- 0.289
- 0.233
- 0.206
- 0.55
- 0.182
- 0.305
- 0.665
- 0.117
- 0.468
- 0.199
- 0.175
- 0.202
- 0.172
- 0.436
- 0.283
- 0.442
- 0.241
- 0.224
- 0.107
- 0.239
- 0.312
- 0.218
- 0.106
- 0.033
- 0.29
- 0.132
- 0.553
- 0.23
- 0.588
train_loss:
- 1.273
- 1.955
- 0.461
- 1.819
- 0.385
- 0.345
- 1.668
- 0.896
- 0.381
- 0.942
- 1.522
- 2.064
- 0.923
- 0.882
- 1.396
- 1.327
- 0.752
- 0.743
- 1.375
- 1.181
- 0.741
- 0.725
- 0.745
- 1.628
- 1.254
- 0.284
- 1.138
- 1.185
- 0.712
- 1.059
- 0.558
- 0.624
- 1.059
- 1.046
- 0.61
- 0.916
- 0.614
- 0.924
- 0.866
- 0.525
- 0.478
- 0.635
- 0.457
- 0.9
- 0.575
- 0.879
- 0.799
- 1.063
- 0.511
- 0.771
- 0.474
- 0.75
- 0.716
- 0.648
- 0.223
- 0.452
- 0.394
- 0.919
- 0.7
- 0.438
- 0.657
- 0.141
- 0.416
- 0.605
- 0.875
- 0.198
- 0.354
- 0.361
- 0.596
- 0.809
- 0.557
- 0.333
- 0.489
- 0.506
- 0.389
- 0.547
- 0.343
- 0.283
- 0.306
- 0.306
- 0.295
- 0.454
- 0.492
- 0.289
- 0.316
- 0.471
- 0.452
- 0.565
- 0.568
- 0.422
- 0.53
- 0.361
- 0.514
- 0.265
- 0.28
- 0.091
- 0.254
- 0.217
- 0.471
- 0.354
unequal: 0
verbose: 1
