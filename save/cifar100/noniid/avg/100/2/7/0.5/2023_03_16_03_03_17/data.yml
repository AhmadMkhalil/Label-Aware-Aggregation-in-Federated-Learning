avg_train_accuracy: 0.191
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0232
- 0.0252
- 0.0353
- 0.029
- 0.0453
- 0.0445
- 0.0489
- 0.0439
- 0.0545
- 0.0733
- 0.1217
- 0.1205
- 0.0932
- 0.111
- 0.149
- 0.1471
- 0.1629
- 0.1609
- 0.145
- 0.1361
- 0.1571
- 0.1567
- 0.1274
- 0.1268
- 0.1265
- 0.1811
- 0.149
- 0.1307
- 0.1672
- 0.1743
- 0.1421
- 0.0987
- 0.1581
- 0.1362
- 0.1574
- 0.1392
- 0.1801
- 0.1864
- 0.1564
- 0.1765
- 0.1707
- 0.1831
- 0.1635
- 0.1852
- 0.1895
- 0.1886
- 0.2056
- 0.1979
- 0.2008
- 0.2129
- 0.1904
- 0.1962
- 0.2152
- 0.2208
- 0.2177
- 0.2086
- 0.2181
- 0.2084
- 0.2097
- 0.2068
- 0.2038
- 0.2082
- 0.1936
- 0.2185
- 0.218
- 0.1935
- 0.2076
- 0.2166
- 0.1578
- 0.1704
- 0.2055
- 0.1785
- 0.2008
- 0.1969
- 0.1751
- 0.1847
- 0.1691
- 0.1661
- 0.1789
- 0.1755
- 0.2001
- 0.1856
- 0.1822
- 0.21
- 0.2158
- 0.2162
- 0.1928
- 0.2228
- 0.2247
- 0.1992
- 0.2303
- 0.2083
- 0.2222
- 0.1994
- 0.2138
- 0.2264
- 0.2132
- 0.2215
- 0.2172
- 0.2078
test_loss_list:
- 1.855970950126648
- 1.8425930070877075
- 1.7619527959823609
- 1.8583197736740111
- 1.7287687826156617
- 1.7324587869644166
- 1.7122812509536742
- 1.8742541027069093
- 1.6722510862350464
- 1.63449453830719
- 1.5723494386672974
- 1.5636483573913573
- 1.6019068741798401
- 1.5427601313591004
- 1.4971742033958435
- 1.4964140558242798
- 1.4762152409553528
- 1.4780390787124633
- 1.4881711578369141
- 1.4752246499061585
- 1.4491803240776062
- 1.4596608066558838
- 1.5108969879150391
- 1.5050539779663086
- 1.536345624923706
- 1.4193113684654235
- 1.4563323140144349
- 1.5137613749504089
- 1.4257219433784485
- 1.4251036167144775
- 1.4756034469604493
- 1.6371535778045654
- 1.4477422189712525
- 1.5132547545433044
- 1.4341371750831604
- 1.487369680404663
- 1.404197597503662
- 1.3855297923088075
- 1.4451453828811645
- 1.4152281665802002
- 1.4168227887153626
- 1.400507071018219
- 1.4277832412719726
- 1.3910009717941285
- 1.3916487455368043
- 1.3973386669158936
- 1.3604141068458557
- 1.3805250430107117
- 1.369122438430786
- 1.346479001045227
- 1.38701073884964
- 1.382034058570862
- 1.349409441947937
- 1.3526694655418396
- 1.344286894798279
- 1.344841067790985
- 1.3331812405586243
- 1.368529031276703
- 1.3702387642860412
- 1.3472480154037476
- 1.3623880100250245
- 1.3542903017997743
- 1.3879737281799316
- 1.3314597368240357
- 1.3403192067146301
- 1.392839035987854
- 1.352334656715393
- 1.3269360995292663
- 1.4759558749198913
- 1.4417912912368775
- 1.3510693550109862
- 1.415187063217163
- 1.3730405354499817
- 1.383214728832245
- 1.4373350191116332
- 1.4090860986709595
- 1.4597174334526062
- 1.4738627123832702
- 1.427922351360321
- 1.454773597717285
- 1.3819850850105286
- 1.4244435453414916
- 1.4382021927833557
- 1.3508511304855346
- 1.3427800345420837
- 1.3550968098640441
- 1.3992854571342468
- 1.327868800163269
- 1.331454119682312
- 1.3906393074989318
- 1.322428376674652
- 1.387914342880249
- 1.3299152445793152
- 1.4042593789100648
- 1.3634513068199157
- 1.3314353680610658
- 1.3640173697471618
- 1.362007668018341
- 1.375822057723999
- 1.3710250782966613
train_accuracy:
- 0.008
- 0.046
- 0.215
- 0.653
- 0.014
- 0.027
- 0.314
- 0.589
- 0.697
- 0.509
- 0.417
- 0.566
- 0.069
- 0.396
- 0.148
- 0.403
- 0.236
- 0.111
- 0.038
- 0.006
- 0.368
- 0.087
- 0.294
- 0.362
- 0.084
- 0.169
- 0.209
- 0.327
- 0.35
- 0.149
- 0.082
- 0.324
- 0.567
- 0.642
- 0.088
- 0.31
- 0.476
- 0.595
- 0.078
- 0.162
- 0.092
- 0.533
- 0.102
- 0.223
- 0.161
- 0.283
- 0.524
- 0.173
- 0.386
- 0.219
- 0.292
- 0.313
- 0.181
- 0.188
- 0.178
- 0.2
- 0.235
- 0.219
- 0.261
- 0.593
- 0.149
- 0.202
- 0.464
- 0.257
- 0.069
- 0.128
- 0.417
- 0.227
- 0.263
- 0.363
- 0.546
- 0.105
- 0.195
- 0.205
- 0.099
- 0.212
- 0.288
- 0.333
- 0.354
- 0.313
- 0.307
- 0.119
- 0.108
- 0.231
- 0.217
- 0.437
- 0.343
- 0.271
- 0.176
- 0.301
- 0.2
- 0.179
- 0.219
- 0.512
- 0.469
- 0.174
- 0.385
- 0.235
- 0.211
- 0.191
train_loss:
- 2.037
- 1.16
- 1.796
- 0.418
- 1.709
- 1.03
- 1.006
- 0.303
- 1.537
- 1.459
- 2.002
- 1.385
- 0.872
- 1.396
- 1.873
- 1.319
- 1.737
- 1.237
- 1.218
- 0.752
- 1.171
- 1.078
- 0.702
- 0.666
- 0.626
- 1.51
- 0.667
- 0.621
- 0.996
- 1.008
- 0.571
- 0.189
- 0.982
- 0.554
- 0.563
- 0.577
- 0.916
- 0.89
- 0.501
- 0.819
- 0.555
- 0.8
- 0.499
- 0.769
- 0.845
- 0.787
- 0.763
- 0.709
- 0.748
- 0.701
- 0.444
- 0.713
- 0.968
- 0.918
- 0.622
- 0.674
- 0.669
- 0.566
- 0.619
- 0.373
- 0.583
- 0.585
- 0.347
- 0.74
- 0.508
- 0.315
- 0.545
- 0.535
- 0.155
- 0.327
- 0.473
- 0.308
- 0.429
- 0.288
- 0.259
- 0.302
- 0.246
- 0.237
- 0.234
- 0.275
- 0.388
- 0.238
- 0.232
- 0.447
- 0.473
- 0.419
- 0.307
- 0.389
- 0.382
- 0.209
- 0.496
- 0.214
- 0.355
- 0.245
- 0.335
- 0.339
- 0.306
- 0.364
- 0.279
- 0.254
unequal: 0
verbose: 1
