avg_train_accuracy: 0.812
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0161
- 0.0114
- 0.0188
- 0.0538
- 0.0179
- 0.0187
- 0.0159
- 0.0693
- 0.1048
- 0.1091
- 0.016
- 0.0187
- 0.0188
- 0.0172
- 0.0192
- 0.0193
- 0.0192
- 0.0151
- 0.1198
- 0.0162
- 0.0165
- 0.1288
- 0.152
- 0.1498
- 0.0189
- 0.0192
- 0.1503
- 0.018
- 0.0157
- 0.0172
- 0.0179
- 0.1584
- 0.0188
- 0.0189
- 0.0193
- 0.0194
- 0.0166
- 0.1667
- 0.0179
- 0.0192
- 0.0181
- 0.016
- 0.017
- 0.1813
- 0.0154
- 0.0183
- 0.173
- 0.0173
- 0.018
- 0.1819
- 0.0183
- 0.0193
- 0.0171
- 0.1767
- 0.0192
- 0.196
- 0.0178
- 0.0188
- 0.0193
- 0.017
- 0.0164
- 0.019
- 0.0185
- 0.0177
- 0.0182
- 0.0189
- 0.194
- 0.018
- 0.017
- 0.0193
- 0.0191
- 0.0166
- 0.1958
- 0.1967
- 0.1963
- 0.0185
- 0.1952
- 0.0196
- 0.199
- 0.0193
- 0.1967
- 0.0192
- 0.0173
- 0.2139
- 0.0174
- 0.2033
- 0.0161
- 0.2179
- 0.0199
- 0.0167
- 0.0192
- 0.0188
- 0.0194
- 0.0178
- 0.2102
- 0.0164
- 0.2066
- 0.0167
- 0.2271
- 0.0195
test_loss_list:
- 3.454116563796997
- 5.12463376045227
- 4.970867586135864
- 1.8439125394821168
- 4.671574592590332
- 4.169594163894653
- 4.4954643821716305
- 1.7744727182388305
- 1.732432963848114
- 1.72478586435318
- 4.3382204723358155
- 4.442017459869385
- 4.562516450881958
- 4.6360906314849855
- 4.288008308410644
- 4.410578985214233
- 4.513444271087646
- 4.498227643966675
- 1.664753110408783
- 4.204148368835449
- 4.276485757827759
- 1.6454204082489015
- 1.6237991976737975
- 1.631196253299713
- 4.344247226715088
- 4.330897340774536
- 1.6284882950782775
- 4.198847236633301
- 4.31578800201416
- 4.171782693862915
- 4.197921390533447
- 1.5761615777015685
- 4.069201936721802
- 4.225588665008545
- 4.2769503402709965
- 4.247526388168335
- 4.400594730377197
- 1.5617356705665588
- 4.339410171508789
- 4.299701919555664
- 4.056551465988159
- 4.094070262908936
- 4.135753116607666
- 1.5169401717185975
- 4.179562654495239
- 4.152824258804321
- 1.5127902841567993
- 4.052707824707031
- 4.337823696136475
- 1.5224526190757752
- 3.8904871940612793
- 3.9202548980712892
- 4.019174728393555
- 1.5097044944763183
- 3.870477170944214
- 1.4882764554023742
- 4.033905754089355
- 3.9894496536254884
- 3.9304956150054933
- 4.218434934616089
- 4.121788816452026
- 4.101206874847412
- 3.85799054145813
- 4.063023309707642
- 4.255248336791992
- 3.969749402999878
- 1.4517119717597962
- 3.8384410762786865
- 4.144857425689697
- 3.79540922164917
- 3.939723768234253
- 4.290063781738281
- 1.4715171217918397
- 1.4743178272247315
- 1.484193115234375
- 3.9934762382507323
- 1.5021355867385864
- 3.8193741035461426
- 1.490012562274933
- 3.654140453338623
- 1.5075917172431945
- 3.7536059284210204
- 4.057754611968994
- 1.460415871143341
- 3.976041765213013
- 1.4875668859481812
- 4.1402170276641845
- 1.4760892987251282
- 3.6990342330932617
- 4.0446342086791995
- 3.753632650375366
- 3.8171158123016355
- 3.889006814956665
- 3.833899440765381
- 1.4299646544456481
- 3.909848165512085
- 1.4578965544700622
- 4.021750354766846
- 1.4410989212989807
- 3.757173385620117
train_accuracy:
- 0.762
- 0.096
- 0.888
- 0.066
- 0.878
- 0.919
- 0.694
- 0.075
- 0.09
- 0.12
- 0.826
- 0.945
- 0.963
- 0.767
- 0.886
- 0.929
- 0.911
- 0.672
- 0.131
- 0.642
- 0.88
- 0.129
- 0.172
- 0.142
- 0.985
- 0.956
- 0.13
- 0.817
- 0.65
- 0.875
- 0.847
- 0.159
- 0.892
- 0.967
- 0.98
- 0.941
- 0.824
- 0.163
- 0.843
- 0.976
- 0.803
- 0.762
- 0.845
- 0.219
- 0.708
- 0.867
- 0.163
- 0.812
- 0.82
- 0.176
- 0.875
- 0.925
- 0.757
- 0.168
- 0.98
- 0.236
- 0.805
- 0.865
- 0.966
- 0.859
- 0.774
- 0.919
- 0.852
- 0.848
- 0.88
- 0.923
- 0.239
- 0.883
- 0.776
- 0.94
- 0.935
- 0.789
- 0.212
- 0.179
- 0.185
- 0.877
- 0.2
- 0.949
- 0.194
- 0.977
- 0.208
- 0.939
- 0.786
- 0.239
- 0.882
- 0.204
- 0.731
- 0.255
- 0.88
- 0.81
- 0.928
- 0.859
- 0.97
- 0.879
- 0.204
- 0.706
- 0.193
- 0.759
- 0.269
- 0.812
train_loss:
- 0.575
- 0.948
- 0.867
- 4.532
- 0.669
- 0.859
- 0.965
- 4.125
- 3.514
- 3.34
- 0.815
- 0.709
- 0.117
- 0.793
- 0.881
- 0.165
- 0.129
- 0.99
- 3.343
- 0.652
- 0.855
- 3.465
- 2.972
- 2.675
- 0.374
- 0.684
- 2.587
- 0.556
- 0.961
- 0.822
- 0.658
- 3.104
- 0.406
- 0.561
- 0.06
- 0.545
- 0.993
- 2.777
- 0.513
- 0.469
- 0.732
- 0.821
- 0.706
- 2.92
- 0.567
- 0.619
- 2.542
- 0.469
- 0.603
- 2.579
- 0.404
- 0.569
- 0.592
- 2.217
- 0.284
- 2.473
- 0.374
- 0.55
- 0.443
- 0.745
- 0.79
- 0.473
- 0.608
- 0.511
- 0.641
- 0.424
- 2.313
- 0.297
- 0.612
- 0.514
- 0.047
- 0.521
- 2.418
- 1.832
- 1.783
- 0.349
- 1.627
- 0.389
- 1.794
- 0.291
- 1.549
- 0.313
- 0.58
- 2.055
- 0.302
- 1.603
- 0.562
- 1.73
- 0.374
- 0.637
- 0.519
- 0.469
- 0.466
- 0.484
- 1.428
- 0.304
- 1.131
- 0.456
- 1.565
- 0.313
unequal: 0
verbose: 1
