avg_train_accuracy: 0.268
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0162
- 0.0225
- 0.033
- 0.0532
- 0.0599
- 0.0991
- 0.1085
- 0.1188
- 0.1155
- 0.1335
- 0.1086
- 0.1176
- 0.1245
- 0.1037
- 0.1425
- 0.1579
- 0.1629
- 0.164
- 0.1389
- 0.1684
- 0.1582
- 0.1746
- 0.1637
- 0.1582
- 0.1798
- 0.1533
- 0.1595
- 0.1658
- 0.1694
- 0.1694
- 0.1502
- 0.1417
- 0.1633
- 0.1891
- 0.1859
- 0.1338
- 0.162
- 0.1794
- 0.1849
- 0.182
- 0.1894
- 0.1893
- 0.1875
- 0.1709
- 0.1863
- 0.2019
- 0.2094
- 0.187
- 0.194
- 0.2017
- 0.1955
- 0.1989
- 0.1934
- 0.2038
- 0.1954
- 0.2187
- 0.2126
- 0.21
- 0.2068
- 0.2061
- 0.2106
- 0.222
- 0.2144
- 0.2121
- 0.2076
- 0.2083
- 0.205
- 0.2112
- 0.189
- 0.1757
- 0.1683
- 0.221
- 0.2307
- 0.2029
- 0.2099
- 0.2267
- 0.2174
- 0.2169
- 0.2115
- 0.2193
- 0.2306
- 0.2186
- 0.2203
- 0.235
- 0.2308
- 0.2282
- 0.2221
- 0.2285
- 0.2336
- 0.2243
- 0.2346
- 0.2276
- 0.2224
- 0.2256
- 0.2343
- 0.2075
- 0.2179
- 0.1968
- 0.1923
- 0.2087
test_loss_list:
- 1.8975105381011963
- 1.8453951501846313
- 1.776767520904541
- 1.7305906677246095
- 1.6973927307128907
- 1.6236384224891662
- 1.5923331308364868
- 1.5747095704078675
- 1.5608086371421814
- 1.5377701759338378
- 1.5779230070114136
- 1.561100389957428
- 1.531211063861847
- 1.5818621468544007
- 1.501058404445648
- 1.472472746372223
- 1.462642526626587
- 1.4641759872436524
- 1.4889709877967834
- 1.4439137077331543
- 1.4588201451301575
- 1.4270252561569214
- 1.4413383150100707
- 1.4638190031051637
- 1.412671866416931
- 1.4648327827453613
- 1.445408911705017
- 1.4354822754859924
- 1.4304579925537109
- 1.4275438213348388
- 1.4678265309333802
- 1.504152045249939
- 1.4460955548286438
- 1.3883292603492736
- 1.39574782371521
- 1.5186105966567993
- 1.4445403289794922
- 1.4100943803787231
- 1.3944198179244995
- 1.3977362489700318
- 1.3922959208488463
- 1.3858770060539245
- 1.389607970714569
- 1.429620156288147
- 1.3938973927497864
- 1.3545469975471496
- 1.3464029455184936
- 1.3932170033454896
- 1.3736519932746887
- 1.3701616978645326
- 1.3682713532447814
- 1.3650752305984497
- 1.3770332407951356
- 1.360917043685913
- 1.3751032042503357
- 1.3358815145492553
- 1.341715714931488
- 1.3494341993331909
- 1.3565159392356874
- 1.3620649790763855
- 1.3550530171394348
- 1.3260570216178893
- 1.3365416169166564
- 1.3439860582351684
- 1.3593180441856385
- 1.3550519323349
- 1.3628384685516357
- 1.359328067302704
- 1.3992596673965454
- 1.43879691362381
- 1.454905571937561
- 1.3331581711769105
- 1.3163665056228637
- 1.3719059467315673
- 1.3640946435928345
- 1.3232715392112733
- 1.351254210472107
- 1.337432897090912
- 1.3555904340744018
- 1.3393088173866272
- 1.3122884964942931
- 1.3489251780509948
- 1.3390262985229493
- 1.3083632040023803
- 1.3186329531669616
- 1.322648787498474
- 1.3372152328491211
- 1.3199652552604675
- 1.3172054505348205
- 1.3339665293693543
- 1.315232927799225
- 1.3407209396362305
- 1.35260586977005
- 1.3382762789726257
- 1.3157353115081787
- 1.3875590419769288
- 1.3590284371376038
- 1.4177310872077942
- 1.4340668082237245
- 1.3790140962600708
train_accuracy:
- 0.002
- 0.372
- 0.017
- 0.031
- 0.354
- 0.095
- 0.104
- 0.101
- 0.063
- 0.055
- 0.079
- 0.084
- 0.226
- 0.574
- 0.383
- 0.331
- 0.116
- 0.174
- 0.052
- 0.084
- 0.333
- 0.021
- 0.197
- 0.16
- 0.165
- 0.139
- 0.396
- 0.136
- 0.451
- 0.296
- 0.036
- 0.116
- 0.501
- 0.166
- 0.281
- 0.366
- 0.138
- 0.169
- 0.293
- 0.055
- 0.263
- 0.092
- 0.241
- 0.148
- 0.136
- 0.198
- 0.176
- 0.24
- 0.147
- 0.186
- 0.388
- 0.347
- 0.179
- 0.483
- 0.176
- 0.216
- 0.207
- 0.271
- 0.391
- 0.178
- 0.193
- 0.184
- 0.249
- 0.31
- 0.346
- 0.154
- 0.388
- 0.138
- 0.519
- 0.519
- 0.524
- 0.174
- 0.077
- 0.13
- 0.176
- 0.214
- 0.204
- 0.25
- 0.124
- 0.194
- 0.194
- 0.33
- 0.048
- 0.23
- 0.226
- 0.23
- 0.324
- 0.237
- 0.08
- 0.214
- 0.084
- 0.269
- 0.14
- 0.22
- 0.235
- 0.158
- 0.08
- 0.403
- 0.206
- 0.268
train_loss:
- 1.623
- 1.513
- 1.434
- 1.343
- 1.307
- 1.753
- 1.664
- 1.573
- 1.19
- 1.49
- 0.711
- 1.052
- 1.057
- 0.658
- 1.361
- 1.337
- 1.31
- 1.242
- 0.622
- 1.21
- 0.879
- 1.189
- 0.856
- 0.823
- 1.134
- 0.517
- 0.776
- 0.78
- 0.756
- 0.764
- 0.485
- 0.475
- 0.702
- 0.982
- 0.683
- 0.189
- 0.637
- 0.686
- 0.672
- 0.654
- 0.632
- 0.625
- 0.623
- 0.386
- 0.634
- 0.812
- 0.8
- 0.383
- 0.57
- 0.554
- 0.55
- 0.537
- 0.521
- 0.515
- 0.487
- 0.691
- 0.523
- 0.489
- 0.489
- 0.464
- 0.458
- 0.625
- 0.463
- 0.451
- 0.427
- 0.426
- 0.426
- 0.41
- 0.281
- 0.272
- 0.25
- 0.552
- 0.524
- 0.268
- 0.371
- 0.494
- 0.375
- 0.371
- 0.352
- 0.362
- 0.463
- 0.335
- 0.348
- 0.437
- 0.421
- 0.41
- 0.312
- 0.402
- 0.328
- 0.288
- 0.382
- 0.289
- 0.278
- 0.279
- 0.352
- 0.186
- 0.274
- 0.179
- 0.194
- 0.254
unequal: 0
verbose: 1
