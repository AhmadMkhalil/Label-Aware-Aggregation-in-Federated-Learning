avg_train_accuracy: 0.235
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0158
- 0.0327
- 0.0442
- 0.0579
- 0.0898
- 0.0908
- 0.0979
- 0.1013
- 0.0858
- 0.0985
- 0.1298
- 0.1381
- 0.1299
- 0.1271
- 0.1324
- 0.1585
- 0.1685
- 0.1563
- 0.1316
- 0.1482
- 0.1286
- 0.1692
- 0.174
- 0.1881
- 0.1753
- 0.1729
- 0.1502
- 0.1613
- 0.1395
- 0.1944
- 0.1818
- 0.1825
- 0.1976
- 0.2099
- 0.2032
- 0.2007
- 0.173
- 0.2081
- 0.2167
- 0.2163
- 0.2078
- 0.2016
- 0.2026
- 0.2058
- 0.2045
- 0.2173
- 0.2128
- 0.2252
- 0.2261
- 0.2165
- 0.2253
- 0.2165
- 0.2106
- 0.1932
- 0.2103
- 0.2122
- 0.2184
- 0.2136
- 0.2149
- 0.215
- 0.2306
- 0.2343
- 0.2268
- 0.2252
- 0.2356
- 0.2292
- 0.2308
- 0.2233
- 0.2333
- 0.216
- 0.2002
- 0.1899
- 0.2113
- 0.2213
- 0.2343
- 0.2346
- 0.238
- 0.2304
- 0.2385
- 0.2294
- 0.2385
- 0.2359
- 0.2399
- 0.2314
- 0.2433
- 0.2383
- 0.2433
- 0.2474
- 0.2372
- 0.2452
- 0.2444
- 0.24
- 0.2324
- 0.2178
- 0.2261
- 0.2283
- 0.2314
- 0.2426
- 0.2344
- 0.2477
test_loss_list:
- 1.8637258911132812
- 1.8066502141952514
- 1.7469946575164794
- 1.7058118343353272
- 1.6507832956314088
- 1.6341375637054443
- 1.623238799571991
- 1.6083449196815491
- 1.6478341507911682
- 1.612232367992401
- 1.543355700969696
- 1.5250253224372863
- 1.5311880278587342
- 1.5319217896461488
- 1.5190067839622499
- 1.4774228596687318
- 1.4641136884689332
- 1.4759880232810973
- 1.5129514265060424
- 1.492137417793274
- 1.5338345122337342
- 1.4423741030693054
- 1.4479767084121704
- 1.4164915895462036
- 1.434909644126892
- 1.4373187160491943
- 1.4871774625778198
- 1.4541651487350464
- 1.5097691655158996
- 1.4095411276817322
- 1.4131631422042847
- 1.4181983637809754
- 1.3943569993972778
- 1.380769865512848
- 1.3826444625854493
- 1.3960685062408447
- 1.4383880615234375
- 1.3707231569290161
- 1.364675989151001
- 1.3516884708404542
- 1.3784492897987366
- 1.38633074760437
- 1.3819784235954284
- 1.3841213870048523
- 1.375672013759613
- 1.355015971660614
- 1.3658251953125
- 1.345354015827179
- 1.3395826721191406
- 1.3595633792877198
- 1.339833517074585
- 1.3629713582992553
- 1.3724781632423402
- 1.4105853319168091
- 1.3675738263130188
- 1.3672670364379882
- 1.3543968677520752
- 1.361068105697632
- 1.3630332922935486
- 1.3598334765434266
- 1.321373188495636
- 1.3153275847434998
- 1.3336231589317322
- 1.34009929895401
- 1.316771366596222
- 1.3318013763427734
- 1.3404502248764039
- 1.3474951696395874
- 1.3199703097343445
- 1.3644358205795288
- 1.4144790172576904
- 1.4389168882369996
- 1.373037793636322
- 1.3569624161720275
- 1.3232951712608338
- 1.327188959121704
- 1.312343327999115
- 1.332943835258484
- 1.3039595317840575
- 1.3357330465316772
- 1.3196947503089904
- 1.3164908385276795
- 1.3089319396018981
- 1.3322704911231995
- 1.31265070438385
- 1.315197548866272
- 1.305402274131775
- 1.307016749382019
- 1.3308666920661927
- 1.3133611536026002
- 1.3013654923439026
- 1.324726574420929
- 1.3424218559265138
- 1.3779751992225646
- 1.3534825873374938
- 1.3536368060111998
- 1.3513181400299072
- 1.3187486624717712
- 1.3466375494003295
- 1.3139729070663453
train_accuracy:
- 0.0
- 0.018
- 0.0
- 0.032
- 0.092
- 0.097
- 0.093
- 0.437
- 0.014
- 0.165
- 0.067
- 0.138
- 0.412
- 0.124
- 0.002
- 0.11
- 0.154
- 0.041
- 0.049
- 0.207
- 0.177
- 0.027
- 0.323
- 0.116
- 0.092
- 0.087
- 0.123
- 0.39
- 0.431
- 0.184
- 0.01
- 0.306
- 0.196
- 0.155
- 0.128
- 0.11
- 0.273
- 0.212
- 0.283
- 0.201
- 0.242
- 0.118
- 0.407
- 0.169
- 0.402
- 0.159
- 0.205
- 0.201
- 0.127
- 0.253
- 0.241
- 0.285
- 0.053
- 0.17
- 0.184
- 0.233
- 0.2
- 0.255
- 0.152
- 0.129
- 0.04
- 0.178
- 0.22
- 0.233
- 0.274
- 0.215
- 0.085
- 0.21
- 0.088
- 0.267
- 0.305
- 0.162
- 0.119
- 0.43
- 0.242
- 0.16
- 0.274
- 0.223
- 0.237
- 0.194
- 0.249
- 0.285
- 0.255
- 0.129
- 0.242
- 0.223
- 0.326
- 0.243
- 0.396
- 0.239
- 0.248
- 0.156
- 0.161
- 0.361
- 0.167
- 0.155
- 0.118
- 0.234
- 0.243
- 0.235
train_loss:
- 2.166
- 1.455
- 1.386
- 1.383
- 1.781
- 1.262
- 1.191
- 1.18
- 0.764
- 1.137
- 1.458
- 1.45
- 1.064
- 1.011
- 1.007
- 1.288
- 1.321
- 0.95
- 0.601
- 0.901
- 0.56
- 1.197
- 0.84
- 1.189
- 0.849
- 0.807
- 0.522
- 0.787
- 0.449
- 1.006
- 0.793
- 0.686
- 0.995
- 0.934
- 0.746
- 0.654
- 0.449
- 0.943
- 0.869
- 0.902
- 0.62
- 0.6
- 0.587
- 0.595
- 0.626
- 0.784
- 0.581
- 0.748
- 0.729
- 0.563
- 0.733
- 0.511
- 0.507
- 0.314
- 0.506
- 0.521
- 0.483
- 0.48
- 0.459
- 0.479
- 0.624
- 0.602
- 0.443
- 0.426
- 0.565
- 0.436
- 0.389
- 0.412
- 0.529
- 0.264
- 0.28
- 0.254
- 0.387
- 0.373
- 0.505
- 0.373
- 0.475
- 0.377
- 0.477
- 0.34
- 0.444
- 0.357
- 0.448
- 0.321
- 0.401
- 0.333
- 0.401
- 0.378
- 0.301
- 0.37
- 0.39
- 0.272
- 0.258
- 0.203
- 0.272
- 0.263
- 0.252
- 0.339
- 0.242
- 0.324
unequal: 0
verbose: 1
