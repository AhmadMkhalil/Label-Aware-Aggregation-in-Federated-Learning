avg_train_accuracy: 0.42
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0146
- 0.0407
- 0.0424
- 0.0504
- 0.0841
- 0.1048
- 0.0983
- 0.0802
- 0.0963
- 0.1076
- 0.0905
- 0.0851
- 0.1057
- 0.1244
- 0.1522
- 0.1613
- 0.1607
- 0.1515
- 0.1523
- 0.1492
- 0.1318
- 0.1631
- 0.1433
- 0.1596
- 0.1627
- 0.1781
- 0.1803
- 0.1796
- 0.1711
- 0.1501
- 0.166
- 0.1721
- 0.1546
- 0.1667
- 0.185
- 0.183
- 0.1939
- 0.1964
- 0.192
- 0.1702
- 0.1834
- 0.2064
- 0.1957
- 0.1929
- 0.2065
- 0.2075
- 0.2034
- 0.1855
- 0.194
- 0.1991
- 0.2122
- 0.2177
- 0.2216
- 0.2187
- 0.2167
- 0.2186
- 0.1948
- 0.2039
- 0.2071
- 0.22
- 0.2113
- 0.2108
- 0.2133
- 0.2081
- 0.2062
- 0.2113
- 0.2272
- 0.2004
- 0.2213
- 0.2179
- 0.2138
- 0.2109
- 0.2239
- 0.22
- 0.2225
- 0.1938
- 0.2117
- 0.2138
- 0.1885
- 0.2299
- 0.2032
- 0.2115
- 0.2117
- 0.2248
- 0.2168
- 0.2129
- 0.2271
- 0.2205
- 0.2186
- 0.2185
- 0.2163
- 0.2199
- 0.2233
- 0.2242
- 0.2341
- 0.2122
- 0.2335
- 0.2289
- 0.2344
- 0.2243
test_loss_list:
- 1.9004347705841065
- 1.7976315069198607
- 1.7491278648376465
- 1.7161474990844727
- 1.6513355684280395
- 1.6183847284317017
- 1.6106965374946594
- 1.63913419008255
- 1.6099776816368103
- 1.5783085489273072
- 1.6291208624839784
- 1.651724524497986
- 1.579055757522583
- 1.5534352254867554
- 1.5091874146461486
- 1.4856240844726563
- 1.4783624196052552
- 1.4817565512657165
- 1.4796552991867065
- 1.4895299935340882
- 1.5277636766433715
- 1.457434024810791
- 1.502734067440033
- 1.4687824296951293
- 1.4633072328567505
- 1.4267346835136414
- 1.424705090522766
- 1.4210167169570922
- 1.439347107410431
- 1.480838487148285
- 1.4457902359962462
- 1.4353162598609925
- 1.4817477107048034
- 1.4514146995544435
- 1.4116819858551026
- 1.4237408638000488
- 1.3868292188644409
- 1.3900121021270753
- 1.4062352323532104
- 1.4501880979537964
- 1.4170608806610108
- 1.37253422498703
- 1.3949136590957643
- 1.4008086395263672
- 1.3703932571411133
- 1.3653785800933838
- 1.3686910104751586
- 1.4216653728485107
- 1.39694251537323
- 1.3931618189811708
- 1.3577925229072572
- 1.345663356781006
- 1.3489084076881408
- 1.3484966087341308
- 1.364497766494751
- 1.3395656728744507
- 1.3945079851150513
- 1.382795910835266
- 1.380497145652771
- 1.3446087837219238
- 1.367466230392456
- 1.3552516794204712
- 1.3632383346557617
- 1.3682816863059997
- 1.3806836485862732
- 1.3622116184234618
- 1.3382982921600342
- 1.3889498686790467
- 1.339707543849945
- 1.3467559099197388
- 1.3613246703147888
- 1.3620184803009032
- 1.3384507918357849
- 1.3420376706123351
- 1.3468107986450195
- 1.4143386387825012
- 1.3806090402603148
- 1.3707641005516051
- 1.4280024790763854
- 1.33684809923172
- 1.407318058013916
- 1.3691991758346558
- 1.3727613282203674
- 1.3509997582435609
- 1.3579000282287597
- 1.3618777585029602
- 1.3347217226028443
- 1.3503512167930602
- 1.3554074454307556
- 1.3519786381721497
- 1.3621688270568848
- 1.3504889464378358
- 1.3553576707839965
- 1.3572130584716797
- 1.3241662502288818
- 1.3866876316070558
- 1.3297606301307678
- 1.3441834878921508
- 1.3244879460334777
- 1.3543323278427124
train_accuracy:
- 0.031
- 0.025
- 0.392
- 0.427
- 0.129
- 0.101
- 0.085
- 0.014
- 0.056
- 0.41
- 0.165
- 0.401
- 0.467
- 0.504
- 0.392
- 0.025
- 0.157
- 0.128
- 0.118
- 0.436
- 0.121
- 0.168
- 0.265
- 0.21
- 0.142
- 0.141
- 0.182
- 0.161
- 0.463
- 0.52
- 0.525
- 0.135
- 0.508
- 0.129
- 0.163
- 0.475
- 0.171
- 0.082
- 0.284
- 0.51
- 0.138
- 0.205
- 0.435
- 0.153
- 0.191
- 0.195
- 0.105
- 0.081
- 0.271
- 0.295
- 0.194
- 0.071
- 0.094
- 0.212
- 0.191
- 0.208
- 0.174
- 0.42
- 0.173
- 0.22
- 0.183
- 0.235
- 0.218
- 0.188
- 0.268
- 0.19
- 0.212
- 0.16
- 0.204
- 0.142
- 0.186
- 0.468
- 0.215
- 0.42
- 0.14
- 0.463
- 0.387
- 0.512
- 0.429
- 0.206
- 0.504
- 0.196
- 0.287
- 0.2
- 0.317
- 0.544
- 0.234
- 0.208
- 0.101
- 0.451
- 0.428
- 0.554
- 0.193
- 0.064
- 0.211
- 0.248
- 0.219
- 0.45
- 0.218
- 0.42
train_loss:
- 1.622
- 2.013
- 1.438
- 1.378
- 1.782
- 1.727
- 1.248
- 0.798
- 1.188
- 1.141
- 0.742
- 0.711
- 1.114
- 1.094
- 1.402
- 1.371
- 1.383
- 1.039
- 0.94
- 0.968
- 0.627
- 1.3
- 0.593
- 0.863
- 0.907
- 1.219
- 1.19
- 0.823
- 0.84
- 0.522
- 0.805
- 0.802
- 0.498
- 0.769
- 1.033
- 0.758
- 1.014
- 0.699
- 0.681
- 0.456
- 0.703
- 0.932
- 0.66
- 0.678
- 0.872
- 0.884
- 0.647
- 0.395
- 0.611
- 0.621
- 0.774
- 0.774
- 0.743
- 0.73
- 0.518
- 0.756
- 0.352
- 0.511
- 0.516
- 0.693
- 0.494
- 0.482
- 0.445
- 0.503
- 0.479
- 0.478
- 0.612
- 0.303
- 0.595
- 0.433
- 0.417
- 0.43
- 0.534
- 0.435
- 0.387
- 0.267
- 0.399
- 0.383
- 0.241
- 0.505
- 0.254
- 0.356
- 0.343
- 0.373
- 0.337
- 0.327
- 0.457
- 0.335
- 0.342
- 0.32
- 0.337
- 0.298
- 0.312
- 0.311
- 0.415
- 0.2
- 0.391
- 0.286
- 0.379
- 0.278
unequal: 0
verbose: 1
