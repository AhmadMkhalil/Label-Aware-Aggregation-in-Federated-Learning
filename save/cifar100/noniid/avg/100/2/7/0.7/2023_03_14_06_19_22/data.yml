avg_train_accuracy: 0.421
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.017
- 0.0326
- 0.0403
- 0.0377
- 0.0765
- 0.0793
- 0.0842
- 0.0867
- 0.0933
- 0.1028
- 0.1292
- 0.1261
- 0.1413
- 0.1013
- 0.1161
- 0.1468
- 0.1596
- 0.1461
- 0.143
- 0.1411
- 0.1528
- 0.1521
- 0.1537
- 0.1739
- 0.1561
- 0.1775
- 0.1718
- 0.1685
- 0.1887
- 0.1813
- 0.1598
- 0.1713
- 0.194
- 0.1983
- 0.1769
- 0.1801
- 0.1956
- 0.1907
- 0.1868
- 0.17
- 0.1607
- 0.1996
- 0.1988
- 0.2026
- 0.2096
- 0.2106
- 0.2014
- 0.1977
- 0.1997
- 0.1987
- 0.2133
- 0.2192
- 0.1917
- 0.203
- 0.1996
- 0.2008
- 0.2166
- 0.2211
- 0.2213
- 0.2248
- 0.1811
- 0.1764
- 0.2162
- 0.2138
- 0.1906
- 0.1818
- 0.2031
- 0.2036
- 0.2095
- 0.2113
- 0.2119
- 0.2265
- 0.2307
- 0.2088
- 0.2111
- 0.2158
- 0.2277
- 0.2277
- 0.2278
- 0.205
- 0.1817
- 0.2027
- 0.2261
- 0.2235
- 0.2143
- 0.2234
- 0.2124
- 0.2164
- 0.2299
- 0.2273
- 0.2216
- 0.231
- 0.2248
- 0.2083
- 0.2342
- 0.209
- 0.2185
- 0.2242
- 0.2018
- 0.213
test_loss_list:
- 1.861282124519348
- 1.802559585571289
- 1.7486581993103028
- 1.7689296913146972
- 1.672448468208313
- 1.666960198879242
- 1.6494907808303834
- 1.625320656299591
- 1.6058151698112488
- 1.589056043624878
- 1.5473466420173645
- 1.550603790283203
- 1.508755886554718
- 1.5913004088401794
- 1.5447421598434448
- 1.4941076397895814
- 1.4748223304748536
- 1.492587025165558
- 1.4920379757881164
- 1.4826388955116272
- 1.475455448627472
- 1.46638840675354
- 1.463806049823761
- 1.429922776222229
- 1.4732519388198853
- 1.4232222938537598
- 1.4374559664726256
- 1.4390730452537537
- 1.401015727519989
- 1.421928951740265
- 1.4552812790870666
- 1.4309683227539063
- 1.400235230922699
- 1.3919848346710204
- 1.4241091012954712
- 1.4122276067733766
- 1.3873635458946227
- 1.3902296710014344
- 1.3980164241790771
- 1.4391037178039552
- 1.4722945713996887
- 1.3715446543693544
- 1.3682066559791566
- 1.376938397884369
- 1.3540774941444398
- 1.3667103910446168
- 1.3700517320632934
- 1.3809701347351073
- 1.3706669950485229
- 1.3735805702209474
- 1.3582440137863159
- 1.3387861776351928
- 1.3894268655776978
- 1.373185179233551
- 1.3814975214004517
- 1.3704689288139342
- 1.3471395397186279
- 1.3302628636360168
- 1.3496879887580873
- 1.3253463506698608
- 1.437839469909668
- 1.4574694013595582
- 1.3406762385368347
- 1.3545347619056702
- 1.4114900279045104
- 1.4317926359176636
- 1.3790886878967286
- 1.361931667327881
- 1.3652295327186585
- 1.3664393711090088
- 1.3546209907531739
- 1.3226287579536438
- 1.319366352558136
- 1.382383234500885
- 1.3591649150848388
- 1.3551242518424989
- 1.3225407075881959
- 1.323746111392975
- 1.3280509877204896
- 1.384768419265747
- 1.440669505596161
- 1.3848340678215028
- 1.3304670000076293
- 1.3412429285049439
- 1.3474144768714904
- 1.347189953327179
- 1.356916584968567
- 1.3553670930862427
- 1.3222924995422363
- 1.331618800163269
- 1.3493526291847229
- 1.3253860139846803
- 1.3341632461547852
- 1.3907312893867492
- 1.3230599570274353
- 1.3918805027008057
- 1.3756707787513733
- 1.3510802030563354
- 1.4140893149375915
- 1.3746286487579347
train_accuracy:
- 0.003
- 0.036
- 0.507
- 0.001
- 0.053
- 0.061
- 0.046
- 0.165
- 0.204
- 0.353
- 0.146
- 0.029
- 0.166
- 0.094
- 0.142
- 0.15
- 0.131
- 0.225
- 0.088
- 0.267
- 0.417
- 0.075
- 0.11
- 0.127
- 0.289
- 0.149
- 0.248
- 0.193
- 0.339
- 0.487
- 0.229
- 0.317
- 0.168
- 0.221
- 0.328
- 0.134
- 0.162
- 0.22
- 0.149
- 0.272
- 0.531
- 0.356
- 0.335
- 0.337
- 0.027
- 0.353
- 0.231
- 0.224
- 0.131
- 0.166
- 0.326
- 0.257
- 0.224
- 0.29
- 0.314
- 0.218
- 0.406
- 0.176
- 0.165
- 0.124
- 0.611
- 0.086
- 0.219
- 0.088
- 0.355
- 0.261
- 0.56
- 0.287
- 0.251
- 0.157
- 0.358
- 0.172
- 0.16
- 0.216
- 0.152
- 0.437
- 0.168
- 0.195
- 0.129
- 0.291
- 0.169
- 0.146
- 0.31
- 0.176
- 0.233
- 0.303
- 0.204
- 0.465
- 0.182
- 0.288
- 0.38
- 0.128
- 0.196
- 0.296
- 0.183
- 0.481
- 0.529
- 0.169
- 0.273
- 0.421
train_loss:
- 2.092
- 1.496
- 1.412
- 0.895
- 1.788
- 1.26
- 1.244
- 1.199
- 1.131
- 1.127
- 1.479
- 1.07
- 1.445
- 0.306
- 1.048
- 1.382
- 1.339
- 0.977
- 0.942
- 0.919
- 0.918
- 0.906
- 0.859
- 1.152
- 0.547
- 1.116
- 0.807
- 0.825
- 1.082
- 0.78
- 0.472
- 0.723
- 0.993
- 0.97
- 0.493
- 0.703
- 0.944
- 0.661
- 0.638
- 0.421
- 0.395
- 0.868
- 0.872
- 0.628
- 0.821
- 0.599
- 0.619
- 0.586
- 0.576
- 0.549
- 0.73
- 0.742
- 0.349
- 0.502
- 0.489
- 0.508
- 0.671
- 0.665
- 0.493
- 0.639
- 0.152
- 0.296
- 0.61
- 0.45
- 0.288
- 0.288
- 0.416
- 0.426
- 0.411
- 0.396
- 0.419
- 0.545
- 0.521
- 0.252
- 0.383
- 0.382
- 0.49
- 0.491
- 0.35
- 0.233
- 0.216
- 0.33
- 0.449
- 0.334
- 0.338
- 0.33
- 0.306
- 0.321
- 0.405
- 0.305
- 0.307
- 0.389
- 0.284
- 0.199
- 0.376
- 0.201
- 0.265
- 0.255
- 0.172
- 0.263
unequal: 0
verbose: 1
