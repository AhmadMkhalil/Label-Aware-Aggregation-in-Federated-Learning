avg_train_accuracy: 0.405
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0175
- 0.036
- 0.0439
- 0.0571
- 0.0604
- 0.0905
- 0.1071
- 0.098
- 0.105
- 0.0848
- 0.1214
- 0.1199
- 0.0973
- 0.1167
- 0.1381
- 0.1408
- 0.1217
- 0.1445
- 0.1457
- 0.128
- 0.139
- 0.1194
- 0.1587
- 0.1706
- 0.1647
- 0.1445
- 0.1574
- 0.1771
- 0.1738
- 0.1729
- 0.1492
- 0.1702
- 0.1668
- 0.1692
- 0.1877
- 0.1802
- 0.1968
- 0.1904
- 0.197
- 0.1766
- 0.1913
- 0.1931
- 0.192
- 0.1995
- 0.1758
- 0.1869
- 0.1748
- 0.1597
- 0.1845
- 0.2017
- 0.2053
- 0.1988
- 0.2019
- 0.1996
- 0.1979
- 0.189
- 0.2023
- 0.2039
- 0.215
- 0.2061
- 0.2055
- 0.2021
- 0.2095
- 0.2177
- 0.1922
- 0.2051
- 0.2086
- 0.2193
- 0.2236
- 0.215
- 0.2142
- 0.2145
- 0.2232
- 0.2261
- 0.1998
- 0.2232
- 0.203
- 0.2217
- 0.2142
- 0.1963
- 0.1884
- 0.2268
- 0.2241
- 0.2353
- 0.2203
- 0.2008
- 0.1931
- 0.2055
- 0.2142
- 0.2285
- 0.2299
- 0.2292
- 0.2119
- 0.217
- 0.2141
- 0.192
- 0.2164
- 0.2333
- 0.2313
- 0.2251
test_loss_list:
- 1.8665990400314332
- 1.8064639472961426
- 1.740436887741089
- 1.7104581594467163
- 1.6910489368438721
- 1.628458435535431
- 1.5975012159347535
- 1.59525901556015
- 1.5797596979141235
- 1.6367239570617675
- 1.542587697505951
- 1.539162347316742
- 1.5892007541656494
- 1.5577173495292664
- 1.506237986087799
- 1.50400869846344
- 1.5442654585838318
- 1.4861636781692504
- 1.4890828919410706
- 1.5360059118270875
- 1.493482050895691
- 1.544252133369446
- 1.4501917266845703
- 1.43427321434021
- 1.4424217438697815
- 1.4944446277618408
- 1.4598507809638976
- 1.4260913109779358
- 1.4335484385490418
- 1.4356954383850098
- 1.480475091934204
- 1.448015866279602
- 1.4319635033607483
- 1.4264698481559754
- 1.3987646079063416
- 1.4124292349815368
- 1.3825243854522704
- 1.3982980418205262
- 1.3728620862960816
- 1.429180109500885
- 1.3815925455093383
- 1.3901412606239318
- 1.390936086177826
- 1.3751255011558532
- 1.4268388533592224
- 1.4129328775405883
- 1.4386516094207764
- 1.4711762881278991
- 1.4107648634910583
- 1.3674184131622313
- 1.3620958638191223
- 1.389697983264923
- 1.3606518149375915
- 1.3816490912437438
- 1.387647521495819
- 1.4083700895309448
- 1.38226491689682
- 1.379563388824463
- 1.3451436161994934
- 1.3651297402381897
- 1.369387810230255
- 1.3847248005867003
- 1.35202068567276
- 1.3419748640060425
- 1.4022535824775695
- 1.3637673377990722
- 1.3627387690544128
- 1.3359218788146974
- 1.3243774962425232
- 1.3463793754577638
- 1.3572751951217652
- 1.3700155639648437
- 1.3224805903434753
- 1.3449727702140808
- 1.3942614722251891
- 1.3258116006851197
- 1.3862541604042053
- 1.3403000950813293
- 1.3516759705543517
- 1.409105350971222
- 1.4334664678573608
- 1.333062274456024
- 1.350145125389099
- 1.3175605344772339
- 1.3585518717765808
- 1.3900701475143433
- 1.424484350681305
- 1.3757906126976014
- 1.3580734825134277
- 1.3177715730667114
- 1.3404620671272278
- 1.3176633310317993
- 1.3836296582221985
- 1.3555920314788819
- 1.371011197566986
- 1.4316479563713074
- 1.3667439866065978
- 1.316533226966858
- 1.314518189430237
- 1.3384434938430787
train_accuracy:
- 0.021
- 0.383
- 0.0
- 0.151
- 0.208
- 0.291
- 0.082
- 0.035
- 0.215
- 0.009
- 0.14
- 0.066
- 0.042
- 0.084
- 0.127
- 0.018
- 0.321
- 0.216
- 0.041
- 0.14
- 0.234
- 0.348
- 0.189
- 0.149
- 0.195
- 0.202
- 0.399
- 0.14
- 0.428
- 0.153
- 0.214
- 0.473
- 0.156
- 0.372
- 0.182
- 0.083
- 0.205
- 0.432
- 0.127
- 0.139
- 0.234
- 0.372
- 0.027
- 0.238
- 0.06
- 0.322
- 0.179
- 0.27
- 0.295
- 0.169
- 0.179
- 0.21
- 0.181
- 0.265
- 0.121
- 0.14
- 0.218
- 0.433
- 0.291
- 0.226
- 0.309
- 0.451
- 0.186
- 0.101
- 0.195
- 0.193
- 0.465
- 0.211
- 0.205
- 0.237
- 0.222
- 0.247
- 0.309
- 0.42
- 0.152
- 0.198
- 0.251
- 0.335
- 0.21
- 0.192
- 0.222
- 0.226
- 0.135
- 0.245
- 0.259
- 0.378
- 0.454
- 0.33
- 0.381
- 0.208
- 0.187
- 0.252
- 0.203
- 0.113
- 0.17
- 0.349
- 0.221
- 0.252
- 0.209
- 0.405
train_loss:
- 2.185
- 1.486
- 1.461
- 1.386
- 1.324
- 1.735
- 1.632
- 1.183
- 1.167
- 0.726
- 1.492
- 1.102
- 0.707
- 1.044
- 1.397
- 1.008
- 0.624
- 1.311
- 0.947
- 0.591
- 0.92
- 0.561
- 1.236
- 1.174
- 0.868
- 0.552
- 0.813
- 1.09
- 0.78
- 0.773
- 0.51
- 0.741
- 0.743
- 0.747
- 0.977
- 0.705
- 0.945
- 0.679
- 0.927
- 0.441
- 0.875
- 0.653
- 0.644
- 0.829
- 0.396
- 0.583
- 0.37
- 0.354
- 0.538
- 0.779
- 0.741
- 0.512
- 0.737
- 0.54
- 0.533
- 0.36
- 0.509
- 0.499
- 0.655
- 0.486
- 0.47
- 0.445
- 0.493
- 0.612
- 0.302
- 0.438
- 0.409
- 0.572
- 0.57
- 0.407
- 0.388
- 0.373
- 0.533
- 0.38
- 0.27
- 0.487
- 0.256
- 0.477
- 0.353
- 0.216
- 0.24
- 0.454
- 0.322
- 0.442
- 0.301
- 0.228
- 0.208
- 0.327
- 0.317
- 0.4
- 0.295
- 0.399
- 0.196
- 0.299
- 0.28
- 0.19
- 0.284
- 0.37
- 0.366
- 0.26
unequal: 0
verbose: 1
