avg_train_accuracy: 0.315
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0125
- 0.0248
- 0.0629
- 0.0403
- 0.0595
- 0.0948
- 0.1048
- 0.104
- 0.1082
- 0.1321
- 0.1432
- 0.1495
- 0.1396
- 0.1429
- 0.1437
- 0.1639
- 0.1672
- 0.1722
- 0.1665
- 0.1746
- 0.1554
- 0.16
- 0.1712
- 0.1659
- 0.1891
- 0.1974
- 0.1957
- 0.1873
- 0.1886
- 0.1986
- 0.1906
- 0.201
- 0.2071
- 0.1964
- 0.2006
- 0.1971
- 0.19
- 0.194
- 0.1747
- 0.1884
- 0.216
- 0.2037
- 0.2002
- 0.208
- 0.1873
- 0.2104
- 0.2081
- 0.2034
- 0.1853
- 0.2018
- 0.2218
- 0.2253
- 0.2265
- 0.208
- 0.2084
- 0.2156
- 0.2103
- 0.2123
- 0.2114
- 0.2272
- 0.1978
- 0.2246
- 0.2305
- 0.2228
- 0.2162
- 0.1717
- 0.1654
- 0.1676
- 0.2249
- 0.2254
- 0.2244
- 0.2151
- 0.2191
- 0.1959
- 0.1854
- 0.1824
- 0.1766
- 0.2331
- 0.2247
- 0.2173
- 0.2169
- 0.2203
- 0.1934
- 0.1936
- 0.2141
- 0.2151
- 0.2163
- 0.1967
- 0.2169
- 0.2231
- 0.2264
- 0.2006
- 0.1912
- 0.208
- 0.223
- 0.2217
- 0.2345
- 0.2343
- 0.2254
- 0.2297
test_loss_list:
- 1.904674162864685
- 1.83994215965271
- 1.7261506986618043
- 1.7493077182769776
- 1.6875439929962157
- 1.6224003624916077
- 1.6012224435806275
- 1.5988314414024354
- 1.572910075187683
- 1.5387442564964295
- 1.511409478187561
- 1.5078498029708862
- 1.5096843552589416
- 1.5050166964530944
- 1.5010377192497253
- 1.467192349433899
- 1.4520516586303711
- 1.4386803245544433
- 1.459960560798645
- 1.4334476208686828
- 1.4637205290794373
- 1.4539246940612793
- 1.4328826808929442
- 1.4408497762680055
- 1.4038505005836486
- 1.3855010652542115
- 1.3853696489334106
- 1.391590473651886
- 1.39503164768219
- 1.378722574710846
- 1.3890055298805237
- 1.377653841972351
- 1.3641011595726014
- 1.377622573375702
- 1.3666441226005555
- 1.3824738001823424
- 1.3948228001594543
- 1.3726343297958374
- 1.4329305410385131
- 1.3904588913917542
- 1.339703505039215
- 1.3641414284706115
- 1.36966623544693
- 1.351366617679596
- 1.4004354691505432
- 1.3594235563278199
- 1.356620924472809
- 1.3742074751853943
- 1.3964482545852661
- 1.3626738834381102
- 1.323151957988739
- 1.3222818994522094
- 1.3227430438995362
- 1.3656285786628723
- 1.3628052401542663
- 1.3408043694496155
- 1.3435851454734802
- 1.3486789226531983
- 1.3436957144737243
- 1.3122253108024597
- 1.37962219953537
- 1.3207765245437622
- 1.3051209139823914
- 1.3273647713661194
- 1.335647840499878
- 1.4666459655761719
- 1.4763842916488648
- 1.4744964361190795
- 1.3185345220565796
- 1.317583031654358
- 1.325080680847168
- 1.357861089706421
- 1.3608965063095093
- 1.3988845753669739
- 1.4363587760925294
- 1.4320857071876525
- 1.46399267911911
- 1.313076069355011
- 1.3210364866256714
- 1.342048089504242
- 1.3400043654441833
- 1.3401810240745544
- 1.402965805530548
- 1.4157011079788209
- 1.3590453577041626
- 1.3394600319862366
- 1.3404073739051818
- 1.4023669838905335
- 1.3460648465156555
- 1.3434001231193542
- 1.3286039161682128
- 1.3955893540382385
- 1.4270847678184508
- 1.36698410987854
- 1.334304599761963
- 1.3410458540916443
- 1.3092555475234986
- 1.307622754573822
- 1.3248357605934142
- 1.3295084524154663
train_accuracy:
- 0.0
- 0.071
- 0.032
- 0.084
- 0.158
- 0.149
- 0.034
- 0.19
- 0.068
- 0.189
- 0.056
- 0.116
- 0.035
- 0.246
- 0.111
- 0.125
- 0.127
- 0.144
- 0.081
- 0.174
- 0.007
- 0.239
- 0.116
- 0.42
- 0.107
- 0.058
- 0.204
- 0.262
- 0.344
- 0.179
- 0.106
- 0.16
- 0.195
- 0.041
- 0.184
- 0.15
- 0.142
- 0.333
- 0.186
- 0.347
- 0.058
- 0.23
- 0.302
- 0.247
- 0.146
- 0.158
- 0.178
- 0.178
- 0.48
- 0.046
- 0.318
- 0.078
- 0.206
- 0.133
- 0.093
- 0.32
- 0.175
- 0.344
- 0.08
- 0.199
- 0.02
- 0.209
- 0.071
- 0.147
- 0.415
- 0.153
- 0.244
- 0.223
- 0.171
- 0.223
- 0.204
- 0.064
- 0.15
- 0.147
- 0.111
- 0.312
- 0.173
- 0.422
- 0.083
- 0.202
- 0.163
- 0.203
- 0.018
- 0.14
- 0.139
- 0.16
- 0.262
- 0.32
- 0.239
- 0.409
- 0.176
- 0.319
- 0.291
- 0.353
- 0.305
- 0.057
- 0.272
- 0.208
- 0.176
- 0.315
train_loss:
- 1.614
- 1.474
- 1.895
- 0.87
- 1.279
- 1.685
- 1.205
- 1.167
- 1.15
- 1.498
- 1.476
- 1.401
- 1.029
- 1.006
- 0.961
- 1.303
- 1.269
- 1.253
- 0.9
- 1.189
- 0.567
- 0.846
- 0.835
- 0.81
- 1.09
- 1.068
- 1.041
- 0.779
- 0.727
- 0.992
- 0.698
- 0.929
- 0.929
- 0.673
- 0.657
- 0.631
- 0.612
- 0.609
- 0.371
- 0.598
- 0.824
- 0.58
- 0.565
- 0.773
- 0.369
- 0.745
- 0.523
- 0.54
- 0.357
- 0.51
- 0.692
- 0.67
- 0.666
- 0.348
- 0.468
- 0.461
- 0.47
- 0.449
- 0.437
- 0.599
- 0.284
- 0.579
- 0.574
- 0.416
- 0.405
- 0.118
- 0.246
- 0.242
- 0.535
- 0.523
- 0.39
- 0.367
- 0.355
- 0.233
- 0.211
- 0.234
- 0.213
- 0.475
- 0.352
- 0.33
- 0.337
- 0.322
- 0.217
- 0.214
- 0.311
- 0.296
- 0.313
- 0.2
- 0.298
- 0.3
- 0.293
- 0.187
- 0.183
- 0.277
- 0.288
- 0.273
- 0.346
- 0.278
- 0.266
- 0.257
unequal: 0
verbose: 1
