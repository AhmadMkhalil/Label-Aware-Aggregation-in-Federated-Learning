avg_train_accuracy: 0.21
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.015
- 0.0222
- 0.0319
- 0.0459
- 0.0607
- 0.0853
- 0.0849
- 0.1049
- 0.0965
- 0.1223
- 0.1168
- 0.1242
- 0.1417
- 0.1524
- 0.1399
- 0.1571
- 0.1456
- 0.1603
- 0.1706
- 0.1638
- 0.1726
- 0.1657
- 0.1623
- 0.1652
- 0.1658
- 0.1455
- 0.1546
- 0.1814
- 0.1596
- 0.1674
- 0.1716
- 0.184
- 0.1932
- 0.1946
- 0.1886
- 0.199
- 0.1883
- 0.2006
- 0.1797
- 0.1858
- 0.1917
- 0.1879
- 0.1926
- 0.1922
- 0.2022
- 0.2058
- 0.2098
- 0.2037
- 0.1829
- 0.2129
- 0.1885
- 0.1964
- 0.2006
- 0.2042
- 0.2024
- 0.2061
- 0.2154
- 0.1919
- 0.2145
- 0.2056
- 0.2045
- 0.2074
- 0.1903
- 0.2213
- 0.1982
- 0.1822
- 0.2182
- 0.1978
- 0.2049
- 0.2212
- 0.2085
- 0.2116
- 0.2207
- 0.2147
- 0.2205
- 0.2148
- 0.1741
- 0.174
- 0.2
- 0.2247
- 0.1992
- 0.2261
- 0.2057
- 0.2143
- 0.2314
- 0.2239
- 0.2193
- 0.198
- 0.2141
- 0.1953
- 0.2107
- 0.2138
- 0.2175
- 0.2003
- 0.2119
- 0.2186
- 0.2293
- 0.223
- 0.2175
- 0.2331
test_loss_list:
- 1.8878393363952637
- 1.82773738861084
- 1.7838602733612061
- 1.7332848262786866
- 1.7024417304992676
- 1.6310884308815004
- 1.6291611313819885
- 1.5809435486793517
- 1.5889382672309875
- 1.5490114426612853
- 1.5439449286460876
- 1.5375017762184142
- 1.502304208278656
- 1.4899438309669495
- 1.5019521045684814
- 1.481897406578064
- 1.4957578539848329
- 1.470143234729767
- 1.4454156541824341
- 1.4473990893363953
- 1.4340670704841614
- 1.4448550748825073
- 1.4511136484146119
- 1.439412248134613
- 1.4401291227340698
- 1.4813675951957703
- 1.4590720963478088
- 1.4027517318725586
- 1.456971411705017
- 1.4426194167137145
- 1.4205059814453125
- 1.394856605529785
- 1.3813559222221374
- 1.3897179126739503
- 1.3861217260360719
- 1.371737163066864
- 1.3841577434539796
- 1.365397753715515
- 1.4108661103248596
- 1.3994501090049745
- 1.391738965511322
- 1.391817750930786
- 1.3896728682518005
- 1.3877256464958192
- 1.3641842365264893
- 1.3629377746582032
- 1.3508008646965026
- 1.362975709438324
- 1.413321349620819
- 1.342699751853943
- 1.4016474556922913
- 1.3855838871002197
- 1.3766127610206604
- 1.362730791568756
- 1.3721595907211304
- 1.3671627521514893
- 1.3413699507713317
- 1.3959031295776367
- 1.3434362721443176
- 1.3683095502853393
- 1.3647134518623352
- 1.363367931842804
- 1.401199312210083
- 1.334278256893158
- 1.3888042306900024
- 1.4307071924209596
- 1.3379548859596253
- 1.389038643836975
- 1.369255907535553
- 1.3287023758888246
- 1.3628814244270324
- 1.3603887844085694
- 1.3363113832473754
- 1.36382004737854
- 1.3494845819473267
- 1.3430088877677917
- 1.4523245000839233
- 1.4545012712478638
- 1.3830459642410278
- 1.3213591647148133
- 1.3924523663520814
- 1.319977536201477
- 1.378725004196167
- 1.363883011341095
- 1.320054564476013
- 1.3381998658180236
- 1.3466221570968628
- 1.4136861538887024
- 1.3645914602279663
- 1.4179211139678956
- 1.3695821022987367
- 1.368713207244873
- 1.359287600517273
- 1.4163845825195311
- 1.3747442507743834
- 1.3588202786445618
- 1.338458504676819
- 1.3473576998710632
- 1.3663386702537537
- 1.3277263736724854
train_accuracy:
- 0.009
- 0.002
- 0.174
- 0.022
- 0.077
- 0.194
- 0.077
- 0.099
- 0.184
- 0.116
- 0.001
- 0.164
- 0.132
- 0.149
- 0.125
- 0.316
- 0.147
- 0.174
- 0.175
- 0.209
- 0.334
- 0.12
- 0.242
- 0.163
- 0.398
- 0.346
- 0.518
- 0.076
- 0.299
- 0.146
- 0.146
- 0.113
- 0.081
- 0.113
- 0.018
- 0.186
- 0.171
- 0.303
- 0.015
- 0.268
- 0.465
- 0.172
- 0.21
- 0.161
- 0.388
- 0.164
- 0.074
- 0.183
- 0.261
- 0.206
- 0.046
- 0.259
- 0.222
- 0.242
- 0.28
- 0.463
- 0.431
- 0.289
- 0.169
- 0.098
- 0.206
- 0.122
- 0.437
- 0.454
- 0.081
- 0.156
- 0.179
- 0.085
- 0.178
- 0.215
- 0.197
- 0.196
- 0.212
- 0.097
- 0.388
- 0.195
- 0.418
- 0.546
- 0.285
- 0.132
- 0.133
- 0.207
- 0.187
- 0.22
- 0.181
- 0.132
- 0.207
- 0.643
- 0.159
- 0.159
- 0.192
- 0.185
- 0.187
- 0.294
- 0.389
- 0.123
- 0.146
- 0.068
- 0.263
- 0.21
train_loss:
- 1.629
- 1.488
- 1.418
- 1.39
- 1.305
- 1.778
- 1.226
- 1.649
- 1.172
- 1.586
- 1.137
- 1.115
- 1.461
- 1.414
- 1.032
- 1.333
- 0.987
- 1.32
- 1.263
- 0.959
- 1.211
- 0.864
- 0.887
- 0.86
- 0.853
- 0.538
- 0.805
- 1.114
- 0.52
- 0.775
- 0.768
- 1.02
- 1.0
- 0.955
- 0.737
- 0.951
- 0.707
- 0.895
- 0.448
- 0.655
- 0.626
- 0.638
- 0.612
- 0.608
- 0.823
- 0.801
- 0.802
- 0.566
- 0.388
- 0.743
- 0.357
- 0.524
- 0.537
- 0.512
- 0.512
- 0.476
- 0.669
- 0.344
- 0.641
- 0.472
- 0.451
- 0.459
- 0.285
- 0.582
- 0.301
- 0.27
- 0.569
- 0.304
- 0.424
- 0.556
- 0.404
- 0.38
- 0.519
- 0.363
- 0.497
- 0.37
- 0.126
- 0.247
- 0.356
- 0.47
- 0.24
- 0.464
- 0.228
- 0.33
- 0.428
- 0.321
- 0.31
- 0.194
- 0.309
- 0.212
- 0.289
- 0.277
- 0.276
- 0.194
- 0.289
- 0.269
- 0.369
- 0.306
- 0.247
- 0.352
unequal: 0
verbose: 1
