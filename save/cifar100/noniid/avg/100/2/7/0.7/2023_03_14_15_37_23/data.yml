avg_train_accuracy: 0.44
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0142
- 0.0367
- 0.0637
- 0.0834
- 0.0751
- 0.0833
- 0.0914
- 0.1173
- 0.1081
- 0.1106
- 0.0909
- 0.1356
- 0.1322
- 0.1451
- 0.119
- 0.1539
- 0.1267
- 0.1321
- 0.1626
- 0.1505
- 0.172
- 0.1609
- 0.1585
- 0.1629
- 0.1624
- 0.1809
- 0.1573
- 0.1596
- 0.1683
- 0.1696
- 0.1889
- 0.1826
- 0.1559
- 0.1687
- 0.1909
- 0.1817
- 0.1851
- 0.1558
- 0.1744
- 0.1812
- 0.1987
- 0.1783
- 0.2003
- 0.1964
- 0.2058
- 0.2029
- 0.2119
- 0.2029
- 0.1998
- 0.2132
- 0.2024
- 0.171
- 0.2114
- 0.2085
- 0.1826
- 0.1998
- 0.2216
- 0.2209
- 0.221
- 0.1939
- 0.1766
- 0.1921
- 0.2096
- 0.1813
- 0.203
- 0.1781
- 0.2007
- 0.2066
- 0.2065
- 0.1873
- 0.1709
- 0.2168
- 0.2128
- 0.2101
- 0.2188
- 0.2266
- 0.2193
- 0.2175
- 0.2301
- 0.2314
- 0.2339
- 0.2372
- 0.2301
- 0.2356
- 0.2356
- 0.2353
- 0.2274
- 0.2353
- 0.2263
- 0.2224
- 0.2186
- 0.218
- 0.2201
- 0.234
- 0.226
- 0.2387
- 0.2075
- 0.1974
- 0.1837
- 0.1819
test_loss_list:
- 1.893612117767334
- 1.7934405040740966
- 1.7287618017196655
- 1.6889163589477538
- 1.662634732723236
- 1.6396699690818786
- 1.6239852905273438
- 1.5828856873512267
- 1.5913155961036682
- 1.5738911986351014
- 1.6229242086410522
- 1.5312085008621217
- 1.5408979654312134
- 1.5035627317428588
- 1.5530148816108704
- 1.490858438014984
- 1.5474255180358887
- 1.5212611985206603
- 1.4688059735298156
- 1.4876840353012084
- 1.4545809102058411
- 1.4675232219696044
- 1.4750007104873657
- 1.4597715377807616
- 1.4638889002799989
- 1.4365804743766786
- 1.4759677743911743
- 1.4718858242034911
- 1.4512317037582398
- 1.4582883524894714
- 1.414916524887085
- 1.434614770412445
- 1.485153043270111
- 1.4551075220108032
- 1.413017556667328
- 1.4259649729728698
- 1.4203872275352478
- 1.4935957980155945
- 1.430804145336151
- 1.4177417135238648
- 1.392283866405487
- 1.428538420200348
- 1.379471800327301
- 1.3959323382377624
- 1.3872102189064026
- 1.3767446160316468
- 1.364011881351471
- 1.3810469174385072
- 1.3853261709213256
- 1.3611547350883484
- 1.3881483721733092
- 1.4425975108146667
- 1.367686755657196
- 1.3770782995223998
- 1.4295335507392883
- 1.3941994833946227
- 1.3442054295539856
- 1.3515779638290406
- 1.34792795419693
- 1.398764319419861
- 1.4412982702255248
- 1.406184935569763
- 1.3730024981498719
- 1.4371297764778137
- 1.3971223902702332
- 1.4544544219970703
- 1.3926841306686402
- 1.381134614944458
- 1.377403244972229
- 1.4217734932899475
- 1.464311945438385
- 1.3602058005332947
- 1.3680615329742432
- 1.3788086795806884
- 1.3606077742576599
- 1.344545338153839
- 1.3558666443824767
- 1.3643970680236817
- 1.336144299507141
- 1.3362553310394287
- 1.332567148208618
- 1.3249591588974
- 1.33616361618042
- 1.3328895258903504
- 1.3372084760665894
- 1.3381318736076355
- 1.3541440272331238
- 1.328429980278015
- 1.3447457480430602
- 1.354521381855011
- 1.3674566459655761
- 1.3682347345352173
- 1.373001642227173
- 1.3415110850334167
- 1.366441535949707
- 1.3267668771743775
- 1.3938838291168212
- 1.4358317232131959
- 1.4646177649497987
- 1.4810077166557312
train_accuracy:
- 0.003
- 0.02
- 0.037
- 0.173
- 0.269
- 0.0
- 0.289
- 0.233
- 0.241
- 0.078
- 0.063
- 0.024
- 0.1
- 0.152
- 0.235
- 0.125
- 0.22
- 0.102
- 0.105
- 0.104
- 0.153
- 0.339
- 0.118
- 0.144
- 0.112
- 0.066
- 0.158
- 0.113
- 0.128
- 0.122
- 0.4
- 0.103
- 0.521
- 0.295
- 0.177
- 0.183
- 0.136
- 0.366
- 0.138
- 0.093
- 0.203
- 0.071
- 0.242
- 0.272
- 0.216
- 0.018
- 0.054
- 0.225
- 0.303
- 0.178
- 0.42
- 0.085
- 0.218
- 0.185
- 0.374
- 0.189
- 0.296
- 0.187
- 0.254
- 0.179
- 0.128
- 0.179
- 0.347
- 0.235
- 0.174
- 0.137
- 0.245
- 0.208
- 0.181
- 0.159
- 0.517
- 0.342
- 0.258
- 0.174
- 0.223
- 0.206
- 0.274
- 0.077
- 0.199
- 0.194
- 0.042
- 0.233
- 0.038
- 0.204
- 0.225
- 0.007
- 0.204
- 0.048
- 0.186
- 0.236
- 0.236
- 0.165
- 0.067
- 0.232
- 0.101
- 0.249
- 0.199
- 0.269
- 0.499
- 0.44
train_loss:
- 1.635
- 2.007
- 1.872
- 1.771
- 1.316
- 1.266
- 1.227
- 1.601
- 1.16
- 1.14
- 0.7
- 1.5
- 1.055
- 1.425
- 0.664
- 1.371
- 0.637
- 0.953
- 1.303
- 0.929
- 1.253
- 0.918
- 0.886
- 0.861
- 0.835
- 1.146
- 0.564
- 0.812
- 0.824
- 0.772
- 1.046
- 0.757
- 0.485
- 0.726
- 0.988
- 0.706
- 0.727
- 0.418
- 0.672
- 0.707
- 0.896
- 0.45
- 0.882
- 0.621
- 0.823
- 0.62
- 0.817
- 0.594
- 0.591
- 0.78
- 0.552
- 0.367
- 0.741
- 0.559
- 0.358
- 0.543
- 0.702
- 0.675
- 0.662
- 0.338
- 0.314
- 0.467
- 0.473
- 0.296
- 0.461
- 0.279
- 0.447
- 0.437
- 0.424
- 0.293
- 0.259
- 0.554
- 0.41
- 0.394
- 0.399
- 0.518
- 0.403
- 0.378
- 0.506
- 0.496
- 0.478
- 0.479
- 0.362
- 0.459
- 0.451
- 0.424
- 0.32
- 0.425
- 0.32
- 0.323
- 0.304
- 0.298
- 0.289
- 0.384
- 0.278
- 0.377
- 0.206
- 0.191
- 0.178
- 0.181
unequal: 0
verbose: 1
