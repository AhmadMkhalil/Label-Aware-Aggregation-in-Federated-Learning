avg_train_accuracy: 0.204
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0259
- 0.067
- 0.065
- 0.1073
- 0.1054
- 0.0924
- 0.1086
- 0.1327
- 0.1299
- 0.1499
- 0.1525
- 0.152
- 0.1196
- 0.1095
- 0.1392
- 0.1505
- 0.176
- 0.1903
- 0.1873
- 0.1977
- 0.1965
- 0.1995
- 0.2109
- 0.2087
- 0.2158
- 0.2194
- 0.2207
- 0.221
- 0.1962
- 0.2248
- 0.2201
- 0.2258
- 0.2178
- 0.2153
- 0.2141
- 0.2288
- 0.2379
- 0.2306
- 0.2386
- 0.204
- 0.186
- 0.2116
- 0.2261
- 0.2258
- 0.2409
- 0.2372
- 0.2013
- 0.248
- 0.2509
- 0.2494
- 0.2528
- 0.2528
- 0.2573
- 0.2571
- 0.2479
- 0.2555
- 0.2397
- 0.2503
- 0.262
- 0.2504
- 0.2556
- 0.2192
- 0.2384
- 0.2414
- 0.2458
- 0.2655
- 0.254
- 0.2415
- 0.2644
- 0.2682
- 0.2647
- 0.2713
- 0.2597
- 0.2674
- 0.263
- 0.2589
- 0.2594
- 0.2688
- 0.268
- 0.2608
- 0.2699
- 0.2666
- 0.234
- 0.2783
- 0.2646
- 0.2605
- 0.2573
- 0.2763
- 0.2763
- 0.2718
- 0.2712
- 0.2759
- 0.2762
- 0.2704
- 0.2766
- 0.2698
- 0.2367
- 0.2725
- 0.2815
- 0.2601
test_loss_list:
- 1.8532208776474
- 1.7274589014053345
- 1.6993245410919189
- 1.632827799320221
- 1.5905538010597229
- 1.5979501461982728
- 1.570510241985321
- 1.5326862668991088
- 1.524708034992218
- 1.4967886543273925
- 1.4927159190177917
- 1.4724994325637817
- 1.5211602783203124
- 1.5628191637992859
- 1.4912753319740295
- 1.4683609342575072
- 1.4342241311073303
- 1.4222179532051087
- 1.4231974959373475
- 1.412143211364746
- 1.4071570754051208
- 1.368950960636139
- 1.3747698855400086
- 1.3647140169143677
- 1.3709056210517883
- 1.3894374465942383
- 1.3636175775527954
- 1.3334314179420472
- 1.379819667339325
- 1.3223404836654664
- 1.3382788372039796
- 1.332378900051117
- 1.355990900993347
- 1.3269934415817262
- 1.3340199398994446
- 1.3131112694740295
- 1.312350995540619
- 1.3090150022506715
- 1.2972411131858825
- 1.3587033486366271
- 1.3971805024147033
- 1.3297654914855956
- 1.315602219104767
- 1.3118207454681396
- 1.2867410707473754
- 1.2992983436584473
- 1.3573459959030152
- 1.2721815061569215
- 1.2852494812011719
- 1.2843784475326538
- 1.2864506268501281
- 1.2581697249412536
- 1.2739699053764344
- 1.269036271572113
- 1.2838762950897218
- 1.2806144547462464
- 1.3043611478805541
- 1.2661918258666993
- 1.2582859420776367
- 1.2798061084747314
- 1.2586160588264466
- 1.3342731976509095
- 1.2944890928268433
- 1.2913386583328248
- 1.2858999013900756
- 1.2359974908828735
- 1.2698300552368165
- 1.296922664642334
- 1.2599401593208313
- 1.2507792687416077
- 1.2632288432121277
- 1.2484070467948913
- 1.2581405282020568
- 1.2537714958190918
- 1.2677945756912232
- 1.268239872455597
- 1.2512059259414672
- 1.2448026943206787
- 1.2441033959388732
- 1.2672027945518494
- 1.2524144911766053
- 1.2664650750160218
- 1.3198415541648865
- 1.2411373949050903
- 1.2721119689941407
- 1.2698725795745849
- 1.280653486251831
- 1.228450117111206
- 1.244444558620453
- 1.2560921096801758
- 1.251831862926483
- 1.2435756015777588
- 1.2485849738121033
- 1.256878125667572
- 1.235014259815216
- 1.255798466205597
- 1.3310146951675415
- 1.2449521255493163
- 1.2347671151161195
- 1.2934481167793275
train_accuracy:
- 0.015
- 0.053
- 0.0
- 0.111
- 0.063
- 0.18
- 0.498
- 0.107
- 0.213
- 0.146
- 0.165
- 0.018
- 0.069
- 0.309
- 0.139
- 0.14
- 0.195
- 0.206
- 0.225
- 0.176
- 0.24
- 0.085
- 0.198
- 0.202
- 0.248
- 0.23
- 0.141
- 0.223
- 0.29
- 0.249
- 0.118
- 0.139
- 0.196
- 0.221
- 0.233
- 0.237
- 0.243
- 0.19
- 0.225
- 0.508
- 0.442
- 0.184
- 0.444
- 0.521
- 0.382
- 0.257
- 0.107
- 0.258
- 0.068
- 0.252
- 0.267
- 0.111
- 0.26
- 0.192
- 0.231
- 0.242
- 0.054
- 0.221
- 0.265
- 0.257
- 0.382
- 0.469
- 0.478
- 0.214
- 0.223
- 0.419
- 0.194
- 0.394
- 0.277
- 0.111
- 0.252
- 0.126
- 0.255
- 0.277
- 0.455
- 0.233
- 0.233
- 0.167
- 0.259
- 0.33
- 0.254
- 0.247
- 0.225
- 0.278
- 0.31
- 0.281
- 0.268
- 0.255
- 0.289
- 0.25
- 0.263
- 0.284
- 0.272
- 0.175
- 0.275
- 0.035
- 0.286
- 0.287
- 0.289
- 0.204
train_loss:
- 2.743
- 2.526
- 1.753
- 2.279
- 1.691
- 1.623
- 1.515
- 2.071
- 1.478
- 1.941
- 1.893
- 1.377
- 0.81
- 0.799
- 1.251
- 1.272
- 1.757
- 2.169
- 1.602
- 2.072
- 1.546
- 1.169
- 1.92
- 1.503
- 1.829
- 2.125
- 1.399
- 1.352
- 0.59
- 1.296
- 0.926
- 1.29
- 0.896
- 0.893
- 0.864
- 1.183
- 1.436
- 0.833
- 1.078
- 0.498
- 0.469
- 0.77
- 0.773
- 0.698
- 1.024
- 0.755
- 0.445
- 1.23
- 0.96
- 0.895
- 1.121
- 0.695
- 1.108
- 0.822
- 0.604
- 0.783
- 0.533
- 0.615
- 0.953
- 0.555
- 0.611
- 0.35
- 0.508
- 0.54
- 0.518
- 0.715
- 0.528
- 0.482
- 0.645
- 0.806
- 0.624
- 0.784
- 0.446
- 0.595
- 0.551
- 0.434
- 0.443
- 0.525
- 0.522
- 0.395
- 0.532
- 0.492
- 0.274
- 0.626
- 0.364
- 0.374
- 0.351
- 0.472
- 0.551
- 0.425
- 0.406
- 0.545
- 0.394
- 0.376
- 0.411
- 0.296
- 0.181
- 0.486
- 0.402
- 0.262
unequal: 0
verbose: 1
