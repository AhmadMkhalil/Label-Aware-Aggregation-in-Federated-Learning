avg_train_accuracy: 0.276
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0201
- 0.0708
- 0.0938
- 0.1053
- 0.1154
- 0.1306
- 0.1391
- 0.1322
- 0.1472
- 0.1379
- 0.1336
- 0.0838
- 0.1598
- 0.1685
- 0.1742
- 0.1793
- 0.1715
- 0.1826
- 0.1478
- 0.0925
- 0.1889
- 0.1549
- 0.1331
- 0.1964
- 0.1911
- 0.1785
- 0.1923
- 0.1875
- 0.1905
- 0.2127
- 0.2157
- 0.1883
- 0.2149
- 0.2221
- 0.1816
- 0.2082
- 0.2249
- 0.2155
- 0.1818
- 0.2113
- 0.2141
- 0.2353
- 0.2265
- 0.2344
- 0.2085
- 0.2375
- 0.2013
- 0.2155
- 0.1937
- 0.1732
- 0.2431
- 0.2423
- 0.2276
- 0.2453
- 0.2482
- 0.2473
- 0.2333
- 0.2487
- 0.2491
- 0.2419
- 0.2472
- 0.2559
- 0.2571
- 0.2383
- 0.257
- 0.2505
- 0.2511
- 0.2156
- 0.2337
- 0.2577
- 0.2487
- 0.257
- 0.2295
- 0.2423
- 0.2588
- 0.2591
- 0.2621
- 0.2537
- 0.266
- 0.2645
- 0.2538
- 0.2616
- 0.2446
- 0.2514
- 0.2662
- 0.2664
- 0.2708
- 0.2613
- 0.2695
- 0.2732
- 0.2657
- 0.2576
- 0.2331
- 0.2458
- 0.2711
- 0.259
- 0.2722
- 0.2643
- 0.2708
- 0.2541
test_loss_list:
- 1.9452509450912476
- 1.726796979904175
- 1.66978187084198
- 1.6219766068458557
- 1.5933814787864684
- 1.5753997802734374
- 1.5455782723426819
- 1.5331428480148315
- 1.5026667284965516
- 1.5311599445343018
- 1.5434277176856994
- 1.6624000549316407
- 1.4628904342651368
- 1.460468235015869
- 1.458993408679962
- 1.439043674468994
- 1.455115921497345
- 1.4134061455726623
- 1.4728410983085631
- 1.655045108795166
- 1.3998284006118775
- 1.4679647636413575
- 1.5120187401771545
- 1.3812715482711793
- 1.3945822405815125
- 1.4171592497825622
- 1.3818275332450867
- 1.3926097965240478
- 1.385137572288513
- 1.35989422082901
- 1.3587241935729981
- 1.3891683530807495
- 1.3509834694862366
- 1.3391698956489564
- 1.400136992931366
- 1.343147964477539
- 1.3228712701797485
- 1.3412237238883973
- 1.392840850353241
- 1.3467319536209106
- 1.3432458901405335
- 1.3162697267532348
- 1.3314163064956666
- 1.315446605682373
- 1.3460103559494019
- 1.2933533430099486
- 1.3668399357795715
- 1.3370342564582824
- 1.3773352122306823
- 1.4360772132873536
- 1.2898735618591308
- 1.2988705253601074
- 1.3350793623924255
- 1.3017558932304383
- 1.277225365638733
- 1.2974640870094298
- 1.322029221057892
- 1.28459796667099
- 1.3009963893890382
- 1.314761793613434
- 1.2767548060417175
- 1.2707686614990235
- 1.2728010153770446
- 1.314748272895813
- 1.2681488466262818
- 1.2886634969711304
- 1.2792403244972228
- 1.3517954349517822
- 1.3141769695281982
- 1.2650282239913941
- 1.2835163116455077
- 1.2542907547950746
- 1.3199882340431213
- 1.2996869826316833
- 1.2678739380836488
- 1.2780126905441285
- 1.2694631218910217
- 1.2850636196136476
- 1.256774775981903
- 1.2427927374839782
- 1.2725841307640076
- 1.2641927576065064
- 1.3013244295120239
- 1.2807307052612305
- 1.2450517725944519
- 1.2576223707199097
- 1.2481297159194946
- 1.271129970550537
- 1.2528066778182982
- 1.2599957966804505
- 1.263344280719757
- 1.2855071449279785
- 1.3358099555969238
- 1.2923015761375427
- 1.2493912386894226
- 1.284828999042511
- 1.2478400516510009
- 1.2637062978744507
- 1.2496446943283082
- 1.296639895439148
train_accuracy:
- 0.0
- 0.088
- 0.355
- 0.01
- 0.13
- 0.142
- 0.13
- 0.001
- 0.191
- 0.116
- 0.377
- 0.253
- 0.192
- 0.199
- 0.148
- 0.13
- 0.304
- 0.216
- 0.249
- 0.165
- 0.21
- 0.224
- 0.364
- 0.186
- 0.12
- 0.14
- 0.103
- 0.343
- 0.171
- 0.24
- 0.047
- 0.17
- 0.201
- 0.215
- 0.453
- 0.325
- 0.255
- 0.202
- 0.359
- 0.218
- 0.249
- 0.231
- 0.115
- 0.261
- 0.054
- 0.263
- 0.438
- 0.316
- 0.342
- 0.354
- 0.257
- 0.286
- 0.214
- 0.265
- 0.049
- 0.234
- 0.137
- 0.249
- 0.137
- 0.223
- 0.271
- 0.326
- 0.109
- 0.231
- 0.179
- 0.273
- 0.315
- 0.378
- 0.222
- 0.257
- 0.269
- 0.068
- 0.354
- 0.418
- 0.299
- 0.233
- 0.268
- 0.184
- 0.284
- 0.22
- 0.2
- 0.134
- 0.223
- 0.107
- 0.285
- 0.265
- 0.271
- 0.118
- 0.257
- 0.273
- 0.296
- 0.209
- 0.506
- 0.195
- 0.278
- 0.421
- 0.257
- 0.251
- 0.342
- 0.276
train_loss:
- 1.273
- 3.372
- 2.425
- 2.319
- 2.214
- 2.664
- 2.071
- 1.515
- 1.987
- 1.367
- 1.296
- 0.327
- 1.861
- 1.787
- 1.738
- 1.721
- 1.241
- 1.681
- 0.729
- 0.231
- 1.639
- 0.705
- 0.646
- 1.565
- 1.082
- 1.027
- 1.082
- 1.032
- 1.026
- 1.785
- 1.359
- 0.613
- 1.307
- 1.24
- 0.582
- 0.872
- 1.228
- 0.888
- 0.492
- 0.894
- 0.842
- 1.466
- 0.794
- 1.127
- 0.464
- 1.089
- 0.429
- 0.742
- 0.456
- 0.427
- 1.32
- 0.958
- 0.661
- 1.229
- 0.708
- 0.908
- 0.594
- 0.874
- 0.815
- 0.647
- 0.607
- 0.807
- 0.865
- 0.545
- 0.758
- 0.717
- 0.542
- 0.306
- 0.45
- 0.817
- 0.523
- 0.691
- 0.291
- 0.466
- 0.842
- 0.501
- 0.803
- 0.458
- 0.609
- 0.617
- 0.404
- 0.545
- 0.435
- 0.392
- 0.556
- 0.528
- 0.538
- 0.36
- 0.508
- 0.636
- 0.351
- 0.359
- 0.259
- 0.3
- 0.598
- 0.331
- 0.456
- 0.351
- 0.454
- 0.344
unequal: 0
verbose: 1
