avg_train_accuracy: 0.336
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0284
- 0.0748
- 0.0759
- 0.0821
- 0.0872
- 0.121
- 0.1059
- 0.1145
- 0.1396
- 0.1283
- 0.1388
- 0.1614
- 0.146
- 0.145
- 0.173
- 0.161
- 0.1761
- 0.1498
- 0.1809
- 0.1893
- 0.187
- 0.18
- 0.1971
- 0.1599
- 0.1889
- 0.2118
- 0.2011
- 0.1649
- 0.1851
- 0.1978
- 0.2026
- 0.1699
- 0.2092
- 0.2021
- 0.2034
- 0.2203
- 0.2182
- 0.2129
- 0.2121
- 0.2312
- 0.2303
- 0.2259
- 0.2305
- 0.2297
- 0.2404
- 0.2222
- 0.2425
- 0.237
- 0.244
- 0.2338
- 0.2419
- 0.2336
- 0.2474
- 0.2451
- 0.2394
- 0.2367
- 0.2367
- 0.2297
- 0.2409
- 0.2434
- 0.2554
- 0.2498
- 0.2476
- 0.2468
- 0.2449
- 0.2354
- 0.2597
- 0.2662
- 0.2583
- 0.2363
- 0.2435
- 0.2588
- 0.266
- 0.2625
- 0.25
- 0.2465
- 0.2632
- 0.2399
- 0.2464
- 0.2651
- 0.2665
- 0.2309
- 0.2667
- 0.2601
- 0.2479
- 0.2637
- 0.2616
- 0.2564
- 0.2565
- 0.2686
- 0.272
- 0.2677
- 0.2525
- 0.2631
- 0.2665
- 0.2565
- 0.2547
- 0.2546
- 0.2718
- 0.2509
test_loss_list:
- 1.8331659269332885
- 1.7052221918106079
- 1.6609273910522462
- 1.6526889657974244
- 1.6326667499542236
- 1.5814557194709777
- 1.5893969345092773
- 1.561805899143219
- 1.5260149884223937
- 1.5382887601852417
- 1.497086317539215
- 1.477846622467041
- 1.4927596950531006
- 1.5014277458190919
- 1.4418789625167847
- 1.4616069602966308
- 1.4368362760543822
- 1.4578945517539978
- 1.4202705097198487
- 1.4144946694374085
- 1.397619457244873
- 1.420465669631958
- 1.387526364326477
- 1.4477781128883362
- 1.3963329362869263
- 1.3724027967453003
- 1.373408396244049
- 1.4558178973197937
- 1.4161293697357178
- 1.3674232292175292
- 1.362368471622467
- 1.4305451941490173
- 1.3388381958007813
- 1.3704923844337464
- 1.3629809641838073
- 1.3290273809432984
- 1.332653067111969
- 1.3363093066215515
- 1.3333585238456727
- 1.3191687369346619
- 1.332711899280548
- 1.3344408750534058
- 1.3026986455917358
- 1.3128883838653564
- 1.2908044505119323
- 1.3277570724487304
- 1.2969226741790771
- 1.3047687578201295
- 1.292604067325592
- 1.3019594383239745
- 1.288538842201233
- 1.3039200139045715
- 1.2836262726783751
- 1.3018375039100647
- 1.3076314806938172
- 1.2919683742523194
- 1.2938291549682617
- 1.3191430377960205
- 1.2913044238090514
- 1.2842920231819153
- 1.2653094959259032
- 1.280214307308197
- 1.2874510955810547
- 1.2889819407463075
- 1.3040826940536498
- 1.3227202773094178
- 1.2732408237457276
- 1.2704348802566527
- 1.2857020473480225
- 1.2935912346839904
- 1.2918296957015991
- 1.2707638049125671
- 1.271833200454712
- 1.2699430656433106
- 1.3055312371253966
- 1.277689688205719
- 1.2718530702590942
- 1.3138790774345397
- 1.2862921452522278
- 1.2472623014450073
- 1.2536994862556456
- 1.3245019245147704
- 1.2556439065933227
- 1.2760386323928834
- 1.2947625994682312
- 1.2588196444511413
- 1.257046067714691
- 1.2761004424095155
- 1.2730543398857117
- 1.244980812072754
- 1.251433811187744
- 1.2685332918167114
- 1.2985920882225037
- 1.2571631073951721
- 1.266477680206299
- 1.278969886302948
- 1.2715900874137878
- 1.287252721786499
- 1.2496958661079407
- 1.2971637511253358
train_accuracy:
- 0.004
- 0.074
- 0.069
- 0.072
- 0.33
- 0.165
- 0.241
- 0.567
- 0.128
- 0.141
- 0.534
- 0.172
- 0.064
- 0.343
- 0.032
- 0.12
- 0.171
- 0.567
- 0.196
- 0.088
- 0.176
- 0.172
- 0.16
- 0.015
- 0.476
- 0.237
- 0.154
- 0.534
- 0.391
- 0.298
- 0.19
- 0.446
- 0.225
- 0.418
- 0.269
- 0.05
- 0.234
- 0.41
- 0.316
- 0.242
- 0.249
- 0.192
- 0.243
- 0.217
- 0.303
- 0.125
- 0.243
- 0.2
- 0.222
- 0.351
- 0.243
- 0.199
- 0.228
- 0.225
- 0.228
- 0.206
- 0.334
- 0.189
- 0.197
- 0.218
- 0.309
- 0.284
- 0.365
- 0.234
- 0.181
- 0.186
- 0.237
- 0.301
- 0.241
- 0.04
- 0.338
- 0.261
- 0.263
- 0.221
- 0.213
- 0.13
- 0.254
- 0.194
- 0.165
- 0.263
- 0.253
- 0.544
- 0.272
- 0.162
- 0.174
- 0.229
- 0.202
- 0.224
- 0.226
- 0.297
- 0.322
- 0.251
- 0.085
- 0.347
- 0.251
- 0.225
- 0.106
- 0.288
- 0.177
- 0.336
train_loss:
- 2.769
- 2.55
- 1.816
- 1.691
- 1.626
- 2.154
- 1.574
- 1.53
- 2.019
- 1.432
- 1.441
- 1.896
- 1.389
- 1.311
- 1.825
- 1.241
- 1.706
- 0.797
- 1.654
- 1.621
- 1.208
- 1.117
- 1.579
- 0.694
- 1.071
- 1.866
- 1.105
- 0.622
- 0.988
- 1.037
- 0.965
- 0.602
- 1.321
- 0.965
- 0.901
- 1.277
- 1.217
- 0.912
- 0.876
- 1.469
- 1.427
- 1.074
- 1.117
- 1.038
- 1.088
- 0.762
- 1.333
- 1.01
- 0.981
- 0.695
- 0.942
- 0.726
- 0.936
- 0.858
- 0.623
- 0.643
- 0.639
- 0.59
- 0.594
- 0.808
- 0.75
- 0.72
- 0.563
- 0.701
- 0.502
- 0.488
- 0.739
- 0.882
- 0.655
- 0.369
- 0.478
- 0.809
- 0.773
- 0.599
- 0.409
- 0.454
- 0.71
- 0.303
- 0.396
- 0.571
- 0.555
- 0.269
- 0.617
- 0.402
- 0.368
- 0.509
- 0.377
- 0.478
- 0.337
- 0.487
- 0.449
- 0.415
- 0.348
- 0.463
- 0.513
- 0.315
- 0.329
- 0.306
- 0.408
- 0.289
unequal: 0
verbose: 1
