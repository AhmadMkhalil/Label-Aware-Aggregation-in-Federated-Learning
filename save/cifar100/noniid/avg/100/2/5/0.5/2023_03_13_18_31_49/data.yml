avg_train_accuracy: 0.301
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0136
- 0.0323
- 0.0938
- 0.1015
- 0.0918
- 0.118
- 0.1378
- 0.1504
- 0.153
- 0.1431
- 0.1633
- 0.1703
- 0.1604
- 0.1608
- 0.1567
- 0.1877
- 0.1917
- 0.1898
- 0.1516
- 0.1951
- 0.1992
- 0.2021
- 0.2086
- 0.2108
- 0.2009
- 0.2006
- 0.2045
- 0.2169
- 0.2151
- 0.2064
- 0.2219
- 0.2241
- 0.2168
- 0.2121
- 0.2173
- 0.2252
- 0.2339
- 0.2381
- 0.2024
- 0.2182
- 0.2233
- 0.2256
- 0.223
- 0.2424
- 0.2045
- 0.2158
- 0.2376
- 0.2316
- 0.228
- 0.2286
- 0.2106
- 0.2312
- 0.2342
- 0.2291
- 0.2462
- 0.2517
- 0.2524
- 0.2495
- 0.2362
- 0.2517
- 0.2402
- 0.2551
- 0.261
- 0.2166
- 0.2398
- 0.2585
- 0.2582
- 0.2549
- 0.2659
- 0.2527
- 0.2589
- 0.2469
- 0.2697
- 0.253
- 0.2153
- 0.262
- 0.2503
- 0.2622
- 0.2456
- 0.2507
- 0.2655
- 0.2544
- 0.2618
- 0.2516
- 0.2581
- 0.2781
- 0.2725
- 0.2567
- 0.2584
- 0.2771
- 0.2776
- 0.2774
- 0.2718
- 0.2783
- 0.2777
- 0.2762
- 0.2737
- 0.2822
- 0.2722
- 0.28
test_loss_list:
- 1.8710767173767089
- 1.774892373085022
- 1.6635478734970093
- 1.6297398805618286
- 1.6222465682029723
- 1.5808142948150634
- 1.5242166805267334
- 1.5189485836029053
- 1.4925835514068604
- 1.4835108423233032
- 1.4655476927757263
- 1.456714539527893
- 1.4571029615402222
- 1.4461587619781495
- 1.4656539463996887
- 1.415772383213043
- 1.3980965781211854
- 1.402805256843567
- 1.4609457540512085
- 1.3902386927604675
- 1.3758066964149476
- 1.3807425355911256
- 1.3752343201637267
- 1.3628404307365418
- 1.3681435322761535
- 1.3561927962303162
- 1.3552070832252503
- 1.337131552696228
- 1.3429508352279662
- 1.3571875405311584
- 1.3372357821464538
- 1.330754075050354
- 1.3408917331695556
- 1.3468818736076356
- 1.3283857607841492
- 1.3114118814468383
- 1.3014285111427306
- 1.2991086435317993
- 1.3582532238960265
- 1.3323693299293518
- 1.3127916741371155
- 1.3151576948165893
- 1.3226822543144225
- 1.2690527439117432
- 1.354815626144409
- 1.3257490491867066
- 1.286941909790039
- 1.2999951434135437
- 1.3165352487564086
- 1.3064516878128052
- 1.337892906665802
- 1.3013866543769836
- 1.2873638582229614
- 1.2984093928337097
- 1.262690589427948
- 1.2629908227920532
- 1.2696440505981446
- 1.2602639746665956
- 1.297264633178711
- 1.2678576350212096
- 1.304670295715332
- 1.2716401505470276
- 1.2403110265731812
- 1.3314562129974366
- 1.2821763849258423
- 1.2522612500190735
- 1.2606195735931396
- 1.2644009280204773
- 1.2352111792564393
- 1.2631278014183045
- 1.2522795629501342
- 1.2708586001396178
- 1.2319561529159546
- 1.2715218472480774
- 1.3533404850959778
- 1.2495977282524109
- 1.2820576214790345
- 1.243095142841339
- 1.283426661491394
- 1.2818963479995729
- 1.2445930933952332
- 1.2623576164245605
- 1.2501668238639831
- 1.2628572130203246
- 1.2606188988685607
- 1.2304997110366822
- 1.2436494398117066
- 1.2656464886665344
- 1.2496944904327392
- 1.2253098559379578
- 1.2219955325126648
- 1.2321105122566223
- 1.2405622982978821
- 1.2355006957054138
- 1.2227944588661195
- 1.2298342776298523
- 1.2388006472587585
- 1.221005880832672
- 1.2491325902938843
- 1.2480519604682923
train_accuracy:
- 0.014
- 0.051
- 0.107
- 0.086
- 0.079
- 0.104
- 0.143
- 0.169
- 0.023
- 0.114
- 0.152
- 0.051
- 0.082
- 0.144
- 0.126
- 0.196
- 0.092
- 0.101
- 0.121
- 0.232
- 0.208
- 0.193
- 0.192
- 0.199
- 0.163
- 0.16
- 0.155
- 0.291
- 0.19
- 0.297
- 0.128
- 0.188
- 0.402
- 0.217
- 0.028
- 0.233
- 0.249
- 0.224
- 0.117
- 0.526
- 0.202
- 0.308
- 0.531
- 0.205
- 0.431
- 0.476
- 0.364
- 0.324
- 0.413
- 0.351
- 0.276
- 0.254
- 0.205
- 0.376
- 0.246
- 0.242
- 0.216
- 0.135
- 0.561
- 0.172
- 0.392
- 0.373
- 0.266
- 0.567
- 0.202
- 0.274
- 0.229
- 0.22
- 0.145
- 0.113
- 0.307
- 0.295
- 0.156
- 0.442
- 0.185
- 0.17
- 0.239
- 0.096
- 0.441
- 0.555
- 0.222
- 0.233
- 0.24
- 0.246
- 0.242
- 0.243
- 0.147
- 0.378
- 0.083
- 0.262
- 0.252
- 0.279
- 0.229
- 0.195
- 0.312
- 0.091
- 0.444
- 0.306
- 0.362
- 0.301
train_loss:
- 2.054
- 1.894
- 3.113
- 2.286
- 1.605
- 2.131
- 2.204
- 2.54
- 2.008
- 1.445
- 1.875
- 1.892
- 1.301
- 1.266
- 1.184
- 2.226
- 1.284
- 1.613
- 0.69
- 1.543
- 1.591
- 1.485
- 1.913
- 1.436
- 1.045
- 1.012
- 1.032
- 1.316
- 1.298
- 0.988
- 1.258
- 1.2
- 0.915
- 0.886
- 0.889
- 1.238
- 1.128
- 1.11
- 0.532
- 0.719
- 0.786
- 0.75
- 0.801
- 1.123
- 0.436
- 0.726
- 0.712
- 0.776
- 0.69
- 0.644
- 0.391
- 0.677
- 0.66
- 0.662
- 0.87
- 0.891
- 0.884
- 0.628
- 0.567
- 0.769
- 0.587
- 0.797
- 0.645
- 0.33
- 0.544
- 0.731
- 0.722
- 0.486
- 0.733
- 0.53
- 0.507
- 0.477
- 0.693
- 0.463
- 0.25
- 0.619
- 0.405
- 0.497
- 0.401
- 0.461
- 0.469
- 0.398
- 0.396
- 0.439
- 0.396
- 0.696
- 0.564
- 0.402
- 0.371
- 0.485
- 0.543
- 0.483
- 0.383
- 0.479
- 0.456
- 0.418
- 0.349
- 0.558
- 0.415
- 0.483
unequal: 0
verbose: 1
