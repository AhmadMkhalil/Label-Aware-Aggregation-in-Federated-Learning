avg_train_accuracy: 0.294
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0184
- 0.0732
- 0.0623
- 0.1012
- 0.116
- 0.1308
- 0.0971
- 0.1427
- 0.1323
- 0.1239
- 0.1069
- 0.1428
- 0.1758
- 0.1831
- 0.1926
- 0.1734
- 0.198
- 0.1998
- 0.202
- 0.2077
- 0.1983
- 0.2101
- 0.2195
- 0.2178
- 0.2199
- 0.2251
- 0.2034
- 0.1716
- 0.1931
- 0.2022
- 0.2253
- 0.2198
- 0.2327
- 0.2345
- 0.2406
- 0.2319
- 0.2397
- 0.2095
- 0.2436
- 0.2291
- 0.232
- 0.2314
- 0.2458
- 0.2436
- 0.2444
- 0.2535
- 0.2539
- 0.2161
- 0.2487
- 0.2374
- 0.2556
- 0.2507
- 0.2545
- 0.2408
- 0.2384
- 0.2648
- 0.2569
- 0.26
- 0.2654
- 0.2538
- 0.2647
- 0.2654
- 0.2602
- 0.2671
- 0.2527
- 0.2617
- 0.2651
- 0.2691
- 0.2668
- 0.2485
- 0.2683
- 0.2702
- 0.2571
- 0.2576
- 0.2575
- 0.2706
- 0.2729
- 0.2748
- 0.2749
- 0.2615
- 0.2716
- 0.2614
- 0.242
- 0.2699
- 0.271
- 0.2609
- 0.2307
- 0.2469
- 0.2732
- 0.2696
- 0.2745
- 0.2729
- 0.2693
- 0.2589
- 0.2731
- 0.2752
- 0.2745
- 0.2773
- 0.2766
- 0.2524
test_loss_list:
- 1.8475770664215088
- 1.71057186126709
- 1.6975748443603516
- 1.6334023118019103
- 1.6050937247276307
- 1.5614540338516236
- 1.6003428316116333
- 1.5325024700164795
- 1.524574911594391
- 1.5342421340942383
- 1.5488109517097473
- 1.4974758648872375
- 1.4485491824150085
- 1.4444179821014405
- 1.4417320728302
- 1.4465785098075867
- 1.3845124053955078
- 1.3889387369155883
- 1.388463068008423
- 1.3782946252822876
- 1.3754380464553833
- 1.369649589061737
- 1.355208146572113
- 1.3498196983337403
- 1.3472739815711976
- 1.319971125125885
- 1.3527124953269958
- 1.4165299463272094
- 1.3655915403366088
- 1.3458306527137756
- 1.3139396023750305
- 1.3219051384925842
- 1.2970815420150756
- 1.3033646750450134
- 1.2837990880012513
- 1.2921206593513488
- 1.2818752479553224
- 1.3277859807014465
- 1.2691137409210205
- 1.3010830068588257
- 1.2885768151283263
- 1.287094075679779
- 1.269227056503296
- 1.2794553542137146
- 1.266622712612152
- 1.2471978163719177
- 1.2637706589698792
- 1.3160074710845948
- 1.265505657196045
- 1.2946677207946777
- 1.247326259613037
- 1.260199019908905
- 1.244820294380188
- 1.2741176056861878
- 1.2872615909576417
- 1.2491578888893127
- 1.259343502521515
- 1.2571263480186463
- 1.2362672066688538
- 1.262806363105774
- 1.2422607636451721
- 1.2500982785224914
- 1.2531888484954834
- 1.2457391500473023
- 1.2566092252731322
- 1.245951416492462
- 1.2458137011528014
- 1.2484532523155212
- 1.238627574443817
- 1.280837197303772
- 1.2452677011489868
- 1.2316596055030822
- 1.2629874277114868
- 1.2586933755874634
- 1.2512492203712464
- 1.222901861667633
- 1.2328902745246888
- 1.2343096470832824
- 1.2253024363517762
- 1.2478021097183227
- 1.219939525127411
- 1.2528781652450562
- 1.3017165398597716
- 1.2273131155967711
- 1.22909024477005
- 1.262926037311554
- 1.3185441875457764
- 1.2740514636039735
- 1.2282090950012208
- 1.2348591876029968
- 1.2119759821891785
- 1.2284218668937683
- 1.266178970336914
- 1.2610771250724793
- 1.2363798093795777
- 1.2315176796913148
- 1.23876211643219
- 1.2418142080307006
- 1.235546567440033
- 1.266494140625
train_accuracy:
- 0.018
- 0.094
- 0.181
- 0.116
- 0.118
- 0.146
- 0.058
- 0.136
- 0.123
- 0.319
- 0.091
- 0.401
- 0.035
- 0.189
- 0.19
- 0.241
- 0.04
- 0.212
- 0.211
- 0.235
- 0.539
- 0.206
- 0.216
- 0.261
- 0.254
- 0.014
- 0.443
- 0.213
- 0.199
- 0.196
- 0.295
- 0.245
- 0.312
- 0.219
- 0.08
- 0.298
- 0.167
- 0.439
- 0.287
- 0.366
- 0.243
- 0.201
- 0.233
- 0.289
- 0.351
- 0.158
- 0.241
- 0.149
- 0.278
- 0.508
- 0.321
- 0.296
- 0.297
- 0.219
- 0.257
- 0.262
- 0.255
- 0.149
- 0.322
- 0.285
- 0.263
- 0.167
- 0.249
- 0.312
- 0.453
- 0.286
- 0.314
- 0.256
- 0.054
- 0.258
- 0.281
- 0.248
- 0.219
- 0.136
- 0.595
- 0.337
- 0.214
- 0.065
- 0.311
- 0.378
- 0.334
- 0.299
- 0.497
- 0.308
- 0.335
- 0.226
- 0.289
- 0.332
- 0.272
- 0.129
- 0.286
- 0.295
- 0.337
- 0.272
- 0.276
- 0.267
- 0.323
- 0.36
- 0.333
- 0.294
train_loss:
- 2.782
- 2.572
- 1.74
- 2.286
- 2.187
- 2.148
- 0.934
- 2.015
- 1.45
- 1.377
- 0.852
- 1.301
- 2.405
- 2.32
- 2.217
- 1.234
- 1.735
- 1.657
- 1.591
- 1.527
- 1.124
- 1.45
- 1.479
- 1.505
- 1.407
- 1.415
- 0.629
- 0.564
- 0.932
- 0.898
- 1.314
- 0.94
- 1.217
- 1.24
- 1.219
- 0.812
- 1.178
- 0.49
- 1.141
- 0.792
- 0.775
- 0.772
- 1.062
- 1.007
- 0.746
- 1.004
- 0.955
- 0.454
- 0.922
- 0.682
- 0.911
- 0.886
- 0.644
- 0.583
- 0.608
- 1.079
- 0.775
- 0.784
- 0.797
- 0.554
- 0.753
- 0.767
- 0.727
- 0.552
- 0.507
- 0.701
- 0.846
- 0.635
- 0.527
- 0.475
- 0.752
- 0.482
- 0.454
- 0.431
- 0.424
- 0.75
- 0.546
- 0.695
- 0.421
- 0.366
- 0.52
- 0.394
- 0.247
- 0.498
- 0.347
- 0.35
- 0.235
- 0.362
- 0.474
- 0.355
- 0.462
- 0.529
- 0.315
- 0.303
- 0.405
- 0.406
- 0.414
- 0.379
- 0.483
- 0.229
unequal: 0
verbose: 1
