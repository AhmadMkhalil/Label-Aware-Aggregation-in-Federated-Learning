avg_train_accuracy: 0.218
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0297
- 0.0458
- 0.0826
- 0.1015
- 0.1143
- 0.1267
- 0.1176
- 0.1184
- 0.1277
- 0.1314
- 0.1531
- 0.1207
- 0.1383
- 0.1181
- 0.1799
- 0.1819
- 0.166
- 0.187
- 0.1763
- 0.178
- 0.1941
- 0.2025
- 0.2082
- 0.2018
- 0.1668
- 0.214
- 0.2186
- 0.2067
- 0.2223
- 0.2151
- 0.2295
- 0.2294
- 0.2045
- 0.2308
- 0.2342
- 0.2347
- 0.2205
- 0.2353
- 0.2419
- 0.2431
- 0.2467
- 0.2406
- 0.1999
- 0.2388
- 0.2301
- 0.2522
- 0.2496
- 0.2541
- 0.2554
- 0.2515
- 0.2578
- 0.2568
- 0.2537
- 0.2494
- 0.2616
- 0.2195
- 0.2402
- 0.2629
- 0.253
- 0.25
- 0.2607
- 0.2565
- 0.2305
- 0.266
- 0.253
- 0.2466
- 0.2526
- 0.2675
- 0.2682
- 0.2748
- 0.2695
- 0.2726
- 0.2744
- 0.2538
- 0.272
- 0.2636
- 0.2531
- 0.2248
- 0.2566
- 0.2749
- 0.2564
- 0.2645
- 0.2321
- 0.2707
- 0.2342
- 0.2621
- 0.2741
- 0.2745
- 0.2772
- 0.2789
- 0.2806
- 0.2829
- 0.2738
- 0.2766
- 0.2766
- 0.2841
- 0.2654
- 0.265
- 0.2779
- 0.2722
test_loss_list:
- 1.8275157690048218
- 1.7410804653167724
- 1.668147358894348
- 1.6267791318893432
- 1.5857661390304565
- 1.548280920982361
- 1.5468141412734986
- 1.5364848256111145
- 1.5171982526779175
- 1.503140697479248
- 1.4724329447746276
- 1.5255855751037597
- 1.4948849177360535
- 1.5282420587539673
- 1.4370094394683839
- 1.418285789489746
- 1.446502776145935
- 1.410756115913391
- 1.4237859535217285
- 1.4172801184654236
- 1.3802493691444397
- 1.377797441482544
- 1.3767699933052062
- 1.3778182244300843
- 1.415701506137848
- 1.3492401981353759
- 1.3464408063888549
- 1.3732497930526733
- 1.3400976085662841
- 1.3437700963020325
- 1.3223020577430724
- 1.3192664313316345
- 1.3534277296066284
- 1.3075769901275636
- 1.3113857078552247
- 1.3053689074516297
- 1.316062226295471
- 1.3029871940612794
- 1.3014191269874573
- 1.293546278476715
- 1.2990997624397278
- 1.283569734096527
- 1.3664192318916322
- 1.2928359842300414
- 1.305106933116913
- 1.2853388428688048
- 1.2924354219436645
- 1.276735668182373
- 1.2881689596176147
- 1.2810202193260194
- 1.2529962491989135
- 1.2640542960166932
- 1.2654103207588197
- 1.2619530534744263
- 1.2463438200950623
- 1.3345486330986023
- 1.2781798791885377
- 1.2430127000808715
- 1.2684983587265015
- 1.2794811844825744
- 1.2571649312973023
- 1.2602356457710266
- 1.3131141448020935
- 1.2399778985977172
- 1.2679636597633361
- 1.2864690732955932
- 1.2647075128555298
- 1.2344616770744323
- 1.2435956931114196
- 1.2409241318702697
- 1.2469311475753784
- 1.2327105689048767
- 1.2401002073287963
- 1.2745962452888489
- 1.242716085910797
- 1.260618233680725
- 1.2764346742630004
- 1.3340757822990417
- 1.264028799533844
- 1.234405996799469
- 1.278915934562683
- 1.252771680355072
- 1.3302600193023681
- 1.2350507688522339
- 1.325361487865448
- 1.261311068534851
- 1.2373744559288025
- 1.2304825282096863
- 1.2388884782791139
- 1.2315265727043152
- 1.244478361606598
- 1.2457271575927735
- 1.2331294655799865
- 1.2349400424957275
- 1.2567598605155945
- 1.2268178033828736
- 1.273551743030548
- 1.2542721581459046
- 1.2373278307914735
- 1.2670350885391235
train_accuracy:
- 0.019
- 0.002
- 0.013
- 0.281
- 0.007
- 0.122
- 0.096
- 0.449
- 0.042
- 0.275
- 0.151
- 0.045
- 0.095
- 0.008
- 0.214
- 0.234
- 0.361
- 0.346
- 0.15
- 0.547
- 0.326
- 0.191
- 0.165
- 0.2
- 0.413
- 0.185
- 0.225
- 0.475
- 0.214
- 0.275
- 0.134
- 0.209
- 0.472
- 0.197
- 0.255
- 0.259
- 0.37
- 0.202
- 0.27
- 0.222
- 0.273
- 0.043
- 0.192
- 0.194
- 0.095
- 0.275
- 0.22
- 0.245
- 0.252
- 0.275
- 0.272
- 0.165
- 0.197
- 0.258
- 0.276
- 0.284
- 0.414
- 0.192
- 0.196
- 0.352
- 0.292
- 0.451
- 0.467
- 0.226
- 0.221
- 0.402
- 0.297
- 0.15
- 0.307
- 0.225
- 0.098
- 0.277
- 0.097
- 0.472
- 0.26
- 0.251
- 0.304
- 0.414
- 0.422
- 0.275
- 0.243
- 0.22
- 0.274
- 0.229
- 0.449
- 0.242
- 0.235
- 0.129
- 0.24
- 0.126
- 0.283
- 0.179
- 0.257
- 0.245
- 0.154
- 0.13
- 0.3
- 0.338
- 0.299
- 0.218
train_loss:
- 2.762
- 1.871
- 2.41
- 2.33
- 2.226
- 2.145
- 1.51
- 1.429
- 1.493
- 1.41
- 1.908
- 0.831
- 1.302
- 0.757
- 2.311
- 1.317
- 1.22
- 1.644
- 1.152
- 1.122
- 1.555
- 1.589
- 1.505
- 1.099
- 0.675
- 1.449
- 1.382
- 0.996
- 1.781
- 0.984
- 1.334
- 1.274
- 0.593
- 1.248
- 1.223
- 1.196
- 0.834
- 1.114
- 1.495
- 1.069
- 1.36
- 0.8
- 0.462
- 0.974
- 0.744
- 1.248
- 0.911
- 1.004
- 1.156
- 0.923
- 0.949
- 0.858
- 0.645
- 0.59
- 0.833
- 0.354
- 0.578
- 0.803
- 0.564
- 0.56
- 0.704
- 0.521
- 0.332
- 0.736
- 0.498
- 0.509
- 0.546
- 0.674
- 0.838
- 0.637
- 0.578
- 0.636
- 0.744
- 0.288
- 0.573
- 0.426
- 0.414
- 0.271
- 0.413
- 0.648
- 0.295
- 0.371
- 0.248
- 0.515
- 0.243
- 0.379
- 0.483
- 0.494
- 0.456
- 0.464
- 0.539
- 0.433
- 0.366
- 0.516
- 0.406
- 0.426
- 0.286
- 0.307
- 0.367
- 0.259
unequal: 0
verbose: 1
