avg_train_accuracy: 0.257
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0266
- 0.0582
- 0.0645
- 0.1114
- 0.1095
- 0.1194
- 0.1116
- 0.1102
- 0.1205
- 0.1438
- 0.1577
- 0.166
- 0.1741
- 0.1662
- 0.1641
- 0.1646
- 0.1827
- 0.1882
- 0.1855
- 0.1974
- 0.1915
- 0.2002
- 0.1968
- 0.1931
- 0.2121
- 0.1758
- 0.187
- 0.2109
- 0.2218
- 0.2174
- 0.179
- 0.2048
- 0.1964
- 0.1906
- 0.2061
- 0.1724
- 0.2326
- 0.2335
- 0.233
- 0.2328
- 0.2148
- 0.2198
- 0.2255
- 0.2176
- 0.2231
- 0.2248
- 0.2196
- 0.2239
- 0.2278
- 0.2341
- 0.2285
- 0.2415
- 0.2409
- 0.2392
- 0.2099
- 0.2243
- 0.2259
- 0.2492
- 0.2395
- 0.2507
- 0.2532
- 0.2455
- 0.2548
- 0.2456
- 0.2526
- 0.2565
- 0.2594
- 0.2569
- 0.2591
- 0.264
- 0.2588
- 0.2302
- 0.2374
- 0.2601
- 0.2212
- 0.2608
- 0.2619
- 0.2565
- 0.2442
- 0.2583
- 0.2616
- 0.2551
- 0.2639
- 0.253
- 0.2279
- 0.2629
- 0.2468
- 0.2715
- 0.2455
- 0.2148
- 0.2667
- 0.2556
- 0.2421
- 0.2707
- 0.2651
- 0.2669
- 0.2654
- 0.26
- 0.2568
- 0.2662
test_loss_list:
- 1.8351104021072389
- 1.7283180809020997
- 1.7014351034164428
- 1.625749011039734
- 1.5966593074798583
- 1.567278561592102
- 1.5568312740325927
- 1.5505956768989564
- 1.5350845313072206
- 1.5118750047683716
- 1.4848241591453553
- 1.4759852600097656
- 1.4486250591278076
- 1.459125099182129
- 1.4511390328407288
- 1.4525252294540405
- 1.4240154576301576
- 1.4082236766815186
- 1.3986413431167604
- 1.387860369682312
- 1.392816083431244
- 1.3714166808128356
- 1.3789482522010803
- 1.382108097076416
- 1.3513787198066711
- 1.4169182252883912
- 1.39347847700119
- 1.3480799078941346
- 1.3392984247207642
- 1.3442519974708558
- 1.3965656638145447
- 1.3585205149650574
- 1.3676774859428407
- 1.3807438397407532
- 1.3511842250823975
- 1.4072962164878846
- 1.3154224205017089
- 1.3169176864624024
- 1.3191388583183288
- 1.3039952969551087
- 1.3367863631248473
- 1.3186342430114746
- 1.3171238136291503
- 1.325635483264923
- 1.3194266939163208
- 1.315611617565155
- 1.3280742454528809
- 1.3251351165771483
- 1.3155685806274413
- 1.296161551475525
- 1.3033357858657837
- 1.2879146099090577
- 1.2826083660125733
- 1.2876676273345948
- 1.3464331865310668
- 1.3157899045944215
- 1.3140833163261414
- 1.2732249236106872
- 1.281236741542816
- 1.2728965997695922
- 1.2628674411773682
- 1.297098822593689
- 1.269685025215149
- 1.2993449473381042
- 1.2754578614234924
- 1.2593312788009643
- 1.2556333351135254
- 1.261724603176117
- 1.2799979496002196
- 1.2434844017028808
- 1.250757462978363
- 1.3135025930404662
- 1.2992575693130493
- 1.2489800190925597
- 1.3435220742225646
- 1.2573904514312744
- 1.242059621810913
- 1.2637840270996095
- 1.289262170791626
- 1.2551638078689575
- 1.2521199560165406
- 1.2678464674949645
- 1.256223976612091
- 1.2737782669067383
- 1.3389336371421814
- 1.2535742115974426
- 1.2825297331809997
- 1.249313187599182
- 1.2923889327049256
- 1.3716214632987975
- 1.2526238536834717
- 1.282599241733551
- 1.3108206605911255
- 1.2424660062789916
- 1.261466362476349
- 1.2431454920768739
- 1.246795208454132
- 1.2643520474433898
- 1.2653300833702088
- 1.2457331252098083
train_accuracy:
- 0.127
- 0.194
- 0.041
- 0.103
- 0.139
- 0.127
- 0.261
- 0.417
- 0.05
- 0.151
- 0.146
- 0.181
- 0.088
- 0.16
- 0.148
- 0.276
- 0.18
- 0.187
- 0.191
- 0.107
- 0.211
- 0.232
- 0.15
- 0.169
- 0.296
- 0.234
- 0.152
- 0.24
- 0.206
- 0.276
- 0.085
- 0.189
- 0.188
- 0.177
- 0.126
- 0.375
- 0.249
- 0.294
- 0.257
- 0.225
- 0.275
- 0.392
- 0.216
- 0.298
- 0.356
- 0.218
- 0.183
- 0.528
- 0.234
- 0.212
- 0.108
- 0.262
- 0.288
- 0.247
- 0.532
- 0.198
- 0.426
- 0.332
- 0.261
- 0.274
- 0.256
- 0.127
- 0.071
- 0.237
- 0.246
- 0.259
- 0.251
- 0.247
- 0.322
- 0.206
- 0.257
- 0.229
- 0.229
- 0.269
- 0.515
- 0.31
- 0.251
- 0.098
- 0.236
- 0.37
- 0.043
- 0.323
- 0.292
- 0.362
- 0.31
- 0.281
- 0.277
- 0.316
- 0.106
- 0.188
- 0.272
- 0.249
- 0.224
- 0.142
- 0.293
- 0.324
- 0.083
- 0.075
- 0.317
- 0.257
train_loss:
- 2.778
- 1.914
- 1.725
- 2.997
- 1.633
- 2.144
- 1.518
- 1.456
- 1.434
- 1.907
- 1.955
- 2.361
- 1.852
- 1.266
- 1.272
- 1.202
- 1.641
- 1.678
- 1.183
- 2.019
- 0.722
- 1.486
- 1.063
- 1.098
- 1.452
- 0.619
- 0.981
- 1.368
- 1.349
- 1.34
- 0.554
- 0.91
- 0.858
- 0.827
- 0.884
- 0.495
- 1.512
- 1.187
- 1.146
- 1.094
- 0.517
- 0.799
- 0.723
- 0.761
- 0.729
- 0.679
- 0.729
- 0.724
- 0.656
- 0.712
- 0.709
- 0.885
- 0.716
- 0.664
- 0.362
- 0.576
- 0.588
- 0.866
- 0.614
- 0.877
- 0.841
- 0.558
- 0.801
- 0.535
- 0.762
- 0.779
- 0.722
- 0.722
- 0.881
- 0.576
- 0.685
- 0.314
- 0.436
- 0.642
- 0.272
- 0.639
- 0.475
- 0.466
- 0.395
- 0.464
- 0.545
- 0.403
- 0.548
- 0.437
- 0.23
- 0.494
- 0.434
- 0.655
- 0.248
- 0.228
- 0.603
- 0.35
- 0.32
- 0.615
- 0.436
- 0.488
- 0.324
- 0.302
- 0.298
- 0.435
unequal: 0
verbose: 1
