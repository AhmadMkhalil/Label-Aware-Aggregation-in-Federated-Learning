avg_train_accuracy: 0.299
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0371
- 0.0547
- 0.0613
- 0.096
- 0.0828
- 0.0964
- 0.0975
- 0.1311
- 0.144
- 0.1535
- 0.1574
- 0.1659
- 0.1757
- 0.179
- 0.17
- 0.1923
- 0.1674
- 0.1755
- 0.1793
- 0.1983
- 0.1947
- 0.1952
- 0.1589
- 0.1394
- 0.1743
- 0.1817
- 0.2008
- 0.1613
- 0.2191
- 0.2169
- 0.2152
- 0.2131
- 0.2248
- 0.2231
- 0.2053
- 0.2086
- 0.2326
- 0.2268
- 0.2316
- 0.2331
- 0.2146
- 0.2417
- 0.2285
- 0.2212
- 0.2302
- 0.2467
- 0.215
- 0.2295
- 0.2434
- 0.2429
- 0.2491
- 0.2303
- 0.2524
- 0.2379
- 0.2412
- 0.2537
- 0.2193
- 0.2498
- 0.2433
- 0.207
- 0.2536
- 0.2424
- 0.2487
- 0.2457
- 0.2607
- 0.2558
- 0.2547
- 0.1832
- 0.2515
- 0.251
- 0.2262
- 0.2387
- 0.2513
- 0.2491
- 0.2677
- 0.2563
- 0.261
- 0.2364
- 0.2493
- 0.2496
- 0.215
- 0.2688
- 0.2636
- 0.2642
- 0.2641
- 0.2617
- 0.2665
- 0.2659
- 0.2744
- 0.2461
- 0.2564
- 0.2718
- 0.2526
- 0.2732
- 0.2726
- 0.2748
- 0.2755
- 0.2779
- 0.2746
- 0.2551
test_loss_list:
- 1.8099547243118286
- 1.7314392995834351
- 1.6715960168838502
- 1.6265736317634583
- 1.6241153049468995
- 1.5776427674293518
- 1.5870759892463684
- 1.5290554118156434
- 1.50057471036911
- 1.485997862815857
- 1.4867589592933654
- 1.4766590929031371
- 1.4533952808380126
- 1.4550679540634155
- 1.4434467959403992
- 1.4247105836868286
- 1.4463163924217224
- 1.4074040365219116
- 1.4070312261581421
- 1.3813008236885072
- 1.3834058594703675
- 1.378920979499817
- 1.441997663974762
- 1.482941267490387
- 1.4069439625740052
- 1.398932821750641
- 1.3583472275733948
- 1.45000586271286
- 1.3406012773513794
- 1.3358006048202515
- 1.3380156874656677
- 1.3350387144088744
- 1.3215879487991333
- 1.326738142967224
- 1.3547421026229858
- 1.3429907393455505
- 1.3013881635665894
- 1.3182509016990662
- 1.3070074653625487
- 1.3055858278274537
- 1.3306112408638
- 1.2922318959236145
- 1.301393711566925
- 1.3239462518692016
- 1.3118484926223755
- 1.2774351477622985
- 1.3473151159286498
- 1.3191966247558593
- 1.276290581226349
- 1.2791419959068298
- 1.2784078860282897
- 1.3176350593566895
- 1.2624088263511657
- 1.2913698387145995
- 1.2924589347839355
- 1.2649677085876465
- 1.3372044491767883
- 1.2587807917594909
- 1.284691710472107
- 1.3606520438194274
- 1.2661808919906616
- 1.2846418261528014
- 1.2769539999961852
- 1.2828115272521972
- 1.2507357382774353
- 1.2703476691246032
- 1.2706164455413818
- 1.4385372877120972
- 1.25661075592041
- 1.2705857968330383
- 1.3359529972076416
- 1.2950007343292236
- 1.2736915349960327
- 1.2711023664474488
- 1.2439401245117188
- 1.2656578779220582
- 1.2575672817230226
- 1.3130446577072143
- 1.280240650177002
- 1.2748676252365112
- 1.372423391342163
- 1.2468580746650695
- 1.2615658593177796
- 1.267047049999237
- 1.2686398124694824
- 1.2678298211097718
- 1.2631090235710145
- 1.2697815203666687
- 1.2406738376617432
- 1.304960219860077
- 1.2741616249084473
- 1.2377358603477477
- 1.29179541349411
- 1.2440936136245728
- 1.238942642211914
- 1.234526402950287
- 1.2605933046340942
- 1.2444101285934448
- 1.2467691588401795
- 1.295565197467804
train_accuracy:
- 0.034
- 0.002
- 0.001
- 0.212
- 0.013
- 0.019
- 0.469
- 0.126
- 0.146
- 0.166
- 0.164
- 0.185
- 0.022
- 0.202
- 0.096
- 0.061
- 0.118
- 0.384
- 0.179
- 0.216
- 0.21
- 0.19
- 0.367
- 0.115
- 0.169
- 0.244
- 0.205
- 0.34
- 0.245
- 0.247
- 0.342
- 0.04
- 0.254
- 0.053
- 0.313
- 0.434
- 0.265
- 0.16
- 0.251
- 0.263
- 0.21
- 0.253
- 0.331
- 0.225
- 0.247
- 0.284
- 0.21
- 0.15
- 0.146
- 0.229
- 0.286
- 0.217
- 0.274
- 0.218
- 0.24
- 0.109
- 0.13
- 0.283
- 0.093
- 0.212
- 0.221
- 0.185
- 0.324
- 0.225
- 0.206
- 0.054
- 0.223
- 0.107
- 0.306
- 0.228
- 0.455
- 0.245
- 0.368
- 0.241
- 0.291
- 0.267
- 0.207
- 0.12
- 0.322
- 0.254
- 0.216
- 0.292
- 0.128
- 0.107
- 0.253
- 0.266
- 0.277
- 0.058
- 0.299
- 0.129
- 0.243
- 0.284
- 0.234
- 0.282
- 0.296
- 0.249
- 0.251
- 0.218
- 0.264
- 0.299
train_loss:
- 3.516
- 1.797
- 1.843
- 2.327
- 1.607
- 1.633
- 1.511
- 2.103
- 2.054
- 1.983
- 1.894
- 2.33
- 1.816
- 1.79
- 1.231
- 2.136
- 0.774
- 1.221
- 1.09
- 1.581
- 1.152
- 1.1
- 0.706
- 0.609
- 0.962
- 0.991
- 1.032
- 0.628
- 1.833
- 1.043
- 1.013
- 1.324
- 1.337
- 1.242
- 0.587
- 0.889
- 1.211
- 0.853
- 1.148
- 1.093
- 0.481
- 1.099
- 0.803
- 0.708
- 0.788
- 1.145
- 0.435
- 0.675
- 1.079
- 0.762
- 1.228
- 0.441
- 0.942
- 0.635
- 0.715
- 0.878
- 0.397
- 0.896
- 0.628
- 0.34
- 0.836
- 0.587
- 0.598
- 0.527
- 0.801
- 0.577
- 0.544
- 0.132
- 0.721
- 0.515
- 0.323
- 0.496
- 0.552
- 0.514
- 0.684
- 0.483
- 0.615
- 0.285
- 0.486
- 0.445
- 0.26
- 0.785
- 0.559
- 0.584
- 0.54
- 0.399
- 0.522
- 0.57
- 0.533
- 0.229
- 0.352
- 0.531
- 0.329
- 0.476
- 0.485
- 0.376
- 0.703
- 0.268
- 0.408
- 0.228
unequal: 0
verbose: 1
