avg_train_accuracy: 0.264
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0122
- 0.018
- 0.027
- 0.1103
- 0.0865
- 0.0828
- 0.0595
- 0.0908
- 0.1269
- 0.091
- 0.0525
- 0.0971
- 0.0845
- 0.0499
- 0.1449
- 0.0997
- 0.0902
- 0.1397
- 0.1048
- 0.1182
- 0.1622
- 0.112
- 0.1143
- 0.2038
- 0.1408
- 0.1275
- 0.084
- 0.1325
- 0.2071
- 0.147
- 0.1871
- 0.1468
- 0.1469
- 0.1994
- 0.1356
- 0.1548
- 0.2037
- 0.1837
- 0.1519
- 0.1457
- 0.2105
- 0.2357
- 0.2113
- 0.1768
- 0.2168
- 0.2179
- 0.2414
- 0.1601
- 0.1691
- 0.2187
- 0.1263
- 0.147
- 0.2106
- 0.1757
- 0.1703
- 0.1514
- 0.1545
- 0.2192
- 0.2201
- 0.1821
- 0.1809
- 0.1157
- 0.2291
- 0.224
- 0.1792
- 0.2396
- 0.2391
- 0.2067
- 0.1409
- 0.1578
- 0.2627
- 0.1957
- 0.1908
- 0.1942
- 0.1815
- 0.1851
- 0.2489
- 0.2026
- 0.2447
- 0.2355
- 0.2055
- 0.1724
- 0.2424
- 0.198
- 0.132
- 0.2268
- 0.2566
- 0.1485
- 0.1778
- 0.1845
- 0.1889
- 0.2447
- 0.2031
- 0.2028
- 0.2755
- 0.2754
- 0.2606
- 0.2532
- 0.2258
- 0.2515
test_loss_list:
- 1.8488795804977416
- 1.8225257778167725
- 1.857128791809082
- 1.6452675151824951
- 1.6580614924430848
- 1.6236007261276244
- 1.6517244219779967
- 1.5810732293128966
- 1.5280716872215272
- 1.6142372131347655
- 1.789406590461731
- 1.5221211767196656
- 1.6084865069389342
- 1.9262829160690307
- 1.477991087436676
- 1.5770120358467101
- 1.6233454895019532
- 1.4844878101348877
- 1.5910315275192262
- 1.5198122477531433
- 1.4272071838378906
- 1.546387276649475
- 1.5349683356285095
- 1.4039507389068604
- 1.4930644297599793
- 1.5167139554023743
- 1.6871201658248902
- 1.493685350418091
- 1.3746110963821412
- 1.496524097919464
- 1.3912723898887633
- 1.5008883166313172
- 1.480524091720581
- 1.3690777492523194
- 1.5348485803604126
- 1.4556026196479797
- 1.3697050666809083
- 1.3888701939582824
- 1.479089503288269
- 1.4612699127197266
- 1.3467490267753601
- 1.3359177541732787
- 1.3673707675933837
- 1.429596838951111
- 1.365602741241455
- 1.3722860503196717
- 1.3408625435829162
- 1.4799603700637818
- 1.43415048122406
- 1.3351773881912232
- 1.549544529914856
- 1.4753465747833252
- 1.333536536693573
- 1.4112764406204223
- 1.4420079827308654
- 1.4995145273208619
- 1.510282428264618
- 1.3620497941970826
- 1.3628555393218995
- 1.4079862928390503
- 1.427022454738617
- 1.6129746890068055
- 1.305165367126465
- 1.3351670169830323
- 1.4621346831321715
- 1.3107743120193482
- 1.3070562958717347
- 1.3918293738365173
- 1.5236350464820863
- 1.4781457233428954
- 1.2685495710372925
- 1.4337352633476257
- 1.389300398826599
- 1.4036745309829712
- 1.4507500076293944
- 1.4008151912689208
- 1.2843056559562682
- 1.416272189617157
- 1.2803444957733154
- 1.3328471326828002
- 1.3492238378524781
- 1.4479104948043824
- 1.299407298564911
- 1.3853529810905456
- 1.645546591281891
- 1.3540967512130737
- 1.2687123227119446
- 1.5409387922286988
- 1.4496181964874268
- 1.4239001989364624
- 1.4027853155136107
- 1.2772836709022521
- 1.3652739357948303
- 1.3871869158744812
- 1.2557919597625733
- 1.2783756351470947
- 1.30426602602005
- 1.301056787967682
- 1.3384891605377198
- 1.2979435586929322
train_accuracy:
- 0.0
- 0.001
- 0.361
- 0.11
- 0.05
- 0.055
- 0.77
- 0.089
- 0.13
- 0.547
- 0.265
- 0.06
- 0.053
- 0.558
- 0.755
- 0.077
- 0.578
- 0.139
- 0.483
- 0.794
- 0.148
- 0.679
- 0.428
- 0.234
- 0.532
- 0.092
- 0.556
- 0.805
- 0.21
- 0.123
- 0.141
- 0.616
- 0.601
- 0.666
- 0.598
- 0.136
- 0.193
- 0.161
- 0.121
- 0.128
- 0.221
- 0.265
- 0.202
- 0.105
- 0.444
- 0.22
- 0.21
- 0.406
- 0.598
- 0.682
- 0.49
- 0.463
- 0.2
- 0.677
- 0.738
- 0.663
- 0.12
- 0.53
- 0.21
- 0.147
- 0.586
- 0.579
- 0.669
- 0.224
- 0.645
- 0.247
- 0.244
- 0.523
- 0.261
- 0.691
- 0.294
- 0.573
- 0.706
- 0.543
- 0.615
- 0.608
- 0.216
- 0.422
- 0.584
- 0.533
- 0.685
- 0.73
- 0.27
- 0.447
- 0.201
- 0.212
- 0.259
- 0.397
- 0.708
- 0.136
- 0.142
- 0.212
- 0.55
- 0.569
- 0.293
- 0.301
- 0.279
- 0.259
- 0.748
- 0.264
train_loss:
- 3.02
- 1.699
- 1.548
- 3.714
- 2.42
- 1.603
- 1.404
- 2.295
- 2.213
- 1.237
- 0.428
- 2.189
- 1.144
- 0.209
- 1.993
- 1.187
- 1.021
- 1.822
- 0.972
- 1.241
- 1.979
- 0.948
- 0.929
- 2.615
- 0.966
- 0.849
- 0.324
- 0.983
- 2.267
- 0.792
- 1.607
- 0.914
- 0.781
- 1.559
- 0.709
- 0.846
- 1.314
- 0.923
- 0.702
- 0.85
- 1.289
- 1.888
- 1.366
- 0.82
- 1.145
- 1.146
- 1.698
- 0.335
- 0.656
- 1.145
- 0.202
- 0.552
- 1.188
- 0.587
- 0.575
- 0.469
- 0.53
- 0.9
- 0.988
- 0.621
- 0.507
- 0.205
- 1.031
- 0.968
- 0.431
- 0.852
- 0.841
- 0.436
- 0.228
- 0.573
- 1.259
- 0.459
- 0.533
- 0.477
- 0.43
- 0.419
- 0.712
- 0.493
- 0.744
- 0.647
- 0.495
- 0.37
- 0.602
- 0.34
- 0.096
- 0.666
- 0.725
- 0.162
- 0.294
- 0.329
- 0.374
- 0.545
- 0.321
- 0.454
- 0.893
- 0.759
- 0.579
- 0.651
- 0.298
- 0.545
unequal: 0
verbose: 1
