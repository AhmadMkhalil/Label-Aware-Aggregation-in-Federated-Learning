avg_train_accuracy: 0.196
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0186
- 0.0226
- 0.0233
- 0.0335
- 0.0316
- 0.1197
- 0.072
- 0.0951
- 0.061
- 0.1081
- 0.1341
- 0.1266
- 0.1096
- 0.0915
- 0.1763
- 0.1448
- 0.1594
- 0.0597
- 0.1113
- 0.1674
- 0.159
- 0.1375
- 0.1987
- 0.145
- 0.1308
- 0.0704
- 0.1041
- 0.123
- 0.0751
- 0.1821
- 0.1815
- 0.2154
- 0.1885
- 0.2014
- 0.1944
- 0.2252
- 0.1705
- 0.1716
- 0.2027
- 0.2314
- 0.2228
- 0.164
- 0.2236
- 0.1664
- 0.2111
- 0.1903
- 0.2086
- 0.168
- 0.2075
- 0.1815
- 0.2219
- 0.2208
- 0.1277
- 0.1461
- 0.2425
- 0.2224
- 0.1866
- 0.2317
- 0.1836
- 0.2326
- 0.2335
- 0.1928
- 0.1711
- 0.2256
- 0.2298
- 0.2038
- 0.1871
- 0.262
- 0.2103
- 0.1756
- 0.2046
- 0.1787
- 0.1893
- 0.1731
- 0.241
- 0.2389
- 0.2426
- 0.2428
- 0.2466
- 0.2228
- 0.1849
- 0.1809
- 0.1999
- 0.2415
- 0.2067
- 0.1893
- 0.1861
- 0.1822
- 0.224
- 0.1871
- 0.243
- 0.2071
- 0.2439
- 0.249
- 0.2512
- 0.1884
- 0.2479
- 0.2395
- 0.2481
- 0.2138
test_loss_list:
- 1.9297639560699462
- 1.7904785013198852
- 1.924909405708313
- 1.714263343811035
- 1.780576229095459
- 1.6232196497917175
- 1.6763656282424926
- 1.600638873577118
- 1.6614052414894105
- 1.5805435824394225
- 1.5406961297988893
- 1.5460781502723693
- 1.5725876712799072
- 1.6109723806381226
- 1.4874839448928834
- 1.5143216443061829
- 1.4956708335876465
- 1.781638560295105
- 1.5677027893066406
- 1.4541457271575928
- 1.4865364193916322
- 1.4843552088737488
- 1.433078637123108
- 1.5156968903541566
- 1.5309738779067994
- 1.8080535650253295
- 1.5683007502555848
- 1.5299876284599305
- 1.7595849800109864
- 1.403918297290802
- 1.4279292440414428
- 1.3975189089775086
- 1.425389471054077
- 1.3991630697250366
- 1.4113128113746642
- 1.386868989467621
- 1.4573212480545044
- 1.4359549760818482
- 1.3874273848533631
- 1.370727469921112
- 1.3689059662818908
- 1.4722098684310914
- 1.3704461002349853
- 1.4756615853309631
- 1.3854875731468201
- 1.4093962240219116
- 1.3760858869552612
- 1.471580626964569
- 1.3734547328948974
- 1.4321159291267396
- 1.361458728313446
- 1.3722500157356263
- 1.6166443467140197
- 1.539865300655365
- 1.314018566608429
- 1.3551485776901244
- 1.4119396710395813
- 1.3235782384872437
- 1.4332450246810913
- 1.3404431009292603
- 1.3363301610946656
- 1.4237148690223693
- 1.4546971893310547
- 1.3451692485809326
- 1.339972972869873
- 1.3834402585029602
- 1.4139659404754639
- 1.3037246251106263
- 1.4011514735221864
- 1.4913940477371215
- 1.3844433403015137
- 1.4411134028434753
- 1.3964170575141908
- 1.4485626101493836
- 1.3103704404830934
- 1.3176090788841248
- 1.3291223931312561
- 1.3307132935523986
- 1.3344710969924927
- 1.359628508090973
- 1.464076099395752
- 1.4792463374137879
- 1.4280859518051148
- 1.3208977174758911
- 1.4066033697128295
- 1.4307534408569336
- 1.4456173872947693
- 1.4622309470176698
- 1.342611050605774
- 1.437383918762207
- 1.3068826484680176
- 1.384985020160675
- 1.3144551873207093
- 1.3130214500427246
- 1.3293541359901428
- 1.4681015396118164
- 1.3036106944084167
- 1.3295742964744568
- 1.3173381304740905
- 1.3913157868385315
train_accuracy:
- 0.0
- 0.014
- 0.283
- 0.537
- 0.393
- 0.142
- 0.034
- 0.081
- 0.734
- 0.612
- 0.408
- 0.487
- 0.214
- 0.377
- 0.172
- 0.144
- 0.139
- 0.062
- 0.32
- 0.166
- 0.151
- 0.762
- 0.211
- 0.106
- 0.722
- 0.625
- 0.092
- 0.223
- 0.489
- 0.186
- 0.147
- 0.188
- 0.161
- 0.557
- 0.184
- 0.244
- 0.327
- 0.146
- 0.188
- 0.23
- 0.227
- 0.737
- 0.204
- 0.718
- 0.495
- 0.646
- 0.506
- 0.152
- 0.169
- 0.158
- 0.186
- 0.208
- 0.423
- 0.095
- 0.251
- 0.67
- 0.501
- 0.22
- 0.136
- 0.239
- 0.245
- 0.636
- 0.679
- 0.217
- 0.241
- 0.428
- 0.141
- 0.254
- 0.202
- 0.541
- 0.476
- 0.659
- 0.395
- 0.127
- 0.224
- 0.212
- 0.629
- 0.243
- 0.272
- 0.593
- 0.648
- 0.151
- 0.171
- 0.217
- 0.484
- 0.139
- 0.559
- 0.129
- 0.585
- 0.159
- 0.225
- 0.501
- 0.538
- 0.257
- 0.253
- 0.42
- 0.25
- 0.254
- 0.223
- 0.196
train_loss:
- 1.794
- 2.904
- 0.536
- 2.705
- 1.473
- 3.455
- 1.373
- 2.408
- 1.405
- 2.189
- 2.151
- 2.11
- 1.246
- 1.178
- 2.848
- 1.961
- 1.896
- 0.308
- 1.082
- 1.77
- 1.703
- 1.1
- 2.356
- 1.132
- 0.933
- 0.256
- 0.891
- 0.9
- 0.233
- 1.526
- 1.488
- 2.224
- 1.557
- 1.461
- 1.306
- 1.911
- 0.758
- 0.87
- 1.301
- 1.679
- 1.329
- 0.78
- 1.149
- 0.602
- 1.084
- 0.697
- 1.006
- 0.715
- 0.958
- 0.782
- 1.04
- 1.077
- 0.199
- 0.479
- 1.045
- 0.826
- 0.519
- 1.02
- 0.445
- 0.933
- 0.87
- 0.495
- 0.465
- 0.772
- 0.84
- 0.616
- 0.46
- 1.062
- 0.609
- 0.353
- 0.523
- 0.423
- 0.394
- 0.399
- 0.666
- 0.812
- 0.569
- 0.669
- 0.716
- 0.441
- 0.374
- 0.375
- 0.398
- 0.639
- 0.366
- 0.355
- 0.363
- 0.298
- 0.405
- 0.32
- 0.499
- 0.303
- 0.463
- 0.567
- 0.492
- 0.209
- 0.452
- 0.515
- 0.496
- 0.338
unequal: 0
verbose: 1
