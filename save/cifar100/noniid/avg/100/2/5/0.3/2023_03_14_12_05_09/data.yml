avg_train_accuracy: 0.223
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0157
- 0.0316
- 0.1061
- 0.0655
- 0.0775
- 0.0871
- 0.1117
- 0.1558
- 0.1419
- 0.0855
- 0.1066
- 0.1749
- 0.1095
- 0.1499
- 0.147
- 0.1005
- 0.1443
- 0.1001
- 0.1816
- 0.1143
- 0.1159
- 0.1142
- 0.2001
- 0.2118
- 0.1764
- 0.1965
- 0.1945
- 0.203
- 0.19
- 0.1979
- 0.2086
- 0.2054
- 0.1733
- 0.1424
- 0.0931
- 0.21
- 0.1563
- 0.2164
- 0.1546
- 0.1642
- 0.207
- 0.243
- 0.2226
- 0.2281
- 0.1912
- 0.2225
- 0.1814
- 0.2307
- 0.1925
- 0.2259
- 0.2291
- 0.2256
- 0.2538
- 0.2424
- 0.1801
- 0.1038
- 0.0777
- 0.1551
- 0.2419
- 0.2549
- 0.2181
- 0.1929
- 0.2286
- 0.1601
- 0.2315
- 0.1945
- 0.2398
- 0.2065
- 0.1626
- 0.2361
- 0.2014
- 0.1979
- 0.1866
- 0.2618
- 0.2354
- 0.2428
- 0.1997
- 0.2669
- 0.2243
- 0.2657
- 0.2346
- 0.1968
- 0.2174
- 0.2657
- 0.2493
- 0.1701
- 0.1051
- 0.2698
- 0.1893
- 0.1942
- 0.2715
- 0.2213
- 0.2523
- 0.2608
- 0.2261
- 0.2545
- 0.2233
- 0.1948
- 0.2556
- 0.2522
test_loss_list:
- 1.852854504585266
- 1.761248188018799
- 1.672466323375702
- 1.69587055683136
- 1.6379744839668273
- 1.621586470603943
- 1.5658914208412171
- 1.5394513726234436
- 1.5415916180610656
- 1.6286254334449768
- 1.5496594429016113
- 1.4806052088737487
- 1.5697127056121827
- 1.5068926787376404
- 1.5043983411788941
- 1.6140722274780273
- 1.4784551191329955
- 1.5913677906990051
- 1.4363553547859191
- 1.5708789134025574
- 1.5409874653816222
- 1.5718942165374756
- 1.3910520553588868
- 1.3990282273292542
- 1.4377461457252503
- 1.4301734638214112
- 1.4392265009880065
- 1.4144881582260131
- 1.431630084514618
- 1.3919424653053283
- 1.3799782109260559
- 1.3791918540000916
- 1.4222747826576232
- 1.4825670218467712
- 1.6858503103256226
- 1.345590193271637
- 1.4642847561836243
- 1.351231005191803
- 1.4754954075813294
- 1.4510290908813477
- 1.3575840663909913
- 1.3345976328849793
- 1.367315273284912
- 1.347820644378662
- 1.3987953853607178
- 1.3396225666999817
- 1.4368274307250977
- 1.3389590191841125
- 1.3965629816055298
- 1.3316508364677428
- 1.3496014261245728
- 1.3535716652870178
- 1.3294690370559692
- 1.3371879744529724
- 1.4424352502822877
- 1.6925900292396545
- 1.8679397201538086
- 1.4604046034812928
- 1.291004981994629
- 1.294983034133911
- 1.3698311996459962
- 1.411984622478485
- 1.333307375907898
- 1.4962639498710633
- 1.317391791343689
- 1.4026233816146851
- 1.3167608761787415
- 1.3824168157577514
- 1.4834167456626892
- 1.3173446536064148
- 1.4052370238304137
- 1.3962161874771117
- 1.425329670906067
- 1.2874843716621398
- 1.340575749874115
- 1.3333867383003235
- 1.4318667721748353
- 1.302288019657135
- 1.3994622778892518
- 1.309663589000702
- 1.362854859828949
- 1.4380042171478271
- 1.3675711822509766
- 1.28139009475708
- 1.325651297569275
- 1.5370558452606202
- 1.8500802183151246
- 1.2916380786895751
- 1.4930763459205627
- 1.4607639718055725
- 1.2900523495674134
- 1.404618558883667
- 1.3226663017272948
- 1.305134632587433
- 1.3758013248443604
- 1.306889157295227
- 1.3663795399665832
- 1.4555914735794067
- 1.29635502576828
- 1.3092416858673095
train_accuracy:
- 0.0
- 0.023
- 0.089
- 0.102
- 0.062
- 0.566
- 0.085
- 0.167
- 0.484
- 0.791
- 0.102
- 0.173
- 0.083
- 0.152
- 0.136
- 0.066
- 0.101
- 0.064
- 0.168
- 0.384
- 0.49
- 0.577
- 0.148
- 0.208
- 0.138
- 0.176
- 0.437
- 0.535
- 0.16
- 0.17
- 0.198
- 0.358
- 0.156
- 0.454
- 0.316
- 0.537
- 0.646
- 0.552
- 0.356
- 0.146
- 0.184
- 0.23
- 0.219
- 0.228
- 0.462
- 0.505
- 0.544
- 0.214
- 0.654
- 0.507
- 0.198
- 0.195
- 0.243
- 0.223
- 0.203
- 0.605
- 0.505
- 0.583
- 0.221
- 0.262
- 0.699
- 0.49
- 0.189
- 0.339
- 0.62
- 0.168
- 0.231
- 0.173
- 0.586
- 0.518
- 0.16
- 0.481
- 0.466
- 0.264
- 0.587
- 0.54
- 0.765
- 0.277
- 0.193
- 0.285
- 0.497
- 0.161
- 0.64
- 0.265
- 0.249
- 0.774
- 0.561
- 0.26
- 0.465
- 0.748
- 0.259
- 0.199
- 0.262
- 0.671
- 0.503
- 0.548
- 0.222
- 0.635
- 0.686
- 0.223
train_loss:
- 3.055
- 2.795
- 3.629
- 0.625
- 2.475
- 2.292
- 2.324
- 3.158
- 2.102
- 1.24
- 1.331
- 2.872
- 1.13
- 1.826
- 1.878
- 0.966
- 1.221
- 0.994
- 1.793
- 0.994
- 0.922
- 0.934
- 1.73
- 2.206
- 1.678
- 1.413
- 1.383
- 1.426
- 1.454
- 0.898
- 1.405
- 1.256
- 0.957
- 0.705
- 0.206
- 1.282
- 0.651
- 1.286
- 0.643
- 0.697
- 1.328
- 1.674
- 1.15
- 1.197
- 0.674
- 1.099
- 0.607
- 1.05
- 0.607
- 1.065
- 0.909
- 0.875
- 1.166
- 1.057
- 0.286
- 0.17
- 0.111
- 0.581
- 0.923
- 1.197
- 0.538
- 0.461
- 0.675
- 0.227
- 0.772
- 0.535
- 0.71
- 0.445
- 0.414
- 0.712
- 0.455
- 0.426
- 0.423
- 1.004
- 0.636
- 0.655
- 0.37
- 0.821
- 0.424
- 0.815
- 0.407
- 0.365
- 0.404
- 0.725
- 0.559
- 0.148
- 0.063
- 0.754
- 0.202
- 0.263
- 0.669
- 0.322
- 0.471
- 0.516
- 0.298
- 0.446
- 0.294
- 0.248
- 0.481
- 0.423
unequal: 0
verbose: 1
