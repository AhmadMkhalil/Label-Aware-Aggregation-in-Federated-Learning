avg_train_accuracy: 0.439
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0113
- 0.0169
- 0.0241
- 0.028
- 0.0341
- 0.0657
- 0.0922
- 0.1087
- 0.0694
- 0.1147
- 0.0824
- 0.1146
- 0.0925
- 0.1347
- 0.1444
- 0.1039
- 0.0667
- 0.0826
- 0.0571
- 0.0788
- 0.0924
- 0.0631
- 0.0549
- 0.1512
- 0.1609
- 0.1029
- 0.1764
- 0.1621
- 0.1324
- 0.1349
- 0.1246
- 0.1281
- 0.1286
- 0.2089
- 0.189
- 0.216
- 0.1779
- 0.1982
- 0.2217
- 0.1638
- 0.2131
- 0.207
- 0.183
- 0.16
- 0.1675
- 0.1588
- 0.2351
- 0.171
- 0.1681
- 0.2208
- 0.2398
- 0.1883
- 0.1996
- 0.0931
- 0.1793
- 0.156
- 0.2238
- 0.1806
- 0.1014
- 0.1897
- 0.2225
- 0.1863
- 0.2467
- 0.2009
- 0.2482
- 0.2406
- 0.2375
- 0.1847
- 0.2282
- 0.1587
- 0.2246
- 0.177
- 0.2581
- 0.2217
- 0.1187
- 0.2426
- 0.2033
- 0.2356
- 0.2416
- 0.1737
- 0.1615
- 0.1863
- 0.2292
- 0.24
- 0.2123
- 0.2394
- 0.1996
- 0.2514
- 0.2079
- 0.2065
- 0.2314
- 0.2391
- 0.2365
- 0.2557
- 0.2383
- 0.2431
- 0.2507
- 0.2395
- 0.2031
- 0.2089
test_loss_list:
- 2.0834277725219725
- 1.8409539699554442
- 1.8713886642456055
- 1.7967429304122924
- 1.8251393413543702
- 1.652673511505127
- 1.6066238713264465
- 1.5844442391395568
- 1.646468336582184
- 1.544922776222229
- 1.6275519061088561
- 1.5379972314834596
- 1.6221730017662048
- 1.5125385904312134
- 1.499983744621277
- 1.5903582382202148
- 1.7952254486083985
- 1.6482947373390198
- 1.7499290752410888
- 1.6206555843353272
- 1.5998025488853456
- 1.8522779035568238
- 1.919738335609436
- 1.439652693271637
- 1.444698259830475
- 1.6098184061050416
- 1.4222480320930482
- 1.4535752534866333
- 1.5150889539718628
- 1.5135064387321473
- 1.56370267868042
- 1.5350066828727722
- 1.542663552761078
- 1.407095890045166
- 1.4291727375984191
- 1.402773814201355
- 1.4620563530921935
- 1.4268315076828002
- 1.4023867487907409
- 1.4843638134002686
- 1.3632572650909425
- 1.3872808146476745
- 1.4104774737358092
- 1.4178709530830382
- 1.4070845293998717
- 1.4462762212753295
- 1.3257557225227357
- 1.4492206001281738
- 1.428243534564972
- 1.3268622159957886
- 1.3285137271881104
- 1.4253632521629334
- 1.3617993426322936
- 1.7229590678215028
- 1.4034129524230956
- 1.4461165046691895
- 1.310450415611267
- 1.4213758158683776
- 1.7462460374832154
- 1.3588415050506593
- 1.3099507212638855
- 1.4133971452713012
- 1.301211576461792
- 1.3950110721588134
- 1.3150206971168519
- 1.322416090965271
- 1.326365122795105
- 1.4204715132713317
- 1.3116496753692628
- 1.5107299780845642
- 1.3189722084999085
- 1.4505069398880004
- 1.2895098972320556
- 1.339003849029541
- 1.634975392818451
- 1.2958141899108886
- 1.3867365789413453
- 1.3184706091880798
- 1.3028331756591798
- 1.4816541862487793
- 1.458995234966278
- 1.4315266704559326
- 1.322846601009369
- 1.3061798930168151
- 1.3723621582984924
- 1.3271970534324646
- 1.4007581329345704
- 1.275063192844391
- 1.382616240978241
- 1.3748382210731507
- 1.32390300989151
- 1.320994620323181
- 1.3236597800254821
- 1.2801699423789978
- 1.3259005308151246
- 1.318610200881958
- 1.3070202326774598
- 1.3357922101020814
- 1.4403992891311646
- 1.417718231678009
train_accuracy:
- 0.002
- 0.685
- 0.47
- 0.001
- 0.373
- 0.739
- 0.693
- 0.728
- 0.639
- 0.11
- 0.054
- 0.684
- 0.629
- 0.57
- 0.124
- 0.07
- 0.651
- 0.522
- 0.665
- 0.575
- 0.053
- 0.645
- 0.775
- 0.14
- 0.113
- 0.485
- 0.126
- 0.651
- 0.101
- 0.648
- 0.579
- 0.083
- 0.074
- 0.225
- 0.566
- 0.221
- 0.497
- 0.201
- 0.203
- 0.466
- 0.257
- 0.213
- 0.467
- 0.142
- 0.559
- 0.649
- 0.296
- 0.123
- 0.114
- 0.186
- 0.222
- 0.633
- 0.503
- 0.696
- 0.458
- 0.638
- 0.259
- 0.119
- 0.505
- 0.61
- 0.182
- 0.622
- 0.264
- 0.683
- 0.306
- 0.237
- 0.221
- 0.411
- 0.212
- 0.647
- 0.202
- 0.622
- 0.315
- 0.464
- 0.479
- 0.225
- 0.569
- 0.221
- 0.233
- 0.495
- 0.428
- 0.684
- 0.199
- 0.635
- 0.174
- 0.417
- 0.289
- 0.332
- 0.183
- 0.699
- 0.504
- 0.533
- 0.221
- 0.222
- 0.294
- 0.219
- 0.232
- 0.402
- 0.162
- 0.439
train_loss:
- 0.569
- 3.026
- 1.591
- 1.554
- 1.47
- 2.513
- 2.382
- 2.27
- 1.376
- 2.154
- 1.293
- 2.077
- 1.198
- 2.01
- 1.947
- 1.084
- 0.265
- 1.045
- 0.317
- 1.092
- 0.96
- 0.175
- 0.221
- 1.82
- 1.737
- 0.293
- 1.615
- 1.622
- 0.882
- 0.83
- 0.794
- 0.779
- 0.785
- 2.041
- 1.525
- 2.05
- 0.698
- 1.159
- 1.896
- 0.306
- 1.491
- 1.351
- 0.754
- 0.763
- 0.688
- 0.833
- 1.729
- 0.588
- 0.66
- 1.123
- 1.519
- 0.746
- 0.693
- 0.108
- 0.663
- 0.665
- 1.062
- 0.594
- 0.108
- 0.646
- 0.937
- 0.556
- 1.294
- 0.58
- 1.252
- 0.857
- 0.778
- 0.21
- 0.762
- 0.179
- 0.903
- 0.497
- 1.097
- 0.486
- 0.1
- 0.698
- 0.466
- 0.68
- 0.674
- 0.156
- 0.369
- 0.374
- 0.775
- 0.569
- 0.431
- 0.589
- 0.386
- 0.628
- 0.294
- 0.467
- 0.492
- 0.505
- 0.54
- 0.603
- 0.464
- 0.461
- 0.546
- 0.461
- 0.257
- 0.246
unequal: 0
verbose: 1
