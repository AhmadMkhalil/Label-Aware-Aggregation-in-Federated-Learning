avg_train_accuracy: 0.262
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.017
- 0.0757
- 0.0261
- 0.1019
- 0.0757
- 0.0595
- 0.0432
- 0.1303
- 0.1242
- 0.1241
- 0.1577
- 0.0975
- 0.1674
- 0.115
- 0.1226
- 0.087
- 0.1277
- 0.121
- 0.1591
- 0.1188
- 0.1686
- 0.1473
- 0.1449
- 0.202
- 0.1151
- 0.1419
- 0.1618
- 0.1329
- 0.1874
- 0.1936
- 0.1016
- 0.132
- 0.1831
- 0.1012
- 0.1289
- 0.2225
- 0.2024
- 0.1667
- 0.1631
- 0.1458
- 0.1205
- 0.1301
- 0.0969
- 0.1425
- 0.14
- 0.2017
- 0.2075
- 0.1726
- 0.219
- 0.1787
- 0.2228
- 0.2112
- 0.2371
- 0.1591
- 0.2226
- 0.2207
- 0.2342
- 0.2154
- 0.2274
- 0.2153
- 0.2395
- 0.2156
- 0.1725
- 0.2377
- 0.1943
- 0.1996
- 0.182
- 0.181
- 0.2306
- 0.2044
- 0.2367
- 0.2337
- 0.2338
- 0.2198
- 0.2335
- 0.2646
- 0.2443
- 0.2402
- 0.2243
- 0.2278
- 0.1927
- 0.2032
- 0.2419
- 0.1726
- 0.2469
- 0.2007
- 0.2532
- 0.242
- 0.2102
- 0.1965
- 0.1972
- 0.1882
- 0.1899
- 0.1969
- 0.242
- 0.2449
- 0.1852
- 0.2017
- 0.2505
- 0.2539
test_loss_list:
- 2.0708930683135987
- 1.7385746383666991
- 1.8874616527557373
- 1.6672729778289794
- 1.6665006971359253
- 1.6896309804916383
- 1.764505524635315
- 1.5727405905723573
- 1.5627072334289551
- 1.5437119555473329
- 1.5205277919769287
- 1.6061121892929078
- 1.4852317905426025
- 1.5509817004203796
- 1.5036484122276306
- 1.6223421216011047
- 1.4860969614982604
- 1.5190839219093322
- 1.4478661274909974
- 1.5247946166992188
- 1.4409527158737183
- 1.4597010684013367
- 1.4845338225364686
- 1.4097019457817077
- 1.589198760986328
- 1.4606409120559691
- 1.4232339644432068
- 1.4886111998558045
- 1.3919000291824342
- 1.3896862745285035
- 1.6423768496513367
- 1.4584731602668761
- 1.375653645992279
- 1.5871239161491395
- 1.4904971623420715
- 1.3422702646255493
- 1.3784340977668763
- 1.4428392720222474
- 1.4194243407249452
- 1.4690605115890503
- 1.5635514163970947
- 1.4884779143333435
- 1.723833637237549
- 1.465639319419861
- 1.4837394285202026
- 1.3402365398406983
- 1.3450106239318849
- 1.4227727127075196
- 1.3145805764198304
- 1.3987873959541322
- 1.3158898544311524
- 1.3506836080551148
- 1.323127067089081
- 1.4912538385391236
- 1.3137119126319885
- 1.3246392607688904
- 1.2991636395454407
- 1.3384465837478638
- 1.3158049440383912
- 1.3490963244438172
- 1.3204026985168458
- 1.3449554300308229
- 1.4508064675331116
- 1.2875561666488649
- 1.3911337876319885
- 1.354342381954193
- 1.3962290716171264
- 1.381589608192444
- 1.2946153736114503
- 1.3559489178657531
- 1.2787280893325805
- 1.2999776315689087
- 1.3067924547195435
- 1.317151336669922
- 1.2988819837570191
- 1.2718427395820617
- 1.306704547405243
- 1.3151061487197877
- 1.3329366517066956
- 1.3045829510688782
- 1.3871752667427062
- 1.3453097605705262
- 1.2739379024505615
- 1.461684672832489
- 1.270911729335785
- 1.3763316679000854
- 1.2658778762817382
- 1.299436285495758
- 1.3716602635383606
- 1.406506791114807
- 1.390108802318573
- 1.4271072626113892
- 1.4149612021446227
- 1.4029464769363402
- 1.2992015719413756
- 1.3044663763046265
- 1.4391339564323424
- 1.3773937821388245
- 1.2626475524902343
- 1.2710903263092042
train_accuracy:
- 0.0
- 0.085
- 0.383
- 0.115
- 0.653
- 0.033
- 0.008
- 0.126
- 0.095
- 0.123
- 0.151
- 0.384
- 0.181
- 0.702
- 0.193
- 0.572
- 0.648
- 0.4
- 0.145
- 0.768
- 0.14
- 0.145
- 0.603
- 0.212
- 0.533
- 0.168
- 0.158
- 0.73
- 0.179
- 0.679
- 0.28
- 0.505
- 0.584
- 0.627
- 0.668
- 0.232
- 0.205
- 0.162
- 0.531
- 0.102
- 0.272
- 0.791
- 0.696
- 0.682
- 0.104
- 0.184
- 0.187
- 0.144
- 0.615
- 0.145
- 0.677
- 0.206
- 0.246
- 0.548
- 0.206
- 0.66
- 0.254
- 0.206
- 0.232
- 0.213
- 0.225
- 0.652
- 0.131
- 0.211
- 0.621
- 0.651
- 0.15
- 0.708
- 0.567
- 0.732
- 0.239
- 0.212
- 0.204
- 0.546
- 0.221
- 0.254
- 0.239
- 0.595
- 0.565
- 0.596
- 0.655
- 0.621
- 0.539
- 0.589
- 0.229
- 0.638
- 0.251
- 0.637
- 0.187
- 0.748
- 0.695
- 0.643
- 0.726
- 0.174
- 0.647
- 0.704
- 0.459
- 0.153
- 0.245
- 0.262
train_loss:
- 0.537
- 4.283
- 0.598
- 3.754
- 2.535
- 0.482
- 1.29
- 3.332
- 2.374
- 2.202
- 2.977
- 0.488
- 2.966
- 1.248
- 1.161
- 1.018
- 1.929
- 1.159
- 1.886
- 1.048
- 1.68
- 1.773
- 1.017
- 2.28
- 0.303
- 0.92
- 1.54
- 1.018
- 1.506
- 1.541
- 0.261
- 0.911
- 1.384
- 0.233
- 0.921
- 2.113
- 1.405
- 0.763
- 0.84
- 0.697
- 0.252
- 0.743
- 0.165
- 0.77
- 0.66
- 1.296
- 1.219
- 0.746
- 1.256
- 0.704
- 1.116
- 1.046
- 1.431
- 0.228
- 1.136
- 1.012
- 0.964
- 0.959
- 1.084
- 0.857
- 1.032
- 0.653
- 0.499
- 0.89
- 0.459
- 0.544
- 0.55
- 0.539
- 0.853
- 0.462
- 0.867
- 0.789
- 0.697
- 0.505
- 0.721
- 1.003
- 0.68
- 0.592
- 0.478
- 0.445
- 0.443
- 0.423
- 0.597
- 0.169
- 0.525
- 0.446
- 0.558
- 0.626
- 0.335
- 0.341
- 0.353
- 0.318
- 0.292
- 0.296
- 0.504
- 0.505
- 0.142
- 0.396
- 0.48
- 0.498
unequal: 0
verbose: 1
