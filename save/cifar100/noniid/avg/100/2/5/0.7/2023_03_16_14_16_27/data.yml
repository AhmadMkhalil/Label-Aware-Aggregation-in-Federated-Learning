avg_train_accuracy: 0.011
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0238
- 0.0729
- 0.0836
- 0.1088
- 0.1108
- 0.1321
- 0.1408
- 0.1427
- 0.1496
- 0.1621
- 0.168
- 0.1721
- 0.1818
- 0.1744
- 0.1864
- 0.1848
- 0.1877
- 0.1949
- 0.201
- 0.2049
- 0.2098
- 0.2098
- 0.2121
- 0.2147
- 0.2134
- 0.2191
- 0.2214
- 0.2194
- 0.2236
- 0.2273
- 0.2328
- 0.2319
- 0.2304
- 0.2383
- 0.2262
- 0.2404
- 0.2404
- 0.2455
- 0.2417
- 0.2437
- 0.2432
- 0.2436
- 0.2314
- 0.2395
- 0.2518
- 0.2525
- 0.249
- 0.2496
- 0.2606
- 0.2567
- 0.2623
- 0.2597
- 0.262
- 0.2644
- 0.269
- 0.2646
- 0.2619
- 0.2668
- 0.266
- 0.2686
- 0.2685
- 0.2665
- 0.2682
- 0.2618
- 0.2736
- 0.272
- 0.2646
- 0.2732
- 0.2742
- 0.2758
- 0.2728
- 0.2724
- 0.2711
- 0.2765
- 0.2735
- 0.2689
- 0.2728
- 0.2747
- 0.2754
- 0.2801
- 0.2806
- 0.2759
- 0.2753
- 0.2839
- 0.2785
- 0.2773
- 0.2796
- 0.2778
- 0.2789
- 0.2765
- 0.28
- 0.2628
- 0.2814
- 0.278
- 0.2825
- 0.2797
- 0.2795
- 0.2811
- 0.2844
- 0.2859
test_loss_list:
- 1.8285435009002686
- 1.7058737659454346
- 1.6559132051467895
- 1.6103574657440185
- 1.590810911655426
- 1.555356616973877
- 1.521981019973755
- 1.5078576517105102
- 1.4875154328346252
- 1.4688195562362671
- 1.4521843338012694
- 1.446538541316986
- 1.4171758913993835
- 1.4295165252685547
- 1.4026593828201295
- 1.4048866295814515
- 1.396791307926178
- 1.3780834794044494
- 1.367938289642334
- 1.3659432911872864
- 1.356964557170868
- 1.3501757192611694
- 1.3472309184074402
- 1.3353305983543395
- 1.3462595391273497
- 1.3321000337600708
- 1.3256317353248597
- 1.3275808024406432
- 1.3212494659423828
- 1.3156485390663146
- 1.3069928312301635
- 1.3014317274093627
- 1.309310314655304
- 1.2997518467903137
- 1.3198767876625062
- 1.290534873008728
- 1.2939910197257996
- 1.2922295641899109
- 1.2867243123054504
- 1.2816340398788453
- 1.2801912999153138
- 1.2901482820510863
- 1.3088523387908935
- 1.2931699967384338
- 1.2664755821228026
- 1.2702308154106141
- 1.2755698513984681
- 1.277375626564026
- 1.2666830372810365
- 1.2630573582649232
- 1.2582176756858825
- 1.2606649708747864
- 1.258888041973114
- 1.2494791650772095
- 1.2471408295631408
- 1.2545119714736939
- 1.2623362374305724
- 1.2505436277389526
- 1.2482212924957274
- 1.2497963285446168
- 1.2541619062423706
- 1.2479369616508484
- 1.2498568105697632
- 1.2521272039413451
- 1.2452255606651306
- 1.2431858277320862
- 1.2527219295501708
- 1.245183184146881
- 1.2487500238418578
- 1.2471088242530823
- 1.2435264372825623
- 1.2395311331748962
- 1.2507791018486023
- 1.2371897149085997
- 1.239354476928711
- 1.251347839832306
- 1.2438780212402343
- 1.2363726377487183
- 1.2298802971839904
- 1.2329802060127257
- 1.2408771061897277
- 1.2354009771347045
- 1.2443853521347046
- 1.2258855700492859
- 1.2347104406356813
- 1.2332978057861328
- 1.2362828040122986
- 1.233860239982605
- 1.239871747493744
- 1.2483984971046447
- 1.237885956764221
- 1.2759055876731873
- 1.2308174276351929
- 1.2379160332679748
- 1.233800311088562
- 1.2345942783355712
- 1.2362999176979066
- 1.2263556981086732
- 1.2246512031555177
- 1.2282536506652832
train_accuracy:
- 0.027
- 0.055
- 0.059
- 0.013
- 0.131
- 0.154
- 0.142
- 0.026
- 0.122
- 0.07
- 0.149
- 0.184
- 0.018
- 0.16
- 0.188
- 0.142
- 0.088
- 0.045
- 0.195
- 0.073
- 0.23
- 0.06
- 0.227
- 0.227
- 0.218
- 0.051
- 0.219
- 0.037
- 0.167
- 0.101
- 0.239
- 0.025
- 0.076
- 0.244
- 0.029
- 0.194
- 0.2
- 0.117
- 0.264
- 0.087
- 0.037
- 0.269
- 0.18
- 0.103
- 0.275
- 0.195
- 0.257
- 0.2
- 0.264
- 0.063
- 0.257
- 0.036
- 0.277
- 0.15
- 0.292
- 0.26
- 0.27
- 0.248
- 0.073
- 0.03
- 0.303
- 0.225
- 0.06
- 0.009
- 0.289
- 0.288
- 0.247
- 0.237
- 0.293
- 0.26
- 0.082
- 0.295
- 0.224
- 0.058
- 0.131
- 0.244
- 0.281
- 0.288
- 0.069
- 0.308
- 0.083
- 0.121
- 0.112
- 0.009
- 0.305
- 0.034
- 0.273
- 0.126
- 0.092
- 0.087
- 0.247
- 0.297
- 0.055
- 0.251
- 0.269
- 0.231
- 0.306
- 0.241
- 0.232
- 0.011
train_loss:
- 2.639
- 2.414
- 1.815
- 2.211
- 1.682
- 2.035
- 1.994
- 1.538
- 1.519
- 1.843
- 1.783
- 2.121
- 1.74
- 0.985
- 1.649
- 1.245
- 1.237
- 1.568
- 1.541
- 1.506
- 1.762
- 1.125
- 1.41
- 1.381
- 1.05
- 1.052
- 1.293
- 1.007
- 0.98
- 1.194
- 1.215
- 0.929
- 0.885
- 1.159
- 0.645
- 1.12
- 1.103
- 1.067
- 1.031
- 1.042
- 0.776
- 0.831
- 0.549
- 0.734
- 0.952
- 0.927
- 0.889
- 0.72
- 1.063
- 0.73
- 1.018
- 0.629
- 0.682
- 0.786
- 0.789
- 0.767
- 0.632
- 0.578
- 0.755
- 0.851
- 0.831
- 0.566
- 0.649
- 0.51
- 0.777
- 0.623
- 0.477
- 0.592
- 0.563
- 0.546
- 0.514
- 0.478
- 0.418
- 0.456
- 0.451
- 0.399
- 0.402
- 0.62
- 0.438
- 0.585
- 0.566
- 0.403
- 0.386
- 0.45
- 0.446
- 0.382
- 0.437
- 0.351
- 0.336
- 0.336
- 0.33
- 0.253
- 0.465
- 0.308
- 0.377
- 0.315
- 0.354
- 0.371
- 0.348
- 0.349
unequal: 0
verbose: 1
