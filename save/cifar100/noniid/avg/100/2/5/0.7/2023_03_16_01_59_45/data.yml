avg_train_accuracy: 0.289
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0124
- 0.0427
- 0.0818
- 0.1023
- 0.1226
- 0.1353
- 0.1362
- 0.1495
- 0.1578
- 0.1687
- 0.1697
- 0.1576
- 0.1705
- 0.1777
- 0.1862
- 0.1904
- 0.1869
- 0.1957
- 0.1954
- 0.2053
- 0.208
- 0.2122
- 0.2171
- 0.2178
- 0.2185
- 0.2174
- 0.226
- 0.228
- 0.225
- 0.2285
- 0.2302
- 0.2377
- 0.229
- 0.2408
- 0.2397
- 0.2374
- 0.239
- 0.2453
- 0.2443
- 0.2474
- 0.2468
- 0.2488
- 0.2528
- 0.2555
- 0.2583
- 0.2573
- 0.2571
- 0.2564
- 0.2531
- 0.2542
- 0.2618
- 0.2589
- 0.2578
- 0.2671
- 0.2653
- 0.2634
- 0.2659
- 0.268
- 0.2644
- 0.2673
- 0.2678
- 0.2677
- 0.2703
- 0.2739
- 0.2714
- 0.2743
- 0.2749
- 0.2614
- 0.2666
- 0.2598
- 0.2783
- 0.27
- 0.272
- 0.2743
- 0.2777
- 0.2711
- 0.275
- 0.2716
- 0.2628
- 0.2735
- 0.2799
- 0.2741
- 0.2799
- 0.2774
- 0.2807
- 0.2803
- 0.2697
- 0.279
- 0.2815
- 0.2764
- 0.281
- 0.2845
- 0.2817
- 0.2763
- 0.2758
- 0.2855
- 0.2834
- 0.2859
- 0.2762
- 0.2853
test_loss_list:
- 1.8823364210128783
- 1.778923854827881
- 1.6819147157669068
- 1.6246580600738525
- 1.5877998971939087
- 1.5458057141304016
- 1.5278445982933044
- 1.5038879466056825
- 1.4861375999450683
- 1.4665653944015502
- 1.4644541096687318
- 1.474261281490326
- 1.4450340485572815
- 1.4330677556991578
- 1.4104678201675416
- 1.4020326399803162
- 1.3993683671951294
- 1.3904916667938232
- 1.3838854026794434
- 1.3663382625579834
- 1.3661599683761596
- 1.3602540159225465
- 1.350773205757141
- 1.3465593266487121
- 1.3391004633903503
- 1.3401727104187011
- 1.3321385169029236
- 1.3297085881233215
- 1.3116949129104614
- 1.3130041885375976
- 1.3092462730407715
- 1.3009560298919678
- 1.3081589913368226
- 1.2956071019172668
- 1.303127794265747
- 1.2979624390602111
- 1.281867606639862
- 1.2778977465629577
- 1.2829947280883789
- 1.27250550031662
- 1.2707026648521422
- 1.2663274240493774
- 1.2638074088096618
- 1.2539884853363037
- 1.2639229536056518
- 1.2622352719306946
- 1.2448479533195496
- 1.2611667251586913
- 1.2650883984565735
- 1.2620821857452393
- 1.2471396470069884
- 1.2576492142677307
- 1.2467404341697692
- 1.2323617005348206
- 1.2339343571662902
- 1.2392083406448364
- 1.2330313730239868
- 1.2195247650146483
- 1.2342676663398742
- 1.2315757060050965
- 1.2377061009407044
- 1.2241896986961365
- 1.2266485071182252
- 1.2254710125923156
- 1.2202863478660584
- 1.2223094034194946
- 1.2249733233451843
- 1.2471200585365296
- 1.2337958192825318
- 1.2575513410568238
- 1.2078884482383727
- 1.2306664776802063
- 1.2194962453842164
- 1.2273744940757751
- 1.2099831175804139
- 1.2223027801513673
- 1.21587397813797
- 1.2270610070228576
- 1.2482701206207276
- 1.2237778067588807
- 1.1993238759040832
- 1.2209928369522094
- 1.2059159684181213
- 1.2075968742370606
- 1.2092558336257935
- 1.2031605553627014
- 1.2348995733261108
- 1.206162347793579
- 1.2051635456085206
- 1.2116184258460998
- 1.2059716844558717
- 1.1925677061080933
- 1.200963180065155
- 1.2217163133621216
- 1.2288674640655517
- 1.2097911143302917
- 1.2031529116630555
- 1.19817316532135
- 1.2352704119682312
- 1.2056947898864747
train_accuracy:
- 0.0
- 0.014
- 0.098
- 0.115
- 0.006
- 0.114
- 0.011
- 0.225
- 0.036
- 0.125
- 0.199
- 0.009
- 0.116
- 0.149
- 0.141
- 0.156
- 0.02
- 0.213
- 0.22
- 0.184
- 0.17
- 0.229
- 0.239
- 0.186
- 0.207
- 0.189
- 0.254
- 0.256
- 0.253
- 0.234
- 0.213
- 0.247
- 0.209
- 0.03
- 0.265
- 0.243
- 0.08
- 0.064
- 0.104
- 0.087
- 0.236
- 0.275
- 0.25
- 0.086
- 0.045
- 0.264
- 0.277
- 0.316
- 0.212
- 0.207
- 0.283
- 0.315
- 0.225
- 0.132
- 0.158
- 0.184
- 0.24
- 0.287
- 0.182
- 0.169
- 0.224
- 0.296
- 0.283
- 0.306
- 0.15
- 0.274
- 0.11
- 0.151
- 0.337
- 0.268
- 0.291
- 0.21
- 0.267
- 0.295
- 0.283
- 0.208
- 0.29
- 0.277
- 0.31
- 0.239
- 0.149
- 0.197
- 0.151
- 0.263
- 0.291
- 0.137
- 0.231
- 0.288
- 0.324
- 0.206
- 0.089
- 0.073
- 0.314
- 0.175
- 0.268
- 0.281
- 0.066
- 0.297
- 0.247
- 0.289
train_loss:
- 1.607
- 1.98
- 2.369
- 2.259
- 2.14
- 2.117
- 1.593
- 1.953
- 1.526
- 1.86
- 1.438
- 1.026
- 1.382
- 1.348
- 1.681
- 1.651
- 1.605
- 1.577
- 1.565
- 1.513
- 1.45
- 1.747
- 1.101
- 1.088
- 1.366
- 1.067
- 1.584
- 1.273
- 1.016
- 0.94
- 0.996
- 1.463
- 0.707
- 1.391
- 1.35
- 0.879
- 0.865
- 1.087
- 0.838
- 1.036
- 0.798
- 0.996
- 0.964
- 0.983
- 1.132
- 0.908
- 0.719
- 0.693
- 0.684
- 0.677
- 0.848
- 0.647
- 0.632
- 0.804
- 0.622
- 0.776
- 0.604
- 0.74
- 0.58
- 0.692
- 0.543
- 0.841
- 0.65
- 0.791
- 0.534
- 0.499
- 0.599
- 0.357
- 0.477
- 0.365
- 0.582
- 0.453
- 0.46
- 0.429
- 0.564
- 0.448
- 0.52
- 0.413
- 0.303
- 0.396
- 0.508
- 0.396
- 0.471
- 0.467
- 0.466
- 0.444
- 0.278
- 0.417
- 0.508
- 0.329
- 0.422
- 0.414
- 0.413
- 0.305
- 0.303
- 0.376
- 0.384
- 0.359
- 0.224
- 0.353
unequal: 0
verbose: 1
