avg_train_accuracy: 0.234
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0186
- 0.0799
- 0.0964
- 0.1148
- 0.1218
- 0.1341
- 0.139
- 0.1483
- 0.149
- 0.1518
- 0.1598
- 0.1645
- 0.1657
- 0.1772
- 0.1808
- 0.1813
- 0.1886
- 0.192
- 0.1922
- 0.199
- 0.2026
- 0.206
- 0.2102
- 0.2059
- 0.2056
- 0.2111
- 0.2049
- 0.2133
- 0.2035
- 0.2215
- 0.2225
- 0.2273
- 0.2235
- 0.2272
- 0.2322
- 0.2285
- 0.2362
- 0.237
- 0.2389
- 0.2404
- 0.2394
- 0.2427
- 0.2454
- 0.2465
- 0.2493
- 0.2443
- 0.2515
- 0.2522
- 0.2507
- 0.2435
- 0.2528
- 0.2603
- 0.2589
- 0.2625
- 0.2622
- 0.2644
- 0.2574
- 0.2589
- 0.2626
- 0.2509
- 0.2671
- 0.2607
- 0.2598
- 0.251
- 0.2639
- 0.2651
- 0.261
- 0.2727
- 0.2593
- 0.272
- 0.269
- 0.2681
- 0.2743
- 0.268
- 0.2813
- 0.2709
- 0.2759
- 0.271
- 0.2606
- 0.2782
- 0.2757
- 0.2784
- 0.2744
- 0.2766
- 0.2805
- 0.2759
- 0.2751
- 0.2785
- 0.28
- 0.2757
- 0.2747
- 0.2738
- 0.2705
- 0.2711
- 0.2809
- 0.2783
- 0.2618
- 0.2847
- 0.2805
- 0.2768
test_loss_list:
- 1.8564878511428833
- 1.6993848276138306
- 1.642582676410675
- 1.5977503418922425
- 1.5652002716064453
- 1.54520565032959
- 1.522905888557434
- 1.4972416400909423
- 1.4889967298507691
- 1.4894115471839904
- 1.4696754240989685
- 1.4524984240531922
- 1.4496377944946288
- 1.4319778084754944
- 1.4207485818862915
- 1.4216748690605163
- 1.4114258146286012
- 1.3898611783981323
- 1.3890985417366029
- 1.381105055809021
- 1.3759638929367066
- 1.36520991563797
- 1.3515951752662658
- 1.3545144867897034
- 1.3531548047065736
- 1.3490625262260436
- 1.3657728934288025
- 1.3426374912261962
- 1.3654374551773072
- 1.3223334813117982
- 1.311041805744171
- 1.313387861251831
- 1.3196986293792725
- 1.304173502922058
- 1.3023150873184204
- 1.3044010305404663
- 1.297298321723938
- 1.2932962107658386
- 1.2978256297111512
- 1.2826863741874694
- 1.2809172677993774
- 1.2726296138763429
- 1.2709611392021178
- 1.2660078358650209
- 1.2674352288246156
- 1.2757565045356751
- 1.2680359625816344
- 1.2630695414543152
- 1.2619308590888978
- 1.275604772567749
- 1.258319902420044
- 1.2473620748519898
- 1.2504518508911133
- 1.2561896777153014
- 1.256775712966919
- 1.2532445359230042
- 1.2403338861465454
- 1.2405296874046325
- 1.2364995527267455
- 1.2607078409194947
- 1.232168025970459
- 1.2466055154800415
- 1.238961169719696
- 1.2658817481994629
- 1.234657166004181
- 1.2296486353874208
- 1.239447386264801
- 1.219920916557312
- 1.2506501364707947
- 1.2225882816314697
- 1.2273754000663757
- 1.2361840796470642
- 1.226399781703949
- 1.2231975483894348
- 1.2171864414215088
- 1.22980685710907
- 1.2234806728363037
- 1.2245322799682616
- 1.2543649411201476
- 1.2172581577301025
- 1.2209710192680359
- 1.2173798489570617
- 1.2246106839179993
- 1.2339330506324768
- 1.2132281041145325
- 1.2253667616844177
- 1.2200068998336793
- 1.221851646900177
- 1.2196774125099181
- 1.225115752220154
- 1.230280122756958
- 1.2353584527969361
- 1.2319803047180176
- 1.2364507269859315
- 1.2194409465789795
- 1.2213156700134278
- 1.2612816834449767
- 1.2151009702682496
- 1.2199085116386414
- 1.2304086923599242
train_accuracy:
- 0.015
- 0.087
- 0.105
- 0.113
- 0.009
- 0.182
- 0.004
- 0.066
- 0.037
- 0.14
- 0.016
- 0.107
- 0.145
- 0.016
- 0.0
- 0.236
- 0.17
- 0.007
- 0.018
- 0.096
- 0.028
- 0.209
- 0.074
- 0.214
- 0.239
- 0.242
- 0.076
- 0.183
- 0.266
- 0.281
- 0.202
- 0.247
- 0.191
- 0.239
- 0.143
- 0.111
- 0.077
- 0.08
- 0.223
- 0.241
- 0.157
- 0.217
- 0.079
- 0.202
- 0.219
- 0.104
- 0.204
- 0.222
- 0.032
- 0.086
- 0.206
- 0.219
- 0.229
- 0.064
- 0.278
- 0.291
- 0.009
- 0.282
- 0.111
- 0.15
- 0.232
- 0.052
- 0.103
- 0.196
- 0.222
- 0.219
- 0.221
- 0.026
- 0.117
- 0.228
- 0.103
- 0.149
- 0.33
- 0.113
- 0.066
- 0.234
- 0.234
- 0.065
- 0.295
- 0.108
- 0.127
- 0.031
- 0.281
- 0.276
- 0.13
- 0.086
- 0.297
- 0.299
- 0.062
- 0.223
- 0.245
- 0.257
- 0.317
- 0.262
- 0.258
- 0.229
- 0.37
- 0.249
- 0.259
- 0.234
train_loss:
- 2.217
- 2.981
- 2.323
- 2.685
- 1.756
- 2.496
- 1.617
- 1.981
- 1.539
- 1.487
- 1.499
- 1.467
- 1.381
- 2.088
- 1.382
- 1.32
- 1.583
- 1.644
- 1.238
- 1.561
- 1.784
- 1.468
- 1.188
- 1.15
- 1.142
- 1.106
- 0.803
- 1.032
- 0.755
- 1.302
- 1.286
- 1.254
- 0.962
- 1.218
- 1.167
- 0.959
- 1.124
- 1.088
- 1.057
- 1.288
- 0.852
- 0.994
- 0.991
- 0.954
- 0.754
- 0.765
- 1.108
- 0.749
- 0.895
- 0.567
- 0.833
- 1.011
- 0.806
- 0.958
- 0.935
- 0.947
- 0.744
- 0.598
- 0.734
- 0.464
- 0.718
- 0.598
- 0.554
- 0.427
- 0.636
- 0.518
- 0.533
- 0.636
- 0.383
- 0.731
- 0.495
- 0.581
- 0.555
- 0.484
- 0.649
- 0.623
- 0.545
- 0.452
- 0.315
- 0.519
- 0.498
- 0.469
- 0.477
- 0.448
- 0.479
- 0.376
- 0.442
- 0.443
- 0.414
- 0.345
- 0.317
- 0.316
- 0.331
- 0.312
- 0.38
- 0.321
- 0.251
- 0.359
- 0.358
- 0.293
unequal: 0
verbose: 1
