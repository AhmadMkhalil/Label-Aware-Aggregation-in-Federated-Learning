avg_train_accuracy: 0.164
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0156
- 0.0793
- 0.0911
- 0.0841
- 0.1068
- 0.1169
- 0.1413
- 0.1476
- 0.1523
- 0.1573
- 0.1695
- 0.1734
- 0.1779
- 0.1844
- 0.1866
- 0.1825
- 0.1958
- 0.1977
- 0.2018
- 0.2023
- 0.2068
- 0.2055
- 0.2112
- 0.2158
- 0.2197
- 0.223
- 0.2205
- 0.2226
- 0.2257
- 0.2227
- 0.2283
- 0.2271
- 0.2294
- 0.2313
- 0.2316
- 0.2403
- 0.2367
- 0.2416
- 0.2408
- 0.2401
- 0.2337
- 0.244
- 0.2316
- 0.2415
- 0.2452
- 0.2507
- 0.2459
- 0.2483
- 0.2488
- 0.2563
- 0.2592
- 0.2566
- 0.2594
- 0.263
- 0.2599
- 0.2531
- 0.2638
- 0.2609
- 0.2662
- 0.2614
- 0.2609
- 0.2584
- 0.2594
- 0.2509
- 0.2608
- 0.2649
- 0.261
- 0.2666
- 0.2736
- 0.263
- 0.2521
- 0.2688
- 0.2721
- 0.2677
- 0.2697
- 0.2705
- 0.2774
- 0.2707
- 0.2707
- 0.2739
- 0.2775
- 0.2776
- 0.2782
- 0.27
- 0.2776
- 0.2794
- 0.2722
- 0.2693
- 0.2744
- 0.282
- 0.2797
- 0.2839
- 0.2769
- 0.2782
- 0.2834
- 0.2831
- 0.278
- 0.2823
- 0.2815
- 0.2846
test_loss_list:
- 1.8577718544006347
- 1.706667618751526
- 1.6597437572479248
- 1.6433215045928955
- 1.6024183678627013
- 1.569938600063324
- 1.5320005774497987
- 1.5136882758140564
- 1.4885820841789246
- 1.4793479609489442
- 1.4599539923667908
- 1.4432445287704467
- 1.428863663673401
- 1.4200541615486144
- 1.4082272529602051
- 1.4143125343322753
- 1.389077045917511
- 1.382350776195526
- 1.3726193594932556
- 1.3616051602363586
- 1.3594285893440246
- 1.3633665704727174
- 1.3556345772743226
- 1.3484181427955628
- 1.332816116809845
- 1.3325496006011963
- 1.3251274824142456
- 1.3210500645637513
- 1.31443443775177
- 1.3141346669197083
- 1.3015918493270875
- 1.3051172065734864
- 1.303299412727356
- 1.2968627572059632
- 1.292768120765686
- 1.2761284017562866
- 1.2810105228424071
- 1.2793305468559266
- 1.2755854940414428
- 1.2792773032188416
- 1.2971999740600586
- 1.2735071468353272
- 1.29903653383255
- 1.2739005517959594
- 1.2642980766296388
- 1.2594886660575866
- 1.2609929704666138
- 1.2613238668441773
- 1.2545828413963318
- 1.2464365005493163
- 1.243573875427246
- 1.2375016355514525
- 1.239703824520111
- 1.238226420879364
- 1.2323907041549682
- 1.248377480506897
- 1.2344857120513917
- 1.2405078625679016
- 1.2243805074691771
- 1.2339541625976562
- 1.2291160559654235
- 1.2392447924613952
- 1.2359464263916016
- 1.2538346862792968
- 1.2384914302825927
- 1.2238407278060912
- 1.2300458669662475
- 1.2232112956047059
- 1.2158882474899293
- 1.235566761493683
- 1.257502362728119
- 1.218473243713379
- 1.2207422399520873
- 1.2262900018692016
- 1.2182427644729614
- 1.2252414989471436
- 1.2046452260017395
- 1.223193724155426
- 1.2282104110717773
- 1.2161541867256165
- 1.2089204692840576
- 1.2076859021186828
- 1.2066696429252624
- 1.2295225429534913
- 1.209838707447052
- 1.2054403138160705
- 1.2267966890335082
- 1.23023503780365
- 1.2135552287101745
- 1.2047017550468444
- 1.2069437384605408
- 1.2001772332191467
- 1.2217589020729065
- 1.2158274626731873
- 1.2058109331130982
- 1.2010952758789062
- 1.2052562618255616
- 1.2014061665534974
- 1.2069648456573487
- 1.2088778138160705
train_accuracy:
- 0.0
- 0.062
- 0.084
- 0.0
- 0.157
- 0.015
- 0.163
- 0.005
- 0.003
- 0.256
- 0.151
- 0.008
- 0.192
- 0.075
- 0.159
- 0.139
- 0.085
- 0.235
- 0.177
- 0.11
- 0.122
- 0.18
- 0.232
- 0.2
- 0.001
- 0.04
- 0.027
- 0.048
- 0.204
- 0.287
- 0.188
- 0.204
- 0.212
- 0.068
- 0.244
- 0.169
- 0.042
- 0.078
- 0.218
- 0.146
- 0.122
- 0.176
- 0.31
- 0.298
- 0.214
- 0.284
- 0.185
- 0.206
- 0.218
- 0.094
- 0.119
- 0.289
- 0.068
- 0.255
- 0.055
- 0.175
- 0.237
- 0.16
- 0.057
- 0.134
- 0.091
- 0.277
- 0.208
- 0.165
- 0.226
- 0.236
- 0.322
- 0.03
- 0.274
- 0.301
- 0.216
- 0.153
- 0.101
- 0.154
- 0.231
- 0.312
- 0.247
- 0.243
- 0.226
- 0.335
- 0.289
- 0.332
- 0.031
- 0.212
- 0.261
- 0.113
- 0.291
- 0.307
- 0.209
- 0.264
- 0.256
- 0.249
- 0.278
- 0.218
- 0.331
- 0.112
- 0.245
- 0.175
- 0.3
- 0.164
train_loss:
- 2.157
- 2.983
- 1.835
- 1.305
- 1.724
- 1.668
- 2.44
- 1.964
- 1.532
- 1.454
- 2.197
- 1.407
- 1.749
- 1.324
- 1.684
- 0.975
- 1.593
- 1.58
- 1.525
- 1.496
- 1.479
- 1.124
- 1.386
- 1.382
- 1.372
- 1.041
- 1.584
- 1.262
- 1.233
- 0.969
- 0.956
- 0.93
- 1.407
- 0.905
- 0.882
- 1.099
- 1.079
- 0.814
- 0.832
- 0.815
- 0.592
- 0.814
- 0.554
- 0.771
- 0.749
- 0.757
- 0.725
- 0.725
- 0.903
- 0.694
- 0.869
- 0.849
- 0.838
- 0.816
- 0.798
- 0.46
- 0.92
- 0.768
- 0.748
- 0.577
- 0.563
- 0.54
- 0.558
- 0.404
- 0.514
- 0.678
- 0.523
- 0.635
- 0.626
- 0.369
- 0.338
- 0.596
- 0.6
- 0.478
- 0.56
- 0.425
- 0.559
- 0.447
- 0.439
- 0.418
- 0.503
- 0.498
- 0.496
- 0.292
- 0.553
- 0.474
- 0.282
- 0.357
- 0.383
- 0.431
- 0.41
- 0.431
- 0.263
- 0.341
- 0.401
- 0.389
- 0.322
- 0.388
- 0.438
- 0.377
unequal: 0
verbose: 1
