avg_train_accuracy: 0.258
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0178
- 0.0566
- 0.0917
- 0.0994
- 0.1114
- 0.1146
- 0.1309
- 0.1467
- 0.1522
- 0.1564
- 0.1566
- 0.1612
- 0.1725
- 0.1752
- 0.1776
- 0.1777
- 0.1891
- 0.1886
- 0.1938
- 0.1954
- 0.1975
- 0.1985
- 0.2109
- 0.2078
- 0.2136
- 0.2088
- 0.2165
- 0.2184
- 0.2163
- 0.21
- 0.2165
- 0.2082
- 0.2201
- 0.2258
- 0.2226
- 0.2346
- 0.2347
- 0.2337
- 0.2334
- 0.2386
- 0.2348
- 0.2372
- 0.243
- 0.241
- 0.2447
- 0.2451
- 0.2484
- 0.2487
- 0.2468
- 0.2494
- 0.2505
- 0.2532
- 0.2497
- 0.2518
- 0.2535
- 0.2531
- 0.2609
- 0.2434
- 0.2549
- 0.2519
- 0.2546
- 0.2591
- 0.2599
- 0.2619
- 0.2636
- 0.266
- 0.2612
- 0.2593
- 0.2588
- 0.2694
- 0.2517
- 0.2649
- 0.2643
- 0.2634
- 0.2622
- 0.2654
- 0.2696
- 0.2657
- 0.2655
- 0.2667
- 0.2698
- 0.2536
- 0.2581
- 0.2682
- 0.2688
- 0.2639
- 0.2654
- 0.2651
- 0.2738
- 0.2706
- 0.2647
- 0.2568
- 0.2719
- 0.2715
- 0.267
- 0.2685
- 0.2743
- 0.2684
- 0.2661
- 0.2749
test_loss_list:
- 1.8375386905670166
- 1.7326243591308594
- 1.663405668735504
- 1.626533818244934
- 1.592892062664032
- 1.5760573387145995
- 1.5354292058944703
- 1.5110217976570128
- 1.4971262121200561
- 1.4792264127731323
- 1.4706651782989502
- 1.4603759145736694
- 1.4420300436019897
- 1.4295047473907472
- 1.4208384990692138
- 1.4198335886001587
- 1.3973290848731994
- 1.3938555121421814
- 1.3860041975975037
- 1.3769532370567321
- 1.3744413590431213
- 1.3694904804229737
- 1.3586256980895997
- 1.3585122179985047
- 1.3471087050437927
- 1.3499234008789063
- 1.3325983500480652
- 1.32065110206604
- 1.3236569714546205
- 1.34335116147995
- 1.3221861386299134
- 1.3415256333351135
- 1.3179413390159607
- 1.3016899061203002
- 1.3080697393417358
- 1.2887558937072754
- 1.2913440704345702
- 1.2916794037818908
- 1.2909128546714783
- 1.2881119775772094
- 1.2832661652565003
- 1.2799610686302185
- 1.2798399662971496
- 1.2773610830307007
- 1.2693447804450988
- 1.2665675640106202
- 1.260464608669281
- 1.261567437648773
- 1.2734315967559815
- 1.2657045817375183
- 1.2567185044288636
- 1.2470612931251526
- 1.2536511778831483
- 1.2498494935035707
- 1.250794644355774
- 1.2541375946998596
- 1.2530168175697327
- 1.2610135865211487
- 1.2489882111549377
- 1.2556690645217896
- 1.255434639453888
- 1.2406507587432862
- 1.2350878858566283
- 1.2391423416137695
- 1.2362693786621093
- 1.2434560012817384
- 1.2399062371253968
- 1.2372568893432616
- 1.24316326379776
- 1.2369515299797058
- 1.2606065917015075
- 1.2342716574668884
- 1.2384923100471497
- 1.2440309453010558
- 1.2432823872566223
- 1.2386241412162782
- 1.2349361443519593
- 1.2356989407539367
- 1.237864785194397
- 1.2338261699676514
- 1.2333604741096496
- 1.2642186403274536
- 1.249746618270874
- 1.2311996269226073
- 1.2366303181648255
- 1.241777436733246
- 1.2438326644897462
- 1.2437557697296142
- 1.2329362559318542
- 1.2386534714698791
- 1.2419537210464477
- 1.2654552459716797
- 1.2269026374816894
- 1.238155107498169
- 1.2402478313446046
- 1.2467254996299744
- 1.237141261100769
- 1.2444872307777404
- 1.2475964117050171
- 1.2289608478546143
train_accuracy:
- 0.018
- 0.057
- 0.015
- 0.081
- 0.012
- 0.103
- 0.131
- 0.021
- 0.135
- 0.014
- 0.069
- 0.017
- 0.15
- 0.164
- 0.16
- 0.108
- 0.203
- 0.172
- 0.174
- 0.057
- 0.21
- 0.163
- 0.181
- 0.218
- 0.204
- 0.107
- 0.186
- 0.02
- 0.128
- 0.162
- 0.188
- 0.287
- 0.158
- 0.202
- 0.206
- 0.212
- 0.074
- 0.26
- 0.268
- 0.049
- 0.264
- 0.251
- 0.233
- 0.26
- 0.049
- 0.242
- 0.119
- 0.043
- 0.273
- 0.242
- 0.237
- 0.057
- 0.232
- 0.072
- 0.259
- 0.173
- 0.068
- 0.087
- 0.046
- 0.074
- 0.247
- 0.12
- 0.028
- 0.268
- 0.032
- 0.282
- 0.295
- 0.052
- 0.098
- 0.1
- 0.081
- 0.232
- 0.272
- 0.252
- 0.323
- 0.231
- 0.184
- 0.281
- 0.192
- 0.25
- 0.236
- 0.221
- 0.26
- 0.189
- 0.275
- 0.247
- 0.323
- 0.108
- 0.214
- 0.282
- 0.253
- 0.168
- 0.267
- 0.157
- 0.29
- 0.281
- 0.284
- 0.289
- 0.223
- 0.258
train_loss:
- 2.736
- 1.998
- 2.374
- 1.799
- 1.763
- 1.69
- 2.043
- 2.012
- 1.935
- 1.494
- 1.458
- 1.432
- 1.77
- 1.374
- 1.332
- 1.286
- 1.643
- 1.25
- 1.544
- 1.517
- 1.191
- 1.17
- 1.745
- 1.396
- 1.378
- 1.325
- 1.349
- 1.292
- 0.983
- 0.712
- 0.983
- 0.731
- 0.944
- 1.167
- 0.923
- 1.132
- 1.072
- 0.876
- 0.856
- 1.239
- 0.833
- 0.785
- 1.166
- 0.959
- 0.784
- 0.928
- 0.918
- 0.912
- 1.044
- 0.849
- 0.7
- 0.826
- 0.634
- 0.772
- 0.767
- 0.611
- 0.896
- 0.465
- 0.85
- 0.547
- 0.698
- 0.675
- 0.648
- 0.662
- 0.644
- 0.735
- 0.61
- 0.49
- 0.474
- 0.582
- 0.351
- 0.565
- 0.536
- 0.45
- 0.413
- 0.421
- 0.513
- 0.492
- 0.399
- 0.489
- 0.393
- 0.304
- 0.38
- 0.447
- 0.435
- 0.347
- 0.338
- 0.334
- 0.415
- 0.426
- 0.359
- 0.259
- 0.464
- 0.315
- 0.317
- 0.293
- 0.358
- 0.287
- 0.299
- 0.413
unequal: 0
verbose: 1
