avg_train_accuracy: 0.077
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0161
- 0.0773
- 0.0953
- 0.1102
- 0.118
- 0.1271
- 0.1313
- 0.1482
- 0.1383
- 0.1521
- 0.1618
- 0.1557
- 0.1705
- 0.1727
- 0.1786
- 0.1887
- 0.1881
- 0.1898
- 0.1969
- 0.194
- 0.1971
- 0.2045
- 0.2036
- 0.2057
- 0.2089
- 0.2136
- 0.2143
- 0.2165
- 0.2168
- 0.2179
- 0.2211
- 0.2228
- 0.2222
- 0.2214
- 0.2272
- 0.2292
- 0.227
- 0.2298
- 0.2327
- 0.236
- 0.2338
- 0.2345
- 0.2382
- 0.2378
- 0.2359
- 0.2283
- 0.2364
- 0.2464
- 0.2425
- 0.249
- 0.2498
- 0.2491
- 0.2485
- 0.2488
- 0.2413
- 0.2445
- 0.2483
- 0.2475
- 0.2511
- 0.2402
- 0.2485
- 0.2518
- 0.2542
- 0.2583
- 0.2529
- 0.2454
- 0.2636
- 0.2544
- 0.264
- 0.2568
- 0.2582
- 0.2593
- 0.2604
- 0.2619
- 0.2659
- 0.2575
- 0.2619
- 0.2612
- 0.2679
- 0.267
- 0.2665
- 0.2654
- 0.2651
- 0.2656
- 0.2645
- 0.265
- 0.2642
- 0.2702
- 0.271
- 0.2714
- 0.2673
- 0.274
- 0.2759
- 0.2695
- 0.2673
- 0.269
- 0.2687
- 0.2746
- 0.2739
- 0.2728
test_loss_list:
- 1.870129532814026
- 1.711712441444397
- 1.6458061242103577
- 1.6046691060066223
- 1.5821207523345948
- 1.5594240522384644
- 1.5412842059135436
- 1.5150033402442933
- 1.5198014497756958
- 1.4968162178993225
- 1.4712734174728395
- 1.4821864366531372
- 1.446787395477295
- 1.442614858150482
- 1.432603120803833
- 1.4168488144874574
- 1.4120144820213318
- 1.4040020060539247
- 1.4005770897865295
- 1.3858806562423707
- 1.3875689172744752
- 1.3724034595489503
- 1.3670563840866088
- 1.3666679811477662
- 1.360656487941742
- 1.3489599180221559
- 1.3440957403182983
- 1.3384600925445556
- 1.335863618850708
- 1.339946630001068
- 1.3278942608833313
- 1.3333099818229674
- 1.3241293168067931
- 1.3305042171478272
- 1.320333731174469
- 1.3182337713241576
- 1.3126224637031556
- 1.3133999514579773
- 1.3042198944091796
- 1.2984561944007873
- 1.3081543135643006
- 1.2963370633125306
- 1.2931564664840698
- 1.2881791162490845
- 1.297609052658081
- 1.310065062046051
- 1.2930611538887025
- 1.2711547350883483
- 1.2772753524780274
- 1.267484996318817
- 1.2698008513450623
- 1.2761400842666626
- 1.2738778400421142
- 1.2721920680999756
- 1.2840006566047668
- 1.2781499338150024
- 1.265980246067047
- 1.2719378399848937
- 1.2647496008872985
- 1.287675940990448
- 1.268885111808777
- 1.2559766006469726
- 1.2574553990364075
- 1.2484347057342529
- 1.255150556564331
- 1.2783303666114807
- 1.2420874261856079
- 1.2515452361106874
- 1.2408067440986634
- 1.2512821292877196
- 1.2558315587043762
- 1.249546468257904
- 1.2448384618759156
- 1.2557818913459777
- 1.2380792808532715
- 1.2581956458091736
- 1.2505164527893067
- 1.2569166684150697
- 1.2356652998924256
- 1.2337516641616821
- 1.2449027633666991
- 1.2441742491722108
- 1.2491342043876648
- 1.238657534122467
- 1.2474230217933655
- 1.2546281218528748
- 1.2550056767463684
- 1.2297248482704162
- 1.230514976978302
- 1.2364010143280029
- 1.244553143978119
- 1.2404949522018434
- 1.2374618268013
- 1.24842054605484
- 1.2529144072532654
- 1.2505391907691956
- 1.2482287549972535
- 1.2276036310195924
- 1.2326315641403198
- 1.2335524773597717
train_accuracy:
- 0.017
- 0.007
- 0.013
- 0.118
- 0.109
- 0.151
- 0.07
- 0.134
- 0.036
- 0.02
- 0.013
- 0.044
- 0.148
- 0.003
- 0.192
- 0.087
- 0.199
- 0.168
- 0.021
- 0.188
- 0.184
- 0.215
- 0.197
- 0.191
- 0.056
- 0.072
- 0.212
- 0.143
- 0.062
- 0.061
- 0.217
- 0.212
- 0.248
- 0.226
- 0.247
- 0.246
- 0.239
- 0.09
- 0.101
- 0.249
- 0.237
- 0.047
- 0.282
- 0.27
- 0.298
- 0.068
- 0.174
- 0.101
- 0.097
- 0.2
- 0.243
- 0.135
- 0.254
- 0.294
- 0.239
- 0.064
- 0.28
- 0.23
- 0.032
- 0.237
- 0.281
- 0.273
- 0.265
- 0.285
- 0.059
- 0.166
- 0.242
- 0.246
- 0.279
- 0.28
- 0.247
- 0.302
- 0.073
- 0.071
- 0.321
- 0.265
- 0.285
- 0.072
- 0.049
- 0.285
- 0.269
- 0.019
- 0.063
- 0.267
- 0.279
- 0.193
- 0.163
- 0.317
- 0.3
- 0.291
- 0.278
- 0.295
- 0.298
- 0.189
- 0.215
- 0.28
- 0.346
- 0.069
- 0.125
- 0.077
train_loss:
- 2.134
- 2.967
- 2.345
- 2.217
- 1.718
- 1.658
- 1.618
- 1.971
- 1.146
- 1.479
- 1.833
- 1.052
- 1.827
- 1.72
- 1.695
- 1.364
- 1.639
- 1.611
- 1.899
- 1.224
- 1.493
- 1.497
- 1.151
- 1.125
- 1.398
- 1.116
- 1.34
- 1.057
- 1.286
- 0.991
- 1.251
- 0.979
- 0.952
- 0.917
- 1.132
- 1.155
- 0.903
- 0.844
- 0.876
- 1.048
- 0.836
- 1.032
- 1.233
- 0.805
- 0.792
- 0.562
- 0.774
- 0.938
- 0.712
- 0.874
- 0.892
- 0.664
- 0.845
- 0.86
- 0.498
- 0.628
- 0.785
- 0.759
- 0.605
- 0.442
- 0.591
- 0.732
- 0.561
- 0.863
- 0.58
- 0.402
- 0.678
- 0.56
- 0.786
- 0.535
- 0.471
- 0.621
- 0.599
- 0.686
- 0.563
- 0.351
- 0.664
- 0.529
- 0.423
- 0.512
- 0.504
- 0.595
- 0.473
- 0.369
- 0.403
- 0.36
- 0.359
- 0.48
- 0.449
- 0.426
- 0.361
- 0.403
- 0.431
- 0.335
- 0.314
- 0.379
- 0.371
- 0.381
- 0.396
- 0.374
unequal: 0
verbose: 1
