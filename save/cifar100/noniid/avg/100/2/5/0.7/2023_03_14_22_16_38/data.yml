avg_train_accuracy: 0.239
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0245
- 0.0491
- 0.0559
- 0.0918
- 0.1077
- 0.1153
- 0.1222
- 0.1302
- 0.1421
- 0.1541
- 0.16
- 0.1707
- 0.1814
- 0.1816
- 0.1846
- 0.1881
- 0.1936
- 0.1873
- 0.204
- 0.2068
- 0.2095
- 0.2084
- 0.2086
- 0.2109
- 0.2149
- 0.2201
- 0.2229
- 0.2241
- 0.2269
- 0.2305
- 0.2324
- 0.228
- 0.2358
- 0.2374
- 0.2299
- 0.2386
- 0.2414
- 0.2437
- 0.2461
- 0.2419
- 0.2419
- 0.2461
- 0.2388
- 0.2453
- 0.2473
- 0.2526
- 0.2552
- 0.2545
- 0.2516
- 0.2574
- 0.2561
- 0.2582
- 0.2588
- 0.2623
- 0.2587
- 0.2639
- 0.2511
- 0.2658
- 0.2631
- 0.2666
- 0.2672
- 0.2662
- 0.2673
- 0.2682
- 0.2727
- 0.2686
- 0.272
- 0.2694
- 0.2712
- 0.2699
- 0.2746
- 0.2739
- 0.2774
- 0.2653
- 0.275
- 0.2728
- 0.2799
- 0.2651
- 0.2697
- 0.2782
- 0.2756
- 0.273
- 0.2659
- 0.2771
- 0.2809
- 0.2814
- 0.2769
- 0.279
- 0.2758
- 0.2795
- 0.2787
- 0.28
- 0.2817
- 0.284
- 0.2839
- 0.2836
- 0.2814
- 0.2797
- 0.2806
- 0.2823
test_loss_list:
- 1.8549285078048705
- 1.7536715841293335
- 1.7297817373275757
- 1.6416491770744324
- 1.6069390177726746
- 1.5801700854301453
- 1.5581119084358215
- 1.535824820995331
- 1.5055978727340698
- 1.486840434074402
- 1.476937961578369
- 1.4504950070381164
- 1.4460468482971192
- 1.424043560028076
- 1.4064383935928344
- 1.4037459874153138
- 1.3967350339889526
- 1.3971602654457091
- 1.372374255657196
- 1.3664106798171998
- 1.3619173002243041
- 1.3537330842018127
- 1.3521205496788025
- 1.3496553373336793
- 1.3421495127677918
- 1.3343678855895995
- 1.3423520159721374
- 1.323495376110077
- 1.328839795589447
- 1.326510865688324
- 1.3129261875152587
- 1.307997829914093
- 1.2948344802856446
- 1.295512306690216
- 1.3023109340667725
- 1.2859155893325807
- 1.2776024794578553
- 1.2794772648811341
- 1.2772833490371704
- 1.280823471546173
- 1.2839470624923706
- 1.2708185195922852
- 1.2857666683197022
- 1.2711052370071412
- 1.2663014578819274
- 1.2618691849708557
- 1.2681923222541809
- 1.2621695017814636
- 1.2673866033554078
- 1.24637197971344
- 1.246763184070587
- 1.245009799003601
- 1.2469830369949342
- 1.2456954646110534
- 1.251038703918457
- 1.2406900858879089
- 1.2583487010002137
- 1.2372926545143128
- 1.2352226495742797
- 1.2352473831176758
- 1.2331867027282715
- 1.2399793100357055
- 1.2372248768806458
- 1.2368151807785035
- 1.2272811508178711
- 1.2323758220672607
- 1.2321485114097595
- 1.23743679523468
- 1.245235996246338
- 1.2383324313163757
- 1.234974422454834
- 1.2366564273834229
- 1.2222645711898803
- 1.2442294549942017
- 1.2175927424430848
- 1.2332259488105775
- 1.2172504353523255
- 1.2490067529678344
- 1.2392849612236023
- 1.2181906270980836
- 1.2250443935394286
- 1.2315387678146363
- 1.2592488765716552
- 1.2223925638198851
- 1.2186293005943298
- 1.2230747151374817
- 1.2213571739196778
- 1.2164044404029846
- 1.2315509867668153
- 1.218796329498291
- 1.2240214586257934
- 1.217069272994995
- 1.2181538939476013
- 1.2165801072120666
- 1.2173953533172608
- 1.2178748965263366
- 1.225050799846649
- 1.2343156218528748
- 1.2241906094551087
- 1.22408118724823
train_accuracy:
- 0.006
- 0.029
- 0.057
- 0.19
- 0.04
- 0.293
- 0.316
- 0.231
- 0.149
- 0.147
- 0.018
- 0.17
- 0.181
- 0.174
- 0.088
- 0.198
- 0.175
- 0.159
- 0.232
- 0.219
- 0.051
- 0.206
- 0.272
- 0.013
- 0.078
- 0.232
- 0.243
- 0.01
- 0.234
- 0.223
- 0.098
- 0.056
- 0.242
- 0.056
- 0.164
- 0.25
- 0.032
- 0.096
- 0.21
- 0.312
- 0.281
- 0.092
- 0.204
- 0.211
- 0.292
- 0.243
- 0.218
- 0.249
- 0.081
- 0.264
- 0.058
- 0.274
- 0.18
- 0.272
- 0.231
- 0.217
- 0.028
- 0.291
- 0.133
- 0.083
- 0.15
- 0.275
- 0.155
- 0.245
- 0.287
- 0.292
- 0.221
- 0.08
- 0.055
- 0.287
- 0.091
- 0.22
- 0.006
- 0.267
- 0.059
- 0.161
- 0.234
- 0.198
- 0.216
- 0.304
- 0.318
- 0.253
- 0.226
- 0.298
- 0.269
- 0.243
- 0.294
- 0.063
- 0.241
- 0.254
- 0.26
- 0.167
- 0.326
- 0.09
- 0.295
- 0.297
- 0.092
- 0.126
- 0.108
- 0.239
train_loss:
- 2.129
- 1.95
- 1.363
- 2.253
- 1.732
- 1.646
- 1.62
- 1.591
- 1.939
- 1.875
- 2.214
- 1.827
- 2.108
- 1.707
- 1.313
- 1.966
- 1.595
- 0.928
- 1.531
- 1.493
- 1.432
- 1.422
- 1.106
- 1.061
- 1.041
- 1.603
- 1.529
- 1.249
- 1.468
- 1.459
- 1.209
- 0.689
- 1.122
- 1.088
- 0.638
- 1.055
- 1.083
- 0.85
- 0.817
- 0.793
- 0.783
- 0.962
- 0.578
- 0.765
- 0.72
- 1.1
- 0.876
- 0.877
- 0.657
- 0.863
- 0.817
- 0.66
- 0.633
- 0.637
- 0.605
- 0.758
- 0.456
- 0.715
- 0.59
- 0.687
- 0.58
- 0.545
- 0.53
- 0.781
- 0.66
- 0.514
- 0.737
- 0.595
- 0.703
- 0.474
- 0.557
- 0.653
- 0.461
- 0.343
- 0.638
- 0.342
- 0.506
- 0.311
- 0.401
- 0.576
- 0.382
- 0.365
- 0.284
- 0.461
- 0.446
- 0.437
- 0.355
- 0.434
- 0.325
- 0.411
- 0.39
- 0.334
- 0.456
- 0.384
- 0.373
- 0.311
- 0.349
- 0.274
- 0.349
- 0.286
unequal: 0
verbose: 1
