avg_train_accuracy: 0.291
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0207
- 0.0642
- 0.0861
- 0.1018
- 0.1191
- 0.1317
- 0.1287
- 0.1464
- 0.1538
- 0.1624
- 0.1662
- 0.1691
- 0.1713
- 0.1807
- 0.1866
- 0.1874
- 0.1931
- 0.1897
- 0.1818
- 0.1948
- 0.2031
- 0.2068
- 0.2032
- 0.2052
- 0.2108
- 0.2162
- 0.2149
- 0.2224
- 0.2191
- 0.2248
- 0.2257
- 0.2232
- 0.2296
- 0.2292
- 0.2306
- 0.2266
- 0.2293
- 0.2328
- 0.2387
- 0.2392
- 0.2436
- 0.2417
- 0.2408
- 0.2402
- 0.2512
- 0.2404
- 0.2471
- 0.2505
- 0.2444
- 0.25
- 0.2499
- 0.2507
- 0.2527
- 0.251
- 0.2528
- 0.2562
- 0.2571
- 0.253
- 0.2592
- 0.2571
- 0.2592
- 0.2566
- 0.254
- 0.2549
- 0.2557
- 0.257
- 0.2626
- 0.2632
- 0.2581
- 0.2515
- 0.2633
- 0.2609
- 0.2568
- 0.2654
- 0.2663
- 0.2694
- 0.2677
- 0.2691
- 0.2674
- 0.266
- 0.2672
- 0.2646
- 0.2662
- 0.2639
- 0.2633
- 0.2702
- 0.2684
- 0.2674
- 0.2666
- 0.2729
- 0.2722
- 0.27
- 0.2727
- 0.272
- 0.2701
- 0.2723
- 0.2686
- 0.2685
- 0.2695
- 0.2721
test_loss_list:
- 1.858800902366638
- 1.7290581417083741
- 1.6679931449890137
- 1.6207094073295594
- 1.5882102060317993
- 1.549891881942749
- 1.5333966636657714
- 1.5112542033195495
- 1.4841599154472351
- 1.4738614964485168
- 1.46045640707016
- 1.4530758905410766
- 1.4484395956993104
- 1.4228164911270142
- 1.420463469028473
- 1.4019696760177611
- 1.403368079662323
- 1.3943879365921021
- 1.4118775892257691
- 1.3763045263290405
- 1.3602186441421509
- 1.3609315824508668
- 1.3607426524162292
- 1.3550753593444824
- 1.3454138445854187
- 1.334561939239502
- 1.3353764820098877
- 1.3200750041007996
- 1.327921748161316
- 1.3123513054847717
- 1.3201059818267822
- 1.3100216174125672
- 1.3015332198143006
- 1.3015970444679261
- 1.3073338961601257
- 1.298364791870117
- 1.3043575358390809
- 1.2929049682617189
- 1.2885222721099854
- 1.2937542295455933
- 1.280108094215393
- 1.2877007150650024
- 1.2733860945701598
- 1.2766369843482972
- 1.263893618583679
- 1.2750808334350585
- 1.2621897673606872
- 1.2576755905151367
- 1.2634433507919312
- 1.2578809261322021
- 1.264425404071808
- 1.2477646970748901
- 1.2531644535064697
- 1.262248694896698
- 1.2511147332191468
- 1.2558229780197143
- 1.2424357843399048
- 1.2500339698791505
- 1.2443212103843688
- 1.2524597930908203
- 1.2453713893890381
- 1.2528106451034546
- 1.2473271894454956
- 1.2532057714462281
- 1.253069839477539
- 1.2426326060295105
- 1.2320685005187988
- 1.2324365782737732
- 1.2408279585838318
- 1.2671118068695069
- 1.234886863231659
- 1.2444307446479796
- 1.2470803236961365
- 1.2276819562911987
- 1.2288636088371276
- 1.2202354049682618
- 1.228253583908081
- 1.2251871085166932
- 1.228934862613678
- 1.229661078453064
- 1.229184195995331
- 1.2371446585655212
- 1.234317536354065
- 1.2364844512939452
- 1.242551202774048
- 1.2163347673416138
- 1.2297800445556641
- 1.2302832317352295
- 1.2373050332069397
- 1.224398672580719
- 1.224119963645935
- 1.2301259875297545
- 1.2241514539718628
- 1.22905091047287
- 1.2352068996429444
- 1.218696095943451
- 1.2368266129493712
- 1.2365006709098816
- 1.242841410636902
- 1.2329584574699402
train_accuracy:
- 0.0
- 0.007
- 0.064
- 0.108
- 0.112
- 0.131
- 0.013
- 0.137
- 0.147
- 0.033
- 0.199
- 0.186
- 0.058
- 0.218
- 0.03
- 0.217
- 0.021
- 0.163
- 0.1
- 0.109
- 0.192
- 0.056
- 0.234
- 0.166
- 0.208
- 0.226
- 0.222
- 0.018
- 0.196
- 0.137
- 0.022
- 0.256
- 0.207
- 0.225
- 0.26
- 0.113
- 0.136
- 0.116
- 0.175
- 0.201
- 0.213
- 0.147
- 0.002
- 0.052
- 0.263
- 0.231
- 0.121
- 0.104
- 0.238
- 0.131
- 0.211
- 0.277
- 0.249
- 0.229
- 0.134
- 0.24
- 0.092
- 0.244
- 0.093
- 0.182
- 0.238
- 0.167
- 0.238
- 0.237
- 0.242
- 0.066
- 0.275
- 0.043
- 0.163
- 0.078
- 0.289
- 0.219
- 0.241
- 0.253
- 0.257
- 0.253
- 0.249
- 0.095
- 0.078
- 0.251
- 0.292
- 0.246
- 0.108
- 0.282
- 0.237
- 0.048
- 0.289
- 0.242
- 0.244
- 0.268
- 0.176
- 0.128
- 0.259
- 0.26
- 0.264
- 0.312
- 0.244
- 0.271
- 0.259
- 0.291
train_loss:
- 2.14
- 2.463
- 2.334
- 2.229
- 2.135
- 2.515
- 1.219
- 1.937
- 1.921
- 1.874
- 1.81
- 1.406
- 1.363
- 1.694
- 1.994
- 1.623
- 1.263
- 1.244
- 0.881
- 1.491
- 1.483
- 1.455
- 1.119
- 1.117
- 1.105
- 1.34
- 1.327
- 1.312
- 0.997
- 1.268
- 1.464
- 0.967
- 1.177
- 1.167
- 0.904
- 1.093
- 0.88
- 0.837
- 0.854
- 0.804
- 1.021
- 0.782
- 0.987
- 0.786
- 0.938
- 0.737
- 0.911
- 0.718
- 0.885
- 0.663
- 0.648
- 0.869
- 0.81
- 0.631
- 0.645
- 0.933
- 0.783
- 0.581
- 0.575
- 0.545
- 0.708
- 0.53
- 0.695
- 0.556
- 0.529
- 0.504
- 0.638
- 0.612
- 0.471
- 0.338
- 0.715
- 0.397
- 0.481
- 0.556
- 0.555
- 0.537
- 0.426
- 0.536
- 0.413
- 0.378
- 0.398
- 0.373
- 0.374
- 0.383
- 0.373
- 0.455
- 0.361
- 0.366
- 0.334
- 0.523
- 0.325
- 0.357
- 0.418
- 0.344
- 0.341
- 0.473
- 0.241
- 0.312
- 0.299
- 0.306
unequal: 0
verbose: 1
