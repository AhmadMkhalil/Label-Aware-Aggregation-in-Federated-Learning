avg_train_accuracy: 0.277
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0135
- 0.0398
- 0.0844
- 0.1038
- 0.12
- 0.1112
- 0.1279
- 0.1433
- 0.1515
- 0.1549
- 0.1474
- 0.1419
- 0.1654
- 0.1712
- 0.1761
- 0.1821
- 0.1761
- 0.1889
- 0.1912
- 0.1952
- 0.1975
- 0.2006
- 0.2052
- 0.2029
- 0.2083
- 0.2114
- 0.2114
- 0.209
- 0.2149
- 0.2186
- 0.2251
- 0.2232
- 0.2218
- 0.2246
- 0.2266
- 0.2315
- 0.2324
- 0.2324
- 0.233
- 0.2366
- 0.2388
- 0.2399
- 0.2457
- 0.2425
- 0.2438
- 0.2449
- 0.2458
- 0.2403
- 0.2448
- 0.2458
- 0.2531
- 0.2463
- 0.2518
- 0.2498
- 0.2482
- 0.2572
- 0.2575
- 0.2553
- 0.2535
- 0.2517
- 0.2562
- 0.2604
- 0.2569
- 0.262
- 0.2642
- 0.2532
- 0.2615
- 0.2491
- 0.2675
- 0.2683
- 0.2593
- 0.2653
- 0.2665
- 0.2675
- 0.2709
- 0.2649
- 0.2714
- 0.2682
- 0.2566
- 0.2749
- 0.2667
- 0.2693
- 0.2695
- 0.2592
- 0.2772
- 0.2733
- 0.2696
- 0.2696
- 0.2742
- 0.2742
- 0.274
- 0.2728
- 0.2725
- 0.2797
- 0.2798
- 0.2768
- 0.2754
- 0.2777
- 0.2783
- 0.2758
test_loss_list:
- 1.900069785118103
- 1.7933915758132934
- 1.6762149333953857
- 1.6297904205322267
- 1.5888542437553406
- 1.5742004323005676
- 1.5479010224342347
- 1.5164460563659667
- 1.4902374649047851
- 1.4794528675079346
- 1.4905785369873046
- 1.5013568377494813
- 1.44339191198349
- 1.4329058742523193
- 1.422144229412079
- 1.4132563304901122
- 1.4237780594825744
- 1.3959679174423218
- 1.385362458229065
- 1.3870407962799072
- 1.373430917263031
- 1.3729967093467712
- 1.356919538974762
- 1.3516997265815736
- 1.3457005739212036
- 1.3372182846069336
- 1.336529893875122
- 1.337576868534088
- 1.326510524749756
- 1.3211003279685973
- 1.3104265666007995
- 1.3111649107933045
- 1.3097919464111327
- 1.3051264691352844
- 1.2942995929718017
- 1.2815108251571656
- 1.2827022242546082
- 1.2806264448165894
- 1.2839164566993713
- 1.265944049358368
- 1.2686278343200683
- 1.2611539363861084
- 1.264494743347168
- 1.2637700748443603
- 1.258363962173462
- 1.2731971502304078
- 1.2740949940681459
- 1.2639173340797425
- 1.2612140083312988
- 1.2529806351661683
- 1.2445495557785033
- 1.2503537631034851
- 1.2502724313735962
- 1.2415937995910644
- 1.2570195317268371
- 1.2301988840103149
- 1.240903809070587
- 1.2433988738059998
- 1.2449067115783692
- 1.2477696537971497
- 1.229353322982788
- 1.2283273553848266
- 1.2421113181114196
- 1.2290849685668945
- 1.2315969276428222
- 1.2530446171760559
- 1.2325297975540161
- 1.2657856130599976
- 1.2223658084869384
- 1.232554521560669
- 1.2331869769096375
- 1.2274364614486695
- 1.2276942944526672
- 1.2277368235588073
- 1.2257221603393555
- 1.2343086433410644
- 1.2272822093963622
- 1.2374247789382935
- 1.257535855770111
- 1.214542260169983
- 1.2270894575119018
- 1.2224289298057556
- 1.2299089527130127
- 1.259702684879303
- 1.217862801551819
- 1.2243734288215637
- 1.231440453529358
- 1.2276582407951355
- 1.2162642574310303
- 1.2176319241523743
- 1.2309824156761169
- 1.2287099027633668
- 1.2256446552276612
- 1.2221822381019591
- 1.2124796390533448
- 1.2213450074195862
- 1.2204636025428772
- 1.2188989472389222
- 1.217171106338501
- 1.2375231170654297
train_accuracy:
- 0.195
- 0.229
- 0.08
- 0.091
- 0.118
- 0.001
- 0.126
- 0.036
- 0.138
- 0.165
- 0.02
- 0.113
- 0.173
- 0.035
- 0.064
- 0.006
- 0.252
- 0.114
- 0.179
- 0.186
- 0.007
- 0.028
- 0.208
- 0.18
- 0.065
- 0.09
- 0.176
- 0.218
- 0.03
- 0.158
- 0.241
- 0.235
- 0.255
- 0.196
- 0.204
- 0.243
- 0.248
- 0.181
- 0.019
- 0.052
- 0.197
- 0.264
- 0.269
- 0.046
- 0.166
- 0.21
- 0.281
- 0.017
- 0.213
- 0.263
- 0.075
- 0.271
- 0.172
- 0.277
- 0.225
- 0.123
- 0.247
- 0.242
- 0.085
- 0.285
- 0.303
- 0.102
- 0.268
- 0.257
- 0.288
- 0.29
- 0.342
- 0.204
- 0.14
- 0.302
- 0.274
- 0.032
- 0.083
- 0.224
- 0.182
- 0.12
- 0.291
- 0.184
- 0.123
- 0.195
- 0.143
- 0.228
- 0.237
- 0.306
- 0.23
- 0.243
- 0.122
- 0.307
- 0.298
- 0.31
- 0.261
- 0.13
- 0.027
- 0.137
- 0.11
- 0.237
- 0.263
- 0.283
- 0.219
- 0.277
train_loss:
- 1.632
- 2.013
- 2.889
- 2.702
- 2.176
- 1.256
- 1.624
- 2.369
- 1.943
- 1.494
- 1.071
- 1.044
- 1.754
- 1.733
- 1.678
- 1.328
- 0.947
- 1.589
- 1.56
- 1.195
- 1.192
- 1.16
- 1.443
- 1.127
- 1.392
- 1.354
- 1.078
- 1.022
- 1.028
- 1.268
- 1.233
- 0.968
- 1.443
- 0.918
- 0.908
- 1.13
- 1.094
- 0.859
- 1.299
- 1.054
- 0.845
- 1.009
- 0.987
- 0.95
- 0.961
- 1.109
- 1.082
- 0.548
- 0.683
- 0.672
- 0.864
- 0.657
- 0.675
- 0.795
- 0.631
- 0.775
- 0.585
- 0.732
- 0.719
- 0.597
- 0.709
- 0.7
- 0.57
- 0.66
- 0.666
- 0.374
- 0.52
- 0.377
- 0.757
- 0.736
- 0.506
- 0.477
- 0.466
- 0.571
- 0.535
- 0.553
- 0.626
- 0.431
- 0.315
- 0.514
- 0.4
- 0.485
- 0.391
- 0.282
- 0.569
- 0.369
- 0.364
- 0.371
- 0.447
- 0.427
- 0.363
- 0.479
- 0.405
- 0.469
- 0.333
- 0.383
- 0.308
- 0.377
- 0.372
- 0.275
unequal: 0
verbose: 1
