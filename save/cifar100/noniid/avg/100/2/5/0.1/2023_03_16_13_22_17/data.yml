avg_train_accuracy: 0.279
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0178
- 0.0186
- 0.0645
- 0.0841
- 0.0158
- 0.0172
- 0.1023
- 0.0175
- 0.1206
- 0.0182
- 0.1272
- 0.0186
- 0.1341
- 0.1514
- 0.1573
- 0.1607
- 0.0186
- 0.1643
- 0.1752
- 0.0185
- 0.0178
- 0.173
- 0.0187
- 0.0173
- 0.1751
- 0.1813
- 0.1884
- 0.0185
- 0.0187
- 0.1966
- 0.1971
- 0.1989
- 0.2009
- 0.018
- 0.0183
- 0.1979
- 0.0185
- 0.0183
- 0.2026
- 0.0189
- 0.2099
- 0.2098
- 0.018
- 0.2143
- 0.0182
- 0.2181
- 0.2249
- 0.019
- 0.0188
- 0.2231
- 0.2221
- 0.0182
- 0.23
- 0.0193
- 0.2272
- 0.0197
- 0.225
- 0.0177
- 0.0187
- 0.2308
- 0.2312
- 0.0199
- 0.2359
- 0.0188
- 0.0195
- 0.0187
- 0.0186
- 0.2265
- 0.0193
- 0.0187
- 0.237
- 0.2389
- 0.2394
- 0.2453
- 0.0186
- 0.2449
- 0.2451
- 0.2477
- 0.0194
- 0.0187
- 0.0187
- 0.2444
- 0.2484
- 0.0191
- 0.0197
- 0.0188
- 0.0187
- 0.0194
- 0.2436
- 0.2453
- 0.249
- 0.2518
- 0.2426
- 0.0193
- 0.245
- 0.2499
- 0.0211
- 0.0193
- 0.2569
- 0.2523
test_loss_list:
- 3.3971685695648195
- 4.585729761123657
- 1.7894870138168335
- 1.7337017345428467
- 4.34523530960083
- 4.577982158660888
- 1.701460406780243
- 4.552114324569702
- 1.681544029712677
- 4.3773622226715085
- 1.6779339742660522
- 4.291884260177612
- 1.6387176895141602
- 1.6262137007713318
- 1.5967239689826966
- 1.6014045763015747
- 4.415169811248779
- 1.5652960515022278
- 1.5743744158744812
- 4.550507316589355
- 4.527181606292725
- 1.539722719192505
- 4.216612758636475
- 4.849921293258667
- 1.4980989336967467
- 1.5058055233955383
- 1.5196945929527284
- 4.413161783218384
- 4.314218072891236
- 1.4858942341804504
- 1.5039233374595642
- 1.476411633491516
- 1.4857044911384583
- 4.713967733383178
- 4.234287090301514
- 1.4726847982406617
- 4.346337823867798
- 4.305338144302368
- 1.4451037764549255
- 4.049346876144409
- 1.4419299745559693
- 1.445809998512268
- 4.484709453582764
- 1.4464320349693298
- 4.182427072525025
- 1.4366488862037659
- 1.430534107685089
- 3.934017314910889
- 4.389098711013794
- 1.4225114750862122
- 1.4343832540512085
- 4.153268489837647
- 1.4272050261497498
- 4.120061445236206
- 1.417451992034912
- 4.021509828567505
- 1.4091112947463988
- 4.123513174057007
- 4.324288816452026
- 1.389451069831848
- 1.416608669757843
- 3.853572120666504
- 1.3971525478363036
- 4.301006631851196
- 4.062359371185303
- 4.224955272674561
- 4.35109848022461
- 1.3991251754760743
- 4.036249561309814
- 4.085876998901367
- 1.3809066486358643
- 1.3762061285972595
- 1.373550910949707
- 1.3878017997741698
- 4.097244958877564
- 1.3957764267921449
- 1.3979618048667908
- 1.3952709674835204
- 3.9345082950592043
- 4.1891849327087405
- 4.257028493881226
- 1.3920947408676148
- 1.3838575291633606
- 4.0391021156311036
- 3.9574638843536376
- 4.226176071166992
- 4.20676139831543
- 3.782164659500122
- 1.3329679441452027
- 1.3508529138565064
- 1.3556177401542664
- 1.3582051873207093
- 1.3777800226211547
- 3.847967367172241
- 1.3705043601989746
- 1.3782709765434265
- 3.7328755187988283
- 4.049376678466797
- 1.3476482701301575
- 1.3785469818115235
train_accuracy:
- 0.964
- 0.904
- 0.065
- 0.116
- 0.68
- 0.854
- 0.127
- 0.776
- 0.154
- 0.889
- 0.148
- 0.839
- 0.119
- 0.143
- 0.164
- 0.191
- 0.944
- 0.199
- 0.19
- 0.97
- 0.91
- 0.173
- 0.876
- 0.649
- 0.195
- 0.184
- 0.206
- 0.945
- 0.984
- 0.202
- 0.191
- 0.228
- 0.227
- 0.744
- 0.939
- 0.214
- 0.948
- 0.909
- 0.208
- 0.948
- 0.208
- 0.235
- 0.826
- 0.229
- 0.935
- 0.251
- 0.245
- 0.948
- 0.959
- 0.241
- 0.235
- 0.92
- 0.238
- 0.927
- 0.236
- 0.946
- 0.267
- 0.909
- 0.97
- 0.272
- 0.243
- 0.902
- 0.251
- 0.94
- 0.914
- 0.958
- 0.96
- 0.247
- 0.961
- 0.87
- 0.26
- 0.27
- 0.241
- 0.248
- 0.863
- 0.261
- 0.257
- 0.247
- 0.958
- 0.898
- 0.9
- 0.283
- 0.291
- 0.887
- 0.908
- 0.959
- 0.961
- 0.975
- 0.267
- 0.277
- 0.269
- 0.281
- 0.27
- 0.966
- 0.271
- 0.269
- 0.918
- 0.963
- 0.284
- 0.279
train_loss:
- 0.543
- 0.155
- 4.534
- 3.83
- 0.561
- 0.955
- 3.995
- 0.662
- 3.488
- 0.455
- 3.12
- 0.592
- 3.505
- 3.098
- 3.102
- 2.626
- 0.505
- 3.338
- 2.683
- 0.464
- 0.883
- 3.033
- 0.502
- 0.939
- 2.988
- 2.394
- 2.401
- 0.391
- 0.687
- 2.643
- 1.927
- 2.367
- 2.137
- 0.535
- 0.673
- 2.295
- 0.382
- 0.824
- 2.835
- 0.352
- 2.11
- 1.782
- 0.412
- 2.422
- 0.504
- 1.802
- 1.896
- 0.356
- 0.63
- 2.353
- 1.583
- 0.466
- 1.914
- 0.466
- 1.97
- 0.352
- 1.742
- 0.417
- 0.612
- 1.347
- 1.527
- 0.321
- 1.693
- 0.394
- 0.535
- 0.552
- 0.522
- 1.559
- 0.244
- 0.586
- 1.43
- 1.163
- 1.913
- 1.154
- 0.363
- 1.292
- 1.474
- 0.986
- 0.302
- 0.537
- 0.059
- 1.422
- 1.052
- 0.304
- 0.574
- 0.605
- 0.53
- 0.611
- 1.89
- 0.818
- 1.044
- 0.672
- 1.316
- 0.355
- 1.154
- 1.061
- 0.314
- 0.487
- 0.918
- 0.942
unequal: 0
verbose: 1
