avg_train_accuracy: 0.918
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0362
- 0.0872
- 0.0166
- 0.101
- 0.1143
- 0.0189
- 0.1198
- 0.0192
- 0.0151
- 0.134
- 0.0181
- 0.0194
- 0.1363
- 0.0183
- 0.018
- 0.1477
- 0.0175
- 0.0188
- 0.1464
- 0.1451
- 0.0188
- 0.0182
- 0.0177
- 0.0181
- 0.0185
- 0.0188
- 0.1449
- 0.0194
- 0.1602
- 0.1639
- 0.1714
- 0.1722
- 0.178
- 0.1795
- 0.019
- 0.1907
- 0.1886
- 0.1912
- 0.2021
- 0.0188
- 0.2004
- 0.2052
- 0.2119
- 0.2065
- 0.0185
- 0.0187
- 0.215
- 0.0192
- 0.2026
- 0.0189
- 0.019
- 0.2154
- 0.216
- 0.2165
- 0.0198
- 0.2151
- 0.0192
- 0.0194
- 0.2244
- 0.2248
- 0.2322
- 0.2281
- 0.0179
- 0.019
- 0.0195
- 0.2315
- 0.2261
- 0.0211
- 0.238
- 0.2339
- 0.0203
- 0.2269
- 0.0201
- 0.2388
- 0.2431
- 0.247
- 0.2421
- 0.0189
- 0.2419
- 0.2392
- 0.2353
- 0.2386
- 0.2479
- 0.0213
- 0.2504
- 0.246
- 0.251
- 0.0191
- 0.019
- 0.2529
- 0.2418
- 0.2485
- 0.0192
- 0.0189
- 0.2484
- 0.2592
- 0.0198
- 0.258
- 0.0216
- 0.0192
test_loss_list:
- 1.8223829507827758
- 1.7609255743026733
- 4.687376127243042
- 1.7310528993606566
- 1.7032552790641784
- 4.46606110572815
- 1.705547013282776
- 4.465305871963501
- 4.637034244537354
- 1.6605907845497132
- 4.472676563262939
- 4.419763669967652
- 1.628578884601593
- 4.6748559951782225
- 4.71217080116272
- 1.5985655355453492
- 4.200732231140137
- 4.235374526977539
- 1.581049268245697
- 1.6074269151687621
- 4.2181682109832765
- 4.629906568527222
- 4.905240612030029
- 4.443104963302613
- 4.647621793746948
- 4.635803298950195
- 1.5884877729415894
- 4.054034872055054
- 1.5428393149375916
- 1.5304009056091308
- 1.52731281042099
- 1.5418815231323242
- 1.540946741104126
- 1.546294274330139
- 4.617613134384155
- 1.5079878282546997
- 1.5074478888511658
- 1.518072555065155
- 1.482597451210022
- 4.194971113204956
- 1.4934874153137208
- 1.4821177840232849
- 1.4854073524475098
- 1.4865090155601501
- 4.463446645736695
- 4.301430425643921
- 1.446619019508362
- 4.419838762283325
- 1.4662262415885925
- 4.19105972290039
- 4.363996076583862
- 1.457040421962738
- 1.4755429077148436
- 1.4557020521163941
- 4.050142850875854
- 1.4821594786643981
- 4.095466985702514
- 4.029674396514893
- 1.403064365386963
- 1.4270880889892579
- 1.4193948650360106
- 1.4476145958900453
- 4.224006004333496
- 4.379372453689575
- 4.04234317779541
- 1.4079121732711792
- 1.4202533888816833
- 3.9908585739135742
- 1.3982902264595032
- 1.4244771575927735
- 3.836098804473877
- 1.4213238191604614
- 3.8142278003692627
- 1.4189906024932861
- 1.4053103446960449
- 1.3968731689453124
- 1.4140225315093995
- 4.168727293014526
- 1.412409827709198
- 1.4395504093170166
- 1.4541523337364197
- 1.4368577527999877
- 1.4239633727073668
- 3.8637965011596678
- 1.3999539875984193
- 1.4358551955223084
- 1.4254220557212829
- 4.255590076446533
- 4.290827198028564
- 1.3866756081581115
- 1.423510708808899
- 1.4145096349716186
- 4.143561744689942
- 4.264055910110474
- 1.386032416820526
- 1.3839480257034302
- 4.0226856708526615
- 1.3970407700538636
- 3.7930417537689207
- 4.139220218658448
train_accuracy:
- 0.04
- 0.058
- 0.549
- 0.102
- 0.081
- 0.908
- 0.082
- 0.909
- 0.455
- 0.123
- 0.851
- 0.9
- 0.131
- 0.917
- 0.772
- 0.119
- 0.703
- 0.85
- 0.132
- 0.155
- 0.878
- 0.862
- 0.99
- 0.892
- 0.86
- 0.935
- 0.146
- 0.923
- 0.146
- 0.141
- 0.147
- 0.15
- 0.177
- 0.172
- 0.924
- 0.161
- 0.201
- 0.194
- 0.213
- 0.785
- 0.197
- 0.173
- 0.23
- 0.224
- 0.867
- 0.841
- 0.218
- 0.913
- 0.199
- 0.914
- 0.925
- 0.222
- 0.225
- 0.241
- 0.937
- 0.208
- 0.855
- 0.938
- 0.203
- 0.212
- 0.189
- 0.254
- 0.931
- 0.905
- 0.875
- 0.239
- 0.224
- 0.852
- 0.253
- 0.227
- 0.945
- 0.226
- 0.928
- 0.229
- 0.21
- 0.221
- 0.218
- 0.898
- 0.234
- 0.241
- 0.231
- 0.221
- 0.274
- 0.936
- 0.237
- 0.233
- 0.226
- 0.927
- 0.887
- 0.264
- 0.239
- 0.241
- 0.835
- 0.892
- 0.252
- 0.3
- 0.933
- 0.297
- 0.944
- 0.918
train_loss:
- 4.26
- 3.528
- 0.65
- 4.1
- 3.147
- 0.614
- 3.107
- 0.489
- 0.985
- 3.722
- 0.677
- 0.695
- 3.521
- 0.622
- 0.928
- 3.002
- 0.614
- 0.69
- 3.173
- 2.476
- 0.482
- 0.842
- 0.199
- 0.815
- 0.632
- 0.722
- 2.571
- 0.41
- 2.69
- 3.041
- 2.101
- 2.547
- 2.198
- 2.2
- 0.448
- 2.209
- 2.691
- 2.155
- 2.75
- 0.508
- 2.16
- 2.248
- 2.075
- 1.721
- 0.536
- 0.831
- 2.262
- 0.408
- 1.774
- 0.298
- 0.051
- 1.974
- 1.346
- 1.602
- 0.462
- 1.499
- 0.498
- 0.565
- 2.044
- 1.261
- 1.664
- 1.194
- 0.514
- 0.573
- 0.585
- 1.119
- 1.889
- 0.321
- 1.66
- 0.87
- 0.342
- 1.554
- 0.29
- 1.764
- 1.324
- 1.139
- 0.778
- 0.43
- 1.552
- 0.87
- 0.683
- 1.126
- 1.284
- 0.33
- 1.08
- 0.809
- 0.905
- 0.326
- 0.726
- 1.187
- 0.69
- 0.725
- 0.426
- 0.615
- 1.037
- 1.055
- 0.283
- 0.856
- 0.3
- 0.576
unequal: 0
verbose: 1
