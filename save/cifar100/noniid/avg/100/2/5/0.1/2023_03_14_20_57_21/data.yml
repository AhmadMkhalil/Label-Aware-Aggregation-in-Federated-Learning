avg_train_accuracy: 0.241
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041
- 0.0176
- 0.0168
- 0.0179
- 0.0177
- 0.0779
- 0.0916
- 0.1167
- 0.0181
- 0.0172
- 0.0186
- 0.0189
- 0.0184
- 0.0183
- 0.0181
- 0.018
- 0.0184
- 0.1182
- 0.0186
- 0.0185
- 0.1256
- 0.1345
- 0.1402
- 0.1585
- 0.0187
- 0.0182
- 0.0184
- 0.1561
- 0.0185
- 0.1621
- 0.0181
- 0.0185
- 0.0188
- 0.0181
- 0.16
- 0.018
- 0.1675
- 0.0187
- 0.0172
- 0.165
- 0.0187
- 0.018
- 0.019
- 0.1733
- 0.0189
- 0.0182
- 0.1783
- 0.1847
- 0.195
- 0.019
- 0.1844
- 0.0184
- 0.0184
- 0.0181
- 0.1944
- 0.0185
- 0.0187
- 0.1988
- 0.0187
- 0.2037
- 0.0187
- 0.2017
- 0.212
- 0.0188
- 0.2042
- 0.2122
- 0.0189
- 0.0179
- 0.2154
- 0.0185
- 0.2078
- 0.2164
- 0.223
- 0.0191
- 0.019
- 0.2155
- 0.019
- 0.2142
- 0.2275
- 0.0187
- 0.232
- 0.0193
- 0.0192
- 0.2281
- 0.2339
- 0.2273
- 0.0193
- 0.0187
- 0.2311
- 0.0188
- 0.019
- 0.019
- 0.0184
- 0.2366
- 0.2327
- 0.236
- 0.2386
- 0.2344
- 0.2329
- 0.2418
test_loss_list:
- 1.8097397947311402
- 4.448222789764404
- 4.805596952438354
- 5.047497243881225
- 5.167454996109009
- 1.728179407119751
- 1.7168548488616944
- 1.6876290941238403
- 4.737124080657959
- 4.577634048461914
- 4.525703363418579
- 4.689566316604615
- 4.782560691833496
- 4.67074426651001
- 4.763856887817383
- 4.982447481155395
- 5.001086702346802
- 1.6238080668449402
- 4.398238277435302
- 4.255935382843018
- 1.6034675526618958
- 1.5804331731796264
- 1.5820664739608765
- 1.5749536418914796
- 4.412239398956299
- 4.346714239120484
- 4.548566150665283
- 1.5548408079147338
- 4.4288660907745365
- 1.5462178540229798
- 4.323853969573975
- 4.243085861206055
- 4.386741628646851
- 4.2434654712677
- 1.5137652230262757
- 4.243427848815918
- 1.5065186643600463
- 4.136258144378662
- 4.212770929336548
- 1.5172516846656798
- 4.248585596084594
- 4.335403842926025
- 4.169408178329467
- 1.4862839150428773
- 3.9806031703948976
- 4.176957015991211
- 1.47150682926178
- 1.4756385850906373
- 1.46325097322464
- 4.058476276397705
- 1.4842673468589782
- 4.169184484481812
- 4.196262216567993
- 4.354988374710083
- 1.454892203807831
- 4.045941047668457
- 4.273635129928589
- 1.4531252145767213
- 3.9495379066467287
- 1.4411713552474976
- 4.11939866065979
- 1.4425929522514342
- 1.4429914879798889
- 3.9655163288116455
- 1.44766277551651
- 1.4548940253257752
- 4.037308902740478
- 4.187394542694092
- 1.4105500268936157
- 3.904648780822754
- 1.4364519262313842
- 1.4269110798835754
- 1.4216972231864928
- 4.034552659988403
- 3.928608818054199
- 1.4055156755447387
- 4.0578019905090335
- 1.4239779901504517
- 1.4036542868614197
- 3.9383488941192626
- 1.3990339159965515
- 4.019258880615235
- 4.068135585784912
- 1.394852192401886
- 1.3943048739433288
- 1.420491371154785
- 3.846346731185913
- 3.9462376022338868
- 1.3795670199394225
- 3.839289789199829
- 4.066562700271606
- 4.028520584106445
- 3.9518412017822264
- 1.3463440990448
- 1.364593231678009
- 1.3649661183357238
- 1.3738356709480286
- 1.3872770380973816
- 1.3943000793457032
- 1.3858641910552978
train_accuracy:
- 0.048
- 0.702
- 0.885
- 0.806
- 0.815
- 0.063
- 0.074
- 0.137
- 0.909
- 0.798
- 0.861
- 0.947
- 0.8
- 0.871
- 0.897
- 0.774
- 0.913
- 0.112
- 0.953
- 0.881
- 0.125
- 0.11
- 0.145
- 0.158
- 0.947
- 0.804
- 0.878
- 0.144
- 0.873
- 0.154
- 0.891
- 0.887
- 0.869
- 0.921
- 0.135
- 0.885
- 0.146
- 0.955
- 0.826
- 0.15
- 0.915
- 0.884
- 0.921
- 0.166
- 0.933
- 0.925
- 0.158
- 0.186
- 0.169
- 0.946
- 0.183
- 0.902
- 0.884
- 0.855
- 0.162
- 0.884
- 0.914
- 0.201
- 0.922
- 0.191
- 0.903
- 0.176
- 0.204
- 0.888
- 0.178
- 0.181
- 0.947
- 0.889
- 0.188
- 0.926
- 0.204
- 0.203
- 0.221
- 0.894
- 0.907
- 0.186
- 0.914
- 0.184
- 0.216
- 0.893
- 0.226
- 0.878
- 0.927
- 0.2
- 0.226
- 0.218
- 0.914
- 0.944
- 0.212
- 0.913
- 0.882
- 0.923
- 0.884
- 0.225
- 0.222
- 0.227
- 0.204
- 0.235
- 0.209
- 0.241
train_loss:
- 4.287
- 0.601
- 0.925
- 0.213
- 0.153
- 4.207
- 3.333
- 3.565
- 0.689
- 0.914
- 0.857
- 0.173
- 0.765
- 0.808
- 0.683
- 0.179
- 0.132
- 3.855
- 0.442
- 0.769
- 3.505
- 3.01
- 3.016
- 2.78
- 0.457
- 0.673
- 0.688
- 3.372
- 0.371
- 2.929
- 0.359
- 0.687
- 0.655
- 0.765
- 3.284
- 0.344
- 2.646
- 0.361
- 0.656
- 2.312
- 0.403
- 0.539
- 0.541
- 3.039
- 0.32
- 0.59
- 2.901
- 2.373
- 2.589
- 0.299
- 2.359
- 0.345
- 0.578
- 0.483
- 2.63
- 0.279
- 0.657
- 2.428
- 0.297
- 2.621
- 0.38
- 2.223
- 2.011
- 0.3
- 1.924
- 1.739
- 0.418
- 0.532
- 2.302
- 0.293
- 1.779
- 2.015
- 1.958
- 0.377
- 0.589
- 1.802
- 0.414
- 1.435
- 1.504
- 0.312
- 1.913
- 0.349
- 0.515
- 1.444
- 1.28
- 0.917
- 0.279
- 0.56
- 1.936
- 0.279
- 0.58
- 0.563
- 0.489
- 1.985
- 1.005
- 1.345
- 1.146
- 1.411
- 0.884
- 0.874
unequal: 0
verbose: 1
