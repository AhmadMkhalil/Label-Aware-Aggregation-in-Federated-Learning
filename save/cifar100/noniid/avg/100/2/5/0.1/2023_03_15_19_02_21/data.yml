avg_train_accuracy: 0.223
avg_train_loss: 0.014
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0159
- 0.0163
- 0.0177
- 0.018
- 0.0621
- 0.0975
- 0.0186
- 0.1079
- 0.1141
- 0.123
- 0.1279
- 0.0185
- 0.0181
- 0.1293
- 0.0185
- 0.1379
- 0.0186
- 0.0182
- 0.0177
- 0.1569
- 0.0187
- 0.0181
- 0.1555
- 0.1691
- 0.0187
- 0.0181
- 0.1758
- 0.1728
- 0.0188
- 0.0189
- 0.0188
- 0.0187
- 0.177
- 0.0183
- 0.181
- 0.1886
- 0.1907
- 0.0182
- 0.0188
- 0.1836
- 0.0188
- 0.1973
- 0.2014
- 0.1979
- 0.0193
- 0.0185
- 0.0192
- 0.0191
- 0.0185
- 0.1945
- 0.0184
- 0.2053
- 0.2057
- 0.019
- 0.0188
- 0.0183
- 0.2264
- 0.0191
- 0.0188
- 0.2124
- 0.2224
- 0.0189
- 0.0189
- 0.2188
- 0.0189
- 0.0189
- 0.0188
- 0.237
- 0.2343
- 0.0199
- 0.0188
- 0.0192
- 0.2308
- 0.2279
- 0.2302
- 0.2212
- 0.2277
- 0.23
- 0.0187
- 0.2359
- 0.2494
- 0.2391
- 0.0196
- 0.0194
- 0.0182
- 0.0192
- 0.0188
- 0.019
- 0.238
- 0.2365
- 0.0195
- 0.249
- 0.0209
- 0.0191
- 0.0196
- 0.2474
- 0.0189
- 0.0186
- 0.0184
- 0.2499
test_loss_list:
- 3.4629718685150146
- 5.0194112491607665
- 5.092402544021606
- 4.961044607162475
- 1.7937340497970582
- 1.7137726163864135
- 4.377725124359131
- 1.6774465441703796
- 1.6571662354469299
- 1.659439504146576
- 1.6726659750938415
- 4.497917890548706
- 4.4283650112152095
- 1.6250413751602173
- 4.4460803985595705
- 1.6235102725028991
- 4.252753686904907
- 4.4199944114685055
- 4.725397348403931
- 1.5630352067947388
- 4.19618013381958
- 4.351837701797486
- 1.556398413181305
- 1.5346161603927613
- 4.349523077011108
- 4.304559173583985
- 1.5212359046936035
- 1.5340007519721985
- 4.120167551040649
- 4.3072252941131595
- 4.1556871795654295
- 4.256386966705322
- 1.5296899700164794
- 4.294606065750122
- 1.5244707942008973
- 1.5116414904594422
- 1.532602195739746
- 4.367907695770263
- 4.4057635402679445
- 1.4837075805664062
- 4.21105224609375
- 1.4844691610336305
- 1.4770994067192078
- 1.501363890171051
- 4.137007102966309
- 4.225566120147705
- 4.374196071624755
- 4.2411310005187985
- 4.469544000625611
- 1.4761134386062622
- 4.0738458251953125
- 1.4615451717376708
- 1.4544738817214966
- 4.202541484832763
- 4.189892826080322
- 4.185898160934448
- 1.3846829771995544
- 3.9349413871765138
- 4.068788108825683
- 1.3963744306564332
- 1.403711256980896
- 4.0849476146698
- 4.1163684844970705
- 1.4035989379882812
- 3.9554601287841797
- 4.193605909347534
- 4.112603340148926
- 1.367277455329895
- 1.3803471302986146
- 3.817925548553467
- 4.091406679153442
- 3.8555932521820067
- 1.3807590532302856
- 1.4060631012916565
- 1.3990559267997742
- 1.4228962349891663
- 1.4117366528511048
- 1.4290080308914184
- 3.9792931270599365
- 1.412768440246582
- 1.3953852367401123
- 1.4082651805877686
- 3.938010196685791
- 4.009395236968994
- 4.181171903610229
- 4.255920629501343
- 3.8977868938446045
- 4.28143424987793
- 1.3879307556152343
- 1.3940050673484803
- 3.9619603157043457
- 1.3751490592956543
- 3.85201060295105
- 3.9447870540618895
- 4.169555435180664
- 1.3730360770225525
- 3.937893943786621
- 4.004812564849853
- 4.034196853637695
- 1.3286010694503785
train_accuracy:
- 0.781
- 0.469
- 0.916
- 0.844
- 0.07
- 0.094
- 0.896
- 0.114
- 0.102
- 0.118
- 0.122
- 0.928
- 0.856
- 0.138
- 0.879
- 0.137
- 0.853
- 0.759
- 0.721
- 0.151
- 0.897
- 0.913
- 0.167
- 0.175
- 0.975
- 0.938
- 0.148
- 0.169
- 0.911
- 0.961
- 0.883
- 0.834
- 0.187
- 0.875
- 0.179
- 0.195
- 0.197
- 0.877
- 0.905
- 0.223
- 0.895
- 0.183
- 0.211
- 0.194
- 0.935
- 0.878
- 0.916
- 0.936
- 0.872
- 0.196
- 0.911
- 0.204
- 0.235
- 0.915
- 0.933
- 0.887
- 0.194
- 0.9
- 0.916
- 0.22
- 0.249
- 0.937
- 0.884
- 0.215
- 0.932
- 0.912
- 0.903
- 0.205
- 0.207
- 0.94
- 0.894
- 0.93
- 0.254
- 0.237
- 0.255
- 0.241
- 0.237
- 0.262
- 0.921
- 0.241
- 0.225
- 0.22
- 0.954
- 0.94
- 0.796
- 0.936
- 0.942
- 0.903
- 0.265
- 0.234
- 0.944
- 0.247
- 0.948
- 0.887
- 0.948
- 0.274
- 0.881
- 0.871
- 0.879
- 0.223
train_loss:
- 0.553
- 0.834
- 0.896
- 0.695
- 4.579
- 3.779
- 0.5
- 3.908
- 3.497
- 3.047
- 2.697
- 0.426
- 0.857
- 3.614
- 0.542
- 3.41
- 0.458
- 0.121
- 0.954
- 3.337
- 0.477
- 0.809
- 3.162
- 2.948
- 0.428
- 0.614
- 2.939
- 2.463
- 0.319
- 0.049
- 0.59
- 0.069
- 2.42
- 0.558
- 2.978
- 1.944
- 2.292
- 0.494
- 0.813
- 2.84
- 0.365
- 2.268
- 1.84
- 1.754
- 0.366
- 0.68
- 0.503
- 0.036
- 0.549
- 2.771
- 0.377
- 1.86
- 2.199
- 0.469
- 0.559
- 0.661
- 2.579
- 0.292
- 0.549
- 2.309
- 1.881
- 0.349
- 0.599
- 2.002
- 0.299
- 0.526
- 0.59
- 2.205
- 1.507
- 0.249
- 0.509
- 0.541
- 1.885
- 1.556
- 1.344
- 1.058
- 1.822
- 0.977
- 0.325
- 1.539
- 1.497
- 1.102
- 0.321
- 0.024
- 0.52
- 0.426
- 0.537
- 0.431
- 1.299
- 1.519
- 0.221
- 1.714
- 0.193
- 0.574
- 0.491
- 1.13
- 0.295
- 0.672
- 0.069
- 1.389
unequal: 0
verbose: 1
