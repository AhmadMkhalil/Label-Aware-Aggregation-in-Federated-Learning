avg_train_accuracy: 0.284
avg_train_loss: 0.008
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0506
- 0.0783
- 0.1064
- 0.1211
- 0.0186
- 0.1197
- 0.1304
- 0.0174
- 0.1332
- 0.0169
- 0.1508
- 0.0148
- 0.1561
- 0.1617
- 0.0153
- 0.1743
- 0.1682
- 0.0173
- 0.0174
- 0.169
- 0.18
- 0.0178
- 0.1879
- 0.1851
- 0.0166
- 0.0181
- 0.1818
- 0.1945
- 0.1974
- 0.2061
- 0.0188
- 0.2035
- 0.0198
- 0.1969
- 0.2152
- 0.0198
- 0.018
- 0.0196
- 0.0158
- 0.0184
- 0.217
- 0.2136
- 0.0179
- 0.0174
- 0.2191
- 0.018
- 0.0186
- 0.2144
- 0.0183
- 0.0178
- 0.2139
- 0.0185
- 0.0175
- 0.0184
- 0.2172
- 0.0197
- 0.2217
- 0.0198
- 0.2271
- 0.2247
- 0.2307
- 0.0185
- 0.2348
- 0.0189
- 0.2333
- 0.2323
- 0.229
- 0.2267
- 0.0185
- 0.2368
- 0.2425
- 0.2387
- 0.019
- 0.2384
- 0.019
- 0.019
- 0.2386
- 0.2419
- 0.2438
- 0.2408
- 0.0205
- 0.0197
- 0.0201
- 0.2446
- 0.2388
- 0.2428
- 0.2481
- 0.2467
- 0.2418
- 0.0204
- 0.0175
- 0.0195
- 0.2477
- 0.2423
- 0.251
- 0.2518
- 0.2488
- 0.0213
- 0.0216
- 0.2521
test_loss_list:
- 1.8105898714065551
- 1.746328501701355
- 1.7029581093788146
- 1.6771103763580322
- 4.543364562988281
- 1.6702594804763793
- 1.6485503482818604
- 4.6232584285736085
- 1.6555434727668763
- 4.2350724411010745
- 1.6224624037742614
- 4.394902286529541
- 1.6177829027175903
- 1.6009635353088378
- 4.379099445343018
- 1.5782440638542174
- 1.5939836859703065
- 4.206673107147217
- 4.413817834854126
- 1.5780203580856322
- 1.5904735565185546
- 4.444151229858399
- 1.5445411729812621
- 1.5606225180625914
- 4.4580712985992434
- 4.388730449676514
- 1.536411919593811
- 1.5260686349868775
- 1.5199117541313172
- 1.5182605385780334
- 4.41954610824585
- 1.5094158339500428
- 4.430259761810302
- 1.4950391244888306
- 1.4935896492004395
- 4.355583047866821
- 4.372119474411011
- 4.401429996490479
- 4.252376775741578
- 4.163890962600708
- 1.4230202531814575
- 1.4423552799224852
- 4.235435695648193
- 4.292346677780151
- 1.4306325697898865
- 4.264152097702026
- 4.124752635955811
- 1.4445362997055053
- 4.265467081069946
- 4.252532148361206
- 1.4356635761260987
- 4.00013237953186
- 4.188238801956177
- 4.2769046401977535
- 1.414138195514679
- 4.122604694366455
- 1.4017798042297362
- 4.127539482116699
- 1.4184623622894288
- 1.4372677206993103
- 1.4272957277297973
- 4.134400062561035
- 1.4153090715408325
- 4.078059959411621
- 1.421256422996521
- 1.4267342233657836
- 1.4317464280128478
- 1.450044229030609
- 4.150915565490723
- 1.4348326897621155
- 1.429125385284424
- 1.4343866801261902
- 4.120039310455322
- 1.4451376461982728
- 4.076415090560913
- 4.180450582504273
- 1.4111300039291381
- 1.4304759740829467
- 1.4278891158103943
- 1.4153436398506165
- 4.022607669830323
- 4.074311408996582
- 4.199970512390137
- 1.4048997354507446
- 1.41854496717453
- 1.423539524078369
- 1.4182637119293213
- 1.4282454919815064
- 1.4275372862815856
- 4.198306474685669
- 4.390967350006104
- 4.066124753952026
- 1.3993528532981871
- 1.418385980129242
- 1.401397385597229
- 1.4033794212341308
- 1.4201515746116637
- 4.096800851821899
- 4.043047389984131
- 1.4077423787117005
train_accuracy:
- 0.07
- 0.088
- 0.101
- 0.152
- 0.758
- 0.108
- 0.131
- 0.805
- 0.164
- 0.823
- 0.173
- 0.627
- 0.19
- 0.198
- 0.451
- 0.138
- 0.177
- 0.884
- 0.706
- 0.176
- 0.177
- 0.724
- 0.209
- 0.216
- 0.771
- 0.923
- 0.162
- 0.223
- 0.18
- 0.161
- 0.873
- 0.19
- 0.961
- 0.202
- 0.227
- 0.968
- 0.89
- 0.977
- 0.617
- 0.831
- 0.182
- 0.194
- 0.826
- 0.857
- 0.196
- 0.911
- 0.866
- 0.171
- 0.957
- 0.781
- 0.2
- 0.842
- 0.905
- 0.953
- 0.216
- 0.979
- 0.25
- 0.861
- 0.247
- 0.251
- 0.2
- 0.93
- 0.257
- 0.831
- 0.232
- 0.242
- 0.242
- 0.217
- 0.936
- 0.267
- 0.271
- 0.26
- 0.945
- 0.281
- 0.865
- 0.939
- 0.275
- 0.265
- 0.223
- 0.256
- 0.903
- 0.887
- 0.979
- 0.278
- 0.279
- 0.262
- 0.278
- 0.274
- 0.263
- 0.984
- 0.824
- 0.875
- 0.296
- 0.272
- 0.242
- 0.284
- 0.241
- 0.979
- 0.977
- 0.284
train_loss:
- 4.271
- 3.87
- 3.643
- 3.567
- 0.508
- 3.847
- 3.172
- 0.641
- 3.057
- 0.764
- 3.357
- 0.804
- 2.946
- 3.011
- 0.649
- 3.263
- 2.567
- 0.645
- 0.847
- 2.497
- 1.936
- 0.517
- 2.835
- 2.046
- 0.498
- 0.765
- 3.169
- 2.49
- 2.447
- 2.584
- 0.481
- 2.415
- 0.495
- 2.461
- 1.993
- 0.373
- 0.738
- 0.558
- 0.939
- 0.684
- 2.543
- 2.033
- 0.517
- 0.754
- 2.186
- 0.42
- 0.62
- 1.789
- 0.416
- 0.597
- 2.074
- 0.341
- 0.697
- 0.587
- 2.219
- 0.312
- 2.252
- 0.411
- 1.751
- 1.22
- 1.598
- 0.375
- 2.009
- 0.391
- 1.914
- 1.628
- 1.321
- 0.988
- 0.373
- 1.587
- 1.469
- 1.043
- 0.329
- 1.398
- 0.397
- 0.539
- 1.374
- 0.942
- 1.463
- 1.443
- 0.309
- 0.045
- 0.587
- 1.15
- 0.987
- 0.987
- 1.149
- 0.753
- 0.868
- 0.285
- 0.685
- 0.609
- 1.095
- 0.552
- 1.225
- 0.737
- 0.867
- 0.271
- 0.015
- 0.815
unequal: 0
verbose: 1
