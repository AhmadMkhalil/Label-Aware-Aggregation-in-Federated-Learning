avg_train_accuracy: 0.292
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0416
- 0.086
- 0.107
- 0.1214
- 0.136
- 0.1496
- 0.1621
- 0.1702
- 0.1742
- 0.1877
- 0.195
- 0.2054
- 0.2016
- 0.2118
- 0.2104
- 0.221
- 0.2233
- 0.2292
- 0.2303
- 0.233
- 0.2366
- 0.2373
- 0.2413
- 0.2474
- 0.2516
- 0.2495
- 0.254
- 0.2615
- 0.2586
- 0.262
- 0.2655
- 0.2688
- 0.2701
- 0.2688
- 0.269
- 0.2759
- 0.2747
- 0.2737
- 0.2775
- 0.2822
- 0.2821
- 0.2848
- 0.2837
- 0.2874
- 0.2851
- 0.2904
- 0.2893
- 0.2921
- 0.2951
- 0.2953
- 0.2994
- 0.2979
- 0.2974
- 0.2966
- 0.2962
- 0.2972
- 0.2979
- 0.3004
- 0.3042
- 0.3052
- 0.3053
- 0.3028
- 0.3073
- 0.3074
- 0.3074
- 0.3081
- 0.3084
- 0.3074
- 0.3109
- 0.3095
- 0.3131
- 0.3138
- 0.3151
- 0.3126
- 0.3159
- 0.3144
- 0.3174
- 0.3193
- 0.3153
- 0.3153
- 0.3216
- 0.3174
- 0.3135
- 0.3181
- 0.3186
- 0.3169
- 0.3196
- 0.3178
- 0.3188
- 0.3198
- 0.3202
- 0.3217
- 0.3194
- 0.3243
- 0.3196
- 0.3235
- 0.3243
- 0.3239
- 0.3262
- 0.3279
test_loss_list:
- 1.7849497556686402
- 1.6494812917709352
- 1.593820116519928
- 1.5486722445487977
- 1.5112061309814453
- 1.4836842370033265
- 1.4595345664024353
- 1.4351724314689636
- 1.4171880221366882
- 1.403274712562561
- 1.3885746908187866
- 1.3749614477157592
- 1.3578205299377442
- 1.3438735389709473
- 1.3276187705993652
- 1.3219315218925476
- 1.3088626384735107
- 1.3028624057769775
- 1.2905802655220031
- 1.2834550976753234
- 1.2746779990196229
- 1.270990993976593
- 1.259646203517914
- 1.2589392900466918
- 1.2582490205764771
- 1.2446765565872193
- 1.245700855255127
- 1.243807783126831
- 1.2293246698379516
- 1.2247274923324585
- 1.216702470779419
- 1.2191433882713318
- 1.210978090763092
- 1.210598473548889
- 1.2057073426246643
- 1.1942525506019592
- 1.195732398033142
- 1.193238971233368
- 1.1884180116653442
- 1.184888138771057
- 1.184933316707611
- 1.1867805886268616
- 1.1820494580268859
- 1.1724222016334533
- 1.1761525630950929
- 1.1757082533836365
- 1.1661774182319642
- 1.1657000613212585
- 1.162641201019287
- 1.1625197792053223
- 1.16253027677536
- 1.1648726081848144
- 1.157435381412506
- 1.162601091861725
- 1.160714077949524
- 1.1570626926422118
- 1.151370394229889
- 1.1501412439346312
- 1.146943678855896
- 1.1462944507598878
- 1.1454487586021422
- 1.1481889224052428
- 1.1476770448684692
- 1.1452840662002564
- 1.1421839022636413
- 1.1408839869499205
- 1.1459126996994018
- 1.140804762840271
- 1.141132206916809
- 1.1413765263557434
- 1.1404311728477479
- 1.1433251595497131
- 1.1467844557762146
- 1.1374781703948975
- 1.143720142841339
- 1.146598491668701
- 1.1389892959594727
- 1.1357639622688294
- 1.1415715074539186
- 1.1390089297294617
- 1.1374391412734985
- 1.1360088849067689
- 1.1398611950874329
- 1.1345946526527404
- 1.1351154804229737
- 1.139033420085907
- 1.1368948936462402
- 1.1402336025238038
- 1.1389526343345642
- 1.1420749568939208
- 1.1380795741081238
- 1.13790189743042
- 1.1393937540054322
- 1.1363083744049072
- 1.139539999961853
- 1.1383793449401856
- 1.1353734827041626
- 1.1359919166564942
- 1.1410086679458618
- 1.1446375155448913
train_accuracy:
- 0.04
- 0.095
- 0.001
- 0.003
- 0.131
- 0.14
- 0.011
- 0.153
- 0.137
- 0.164
- 0.212
- 0.223
- 0.193
- 0.203
- 0.169
- 0.183
- 0.206
- 0.212
- 0.219
- 0.208
- 0.223
- 0.229
- 0.216
- 0.213
- 0.251
- 0.212
- 0.25
- 0.239
- 0.258
- 0.256
- 0.227
- 0.251
- 0.273
- 0.272
- 0.231
- 0.243
- 0.285
- 0.261
- 0.052
- 0.264
- 0.241
- 0.291
- 0.257
- 0.252
- 0.267
- 0.29
- 0.3
- 0.049
- 0.239
- 0.275
- 0.266
- 0.301
- 0.251
- 0.26
- 0.275
- 0.264
- 0.032
- 0.274
- 0.311
- 0.064
- 0.285
- 0.08
- 0.269
- 0.316
- 0.071
- 0.096
- 0.332
- 0.311
- 0.303
- 0.287
- 0.301
- 0.283
- 0.295
- 0.288
- 0.333
- 0.289
- 0.319
- 0.295
- 0.322
- 0.089
- 0.296
- 0.318
- 0.101
- 0.322
- 0.33
- 0.103
- 0.112
- 0.274
- 0.111
- 0.27
- 0.305
- 0.313
- 0.275
- 0.333
- 0.329
- 0.326
- 0.345
- 0.308
- 0.346
- 0.292
train_loss:
- 4.33
- 3.399
- 3.239
- 3.108
- 2.989
- 2.869
- 2.767
- 2.722
- 2.635
- 2.937
- 2.877
- 2.79
- 2.402
- 2.658
- 2.257
- 2.545
- 2.159
- 2.454
- 2.075
- 2.026
- 1.999
- 1.929
- 1.892
- 2.113
- 2.062
- 1.771
- 2.011
- 1.94
- 1.694
- 1.596
- 1.608
- 1.812
- 1.517
- 1.51
- 1.453
- 1.458
- 1.407
- 1.35
- 1.35
- 1.317
- 1.273
- 1.461
- 1.252
- 1.191
- 1.159
- 1.368
- 1.155
- 1.096
- 1.084
- 1.088
- 1.158
- 1.162
- 1.003
- 1.102
- 0.969
- 1.056
- 0.904
- 0.909
- 0.854
- 0.84
- 0.821
- 0.812
- 0.916
- 0.783
- 0.752
- 0.776
- 0.834
- 0.705
- 0.727
- 0.674
- 0.651
- 0.729
- 0.713
- 0.622
- 0.692
- 0.659
- 0.628
- 0.594
- 0.556
- 0.542
- 0.622
- 0.54
- 0.515
- 0.509
- 0.516
- 0.475
- 0.464
- 0.494
- 0.453
- 0.452
- 0.452
- 0.411
- 0.418
- 0.441
- 0.409
- 0.397
- 0.401
- 0.373
- 0.428
- 0.413
unequal: 0
verbose: 1
