avg_train_accuracy: 0.329
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0331
- 0.0781
- 0.0952
- 0.1122
- 0.1297
- 0.1438
- 0.1582
- 0.168
- 0.1729
- 0.182
- 0.1889
- 0.1979
- 0.2043
- 0.2118
- 0.2143
- 0.2225
- 0.2267
- 0.231
- 0.2394
- 0.2403
- 0.2444
- 0.2513
- 0.2502
- 0.2562
- 0.2606
- 0.2588
- 0.2628
- 0.2653
- 0.2741
- 0.2745
- 0.2736
- 0.2784
- 0.2764
- 0.2824
- 0.2857
- 0.2847
- 0.2837
- 0.2856
- 0.2928
- 0.2966
- 0.2946
- 0.2955
- 0.2953
- 0.2991
- 0.2946
- 0.3011
- 0.3016
- 0.2985
- 0.3004
- 0.3048
- 0.3053
- 0.3062
- 0.3031
- 0.308
- 0.3079
- 0.3087
- 0.3112
- 0.3118
- 0.3128
- 0.3114
- 0.3136
- 0.3145
- 0.3136
- 0.3162
- 0.3206
- 0.3178
- 0.321
- 0.3133
- 0.3168
- 0.317
- 0.3199
- 0.3201
- 0.32
- 0.3228
- 0.3259
- 0.326
- 0.3226
- 0.3229
- 0.3242
- 0.3245
- 0.3253
- 0.3282
- 0.3242
- 0.3276
- 0.3295
- 0.3277
- 0.3302
- 0.3286
- 0.3288
- 0.3258
- 0.3297
- 0.3305
- 0.3331
- 0.3326
- 0.3302
- 0.3336
- 0.3354
- 0.3357
- 0.3345
- 0.3324
test_loss_list:
- 1.8048315858840942
- 1.68118417263031
- 1.6198621463775635
- 1.571722903251648
- 1.5330903267860412
- 1.5012227487564087
- 1.4673573207855224
- 1.446752736568451
- 1.423183832168579
- 1.4048713636398316
- 1.393263258934021
- 1.3719411873817444
- 1.3617873668670655
- 1.3534135961532592
- 1.3342241692543029
- 1.3257195234298706
- 1.3177706599235535
- 1.2976288795471191
- 1.2917870783805847
- 1.2887819552421569
- 1.2822910594940184
- 1.2752005767822265
- 1.2600306010246276
- 1.2475453042984008
- 1.2459769344329834
- 1.2354976749420166
- 1.2295522117614746
- 1.2265518045425414
- 1.2140179014205932
- 1.2098340320587158
- 1.2068635654449462
- 1.2007696890830994
- 1.199964988231659
- 1.1925111770629884
- 1.186742901802063
- 1.186765079498291
- 1.1859614872932434
- 1.180424726009369
- 1.1749773168563842
- 1.1690485978126526
- 1.1734632349014282
- 1.1735866093635559
- 1.1673001003265382
- 1.1598061752319335
- 1.1596743941307068
- 1.1588136315345765
- 1.159469919204712
- 1.1525327038764954
- 1.149180657863617
- 1.1424092650413513
- 1.1464811778068542
- 1.1437697315216064
- 1.1477105879783631
- 1.1392249751091004
- 1.1392518877983093
- 1.138008213043213
- 1.1379625582695008
- 1.1305554246902465
- 1.1301999235153197
- 1.1316254830360413
- 1.1322772192955017
- 1.1357671165466308
- 1.1318035840988159
- 1.129092926979065
- 1.1249596428871156
- 1.12885822057724
- 1.1319472551345826
- 1.1312481808662413
- 1.1291516351699828
- 1.1254581117630005
- 1.1250550150871277
- 1.1244226956367493
- 1.1262267804145814
- 1.1227730703353882
- 1.12249849319458
- 1.1226337432861329
- 1.1242064595222474
- 1.1235617399215698
- 1.1241842341423034
- 1.1226143765449523
- 1.1225795435905457
- 1.1206109857559203
- 1.1254929041862487
- 1.1190482544898988
- 1.1196799206733703
- 1.1214989924430847
- 1.1207945108413697
- 1.1211119318008422
- 1.121696457862854
- 1.1236335396766663
- 1.1226101112365723
- 1.120280773639679
- 1.1185428023338317
- 1.11778959274292
- 1.123928692340851
- 1.1220246315002442
- 1.1187088871002198
- 1.1168972849845886
- 1.119644889831543
- 1.1231409287452698
train_accuracy:
- 0.05
- 0.062
- 0.097
- 0.145
- 0.12
- 0.176
- 0.159
- 0.208
- 0.193
- 0.146
- 0.193
- 0.155
- 0.193
- 0.251
- 0.005
- 0.211
- 0.239
- 0.008
- 0.255
- 0.225
- 0.242
- 0.246
- 0.23
- 0.239
- 0.21
- 0.242
- 0.218
- 0.254
- 0.262
- 0.031
- 0.288
- 0.275
- 0.269
- 0.236
- 0.258
- 0.271
- 0.237
- 0.267
- 0.219
- 0.282
- 0.305
- 0.272
- 0.285
- 0.285
- 0.248
- 0.287
- 0.253
- 0.283
- 0.238
- 0.29
- 0.291
- 0.256
- 0.285
- 0.255
- 0.243
- 0.286
- 0.261
- 0.334
- 0.309
- 0.288
- 0.272
- 0.291
- 0.048
- 0.286
- 0.268
- 0.305
- 0.279
- 0.304
- 0.271
- 0.274
- 0.064
- 0.255
- 0.315
- 0.312
- 0.261
- 0.341
- 0.301
- 0.251
- 0.299
- 0.345
- 0.306
- 0.289
- 0.347
- 0.317
- 0.089
- 0.306
- 0.297
- 0.276
- 0.114
- 0.304
- 0.34
- 0.352
- 0.314
- 0.333
- 0.318
- 0.116
- 0.318
- 0.262
- 0.303
- 0.329
train_loss:
- 3.802
- 3.469
- 3.28
- 3.149
- 3.465
- 3.313
- 2.811
- 3.126
- 2.648
- 2.607
- 2.891
- 2.487
- 2.768
- 2.679
- 2.279
- 2.552
- 2.517
- 2.137
- 2.4
- 2.305
- 2.292
- 2.213
- 1.889
- 1.847
- 2.099
- 1.79
- 1.707
- 1.972
- 1.672
- 1.641
- 1.591
- 1.549
- 1.5
- 1.492
- 1.471
- 1.415
- 1.638
- 1.354
- 1.366
- 1.328
- 1.471
- 1.452
- 1.21
- 1.239
- 1.198
- 1.352
- 1.273
- 1.094
- 1.099
- 1.07
- 1.188
- 1.025
- 1.112
- 0.966
- 0.965
- 0.896
- 0.863
- 0.922
- 0.882
- 0.846
- 0.82
- 0.936
- 0.791
- 0.798
- 0.755
- 0.871
- 0.838
- 0.708
- 0.79
- 0.688
- 0.657
- 0.634
- 0.745
- 0.622
- 0.614
- 0.581
- 0.669
- 0.576
- 0.623
- 0.574
- 0.545
- 0.55
- 0.581
- 0.526
- 0.478
- 0.471
- 0.495
- 0.489
- 0.463
- 0.503
- 0.45
- 0.416
- 0.437
- 0.418
- 0.396
- 0.415
- 0.393
- 0.399
- 0.378
- 0.37
unequal: 0
verbose: 1
