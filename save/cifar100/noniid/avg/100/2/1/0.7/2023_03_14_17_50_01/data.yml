avg_train_accuracy: 0.325
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0373
- 0.0897
- 0.1116
- 0.1306
- 0.1465
- 0.1547
- 0.1638
- 0.1735
- 0.1771
- 0.1892
- 0.1946
- 0.2027
- 0.206
- 0.2081
- 0.2134
- 0.2214
- 0.2237
- 0.2241
- 0.2308
- 0.2334
- 0.24
- 0.2402
- 0.2452
- 0.2474
- 0.251
- 0.2548
- 0.2565
- 0.2597
- 0.2656
- 0.2651
- 0.2656
- 0.2673
- 0.2716
- 0.2739
- 0.2755
- 0.2792
- 0.2802
- 0.2813
- 0.2832
- 0.2886
- 0.2865
- 0.2875
- 0.2901
- 0.2881
- 0.2912
- 0.2917
- 0.2966
- 0.2995
- 0.2973
- 0.2961
- 0.2992
- 0.3027
- 0.3017
- 0.3049
- 0.3027
- 0.3038
- 0.3064
- 0.3046
- 0.307
- 0.3049
- 0.3128
- 0.31
- 0.3125
- 0.3146
- 0.3128
- 0.3161
- 0.3149
- 0.317
- 0.318
- 0.3165
- 0.3192
- 0.3228
- 0.3165
- 0.3193
- 0.3217
- 0.3185
- 0.3196
- 0.3238
- 0.3226
- 0.3285
- 0.3252
- 0.3225
- 0.3244
- 0.3223
- 0.3258
- 0.3253
- 0.3266
- 0.3227
- 0.3305
- 0.3275
- 0.3274
- 0.3318
- 0.3303
- 0.3303
- 0.333
- 0.3287
- 0.3325
- 0.3281
- 0.3312
- 0.3266
test_loss_list:
- 1.797568073272705
- 1.6464709663391113
- 1.5857364511489869
- 1.5442655873298645
- 1.5019536232948303
- 1.4736027312278748
- 1.453811025619507
- 1.4302873373031617
- 1.414651460647583
- 1.4001121711730957
- 1.3828336334228515
- 1.3759698963165283
- 1.357399423122406
- 1.346728503704071
- 1.3354302096366881
- 1.326967408657074
- 1.3116917061805724
- 1.3029907393455504
- 1.3007181310653686
- 1.2894928193092345
- 1.2850515699386598
- 1.2719747638702392
- 1.2650612115859985
- 1.259666745662689
- 1.2537972831726074
- 1.25156813621521
- 1.2357190442085266
- 1.2296581172943115
- 1.2313575768470764
- 1.2312856101989746
- 1.219257528781891
- 1.213970730304718
- 1.2073706912994384
- 1.202303981781006
- 1.200738160610199
- 1.1921969866752624
- 1.197228457927704
- 1.1874150800704957
- 1.1847941660881043
- 1.1860138726234437
- 1.1880604028701782
- 1.171374695301056
- 1.168096089363098
- 1.172463710308075
- 1.1721763038635253
- 1.1665633344650268
- 1.1528323197364807
- 1.1612129092216492
- 1.162108211517334
- 1.1566229128837586
- 1.1564529514312745
- 1.1458367490768433
- 1.1459749364852905
- 1.1418969631195068
- 1.1447209119796753
- 1.1411871528625488
- 1.1421602582931518
- 1.1477502799034118
- 1.139327962398529
- 1.143790488243103
- 1.1428109216690063
- 1.1484525561332704
- 1.1384648323059081
- 1.1402491807937623
- 1.1445655488967896
- 1.1324494171142578
- 1.1344810819625855
- 1.131177761554718
- 1.1284178519248962
- 1.135193965435028
- 1.1274705290794373
- 1.1260353851318359
- 1.1327686762809754
- 1.1319864749908448
- 1.1252799940109253
- 1.1322004365921021
- 1.1332968974113464
- 1.1257774138450622
- 1.1270758652687072
- 1.1214419937133788
- 1.1233206224441528
- 1.1312684726715088
- 1.1309697651863098
- 1.1267249870300293
- 1.1233894896507264
- 1.1261070346832276
- 1.1247344994544983
- 1.13032963514328
- 1.121219596862793
- 1.1235868692398072
- 1.129234597682953
- 1.1255785989761353
- 1.1262255907058716
- 1.1280812001228333
- 1.1249696159362792
- 1.1308484697341918
- 1.123041684627533
- 1.130728416442871
- 1.1273770427703858
- 1.129628961086273
train_accuracy:
- 0.008
- 0.091
- 0.115
- 0.132
- 0.142
- 0.144
- 0.159
- 0.166
- 0.129
- 0.192
- 0.197
- 0.192
- 0.22
- 0.186
- 0.183
- 0.182
- 0.188
- 0.194
- 0.243
- 0.01
- 0.227
- 0.201
- 0.185
- 0.194
- 0.246
- 0.207
- 0.257
- 0.214
- 0.218
- 0.212
- 0.249
- 0.209
- 0.251
- 0.216
- 0.227
- 0.225
- 0.216
- 0.261
- 0.23
- 0.236
- 0.267
- 0.293
- 0.295
- 0.229
- 0.265
- 0.289
- 0.044
- 0.304
- 0.261
- 0.253
- 0.248
- 0.019
- 0.286
- 0.296
- 0.312
- 0.285
- 0.303
- 0.29
- 0.283
- 0.322
- 0.284
- 0.326
- 0.319
- 0.278
- 0.289
- 0.275
- 0.276
- 0.324
- 0.26
- 0.316
- 0.259
- 0.325
- 0.321
- 0.295
- 0.316
- 0.303
- 0.297
- 0.036
- 0.298
- 0.276
- 0.341
- 0.28
- 0.322
- 0.334
- 0.283
- 0.089
- 0.328
- 0.34
- 0.067
- 0.34
- 0.342
- 0.304
- 0.284
- 0.305
- 0.299
- 0.275
- 0.35
- 0.276
- 0.081
- 0.325
train_loss:
- 3.841
- 3.94
- 3.675
- 3.521
- 2.954
- 2.854
- 2.744
- 2.733
- 2.633
- 2.951
- 2.524
- 2.796
- 2.389
- 2.333
- 2.291
- 2.565
- 2.195
- 2.087
- 2.355
- 1.997
- 2.3
- 1.927
- 1.926
- 1.874
- 1.823
- 2.073
- 1.81
- 1.757
- 1.925
- 1.895
- 1.61
- 1.553
- 1.556
- 1.481
- 1.456
- 1.463
- 1.617
- 1.404
- 1.35
- 1.513
- 1.461
- 1.29
- 1.245
- 1.202
- 1.339
- 1.122
- 1.192
- 1.33
- 1.25
- 1.095
- 1.18
- 1.022
- 0.978
- 0.978
- 0.969
- 0.923
- 0.923
- 1.002
- 0.887
- 1.003
- 0.959
- 0.922
- 0.794
- 0.898
- 0.832
- 0.794
- 0.741
- 0.72
- 0.721
- 0.786
- 0.68
- 0.663
- 0.749
- 0.637
- 0.599
- 0.68
- 0.686
- 0.592
- 0.54
- 0.554
- 0.555
- 0.603
- 0.59
- 0.509
- 0.494
- 0.478
- 0.502
- 0.534
- 0.449
- 0.451
- 0.442
- 0.442
- 0.422
- 0.406
- 0.424
- 0.451
- 0.396
- 0.441
- 0.394
- 0.422
unequal: 0
verbose: 1
