avg_train_accuracy: 0.364
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0315
- 0.0891
- 0.1093
- 0.1304
- 0.1391
- 0.154
- 0.1615
- 0.1667
- 0.1772
- 0.1866
- 0.1949
- 0.1959
- 0.2045
- 0.2054
- 0.2147
- 0.2189
- 0.2239
- 0.2242
- 0.2268
- 0.232
- 0.2368
- 0.243
- 0.245
- 0.2432
- 0.2541
- 0.2538
- 0.2545
- 0.2572
- 0.2607
- 0.2629
- 0.2667
- 0.2706
- 0.269
- 0.2721
- 0.2774
- 0.2764
- 0.2819
- 0.2796
- 0.2822
- 0.2839
- 0.2864
- 0.2828
- 0.2873
- 0.2864
- 0.2891
- 0.292
- 0.2915
- 0.2966
- 0.294
- 0.2973
- 0.2993
- 0.2967
- 0.2986
- 0.2997
- 0.303
- 0.3054
- 0.3067
- 0.307
- 0.3022
- 0.301
- 0.307
- 0.3102
- 0.3086
- 0.3075
- 0.3122
- 0.3145
- 0.3098
- 0.3102
- 0.3132
- 0.3121
- 0.3149
- 0.3126
- 0.3167
- 0.3159
- 0.3143
- 0.3188
- 0.3172
- 0.3188
- 0.3187
- 0.3201
- 0.3185
- 0.3163
- 0.3193
- 0.3178
- 0.3211
- 0.323
- 0.3196
- 0.3215
- 0.3231
- 0.3192
- 0.3217
- 0.3208
- 0.3254
- 0.3234
- 0.3222
- 0.3231
- 0.3241
- 0.3237
- 0.3285
- 0.3259
test_loss_list:
- 1.795198187828064
- 1.6511755108833313
- 1.5886187076568603
- 1.540691511631012
- 1.503044412136078
- 1.471932466030121
- 1.4459776258468628
- 1.4315042185783386
- 1.411937894821167
- 1.396309850215912
- 1.371973876953125
- 1.3618514895439149
- 1.354916331768036
- 1.3387516593933106
- 1.3305820894241334
- 1.314222276210785
- 1.3048613286018371
- 1.2927113842964173
- 1.2867933225631714
- 1.2774518322944641
- 1.2706296634674072
- 1.2646050214767457
- 1.259610378742218
- 1.2523927569389344
- 1.24601891040802
- 1.2371595573425294
- 1.2372427344322205
- 1.2277004432678222
- 1.2203349566459656
- 1.217626383304596
- 1.2143162965774537
- 1.2112497687339783
- 1.2043247747421264
- 1.2059187173843384
- 1.1984167098999023
- 1.1921041297912598
- 1.1890069270133972
- 1.1859423327445984
- 1.1827773356437683
- 1.1792672657966614
- 1.1710266590118408
- 1.1752817153930664
- 1.1692410898208618
- 1.1734108471870421
- 1.1671763753890991
- 1.1659212255477904
- 1.164767005443573
- 1.1616178822517396
- 1.1587147188186646
- 1.1531115245819092
- 1.155686583518982
- 1.1620560884475708
- 1.1531425380706788
- 1.1528583073616028
- 1.149640860557556
- 1.1449235630035401
- 1.141990203857422
- 1.1460986471176147
- 1.1455579113960266
- 1.1466615295410156
- 1.1413296151161194
- 1.1428662300109864
- 1.1403132438659669
- 1.1405389547348022
- 1.1451817536354065
- 1.1457949423789977
- 1.1359471487998962
- 1.139360785484314
- 1.1354596400260926
- 1.136847779750824
- 1.1354616785049438
- 1.1385539722442628
- 1.1440588569641112
- 1.1323734831809997
- 1.135338523387909
- 1.1330630850791932
- 1.132491524219513
- 1.137254648208618
- 1.138807737827301
- 1.1380374145507812
- 1.1376442003250122
- 1.1451399660110473
- 1.1370599532127381
- 1.1376472330093383
- 1.1369482803344726
- 1.1350012421607971
- 1.1369896197319032
- 1.1371681427955627
- 1.136057472229004
- 1.1395420408248902
- 1.1408186197280883
- 1.1355294895172119
- 1.1433247852325439
- 1.1400467896461486
- 1.1368111920356752
- 1.1441009378433227
- 1.136166775226593
- 1.1412792444229125
- 1.1356177234649658
- 1.1446476984024048
train_accuracy:
- 0.031
- 0.098
- 0.115
- 0.13
- 0.003
- 0.173
- 0.177
- 0.171
- 0.172
- 0.145
- 0.193
- 0.152
- 0.205
- 0.171
- 0.207
- 0.216
- 0.251
- 0.194
- 0.233
- 0.189
- 0.208
- 0.178
- 0.23
- 0.261
- 0.236
- 0.019
- 0.204
- 0.022
- 0.195
- 0.208
- 0.277
- 0.307
- 0.218
- 0.31
- 0.255
- 0.275
- 0.061
- 0.218
- 0.053
- 0.306
- 0.216
- 0.222
- 0.301
- 0.329
- 0.29
- 0.215
- 0.331
- 0.305
- 0.331
- 0.306
- 0.281
- 0.262
- 0.255
- 0.246
- 0.273
- 0.034
- 0.296
- 0.06
- 0.072
- 0.259
- 0.339
- 0.314
- 0.345
- 0.357
- 0.244
- 0.336
- 0.357
- 0.271
- 0.325
- 0.085
- 0.317
- 0.332
- 0.326
- 0.286
- 0.066
- 0.285
- 0.326
- 0.322
- 0.089
- 0.275
- 0.285
- 0.053
- 0.329
- 0.328
- 0.285
- 0.229
- 0.276
- 0.244
- 0.327
- 0.134
- 0.339
- 0.117
- 0.335
- 0.338
- 0.339
- 0.248
- 0.279
- 0.356
- 0.067
- 0.364
train_loss:
- 3.788
- 3.411
- 3.215
- 3.532
- 2.934
- 2.845
- 2.762
- 2.655
- 2.601
- 2.905
- 2.502
- 2.423
- 2.693
- 2.268
- 2.577
- 2.204
- 2.168
- 2.116
- 2.051
- 2.006
- 1.978
- 1.945
- 2.152
- 1.882
- 2.091
- 1.763
- 1.972
- 1.708
- 1.668
- 1.622
- 1.589
- 1.812
- 1.523
- 1.482
- 1.696
- 1.422
- 1.407
- 1.387
- 1.336
- 1.315
- 1.296
- 1.251
- 1.235
- 1.386
- 1.196
- 1.15
- 1.152
- 1.261
- 1.062
- 1.059
- 1.202
- 1.162
- 0.991
- 0.987
- 1.075
- 0.955
- 0.877
- 0.881
- 0.84
- 0.84
- 0.821
- 0.939
- 0.804
- 0.767
- 0.897
- 0.867
- 0.751
- 0.719
- 0.712
- 0.693
- 0.665
- 0.758
- 0.727
- 0.641
- 0.621
- 0.6
- 0.605
- 0.567
- 0.557
- 0.534
- 0.599
- 0.506
- 0.507
- 0.518
- 0.582
- 0.498
- 0.471
- 0.466
- 0.445
- 0.444
- 0.425
- 0.447
- 0.468
- 0.497
- 0.413
- 0.44
- 0.393
- 0.443
- 0.395
- 0.429
unequal: 0
verbose: 1
