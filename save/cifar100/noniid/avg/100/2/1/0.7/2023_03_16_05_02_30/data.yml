avg_train_accuracy: 0.309
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0384
- 0.0931
- 0.112
- 0.1292
- 0.1467
- 0.1589
- 0.1735
- 0.1793
- 0.1876
- 0.1926
- 0.1995
- 0.2087
- 0.2115
- 0.2136
- 0.2219
- 0.224
- 0.2301
- 0.2295
- 0.2392
- 0.234
- 0.2394
- 0.2476
- 0.2533
- 0.2498
- 0.2527
- 0.2525
- 0.2601
- 0.2663
- 0.2662
- 0.2709
- 0.2697
- 0.2673
- 0.2712
- 0.2704
- 0.2732
- 0.276
- 0.2773
- 0.2793
- 0.2804
- 0.2837
- 0.2837
- 0.2857
- 0.29
- 0.29
- 0.2904
- 0.2948
- 0.2954
- 0.2972
- 0.2941
- 0.2978
- 0.2982
- 0.2978
- 0.2993
- 0.3029
- 0.3032
- 0.3055
- 0.3069
- 0.3031
- 0.309
- 0.3099
- 0.3098
- 0.3113
- 0.3117
- 0.3117
- 0.3141
- 0.315
- 0.3148
- 0.3149
- 0.3165
- 0.3171
- 0.3178
- 0.3148
- 0.3184
- 0.3193
- 0.319
- 0.3185
- 0.3222
- 0.3221
- 0.3208
- 0.3216
- 0.3194
- 0.3203
- 0.3248
- 0.3213
- 0.325
- 0.3233
- 0.3233
- 0.3251
- 0.3233
- 0.3249
- 0.3263
- 0.3264
- 0.326
- 0.328
- 0.327
- 0.3263
- 0.3287
- 0.3311
- 0.3297
- 0.3338
test_loss_list:
- 1.7914642238616942
- 1.6435157895088195
- 1.5817592072486877
- 1.5386109948158264
- 1.498039710521698
- 1.4672137928009032
- 1.4443178009986877
- 1.4275565099716188
- 1.4009162998199463
- 1.3867324447631837
- 1.3697798657417297
- 1.3566118717193603
- 1.342989718914032
- 1.3304009771347045
- 1.3212682604789734
- 1.3105739617347718
- 1.2987398314476013
- 1.2926957964897157
- 1.2856930851936341
- 1.276694927215576
- 1.2706156086921692
- 1.2631705164909364
- 1.2564804887771606
- 1.2460665774345399
- 1.240418679714203
- 1.235244598388672
- 1.228040771484375
- 1.2247870230674744
- 1.2250632643699646
- 1.220330057144165
- 1.2113228130340576
- 1.2051748490333558
- 1.1994713711738587
- 1.1949230575561522
- 1.1914188933372498
- 1.1872314167022706
- 1.1873614263534547
- 1.1798201394081116
- 1.1791689372062684
- 1.174993793964386
- 1.1717029762268067
- 1.167938802242279
- 1.164551854133606
- 1.1647172379493713
- 1.162263934612274
- 1.1583705186843871
- 1.15642742395401
- 1.1562783002853394
- 1.1520757913589477
- 1.1463488125801087
- 1.1414823842048645
- 1.140506911277771
- 1.142175486087799
- 1.1392364835739135
- 1.14093825340271
- 1.1347610425949097
- 1.134170343875885
- 1.1367326855659485
- 1.1299461865425109
- 1.1265371656417846
- 1.1269053530693054
- 1.1286875915527343
- 1.124613835811615
- 1.1253239870071412
- 1.1231765961647033
- 1.122815887928009
- 1.123996605873108
- 1.1246366238594054
- 1.1227980875968933
- 1.1231141114234924
- 1.1214453339576722
- 1.1216729402542114
- 1.1207944297790526
- 1.1192099976539611
- 1.1229640340805054
- 1.1195999383926392
- 1.1194350624084473
- 1.1236787152290344
- 1.1266010355949403
- 1.1215327286720276
- 1.1205516242980957
- 1.1208973717689514
- 1.1179177474975586
- 1.1173347544670105
- 1.1165066647529602
- 1.118564820289612
- 1.1240664672851564
- 1.1171171760559082
- 1.120881576538086
- 1.1207504343986512
- 1.120361008644104
- 1.120764434337616
- 1.1228840851783752
- 1.1197988510131835
- 1.1246522974967956
- 1.1184719181060792
- 1.1233012962341309
- 1.1241830062866212
- 1.1196388745307921
- 1.118797812461853
train_accuracy:
- 0.038
- 0.082
- 0.0
- 0.117
- 0.114
- 0.162
- 0.153
- 0.158
- 0.14
- 0.157
- 0.171
- 0.173
- 0.196
- 0.226
- 0.199
- 0.203
- 0.216
- 0.208
- 0.228
- 0.223
- 0.197
- 0.233
- 0.221
- 0.206
- 0.228
- 0.208
- 0.238
- 0.232
- 0.216
- 0.253
- 0.222
- 0.245
- 0.237
- 0.223
- 0.228
- 0.286
- 0.234
- 0.251
- 0.271
- 0.303
- 0.255
- 0.299
- 0.275
- 0.048
- 0.034
- 0.254
- 0.277
- 0.259
- 0.269
- 0.27
- 0.268
- 0.269
- 0.258
- 0.258
- 0.278
- 0.289
- 0.259
- 0.268
- 0.283
- 0.279
- 0.028
- 0.262
- 0.285
- 0.051
- 0.294
- 0.289
- 0.333
- 0.264
- 0.281
- 0.316
- 0.295
- 0.255
- 0.273
- 0.294
- 0.292
- 0.033
- 0.269
- 0.276
- 0.266
- 0.267
- 0.049
- 0.256
- 0.092
- 0.306
- 0.287
- 0.35
- 0.306
- 0.269
- 0.284
- 0.291
- 0.279
- 0.283
- 0.299
- 0.356
- 0.306
- 0.283
- 0.293
- 0.29
- 0.318
- 0.309
train_loss:
- 3.789
- 3.922
- 3.25
- 3.531
- 2.972
- 2.859
- 3.189
- 3.082
- 2.633
- 2.553
- 2.465
- 2.78
- 2.377
- 2.321
- 2.605
- 2.216
- 2.163
- 2.149
- 2.377
- 2.035
- 1.963
- 2.242
- 2.193
- 1.872
- 1.823
- 1.801
- 1.753
- 1.955
- 1.914
- 1.851
- 1.622
- 1.584
- 1.525
- 1.519
- 1.45
- 1.437
- 1.452
- 1.395
- 1.339
- 1.511
- 1.33
- 1.258
- 1.232
- 1.199
- 1.186
- 1.361
- 1.312
- 1.279
- 1.097
- 1.078
- 1.071
- 1.013
- 0.987
- 1.108
- 1.113
- 0.95
- 1.038
- 0.892
- 0.903
- 0.987
- 0.873
- 0.836
- 0.8
- 0.755
- 0.789
- 0.746
- 0.73
- 0.719
- 0.707
- 0.78
- 0.795
- 0.657
- 0.709
- 0.678
- 0.71
- 0.604
- 0.659
- 0.646
- 0.619
- 0.6
- 0.564
- 0.54
- 0.501
- 0.546
- 0.561
- 0.471
- 0.486
- 0.497
- 0.537
- 0.446
- 0.521
- 0.506
- 0.437
- 0.404
- 0.393
- 0.463
- 0.412
- 0.396
- 0.377
- 0.41
unequal: 0
verbose: 1
