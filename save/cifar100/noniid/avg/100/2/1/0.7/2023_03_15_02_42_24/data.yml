avg_train_accuracy: 0.3
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0411
- 0.0984
- 0.1221
- 0.1354
- 0.1463
- 0.1639
- 0.1681
- 0.1743
- 0.185
- 0.195
- 0.1974
- 0.1996
- 0.2136
- 0.2109
- 0.2173
- 0.2202
- 0.2268
- 0.2249
- 0.2294
- 0.2408
- 0.244
- 0.2411
- 0.2423
- 0.2538
- 0.2471
- 0.253
- 0.2551
- 0.2607
- 0.2586
- 0.2605
- 0.2612
- 0.2643
- 0.272
- 0.2725
- 0.2786
- 0.2727
- 0.2719
- 0.2741
- 0.2755
- 0.2821
- 0.2822
- 0.2805
- 0.2815
- 0.2908
- 0.2832
- 0.2874
- 0.2881
- 0.2918
- 0.293
- 0.2907
- 0.2926
- 0.2973
- 0.298
- 0.2994
- 0.2986
- 0.3046
- 0.2965
- 0.3013
- 0.3033
- 0.3049
- 0.2992
- 0.3026
- 0.3043
- 0.3035
- 0.3068
- 0.3065
- 0.3079
- 0.3055
- 0.3056
- 0.3107
- 0.3082
- 0.3114
- 0.3079
- 0.3096
- 0.3148
- 0.3108
- 0.3142
- 0.3093
- 0.3132
- 0.3087
- 0.3107
- 0.3111
- 0.3135
- 0.3151
- 0.313
- 0.3122
- 0.314
- 0.3208
- 0.3167
- 0.3202
- 0.3162
- 0.3196
- 0.3136
- 0.317
- 0.3211
- 0.3158
- 0.3212
- 0.3194
- 0.3213
- 0.3201
test_loss_list:
- 1.7862853717803955
- 1.648386607170105
- 1.5897642397880554
- 1.5427077221870422
- 1.502677628993988
- 1.4710570979118347
- 1.4478120350837707
- 1.4284832239151002
- 1.4072781467437745
- 1.3932100248336792
- 1.3811137437820435
- 1.3628492784500121
- 1.3507543516159057
- 1.3389735174179078
- 1.3269575071334838
- 1.315622203350067
- 1.3082532739639283
- 1.2981823372840882
- 1.2934710693359375
- 1.28544988155365
- 1.2840463590621949
- 1.2715961933135986
- 1.262662534713745
- 1.25485778093338
- 1.2515272855758668
- 1.2484163737297058
- 1.240397458076477
- 1.2299857211112977
- 1.2292235159873963
- 1.2251047110557556
- 1.2192353773117066
- 1.2146354794502259
- 1.212618465423584
- 1.204845700263977
- 1.2025644898414611
- 1.202011296749115
- 1.2023833298683166
- 1.1931495022773744
- 1.1899917507171631
- 1.1859709191322327
- 1.1908215117454528
- 1.1812425303459166
- 1.1817115497589112
- 1.1715711092948913
- 1.169699935913086
- 1.1649687361717225
- 1.16839839220047
- 1.1660274934768677
- 1.1623819136619569
- 1.159322097301483
- 1.1559760427474977
- 1.1518362975120544
- 1.154459822177887
- 1.1540579986572266
- 1.155992615222931
- 1.1534516429901123
- 1.1518964767456055
- 1.1495557045936584
- 1.1446066164970399
- 1.1468018627166747
- 1.1471691083908082
- 1.1413984489440918
- 1.140195746421814
- 1.1454669737815857
- 1.1437110805511475
- 1.1416389751434326
- 1.1407171726226806
- 1.1439724946022034
- 1.141020815372467
- 1.1397420811653136
- 1.1407745504379272
- 1.132739782333374
- 1.1399824333190918
- 1.1378544235229493
- 1.1355592799186707
- 1.1355321192741394
- 1.1387591505050658
- 1.1401123714447021
- 1.1426589727401733
- 1.1425183606147766
- 1.140138154029846
- 1.1388952374458312
- 1.1347262620925904
- 1.1398682713508606
- 1.1388891816139222
- 1.139916682243347
- 1.1400532412528992
- 1.1320011663436889
- 1.138696141242981
- 1.1349489736557006
- 1.137330825328827
- 1.1390206289291382
- 1.1405783557891847
- 1.1383556461334228
- 1.1387117576599122
- 1.1420520186424254
- 1.1407917761802673
- 1.13785062789917
- 1.1356301498413086
- 1.1407477068901062
train_accuracy:
- 0.033
- 0.073
- 0.113
- 0.12
- 0.122
- 0.131
- 0.145
- 0.159
- 0.175
- 0.187
- 0.19
- 0.189
- 0.163
- 0.003
- 0.173
- 0.03
- 0.191
- 0.18
- 0.209
- 0.222
- 0.212
- 0.191
- 0.218
- 0.215
- 0.184
- 0.204
- 0.255
- 0.224
- 0.052
- 0.201
- 0.277
- 0.245
- 0.243
- 0.245
- 0.259
- 0.239
- 0.236
- 0.251
- 0.245
- 0.259
- 0.265
- 0.27
- 0.253
- 0.241
- 0.27
- 0.271
- 0.269
- 0.29
- 0.234
- 0.252
- 0.075
- 0.254
- 0.251
- 0.273
- 0.275
- 0.267
- 0.293
- 0.255
- 0.302
- 0.276
- 0.307
- 0.251
- 0.29
- 0.277
- 0.255
- 0.26
- 0.272
- 0.291
- 0.276
- 0.334
- 0.307
- 0.296
- 0.267
- 0.084
- 0.288
- 0.274
- 0.284
- 0.301
- 0.281
- 0.272
- 0.08
- 0.255
- 0.298
- 0.093
- 0.259
- 0.307
- 0.307
- 0.297
- 0.301
- 0.309
- 0.255
- 0.283
- 0.344
- 0.29
- 0.285
- 0.287
- 0.276
- 0.112
- 0.267
- 0.3
train_loss:
- 4.344
- 3.912
- 3.689
- 3.069
- 2.987
- 3.312
- 2.8
- 3.119
- 2.644
- 2.952
- 2.854
- 2.43
- 2.761
- 2.328
- 2.28
- 2.241
- 2.502
- 2.146
- 2.073
- 2.317
- 2.25
- 1.967
- 1.921
- 2.157
- 1.809
- 2.039
- 1.757
- 1.758
- 1.693
- 1.664
- 1.588
- 1.564
- 1.748
- 1.546
- 1.718
- 1.442
- 1.398
- 1.389
- 1.322
- 1.518
- 1.508
- 1.253
- 1.21
- 1.422
- 1.222
- 1.179
- 1.153
- 1.259
- 1.109
- 1.099
- 1.033
- 1.059
- 1.007
- 1.109
- 1.099
- 1.082
- 0.919
- 0.868
- 0.995
- 0.991
- 0.835
- 0.81
- 0.83
- 0.795
- 0.753
- 0.767
- 0.858
- 0.737
- 0.709
- 0.686
- 0.687
- 0.672
- 0.638
- 0.639
- 0.703
- 0.632
- 0.684
- 0.57
- 0.64
- 0.54
- 0.534
- 0.524
- 0.509
- 0.53
- 0.503
- 0.483
- 0.47
- 0.574
- 0.489
- 0.52
- 0.427
- 0.505
- 0.448
- 0.421
- 0.418
- 0.401
- 0.404
- 0.392
- 0.403
- 0.382
unequal: 0
verbose: 1
