avg_train_accuracy: 0.3
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0403
- 0.0898
- 0.1094
- 0.1304
- 0.1385
- 0.152
- 0.1596
- 0.1724
- 0.1816
- 0.1869
- 0.1979
- 0.204
- 0.2058
- 0.211
- 0.2187
- 0.2225
- 0.2219
- 0.2333
- 0.2319
- 0.2385
- 0.2412
- 0.2444
- 0.2496
- 0.2595
- 0.2585
- 0.2632
- 0.2588
- 0.2689
- 0.2644
- 0.2737
- 0.2706
- 0.2746
- 0.2759
- 0.2775
- 0.2826
- 0.2813
- 0.2801
- 0.2863
- 0.2899
- 0.2926
- 0.294
- 0.2957
- 0.2937
- 0.2966
- 0.2964
- 0.2998
- 0.3009
- 0.3005
- 0.3075
- 0.3045
- 0.3081
- 0.3083
- 0.3089
- 0.3095
- 0.3098
- 0.3132
- 0.3114
- 0.312
- 0.3132
- 0.3147
- 0.3165
- 0.3182
- 0.317
- 0.3176
- 0.3161
- 0.321
- 0.3201
- 0.3204
- 0.3239
- 0.3227
- 0.3214
- 0.3235
- 0.3228
- 0.3211
- 0.3239
- 0.3259
- 0.3214
- 0.324
- 0.3241
- 0.3276
- 0.328
- 0.3266
- 0.3302
- 0.3315
- 0.3269
- 0.3303
- 0.332
- 0.3321
- 0.3296
- 0.3298
- 0.3307
- 0.333
- 0.3311
- 0.3337
- 0.3365
- 0.3352
- 0.3363
- 0.3342
- 0.3353
- 0.3341
test_loss_list:
- 1.785130648612976
- 1.6471846508979797
- 1.587985532283783
- 1.5384398627281188
- 1.4994566202163697
- 1.4696260833740233
- 1.4442695021629333
- 1.4275993371009827
- 1.4012661671638489
- 1.385489959716797
- 1.367994611263275
- 1.3586543154716493
- 1.342366132736206
- 1.3302695417404176
- 1.3168876600265502
- 1.311886305809021
- 1.298799867630005
- 1.2867488646507264
- 1.2808469080924987
- 1.2740770959854126
- 1.2622344517707824
- 1.257227418422699
- 1.2470373916625976
- 1.2372698187828064
- 1.2344943833351136
- 1.233367898464203
- 1.22624746799469
- 1.2221523857116698
- 1.2171155571937562
- 1.2097156858444214
- 1.205770173072815
- 1.2039890313148498
- 1.19294246673584
- 1.1885838198661804
- 1.1830752110481262
- 1.1809588718414306
- 1.1756690049171448
- 1.1716212224960327
- 1.1647447228431702
- 1.1635445594787597
- 1.1606275272369384
- 1.1612387442588805
- 1.1619431281089783
- 1.1589523935317994
- 1.1514486122131347
- 1.156627426147461
- 1.1555849361419677
- 1.1499832582473755
- 1.1456403756141662
- 1.1430241537094117
- 1.143199028968811
- 1.1375917410850525
- 1.1410232591629028
- 1.129972712993622
- 1.1329276013374328
- 1.1327344465255738
- 1.1439053344726562
- 1.1295734882354735
- 1.127611880302429
- 1.1262329292297364
- 1.121465392112732
- 1.1218976616859435
- 1.124119417667389
- 1.1292010474205016
- 1.1204227447509765
- 1.1185585689544677
- 1.1164004921913147
- 1.1189442682266235
- 1.1264174509048461
- 1.127473771572113
- 1.1193681955337524
- 1.117292296886444
- 1.1139830827713013
- 1.120223379135132
- 1.117706208229065
- 1.1217120671272278
- 1.1181767511367797
- 1.123432319164276
- 1.118029341697693
- 1.1147953057289124
- 1.1183915686607362
- 1.119255588054657
- 1.1156243586540222
- 1.1197529673576354
- 1.1157593941688537
- 1.1176568913459777
- 1.114338026046753
- 1.116908609867096
- 1.1178588366508484
- 1.1161029815673829
- 1.1165403723716736
- 1.120489888191223
- 1.1233681559562683
- 1.1162715530395508
- 1.115285699367523
- 1.1166440057754516
- 1.1158906245231628
- 1.116863307952881
- 1.1195285606384278
- 1.1264323329925536
train_accuracy:
- 0.063
- 0.07
- 0.091
- 0.119
- 0.146
- 0.181
- 0.186
- 0.167
- 0.187
- 0.173
- 0.233
- 0.204
- 0.181
- 0.186
- 0.236
- 0.239
- 0.202
- 0.199
- 0.262
- 0.205
- 0.24
- 0.038
- 0.247
- 0.24
- 0.241
- 0.247
- 0.266
- 0.318
- 0.262
- 0.257
- 0.295
- 0.314
- 0.025
- 0.293
- 0.277
- 0.047
- 0.244
- 0.267
- 0.253
- 0.305
- 0.305
- 0.315
- 0.283
- 0.306
- 0.03
- 0.314
- 0.282
- 0.267
- 0.27
- 0.326
- 0.295
- 0.284
- 0.287
- 0.271
- 0.323
- 0.285
- 0.346
- 0.358
- 0.048
- 0.321
- 0.317
- 0.281
- 0.34
- 0.379
- 0.03
- 0.061
- 0.301
- 0.339
- 0.335
- 0.345
- 0.349
- 0.279
- 0.306
- 0.341
- 0.08
- 0.355
- 0.327
- 0.316
- 0.045
- 0.082
- 0.341
- 0.043
- 0.36
- 0.298
- 0.033
- 0.299
- 0.341
- 0.083
- 0.305
- 0.319
- 0.348
- 0.311
- 0.32
- 0.042
- 0.077
- 0.305
- 0.096
- 0.355
- 0.344
- 0.3
train_loss:
- 3.782
- 3.417
- 3.237
- 3.584
- 2.972
- 2.866
- 2.795
- 3.1
- 2.638
- 2.575
- 2.51
- 2.814
- 2.373
- 2.289
- 2.288
- 2.553
- 2.169
- 2.131
- 2.062
- 2.334
- 2.005
- 1.963
- 1.895
- 1.877
- 1.801
- 2.056
- 1.737
- 1.969
- 1.637
- 1.876
- 1.581
- 1.836
- 1.549
- 1.482
- 1.472
- 1.445
- 1.385
- 1.364
- 1.372
- 1.323
- 1.272
- 1.276
- 1.265
- 1.387
- 1.169
- 1.353
- 1.305
- 1.097
- 1.249
- 1.072
- 1.188
- 1.048
- 1.125
- 0.991
- 0.956
- 1.061
- 1.037
- 0.877
- 0.867
- 0.838
- 0.861
- 0.813
- 0.908
- 0.898
- 0.775
- 0.739
- 0.72
- 0.808
- 0.785
- 0.76
- 0.677
- 0.66
- 0.623
- 0.619
- 0.599
- 0.691
- 0.586
- 0.65
- 0.581
- 0.548
- 0.618
- 0.527
- 0.584
- 0.564
- 0.505
- 0.543
- 0.484
- 0.457
- 0.441
- 0.428
- 0.418
- 0.483
- 0.479
- 0.392
- 0.408
- 0.401
- 0.404
- 0.383
- 0.424
- 0.412
unequal: 0
verbose: 1
