avg_train_accuracy: 0.293
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0317
- 0.0918
- 0.1152
- 0.132
- 0.1425
- 0.1522
- 0.1625
- 0.1728
- 0.1842
- 0.1928
- 0.1903
- 0.2019
- 0.2082
- 0.2174
- 0.2177
- 0.2263
- 0.2298
- 0.2289
- 0.2329
- 0.2346
- 0.2352
- 0.2453
- 0.2457
- 0.2506
- 0.2502
- 0.2519
- 0.2563
- 0.2593
- 0.2586
- 0.2591
- 0.2604
- 0.2641
- 0.2706
- 0.272
- 0.2752
- 0.269
- 0.2738
- 0.276
- 0.2805
- 0.2787
- 0.2804
- 0.281
- 0.2795
- 0.2838
- 0.2892
- 0.2877
- 0.29
- 0.2892
- 0.2916
- 0.294
- 0.2924
- 0.2962
- 0.2946
- 0.2941
- 0.2965
- 0.3021
- 0.301
- 0.3011
- 0.2994
- 0.2993
- 0.3001
- 0.2985
- 0.3014
- 0.3001
- 0.3035
- 0.3095
- 0.3056
- 0.3057
- 0.3063
- 0.3084
- 0.3052
- 0.3055
- 0.3087
- 0.31
- 0.3105
- 0.308
- 0.3127
- 0.3109
- 0.3132
- 0.3125
- 0.3123
- 0.3131
- 0.3134
- 0.3121
- 0.3142
- 0.3139
- 0.314
- 0.3145
- 0.3148
- 0.3157
- 0.3139
- 0.316
- 0.3167
- 0.3199
- 0.3178
- 0.3182
- 0.3151
- 0.3193
- 0.319
- 0.3182
test_loss_list:
- 1.7997835874557495
- 1.655829544067383
- 1.594138696193695
- 1.5508976650238038
- 1.5154658555984497
- 1.4887671184539795
- 1.4641010403633117
- 1.441546423435211
- 1.4218263125419617
- 1.4086105418205261
- 1.3877796506881714
- 1.3712524724006654
- 1.3627447915077209
- 1.3502668690681459
- 1.3333220958709717
- 1.3274772024154664
- 1.3188537454605103
- 1.304230055809021
- 1.29630300283432
- 1.2894303250312804
- 1.2835791683197022
- 1.2738303351402283
- 1.266964135169983
- 1.2624747681617736
- 1.2514282512664794
- 1.2503389525413513
- 1.2393637800216675
- 1.233422918319702
- 1.2310322427749634
- 1.2297645974159241
- 1.229003803730011
- 1.2252459335327148
- 1.2238275146484374
- 1.2096194911003113
- 1.2059677815437317
- 1.202869281768799
- 1.2030970692634582
- 1.205477201938629
- 1.2012050938606262
- 1.192115387916565
- 1.1865198826789856
- 1.1805586791038514
- 1.1797924160957336
- 1.1799580192565917
- 1.1755691623687745
- 1.1827888536453246
- 1.1757549905776978
- 1.1743448495864868
- 1.1677467584609986
- 1.1615098667144776
- 1.1624103927612304
- 1.1641725015640259
- 1.1617551612854005
- 1.1588093662261962
- 1.1602841591835023
- 1.1604444885253906
- 1.159041290283203
- 1.1508334398269653
- 1.1533849143981934
- 1.1480543828010559
- 1.145402765274048
- 1.1502001237869264
- 1.1433494901657104
- 1.144667296409607
- 1.1469866728782654
- 1.1392237091064452
- 1.1413951635360717
- 1.1430387544631957
- 1.1390573906898498
- 1.142440104484558
- 1.1366856122016906
- 1.1370666933059692
- 1.1349856853485107
- 1.1325053238868714
- 1.1334711766242982
- 1.1376432991027832
- 1.1316450333595276
- 1.1319189667701721
- 1.1354781413078308
- 1.135027368068695
- 1.1371926403045653
- 1.141151032447815
- 1.1368821716308595
- 1.132848083972931
- 1.1405658793449402
- 1.143393611907959
- 1.137394917011261
- 1.1342349195480346
- 1.1397217869758607
- 1.1317949509620666
- 1.1366958785057069
- 1.1364868712425231
- 1.1344793033599854
- 1.1362430739402771
- 1.1403821921348571
- 1.1362988543510437
- 1.138643617630005
- 1.141057050228119
- 1.1378166437149049
- 1.1387744641304016
train_accuracy:
- 0.033
- 0.079
- 0.092
- 0.109
- 0.103
- 0.092
- 0.112
- 0.15
- 0.16
- 0.137
- 0.184
- 0.01
- 0.21
- 0.197
- 0.217
- 0.198
- 0.186
- 0.002
- 0.2
- 0.195
- 0.174
- 0.034
- 0.202
- 0.196
- 0.257
- 0.204
- 0.197
- 0.187
- 0.217
- 0.275
- 0.283
- 0.23
- 0.218
- 0.221
- 0.031
- 0.261
- 0.235
- 0.203
- 0.253
- 0.231
- 0.261
- 0.244
- 0.053
- 0.246
- 0.267
- 0.305
- 0.023
- 0.282
- 0.285
- 0.271
- 0.238
- 0.065
- 0.062
- 0.317
- 0.27
- 0.267
- 0.277
- 0.325
- 0.271
- 0.294
- 0.327
- 0.274
- 0.303
- 0.077
- 0.281
- 0.281
- 0.275
- 0.302
- 0.055
- 0.278
- 0.052
- 0.309
- 0.051
- 0.32
- 0.291
- 0.303
- 0.291
- 0.309
- 0.255
- 0.286
- 0.295
- 0.252
- 0.318
- 0.089
- 0.292
- 0.294
- 0.05
- 0.254
- 0.258
- 0.326
- 0.337
- 0.288
- 0.306
- 0.306
- 0.293
- 0.284
- 0.304
- 0.311
- 0.29
- 0.293
train_loss:
- 3.799
- 3.42
- 3.228
- 3.089
- 2.955
- 2.869
- 2.759
- 2.717
- 3.029
- 2.949
- 2.499
- 2.43
- 2.724
- 2.69
- 2.278
- 2.554
- 2.501
- 2.108
- 2.049
- 2.022
- 2.002
- 1.954
- 1.918
- 2.156
- 1.853
- 2.049
- 1.734
- 1.731
- 1.679
- 1.654
- 1.863
- 1.807
- 1.767
- 1.506
- 1.489
- 1.456
- 1.611
- 1.584
- 1.579
- 1.35
- 1.291
- 1.298
- 1.224
- 1.214
- 1.387
- 1.312
- 1.114
- 1.267
- 1.107
- 1.097
- 1.01
- 0.999
- 0.976
- 0.986
- 1.073
- 1.095
- 1.058
- 0.908
- 0.862
- 0.863
- 0.841
- 0.799
- 0.81
- 0.762
- 0.756
- 0.776
- 0.746
- 0.821
- 0.695
- 0.771
- 0.664
- 0.764
- 0.647
- 0.624
- 0.622
- 0.571
- 0.6
- 0.586
- 0.634
- 0.533
- 0.585
- 0.586
- 0.5
- 0.532
- 0.57
- 0.535
- 0.474
- 0.457
- 0.513
- 0.454
- 0.451
- 0.418
- 0.434
- 0.464
- 0.442
- 0.404
- 0.376
- 0.363
- 0.384
- 0.424
unequal: 0
verbose: 1
