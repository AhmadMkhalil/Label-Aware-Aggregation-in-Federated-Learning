avg_train_accuracy: 0.297
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0487
- 0.0183
- 0.0811
- 0.0185
- 0.0995
- 0.0185
- 0.1137
- 0.1267
- 0.1293
- 0.1434
- 0.147
- 0.156
- 0.1669
- 0.1643
- 0.1719
- 0.1765
- 0.1748
- 0.0182
- 0.0192
- 0.18
- 0.1904
- 0.184
- 0.0195
- 0.1866
- 0.196
- 0.1962
- 0.2038
- 0.2127
- 0.2049
- 0.2119
- 0.2143
- 0.2115
- 0.2122
- 0.2288
- 0.2248
- 0.2302
- 0.2364
- 0.2382
- 0.2436
- 0.2363
- 0.2345
- 0.242
- 0.2459
- 0.2353
- 0.2421
- 0.2496
- 0.2541
- 0.255
- 0.2554
- 0.2527
- 0.0195
- 0.267
- 0.2623
- 0.2597
- 0.26
- 0.2745
- 0.2678
- 0.0194
- 0.2682
- 0.2742
- 0.2839
- 0.2771
- 0.2821
- 0.2758
- 0.2809
- 0.2698
- 0.2765
- 0.2764
- 0.2856
- 0.2835
- 0.2819
- 0.2889
- 0.2913
- 0.2834
- 0.2838
- 0.0199
- 0.2736
- 0.2831
- 0.2841
- 0.287
- 0.2818
- 0.0217
- 0.2935
- 0.2793
- 0.2844
- 0.0223
- 0.293
- 0.2934
- 0.3001
- 0.2984
- 0.3021
- 0.2903
- 0.2967
- 0.2974
- 0.3028
- 0.0217
- 0.3054
- 0.311
- 0.3057
- 0.3088
test_loss_list:
- 1.7988590002059937
- 4.284705095291137
- 1.6772978401184082
- 4.101751708984375
- 1.6388063764572143
- 4.179608507156372
- 1.589955461025238
- 1.5759510827064513
- 1.5366922426223755
- 1.5270761132240296
- 1.5088167333602904
- 1.5151146793365478
- 1.4940986084938048
- 1.4660477995872498
- 1.4662308931350707
- 1.4496716284751892
- 1.4551381421089173
- 4.255381269454956
- 4.311567258834839
- 1.4212493133544921
- 1.4153912901878356
- 1.4397704410552978
- 4.175469274520874
- 1.4380099487304687
- 1.4173063802719117
- 1.3979739904403687
- 1.3968626213073732
- 1.3597979140281677
- 1.3550943040847778
- 1.3513743662834168
- 1.3436977577209472
- 1.3660791301727295
- 1.359548842906952
- 1.3404982590675354
- 1.337859208583832
- 1.3368401908874512
- 1.3269862532615662
- 1.3281625056266784
- 1.3253803086280822
- 1.314501268863678
- 1.327369179725647
- 1.3214867615699768
- 1.317264688014984
- 1.3330737376213073
- 1.3306646132469178
- 1.2961191821098328
- 1.2831829953193665
- 1.2786800265312195
- 1.2914173650741576
- 1.2906037616729735
- 4.223489875793457
- 1.262771692276001
- 1.26091228723526
- 1.2775117826461793
- 1.2785769748687743
- 1.2422374701499939
- 1.2635274243354797
- 3.9838626098632814
- 1.2503052759170532
- 1.2354717397689818
- 1.2023126268386841
- 1.236629180908203
- 1.2445049238204957
- 1.238614752292633
- 1.2424162459373473
- 1.2523916101455688
- 1.2474638032913208
- 1.246289119720459
- 1.2304448223114013
- 1.2318466305732727
- 1.234138367176056
- 1.2090332293510437
- 1.2250050806999206
- 1.2507050848007202
- 1.2486353421211243
- 3.9858146381378172
- 1.2593744397163391
- 1.2401012659072876
- 1.2380970191955567
- 1.217384054660797
- 1.2509991574287413
- 4.00822003364563
- 1.2083236575126648
- 1.2428040599822998
- 1.2254194617271423
- 3.7336167907714843
- 1.200293583869934
- 1.2164173769950866
- 1.190042064189911
- 1.2025969862937926
- 1.2127433443069457
- 1.2340003085136413
- 1.2122187995910645
- 1.202269022464752
- 1.19184232711792
- 3.767274160385132
- 1.1883617591857911
- 1.1888557386398315
- 1.2084367966651917
- 1.20184410572052
train_accuracy:
- 0.071
- 0.873
- 0.093
- 0.968
- 0.091
- 0.962
- 0.085
- 0.12
- 0.113
- 0.094
- 0.2
- 0.212
- 0.172
- 0.159
- 0.21
- 0.138
- 0.12
- 0.841
- 0.904
- 0.187
- 0.265
- 0.24
- 0.927
- 0.258
- 0.221
- 0.152
- 0.231
- 0.159
- 0.178
- 0.18
- 0.181
- 0.178
- 0.211
- 0.2
- 0.219
- 0.181
- 0.21
- 0.205
- 0.278
- 0.221
- 0.223
- 0.277
- 0.218
- 0.267
- 0.266
- 0.231
- 0.271
- 0.256
- 0.284
- 0.212
- 0.926
- 0.243
- 0.229
- 0.24
- 0.293
- 0.28
- 0.22
- 0.912
- 0.31
- 0.281
- 0.293
- 0.221
- 0.331
- 0.263
- 0.333
- 0.276
- 0.252
- 0.233
- 0.339
- 0.228
- 0.26
- 0.301
- 0.326
- 0.322
- 0.342
- 0.877
- 0.301
- 0.248
- 0.238
- 0.284
- 0.308
- 0.953
- 0.326
- 0.239
- 0.297
- 0.926
- 0.251
- 0.315
- 0.285
- 0.251
- 0.344
- 0.268
- 0.342
- 0.276
- 0.299
- 0.925
- 0.347
- 0.304
- 0.251
- 0.297
train_loss:
- 4.296
- 0.515
- 4.282
- 0.491
- 4.014
- 0.409
- 3.837
- 3.479
- 3.419
- 3.393
- 3.166
- 2.706
- 3.116
- 3.1
- 2.536
- 2.919
- 2.912
- 0.458
- 0.084
- 3.277
- 2.272
- 1.84
- 0.364
- 1.877
- 2.808
- 2.556
- 2.319
- 2.903
- 2.616
- 2.423
- 2.166
- 1.734
- 2.178
- 2.54
- 1.763
- 2.225
- 2.119
- 1.753
- 1.743
- 1.713
- 1.261
- 1.486
- 1.597
- 2.038
- 1.244
- 2.311
- 2.314
- 1.424
- 1.099
- 1.782
- 0.411
- 2.128
- 1.459
- 1.419
- 1.742
- 1.947
- 1.248
- 0.333
- 1.62
- 1.941
- 2.1
- 1.311
- 1.093
- 1.242
- 0.783
- 0.916
- 1.173
- 1.485
- 1.275
- 1.102
- 0.829
- 1.713
- 0.809
- 0.502
- 1.034
- 0.351
- 1.837
- 0.935
- 1.232
- 1.382
- 0.872
- 0.319
- 1.526
- 0.811
- 1.539
- 0.253
- 1.201
- 0.92
- 0.861
- 0.759
- 0.666
- 1.054
- 0.932
- 0.643
- 0.635
- 0.262
- 1.269
- 0.506
- 0.677
- 0.861
unequal: 0
verbose: 1
