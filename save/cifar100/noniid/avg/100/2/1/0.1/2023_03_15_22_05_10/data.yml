avg_train_accuracy: 0.296
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0179
- 0.0706
- 0.0913
- 0.0984
- 0.1204
- 0.1269
- 0.1371
- 0.1386
- 0.1493
- 0.1629
- 0.1615
- 0.1684
- 0.172
- 0.1822
- 0.1869
- 0.1943
- 0.1952
- 0.2019
- 0.193
- 0.2061
- 0.2015
- 0.2117
- 0.2165
- 0.2222
- 0.2217
- 0.2261
- 0.2252
- 0.2247
- 0.2323
- 0.2367
- 0.2378
- 0.2449
- 0.2502
- 0.2487
- 0.2434
- 0.2584
- 0.2551
- 0.248
- 0.2579
- 0.2562
- 0.0183
- 0.256
- 0.2523
- 0.2608
- 0.2571
- 0.2359
- 0.2649
- 0.2613
- 0.27
- 0.2722
- 0.2744
- 0.2581
- 0.2654
- 0.2693
- 0.2867
- 0.281
- 0.2834
- 0.2811
- 0.2714
- 0.2688
- 0.2709
- 0.2822
- 0.2893
- 0.2863
- 0.2876
- 0.2863
- 0.2817
- 0.2944
- 0.0189
- 0.2794
- 0.2985
- 0.2902
- 0.2924
- 0.019
- 0.2891
- 0.298
- 0.291
- 0.2942
- 0.2992
- 0.3032
- 0.2926
- 0.3041
- 0.3056
- 0.3023
- 0.3004
- 0.3019
- 0.3068
- 0.3052
- 0.0199
- 0.3027
- 0.3027
- 0.3171
- 0.3081
- 0.3101
- 0.3127
- 0.3208
- 0.0197
- 0.3142
- 0.307
- 0.308
test_loss_list:
- 3.3303281116485595
- 1.7650724840164185
- 1.6869100999832154
- 1.6380136442184448
- 1.5930053091049194
- 1.557841386795044
- 1.5461693120002746
- 1.519384379386902
- 1.5056724286079406
- 1.490729775428772
- 1.4837185144424438
- 1.479767882823944
- 1.4629468941688537
- 1.4484156012535094
- 1.4573166251182557
- 1.4404574537277222
- 1.4171463871002197
- 1.397523477077484
- 1.4156400489807128
- 1.4052597498893737
- 1.4165656805038451
- 1.3734854793548583
- 1.3654028654098511
- 1.3533434963226318
- 1.353213176727295
- 1.3473808097839355
- 1.3562199234962464
- 1.3534125733375548
- 1.3393006992340089
- 1.3339251565933228
- 1.3255185270309449
- 1.3117582249641417
- 1.32002343416214
- 1.295594916343689
- 1.3237349390983582
- 1.2936630725860596
- 1.2878471064567565
- 1.310956678390503
- 1.2832648181915283
- 1.2837952041625977
- 4.555366554260254
- 1.2703833341598512
- 1.2787881422042846
- 1.2793399667739869
- 1.2936393737792968
- 1.3644981646537782
- 1.2670082473754882
- 1.2661670470237731
- 1.2529169726371765
- 1.2542252516746522
- 1.2501797461509705
- 1.276246852874756
- 1.262771348953247
- 1.267569661140442
- 1.2372447180747985
- 1.241824414730072
- 1.2318323802948
- 1.2328987550735473
- 1.2580399417877197
- 1.2703989267349243
- 1.2762870478630066
- 1.2749021244049072
- 1.228432924747467
- 1.2639897608757018
- 1.2406417155265808
- 1.2604275751113891
- 1.2642526149749755
- 1.2547156047821044
- 4.587997779846192
- 1.2439809560775756
- 1.1959519743919373
- 1.233222119808197
- 1.2320140957832337
- 4.194667510986328
- 1.2187116646766663
- 1.2025750970840454
- 1.2258744883537291
- 1.2190314316749573
- 1.2239887595176697
- 1.206255226135254
- 1.2279779672622682
- 1.2065499210357666
- 1.20598637342453
- 1.2140999460220336
- 1.2047436118125916
- 1.214758267402649
- 1.2050403141975403
- 1.2221092224121093
- 4.214802389144897
- 1.2004556608200074
- 1.2041734051704407
- 1.178626663684845
- 1.190633156299591
- 1.1993242383003235
- 1.2087556004524231
- 1.181693868637085
- 4.149617509841919
- 1.188047125339508
- 1.203538520336151
- 1.208965175151825
train_accuracy:
- 0.885
- 0.058
- 0.087
- 0.08
- 0.098
- 0.113
- 0.122
- 0.109
- 0.14
- 0.167
- 0.171
- 0.164
- 0.139
- 0.166
- 0.163
- 0.179
- 0.191
- 0.19
- 0.171
- 0.161
- 0.159
- 0.202
- 0.205
- 0.148
- 0.231
- 0.205
- 0.223
- 0.203
- 0.214
- 0.193
- 0.246
- 0.253
- 0.232
- 0.245
- 0.257
- 0.186
- 0.225
- 0.228
- 0.259
- 0.258
- 0.899
- 0.218
- 0.238
- 0.232
- 0.229
- 0.179
- 0.264
- 0.256
- 0.273
- 0.278
- 0.212
- 0.253
- 0.26
- 0.265
- 0.292
- 0.273
- 0.273
- 0.277
- 0.256
- 0.262
- 0.248
- 0.27
- 0.273
- 0.266
- 0.277
- 0.274
- 0.263
- 0.279
- 0.904
- 0.284
- 0.27
- 0.26
- 0.302
- 0.843
- 0.285
- 0.3
- 0.271
- 0.289
- 0.293
- 0.281
- 0.299
- 0.302
- 0.294
- 0.212
- 0.305
- 0.323
- 0.314
- 0.287
- 0.878
- 0.236
- 0.307
- 0.321
- 0.303
- 0.339
- 0.284
- 0.303
- 0.868
- 0.313
- 0.295
- 0.296
train_loss:
- 0.438
- 4.524
- 3.904
- 3.824
- 3.603
- 3.496
- 3.409
- 3.125
- 3.196
- 3.311
- 2.839
- 2.922
- 2.937
- 2.551
- 2.609
- 2.887
- 2.844
- 2.664
- 2.158
- 2.728
- 2.165
- 2.846
- 2.052
- 2.783
- 2.4
- 1.802
- 2.381
- 2.41
- 2.11
- 2.389
- 2.053
- 2.264
- 2.313
- 2.233
- 1.705
- 2.086
- 1.878
- 1.424
- 1.952
- 1.667
- 0.593
- 2.27
- 1.423
- 1.536
- 1.128
- 0.957
- 1.495
- 1.636
- 1.266
- 1.187
- 1.857
- 1.374
- 1.08
- 1.702
- 1.761
- 1.864
- 1.145
- 0.955
- 1.896
- 1.274
- 1.008
- 1.278
- 1.243
- 0.87
- 0.88
- 0.713
- 1.107
- 0.599
- 0.473
- 1.806
- 1.03
- 0.643
- 1.495
- 0.371
- 1.246
- 1.026
- 0.64
- 1.467
- 0.899
- 0.737
- 0.832
- 1.242
- 0.577
- 1.492
- 0.965
- 1.2
- 0.702
- 1.037
- 0.343
- 1.385
- 0.72
- 0.573
- 0.641
- 0.959
- 0.784
- 0.463
- 0.311
- 0.762
- 0.812
- 0.422
unequal: 0
verbose: 1
