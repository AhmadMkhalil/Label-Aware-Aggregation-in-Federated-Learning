avg_train_accuracy: 0.275
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0367
- 0.0881
- 0.1005
- 0.1143
- 0.0179
- 0.1242
- 0.1285
- 0.1378
- 0.1531
- 0.1514
- 0.156
- 0.158
- 0.1662
- 0.1727
- 0.1755
- 0.1851
- 0.1844
- 0.1832
- 0.1947
- 0.0195
- 0.1931
- 0.2079
- 0.21
- 0.21
- 0.0192
- 0.2236
- 0.2288
- 0.2211
- 0.2255
- 0.2184
- 0.2225
- 0.2243
- 0.2369
- 0.2386
- 0.2471
- 0.249
- 0.2501
- 0.2428
- 0.2431
- 0.2419
- 0.019
- 0.2462
- 0.2486
- 0.2529
- 0.2655
- 0.2588
- 0.2547
- 0.257
- 0.27
- 0.2562
- 0.2617
- 0.2644
- 0.2719
- 0.277
- 0.0195
- 0.0193
- 0.2777
- 0.284
- 0.2798
- 0.272
- 0.2748
- 0.2738
- 0.2684
- 0.2851
- 0.288
- 0.2797
- 0.2787
- 0.0193
- 0.2886
- 0.2778
- 0.2784
- 0.0194
- 0.2923
- 0.2811
- 0.2871
- 0.2883
- 0.283
- 0.2949
- 0.295
- 0.2869
- 0.299
- 0.2949
- 0.2867
- 0.2909
- 0.0228
- 0.2961
- 0.289
- 0.2915
- 0.0223
- 0.3065
- 0.0231
- 0.2895
- 0.3013
- 0.3046
- 0.0226
- 0.3023
- 0.2934
- 0.0265
- 0.3037
- 0.2962
test_loss_list:
- 1.7881896018981933
- 1.6859196615219116
- 1.6436515998840333
- 1.6023622465133667
- 4.537474479675293
- 1.5795046448707581
- 1.5729784965515137
- 1.538554651737213
- 1.5209972405433654
- 1.531644868850708
- 1.5086448073387146
- 1.4915401124954224
- 1.4839403247833252
- 1.4541525721549988
- 1.462966034412384
- 1.446392171382904
- 1.4292791152000428
- 1.4341334438323974
- 1.411579785346985
- 4.478699617385864
- 1.4086195850372314
- 1.383389344215393
- 1.3718141674995423
- 1.3700011229515077
- 4.57452654838562
- 1.3475022625923156
- 1.3318429827690124
- 1.3464150905609131
- 1.3266005158424377
- 1.3463548111915589
- 1.3382219076156616
- 1.3383221268653869
- 1.3134903836250305
- 1.3157081913948059
- 1.298592746257782
- 1.315514600276947
- 1.301909806728363
- 1.3185992980003356
- 1.331933515071869
- 1.342891082763672
- 4.546736841201782
- 1.3109738326072693
- 1.3223646807670593
- 1.294398114681244
- 1.2664581942558288
- 1.287725977897644
- 1.2733127355575562
- 1.2846082878112792
- 1.2728123664855957
- 1.2836053228378297
- 1.2820330619812013
- 1.259608542919159
- 1.243397397994995
- 1.2562137031555176
- 4.4184254550933835
- 4.384461412429809
- 1.2247705507278441
- 1.2178329753875732
- 1.2364679455757142
- 1.2462934255599976
- 1.246484854221344
- 1.2438570213317872
- 1.2662638664245605
- 1.2438959646224976
- 1.2285962224006652
- 1.232045876979828
- 1.2259387254714966
- 4.18095329284668
- 1.2153090310096741
- 1.2466310858726501
- 1.2460070538520813
- 4.1434512424469
- 1.2010454058647155
- 1.2084365892410278
- 1.2203974962234496
- 1.225511267185211
- 1.224182608127594
- 1.2209922909736632
- 1.2069481062889098
- 1.2362942910194397
- 1.20762446641922
- 1.2129067921638488
- 1.2292994308471679
- 1.2160750079154967
- 4.077872467041016
- 1.2076855564117432
- 1.2165791034698485
- 1.2053582644462586
- 3.848270196914673
- 1.1955261182785035
- 3.648952217102051
- 1.1952494740486146
- 1.2202512407302857
- 1.1950090074539184
- 3.656196537017822
- 1.1837381029129028
- 1.1928081178665162
- 3.3523720026016237
- 1.2010721611976622
- 1.2042409658432007
train_accuracy:
- 0.056
- 0.094
- 0.092
- 0.114
- 0.964
- 0.089
- 0.084
- 0.139
- 0.162
- 0.167
- 0.141
- 0.162
- 0.193
- 0.115
- 0.16
- 0.152
- 0.216
- 0.152
- 0.219
- 0.899
- 0.171
- 0.165
- 0.225
- 0.19
- 0.964
- 0.193
- 0.176
- 0.209
- 0.21
- 0.195
- 0.231
- 0.214
- 0.206
- 0.197
- 0.214
- 0.202
- 0.196
- 0.217
- 0.208
- 0.207
- 0.869
- 0.192
- 0.192
- 0.214
- 0.235
- 0.186
- 0.278
- 0.213
- 0.249
- 0.28
- 0.258
- 0.217
- 0.247
- 0.292
- 0.924
- 0.883
- 0.234
- 0.257
- 0.236
- 0.263
- 0.271
- 0.281
- 0.265
- 0.235
- 0.239
- 0.311
- 0.302
- 0.907
- 0.289
- 0.281
- 0.255
- 0.924
- 0.247
- 0.329
- 0.256
- 0.266
- 0.279
- 0.267
- 0.257
- 0.269
- 0.277
- 0.304
- 0.349
- 0.285
- 0.95
- 0.277
- 0.265
- 0.324
- 0.948
- 0.243
- 0.943
- 0.313
- 0.252
- 0.286
- 0.903
- 0.309
- 0.306
- 0.961
- 0.267
- 0.275
train_loss:
- 4.348
- 3.885
- 3.749
- 3.677
- 0.602
- 3.839
- 3.065
- 3.31
- 3.169
- 2.721
- 2.822
- 3.248
- 2.575
- 3.051
- 2.527
- 3.043
- 2.764
- 2.873
- 2.375
- 0.564
- 2.767
- 2.827
- 2.18
- 2.673
- 0.464
- 2.709
- 2.498
- 2.24
- 2.607
- 2.055
- 2.285
- 1.836
- 2.29
- 1.971
- 2.148
- 1.581
- 2.418
- 1.457
- 1.114
- 0.937
- 0.437
- 2.419
- 0.938
- 1.792
- 2.034
- 0.909
- 1.982
- 1.643
- 1.489
- 1.522
- 1.143
- 1.884
- 1.958
- 1.878
- 0.409
- 0.061
- 1.792
- 1.541
- 1.087
- 1.725
- 1.507
- 1.053
- 0.799
- 1.141
- 1.31
- 1.427
- 1.391
- 0.338
- 1.15
- 0.595
- 1.703
- 0.305
- 1.349
- 1.122
- 0.761
- 1.286
- 1.179
- 0.949
- 0.753
- 0.759
- 1.581
- 0.836
- 0.985
- 1.158
- 0.326
- 1.018
- 0.68
- 0.687
- 0.264
- 1.07
- 0.22
- 1.13
- 0.643
- 0.707
- 0.207
- 1.095
- 0.781
- 0.19
- 0.678
- 0.619
unequal: 0
verbose: 1
