avg_train_accuracy: 0.262
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0344
- 0.0742
- 0.101
- 0.113
- 0.1211
- 0.1322
- 0.1349
- 0.1466
- 0.1499
- 0.1509
- 0.1645
- 0.1726
- 0.1717
- 0.1816
- 0.1858
- 0.0186
- 0.019
- 0.182
- 0.1881
- 0.1925
- 0.0189
- 0.2021
- 0.2024
- 0.2073
- 0.2144
- 0.2183
- 0.2127
- 0.0195
- 0.0189
- 0.2136
- 0.21
- 0.2159
- 0.2289
- 0.0193
- 0.2279
- 0.2335
- 0.2342
- 0.2339
- 0.2274
- 0.2409
- 0.2416
- 0.2411
- 0.2423
- 0.2575
- 0.2468
- 0.2467
- 0.2452
- 0.2537
- 0.25
- 0.2599
- 0.2614
- 0.2555
- 0.2593
- 0.2595
- 0.2641
- 0.2617
- 0.2646
- 0.2667
- 0.2625
- 0.2676
- 0.2738
- 0.2726
- 0.272
- 0.2712
- 0.2719
- 0.2736
- 0.2701
- 0.2796
- 0.2725
- 0.273
- 0.2816
- 0.2771
- 0.2785
- 0.284
- 0.2857
- 0.289
- 0.2909
- 0.2845
- 0.2886
- 0.2846
- 0.2929
- 0.2958
- 0.2855
- 0.0196
- 0.2848
- 0.0207
- 0.2874
- 0.2961
- 0.288
- 0.2855
- 0.2902
- 0.2818
- 0.2958
- 0.0205
- 0.2962
- 0.2943
- 0.2919
- 0.2979
- 0.2882
- 0.2915
test_loss_list:
- 1.801296443939209
- 1.7021022462844848
- 1.6462844276428223
- 1.59358540058136
- 1.576195342540741
- 1.548425145149231
- 1.5374943327903747
- 1.5176997184753418
- 1.5194624948501587
- 1.4945060157775878
- 1.482527506351471
- 1.4643851613998413
- 1.463667016029358
- 1.443311960697174
- 1.4265612411499022
- 4.631890182495117
- 4.728228521347046
- 1.4201782941818237
- 1.427550721168518
- 1.4052568006515502
- 4.497743453979492
- 1.3994653797149659
- 1.369752128124237
- 1.3838760352134705
- 1.3639722061157227
- 1.362360486984253
- 1.3851280617713928
- 4.382261724472046
- 4.615864028930664
- 1.3501135802268982
- 1.3689043164253234
- 1.339427993297577
- 1.3280084204673768
- 4.30609164237976
- 1.332755753993988
- 1.30499370098114
- 1.3211453294754028
- 1.3205730271339418
- 1.3405359292030334
- 1.3018821597099304
- 1.3131735229492187
- 1.311865360736847
- 1.2923193883895874
- 1.2747896480560303
- 1.2989828276634217
- 1.291947157382965
- 1.287087459564209
- 1.2921544098854065
- 1.289828884601593
- 1.2780424118041993
- 1.281079773902893
- 1.2939952969551087
- 1.2737460255622863
- 1.2707011485099793
- 1.2669346737861633
- 1.2801830744743348
- 1.2585824918746948
- 1.26589195728302
- 1.2754698371887208
- 1.2700598669052123
- 1.2418576097488403
- 1.2553159499168396
- 1.2696820425987243
- 1.2720096707344055
- 1.2639619350433349
- 1.2760892510414124
- 1.289369342327118
- 1.2728886222839355
- 1.2698496961593628
- 1.2623428606987
- 1.2633305501937866
- 1.2624904274940492
- 1.2631287479400635
- 1.2679817795753479
- 1.242817461490631
- 1.2400352120399476
- 1.2537928771972657
- 1.253350613117218
- 1.2625848078727722
- 1.26830504655838
- 1.2413454937934876
- 1.2507690024375915
- 1.275604283809662
- 4.370675086975098
- 1.235165069103241
- 4.06494969367981
- 1.2277711510658265
- 1.2287853860855102
- 1.2357106733322143
- 1.2413026547431947
- 1.2398524260520936
- 1.2416221046447753
- 1.2247972536087035
- 4.094334459304809
- 1.21288006067276
- 1.233533375263214
- 1.247205171585083
- 1.2264162683486939
- 1.2571483802795411
- 1.2226644802093505
train_accuracy:
- 0.013
- 0.049
- 0.116
- 0.105
- 0.095
- 0.147
- 0.146
- 0.113
- 0.139
- 0.191
- 0.153
- 0.17
- 0.155
- 0.226
- 0.186
- 0.898
- 0.898
- 0.172
- 0.151
- 0.162
- 0.877
- 0.198
- 0.188
- 0.224
- 0.185
- 0.163
- 0.171
- 0.913
- 0.982
- 0.193
- 0.197
- 0.211
- 0.189
- 0.902
- 0.233
- 0.21
- 0.228
- 0.178
- 0.183
- 0.214
- 0.182
- 0.216
- 0.214
- 0.259
- 0.245
- 0.223
- 0.245
- 0.251
- 0.273
- 0.221
- 0.268
- 0.202
- 0.218
- 0.268
- 0.238
- 0.219
- 0.261
- 0.24
- 0.239
- 0.269
- 0.258
- 0.275
- 0.25
- 0.231
- 0.25
- 0.239
- 0.22
- 0.267
- 0.227
- 0.272
- 0.231
- 0.264
- 0.23
- 0.229
- 0.26
- 0.306
- 0.248
- 0.267
- 0.235
- 0.237
- 0.275
- 0.259
- 0.243
- 0.916
- 0.27
- 0.93
- 0.3
- 0.266
- 0.287
- 0.271
- 0.261
- 0.305
- 0.276
- 0.962
- 0.3
- 0.289
- 0.237
- 0.286
- 0.259
- 0.262
train_loss:
- 4.303
- 3.891
- 3.697
- 3.639
- 3.499
- 3.168
- 3.078
- 3.156
- 2.704
- 3.253
- 3.176
- 2.854
- 2.899
- 2.814
- 3.017
- 0.602
- 0.133
- 2.822
- 2.732
- 2.652
- 0.436
- 3.227
- 2.195
- 2.495
- 2.765
- 2.392
- 1.942
- 0.421
- 0.067
- 2.24
- 1.551
- 2.491
- 2.389
- 0.351
- 2.743
- 2.118
- 1.518
- 2.252
- 1.702
- 1.879
- 2.033
- 2.108
- 2.279
- 2.157
- 1.574
- 1.682
- 1.366
- 1.475
- 2.115
- 1.767
- 1.272
- 1.845
- 1.434
- 1.78
- 1.217
- 1.503
- 1.874
- 0.989
- 0.658
- 1.506
- 1.658
- 1.17
- 0.74
- 1.528
- 0.593
- 1.329
- 0.846
- 1.293
- 1.217
- 1.119
- 0.902
- 1.307
- 0.798
- 0.83
- 1.353
- 0.941
- 0.659
- 1.021
- 0.875
- 1.002
- 0.676
- 0.632
- 0.711
- 0.417
- 0.744
- 0.262
- 1.031
- 0.668
- 1.071
- 0.466
- 0.495
- 1.586
- 0.977
- 0.28
- 1.086
- 0.485
- 0.721
- 0.413
- 0.462
- 0.735
unequal: 0
verbose: 1
