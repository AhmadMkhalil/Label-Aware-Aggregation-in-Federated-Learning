avg_train_accuracy: 0.282
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0415
- 0.079
- 0.0952
- 0.1012
- 0.1235
- 0.1326
- 0.1342
- 0.14
- 0.1483
- 0.1636
- 0.1748
- 0.1655
- 0.183
- 0.1798
- 0.1691
- 0.1781
- 0.1926
- 0.1915
- 0.2097
- 0.1989
- 0.2085
- 0.2233
- 0.217
- 0.2286
- 0.2176
- 0.2238
- 0.0185
- 0.2227
- 0.2332
- 0.0188
- 0.2407
- 0.2312
- 0.236
- 0.0189
- 0.2408
- 0.231
- 0.2333
- 0.0192
- 0.2365
- 0.2332
- 0.236
- 0.2454
- 0.2511
- 0.2549
- 0.2523
- 0.2584
- 0.2611
- 0.2625
- 0.2546
- 0.2656
- 0.0187
- 0.2665
- 0.2666
- 0.2616
- 0.2732
- 0.0191
- 0.2676
- 0.277
- 0.2785
- 0.28
- 0.0191
- 0.2641
- 0.2726
- 0.2824
- 0.2814
- 0.2731
- 0.2844
- 0.2882
- 0.2813
- 0.0198
- 0.2808
- 0.2774
- 0.2871
- 0.2782
- 0.2816
- 0.2821
- 0.2866
- 0.0199
- 0.2903
- 0.2864
- 0.2841
- 0.2982
- 0.2936
- 0.2992
- 0.2911
- 0.3016
- 0.3019
- 0.3006
- 0.2968
- 0.2956
- 0.3083
- 0.3063
- 0.0208
- 0.3008
- 0.2969
- 0.2951
- 0.2952
- 0.2971
- 0.3079
- 0.3137
test_loss_list:
- 1.787273736000061
- 1.716005356311798
- 1.6425116348266602
- 1.6231938004493713
- 1.5768614840507507
- 1.567601912021637
- 1.5519888281822205
- 1.5398375988006592
- 1.5053295469284058
- 1.489277629852295
- 1.4593580555915833
- 1.474473226070404
- 1.441538462638855
- 1.4571325612068176
- 1.477076895236969
- 1.4598827362060547
- 1.4262016105651856
- 1.4178401255607604
- 1.3892152571678162
- 1.4023235511779786
- 1.375168182849884
- 1.3593592548370361
- 1.3658423447608947
- 1.3411685419082642
- 1.3702207446098327
- 1.3577653765678406
- 4.5049285984039305
- 1.3338433027267456
- 1.3053429055213928
- 4.351246995925903
- 1.2970340943336487
- 1.310933473110199
- 1.3122292971611023
- 4.189868030548095
- 1.2956274628639222
- 1.3118780946731567
- 1.2997234320640565
- 4.125967931747437
- 1.2963772201538086
- 1.3129815125465394
- 1.3351265096664429
- 1.3054753923416138
- 1.2754474043846131
- 1.2664047288894653
- 1.2835965704917909
- 1.2678317475318908
- 1.2555663180351258
- 1.262011170387268
- 1.2858813333511352
- 1.2553612184524536
- 4.145332326889038
- 1.2514672207832336
- 1.2475637149810792
- 1.2504420590400696
- 1.2276561069488525
- 3.9884179973602296
- 1.2377440571784972
- 1.2223417901992797
- 1.217064743041992
- 1.2209960842132568
- 3.9894542598724367
- 1.2451963758468627
- 1.2209638023376466
- 1.2004985189437867
- 1.2186213850975036
- 1.2479796314239502
- 1.2200398182868957
- 1.2079913091659547
- 1.231663055419922
- 3.8523702812194824
- 1.213366184234619
- 1.2414292621612548
- 1.221293749809265
- 1.2471208953857422
- 1.236007912158966
- 1.226584234237671
- 1.2189391589164733
- 3.8268104648590087
- 1.2050227165222167
- 1.2239732575416564
- 1.2251970076560974
- 1.1923358011245728
- 1.2056298685073852
- 1.2024657034873962
- 1.2110600638389588
- 1.2035189008712768
- 1.1900030732154847
- 1.206189284324646
- 1.2051713037490845
- 1.2272940969467163
- 1.193717863559723
- 1.1931234645843505
- 3.691091022491455
- 1.1966501379013061
- 1.200107147693634
- 1.2267491626739502
- 1.2132581639289857
- 1.193597333431244
- 1.1781412196159362
- 1.1739217233657837
train_accuracy:
- 0.038
- 0.058
- 0.093
- 0.088
- 0.129
- 0.127
- 0.159
- 0.117
- 0.134
- 0.17
- 0.138
- 0.177
- 0.198
- 0.175
- 0.166
- 0.152
- 0.174
- 0.189
- 0.236
- 0.195
- 0.183
- 0.244
- 0.2
- 0.176
- 0.172
- 0.196
- 0.908
- 0.195
- 0.191
- 0.948
- 0.259
- 0.202
- 0.207
- 0.911
- 0.227
- 0.236
- 0.237
- 0.91
- 0.237
- 0.246
- 0.253
- 0.215
- 0.263
- 0.213
- 0.254
- 0.216
- 0.212
- 0.245
- 0.258
- 0.298
- 0.883
- 0.238
- 0.253
- 0.251
- 0.305
- 0.919
- 0.229
- 0.252
- 0.239
- 0.312
- 0.923
- 0.229
- 0.265
- 0.239
- 0.268
- 0.263
- 0.239
- 0.319
- 0.233
- 0.932
- 0.318
- 0.271
- 0.241
- 0.224
- 0.245
- 0.234
- 0.329
- 0.958
- 0.243
- 0.265
- 0.285
- 0.277
- 0.257
- 0.328
- 0.262
- 0.284
- 0.273
- 0.276
- 0.291
- 0.295
- 0.279
- 0.278
- 0.897
- 0.332
- 0.338
- 0.295
- 0.286
- 0.3
- 0.29
- 0.282
train_loss:
- 4.434
- 3.615
- 3.799
- 3.633
- 3.604
- 3.15
- 3.15
- 3.07
- 3.304
- 2.807
- 3.057
- 2.519
- 3.087
- 2.27
- 1.882
- 2.747
- 2.941
- 2.943
- 2.624
- 2.469
- 2.884
- 2.267
- 2.569
- 2.586
- 2.023
- 2.188
- 0.617
- 2.771
- 2.477
- 0.45
- 2.321
- 2.307
- 2.1
- 0.397
- 2.766
- 1.924
- 2.018
- 0.352
- 1.941
- 1.308
- 1.083
- 2.043
- 1.765
- 2.036
- 1.226
- 1.663
- 2.012
- 1.683
- 1.079
- 1.511
- 0.366
- 1.892
- 1.716
- 2.071
- 1.239
- 0.32
- 2.136
- 1.589
- 1.405
- 1.033
- 0.3
- 1.73
- 1.695
- 1.19
- 1.263
- 0.917
- 0.992
- 0.96
- 0.742
- 0.295
- 0.899
- 0.959
- 0.658
- 1.352
- 1.444
- 1.004
- 0.692
- 0.252
- 1.582
- 1.152
- 1.13
- 0.775
- 0.908
- 0.578
- 1.071
- 0.874
- 0.602
- 0.8
- 0.993
- 0.721
- 0.661
- 0.53
- 0.278
- 0.717
- 0.316
- 1.371
- 1.663
- 1.101
- 0.885
- 0.489
unequal: 0
verbose: 1
