avg_train_accuracy: 0.3
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0377
- 0.0792
- 0.0907
- 0.1098
- 0.1189
- 0.1332
- 0.1471
- 0.1517
- 0.1544
- 0.1576
- 0.1618
- 0.1683
- 0.1646
- 0.1798
- 0.1866
- 0.1829
- 0.1961
- 0.1887
- 0.1976
- 0.1903
- 0.2023
- 0.2073
- 0.2083
- 0.222
- 0.2275
- 0.22
- 0.2229
- 0.2178
- 0.227
- 0.2343
- 0.2387
- 0.2447
- 0.2427
- 0.2426
- 0.2383
- 0.2393
- 0.2471
- 0.2477
- 0.2472
- 0.2439
- 0.2587
- 0.2628
- 0.2661
- 0.0188
- 0.2606
- 0.2522
- 0.2558
- 0.2745
- 0.2574
- 0.258
- 0.2545
- 0.2606
- 0.2651
- 0.2624
- 0.2633
- 0.2592
- 0.2728
- 0.2843
- 0.2863
- 0.2866
- 0.2819
- 0.287
- 0.2838
- 0.2752
- 0.2884
- 0.2962
- 0.2794
- 0.2942
- 0.2788
- 0.274
- 0.2935
- 0.2931
- 0.3038
- 0.288
- 0.2775
- 0.2978
- 0.2812
- 0.2867
- 0.2988
- 0.2939
- 0.3055
- 0.2898
- 0.3022
- 0.3081
- 0.0194
- 0.3061
- 0.3106
- 0.2987
- 0.2961
- 0.3025
- 0.2964
- 0.3025
- 0.3004
- 0.3118
- 0.0193
- 0.3011
- 0.3049
- 0.2966
- 0.3132
- 0.3129
test_loss_list:
- 1.7933064270019532
- 1.7027739334106444
- 1.651434440612793
- 1.603606972694397
- 1.5760468316078187
- 1.57631014585495
- 1.5348422312736512
- 1.519457950592041
- 1.5083965802192687
- 1.4876479649543761
- 1.4938605833053589
- 1.4738498282432557
- 1.4928553223609924
- 1.455122971534729
- 1.4383547377586365
- 1.4515732765197753
- 1.428213837146759
- 1.4251849460601806
- 1.4074033308029175
- 1.4083959341049195
- 1.3908225798606872
- 1.394482970237732
- 1.3911945557594299
- 1.3732840418815613
- 1.3481221604347229
- 1.360057728290558
- 1.3538869643211364
- 1.3632440090179443
- 1.3410199213027953
- 1.3296478915214538
- 1.3242960023880004
- 1.3274430656433105
- 1.3291923141479491
- 1.3202025365829468
- 1.33104159116745
- 1.3349853253364563
- 1.3186445140838623
- 1.3000757431983947
- 1.3051396298408509
- 1.3164038848876953
- 1.2976168870925904
- 1.283582453727722
- 1.2930873346328735
- 4.484308233261109
- 1.2786621761322021
- 1.2919916820526123
- 1.274990496635437
- 1.2592772793769837
- 1.2842656755447388
- 1.2874680685997009
- 1.3055659174919128
- 1.2795458674430846
- 1.2803463816642762
- 1.2847809886932373
- 1.2822139620780946
- 1.2798161315917969
- 1.2432934427261353
- 1.2288228154182435
- 1.236483108997345
- 1.235440320968628
- 1.2434504866600036
- 1.2361299753189088
- 1.2379967451095581
- 1.267913212776184
- 1.222811870574951
- 1.2319820594787598
- 1.250042061805725
- 1.2370158958435058
- 1.2459469079971313
- 1.271349744796753
- 1.2250292158126832
- 1.2196880221366881
- 1.2033181238174437
- 1.2433159828186036
- 1.2621349453926087
- 1.2240300512313842
- 1.2669253635406494
- 1.2571290493011475
- 1.2349246120452881
- 1.2292557549476624
- 1.237954683303833
- 1.2422369027137756
- 1.2178930473327636
- 1.2262302255630493
- 4.455701990127563
- 1.2075153064727784
- 1.2068735337257386
- 1.2193531727790832
- 1.25513765335083
- 1.2264125633239746
- 1.2292299604415893
- 1.2107609796524048
- 1.2267511487007141
- 1.2090938925743102
- 4.319418678283691
- 1.2197719764709474
- 1.2011058616638184
- 1.217513370513916
- 1.199012243747711
- 1.1915849089622497
train_accuracy:
- 0.042
- 0.069
- 0.081
- 0.086
- 0.088
- 0.125
- 0.131
- 0.128
- 0.168
- 0.155
- 0.155
- 0.185
- 0.17
- 0.17
- 0.205
- 0.19
- 0.16
- 0.161
- 0.206
- 0.199
- 0.182
- 0.215
- 0.199
- 0.189
- 0.254
- 0.231
- 0.255
- 0.243
- 0.248
- 0.242
- 0.243
- 0.208
- 0.228
- 0.255
- 0.228
- 0.23
- 0.228
- 0.284
- 0.242
- 0.284
- 0.225
- 0.271
- 0.223
- 0.892
- 0.265
- 0.264
- 0.295
- 0.253
- 0.285
- 0.308
- 0.311
- 0.253
- 0.302
- 0.261
- 0.302
- 0.302
- 0.239
- 0.325
- 0.281
- 0.263
- 0.266
- 0.332
- 0.283
- 0.277
- 0.31
- 0.276
- 0.286
- 0.298
- 0.295
- 0.287
- 0.321
- 0.255
- 0.28
- 0.302
- 0.289
- 0.346
- 0.333
- 0.345
- 0.334
- 0.333
- 0.333
- 0.237
- 0.344
- 0.299
- 0.972
- 0.33
- 0.288
- 0.299
- 0.283
- 0.353
- 0.358
- 0.327
- 0.302
- 0.315
- 0.919
- 0.299
- 0.247
- 0.305
- 0.319
- 0.3
train_loss:
- 4.375
- 3.962
- 3.735
- 3.594
- 3.574
- 3.12
- 3.422
- 3.139
- 3.189
- 3.233
- 2.814
- 3.083
- 2.458
- 2.917
- 3.052
- 2.247
- 2.731
- 2.87
- 2.655
- 2.671
- 2.88
- 2.105
- 2.475
- 2.425
- 2.653
- 2.325
- 2.515
- 1.955
- 2.291
- 2.448
- 2.209
- 2.11
- 1.991
- 1.98
- 1.918
- 1.419
- 2.438
- 2.183
- 1.886
- 1.723
- 1.871
- 1.739
- 1.466
- 0.618
- 1.783
- 1.092
- 2.144
- 1.346
- 1.655
- 1.189
- 0.979
- 1.949
- 0.949
- 1.668
- 0.844
- 1.696
- 2.006
- 1.282
- 1.526
- 1.258
- 1.303
- 0.985
- 1.496
- 0.976
- 1.366
- 1.019
- 0.91
- 1.289
- 1.079
- 1.63
- 0.947
- 1.639
- 0.927
- 1.276
- 0.822
- 1.094
- 0.635
- 0.439
- 0.8
- 0.97
- 0.567
- 1.388
- 0.763
- 0.798
- 0.516
- 0.783
- 0.548
- 1.123
- 0.698
- 0.697
- 0.364
- 0.691
- 0.673
- 1.108
- 0.402
- 0.768
- 1.152
- 0.995
- 0.469
- 0.58
unequal: 0
verbose: 1
