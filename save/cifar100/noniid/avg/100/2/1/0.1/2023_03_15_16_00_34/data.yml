avg_train_accuracy: 0.93
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0451
- 0.0787
- 0.0951
- 0.1069
- 0.1174
- 0.1177
- 0.1377
- 0.1467
- 0.1554
- 0.1556
- 0.1703
- 0.1807
- 0.1833
- 0.1755
- 0.0186
- 0.1838
- 0.2005
- 0.1938
- 0.2041
- 0.1975
- 0.019
- 0.1984
- 0.2083
- 0.2003
- 0.2068
- 0.2152
- 0.0189
- 0.2215
- 0.019
- 0.2176
- 0.218
- 0.2267
- 0.2233
- 0.2305
- 0.244
- 0.2446
- 0.2366
- 0.2396
- 0.2427
- 0.2532
- 0.2582
- 0.2541
- 0.0191
- 0.256
- 0.2549
- 0.2659
- 0.2619
- 0.2575
- 0.2656
- 0.2588
- 0.2524
- 0.2695
- 0.2679
- 0.0191
- 0.2649
- 0.2703
- 0.2788
- 0.2775
- 0.2708
- 0.271
- 0.2729
- 0.281
- 0.2847
- 0.2774
- 0.2803
- 0.2747
- 0.281
- 0.2627
- 0.2841
- 0.2836
- 0.2879
- 0.2703
- 0.2868
- 0.2991
- 0.2922
- 0.2857
- 0.2754
- 0.2927
- 0.2925
- 0.2954
- 0.2868
- 0.2854
- 0.2964
- 0.2919
- 0.0192
- 0.2965
- 0.2954
- 0.2971
- 0.2948
- 0.2832
- 0.0197
- 0.0197
- 0.3039
- 0.3043
- 0.0206
- 0.2982
- 0.3033
- 0.3013
- 0.3004
- 0.0224
test_loss_list:
- 1.7956644105911255
- 1.7028637361526489
- 1.6352881407737732
- 1.6049020600318908
- 1.5753958654403686
- 1.55658584356308
- 1.5384095120429992
- 1.5288693976402283
- 1.496830780506134
- 1.506357831954956
- 1.460500054359436
- 1.46399174451828
- 1.4476342630386352
- 1.4583083987236023
- 4.545158720016479
- 1.4284822010993958
- 1.4029163551330566
- 1.4203921413421632
- 1.4035143184661865
- 1.3948704934120177
- 4.376408710479736
- 1.3916276979446411
- 1.3648719573020935
- 1.38140127658844
- 1.373046052455902
- 1.354936420917511
- 4.257188053131103
- 1.3408111929893494
- 4.11226526260376
- 1.3273378705978394
- 1.338253903388977
- 1.3412195801734925
- 1.3556874632835387
- 1.321197988986969
- 1.3033665370941163
- 1.2779222321510315
- 1.2955759286880493
- 1.2982459521293641
- 1.2859260296821595
- 1.276812515258789
- 1.2789615273475647
- 1.2794434309005738
- 4.157224454879761
- 1.269014573097229
- 1.276778576374054
- 1.2507968831062317
- 1.2474130201339722
- 1.255470678806305
- 1.2519301104545593
- 1.258236927986145
- 1.2770041704177857
- 1.253807077407837
- 1.2510164761543274
- 4.138579521179199
- 1.2413655924797058
- 1.2303483533859252
- 1.2427699255943299
- 1.2486867022514343
- 1.2444837474822998
- 1.236326172351837
- 1.2415326189994813
- 1.2443122363090515
- 1.2244701862335206
- 1.2375917768478393
- 1.255434708595276
- 1.227727348804474
- 1.231632354259491
- 1.2693266654014588
- 1.2257487058639527
- 1.2307125902175904
- 1.2117164087295533
- 1.2607641172409059
- 1.2347977566719055
- 1.20665846824646
- 1.2323160004615783
- 1.2301529574394225
- 1.2672579550743104
- 1.2165525197982787
- 1.2311799645423889
- 1.227063889503479
- 1.2506581211090089
- 1.2437041425704956
- 1.2122294974327088
- 1.224819312095642
- 4.246452341079712
- 1.1963220763206481
- 1.2159557271003723
- 1.207761023044586
- 1.213085148334503
- 1.2434036016464234
- 4.035932989120483
- 4.053429031372071
- 1.192876009941101
- 1.2184027910232544
- 3.7262279891967776
- 1.2070814418792724
- 1.1955593633651733
- 1.1990996503829956
- 1.2094413805007935
- 3.626727638244629
train_accuracy:
- 0.025
- 0.053
- 0.075
- 0.102
- 0.084
- 0.147
- 0.127
- 0.152
- 0.161
- 0.136
- 0.171
- 0.179
- 0.164
- 0.178
- 0.859
- 0.19
- 0.173
- 0.179
- 0.195
- 0.181
- 0.916
- 0.176
- 0.214
- 0.164
- 0.216
- 0.221
- 0.859
- 0.202
- 0.938
- 0.202
- 0.21
- 0.208
- 0.228
- 0.218
- 0.227
- 0.245
- 0.223
- 0.265
- 0.229
- 0.248
- 0.233
- 0.256
- 0.907
- 0.225
- 0.236
- 0.214
- 0.257
- 0.267
- 0.232
- 0.274
- 0.255
- 0.278
- 0.208
- 0.919
- 0.273
- 0.298
- 0.29
- 0.278
- 0.295
- 0.246
- 0.276
- 0.272
- 0.271
- 0.299
- 0.261
- 0.253
- 0.284
- 0.257
- 0.271
- 0.319
- 0.306
- 0.262
- 0.271
- 0.292
- 0.306
- 0.338
- 0.255
- 0.318
- 0.309
- 0.278
- 0.283
- 0.316
- 0.277
- 0.335
- 0.938
- 0.285
- 0.294
- 0.271
- 0.351
- 0.328
- 0.949
- 0.925
- 0.306
- 0.311
- 0.919
- 0.29
- 0.272
- 0.335
- 0.295
- 0.93
train_loss:
- 4.327
- 3.93
- 3.81
- 3.653
- 3.61
- 3.507
- 3.379
- 3.129
- 3.226
- 3.083
- 3.168
- 2.752
- 2.928
- 2.476
- 0.579
- 3.11
- 2.809
- 2.315
- 2.659
- 2.971
- 0.472
- 2.671
- 2.428
- 2.215
- 2.035
- 2.687
- 0.438
- 2.652
- 0.345
- 2.541
- 1.858
- 2.347
- 1.783
- 2.611
- 2.696
- 2.352
- 2.148
- 1.677
- 2.161
- 1.993
- 2.28
- 1.823
- 0.388
- 2.257
- 1.782
- 2.079
- 1.958
- 1.633
- 1.802
- 1.514
- 1.071
- 1.741
- 1.723
- 0.36
- 1.74
- 1.953
- 1.522
- 1.046
- 1.208
- 1.572
- 1.115
- 1.044
- 1.712
- 1.508
- 0.884
- 1.59
- 1.648
- 1.203
- 1.413
- 1.147
- 1.3
- 1.06
- 1.293
- 1.099
- 0.881
- 0.905
- 1.051
- 1.126
- 1.261
- 0.819
- 0.546
- 0.92
- 1.246
- 0.829
- 0.413
- 0.875
- 0.907
- 0.458
- 0.659
- 0.415
- 0.29
- 0.026
- 1.31
- 0.825
- 0.233
- 0.667
- 0.975
- 0.488
- 0.648
- 0.256
unequal: 0
verbose: 1
