avg_train_accuracy: 0.913
avg_train_loss: 0.002
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0469
- 0.0913
- 0.1094
- 0.114
- 0.1302
- 0.1494
- 0.1546
- 0.1542
- 0.1472
- 0.163
- 0.1755
- 0.1737
- 0.1778
- 0.1724
- 0.1993
- 0.1835
- 0.1997
- 0.1969
- 0.017
- 0.1925
- 0.2047
- 0.0191
- 0.1982
- 0.2111
- 0.0187
- 0.2121
- 0.2212
- 0.2167
- 0.2111
- 0.204
- 0.2198
- 0.2302
- 0.2337
- 0.2325
- 0.0192
- 0.2352
- 0.2409
- 0.2366
- 0.2419
- 0.2405
- 0.2444
- 0.2391
- 0.2507
- 0.2526
- 0.2499
- 0.2541
- 0.2573
- 0.2537
- 0.2579
- 0.2536
- 0.2514
- 0.2425
- 0.2557
- 0.2634
- 0.2616
- 0.2595
- 0.2653
- 0.2576
- 0.2556
- 0.0193
- 0.2662
- 0.277
- 0.2788
- 0.2678
- 0.269
- 0.2791
- 0.2721
- 0.2714
- 0.2781
- 0.2807
- 0.2796
- 0.2821
- 0.2798
- 0.2873
- 0.2803
- 0.2835
- 0.2968
- 0.2869
- 0.2878
- 0.2882
- 0.2783
- 0.2848
- 0.2918
- 0.2791
- 0.288
- 0.2962
- 0.2972
- 0.2999
- 0.3004
- 0.2901
- 0.2991
- 0.305
- 0.0189
- 0.2959
- 0.2989
- 0.0215
- 0.2936
- 0.3008
- 0.2938
- 0.0214
test_loss_list:
- 1.780844316482544
- 1.6678931641578674
- 1.628348479270935
- 1.5995553755760192
- 1.5613787603378295
- 1.5448975920677186
- 1.5247812485694885
- 1.51055850982666
- 1.4999254608154298
- 1.4896312928199769
- 1.485457010269165
- 1.46008394241333
- 1.4769447040557862
- 1.461582522392273
- 1.4188952589035033
- 1.4376502180099486
- 1.4186657309532165
- 1.4253906989097596
- 4.6632138442993165
- 1.414596974849701
- 1.399671711921692
- 4.3310110473632815
- 1.3951703143119811
- 1.377683343887329
- 4.277861909866333
- 1.3623153209686278
- 1.3483976912498474
- 1.3435780787467957
- 1.3635767698287964
- 1.3848285031318666
- 1.3644728064537048
- 1.3550945210456848
- 1.3308783960342407
- 1.3263791942596435
- 4.437389183044433
- 1.3211238527297973
- 1.3201942944526672
- 1.3164196085929871
- 1.3227989864349365
- 1.3187136149406433
- 1.304464383125305
- 1.3048188543319703
- 1.2743534708023072
- 1.2727275776863098
- 1.3017702627182006
- 1.2856792378425599
- 1.2719026470184327
- 1.2927379488945008
- 1.2752724552154542
- 1.2953343772888184
- 1.2909695768356324
- 1.3162193775177002
- 1.2892260670661926
- 1.2726715755462648
- 1.2723317313194276
- 1.2824738574028016
- 1.2799982595443726
- 1.3066819620132446
- 1.3188475394248962
- 4.262176141738892
- 1.2744833827018738
- 1.2497318077087403
- 1.2320393300056458
- 1.2513405060768128
- 1.2327707862854005
- 1.2400121903419494
- 1.2507264494895936
- 1.266741268634796
- 1.2546065688133239
- 1.2425443506240845
- 1.2279217529296875
- 1.237522325515747
- 1.2476972103118897
- 1.227470064163208
- 1.2522699022293091
- 1.2437402892112732
- 1.2167616748809815
- 1.231096661090851
- 1.2256368279457093
- 1.2123856806755067
- 1.2448284196853638
- 1.2381430864334106
- 1.2280100202560424
- 1.2544711899757386
- 1.237519507408142
- 1.2302235746383667
- 1.2168809819221496
- 1.2178496026992798
- 1.211928253173828
- 1.2270993685722351
- 1.2188489174842834
- 1.2032122826576233
- 4.232186183929444
- 1.2027294540405273
- 1.2133709907531738
- 3.7906117820739746
- 1.221500198841095
- 1.2010465598106383
- 1.2163770651817323
- 3.7503840065002443
train_accuracy:
- 0.043
- 0.08
- 0.113
- 0.063
- 0.121
- 0.103
- 0.089
- 0.135
- 0.104
- 0.118
- 0.11
- 0.139
- 0.144
- 0.15
- 0.163
- 0.142
- 0.183
- 0.139
- 0.767
- 0.167
- 0.189
- 0.942
- 0.167
- 0.161
- 0.942
- 0.174
- 0.186
- 0.219
- 0.179
- 0.173
- 0.152
- 0.166
- 0.199
- 0.233
- 0.959
- 0.192
- 0.162
- 0.229
- 0.151
- 0.206
- 0.238
- 0.21
- 0.273
- 0.206
- 0.193
- 0.208
- 0.253
- 0.237
- 0.234
- 0.229
- 0.23
- 0.231
- 0.22
- 0.257
- 0.233
- 0.241
- 0.228
- 0.222
- 0.23
- 0.93
- 0.191
- 0.232
- 0.275
- 0.229
- 0.291
- 0.263
- 0.242
- 0.241
- 0.241
- 0.226
- 0.301
- 0.252
- 0.308
- 0.277
- 0.286
- 0.259
- 0.273
- 0.263
- 0.287
- 0.318
- 0.313
- 0.294
- 0.279
- 0.27
- 0.233
- 0.285
- 0.31
- 0.261
- 0.296
- 0.297
- 0.264
- 0.29
- 0.858
- 0.302
- 0.274
- 0.898
- 0.274
- 0.31
- 0.309
- 0.913
train_loss:
- 4.376
- 3.955
- 3.501
- 3.604
- 3.34
- 3.457
- 3.147
- 3.317
- 3.258
- 2.795
- 2.949
- 3.175
- 2.592
- 2.847
- 2.856
- 2.482
- 2.731
- 2.334
- 0.627
- 2.535
- 2.432
- 0.46
- 3.125
- 2.562
- 0.408
- 2.338
- 2.377
- 2.576
- 1.826
- 1.372
- 2.055
- 2.148
- 2.099
- 2.199
- 0.477
- 2.64
- 1.809
- 1.735
- 1.423
- 1.879
- 2.483
- 1.556
- 2.319
- 2.035
- 1.402
- 1.58
- 1.539
- 1.284
- 1.801
- 1.339
- 1.041
- 0.709
- 1.744
- 2.024
- 1.34
- 0.83
- 1.121
- 0.801
- 0.596
- 0.43
- 1.576
- 1.903
- 1.878
- 1.31
- 1.369
- 1.486
- 0.979
- 1.081
- 0.866
- 1.121
- 1.248
- 0.838
- 0.896
- 1.764
- 1.113
- 1.019
- 0.959
- 0.921
- 1.353
- 0.95
- 0.556
- 1.158
- 0.798
- 0.739
- 0.957
- 0.816
- 1.07
- 0.671
- 0.964
- 1.448
- 0.865
- 0.573
- 0.391
- 0.832
- 0.582
- 0.275
- 0.594
- 0.718
- 1.07
- 0.227
unequal: 0
verbose: 1
