avg_train_accuracy: 0.32
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.045
- 0.0844
- 0.0976
- 0.1179
- 0.1364
- 0.1499
- 0.1591
- 0.1719
- 0.1764
- 0.1815
- 0.1939
- 0.1964
- 0.2073
- 0.2089
- 0.2191
- 0.216
- 0.2209
- 0.23
- 0.2344
- 0.2344
- 0.2417
- 0.2416
- 0.2444
- 0.2482
- 0.2501
- 0.2479
- 0.2562
- 0.2578
- 0.2593
- 0.2651
- 0.2635
- 0.2662
- 0.2682
- 0.2721
- 0.2728
- 0.2761
- 0.278
- 0.2817
- 0.2821
- 0.2803
- 0.2815
- 0.2837
- 0.285
- 0.291
- 0.2902
- 0.2927
- 0.2903
- 0.2967
- 0.2965
- 0.2991
- 0.3001
- 0.2965
- 0.3002
- 0.3006
- 0.3038
- 0.3037
- 0.3054
- 0.3085
- 0.311
- 0.3094
- 0.3065
- 0.3088
- 0.3132
- 0.3137
- 0.3105
- 0.3132
- 0.314
- 0.3117
- 0.3128
- 0.3124
- 0.315
- 0.3194
- 0.3129
- 0.3161
- 0.3194
- 0.3214
- 0.3225
- 0.3192
- 0.3184
- 0.3249
- 0.3225
- 0.3202
- 0.3254
- 0.3233
- 0.3226
- 0.3255
- 0.327
- 0.326
- 0.3299
- 0.3232
- 0.3245
- 0.3248
- 0.3299
- 0.328
- 0.3283
- 0.3242
- 0.3308
- 0.3298
- 0.3334
- 0.329
test_loss_list:
- 1.7743845224380492
- 1.650305631160736
- 1.6022558426856994
- 1.5594971108436584
- 1.516927375793457
- 1.4895777893066406
- 1.464641842842102
- 1.441490545272827
- 1.423743326663971
- 1.4062816619873046
- 1.390567901134491
- 1.3734833097457886
- 1.3608249926567078
- 1.3499826025962829
- 1.341404342651367
- 1.3218235969543457
- 1.3134436368942262
- 1.3026609754562377
- 1.2946868896484376
- 1.283588058948517
- 1.2802836251258851
- 1.2772221493721008
- 1.2671433186531067
- 1.2592519545555114
- 1.25959210395813
- 1.253909044265747
- 1.241326506137848
- 1.2408362603187562
- 1.2316408848762512
- 1.223995156288147
- 1.2223965406417847
- 1.2235327291488647
- 1.2186632609367372
- 1.2153814268112182
- 1.2049415159225463
- 1.2051272368431092
- 1.1972073125839233
- 1.196705448627472
- 1.1924337482452392
- 1.1882750082015991
- 1.1890571737289428
- 1.1829331398010254
- 1.1828072357177735
- 1.1694398212432862
- 1.1674814534187317
- 1.169193251132965
- 1.1639164972305298
- 1.1589125776290894
- 1.1622710561752319
- 1.1628169703483582
- 1.1579476261138917
- 1.1559838438034058
- 1.1512006878852845
- 1.1528335738182067
- 1.1415887117385863
- 1.1455741000175477
- 1.1486242127418518
- 1.1457052516937256
- 1.1440097832679748
- 1.1459823632240296
- 1.1536667680740356
- 1.137948718070984
- 1.1397437167167663
- 1.1326213383674621
- 1.1401327228546143
- 1.13193838596344
- 1.1391591453552246
- 1.1399845695495605
- 1.137136607170105
- 1.1357323265075683
- 1.1285561966896056
- 1.1329491066932678
- 1.1304234147071839
- 1.132715678215027
- 1.1338599586486817
- 1.1221251487731934
- 1.1294552826881408
- 1.1272094440460205
- 1.1302027630805969
- 1.1246235060691834
- 1.1277635884284973
- 1.1343943524360656
- 1.1229264831542969
- 1.136406750679016
- 1.1295678210258484
- 1.119934492111206
- 1.1271254873275758
- 1.1291623973846436
- 1.1207578730583192
- 1.1317032408714294
- 1.1306290435791015
- 1.124813735485077
- 1.1219101309776307
- 1.128740885257721
- 1.1326993107795715
- 1.1394151854515076
- 1.1356534457206726
- 1.1269035816192627
- 1.123898878097534
- 1.1310808634757996
train_accuracy:
- 0.048
- 0.067
- 0.071
- 0.093
- 0.125
- 0.13
- 0.163
- 0.169
- 0.157
- 0.189
- 0.208
- 0.192
- 0.177
- 0.192
- 0.22
- 0.213
- 0.193
- 0.197
- 0.232
- 0.221
- 0.147
- 0.23
- 0.251
- 0.221
- 0.251
- 0.218
- 0.221
- 0.245
- 0.273
- 0.255
- 0.225
- 0.283
- 0.278
- 0.282
- 0.249
- 0.257
- 0.263
- 0.284
- 0.255
- 0.072
- 0.163
- 0.26
- 0.267
- 0.119
- 0.305
- 0.269
- 0.262
- 0.294
- 0.309
- 0.269
- 0.294
- 0.274
- 0.267
- 0.272
- 0.299
- 0.298
- 0.303
- 0.296
- 0.29
- 0.317
- 0.311
- 0.294
- 0.18
- 0.31
- 0.3
- 0.294
- 0.297
- 0.297
- 0.289
- 0.315
- 0.314
- 0.304
- 0.133
- 0.293
- 0.287
- 0.303
- 0.29
- 0.308
- 0.32
- 0.307
- 0.306
- 0.292
- 0.304
- 0.289
- 0.313
- 0.32
- 0.336
- 0.319
- 0.343
- 0.162
- 0.316
- 0.187
- 0.309
- 0.348
- 0.295
- 0.312
- 0.313
- 0.298
- 0.327
- 0.32
train_loss:
- 4.321
- 3.198
- 3.017
- 2.947
- 3.462
- 3.286
- 2.61
- 3.127
- 2.506
- 2.443
- 2.85
- 2.403
- 2.776
- 2.699
- 2.636
- 2.156
- 2.088
- 2.472
- 2.425
- 1.906
- 1.849
- 1.819
- 1.797
- 2.242
- 2.085
- 1.719
- 1.677
- 1.615
- 1.689
- 1.914
- 1.899
- 1.856
- 1.788
- 1.718
- 1.429
- 1.356
- 1.649
- 1.58
- 1.565
- 1.29
- 1.131
- 1.397
- 1.533
- 1.25
- 1.408
- 1.294
- 1.137
- 1.344
- 1.278
- 1.289
- 1.293
- 0.971
- 1.0
- 0.894
- 1.211
- 1.178
- 1.102
- 1.095
- 1.037
- 0.991
- 0.951
- 0.775
- 0.82
- 0.933
- 0.88
- 0.714
- 0.645
- 0.726
- 0.76
- 0.634
- 0.786
- 0.814
- 0.67
- 0.607
- 0.611
- 0.757
- 0.675
- 0.751
- 0.578
- 0.672
- 0.624
- 0.622
- 0.543
- 0.503
- 0.474
- 0.603
- 0.563
- 0.452
- 0.566
- 0.473
- 0.545
- 0.464
- 0.494
- 0.49
- 0.47
- 0.435
- 0.514
- 0.367
- 0.478
- 0.376
unequal: 0
verbose: 1
