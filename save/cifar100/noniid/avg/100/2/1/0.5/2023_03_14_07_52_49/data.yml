avg_train_accuracy: 0.285
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0284
- 0.0924
- 0.1168
- 0.1276
- 0.1412
- 0.1576
- 0.1653
- 0.1741
- 0.1825
- 0.19
- 0.1961
- 0.2038
- 0.2057
- 0.2159
- 0.2147
- 0.2238
- 0.2283
- 0.2307
- 0.2345
- 0.2432
- 0.247
- 0.246
- 0.2502
- 0.2556
- 0.2566
- 0.2565
- 0.2574
- 0.2629
- 0.2663
- 0.272
- 0.2735
- 0.2659
- 0.2772
- 0.2732
- 0.2754
- 0.2841
- 0.285
- 0.2906
- 0.2872
- 0.2896
- 0.2856
- 0.2912
- 0.298
- 0.2996
- 0.2939
- 0.2961
- 0.2945
- 0.3045
- 0.3018
- 0.3015
- 0.3068
- 0.3048
- 0.3071
- 0.303
- 0.3096
- 0.3113
- 0.3085
- 0.3199
- 0.3134
- 0.3147
- 0.3167
- 0.3179
- 0.3167
- 0.3142
- 0.3154
- 0.3208
- 0.3191
- 0.3208
- 0.3208
- 0.3186
- 0.3185
- 0.3201
- 0.3232
- 0.3178
- 0.3256
- 0.3189
- 0.3212
- 0.3247
- 0.3251
- 0.3264
- 0.3272
- 0.3301
- 0.3298
- 0.3226
- 0.3259
- 0.3192
- 0.3285
- 0.3233
- 0.3282
- 0.3273
- 0.3302
- 0.3269
- 0.3314
- 0.3266
- 0.3354
- 0.3329
- 0.3348
- 0.3392
- 0.3356
- 0.3352
test_loss_list:
- 1.7996918010711669
- 1.660240545272827
- 1.587340874671936
- 1.5467001843452453
- 1.5139504957199097
- 1.4828607797622682
- 1.4624332118034362
- 1.4346971440315246
- 1.4143182802200318
- 1.3997470998764039
- 1.3826324677467345
- 1.371792962551117
- 1.3612347626686097
- 1.3432091212272643
- 1.3352846026420593
- 1.3234734320640564
- 1.3106978249549865
- 1.302962782382965
- 1.2969904136657715
- 1.292382731437683
- 1.2834081053733826
- 1.2702707695960997
- 1.2634442973136901
- 1.2537715101242066
- 1.244758930206299
- 1.240633132457733
- 1.2358331394195556
- 1.2331279444694518
- 1.2296416854858399
- 1.2227821493148803
- 1.2225309777259827
- 1.2153241801261903
- 1.2069582748413086
- 1.2027613568305968
- 1.19953045129776
- 1.1915324091911317
- 1.1924968647956848
- 1.1848855209350586
- 1.181371147632599
- 1.1813430333137511
- 1.186342101097107
- 1.1706354761123656
- 1.1636756467819214
- 1.1657656955718994
- 1.165938639640808
- 1.1624230647087097
- 1.1677585959434509
- 1.1591376948356629
- 1.1547217631340028
- 1.1568881225585939
- 1.154314727783203
- 1.1565815567970277
- 1.1541262936592103
- 1.146753387451172
- 1.1440401029586793
- 1.142866747379303
- 1.1473171305656433
- 1.1352862429618835
- 1.1385784292221068
- 1.1384085965156556
- 1.1397580909729004
- 1.137274856567383
- 1.132447669506073
- 1.1376064729690551
- 1.1360897326469421
- 1.1289812326431274
- 1.1414372158050536
- 1.1409796500205993
- 1.1287806582450868
- 1.1320996046066285
- 1.1383332347869872
- 1.1339612436294555
- 1.1307017087936402
- 1.1296213841438294
- 1.1283887243270874
- 1.1336912155151366
- 1.129862723350525
- 1.1256953644752503
- 1.1299499797821044
- 1.1285325908660888
- 1.136742353439331
- 1.131710534095764
- 1.1375081157684326
- 1.1289783859252929
- 1.1266809964179993
- 1.1367557287216186
- 1.1273699736595153
- 1.1353783059120177
- 1.1257305335998535
- 1.1337159633636475
- 1.128764522075653
- 1.1314593386650085
- 1.1248459935188293
- 1.1308105754852296
- 1.1245505499839783
- 1.1263822221755981
- 1.129679262638092
- 1.131239037513733
- 1.1341887831687927
- 1.1351721692085266
train_accuracy:
- 0.164
- 0.09
- 0.101
- 0.109
- 0.132
- 0.153
- 0.119
- 0.161
- 0.164
- 0.155
- 0.155
- 0.154
- 0.164
- 0.193
- 0.177
- 0.195
- 0.226
- 0.141
- 0.216
- 0.236
- 0.229
- 0.239
- 0.158
- 0.229
- 0.111
- 0.237
- 0.245
- 0.244
- 0.247
- 0.279
- 0.239
- 0.259
- 0.264
- 0.271
- 0.266
- 0.268
- 0.244
- 0.269
- 0.261
- 0.279
- 0.268
- 0.26
- 0.267
- 0.284
- 0.264
- 0.267
- 0.283
- 0.302
- 0.126
- 0.287
- 0.327
- 0.285
- 0.291
- 0.247
- 0.301
- 0.126
- 0.296
- 0.306
- 0.311
- 0.29
- 0.29
- 0.304
- 0.246
- 0.345
- 0.285
- 0.302
- 0.316
- 0.308
- 0.271
- 0.293
- 0.315
- 0.3
- 0.3
- 0.269
- 0.307
- 0.264
- 0.212
- 0.327
- 0.317
- 0.305
- 0.3
- 0.326
- 0.302
- 0.303
- 0.314
- 0.308
- 0.343
- 0.296
- 0.277
- 0.309
- 0.324
- 0.305
- 0.327
- 0.33
- 0.313
- 0.32
- 0.364
- 0.335
- 0.315
- 0.285
train_loss:
- 3.555
- 3.212
- 3.697
- 2.905
- 2.782
- 3.298
- 3.168
- 2.527
- 2.506
- 2.925
- 2.397
- 2.239
- 2.707
- 2.221
- 2.134
- 2.146
- 2.523
- 2.004
- 2.391
- 2.302
- 2.258
- 1.842
- 1.793
- 2.191
- 1.741
- 1.697
- 1.628
- 1.576
- 1.922
- 1.922
- 1.83
- 1.486
- 1.725
- 1.421
- 1.386
- 1.633
- 1.58
- 1.636
- 1.285
- 1.618
- 1.251
- 1.242
- 1.486
- 1.392
- 1.164
- 1.09
- 1.291
- 1.235
- 1.058
- 1.206
- 1.189
- 1.11
- 1.185
- 0.973
- 1.093
- 0.926
- 0.872
- 1.042
- 0.99
- 0.798
- 0.783
- 0.904
- 0.814
- 0.709
- 0.677
- 0.881
- 0.807
- 0.868
- 0.733
- 0.679
- 0.616
- 0.614
- 0.622
- 0.708
- 0.729
- 0.58
- 0.536
- 0.67
- 0.649
- 0.642
- 0.614
- 0.633
- 0.594
- 0.45
- 0.507
- 0.456
- 0.577
- 0.426
- 0.471
- 0.444
- 0.431
- 0.434
- 0.512
- 0.413
- 0.483
- 0.43
- 0.456
- 0.457
- 0.42
- 0.402
unequal: 0
verbose: 1
