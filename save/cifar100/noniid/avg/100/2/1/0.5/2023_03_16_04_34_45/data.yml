avg_train_accuracy: 0.273
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0318
- 0.1027
- 0.1153
- 0.1348
- 0.1453
- 0.1588
- 0.1674
- 0.1764
- 0.1821
- 0.1921
- 0.1995
- 0.1995
- 0.2053
- 0.2094
- 0.2149
- 0.2253
- 0.2309
- 0.2332
- 0.234
- 0.237
- 0.2383
- 0.2456
- 0.2478
- 0.2494
- 0.2505
- 0.2547
- 0.2591
- 0.261
- 0.2651
- 0.2648
- 0.264
- 0.2693
- 0.2719
- 0.2712
- 0.2794
- 0.2771
- 0.2833
- 0.2759
- 0.2827
- 0.2851
- 0.2818
- 0.2852
- 0.287
- 0.2842
- 0.2903
- 0.287
- 0.2898
- 0.2917
- 0.2978
- 0.298
- 0.2957
- 0.2956
- 0.2966
- 0.298
- 0.2989
- 0.2996
- 0.3004
- 0.2999
- 0.3061
- 0.3037
- 0.3068
- 0.3036
- 0.3084
- 0.31
- 0.3096
- 0.3082
- 0.3087
- 0.3127
- 0.3074
- 0.3124
- 0.3145
- 0.3119
- 0.309
- 0.3108
- 0.315
- 0.3151
- 0.3127
- 0.3144
- 0.3158
- 0.3214
- 0.3137
- 0.3154
- 0.3177
- 0.3222
- 0.3186
- 0.3183
- 0.3179
- 0.3235
- 0.3178
- 0.3211
- 0.3203
- 0.3192
- 0.3203
- 0.3216
- 0.322
- 0.3186
- 0.3242
- 0.3251
- 0.3235
- 0.3202
test_loss_list:
- 1.7967117929458618
- 1.6396332359313965
- 1.589539544582367
- 1.5509260892868042
- 1.5163233470916748
- 1.483233594894409
- 1.4547460746765137
- 1.4391400408744812
- 1.4207331824302674
- 1.4010779523849488
- 1.3909090161323547
- 1.3787476539611816
- 1.3589928579330444
- 1.3440393090248108
- 1.33867014169693
- 1.3219953751564026
- 1.312004065513611
- 1.3040565395355224
- 1.293661530017853
- 1.2865869545936583
- 1.2791760277748108
- 1.2704592275619506
- 1.2619551014900208
- 1.2573664999008178
- 1.2498725652694702
- 1.2448776006698608
- 1.2404609870910646
- 1.2320881175994873
- 1.227819447517395
- 1.2211857533454895
- 1.2220399045944215
- 1.2105142378807068
- 1.2067910647392273
- 1.209538164138794
- 1.1998356294631958
- 1.2026367664337159
- 1.1981736326217651
- 1.1959526753425598
- 1.1883260083198548
- 1.184321141242981
- 1.18191668510437
- 1.1842147278785706
- 1.1753037071228027
- 1.1828122401237489
- 1.1726084089279174
- 1.1768982672691346
- 1.1730677103996277
- 1.171071012020111
- 1.1615797924995421
- 1.1604939937591552
- 1.1663517236709595
- 1.1564239478111267
- 1.1609778833389282
- 1.1555509567260742
- 1.1540824055671692
- 1.1512241172790527
- 1.1552609562873841
- 1.15281183719635
- 1.1529457974433899
- 1.159813141822815
- 1.147192018032074
- 1.1537365412712097
- 1.1419338965415955
- 1.1431076455116271
- 1.1439260411262513
- 1.1433576822280884
- 1.141611816883087
- 1.1437797594070434
- 1.1473441267013549
- 1.1472985029220581
- 1.1457837867736815
- 1.1511977863311769
- 1.142038106918335
- 1.1486293697357177
- 1.1443890285491944
- 1.1344471645355225
- 1.141143274307251
- 1.136677770614624
- 1.1404988694190978
- 1.1378285050392152
- 1.1432592678070068
- 1.1397916889190673
- 1.1379351115226746
- 1.14228839635849
- 1.1384209728240966
- 1.1348836398124695
- 1.1398986172676087
- 1.1397364497184754
- 1.1333511066436768
- 1.144288911819458
- 1.1446175622940062
- 1.1431596899032592
- 1.1420137238502504
- 1.1451355075836183
- 1.1443600344657898
- 1.150641667842865
- 1.142775354385376
- 1.1416641545295716
- 1.1478508496284485
- 1.1468354153633118
train_accuracy:
- 0.028
- 0.098
- 0.114
- 0.123
- 0.159
- 0.119
- 0.097
- 0.185
- 0.137
- 0.164
- 0.168
- 0.154
- 0.164
- 0.202
- 0.198
- 0.169
- 0.247
- 0.082
- 0.235
- 0.197
- 0.246
- 0.22
- 0.265
- 0.183
- 0.238
- 0.276
- 0.251
- 0.245
- 0.253
- 0.251
- 0.221
- 0.23
- 0.255
- 0.225
- 0.259
- 0.24
- 0.291
- 0.236
- 0.249
- 0.235
- 0.252
- 0.186
- 0.285
- 0.243
- 0.26
- 0.26
- 0.282
- 0.288
- 0.3
- 0.161
- 0.243
- 0.271
- 0.285
- 0.295
- 0.14
- 0.279
- 0.285
- 0.302
- 0.302
- 0.302
- 0.3
- 0.271
- 0.219
- 0.295
- 0.297
- 0.308
- 0.327
- 0.271
- 0.296
- 0.309
- 0.298
- 0.306
- 0.292
- 0.311
- 0.308
- 0.287
- 0.273
- 0.314
- 0.297
- 0.325
- 0.307
- 0.334
- 0.311
- 0.298
- 0.324
- 0.331
- 0.33
- 0.314
- 0.267
- 0.321
- 0.29
- 0.312
- 0.317
- 0.269
- 0.326
- 0.31
- 0.275
- 0.326
- 0.316
- 0.273
train_loss:
- 3.571
- 3.896
- 3.028
- 2.838
- 2.798
- 3.33
- 2.667
- 2.529
- 2.513
- 3.014
- 2.876
- 2.805
- 2.232
- 2.219
- 2.167
- 2.54
- 2.51
- 1.987
- 1.944
- 1.934
- 1.853
- 2.241
- 1.782
- 2.096
- 2.194
- 1.671
- 1.639
- 2.021
- 1.924
- 1.563
- 1.5
- 1.476
- 1.723
- 1.357
- 1.739
- 1.573
- 1.644
- 1.321
- 1.52
- 1.611
- 1.171
- 1.104
- 1.176
- 1.063
- 1.137
- 1.025
- 1.099
- 1.042
- 1.289
- 1.002
- 0.886
- 1.237
- 0.943
- 1.076
- 0.937
- 1.117
- 1.01
- 1.029
- 1.07
- 0.942
- 0.711
- 0.751
- 0.841
- 0.851
- 0.873
- 0.779
- 0.814
- 0.791
- 0.824
- 0.837
- 0.706
- 0.726
- 0.543
- 0.537
- 0.685
- 0.637
- 0.612
- 0.641
- 0.694
- 0.679
- 0.641
- 0.502
- 0.623
- 0.603
- 0.584
- 0.454
- 0.558
- 0.556
- 0.497
- 0.498
- 0.413
- 0.521
- 0.366
- 0.404
- 0.357
- 0.344
- 0.394
- 0.46
- 0.442
- 0.372
unequal: 0
verbose: 1
