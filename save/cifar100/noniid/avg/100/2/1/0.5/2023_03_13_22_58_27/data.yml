avg_train_accuracy: 0.302
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0431
- 0.092
- 0.1185
- 0.1306
- 0.1398
- 0.1579
- 0.1691
- 0.1813
- 0.184
- 0.1973
- 0.1955
- 0.2049
- 0.2092
- 0.2154
- 0.2155
- 0.22
- 0.2227
- 0.2304
- 0.2355
- 0.2336
- 0.2421
- 0.2451
- 0.2435
- 0.2522
- 0.2576
- 0.2523
- 0.2564
- 0.2565
- 0.2651
- 0.2653
- 0.264
- 0.2723
- 0.269
- 0.2781
- 0.2802
- 0.274
- 0.2742
- 0.2835
- 0.2872
- 0.2887
- 0.2899
- 0.285
- 0.2821
- 0.2919
- 0.2893
- 0.2933
- 0.2928
- 0.2985
- 0.2968
- 0.2954
- 0.2977
- 0.2972
- 0.301
- 0.2997
- 0.3036
- 0.3061
- 0.3096
- 0.3023
- 0.306
- 0.304
- 0.3037
- 0.3128
- 0.3124
- 0.3098
- 0.3158
- 0.3107
- 0.3094
- 0.3149
- 0.3134
- 0.3181
- 0.3161
- 0.3159
- 0.3184
- 0.3178
- 0.3191
- 0.3155
- 0.3193
- 0.3213
- 0.3225
- 0.3194
- 0.3205
- 0.3154
- 0.3256
- 0.3236
- 0.3261
- 0.3239
- 0.3218
- 0.3231
- 0.324
- 0.3292
- 0.3248
- 0.3233
- 0.3272
- 0.3266
- 0.3269
- 0.327
- 0.3293
- 0.3275
- 0.3301
- 0.3262
test_loss_list:
- 1.7927027606964112
- 1.6542365646362305
- 1.5982458996772766
- 1.5476037216186525
- 1.512597758769989
- 1.4807012104988098
- 1.452938735485077
- 1.4332579827308656
- 1.411135218143463
- 1.3906296110153198
- 1.371609320640564
- 1.360518000125885
- 1.3438548135757447
- 1.3311012887954712
- 1.3305000019073487
- 1.3123434233665465
- 1.3055781435966491
- 1.2970225858688353
- 1.2897336268424988
- 1.2769197964668273
- 1.270781569480896
- 1.2652653813362122
- 1.2579009127616883
- 1.2475488710403442
- 1.2437668442726135
- 1.2339407444000243
- 1.2266692519187927
- 1.2248372435569763
- 1.217620508670807
- 1.219949915409088
- 1.2097679924964906
- 1.2060325646400452
- 1.2027729368209839
- 1.193222713470459
- 1.1957324576377868
- 1.191850094795227
- 1.1916647481918334
- 1.1803895473480224
- 1.1841338777542114
- 1.1794240999221801
- 1.1804846167564391
- 1.1711965107917786
- 1.176227958202362
- 1.1651908230781556
- 1.1636800503730773
- 1.1566873812675476
- 1.1569365859031677
- 1.1486499309539795
- 1.1466350030899048
- 1.150832669734955
- 1.1437041687965392
- 1.146396164894104
- 1.1460921883583068
- 1.1503828620910646
- 1.1463015246391297
- 1.145877592563629
- 1.1457771730422974
- 1.1341702914237977
- 1.1291852545738221
- 1.1344221973419188
- 1.1361263108253479
- 1.1312684583663941
- 1.1316671466827393
- 1.1313003540039062
- 1.1263501381874084
- 1.1311001181602478
- 1.1308058142662047
- 1.1266464614868164
- 1.1268407273292542
- 1.125268623828888
- 1.1273683500289917
- 1.1192487239837647
- 1.1203419137001038
- 1.1208519697189332
- 1.12255610704422
- 1.121456642150879
- 1.1241598200798035
- 1.1173004961013795
- 1.1216864776611328
- 1.1317802357673645
- 1.1282483744621277
- 1.1280416989326476
- 1.1202390480041504
- 1.1257989382743836
- 1.1262846064567567
- 1.1287086224555969
- 1.1249592256546022
- 1.1249665880203248
- 1.11814834356308
- 1.1196872210502624
- 1.1284435200691223
- 1.1302155327796937
- 1.1237785077095033
- 1.1300834512710571
- 1.1335816311836242
- 1.1308463406562805
- 1.1361635088920594
- 1.136764886379242
- 1.1340362644195556
- 1.1395926976203918
train_accuracy:
- 0.043
- 0.086
- 0.11
- 0.082
- 0.018
- 0.122
- 0.141
- 0.11
- 0.216
- 0.176
- 0.202
- 0.177
- 0.235
- 0.179
- 0.16
- 0.198
- 0.069
- 0.237
- 0.213
- 0.216
- 0.197
- 0.26
- 0.25
- 0.302
- 0.246
- 0.204
- 0.227
- 0.225
- 0.227
- 0.273
- 0.224
- 0.312
- 0.268
- 0.326
- 0.217
- 0.276
- 0.202
- 0.211
- 0.261
- 0.269
- 0.297
- 0.25
- 0.284
- 0.234
- 0.285
- 0.217
- 0.293
- 0.267
- 0.289
- 0.286
- 0.171
- 0.222
- 0.251
- 0.275
- 0.238
- 0.242
- 0.289
- 0.217
- 0.313
- 0.235
- 0.22
- 0.302
- 0.347
- 0.337
- 0.243
- 0.218
- 0.36
- 0.246
- 0.234
- 0.342
- 0.295
- 0.318
- 0.28
- 0.328
- 0.294
- 0.298
- 0.315
- 0.263
- 0.315
- 0.299
- 0.374
- 0.333
- 0.297
- 0.27
- 0.293
- 0.312
- 0.099
- 0.213
- 0.311
- 0.299
- 0.339
- 0.296
- 0.303
- 0.314
- 0.308
- 0.276
- 0.31
- 0.332
- 0.307
- 0.302
train_loss:
- 4.347
- 3.902
- 3.687
- 2.944
- 2.777
- 3.303
- 3.178
- 3.054
- 2.472
- 2.933
- 2.393
- 2.785
- 2.273
- 2.681
- 2.567
- 2.073
- 2.005
- 2.422
- 2.37
- 1.914
- 2.33
- 2.173
- 1.79
- 2.137
- 2.099
- 1.671
- 1.675
- 1.614
- 1.932
- 1.848
- 1.527
- 1.777
- 1.487
- 1.779
- 1.671
- 1.362
- 1.274
- 1.625
- 1.578
- 1.451
- 1.519
- 1.211
- 1.127
- 1.343
- 1.222
- 1.088
- 1.07
- 1.295
- 1.132
- 0.963
- 1.017
- 0.955
- 1.182
- 1.098
- 1.131
- 1.08
- 1.032
- 0.921
- 0.857
- 0.816
- 0.76
- 0.979
- 0.959
- 0.764
- 0.887
- 0.753
- 0.727
- 0.82
- 0.679
- 0.852
- 0.802
- 0.654
- 0.775
- 0.638
- 0.713
- 0.594
- 0.597
- 0.681
- 0.646
- 0.611
- 0.649
- 0.519
- 0.638
- 0.578
- 0.586
- 0.546
- 0.477
- 0.436
- 0.542
- 0.512
- 0.507
- 0.521
- 0.531
- 0.483
- 0.493
- 0.483
- 0.46
- 0.432
- 0.446
- 0.419
unequal: 0
verbose: 1
