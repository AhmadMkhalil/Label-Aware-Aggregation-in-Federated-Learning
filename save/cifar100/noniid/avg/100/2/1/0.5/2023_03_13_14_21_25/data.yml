avg_train_accuracy: 0.315
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.034
- 0.0849
- 0.1024
- 0.1207
- 0.1331
- 0.1488
- 0.1601
- 0.1667
- 0.1724
- 0.181
- 0.1825
- 0.1915
- 0.1987
- 0.1991
- 0.2106
- 0.2155
- 0.2232
- 0.2202
- 0.2249
- 0.2346
- 0.2327
- 0.2352
- 0.235
- 0.2426
- 0.2506
- 0.247
- 0.2519
- 0.2517
- 0.2528
- 0.253
- 0.2607
- 0.2661
- 0.2642
- 0.2644
- 0.2694
- 0.2687
- 0.2713
- 0.2726
- 0.2807
- 0.2807
- 0.2802
- 0.2804
- 0.2828
- 0.2839
- 0.2838
- 0.2859
- 0.2889
- 0.2883
- 0.2888
- 0.2904
- 0.2851
- 0.2902
- 0.2923
- 0.2917
- 0.2959
- 0.2967
- 0.2938
- 0.3003
- 0.3011
- 0.2967
- 0.297
- 0.3069
- 0.3041
- 0.304
- 0.3024
- 0.3011
- 0.3109
- 0.3065
- 0.3031
- 0.3075
- 0.3153
- 0.3122
- 0.3115
- 0.3081
- 0.3139
- 0.3142
- 0.3188
- 0.3083
- 0.3165
- 0.3191
- 0.3113
- 0.3196
- 0.3141
- 0.3125
- 0.3162
- 0.3212
- 0.3149
- 0.3228
- 0.3171
- 0.3193
- 0.3218
- 0.3255
- 0.3153
- 0.3255
- 0.3179
- 0.3182
- 0.3176
- 0.3216
- 0.3232
- 0.3224
test_loss_list:
- 1.806428780555725
- 1.6604210472106933
- 1.5997745990753174
- 1.5547889637947083
- 1.5216006970405578
- 1.4875343346595764
- 1.4720848751068116
- 1.4454422211647033
- 1.4290132117271424
- 1.4156424927711486
- 1.3988950538635254
- 1.3896247887611388
- 1.3704422116279602
- 1.364629738330841
- 1.3484542274475098
- 1.336082866191864
- 1.329479603767395
- 1.31821852684021
- 1.3067594981193542
- 1.2974772953987121
- 1.2916305613517762
- 1.2843334889411926
- 1.282285373210907
- 1.265509579181671
- 1.2577956581115723
- 1.2595435762405396
- 1.247217471599579
- 1.2435310339927674
- 1.2411527061462402
- 1.2399294114112853
- 1.230423092842102
- 1.2249936008453368
- 1.2164124846458435
- 1.222114210128784
- 1.2087586832046509
- 1.2116978192329406
- 1.209591290950775
- 1.2017430067062378
- 1.1946285462379456
- 1.1996458292007446
- 1.1886890625953674
- 1.184671323299408
- 1.186861159801483
- 1.187227816581726
- 1.1894263696670533
- 1.179461989402771
- 1.1738144040107727
- 1.1798181748390197
- 1.1809712052345276
- 1.169401807785034
- 1.1710822224617004
- 1.1593860936164857
- 1.166331443786621
- 1.164447190761566
- 1.1651840496063233
- 1.156934416294098
- 1.164249029159546
- 1.15396582365036
- 1.1557247710227967
- 1.1537132716178895
- 1.155275981426239
- 1.1426730060577392
- 1.1521369862556456
- 1.1507311820983888
- 1.1454389882087708
- 1.151520812511444
- 1.143106153011322
- 1.1497399973869324
- 1.150240228176117
- 1.1435294795036315
- 1.135033402442932
- 1.1406529545783997
- 1.143830692768097
- 1.1470707154273987
- 1.13528160572052
- 1.1395858097076417
- 1.134626157283783
- 1.1402507328987121
- 1.1335675048828124
- 1.1392421841621398
- 1.145027241706848
- 1.1342978262901307
- 1.13681875705719
- 1.1449797701835633
- 1.1343254923820496
- 1.1291020107269287
- 1.1382796549797058
- 1.133244104385376
- 1.137006275653839
- 1.1418599843978883
- 1.1316744923591613
- 1.1335605788230896
- 1.1460146856307984
- 1.1340914154052735
- 1.138625566959381
- 1.14365309715271
- 1.1442898416519165
- 1.1297709655761718
- 1.1334683251380921
- 1.137779676914215
train_accuracy:
- 0.028
- 0.09
- 0.172
- 0.13
- 0.15
- 0.135
- 0.155
- 0.177
- 0.153
- 0.148
- 0.179
- 0.18
- 0.161
- 0.231
- 0.191
- 0.204
- 0.231
- 0.187
- 0.238
- 0.236
- 0.218
- 0.14
- 0.236
- 0.201
- 0.258
- 0.231
- 0.231
- 0.256
- 0.237
- 0.271
- 0.256
- 0.274
- 0.263
- 0.276
- 0.279
- 0.271
- 0.244
- 0.276
- 0.261
- 0.255
- 0.272
- 0.284
- 0.282
- 0.292
- 0.283
- 0.053
- 0.293
- 0.273
- 0.286
- 0.262
- 0.259
- 0.304
- 0.305
- 0.299
- 0.292
- 0.296
- 0.123
- 0.276
- 0.277
- 0.103
- 0.274
- 0.283
- 0.289
- 0.123
- 0.301
- 0.299
- 0.293
- 0.281
- 0.286
- 0.324
- 0.338
- 0.306
- 0.307
- 0.295
- 0.33
- 0.334
- 0.286
- 0.26
- 0.329
- 0.294
- 0.261
- 0.295
- 0.315
- 0.228
- 0.282
- 0.291
- 0.323
- 0.338
- 0.273
- 0.221
- 0.291
- 0.33
- 0.275
- 0.328
- 0.208
- 0.325
- 0.32
- 0.289
- 0.315
- 0.315
train_loss:
- 3.646
- 3.249
- 3.059
- 2.903
- 2.828
- 3.373
- 3.22
- 2.593
- 2.517
- 2.422
- 2.97
- 2.818
- 2.332
- 2.2
- 2.652
- 2.687
- 2.522
- 2.062
- 2.027
- 2.397
- 1.911
- 1.886
- 1.79
- 1.828
- 2.16
- 1.738
- 2.046
- 1.751
- 1.57
- 1.591
- 1.894
- 1.883
- 1.483
- 1.43
- 1.737
- 1.839
- 1.446
- 1.631
- 1.596
- 1.512
- 1.331
- 1.511
- 1.451
- 1.37
- 1.3
- 1.111
- 1.247
- 1.218
- 1.352
- 0.929
- 1.076
- 1.325
- 0.912
- 1.202
- 0.952
- 1.112
- 0.928
- 1.122
- 0.997
- 0.778
- 0.791
- 1.016
- 0.956
- 0.708
- 0.864
- 0.739
- 0.848
- 0.84
- 0.67
- 0.753
- 0.811
- 0.703
- 0.61
- 0.656
- 0.823
- 0.745
- 0.686
- 0.54
- 0.685
- 0.626
- 0.527
- 0.651
- 0.525
- 0.525
- 0.533
- 0.567
- 0.503
- 0.55
- 0.443
- 0.419
- 0.548
- 0.491
- 0.397
- 0.524
- 0.415
- 0.362
- 0.373
- 0.477
- 0.48
- 0.358
unequal: 0
verbose: 1
