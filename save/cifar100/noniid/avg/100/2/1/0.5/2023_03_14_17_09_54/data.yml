avg_train_accuracy: 0.303
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0425
- 0.0885
- 0.1154
- 0.1387
- 0.1479
- 0.1536
- 0.1664
- 0.1754
- 0.1781
- 0.1908
- 0.2002
- 0.1997
- 0.2088
- 0.2152
- 0.2174
- 0.2213
- 0.23
- 0.2271
- 0.2312
- 0.2376
- 0.241
- 0.2418
- 0.2469
- 0.2532
- 0.2501
- 0.257
- 0.2577
- 0.2568
- 0.2569
- 0.2603
- 0.2644
- 0.2686
- 0.2655
- 0.2663
- 0.2712
- 0.272
- 0.2712
- 0.2723
- 0.2794
- 0.2849
- 0.2843
- 0.2821
- 0.2852
- 0.2875
- 0.29
- 0.2889
- 0.2813
- 0.2881
- 0.2912
- 0.2937
- 0.2948
- 0.2927
- 0.2906
- 0.2956
- 0.2939
- 0.2977
- 0.2946
- 0.2994
- 0.2959
- 0.2974
- 0.2996
- 0.2997
- 0.3019
- 0.3038
- 0.3053
- 0.3061
- 0.3038
- 0.3088
- 0.3055
- 0.3066
- 0.3069
- 0.3093
- 0.3105
- 0.3066
- 0.3122
- 0.3087
- 0.3072
- 0.3143
- 0.31
- 0.3088
- 0.3131
- 0.3159
- 0.3134
- 0.3107
- 0.3144
- 0.3159
- 0.3177
- 0.3181
- 0.3154
- 0.3149
- 0.3145
- 0.3113
- 0.316
- 0.3196
- 0.3201
- 0.3215
- 0.3222
- 0.3239
- 0.3159
- 0.3243
test_loss_list:
- 1.7827634048461913
- 1.6513592886924744
- 1.5949316430091858
- 1.5445007586479187
- 1.5041040802001953
- 1.4824666047096253
- 1.4559791111946105
- 1.4317246246337891
- 1.420269522666931
- 1.3996027541160583
- 1.3847855830192566
- 1.3676562309265137
- 1.3548847270011901
- 1.3493144726753235
- 1.3268700695037843
- 1.3175889348983765
- 1.3125228810310363
- 1.3040265321731568
- 1.2952107453346253
- 1.284108989238739
- 1.2806128144264222
- 1.270909583568573
- 1.2664024996757508
- 1.2536144757270813
- 1.2520751786231994
- 1.2463859462738036
- 1.2482600903511047
- 1.2412981033325194
- 1.2403853225708008
- 1.2231059503555297
- 1.2181080961227417
- 1.2189158916473388
- 1.2184475374221801
- 1.2125613903999328
- 1.2092671298980713
- 1.2106879997253417
- 1.1970957159996032
- 1.204824504852295
- 1.194984233379364
- 1.1912867999076844
- 1.1898231530189514
- 1.1793676042556762
- 1.17868346452713
- 1.1770343208312988
- 1.1800379276275634
- 1.1791049337387085
- 1.1757024836540222
- 1.1711078071594239
- 1.1689470982551575
- 1.1712130069732667
- 1.1721020770072936
- 1.1569025492668152
- 1.1615182828903199
- 1.1624428057670593
- 1.1621967935562134
- 1.1537726736068725
- 1.1583490347862244
- 1.1549756121635437
- 1.1492830657958983
- 1.1522724056243896
- 1.147373857498169
- 1.1508106780052185
- 1.1508859944343568
- 1.1499384021759034
- 1.1514446496963502
- 1.1538496899604798
- 1.140276584625244
- 1.1418740010261537
- 1.1419696521759033
- 1.141977264881134
- 1.1395635271072388
- 1.147253623008728
- 1.1455821251869203
- 1.1474317622184753
- 1.1408698344230652
- 1.1497206687927246
- 1.1488516664505004
- 1.1382720947265625
- 1.1491344308853149
- 1.142654914855957
- 1.1403237080574036
- 1.142090811729431
- 1.1370831394195557
- 1.1439790678024293
- 1.1432007503509523
- 1.1395050764083863
- 1.1416760230064391
- 1.1433455085754394
- 1.1365324354171753
- 1.1420459175109863
- 1.1438745141029358
- 1.1503677487373352
- 1.1444103908538819
- 1.1452283787727355
- 1.1453570294380189
- 1.1433632826805116
- 1.1500655245780944
- 1.1505963802337646
- 1.1434506845474244
- 1.1442419981956482
train_accuracy:
- 0.058
- 0.091
- 0.126
- 0.135
- 0.123
- 0.136
- 0.173
- 0.14
- 0.161
- 0.185
- 0.179
- 0.169
- 0.199
- 0.208
- 0.15
- 0.158
- 0.211
- 0.212
- 0.214
- 0.176
- 0.225
- 0.095
- 0.212
- 0.255
- 0.246
- 0.257
- 0.244
- 0.093
- 0.237
- 0.25
- 0.19
- 0.218
- 0.248
- 0.213
- 0.252
- 0.277
- 0.249
- 0.283
- 0.265
- 0.273
- 0.245
- 0.262
- 0.239
- 0.269
- 0.245
- 0.277
- 0.322
- 0.281
- 0.263
- 0.275
- 0.268
- 0.289
- 0.312
- 0.311
- 0.182
- 0.22
- 0.291
- 0.286
- 0.126
- 0.286
- 0.275
- 0.285
- 0.284
- 0.285
- 0.289
- 0.28
- 0.301
- 0.291
- 0.162
- 0.282
- 0.174
- 0.279
- 0.287
- 0.155
- 0.309
- 0.303
- 0.294
- 0.286
- 0.338
- 0.301
- 0.309
- 0.309
- 0.136
- 0.288
- 0.307
- 0.279
- 0.331
- 0.306
- 0.298
- 0.298
- 0.286
- 0.257
- 0.308
- 0.331
- 0.311
- 0.323
- 0.313
- 0.325
- 0.291
- 0.303
train_loss:
- 4.335
- 3.233
- 3.691
- 3.514
- 2.775
- 2.645
- 3.174
- 2.522
- 2.445
- 2.991
- 2.899
- 2.236
- 2.795
- 2.646
- 2.159
- 2.113
- 2.442
- 2.017
- 1.926
- 2.409
- 2.183
- 1.778
- 2.155
- 1.754
- 1.668
- 2.046
- 1.909
- 1.609
- 1.493
- 1.689
- 1.594
- 1.787
- 1.34
- 1.443
- 1.719
- 1.715
- 1.421
- 1.276
- 1.589
- 1.589
- 1.585
- 1.213
- 1.162
- 1.367
- 1.325
- 1.348
- 1.089
- 1.283
- 1.338
- 1.27
- 1.267
- 1.013
- 0.937
- 0.918
- 0.907
- 0.935
- 0.876
- 1.125
- 0.904
- 1.05
- 0.801
- 0.75
- 0.969
- 0.969
- 0.879
- 0.868
- 0.72
- 0.86
- 0.701
- 0.799
- 0.713
- 0.761
- 0.794
- 0.609
- 0.686
- 0.662
- 0.553
- 0.702
- 0.627
- 0.58
- 0.641
- 0.649
- 0.55
- 0.53
- 0.592
- 0.574
- 0.58
- 0.543
- 0.468
- 0.424
- 0.413
- 0.375
- 0.452
- 0.462
- 0.47
- 0.462
- 0.415
- 0.432
- 0.404
- 0.424
unequal: 0
verbose: 1
