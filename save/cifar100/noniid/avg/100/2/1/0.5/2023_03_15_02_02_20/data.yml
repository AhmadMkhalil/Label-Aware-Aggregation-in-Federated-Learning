avg_train_accuracy: 0.296
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0368
- 0.0935
- 0.1097
- 0.1281
- 0.145
- 0.1473
- 0.163
- 0.1711
- 0.1779
- 0.1811
- 0.1925
- 0.2065
- 0.2029
- 0.2092
- 0.2127
- 0.2227
- 0.2306
- 0.2337
- 0.2396
- 0.2401
- 0.2431
- 0.2521
- 0.2454
- 0.2533
- 0.2527
- 0.2595
- 0.2619
- 0.2664
- 0.272
- 0.2647
- 0.2678
- 0.2737
- 0.278
- 0.2727
- 0.2751
- 0.2798
- 0.2829
- 0.2872
- 0.2858
- 0.2886
- 0.2855
- 0.2882
- 0.291
- 0.2945
- 0.2909
- 0.2917
- 0.2967
- 0.3018
- 0.3045
- 0.3007
- 0.3023
- 0.3045
- 0.304
- 0.3007
- 0.304
- 0.3061
- 0.3023
- 0.3053
- 0.306
- 0.3039
- 0.3134
- 0.3111
- 0.3132
- 0.3063
- 0.3149
- 0.3114
- 0.314
- 0.3176
- 0.3126
- 0.3114
- 0.3162
- 0.3171
- 0.321
- 0.3202
- 0.316
- 0.3211
- 0.3123
- 0.3229
- 0.3221
- 0.3155
- 0.3188
- 0.3205
- 0.3206
- 0.3277
- 0.3193
- 0.3144
- 0.3258
- 0.323
- 0.3227
- 0.3243
- 0.3251
- 0.3335
- 0.3292
- 0.3247
- 0.3249
- 0.3241
- 0.3227
- 0.3217
- 0.3271
- 0.3266
test_loss_list:
- 1.7997671842575074
- 1.6499531626701356
- 1.5953395366668701
- 1.548769738674164
- 1.5146701788902284
- 1.4822722530364991
- 1.4568805122375488
- 1.4380421018600464
- 1.420201587677002
- 1.4047889018058777
- 1.3906117510795593
- 1.3779124045372009
- 1.3607018780708313
- 1.3443472456932068
- 1.3338301038742066
- 1.3248466777801513
- 1.3164774131774903
- 1.3096661925315858
- 1.3029364109039308
- 1.2951500368118287
- 1.287583692073822
- 1.2841203784942627
- 1.2596850204467773
- 1.2523726010322571
- 1.2493968868255616
- 1.237511727809906
- 1.2357987332344056
- 1.2318120574951172
- 1.228715431690216
- 1.2185586261749268
- 1.2148947763442992
- 1.2144530868530274
- 1.2025972294807434
- 1.1996534180641174
- 1.1994821906089783
- 1.1875410556793213
- 1.1844013547897339
- 1.1821531891822814
- 1.176362555027008
- 1.1769028830528259
- 1.1734479141235352
- 1.1660371232032776
- 1.171903920173645
- 1.16773921251297
- 1.1662031292915345
- 1.1637021112442016
- 1.1484687638282776
- 1.1523675537109375
- 1.1542428731918335
- 1.1478873801231384
- 1.1491187715530395
- 1.1514316916465759
- 1.1544437909126282
- 1.1397812366485596
- 1.1376552844047547
- 1.1401766324043274
- 1.1388337445259094
- 1.1385792565345765
- 1.1368421983718873
- 1.1387473130226136
- 1.1340571689605712
- 1.1368808054924011
- 1.1373066973686219
- 1.1346058177947997
- 1.13192622423172
- 1.1310471415519714
- 1.1305868196487427
- 1.1279706263542175
- 1.1270039749145508
- 1.1294497776031494
- 1.1293693327903747
- 1.1334377193450929
- 1.1332645678520203
- 1.1328076601028443
- 1.138163287639618
- 1.136226863861084
- 1.1299489212036133
- 1.1228139662742616
- 1.1300883889198303
- 1.1239549541473388
- 1.1276006293296814
- 1.1282373309135436
- 1.1248675847053529
- 1.1216551661491394
- 1.1300332927703858
- 1.1365997886657715
- 1.1297605657577514
- 1.1308353304862977
- 1.1250874495506287
- 1.1227766942977906
- 1.1231632256507873
- 1.1201273274421693
- 1.12458110332489
- 1.122726023197174
- 1.1258841919898988
- 1.1295823860168457
- 1.1309336233139038
- 1.1312693166732788
- 1.1296409606933593
- 1.1303953886032105
train_accuracy:
- 0.022
- 0.094
- 0.072
- 0.127
- 0.125
- 0.154
- 0.148
- 0.106
- 0.163
- 0.181
- 0.165
- 0.167
- 0.172
- 0.128
- 0.179
- 0.218
- 0.178
- 0.241
- 0.153
- 0.252
- 0.246
- 0.204
- 0.175
- 0.084
- 0.236
- 0.267
- 0.252
- 0.243
- 0.287
- 0.286
- 0.099
- 0.291
- 0.28
- 0.301
- 0.225
- 0.229
- 0.222
- 0.295
- 0.102
- 0.252
- 0.275
- 0.229
- 0.251
- 0.287
- 0.073
- 0.229
- 0.239
- 0.301
- 0.306
- 0.235
- 0.278
- 0.281
- 0.301
- 0.286
- 0.265
- 0.263
- 0.301
- 0.251
- 0.282
- 0.184
- 0.324
- 0.32
- 0.284
- 0.297
- 0.318
- 0.133
- 0.263
- 0.275
- 0.144
- 0.271
- 0.276
- 0.326
- 0.344
- 0.315
- 0.283
- 0.286
- 0.288
- 0.33
- 0.334
- 0.28
- 0.309
- 0.354
- 0.303
- 0.291
- 0.297
- 0.281
- 0.332
- 0.298
- 0.291
- 0.356
- 0.14
- 0.324
- 0.286
- 0.276
- 0.191
- 0.292
- 0.275
- 0.323
- 0.341
- 0.296
train_loss:
- 3.549
- 3.934
- 3.0
- 3.508
- 3.375
- 2.739
- 2.654
- 2.533
- 3.077
- 2.371
- 2.935
- 2.832
- 2.272
- 2.214
- 2.186
- 2.627
- 2.507
- 2.451
- 2.401
- 2.297
- 2.256
- 2.186
- 1.866
- 1.79
- 1.713
- 1.711
- 2.016
- 1.989
- 1.903
- 1.507
- 1.517
- 1.758
- 1.477
- 1.731
- 1.385
- 1.412
- 1.462
- 1.664
- 1.298
- 1.59
- 1.242
- 1.189
- 1.464
- 1.433
- 1.075
- 1.302
- 1.184
- 1.353
- 1.274
- 1.051
- 1.278
- 1.156
- 1.169
- 1.0
- 0.916
- 1.088
- 0.832
- 0.832
- 0.766
- 0.861
- 0.995
- 0.987
- 0.913
- 0.817
- 0.909
- 0.734
- 0.71
- 0.849
- 0.698
- 0.651
- 0.776
- 0.796
- 0.754
- 0.702
- 0.69
- 0.688
- 0.564
- 0.702
- 0.669
- 0.5
- 0.561
- 0.468
- 0.512
- 0.619
- 0.473
- 0.446
- 0.541
- 0.584
- 0.511
- 0.522
- 0.49
- 0.549
- 0.512
- 0.423
- 0.405
- 0.387
- 0.38
- 0.348
- 0.351
- 0.38
unequal: 0
verbose: 1
