avg_train_accuracy: 0.342
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0388
- 0.0903
- 0.1046
- 0.1293
- 0.1404
- 0.1504
- 0.1599
- 0.1698
- 0.1797
- 0.1844
- 0.1935
- 0.1984
- 0.2012
- 0.2096
- 0.213
- 0.2211
- 0.2305
- 0.2335
- 0.2343
- 0.2364
- 0.2457
- 0.2416
- 0.2534
- 0.2542
- 0.2548
- 0.2613
- 0.2673
- 0.2641
- 0.2732
- 0.2673
- 0.2742
- 0.2801
- 0.2779
- 0.2738
- 0.2818
- 0.2856
- 0.2916
- 0.2908
- 0.2932
- 0.2919
- 0.2984
- 0.2908
- 0.3002
- 0.3006
- 0.3032
- 0.3046
- 0.3073
- 0.3048
- 0.3068
- 0.3135
- 0.3144
- 0.3207
- 0.3139
- 0.3158
- 0.3163
- 0.3131
- 0.3224
- 0.3149
- 0.3174
- 0.3107
- 0.3188
- 0.3201
- 0.3252
- 0.323
- 0.3272
- 0.3271
- 0.3228
- 0.3281
- 0.3247
- 0.3255
- 0.328
- 0.328
- 0.3266
- 0.3257
- 0.3284
- 0.3343
- 0.3293
- 0.3256
- 0.3336
- 0.3303
- 0.335
- 0.3343
- 0.3324
- 0.331
- 0.3327
- 0.334
- 0.3303
- 0.3322
- 0.33
- 0.3351
- 0.3364
- 0.337
- 0.339
- 0.3343
- 0.3379
- 0.3353
- 0.3366
- 0.3362
- 0.3357
- 0.339
test_loss_list:
- 1.791950831413269
- 1.6544436311721802
- 1.5986162209510804
- 1.5499210858345032
- 1.5189827251434327
- 1.4802017545700072
- 1.4580433058738709
- 1.4406775736808777
- 1.4157748699188233
- 1.4017814588546753
- 1.3866132926940917
- 1.373103094100952
- 1.3599832010269166
- 1.3492561721801757
- 1.3369135570526123
- 1.3209851455688477
- 1.3077022123336792
- 1.3031467938423156
- 1.2930507588386535
- 1.2834351181983947
- 1.2743333530426026
- 1.266068208217621
- 1.2571432447433473
- 1.2545668244361878
- 1.2433957386016845
- 1.2366185426712035
- 1.2337648034095765
- 1.2295200204849244
- 1.2184391498565674
- 1.2155731773376466
- 1.2084631395339966
- 1.2032026958465576
- 1.2019385695457458
- 1.191428849697113
- 1.1837289881706239
- 1.1808225369453431
- 1.1726734805107117
- 1.1707501244544982
- 1.1678699994087218
- 1.1639742755889892
- 1.1600982308387757
- 1.161733865737915
- 1.1531135392189027
- 1.1481580424308777
- 1.1497846126556397
- 1.1430147981643677
- 1.145312159061432
- 1.1422378969192506
- 1.144339849948883
- 1.1316950798034668
- 1.1285599899291991
- 1.128514199256897
- 1.1283713626861571
- 1.125129952430725
- 1.1272633576393127
- 1.1290325284004212
- 1.1209480714797975
- 1.1231474351882935
- 1.1245986342430114
- 1.1329008269309997
- 1.1191577672958375
- 1.118834707736969
- 1.1137624669075012
- 1.120255973339081
- 1.1166297364234925
- 1.1207002544403075
- 1.115136969089508
- 1.111090099811554
- 1.1121390271186828
- 1.1133722710609435
- 1.1097767972946166
- 1.114672727584839
- 1.113426854610443
- 1.1122949314117432
- 1.1154165601730346
- 1.1032532739639282
- 1.1083757638931275
- 1.1199692368507386
- 1.1053514456748963
- 1.1095222997665406
- 1.1060715866088868
- 1.1075062346458435
- 1.1087211799621581
- 1.11061048746109
- 1.1134127569198609
- 1.115983772277832
- 1.111698365211487
- 1.1071153712272643
- 1.1210187602043151
- 1.1053948378562928
- 1.1085494017601014
- 1.1084286952018738
- 1.1132022762298583
- 1.1142848014831543
- 1.1066994285583496
- 1.1122407126426697
- 1.1193346929550172
- 1.1190707755088807
- 1.1079763269424439
- 1.1106307625770568
train_accuracy:
- 0.033
- 0.076
- 0.129
- 0.104
- 0.173
- 0.185
- 0.15
- 0.19
- 0.155
- 0.156
- 0.176
- 0.203
- 0.196
- 0.212
- 0.207
- 0.172
- 0.196
- 0.257
- 0.176
- 0.203
- 0.267
- 0.23
- 0.188
- 0.173
- 0.09
- 0.273
- 0.226
- 0.244
- 0.259
- 0.247
- 0.25
- 0.304
- 0.255
- 0.275
- 0.268
- 0.293
- 0.26
- 0.119
- 0.266
- 0.273
- 0.299
- 0.126
- 0.274
- 0.203
- 0.302
- 0.303
- 0.32
- 0.084
- 0.281
- 0.235
- 0.283
- 0.329
- 0.288
- 0.168
- 0.189
- 0.317
- 0.325
- 0.304
- 0.185
- 0.325
- 0.309
- 0.252
- 0.345
- 0.349
- 0.326
- 0.324
- 0.231
- 0.322
- 0.341
- 0.307
- 0.245
- 0.324
- 0.356
- 0.321
- 0.318
- 0.247
- 0.311
- 0.316
- 0.324
- 0.327
- 0.335
- 0.33
- 0.258
- 0.335
- 0.263
- 0.365
- 0.325
- 0.338
- 0.19
- 0.34
- 0.322
- 0.338
- 0.355
- 0.166
- 0.332
- 0.334
- 0.243
- 0.336
- 0.31
- 0.342
train_loss:
- 4.378
- 3.949
- 3.071
- 3.561
- 3.397
- 2.761
- 3.191
- 3.126
- 2.469
- 2.459
- 2.837
- 2.303
- 2.277
- 2.156
- 2.144
- 2.153
- 2.588
- 2.516
- 1.99
- 1.939
- 2.298
- 1.877
- 2.207
- 2.106
- 1.736
- 2.036
- 2.051
- 1.567
- 1.871
- 1.51
- 1.803
- 1.867
- 1.868
- 1.492
- 1.661
- 1.416
- 1.644
- 1.246
- 1.52
- 1.192
- 1.478
- 1.203
- 1.247
- 1.117
- 1.171
- 1.351
- 1.33
- 1.053
- 1.046
- 1.059
- 1.161
- 1.184
- 0.991
- 0.916
- 0.9
- 0.919
- 1.066
- 0.86
- 0.802
- 0.733
- 0.867
- 0.837
- 0.985
- 0.907
- 0.933
- 0.872
- 0.769
- 0.861
- 0.662
- 0.677
- 0.772
- 0.768
- 0.705
- 0.665
- 0.601
- 0.724
- 0.589
- 0.558
- 0.675
- 0.535
- 0.664
- 0.619
- 0.486
- 0.561
- 0.529
- 0.573
- 0.406
- 0.515
- 0.423
- 0.493
- 0.488
- 0.533
- 0.465
- 0.403
- 0.53
- 0.387
- 0.353
- 0.351
- 0.43
- 0.44
unequal: 0
verbose: 1
