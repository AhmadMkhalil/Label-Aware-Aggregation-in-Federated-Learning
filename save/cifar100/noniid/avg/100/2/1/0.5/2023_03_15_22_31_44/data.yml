avg_train_accuracy: 0.322
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0462
- 0.1035
- 0.1213
- 0.1323
- 0.1486
- 0.1587
- 0.1683
- 0.171
- 0.1808
- 0.1872
- 0.1978
- 0.2038
- 0.2031
- 0.2126
- 0.2233
- 0.2261
- 0.2271
- 0.2343
- 0.2324
- 0.2438
- 0.242
- 0.2418
- 0.239
- 0.2511
- 0.2486
- 0.25
- 0.2508
- 0.2613
- 0.2549
- 0.2679
- 0.2599
- 0.2639
- 0.2676
- 0.2729
- 0.2804
- 0.2714
- 0.2719
- 0.273
- 0.2855
- 0.2813
- 0.2755
- 0.285
- 0.2867
- 0.2837
- 0.2918
- 0.2844
- 0.2883
- 0.2903
- 0.2939
- 0.2861
- 0.2978
- 0.2878
- 0.2979
- 0.303
- 0.3021
- 0.2979
- 0.3046
- 0.3054
- 0.3037
- 0.3007
- 0.3026
- 0.3013
- 0.3048
- 0.3073
- 0.3113
- 0.3135
- 0.3128
- 0.3068
- 0.3105
- 0.3101
- 0.309
- 0.3092
- 0.3119
- 0.3083
- 0.3138
- 0.3177
- 0.3155
- 0.314
- 0.3156
- 0.3136
- 0.3158
- 0.3135
- 0.3138
- 0.3137
- 0.3175
- 0.3158
- 0.3196
- 0.3145
- 0.3199
- 0.3192
- 0.3195
- 0.317
- 0.3172
- 0.3203
- 0.3209
- 0.3226
- 0.3212
- 0.3171
- 0.3222
- 0.3268
test_loss_list:
- 1.766584095954895
- 1.6140693593025208
- 1.5694461226463319
- 1.5267253875732423
- 1.4927422165870667
- 1.4678051114082336
- 1.4425641584396363
- 1.4263881015777589
- 1.4102637577056885
- 1.3979011869430542
- 1.3843163418769837
- 1.3803718018531799
- 1.3579293775558472
- 1.3422904872894288
- 1.3290308761596679
- 1.3223281502723694
- 1.309722101688385
- 1.3013331079483033
- 1.295234034061432
- 1.2839817929267883
- 1.2856651759147644
- 1.2735559749603271
- 1.2748110723495483
- 1.2647243165969848
- 1.2589547967910766
- 1.2529713892936707
- 1.250198447704315
- 1.2400094485282898
- 1.2402252769470214
- 1.2302889704704285
- 1.225863447189331
- 1.226050832271576
- 1.220370454788208
- 1.2245726704597473
- 1.2144759964942933
- 1.2113090944290161
- 1.210516595840454
- 1.204351623058319
- 1.194729995727539
- 1.1935690474510192
- 1.200756046772003
- 1.188184950351715
- 1.1841601157188415
- 1.1878498101234436
- 1.1853324627876283
- 1.1883351635932922
- 1.178908874988556
- 1.1785772085189818
- 1.1805203127861024
- 1.1795380854606627
- 1.1699168181419373
- 1.1743472552299499
- 1.1665982675552369
- 1.1645501089096069
- 1.1688280963897706
- 1.1599214220046996
- 1.1561034798622132
- 1.162602927684784
- 1.1677917456626892
- 1.1683813548088073
- 1.1562216210365295
- 1.154332196712494
- 1.1570364570617675
- 1.1560991954803468
- 1.1566169810295106
- 1.1529151701927185
- 1.1566674995422364
- 1.1517494654655456
- 1.14981196641922
- 1.1569561672210693
- 1.1497717452049256
- 1.1536734795570374
- 1.1439050221443177
- 1.1512470269203186
- 1.144412133693695
- 1.1463059568405152
- 1.1500120997428893
- 1.1590431690216065
- 1.155404679775238
- 1.1544356107711793
- 1.1471059679985047
- 1.1486392688751221
- 1.1475837206840516
- 1.1474969983100891
- 1.1438444447517395
- 1.1434683394432068
- 1.1477160024642945
- 1.1583066082000733
- 1.1424707889556884
- 1.1479997849464416
- 1.1527747845649718
- 1.1453891801834106
- 1.148289728164673
- 1.154246973991394
- 1.1507344126701355
- 1.1526738333702087
- 1.1595764255523682
- 1.1490700316429139
- 1.1443357610702514
- 1.1437912249565125
train_accuracy:
- 0.031
- 0.083
- 0.11
- 0.116
- 0.178
- 0.187
- 0.169
- 0.215
- 0.165
- 0.172
- 0.162
- 0.21
- 0.183
- 0.191
- 0.176
- 0.264
- 0.256
- 0.226
- 0.194
- 0.248
- 0.287
- 0.217
- 0.234
- 0.251
- 0.275
- 0.247
- 0.228
- 0.246
- 0.252
- 0.253
- 0.1
- 0.173
- 0.243
- 0.273
- 0.267
- 0.309
- 0.276
- 0.127
- 0.286
- 0.32
- 0.236
- 0.135
- 0.293
- 0.337
- 0.341
- 0.287
- 0.319
- 0.311
- 0.301
- 0.079
- 0.287
- 0.297
- 0.288
- 0.327
- 0.317
- 0.086
- 0.328
- 0.329
- 0.32
- 0.319
- 0.303
- 0.178
- 0.299
- 0.348
- 0.301
- 0.377
- 0.335
- 0.278
- 0.336
- 0.358
- 0.342
- 0.317
- 0.308
- 0.305
- 0.345
- 0.32
- 0.391
- 0.346
- 0.307
- 0.269
- 0.064
- 0.321
- 0.32
- 0.331
- 0.291
- 0.277
- 0.321
- 0.199
- 0.352
- 0.341
- 0.284
- 0.112
- 0.281
- 0.361
- 0.354
- 0.338
- 0.324
- 0.289
- 0.362
- 0.322
train_loss:
- 4.278
- 3.81
- 3.547
- 2.828
- 3.289
- 3.162
- 2.629
- 2.446
- 2.432
- 2.867
- 2.777
- 2.709
- 2.22
- 2.219
- 2.56
- 2.53
- 1.994
- 2.381
- 1.944
- 2.303
- 2.195
- 1.846
- 1.76
- 2.111
- 1.708
- 1.626
- 1.626
- 1.916
- 1.521
- 1.931
- 1.516
- 1.466
- 1.805
- 1.799
- 1.666
- 1.333
- 1.268
- 1.353
- 1.568
- 1.258
- 1.187
- 1.251
- 1.38
- 1.197
- 1.35
- 1.09
- 1.124
- 1.266
- 1.24
- 0.959
- 1.22
- 0.939
- 1.191
- 1.146
- 1.139
- 0.948
- 1.029
- 1.057
- 0.929
- 1.012
- 0.788
- 0.834
- 0.735
- 0.844
- 0.937
- 0.806
- 0.77
- 0.736
- 0.773
- 0.786
- 0.617
- 0.616
- 0.797
- 0.658
- 0.717
- 0.678
- 0.678
- 0.619
- 0.623
- 0.683
- 0.471
- 0.643
- 0.507
- 0.436
- 0.597
- 0.464
- 0.415
- 0.447
- 0.567
- 0.512
- 0.478
- 0.411
- 0.503
- 0.462
- 0.467
- 0.424
- 0.452
- 0.382
- 0.452
- 0.348
unequal: 0
verbose: 1
