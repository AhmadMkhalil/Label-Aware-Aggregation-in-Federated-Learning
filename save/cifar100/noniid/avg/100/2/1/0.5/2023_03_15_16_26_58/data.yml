avg_train_accuracy: 0.099
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04
- 0.0934
- 0.1204
- 0.1379
- 0.1508
- 0.1555
- 0.1647
- 0.1744
- 0.1823
- 0.1932
- 0.1906
- 0.2093
- 0.2066
- 0.2084
- 0.2166
- 0.2172
- 0.2273
- 0.2266
- 0.2269
- 0.2318
- 0.2362
- 0.2408
- 0.2475
- 0.2465
- 0.2517
- 0.2571
- 0.254
- 0.2619
- 0.2574
- 0.2675
- 0.2667
- 0.2658
- 0.269
- 0.2738
- 0.2769
- 0.2808
- 0.2797
- 0.2797
- 0.2894
- 0.2838
- 0.28
- 0.282
- 0.283
- 0.2874
- 0.2888
- 0.3003
- 0.2996
- 0.2943
- 0.3016
- 0.3026
- 0.3017
- 0.2998
- 0.2954
- 0.2987
- 0.3033
- 0.3091
- 0.3109
- 0.3106
- 0.3172
- 0.3083
- 0.3108
- 0.3125
- 0.3082
- 0.32
- 0.3123
- 0.3113
- 0.3116
- 0.3177
- 0.3169
- 0.3161
- 0.317
- 0.3202
- 0.321
- 0.3232
- 0.3201
- 0.3201
- 0.3159
- 0.3257
- 0.3257
- 0.3252
- 0.3264
- 0.3199
- 0.3203
- 0.3207
- 0.322
- 0.3304
- 0.33
- 0.3297
- 0.3309
- 0.3268
- 0.3296
- 0.3297
- 0.3341
- 0.3313
- 0.3296
- 0.327
- 0.3296
- 0.3299
- 0.3318
- 0.3266
test_loss_list:
- 1.7845633554458618
- 1.646231074333191
- 1.5916585564613341
- 1.5478617691993712
- 1.5153851628303527
- 1.4839458966255188
- 1.4578500008583068
- 1.4395064043998718
- 1.4153538370132446
- 1.3985742163658141
- 1.3876715993881226
- 1.3678358268737794
- 1.356862804889679
- 1.3489831256866456
- 1.340019612312317
- 1.329404709339142
- 1.3118548107147217
- 1.3082865238189698
- 1.3009443140029908
- 1.2917737770080566
- 1.2881089091300963
- 1.276340365409851
- 1.2633847212791443
- 1.260693953037262
- 1.25261372089386
- 1.250895013809204
- 1.2430354046821595
- 1.2360580587387084
- 1.2313918280601501
- 1.2234344291687012
- 1.227250804901123
- 1.216906294822693
- 1.2164580273628234
- 1.2118811106681824
- 1.197552592754364
- 1.200329420566559
- 1.1961744165420531
- 1.1930914807319641
- 1.184712176322937
- 1.186980836391449
- 1.1867609000205994
- 1.187517056465149
- 1.1807414412498474
- 1.1791072916984557
- 1.1694613313674926
- 1.1599733781814576
- 1.161529541015625
- 1.166111192703247
- 1.156140444278717
- 1.1616177654266358
- 1.1571418118476868
- 1.156522970199585
- 1.1628547763824464
- 1.1620132446289062
- 1.1478186440467835
- 1.147727210521698
- 1.151537175178528
- 1.148560917377472
- 1.1438698506355285
- 1.1460426807403565
- 1.1400972938537597
- 1.139874484539032
- 1.141511743068695
- 1.134906084537506
- 1.140191707611084
- 1.137589840888977
- 1.1411644506454468
- 1.1274532222747802
- 1.1369079542160034
- 1.137278869152069
- 1.1356949853897094
- 1.1268520259857178
- 1.129527997970581
- 1.133722004890442
- 1.1323907780647278
- 1.1367543864250182
- 1.14002192735672
- 1.1245537400245667
- 1.131225392818451
- 1.131813018321991
- 1.1334594178199768
- 1.1340148115158082
- 1.129859254360199
- 1.1345964455604554
- 1.1382614803314208
- 1.1264348888397218
- 1.1270321202278137
- 1.122830603122711
- 1.1231560945510863
- 1.1305883049964904
- 1.124739499092102
- 1.1246000266075133
- 1.1278129625320434
- 1.1293041038513183
- 1.129914071559906
- 1.1267108821868896
- 1.1192727065086365
- 1.1290627646446227
- 1.1311833715438844
- 1.1315091753005981
train_accuracy:
- 0.038
- 0.073
- 0.119
- 0.124
- 0.116
- 0.115
- 0.178
- 0.167
- 0.166
- 0.169
- 0.188
- 0.185
- 0.189
- 0.105
- 0.192
- 0.202
- 0.186
- 0.083
- 0.237
- 0.224
- 0.206
- 0.144
- 0.225
- 0.249
- 0.279
- 0.231
- 0.274
- 0.229
- 0.087
- 0.258
- 0.259
- 0.266
- 0.228
- 0.135
- 0.276
- 0.275
- 0.26
- 0.238
- 0.267
- 0.128
- 0.252
- 0.246
- 0.257
- 0.24
- 0.157
- 0.277
- 0.3
- 0.287
- 0.327
- 0.281
- 0.269
- 0.273
- 0.297
- 0.273
- 0.276
- 0.285
- 0.296
- 0.279
- 0.311
- 0.278
- 0.144
- 0.27
- 0.287
- 0.277
- 0.293
- 0.263
- 0.291
- 0.323
- 0.277
- 0.346
- 0.326
- 0.317
- 0.288
- 0.316
- 0.108
- 0.284
- 0.337
- 0.333
- 0.36
- 0.298
- 0.327
- 0.301
- 0.288
- 0.324
- 0.324
- 0.285
- 0.32
- 0.334
- 0.343
- 0.338
- 0.337
- 0.287
- 0.332
- 0.355
- 0.333
- 0.096
- 0.3
- 0.36
- 0.332
- 0.099
train_loss:
- 4.343
- 3.86
- 3.67
- 3.507
- 3.352
- 2.687
- 3.175
- 3.089
- 2.453
- 2.913
- 2.331
- 2.748
- 2.212
- 2.155
- 2.082
- 2.128
- 2.506
- 1.973
- 1.943
- 1.875
- 1.877
- 1.903
- 2.188
- 1.724
- 2.125
- 2.073
- 1.663
- 1.932
- 1.603
- 1.864
- 1.794
- 1.544
- 1.511
- 1.473
- 1.784
- 1.667
- 1.642
- 1.335
- 1.552
- 1.23
- 1.311
- 1.156
- 1.239
- 1.138
- 1.193
- 1.395
- 1.337
- 1.049
- 1.271
- 1.192
- 1.265
- 0.918
- 0.914
- 0.928
- 1.099
- 1.155
- 1.042
- 1.055
- 1.05
- 0.799
- 0.836
- 0.752
- 0.85
- 0.888
- 0.757
- 0.751
- 0.775
- 0.864
- 0.641
- 0.659
- 0.711
- 0.874
- 0.797
- 0.766
- 0.586
- 0.54
- 0.546
- 0.631
- 0.597
- 0.681
- 0.666
- 0.562
- 0.557
- 0.475
- 0.49
- 0.571
- 0.464
- 0.561
- 0.504
- 0.419
- 0.587
- 0.497
- 0.469
- 0.523
- 0.531
- 0.403
- 0.477
- 0.436
- 0.481
- 0.375
unequal: 0
verbose: 1
