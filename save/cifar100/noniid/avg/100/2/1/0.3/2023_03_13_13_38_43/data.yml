avg_train_accuracy: 0.304
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.044
- 0.0582
- 0.0708
- 0.1191
- 0.1015
- 0.1095
- 0.1563
- 0.1228
- 0.1654
- 0.174
- 0.1541
- 0.1894
- 0.1977
- 0.1825
- 0.2066
- 0.2098
- 0.217
- 0.2204
- 0.2094
- 0.2293
- 0.2389
- 0.2196
- 0.2203
- 0.2433
- 0.222
- 0.251
- 0.2531
- 0.2328
- 0.2599
- 0.2318
- 0.2379
- 0.2668
- 0.2636
- 0.2492
- 0.2744
- 0.2722
- 0.252
- 0.2784
- 0.2801
- 0.2836
- 0.2798
- 0.2685
- 0.2867
- 0.2659
- 0.2698
- 0.2939
- 0.2918
- 0.2893
- 0.2945
- 0.301
- 0.2987
- 0.3017
- 0.302
- 0.3089
- 0.2854
- 0.3042
- 0.3053
- 0.301
- 0.3094
- 0.3077
- 0.3095
- 0.3107
- 0.3135
- 0.3149
- 0.3159
- 0.315
- 0.3138
- 0.3124
- 0.2954
- 0.2895
- 0.3206
- 0.3199
- 0.3197
- 0.3179
- 0.319
- 0.2962
- 0.2946
- 0.3213
- 0.2941
- 0.3279
- 0.3019
- 0.3222
- 0.3233
- 0.33
- 0.307
- 0.3048
- 0.3237
- 0.3216
- 0.329
- 0.3267
- 0.3318
- 0.3266
- 0.3104
- 0.3306
- 0.3048
- 0.3034
- 0.3061
- 0.305
- 0.3322
- 0.3064
test_loss_list:
- 1.783039050102234
- 1.6838129949569702
- 1.6386573815345764
- 1.5579751896858216
- 1.5594576787948609
- 1.5386807346343994
- 1.4742431807518006
- 1.500137448310852
- 1.4422676277160644
- 1.429209520816803
- 1.4566609287261962
- 1.388374695777893
- 1.3818032932281494
- 1.3944295787811278
- 1.3544979071617127
- 1.3518795108795165
- 1.3334524202346802
- 1.325342538356781
- 1.339949586391449
- 1.302596333026886
- 1.2884644079208374
- 1.3137773752212525
- 1.3129771327972413
- 1.2705527353286743
- 1.3121116256713867
- 1.2581459403038024
- 1.2579679799079895
- 1.284504063129425
- 1.244800670146942
- 1.292139458656311
- 1.2671378922462464
- 1.226209499835968
- 1.2201956915855408
- 1.2541322827339172
- 1.2017836260795594
- 1.2126057982444762
- 1.2551967573165894
- 1.192257833480835
- 1.1901229548454284
- 1.1882744932174683
- 1.193377778530121
- 1.2170668721199036
- 1.1775702023506165
- 1.2234738636016846
- 1.2174923419952393
- 1.1692434358596802
- 1.1750382328033446
- 1.1762488603591919
- 1.1719758653640746
- 1.163117470741272
- 1.1676870155334473
- 1.1671380615234375
- 1.1643700742721557
- 1.159846751689911
- 1.1961228847503662
- 1.155943639278412
- 1.1566593337059021
- 1.1670541620254518
- 1.1491125559806823
- 1.1567405247688294
- 1.1541314816474915
- 1.1560655426979065
- 1.1516125226020812
- 1.1516651868820191
- 1.147242739200592
- 1.1516353821754455
- 1.1563969469070434
- 1.16338294506073
- 1.1802547478675842
- 1.2026320028305053
- 1.1332143592834472
- 1.1379131412506103
- 1.1337374448776245
- 1.1401137852668761
- 1.1441812872886659
- 1.1827208375930787
- 1.2008082962036133
- 1.1303533387184144
- 1.1963659358024596
- 1.1169416809082031
- 1.1844759488105774
- 1.128682379722595
- 1.1284076023101806
- 1.1302894711494447
- 1.1754925799369813
- 1.180075054168701
- 1.1285008573532105
- 1.135374004840851
- 1.1291558861732482
- 1.1368960905075074
- 1.134410080909729
- 1.140398633480072
- 1.1731302261352539
- 1.122595407962799
- 1.188669846057892
- 1.1990957403182982
- 1.1837036657333373
- 1.1897161626815795
- 1.129056932926178
- 1.1941969728469848
train_accuracy:
- 0.04
- 0.041
- 0.772
- 0.098
- 0.075
- 0.087
- 0.124
- 0.699
- 0.192
- 0.142
- 0.152
- 0.19
- 0.162
- 0.166
- 0.197
- 0.224
- 0.233
- 0.18
- 0.163
- 0.224
- 0.209
- 0.206
- 0.202
- 0.243
- 0.577
- 0.194
- 0.267
- 0.584
- 0.202
- 0.206
- 0.252
- 0.216
- 0.212
- 0.22
- 0.249
- 0.288
- 0.199
- 0.261
- 0.264
- 0.287
- 0.287
- 0.243
- 0.286
- 0.217
- 0.251
- 0.24
- 0.234
- 0.295
- 0.28
- 0.288
- 0.294
- 0.268
- 0.319
- 0.3
- 0.421
- 0.284
- 0.284
- 0.309
- 0.299
- 0.282
- 0.333
- 0.318
- 0.26
- 0.265
- 0.336
- 0.266
- 0.316
- 0.325
- 0.304
- 0.262
- 0.296
- 0.321
- 0.31
- 0.348
- 0.33
- 0.292
- 0.264
- 0.311
- 0.304
- 0.3
- 0.548
- 0.319
- 0.324
- 0.286
- 0.285
- 0.291
- 0.265
- 0.33
- 0.309
- 0.331
- 0.293
- 0.304
- 0.426
- 0.334
- 0.283
- 0.28
- 0.279
- 0.317
- 0.328
- 0.304
train_loss:
- 4.336
- 2.723
- 2.566
- 3.552
- 2.425
- 2.25
- 3.276
- 2.206
- 3.028
- 2.842
- 1.881
- 2.995
- 2.704
- 1.97
- 2.752
- 2.461
- 2.63
- 2.475
- 1.709
- 2.243
- 2.401
- 1.58
- 1.508
- 2.066
- 1.472
- 1.998
- 2.078
- 1.595
- 1.891
- 1.214
- 1.337
- 1.845
- 1.775
- 1.413
- 1.912
- 1.661
- 1.062
- 1.7
- 1.737
- 1.666
- 1.429
- 1.265
- 1.528
- 1.151
- 0.893
- 1.326
- 1.296
- 1.305
- 1.513
- 1.439
- 1.304
- 1.29
- 1.203
- 1.19
- 0.823
- 0.984
- 1.083
- 0.928
- 1.093
- 1.073
- 1.165
- 0.886
- 1.184
- 1.043
- 0.861
- 0.892
- 0.815
- 0.746
- 0.521
- 0.698
- 0.741
- 0.772
- 0.892
- 0.812
- 0.737
- 0.584
- 0.587
- 0.763
- 0.467
- 0.764
- 0.504
- 0.712
- 0.675
- 0.634
- 0.403
- 0.444
- 0.589
- 0.516
- 0.696
- 0.539
- 0.608
- 0.512
- 0.402
- 0.54
- 0.347
- 0.319
- 0.403
- 0.301
- 0.432
- 0.37
unequal: 0
verbose: 1
