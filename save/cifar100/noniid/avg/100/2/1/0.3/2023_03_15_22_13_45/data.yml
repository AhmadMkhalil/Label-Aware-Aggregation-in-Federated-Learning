avg_train_accuracy: 0.304
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0588
- 0.0953
- 0.1188
- 0.1314
- 0.1257
- 0.1487
- 0.1252
- 0.1709
- 0.1407
- 0.1493
- 0.1854
- 0.1915
- 0.1743
- 0.1752
- 0.2097
- 0.1863
- 0.2179
- 0.2226
- 0.1946
- 0.1966
- 0.229
- 0.2018
- 0.233
- 0.2329
- 0.2153
- 0.2177
- 0.2451
- 0.2475
- 0.2542
- 0.2524
- 0.2562
- 0.2569
- 0.2515
- 0.2396
- 0.26
- 0.2464
- 0.2635
- 0.2683
- 0.2726
- 0.2709
- 0.2605
- 0.2742
- 0.2771
- 0.2879
- 0.2832
- 0.2832
- 0.273
- 0.2823
- 0.2873
- 0.2612
- 0.2884
- 0.2886
- 0.2701
- 0.2731
- 0.2855
- 0.2878
- 0.2796
- 0.3013
- 0.278
- 0.2952
- 0.3012
- 0.3062
- 0.3023
- 0.2912
- 0.2877
- 0.3034
- 0.3106
- 0.3042
- 0.2922
- 0.2813
- 0.2865
- 0.3106
- 0.3058
- 0.3077
- 0.3063
- 0.3061
- 0.3092
- 0.2951
- 0.3067
- 0.2851
- 0.3086
- 0.2905
- 0.294
- 0.3111
- 0.3135
- 0.3142
- 0.3109
- 0.3077
- 0.3112
- 0.2949
- 0.3121
- 0.2939
- 0.295
- 0.318
- 0.2926
- 0.3146
- 0.3149
- 0.317
- 0.294
- 0.3142
test_loss_list:
- 1.7772224760055542
- 1.6458340859413148
- 1.5871617197990417
- 1.5519621610641479
- 1.5327007293701171
- 1.4838931369781494
- 1.4984565258026123
- 1.4376491594314575
- 1.4708566188812255
- 1.4610514545440674
- 1.4002065896987914
- 1.3909633898735045
- 1.4185577249526977
- 1.4115288352966309
- 1.3464797496795655
- 1.3780968570709229
- 1.3342045855522155
- 1.32966650724411
- 1.3633285522460938
- 1.3621269798278808
- 1.3044141054153442
- 1.3472275853157043
- 1.2978879022598266
- 1.2974988961219787
- 1.3241684126853943
- 1.3254271030426026
- 1.266371476650238
- 1.2716319894790649
- 1.2602005910873413
- 1.2576783752441407
- 1.254539382457733
- 1.2600912857055664
- 1.2697161960601806
- 1.2985278105735778
- 1.237908432483673
- 1.2675676202774049
- 1.229345018863678
- 1.234869351387024
- 1.2223885822296143
- 1.2198972606658935
- 1.2369249367713928
- 1.2062658715248107
- 1.2057559943199159
- 1.197639091014862
- 1.202167990207672
- 1.200087580680847
- 1.2291471886634826
- 1.18678897857666
- 1.1930802941322327
- 1.2512545037269591
- 1.1866639828681946
- 1.1856874108314515
- 1.232887508869171
- 1.2276905465126038
- 1.1828708600997926
- 1.1886011123657227
- 1.2262935185432433
- 1.1714032697677612
- 1.2290183210372925
- 1.174676160812378
- 1.1748965287208557
- 1.1693986558914184
- 1.1764182305336
- 1.1986118483543395
- 1.21574431180954
- 1.1575129199028016
- 1.1594951820373536
- 1.1658179807662963
- 1.196975131034851
- 1.2255000472068787
- 1.218470196723938
- 1.1564721393585204
- 1.1603046178817749
- 1.168585352897644
- 1.166969449520111
- 1.1750002479553223
- 1.168783473968506
- 1.2120632815361023
- 1.1638716816902162
- 1.226521143913269
- 1.1649835181236268
- 1.207435474395752
- 1.218961260318756
- 1.1632049202919006
- 1.1599264883995055
- 1.1709186482429503
- 1.174054160118103
- 1.1770394229888916
- 1.178435003757477
- 1.2204836869239808
- 1.1644294810295106
- 1.217936065196991
- 1.216280734539032
- 1.1583642721176148
- 1.21205317735672
- 1.155443501472473
- 1.1578210592269897
- 1.1627145314216614
- 1.213387598991394
- 1.156231186389923
train_accuracy:
- 0.045
- 0.087
- 0.129
- 0.118
- 0.208
- 0.156
- 0.097
- 0.169
- 0.128
- 0.579
- 0.152
- 0.18
- 0.131
- 0.153
- 0.211
- 0.143
- 0.217
- 0.206
- 0.523
- 0.602
- 0.223
- 0.199
- 0.254
- 0.219
- 0.58
- 0.223
- 0.242
- 0.223
- 0.277
- 0.235
- 0.232
- 0.244
- 0.237
- 0.387
- 0.259
- 0.535
- 0.261
- 0.251
- 0.283
- 0.275
- 0.247
- 0.259
- 0.276
- 0.25
- 0.256
- 0.266
- 0.25
- 0.311
- 0.269
- 0.524
- 0.269
- 0.269
- 0.229
- 0.21
- 0.269
- 0.258
- 0.226
- 0.279
- 0.243
- 0.272
- 0.291
- 0.274
- 0.27
- 0.475
- 0.249
- 0.332
- 0.277
- 0.276
- 0.285
- 0.243
- 0.199
- 0.331
- 0.267
- 0.32
- 0.294
- 0.328
- 0.328
- 0.44
- 0.35
- 0.571
- 0.299
- 0.22
- 0.259
- 0.28
- 0.304
- 0.277
- 0.297
- 0.272
- 0.336
- 0.255
- 0.34
- 0.283
- 0.306
- 0.303
- 0.271
- 0.359
- 0.293
- 0.312
- 0.294
- 0.304
train_loss:
- 4.327
- 3.882
- 3.629
- 3.515
- 2.351
- 3.313
- 2.328
- 3.082
- 2.075
- 1.944
- 2.922
- 2.854
- 2.005
- 1.851
- 2.823
- 1.864
- 2.588
- 2.435
- 1.75
- 1.595
- 2.318
- 1.497
- 2.223
- 2.186
- 1.482
- 1.461
- 2.128
- 1.917
- 2.226
- 2.132
- 1.805
- 1.7
- 1.714
- 1.23
- 1.77
- 1.348
- 1.583
- 1.581
- 1.823
- 1.878
- 1.308
- 1.456
- 1.719
- 1.608
- 1.501
- 1.307
- 0.948
- 1.287
- 1.37
- 0.902
- 1.203
- 1.34
- 1.033
- 1.003
- 1.216
- 1.103
- 0.857
- 1.183
- 0.707
- 1.137
- 1.077
- 1.077
- 1.006
- 0.839
- 0.709
- 1.023
- 0.945
- 0.948
- 0.748
- 0.54
- 0.643
- 0.864
- 0.855
- 0.829
- 0.857
- 0.726
- 0.795
- 0.486
- 0.755
- 0.491
- 0.663
- 0.572
- 0.403
- 0.619
- 0.643
- 0.515
- 0.545
- 0.64
- 0.609
- 0.39
- 0.515
- 0.436
- 0.403
- 0.681
- 0.392
- 0.621
- 0.497
- 0.477
- 0.358
- 0.438
unequal: 0
verbose: 1
