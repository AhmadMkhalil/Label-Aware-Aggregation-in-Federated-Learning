avg_train_accuracy: 0.295
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0244
- 0.0941
- 0.1158
- 0.1331
- 0.143
- 0.137
- 0.1615
- 0.179
- 0.1791
- 0.1878
- 0.1999
- 0.201
- 0.2102
- 0.2013
- 0.2206
- 0.2258
- 0.2022
- 0.1992
- 0.2067
- 0.2375
- 0.2428
- 0.2456
- 0.2509
- 0.2292
- 0.2264
- 0.2293
- 0.2337
- 0.2373
- 0.2658
- 0.2646
- 0.2443
- 0.2397
- 0.2679
- 0.2737
- 0.2763
- 0.2822
- 0.2567
- 0.281
- 0.2603
- 0.2846
- 0.2887
- 0.2857
- 0.2742
- 0.2661
- 0.2894
- 0.2689
- 0.2738
- 0.2798
- 0.2741
- 0.2971
- 0.2975
- 0.2828
- 0.2995
- 0.2979
- 0.2849
- 0.2827
- 0.3037
- 0.2837
- 0.3055
- 0.2884
- 0.3031
- 0.3096
- 0.3157
- 0.3024
- 0.3112
- 0.2912
- 0.3046
- 0.3138
- 0.2944
- 0.3125
- 0.3136
- 0.3167
- 0.3133
- 0.3175
- 0.3162
- 0.3052
- 0.301
- 0.3203
- 0.3142
- 0.2987
- 0.304
- 0.3005
- 0.3246
- 0.3016
- 0.3226
- 0.3014
- 0.3246
- 0.3226
- 0.3256
- 0.3242
- 0.323
- 0.3212
- 0.3243
- 0.3167
- 0.3106
- 0.3074
- 0.3273
- 0.3282
- 0.3311
- 0.3156
test_loss_list:
- 1.8056898975372315
- 1.6571814632415771
- 1.601200020313263
- 1.560818190574646
- 1.52337877035141
- 1.503798279762268
- 1.4645198559761048
- 1.436619758605957
- 1.4274775648117066
- 1.409723105430603
- 1.3953042483329774
- 1.382202579975128
- 1.3742476415634155
- 1.3647900414466858
- 1.3347973346710205
- 1.3321907639503479
- 1.3507579517364503
- 1.3498837041854859
- 1.3380969190597534
- 1.2896072888374328
- 1.2884620380401612
- 1.2744385623931884
- 1.2703322792053222
- 1.2946655702590943
- 1.2896259832382202
- 1.2847958564758302
- 1.2759804344177246
- 1.2772200775146485
- 1.2241895771026612
- 1.2325204586982728
- 1.2608255386352538
- 1.2739667344093322
- 1.213595016002655
- 1.212497022151947
- 1.2134409356117248
- 1.2051688480377196
- 1.2462532758712768
- 1.1973153829574585
- 1.2307221794128418
- 1.1830463671684266
- 1.185377905368805
- 1.1867234778404236
- 1.210139172077179
- 1.2256321859359742
- 1.1731217741966247
- 1.224472575187683
- 1.2120512509346009
- 1.1958078575134277
- 1.2118191719055176
- 1.162922830581665
- 1.1588347554206848
- 1.1973310399055481
- 1.1573684072494508
- 1.1612542700767516
- 1.1918238639831542
- 1.2019168686866761
- 1.1539027166366578
- 1.2004958963394166
- 1.1473267126083373
- 1.1925052547454833
- 1.152344698905945
- 1.147012677192688
- 1.1450045371055604
- 1.1694642663002015
- 1.1449647116661072
- 1.192385425567627
- 1.1601867198944091
- 1.148855664730072
- 1.1930030107498169
- 1.1362293648719788
- 1.1445686149597167
- 1.1425231051445008
- 1.1429958510398865
- 1.1447250199317933
- 1.1498519611358642
- 1.1679076385498046
- 1.1790359783172608
- 1.1370519590377808
- 1.1534713315963745
- 1.1859786248207091
- 1.1784193229675293
- 1.188056788444519
- 1.1369866275787353
- 1.1865028500556947
- 1.1401504254341126
- 1.1935483360290526
- 1.1358314538002015
- 1.1447491431236267
- 1.1463955950737
- 1.1466748547554015
- 1.1539326238632202
- 1.1490596437454224
- 1.1555909037590026
- 1.17228844165802
- 1.1839424753189087
- 1.1832922029495239
- 1.1342443656921386
- 1.1422406816482544
- 1.1364589214324952
- 1.1830143547058105
train_accuracy:
- 0.02
- 0.092
- 0.119
- 0.105
- 0.164
- 0.145
- 0.182
- 0.159
- 0.15
- 0.186
- 0.229
- 0.174
- 0.181
- 0.177
- 0.243
- 0.267
- 0.157
- 0.162
- 0.185
- 0.257
- 0.247
- 0.23
- 0.214
- 0.472
- 0.548
- 0.576
- 0.579
- 0.198
- 0.299
- 0.293
- 0.178
- 0.176
- 0.263
- 0.255
- 0.249
- 0.247
- 0.218
- 0.296
- 0.258
- 0.264
- 0.315
- 0.286
- 0.262
- 0.233
- 0.25
- 0.269
- 0.254
- 0.231
- 0.512
- 0.283
- 0.259
- 0.282
- 0.272
- 0.285
- 0.543
- 0.275
- 0.274
- 0.56
- 0.332
- 0.255
- 0.298
- 0.293
- 0.294
- 0.295
- 0.35
- 0.243
- 0.334
- 0.275
- 0.503
- 0.307
- 0.284
- 0.349
- 0.285
- 0.301
- 0.352
- 0.272
- 0.515
- 0.303
- 0.337
- 0.519
- 0.237
- 0.278
- 0.307
- 0.251
- 0.305
- 0.239
- 0.283
- 0.352
- 0.299
- 0.336
- 0.352
- 0.33
- 0.273
- 0.387
- 0.256
- 0.505
- 0.32
- 0.288
- 0.32
- 0.295
train_loss:
- 4.41
- 3.945
- 3.645
- 3.452
- 3.34
- 2.296
- 3.176
- 3.148
- 2.977
- 2.901
- 2.888
- 2.751
- 2.682
- 1.87
- 2.507
- 2.397
- 1.831
- 1.644
- 1.817
- 2.403
- 2.335
- 2.26
- 2.178
- 1.522
- 1.5
- 1.501
- 1.555
- 1.347
- 1.998
- 1.841
- 1.295
- 1.155
- 1.923
- 1.799
- 1.647
- 1.808
- 1.111
- 1.795
- 1.17
- 1.604
- 1.58
- 1.505
- 1.177
- 0.997
- 1.411
- 0.957
- 1.006
- 1.01
- 1.0
- 1.235
- 1.349
- 0.976
- 1.181
- 1.165
- 0.892
- 0.738
- 1.143
- 0.816
- 1.136
- 0.756
- 0.96
- 1.233
- 1.095
- 0.662
- 0.851
- 0.603
- 0.883
- 1.059
- 0.718
- 0.884
- 0.899
- 0.753
- 0.873
- 0.86
- 0.783
- 0.585
- 0.434
- 0.729
- 0.791
- 0.599
- 0.548
- 0.49
- 0.617
- 0.516
- 0.637
- 0.482
- 0.71
- 0.618
- 0.578
- 0.681
- 0.596
- 0.523
- 0.476
- 0.456
- 0.392
- 0.386
- 0.511
- 0.481
- 0.489
- 0.378
unequal: 0
verbose: 1
