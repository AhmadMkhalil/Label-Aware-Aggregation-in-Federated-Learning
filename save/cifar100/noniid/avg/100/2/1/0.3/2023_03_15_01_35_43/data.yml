avg_train_accuracy: 0.296
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.015
- 0.0936
- 0.1143
- 0.1341
- 0.1374
- 0.1509
- 0.1691
- 0.1777
- 0.1834
- 0.1773
- 0.1915
- 0.1994
- 0.2072
- 0.1812
- 0.2144
- 0.2193
- 0.2271
- 0.2053
- 0.2328
- 0.1935
- 0.2396
- 0.2071
- 0.2126
- 0.2204
- 0.2174
- 0.2226
- 0.2249
- 0.249
- 0.2555
- 0.2347
- 0.2569
- 0.2572
- 0.2655
- 0.2587
- 0.266
- 0.2474
- 0.2427
- 0.2711
- 0.2712
- 0.2542
- 0.2725
- 0.2838
- 0.2823
- 0.2816
- 0.2887
- 0.2872
- 0.2848
- 0.2878
- 0.2887
- 0.2868
- 0.2908
- 0.2956
- 0.2948
- 0.2969
- 0.3004
- 0.2996
- 0.3026
- 0.3003
- 0.2876
- 0.3046
- 0.2854
- 0.2846
- 0.2821
- 0.2801
- 0.2854
- 0.3047
- 0.3044
- 0.3102
- 0.3045
- 0.3088
- 0.3114
- 0.3098
- 0.3116
- 0.3035
- 0.3152
- 0.289
- 0.3139
- 0.3129
- 0.2926
- 0.3147
- 0.2952
- 0.3153
- 0.2892
- 0.3132
- 0.3174
- 0.2954
- 0.3111
- 0.3137
- 0.3174
- 0.3135
- 0.3175
- 0.3249
- 0.3231
- 0.3208
- 0.309
- 0.302
- 0.325
- 0.3193
- 0.3171
- 0.2995
test_loss_list:
- 1.8304866027832032
- 1.650366187095642
- 1.5983674788475037
- 1.5550945901870727
- 1.5287035036087036
- 1.4958520460128784
- 1.467806303501129
- 1.4478339791297912
- 1.436250171661377
- 1.4220002031326293
- 1.3957820224761963
- 1.375632495880127
- 1.370020694732666
- 1.3807284235954285
- 1.3437664461135865
- 1.3379959988594055
- 1.3241524410247802
- 1.3431771183013916
- 1.3011816048622131
- 1.342781014442444
- 1.2864168190956116
- 1.3307300901412964
- 1.3223574256896973
- 1.3156137895584106
- 1.3138755893707275
- 1.3031723976135254
- 1.3019193625450134
- 1.250097770690918
- 1.251970739364624
- 1.293070890903473
- 1.2373956656455993
- 1.2403756427764892
- 1.2350096988677979
- 1.243096866607666
- 1.2435870313644408
- 1.267991054058075
- 1.2757361626625061
- 1.2128907656669616
- 1.2112380838394166
- 1.2568851971626283
- 1.2047309494018554
- 1.1977427744865417
- 1.196358380317688
- 1.1964712476730346
- 1.1979715299606324
- 1.1992822623252868
- 1.1994496059417725
- 1.1958277654647826
- 1.1926703715324403
- 1.1890593266487122
- 1.1887863755226136
- 1.1879818320274353
- 1.1915898203849793
- 1.1777025651931763
- 1.176204698085785
- 1.1765343356132507
- 1.177141695022583
- 1.1794507586956025
- 1.1873128771781922
- 1.1507402396202087
- 1.1958784508705138
- 1.1976394772529602
- 1.2012128472328185
- 1.2116769742965698
- 1.2063331842422484
- 1.1500963127613069
- 1.1569795966148377
- 1.149787633419037
- 1.1622936177253722
- 1.1621874475479126
- 1.158021469116211
- 1.159974935054779
- 1.1565225076675416
- 1.1710286593437196
- 1.1407146501541137
- 1.1927577424049378
- 1.139446840286255
- 1.1477086555957794
- 1.1999759244918824
- 1.1431880044937133
- 1.1949755430221558
- 1.1407052624225615
- 1.1939250040054321
- 1.1439270293712616
- 1.1491337060928344
- 1.1965627193450927
- 1.1498660457134247
- 1.1455196404457093
- 1.151101109981537
- 1.1490999937057496
- 1.1550062716007232
- 1.144459981918335
- 1.1547020316123962
- 1.1484665977954864
- 1.1725782012939454
- 1.191678795814514
- 1.137419843673706
- 1.1499095928668976
- 1.1512403893470764
- 1.2041267037391663
train_accuracy:
- 0.0
- 0.087
- 0.121
- 0.144
- 0.13
- 0.154
- 0.18
- 0.16
- 0.201
- 0.193
- 0.208
- 0.207
- 0.223
- 0.154
- 0.197
- 0.225
- 0.244
- 0.523
- 0.23
- 0.51
- 0.237
- 0.169
- 0.2
- 0.595
- 0.591
- 0.179
- 0.218
- 0.221
- 0.271
- 0.19
- 0.212
- 0.245
- 0.263
- 0.28
- 0.247
- 0.425
- 0.246
- 0.253
- 0.305
- 0.588
- 0.3
- 0.269
- 0.249
- 0.319
- 0.294
- 0.307
- 0.303
- 0.27
- 0.291
- 0.269
- 0.253
- 0.233
- 0.314
- 0.265
- 0.317
- 0.246
- 0.299
- 0.326
- 0.301
- 0.294
- 0.255
- 0.534
- 0.292
- 0.271
- 0.623
- 0.297
- 0.297
- 0.339
- 0.318
- 0.345
- 0.327
- 0.335
- 0.291
- 0.278
- 0.328
- 0.254
- 0.323
- 0.307
- 0.299
- 0.326
- 0.578
- 0.318
- 0.293
- 0.309
- 0.348
- 0.532
- 0.341
- 0.324
- 0.315
- 0.255
- 0.301
- 0.343
- 0.329
- 0.341
- 0.229
- 0.318
- 0.311
- 0.336
- 0.299
- 0.296
train_loss:
- 3.047
- 3.998
- 3.715
- 3.488
- 3.292
- 3.363
- 3.225
- 3.172
- 2.984
- 2.121
- 2.805
- 2.875
- 2.776
- 1.92
- 2.549
- 2.563
- 2.629
- 1.792
- 2.424
- 1.636
- 2.283
- 1.634
- 1.553
- 1.511
- 1.496
- 1.555
- 1.403
- 2.052
- 1.867
- 1.309
- 2.029
- 1.874
- 1.892
- 1.716
- 1.536
- 1.186
- 0.977
- 1.748
- 1.712
- 1.059
- 1.59
- 1.556
- 1.648
- 1.587
- 1.414
- 1.259
- 1.421
- 1.335
- 1.311
- 1.42
- 1.227
- 1.323
- 1.164
- 1.335
- 1.064
- 1.234
- 1.132
- 1.033
- 0.761
- 1.101
- 0.766
- 0.653
- 0.726
- 0.619
- 0.629
- 0.986
- 0.864
- 0.959
- 0.901
- 0.873
- 0.859
- 0.768
- 0.819
- 0.618
- 0.7
- 0.614
- 0.68
- 0.675
- 0.455
- 0.729
- 0.527
- 0.656
- 0.532
- 0.568
- 0.551
- 0.422
- 0.483
- 0.559
- 0.564
- 0.623
- 0.655
- 0.526
- 0.532
- 0.558
- 0.422
- 0.392
- 0.433
- 0.4
- 0.57
- 0.324
unequal: 0
verbose: 1
