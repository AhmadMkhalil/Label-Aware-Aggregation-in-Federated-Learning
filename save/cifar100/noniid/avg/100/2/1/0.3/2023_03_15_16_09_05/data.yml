avg_train_accuracy: 0.317
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0456
- 0.0883
- 0.1115
- 0.1291
- 0.1492
- 0.1596
- 0.1696
- 0.1755
- 0.1762
- 0.1883
- 0.1946
- 0.1973
- 0.184
- 0.1761
- 0.2091
- 0.2165
- 0.2
- 0.2236
- 0.1986
- 0.2339
- 0.2068
- 0.2435
- 0.2495
- 0.2493
- 0.2511
- 0.2576
- 0.2394
- 0.2593
- 0.2648
- 0.2675
- 0.2649
- 0.2472
- 0.2693
- 0.2711
- 0.2386
- 0.2476
- 0.2734
- 0.2544
- 0.2778
- 0.2775
- 0.2822
- 0.2626
- 0.2601
- 0.2939
- 0.2707
- 0.2889
- 0.2904
- 0.2895
- 0.2919
- 0.298
- 0.2986
- 0.3009
- 0.291
- 0.304
- 0.3078
- 0.2789
- 0.2734
- 0.3065
- 0.2709
- 0.3047
- 0.3031
- 0.3078
- 0.3067
- 0.3058
- 0.295
- 0.2886
- 0.3098
- 0.3158
- 0.3183
- 0.3212
- 0.3156
- 0.3188
- 0.316
- 0.316
- 0.2967
- 0.3195
- 0.3175
- 0.3185
- 0.3222
- 0.3209
- 0.3221
- 0.3042
- 0.2985
- 0.3216
- 0.3216
- 0.325
- 0.3052
- 0.3198
- 0.3243
- 0.326
- 0.3258
- 0.3071
- 0.3319
- 0.3286
- 0.3294
- 0.3292
- 0.3276
- 0.3269
- 0.3312
- 0.3301
test_loss_list:
- 1.7797624588012695
- 1.6486791825294496
- 1.5920185732841492
- 1.5503593063354493
- 1.5137312626838684
- 1.4897207236289978
- 1.4668819284439087
- 1.4478191661834716
- 1.4244920301437378
- 1.3984806728363037
- 1.3869217181205749
- 1.3770195126533509
- 1.3887637972831726
- 1.3866242361068726
- 1.3395043969154359
- 1.3337075114250183
- 1.3492833328247071
- 1.3083181619644164
- 1.350755615234375
- 1.2911007452011107
- 1.3293260407447816
- 1.2733270597457886
- 1.268053274154663
- 1.2605791425704955
- 1.2688068342208862
- 1.255228910446167
- 1.282915678024292
- 1.2367202138900757
- 1.2261645436286925
- 1.2251053285598754
- 1.2319065713882447
- 1.2565414261817933
- 1.2160059022903442
- 1.2161355829238891
- 1.2729269099235534
- 1.2481135249137878
- 1.20061176776886
- 1.23764151096344
- 1.1886617946624756
- 1.193201880455017
- 1.1955162525177
- 1.2254235768318176
- 1.225153260231018
- 1.1660632395744324
- 1.213961842060089
- 1.173782262802124
- 1.1714861106872558
- 1.1720069742202759
- 1.1674546527862548
- 1.1667779731750487
- 1.1685963869094849
- 1.1618651962280273
- 1.178774893283844
- 1.1455021023750305
- 1.1518134903907775
- 1.2000921368598938
- 1.212118492126465
- 1.1513776421546935
- 1.2172825407981873
- 1.1428553438186646
- 1.15966126203537
- 1.1449141669273377
- 1.1452681159973144
- 1.1513848400115967
- 1.1780074667930602
- 1.1860388970375062
- 1.1369645285606385
- 1.135940978527069
- 1.140456464290619
- 1.1392659091949462
- 1.1446985483169556
- 1.1456709837913512
- 1.1525008392333984
- 1.1423553490638734
- 1.1776664328575135
- 1.1360968947410583
- 1.1442058658599854
- 1.1363409948349
- 1.1345491194725037
- 1.1375182032585145
- 1.1440591168403627
- 1.1731560564041137
- 1.185009582042694
- 1.1349991154670716
- 1.132319324016571
- 1.136146605014801
- 1.1749517512321472
- 1.1394576692581178
- 1.1331943678855896
- 1.139322202205658
- 1.1411955118179322
- 1.1736157131195069
- 1.120505418777466
- 1.1362007570266723
- 1.1373863911628723
- 1.1432155227661134
- 1.144683563709259
- 1.1456247615814208
- 1.140623848438263
- 1.1466704821586609
train_accuracy:
- 0.039
- 0.096
- 0.117
- 0.133
- 0.151
- 0.154
- 0.136
- 0.172
- 0.139
- 0.176
- 0.151
- 0.166
- 0.172
- 0.118
- 0.159
- 0.195
- 0.135
- 0.202
- 0.642
- 0.189
- 0.607
- 0.222
- 0.213
- 0.235
- 0.259
- 0.216
- 0.203
- 0.237
- 0.24
- 0.208
- 0.228
- 0.179
- 0.208
- 0.292
- 0.245
- 0.492
- 0.227
- 0.188
- 0.282
- 0.261
- 0.254
- 0.234
- 0.222
- 0.27
- 0.565
- 0.242
- 0.244
- 0.227
- 0.311
- 0.297
- 0.262
- 0.252
- 0.284
- 0.277
- 0.283
- 0.483
- 0.2
- 0.253
- 0.55
- 0.312
- 0.256
- 0.294
- 0.306
- 0.313
- 0.443
- 0.23
- 0.294
- 0.265
- 0.282
- 0.293
- 0.309
- 0.332
- 0.334
- 0.326
- 0.23
- 0.338
- 0.297
- 0.257
- 0.298
- 0.302
- 0.354
- 0.293
- 0.587
- 0.277
- 0.303
- 0.34
- 0.218
- 0.262
- 0.314
- 0.327
- 0.291
- 0.466
- 0.309
- 0.363
- 0.294
- 0.335
- 0.301
- 0.323
- 0.289
- 0.317
train_loss:
- 4.315
- 3.871
- 3.683
- 3.512
- 3.344
- 3.255
- 3.135
- 3.062
- 2.21
- 2.989
- 2.827
- 2.861
- 2.0
- 1.849
- 2.585
- 2.497
- 1.822
- 2.419
- 1.576
- 2.347
- 1.737
- 2.38
- 2.349
- 2.224
- 2.048
- 2.137
- 1.4
- 1.966
- 1.973
- 1.962
- 1.763
- 1.293
- 1.666
- 1.707
- 1.131
- 1.227
- 1.495
- 1.373
- 1.731
- 1.453
- 1.515
- 1.243
- 1.019
- 1.56
- 0.989
- 1.332
- 1.52
- 1.221
- 1.375
- 1.315
- 1.353
- 1.256
- 0.804
- 1.212
- 1.016
- 0.806
- 0.606
- 0.87
- 0.732
- 1.104
- 0.999
- 1.11
- 0.966
- 1.128
- 0.728
- 0.696
- 0.92
- 0.848
- 0.9
- 0.863
- 0.733
- 0.881
- 0.672
- 0.831
- 0.51
- 0.843
- 0.677
- 0.68
- 0.744
- 0.684
- 0.726
- 0.488
- 0.496
- 0.586
- 0.589
- 0.582
- 0.41
- 0.457
- 0.604
- 0.459
- 0.492
- 0.496
- 0.584
- 0.609
- 0.559
- 0.458
- 0.439
- 0.433
- 0.556
- 0.437
unequal: 0
verbose: 1
