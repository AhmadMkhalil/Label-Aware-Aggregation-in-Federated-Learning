avg_train_accuracy: 0.552
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0157
- 0.0936
- 0.0654
- 0.0755
- 0.1328
- 0.0991
- 0.1131
- 0.1195
- 0.1619
- 0.1721
- 0.1853
- 0.187
- 0.1879
- 0.1965
- 0.2011
- 0.2017
- 0.2169
- 0.2214
- 0.2201
- 0.2306
- 0.2135
- 0.197
- 0.2387
- 0.2381
- 0.2419
- 0.2472
- 0.2255
- 0.2439
- 0.2511
- 0.2276
- 0.2348
- 0.229
- 0.2323
- 0.2301
- 0.2637
- 0.2648
- 0.2664
- 0.2669
- 0.2713
- 0.2708
- 0.2724
- 0.2773
- 0.2798
- 0.278
- 0.2645
- 0.28
- 0.2882
- 0.2833
- 0.2839
- 0.2856
- 0.2754
- 0.2838
- 0.2919
- 0.2879
- 0.2722
- 0.2953
- 0.2713
- 0.2762
- 0.2982
- 0.2953
- 0.3001
- 0.2826
- 0.3005
- 0.3028
- 0.3013
- 0.3053
- 0.3025
- 0.2862
- 0.3092
- 0.3037
- 0.3043
- 0.2894
- 0.2802
- 0.3103
- 0.3106
- 0.3103
- 0.2972
- 0.2873
- 0.2882
- 0.3134
- 0.2901
- 0.3181
- 0.3136
- 0.2927
- 0.3121
- 0.3177
- 0.3182
- 0.3127
- 0.2996
- 0.3178
- 0.2963
- 0.314
- 0.3133
- 0.3147
- 0.3229
- 0.2971
- 0.3156
- 0.2921
- 0.3184
- 0.293
test_loss_list:
- 1.8432837152481079
- 1.6491433954238892
- 1.6328367495536804
- 1.6067851209640502
- 1.528663079738617
- 1.5456161212921142
- 1.523628935813904
- 1.5030196261405946
- 1.448371160030365
- 1.4361395168304443
- 1.4199834632873536
- 1.4127496242523194
- 1.4014053845405579
- 1.3887621879577636
- 1.3826725792884826
- 1.3807625675201416
- 1.3595402669906616
- 1.3453330087661743
- 1.3449917650222778
- 1.3319555568695067
- 1.3376961040496826
- 1.3616258716583252
- 1.2943971872329711
- 1.2954786968231202
- 1.2920366740226745
- 1.2817321300506592
- 1.3041610765457152
- 1.2753868317604065
- 1.2692194986343384
- 1.303065423965454
- 1.2890885400772094
- 1.2909622311592102
- 1.288765962123871
- 1.3030766081809997
- 1.233605854511261
- 1.240540282726288
- 1.2408776807785034
- 1.238822536468506
- 1.238602225780487
- 1.2386675453186036
- 1.2347458028793334
- 1.2300739121437072
- 1.2205232453346253
- 1.2166279816627503
- 1.23549959897995
- 1.2035605144500732
- 1.2001636290550233
- 1.2038239526748657
- 1.198753855228424
- 1.203791494369507
- 1.2081070947647095
- 1.1949223113059997
- 1.1905738091468812
- 1.1933658456802367
- 1.2202132940292358
- 1.1759097695350647
- 1.2218441486358642
- 1.2148017621040343
- 1.177995240688324
- 1.1897437167167664
- 1.1739679598808288
- 1.2034710240364075
- 1.17278480052948
- 1.1754112887382506
- 1.1807545185089112
- 1.1782071113586425
- 1.1747170758247376
- 1.203038341999054
- 1.1609135007858276
- 1.1708949637413024
- 1.1747145962715149
- 1.2070375156402589
- 1.2236012840270996
- 1.1673142218589783
- 1.1678243923187255
- 1.1681094098091125
- 1.1902662658691405
- 1.2215928435325623
- 1.2095547533035278
- 1.1605628991127015
- 1.213712112903595
- 1.1506765580177307
- 1.1585748529434203
- 1.1996075105667114
- 1.1620753884315491
- 1.1602190041542053
- 1.1632748460769653
- 1.1709458947181701
- 1.1953214764595033
- 1.157083752155304
- 1.2148515510559081
- 1.16273508310318
- 1.1632995319366455
- 1.1746826934814454
- 1.164775779247284
- 1.1980494022369386
- 1.1662421107292176
- 1.2131744813919068
- 1.158326632976532
- 1.2126664566993712
train_accuracy:
- 0.0
- 0.087
- 0.05
- 0.037
- 0.094
- 0.053
- 0.716
- 0.09
- 0.169
- 0.176
- 0.199
- 0.2
- 0.182
- 0.21
- 0.209
- 0.183
- 0.216
- 0.243
- 0.247
- 0.211
- 0.196
- 0.559
- 0.223
- 0.249
- 0.231
- 0.232
- 0.464
- 0.243
- 0.271
- 0.15
- 0.485
- 0.469
- 0.215
- 0.517
- 0.228
- 0.191
- 0.285
- 0.243
- 0.286
- 0.242
- 0.258
- 0.27
- 0.292
- 0.295
- 0.261
- 0.318
- 0.227
- 0.266
- 0.32
- 0.323
- 0.268
- 0.28
- 0.28
- 0.28
- 0.462
- 0.287
- 0.264
- 0.259
- 0.311
- 0.288
- 0.296
- 0.491
- 0.317
- 0.354
- 0.251
- 0.297
- 0.282
- 0.265
- 0.31
- 0.309
- 0.305
- 0.254
- 0.573
- 0.243
- 0.253
- 0.323
- 0.528
- 0.609
- 0.532
- 0.261
- 0.498
- 0.322
- 0.286
- 0.268
- 0.291
- 0.295
- 0.299
- 0.283
- 0.286
- 0.333
- 0.558
- 0.311
- 0.354
- 0.293
- 0.303
- 0.239
- 0.293
- 0.28
- 0.286
- 0.552
train_loss:
- 2.997
- 3.918
- 2.62
- 2.459
- 3.44
- 2.31
- 2.259
- 2.174
- 3.139
- 2.97
- 3.016
- 2.807
- 2.772
- 2.738
- 2.563
- 2.425
- 2.628
- 2.533
- 2.304
- 2.399
- 1.697
- 1.51
- 2.216
- 2.124
- 2.025
- 2.11
- 1.316
- 1.832
- 1.888
- 1.375
- 1.388
- 1.181
- 1.078
- 1.107
- 1.845
- 1.682
- 1.617
- 1.531
- 1.529
- 1.324
- 1.607
- 1.614
- 1.653
- 1.5
- 0.975
- 1.465
- 1.395
- 1.168
- 1.311
- 1.383
- 0.867
- 1.141
- 1.198
- 1.037
- 0.793
- 1.327
- 0.731
- 0.746
- 1.019
- 0.904
- 1.09
- 0.793
- 0.942
- 1.124
- 0.962
- 0.84
- 0.902
- 0.485
- 0.854
- 0.669
- 0.735
- 0.531
- 0.536
- 0.77
- 0.816
- 0.795
- 0.585
- 0.463
- 0.503
- 0.686
- 0.51
- 0.796
- 0.639
- 0.46
- 0.671
- 0.627
- 0.583
- 0.518
- 0.511
- 0.612
- 0.335
- 0.665
- 0.506
- 0.501
- 0.61
- 0.367
- 0.417
- 0.407
- 0.369
- 0.404
unequal: 0
verbose: 1
