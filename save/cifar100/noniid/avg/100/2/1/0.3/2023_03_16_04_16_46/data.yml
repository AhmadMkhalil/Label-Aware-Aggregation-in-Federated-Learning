avg_train_accuracy: 0.307
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0195
- 0.0851
- 0.1112
- 0.124
- 0.1392
- 0.1531
- 0.147
- 0.1726
- 0.179
- 0.1514
- 0.193
- 0.158
- 0.1979
- 0.1739
- 0.1799
- 0.2132
- 0.2169
- 0.2192
- 0.2283
- 0.2329
- 0.2375
- 0.2314
- 0.2437
- 0.216
- 0.2475
- 0.2514
- 0.2308
- 0.2327
- 0.2355
- 0.2584
- 0.2361
- 0.2617
- 0.2416
- 0.265
- 0.273
- 0.2746
- 0.2504
- 0.2572
- 0.2758
- 0.2864
- 0.285
- 0.2702
- 0.2691
- 0.2873
- 0.2649
- 0.2952
- 0.2963
- 0.2996
- 0.2979
- 0.2912
- 0.2827
- 0.2778
- 0.3
- 0.281
- 0.2954
- 0.3021
- 0.3056
- 0.2912
- 0.2861
- 0.306
- 0.3076
- 0.3109
- 0.2967
- 0.3164
- 0.3204
- 0.3194
- 0.3052
- 0.321
- 0.3223
- 0.3251
- 0.3228
- 0.3271
- 0.3138
- 0.3255
- 0.3257
- 0.3069
- 0.3239
- 0.3045
- 0.326
- 0.3227
- 0.3301
- 0.3088
- 0.3077
- 0.3235
- 0.3035
- 0.3016
- 0.3014
- 0.3371
- 0.3046
- 0.3302
- 0.3304
- 0.3149
- 0.3316
- 0.3339
- 0.3349
- 0.3312
- 0.3335
- 0.3344
- 0.3346
- 0.3145
test_loss_list:
- 1.8273805713653564
- 1.6729230690002441
- 1.613722457885742
- 1.573911919593811
- 1.541516077518463
- 1.5043985080718993
- 1.4900936126708983
- 1.4513651037216186
- 1.4440433621406554
- 1.4528331804275512
- 1.4011201167106628
- 1.434152171611786
- 1.3766752243041993
- 1.4104442024230956
- 1.3884114956855773
- 1.3488200426101684
- 1.336870653629303
- 1.3286688494682313
- 1.3186622858047485
- 1.3070819354057313
- 1.305329144001007
- 1.3025498056411744
- 1.267717595100403
- 1.315479724407196
- 1.2558308696746827
- 1.261667091846466
- 1.2998725771903992
- 1.2913114500045777
- 1.2849216413497926
- 1.2374260330200195
- 1.286982069015503
- 1.2307453227043152
- 1.2744276642799377
- 1.2241033673286439
- 1.2184679102897644
- 1.213234956264496
- 1.256462366580963
- 1.2376550698280335
- 1.193976550102234
- 1.1916746377944947
- 1.188058190345764
- 1.2160712933540345
- 1.227478530406952
- 1.176174714565277
- 1.221815173625946
- 1.1657332229614257
- 1.1643150568008422
- 1.1666405057907105
- 1.1679369020462036
- 1.1873170804977418
- 1.204705548286438
- 1.2060916137695312
- 1.1573543667793273
- 1.2142476391792298
- 1.167670578956604
- 1.156799747943878
- 1.154012770652771
- 1.1798572063446044
- 1.1990278244018555
- 1.143616509437561
- 1.1549720287322998
- 1.1510935139656067
- 1.1746798729896546
- 1.1302337169647216
- 1.1355701470375061
- 1.138656690120697
- 1.1644280934333802
- 1.1294284319877625
- 1.1261499071121215
- 1.1293357276916505
- 1.1405230808258056
- 1.1229597592353822
- 1.1473651289939881
- 1.1192281603813172
- 1.1339075922966004
- 1.172150411605835
- 1.123266682624817
- 1.1712177586555481
- 1.1229647207260132
- 1.1288047313690186
- 1.1234404349327087
- 1.1640853333473205
- 1.1619559741020202
- 1.1328067445755006
- 1.184680664539337
- 1.1912197685241699
- 1.1865954542160033
- 1.1212850141525268
- 1.1891360974311829
- 1.1260046219825746
- 1.126136429309845
- 1.1570405912399293
- 1.1205211329460143
- 1.120260365009308
- 1.1225668668746949
- 1.1213351202011108
- 1.1241428756713867
- 1.1252957558631898
- 1.1268386054039001
- 1.1709449315071105
train_accuracy:
- 0.002
- 0.066
- 0.115
- 0.093
- 0.119
- 0.15
- 0.368
- 0.159
- 0.163
- 0.673
- 0.175
- 0.159
- 0.193
- 0.685
- 0.136
- 0.182
- 0.224
- 0.192
- 0.21
- 0.216
- 0.233
- 0.193
- 0.242
- 0.635
- 0.221
- 0.269
- 0.215
- 0.581
- 0.185
- 0.21
- 0.218
- 0.243
- 0.181
- 0.266
- 0.225
- 0.275
- 0.226
- 0.239
- 0.242
- 0.28
- 0.273
- 0.265
- 0.264
- 0.309
- 0.234
- 0.272
- 0.269
- 0.297
- 0.319
- 0.325
- 0.294
- 0.535
- 0.262
- 0.284
- 0.275
- 0.298
- 0.301
- 0.264
- 0.231
- 0.319
- 0.293
- 0.314
- 0.55
- 0.293
- 0.306
- 0.275
- 0.308
- 0.312
- 0.281
- 0.332
- 0.312
- 0.302
- 0.342
- 0.301
- 0.291
- 0.507
- 0.306
- 0.278
- 0.303
- 0.348
- 0.302
- 0.295
- 0.266
- 0.343
- 0.322
- 0.263
- 0.288
- 0.334
- 0.6
- 0.327
- 0.271
- 0.31
- 0.319
- 0.37
- 0.312
- 0.33
- 0.312
- 0.305
- 0.297
- 0.307
train_loss:
- 3.06
- 4.047
- 3.698
- 3.53
- 3.33
- 3.485
- 2.271
- 3.233
- 3.006
- 2.311
- 2.942
- 1.981
- 2.844
- 1.927
- 1.992
- 2.619
- 2.6
- 2.676
- 2.507
- 2.508
- 2.265
- 1.727
- 2.282
- 1.659
- 2.284
- 2.208
- 1.397
- 1.514
- 1.439
- 1.977
- 1.412
- 1.893
- 1.26
- 1.839
- 1.829
- 1.727
- 1.176
- 1.322
- 1.777
- 1.647
- 1.672
- 1.165
- 0.998
- 1.677
- 1.126
- 1.497
- 1.451
- 1.44
- 1.345
- 1.278
- 0.824
- 0.959
- 1.234
- 0.741
- 1.048
- 1.318
- 1.187
- 0.867
- 0.766
- 0.997
- 1.157
- 0.981
- 0.924
- 1.094
- 0.979
- 0.976
- 0.92
- 0.93
- 0.906
- 0.975
- 0.814
- 0.99
- 0.605
- 0.743
- 0.676
- 0.542
- 0.659
- 0.617
- 0.77
- 0.642
- 0.764
- 0.46
- 0.603
- 0.689
- 0.562
- 0.356
- 0.461
- 0.628
- 0.501
- 0.634
- 0.439
- 0.609
- 0.559
- 0.523
- 0.453
- 0.597
- 0.637
- 0.527
- 0.521
- 0.373
unequal: 0
verbose: 1
