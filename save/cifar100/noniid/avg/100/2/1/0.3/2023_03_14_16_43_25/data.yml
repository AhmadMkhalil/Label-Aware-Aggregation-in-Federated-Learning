avg_train_accuracy: 0.335
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0447
- 0.0388
- 0.1106
- 0.1261
- 0.1385
- 0.1289
- 0.1142
- 0.1601
- 0.1713
- 0.1519
- 0.1925
- 0.1542
- 0.1963
- 0.2037
- 0.2091
- 0.2169
- 0.1886
- 0.1902
- 0.1947
- 0.2273
- 0.2302
- 0.233
- 0.2062
- 0.237
- 0.2038
- 0.2408
- 0.2456
- 0.2491
- 0.2528
- 0.2366
- 0.2294
- 0.259
- 0.2319
- 0.2663
- 0.269
- 0.2691
- 0.2706
- 0.2749
- 0.2761
- 0.2786
- 0.2802
- 0.2811
- 0.2814
- 0.2681
- 0.2814
- 0.2831
- 0.2578
- 0.2845
- 0.2899
- 0.2632
- 0.2618
- 0.2918
- 0.2911
- 0.2719
- 0.2737
- 0.2773
- 0.2909
- 0.2994
- 0.2972
- 0.2983
- 0.3048
- 0.2967
- 0.2874
- 0.3013
- 0.2989
- 0.2996
- 0.309
- 0.2838
- 0.3031
- 0.3062
- 0.2769
- 0.3074
- 0.3081
- 0.3048
- 0.3093
- 0.3052
- 0.3122
- 0.3114
- 0.3126
- 0.2991
- 0.2892
- 0.3142
- 0.3108
- 0.3142
- 0.3103
- 0.3147
- 0.296
- 0.2929
- 0.3149
- 0.3184
- 0.2917
- 0.3165
- 0.2956
- 0.2933
- 0.2928
- 0.3189
- 0.3163
- 0.3177
- 0.3032
- 0.3167
test_loss_list:
- 1.777388229370117
- 1.6913686418533325
- 1.5949974656105042
- 1.552752058506012
- 1.5211987137794494
- 1.5163583779335021
- 1.5233190870285034
- 1.4568555116653443
- 1.4426630306243897
- 1.4526808786392211
- 1.3999278926849366
- 1.440511703491211
- 1.3830911087989808
- 1.369837486743927
- 1.3601538038253784
- 1.3521795058250428
- 1.3687987923622131
- 1.3690599918365478
- 1.3544119691848755
- 1.3060662484169006
- 1.3052913308143617
- 1.301667675971985
- 1.3293185114860535
- 1.2799383330345153
- 1.3245782160758972
- 1.270822217464447
- 1.2650133347511292
- 1.2599030995368958
- 1.2551444339752198
- 1.2727333664894105
- 1.2886149239540101
- 1.2320061922073364
- 1.2724628829956055
- 1.2239356803894044
- 1.2250011849403382
- 1.2186527490615844
- 1.2146161794662476
- 1.2145680499076843
- 1.21774090051651
- 1.2111927723884583
- 1.2091073036193847
- 1.2008490753173828
- 1.2065115070343018
- 1.2233965945243837
- 1.1903535532951355
- 1.189356017112732
- 1.237093300819397
- 1.1834525990486144
- 1.1849853992462158
- 1.2223990273475647
- 1.2320082902908325
- 1.170776948928833
- 1.1762494444847107
- 1.2084965872764588
- 1.204952380657196
- 1.204580557346344
- 1.1705806922912598
- 1.165120346546173
- 1.1627220129966735
- 1.1606159067153932
- 1.1672306156158447
- 1.1701126146316527
- 1.1971227979660035
- 1.1592860412597656
- 1.158382694721222
- 1.1590537381172181
- 1.155012698173523
- 1.2009681463241577
- 1.151092004776001
- 1.1548236227035522
- 1.2051947212219238
- 1.1428788566589356
- 1.14654709815979
- 1.144868471622467
- 1.1509507489204407
- 1.1587251734733581
- 1.156704270839691
- 1.158601839542389
- 1.1491618585586547
- 1.1696806740760803
- 1.1947033286094666
- 1.1365934419631958
- 1.1513329696655275
- 1.1437070226669313
- 1.1559291195869446
- 1.1534954977035523
- 1.1838644552230835
- 1.193411819934845
- 1.1372396397590636
- 1.1394129037857055
- 1.192534291744232
- 1.14284916639328
- 1.1965256857872009
- 1.20897296667099
- 1.2199833989143372
- 1.143769552707672
- 1.1501979041099548
- 1.1470799326896668
- 1.18283509016037
- 1.1394514179229736
train_accuracy:
- 0.048
- 0.017
- 0.091
- 0.111
- 0.137
- 0.11
- 0.075
- 0.168
- 0.15
- 0.101
- 0.169
- 0.1
- 0.162
- 0.225
- 0.18
- 0.177
- 0.364
- 0.119
- 0.579
- 0.183
- 0.212
- 0.207
- 0.147
- 0.23
- 0.158
- 0.232
- 0.194
- 0.212
- 0.245
- 0.482
- 0.495
- 0.227
- 0.182
- 0.23
- 0.253
- 0.252
- 0.263
- 0.27
- 0.242
- 0.232
- 0.282
- 0.245
- 0.257
- 0.395
- 0.248
- 0.254
- 0.237
- 0.267
- 0.269
- 0.432
- 0.525
- 0.277
- 0.27
- 0.491
- 0.246
- 0.243
- 0.27
- 0.272
- 0.262
- 0.287
- 0.273
- 0.268
- 0.246
- 0.294
- 0.274
- 0.24
- 0.271
- 0.249
- 0.295
- 0.287
- 0.247
- 0.302
- 0.278
- 0.312
- 0.288
- 0.325
- 0.327
- 0.29
- 0.269
- 0.286
- 0.272
- 0.311
- 0.291
- 0.318
- 0.304
- 0.302
- 0.416
- 0.553
- 0.309
- 0.302
- 0.475
- 0.314
- 0.262
- 0.282
- 0.573
- 0.31
- 0.287
- 0.283
- 0.46
- 0.335
train_loss:
- 4.353
- 2.799
- 3.772
- 3.552
- 3.463
- 2.384
- 2.204
- 3.114
- 3.09
- 2.156
- 3.039
- 1.993
- 2.813
- 2.946
- 2.783
- 2.632
- 1.845
- 1.689
- 1.818
- 2.519
- 2.398
- 2.373
- 1.605
- 2.273
- 1.431
- 2.2
- 2.193
- 2.068
- 2.252
- 1.413
- 1.357
- 1.89
- 1.257
- 1.807
- 1.934
- 1.96
- 1.825
- 1.725
- 1.604
- 1.737
- 1.629
- 1.547
- 1.443
- 1.051
- 1.267
- 1.459
- 0.933
- 1.409
- 1.248
- 1.075
- 0.85
- 1.149
- 1.51
- 0.895
- 0.979
- 0.872
- 1.164
- 1.133
- 1.175
- 1.185
- 0.968
- 0.988
- 0.688
- 1.036
- 0.976
- 0.985
- 1.003
- 0.531
- 0.984
- 0.905
- 0.664
- 1.059
- 0.869
- 0.84
- 0.802
- 0.85
- 0.773
- 0.622
- 0.878
- 0.585
- 0.449
- 0.709
- 0.753
- 0.725
- 0.556
- 0.709
- 0.561
- 0.375
- 0.675
- 0.545
- 0.375
- 0.558
- 0.382
- 0.278
- 0.336
- 0.486
- 0.451
- 0.514
- 0.431
- 0.568
unequal: 0
verbose: 1
