avg_train_accuracy: 0.192
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0207
- 0.0684
- 0.1026
- 0.123
- 0.1259
- 0.1404
- 0.1568
- 0.1628
- 0.1673
- 0.1762
- 0.183
- 0.1872
- 0.1932
- 0.2025
- 0.2039
- 0.2056
- 0.2139
- 0.2211
- 0.2197
- 0.2241
- 0.2263
- 0.2338
- 0.2326
- 0.241
- 0.2384
- 0.2409
- 0.2468
- 0.2488
- 0.2541
- 0.2533
- 0.2524
- 0.2585
- 0.2575
- 0.2646
- 0.2679
- 0.2631
- 0.2659
- 0.2711
- 0.2667
- 0.2694
- 0.2714
- 0.2737
- 0.2793
- 0.281
- 0.2743
- 0.2758
- 0.2783
- 0.2815
- 0.2838
- 0.2829
- 0.2881
- 0.2901
- 0.2862
- 0.2925
- 0.2918
- 0.2895
- 0.2937
- 0.2899
- 0.291
- 0.2939
- 0.2979
- 0.3001
- 0.2981
- 0.3002
- 0.3009
- 0.3007
- 0.2983
- 0.2999
- 0.3003
- 0.3014
- 0.3051
- 0.3029
- 0.303
- 0.3027
- 0.3002
- 0.3045
- 0.3047
- 0.3021
- 0.3027
- 0.3061
- 0.3082
- 0.3053
- 0.304
- 0.3108
- 0.306
- 0.3042
- 0.3087
- 0.3116
- 0.308
- 0.3114
- 0.3108
- 0.3095
- 0.3071
- 0.3093
- 0.3096
- 0.3094
- 0.3097
- 0.3088
- 0.3091
- 0.3118
test_loss_list:
- 1.8363974618911743
- 1.7143149614334106
- 1.6262644577026366
- 1.5786219453811645
- 1.5391028904914856
- 1.5147236776351929
- 1.4836900901794434
- 1.4611133599281312
- 1.4453072452545166
- 1.4324992966651917
- 1.412808177471161
- 1.4080657696723937
- 1.3857863140106201
- 1.3773794960975647
- 1.3615551400184631
- 1.3536124038696289
- 1.3482461881637573
- 1.3360654711723328
- 1.3233126139640807
- 1.3150955581665038
- 1.3096903443336487
- 1.2987692499160766
- 1.2919418811798096
- 1.286288230419159
- 1.2840297412872315
- 1.2771023392677308
- 1.2649008059501647
- 1.262682387828827
- 1.2590132522583009
- 1.252975389957428
- 1.2522201585769652
- 1.2440686511993408
- 1.2414576864242555
- 1.2341554141044617
- 1.2340673875808716
- 1.2309010457992553
- 1.2282560324668885
- 1.223290364742279
- 1.220264503955841
- 1.217350504398346
- 1.2178338599205016
- 1.2088140749931335
- 1.2100977611541748
- 1.2120704245567322
- 1.2017509627342224
- 1.2001815128326416
- 1.1998435616493226
- 1.1963804149627686
- 1.1890034556388855
- 1.1942537689208985
- 1.1845466351509095
- 1.1905483460426332
- 1.1911641597747802
- 1.1782405400276184
- 1.1811935687065125
- 1.1847380495071411
- 1.1753707361221313
- 1.1815293407440186
- 1.1772091555595399
- 1.1776207304000854
- 1.1740364575386046
- 1.1649471807479859
- 1.1743750190734863
- 1.171314001083374
- 1.1776806974411012
- 1.1758659482002258
- 1.1651289892196655
- 1.1733283734321593
- 1.1644029068946837
- 1.1679281735420226
- 1.1636990213394165
- 1.163821885585785
- 1.174843065738678
- 1.1663427805900575
- 1.167951798439026
- 1.1650404500961304
- 1.1658023023605346
- 1.1679962921142577
- 1.1671039724349976
- 1.1690926146507263
- 1.1671838688850402
- 1.1670911121368408
- 1.1672612953186035
- 1.154701473712921
- 1.1627828407287597
- 1.167045247554779
- 1.1623832702636718
- 1.156436047554016
- 1.1630726528167725
- 1.1683719515800477
- 1.1536280250549316
- 1.163976969718933
- 1.164386100769043
- 1.1666014671325684
- 1.1635554337501526
- 1.1663131546974181
- 1.1659206581115722
- 1.1642521214485169
- 1.1702417159080505
- 1.161116783618927
train_accuracy:
- 0.088
- 0.074
- 0.105
- 0.133
- 0.004
- 0.14
- 0.113
- 0.039
- 0.157
- 0.179
- 0.038
- 0.001
- 0.197
- 0.224
- 0.186
- 0.223
- 0.237
- 0.018
- 0.212
- 0.003
- 0.239
- 0.217
- 0.004
- 0.208
- 0.011
- 0.289
- 0.061
- 0.004
- 0.223
- 0.052
- 0.282
- 0.021
- 0.226
- 0.265
- 0.238
- 0.231
- 0.288
- 0.291
- 0.112
- 0.227
- 0.262
- 0.304
- 0.275
- 0.268
- 0.004
- 0.303
- 0.236
- 0.286
- 0.316
- 0.004
- 0.114
- 0.006
- 0.058
- 0.282
- 0.316
- 0.098
- 0.097
- 0.21
- 0.288
- 0.271
- 0.016
- 0.264
- 0.058
- 0.01
- 0.355
- 0.288
- 0.289
- 0.294
- 0.289
- 0.293
- 0.341
- 0.315
- 0.003
- 0.267
- 0.271
- 0.322
- 0.216
- 0.096
- 0.326
- 0.009
- 0.366
- 0.305
- 0.29
- 0.383
- 0.309
- 0.029
- 0.322
- 0.109
- 0.316
- 0.357
- 0.293
- 0.307
- 0.212
- 0.015
- 0.293
- 0.294
- 0.144
- 0.292
- 0.036
- 0.192
train_loss:
- 2.681
- 2.444
- 3.279
- 3.106
- 2.145
- 2.457
- 2.4
- 1.933
- 1.897
- 2.22
- 2.182
- 2.472
- 1.713
- 2.017
- 1.965
- 1.619
- 2.214
- 1.838
- 1.84
- 1.747
- 1.742
- 1.689
- 1.387
- 1.607
- 1.584
- 1.574
- 1.537
- 1.235
- 1.471
- 1.191
- 1.14
- 1.397
- 1.371
- 1.32
- 1.304
- 1.066
- 1.251
- 1.21
- 1.002
- 1.193
- 1.153
- 0.935
- 1.315
- 1.277
- 0.868
- 0.883
- 0.836
- 0.834
- 0.992
- 0.978
- 0.94
- 1.074
- 0.912
- 0.945
- 0.714
- 0.853
- 0.862
- 0.692
- 0.839
- 0.803
- 0.633
- 0.774
- 0.62
- 0.629
- 0.85
- 0.85
- 0.609
- 0.699
- 0.665
- 0.565
- 0.642
- 0.64
- 0.703
- 0.504
- 0.507
- 0.484
- 0.458
- 0.45
- 0.459
- 0.626
- 0.539
- 0.448
- 0.438
- 0.517
- 0.418
- 0.389
- 0.49
- 0.481
- 0.469
- 0.433
- 0.454
- 0.437
- 0.363
- 0.413
- 0.358
- 0.354
- 0.423
- 0.32
- 0.333
- 0.372
unequal: 0
verbose: 1
