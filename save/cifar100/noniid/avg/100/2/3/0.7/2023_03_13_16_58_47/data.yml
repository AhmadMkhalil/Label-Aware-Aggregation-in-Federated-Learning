avg_train_accuracy: 0.283
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0365
- 0.0869
- 0.114
- 0.1217
- 0.1312
- 0.1453
- 0.1505
- 0.1568
- 0.1676
- 0.1712
- 0.1784
- 0.1827
- 0.1858
- 0.1929
- 0.1977
- 0.203
- 0.2068
- 0.2137
- 0.2169
- 0.2148
- 0.2181
- 0.2255
- 0.2221
- 0.2281
- 0.2279
- 0.2353
- 0.2375
- 0.2428
- 0.2396
- 0.2411
- 0.2425
- 0.2438
- 0.2491
- 0.2523
- 0.2471
- 0.2533
- 0.2556
- 0.2524
- 0.2621
- 0.2563
- 0.2615
- 0.2669
- 0.2673
- 0.2618
- 0.2715
- 0.2674
- 0.2716
- 0.2718
- 0.273
- 0.2719
- 0.2723
- 0.2744
- 0.2769
- 0.2793
- 0.2777
- 0.2756
- 0.2804
- 0.2781
- 0.2791
- 0.2828
- 0.2786
- 0.2826
- 0.283
- 0.2871
- 0.2831
- 0.2829
- 0.2862
- 0.2848
- 0.2855
- 0.2859
- 0.2873
- 0.2839
- 0.285
- 0.287
- 0.2897
- 0.2894
- 0.2891
- 0.2883
- 0.2849
- 0.29
- 0.2894
- 0.2886
- 0.2918
- 0.2932
- 0.2946
- 0.2912
- 0.2927
- 0.2908
- 0.2903
- 0.2917
- 0.2904
- 0.2923
- 0.2917
- 0.299
- 0.2941
- 0.2928
- 0.2961
- 0.2948
- 0.2957
- 0.2921
test_loss_list:
- 1.8042732381820679
- 1.6752128458023072
- 1.6172638702392579
- 1.5774518823623658
- 1.541137466430664
- 1.5170627689361573
- 1.4902029705047608
- 1.4660301733016967
- 1.4474610042572023
- 1.4351164245605468
- 1.4249366569519042
- 1.4152035665512086
- 1.403177134990692
- 1.395145149230957
- 1.3793338298797608
- 1.3689877080917359
- 1.3619788813591003
- 1.361028015613556
- 1.3468133950233458
- 1.3398663258552552
- 1.33545072555542
- 1.328541979789734
- 1.315411877632141
- 1.3125726175308228
- 1.3051659989356994
- 1.3026225805282592
- 1.2936171555519105
- 1.2900806879997253
- 1.2804266548156737
- 1.2757939982414246
- 1.2729193878173828
- 1.272324378490448
- 1.2711408019065857
- 1.2608460140228273
- 1.256919732093811
- 1.2509619426727294
- 1.2492546010017396
- 1.2473593544960022
- 1.2364826560020448
- 1.2387230849266053
- 1.2374733018875121
- 1.228380060195923
- 1.2288312411308289
- 1.2373078656196594
- 1.2340526509284973
- 1.2226146364212036
- 1.21573872089386
- 1.2150327682495117
- 1.2187301182746888
- 1.212894868850708
- 1.2153401923179628
- 1.211515166759491
- 1.2056461763381958
- 1.2166167497634888
- 1.2036292839050293
- 1.2043747425079345
- 1.2017048597335815
- 1.2012998628616334
- 1.2097306656837463
- 1.2079648303985595
- 1.208186888694763
- 1.1996255612373352
- 1.198317904472351
- 1.1899846267700196
- 1.196305902004242
- 1.2012568378448487
- 1.198262403011322
- 1.193565547466278
- 1.207794075012207
- 1.2009467577934265
- 1.1869501876831055
- 1.1924326133728027
- 1.1922064542770385
- 1.1924550771713256
- 1.19244619846344
- 1.2017024660110474
- 1.1911856317520142
- 1.1935479712486268
- 1.1985623693466188
- 1.198536286354065
- 1.1995797204971312
- 1.1947536373138428
- 1.1928684711456299
- 1.1981856369972228
- 1.1844633793830872
- 1.1959478616714478
- 1.1846362113952638
- 1.1935466241836548
- 1.195713257789612
- 1.1955366349220276
- 1.1929962062835693
- 1.1897896909713745
- 1.1964537072181702
- 1.1919878458976745
- 1.1908758807182311
- 1.1995419549942017
- 1.2010014319419862
- 1.1970760107040406
- 1.1982844972610474
- 1.1993089938163757
train_accuracy:
- 0.031
- 0.103
- 0.103
- 0.127
- 0.131
- 0.004
- 0.149
- 0.015
- 0.173
- 0.15
- 0.008
- 0.009
- 0.209
- 0.01
- 0.198
- 0.204
- 0.193
- 0.213
- 0.029
- 0.219
- 0.221
- 0.236
- 0.001
- 0.251
- 0.264
- 0.246
- 0.004
- 0.005
- 0.245
- 0.025
- 0.067
- 0.238
- 0.249
- 0.29
- 0.055
- 0.264
- 0.229
- 0.009
- 0.259
- 0.287
- 0.29
- 0.268
- 0.245
- 0.276
- 0.0
- 0.0
- 0.304
- 0.271
- 0.246
- 0.01
- 0.302
- 0.002
- 0.263
- 0.288
- 0.026
- 0.294
- 0.011
- 0.251
- 0.004
- 0.006
- 0.289
- 0.052
- 0.024
- 0.279
- 0.266
- 0.29
- 0.076
- 0.332
- 0.254
- 0.303
- 0.285
- 0.282
- 0.033
- 0.324
- 0.342
- 0.307
- 0.33
- 0.279
- 0.017
- 0.291
- 0.33
- 0.334
- 0.285
- 0.33
- 0.318
- 0.077
- 0.309
- 0.015
- 0.295
- 0.266
- 0.314
- 0.292
- 0.267
- 0.287
- 0.305
- 0.301
- 0.347
- 0.041
- 0.148
- 0.283
train_loss:
- 3.244
- 2.964
- 2.796
- 2.661
- 2.133
- 2.89
- 2.421
- 1.957
- 2.278
- 1.87
- 2.223
- 1.781
- 2.048
- 2.028
- 2.003
- 1.627
- 1.915
- 2.187
- 1.866
- 1.788
- 1.728
- 2.042
- 1.433
- 1.687
- 1.614
- 1.877
- 1.557
- 1.559
- 1.269
- 1.447
- 1.21
- 1.405
- 1.601
- 1.364
- 1.135
- 1.286
- 1.283
- 1.208
- 1.232
- 0.991
- 1.13
- 1.19
- 1.114
- 1.297
- 1.264
- 1.043
- 1.032
- 1.053
- 0.959
- 0.781
- 0.935
- 0.982
- 0.879
- 1.066
- 0.736
- 0.761
- 0.884
- 0.705
- 0.939
- 0.953
- 0.802
- 0.636
- 0.633
- 0.73
- 0.597
- 0.569
- 0.724
- 0.728
- 0.77
- 0.672
- 0.685
- 0.648
- 0.513
- 0.546
- 0.707
- 0.675
- 0.511
- 0.582
- 0.536
- 0.63
- 0.541
- 0.595
- 0.486
- 0.511
- 0.476
- 0.466
- 0.502
- 0.38
- 0.4
- 0.463
- 0.528
- 0.451
- 0.369
- 0.472
- 0.413
- 0.398
- 0.375
- 0.35
- 0.331
- 0.31
unequal: 0
verbose: 1
