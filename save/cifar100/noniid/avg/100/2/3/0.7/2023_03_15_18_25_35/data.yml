avg_train_accuracy: 0.091
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0416
- 0.0908
- 0.1074
- 0.1163
- 0.1312
- 0.1418
- 0.1556
- 0.1654
- 0.1705
- 0.1764
- 0.18
- 0.1868
- 0.1924
- 0.1923
- 0.1995
- 0.199
- 0.2055
- 0.2076
- 0.2116
- 0.2126
- 0.2215
- 0.2213
- 0.2294
- 0.2265
- 0.2285
- 0.2329
- 0.2366
- 0.2413
- 0.2434
- 0.2435
- 0.2476
- 0.2523
- 0.2522
- 0.2504
- 0.2566
- 0.2582
- 0.2547
- 0.2635
- 0.2656
- 0.2636
- 0.2659
- 0.2686
- 0.2708
- 0.2709
- 0.2696
- 0.2721
- 0.2728
- 0.2728
- 0.2751
- 0.2753
- 0.2736
- 0.2755
- 0.2828
- 0.2824
- 0.2851
- 0.2854
- 0.281
- 0.2821
- 0.2823
- 0.2872
- 0.2882
- 0.2904
- 0.2908
- 0.2919
- 0.285
- 0.2869
- 0.2894
- 0.2949
- 0.2913
- 0.2955
- 0.2932
- 0.2942
- 0.2945
- 0.2941
- 0.2905
- 0.2978
- 0.2961
- 0.2976
- 0.295
- 0.2968
- 0.2981
- 0.2957
- 0.2955
- 0.2994
- 0.3046
- 0.2995
- 0.2996
- 0.2991
- 0.2994
- 0.2995
- 0.3024
- 0.3013
- 0.3024
- 0.3004
- 0.2994
- 0.3019
- 0.3012
- 0.3023
- 0.3023
- 0.3043
test_loss_list:
- 1.7966831016540528
- 1.6649722671508789
- 1.607212142944336
- 1.5671010160446166
- 1.539265968799591
- 1.5117731404304504
- 1.4847423887252809
- 1.465551767349243
- 1.4444991064071655
- 1.4320031642913817
- 1.4185102987289429
- 1.4044321441650391
- 1.3983398532867433
- 1.3926262307167052
- 1.3747120213508606
- 1.3673118472099304
- 1.3593570852279664
- 1.3459971976280212
- 1.3357291436195373
- 1.330807502269745
- 1.3224254870414733
- 1.3200546932220458
- 1.3097774243354798
- 1.3050178790092468
- 1.2995001554489136
- 1.2901725220680236
- 1.2878262639045714
- 1.2864826726913452
- 1.2860387992858886
- 1.2783549952507018
- 1.2680590271949768
- 1.2624067568778992
- 1.2590695667266845
- 1.2587158942222596
- 1.2557774233818053
- 1.25907723903656
- 1.2510662865638733
- 1.2441847944259643
- 1.238666844367981
- 1.2377374410629272
- 1.2355583357810973
- 1.2251095056533814
- 1.222345790863037
- 1.2242476224899292
- 1.2251544761657716
- 1.2224871873855592
- 1.2237673091888428
- 1.231488106250763
- 1.231891791820526
- 1.2103187870979308
- 1.2158320379257201
- 1.215182638168335
- 1.2024025988578797
- 1.2078958201408385
- 1.1983453917503357
- 1.1989224529266358
- 1.201733739376068
- 1.2056289839744567
- 1.2006336903572083
- 1.1904673743247987
- 1.1920195722579956
- 1.187895712852478
- 1.1994648551940919
- 1.1992681550979614
- 1.2021938037872315
- 1.189009246826172
- 1.202472698688507
- 1.1964004755020141
- 1.198627655506134
- 1.1892430901527404
- 1.1972141695022582
- 1.1949488568305968
- 1.1862981033325195
- 1.1878394556045533
- 1.1882503342628479
- 1.1858434724807738
- 1.188851647377014
- 1.1905292296409606
- 1.194175398349762
- 1.1843792152404786
- 1.187019579410553
- 1.1889898443222047
- 1.18628915309906
- 1.1788442897796632
- 1.1818593430519104
- 1.1909390783309937
- 1.1974507474899292
- 1.1985948657989502
- 1.180473427772522
- 1.1812414598464966
- 1.1816149044036866
- 1.1880827641487122
- 1.1889870524406434
- 1.1879695105552672
- 1.1918810725212097
- 1.193546509742737
- 1.1902039074897766
- 1.1948625183105468
- 1.1901694965362548
- 1.1918197584152221
train_accuracy:
- 0.038
- 0.099
- 0.011
- 0.12
- 0.0
- 0.128
- 0.14
- 0.179
- 0.151
- 0.148
- 0.163
- 0.006
- 0.17
- 0.012
- 0.213
- 0.212
- 0.228
- 0.202
- 0.187
- 0.219
- 0.22
- 0.001
- 0.002
- 0.226
- 0.208
- 0.226
- 0.231
- 0.208
- 0.278
- 0.243
- 0.237
- 0.238
- 0.238
- 0.001
- 0.239
- 0.26
- 0.209
- 0.294
- 0.285
- 0.225
- 0.256
- 0.275
- 0.279
- 0.269
- 0.287
- 0.231
- 0.262
- 0.268
- 0.259
- 0.001
- 0.254
- 0.256
- 0.239
- 0.231
- 0.033
- 0.295
- 0.243
- 0.005
- 0.303
- 0.282
- 0.296
- 0.297
- 0.33
- 0.297
- 0.263
- 0.289
- 0.259
- 0.253
- 0.316
- 0.308
- 0.281
- 0.002
- 0.014
- 0.001
- 0.317
- 0.252
- 0.32
- 0.304
- 0.3
- 0.326
- 0.019
- 0.262
- 0.02
- 0.269
- 0.323
- 0.315
- 0.293
- 0.27
- 0.31
- 0.257
- 0.265
- 0.014
- 0.319
- 0.262
- 0.059
- 0.255
- 0.058
- 0.274
- 0.289
- 0.091
train_loss:
- 4.326
- 3.414
- 2.779
- 2.238
- 2.965
- 2.435
- 2.835
- 2.331
- 2.295
- 2.23
- 2.181
- 1.776
- 2.028
- 1.954
- 1.986
- 1.581
- 1.869
- 1.869
- 1.869
- 1.805
- 1.768
- 1.722
- 1.704
- 1.381
- 1.345
- 1.579
- 1.563
- 1.497
- 1.492
- 1.439
- 1.213
- 1.405
- 1.375
- 1.356
- 1.517
- 1.497
- 1.257
- 1.462
- 1.224
- 1.174
- 1.153
- 1.175
- 0.927
- 1.075
- 1.264
- 1.06
- 1.038
- 1.157
- 1.108
- 0.834
- 0.918
- 0.882
- 0.921
- 0.871
- 0.876
- 0.86
- 0.841
- 0.8
- 0.678
- 0.778
- 0.674
- 0.753
- 0.864
- 0.827
- 0.686
- 0.704
- 0.764
- 0.766
- 0.639
- 0.729
- 0.684
- 0.709
- 0.592
- 0.582
- 0.492
- 0.639
- 0.463
- 0.53
- 0.525
- 0.545
- 0.509
- 0.498
- 0.442
- 0.493
- 0.487
- 0.518
- 0.501
- 0.497
- 0.444
- 0.369
- 0.409
- 0.352
- 0.402
- 0.324
- 0.327
- 0.377
- 0.338
- 0.366
- 0.316
- 0.346
unequal: 0
verbose: 1
