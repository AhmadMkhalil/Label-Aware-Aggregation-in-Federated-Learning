avg_train_accuracy: 0.012
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0338
- 0.081
- 0.0945
- 0.1103
- 0.1304
- 0.1399
- 0.1541
- 0.1665
- 0.1751
- 0.1824
- 0.1824
- 0.1895
- 0.197
- 0.198
- 0.1985
- 0.2104
- 0.2123
- 0.2191
- 0.2199
- 0.2226
- 0.222
- 0.2247
- 0.2327
- 0.2338
- 0.2369
- 0.2428
- 0.2422
- 0.245
- 0.2475
- 0.248
- 0.2509
- 0.2516
- 0.2529
- 0.2556
- 0.2568
- 0.2573
- 0.2618
- 0.2629
- 0.2637
- 0.2642
- 0.2696
- 0.2678
- 0.2689
- 0.2705
- 0.2714
- 0.2737
- 0.275
- 0.2754
- 0.2755
- 0.2746
- 0.2779
- 0.2781
- 0.2805
- 0.2836
- 0.286
- 0.2829
- 0.2857
- 0.2871
- 0.285
- 0.2879
- 0.2869
- 0.2885
- 0.2903
- 0.2904
- 0.2891
- 0.2881
- 0.2914
- 0.2959
- 0.2943
- 0.2918
- 0.2935
- 0.2949
- 0.2987
- 0.2978
- 0.2992
- 0.2992
- 0.297
- 0.3007
- 0.3016
- 0.3032
- 0.2994
- 0.3007
- 0.2995
- 0.302
- 0.3007
- 0.3022
- 0.3012
- 0.2997
- 0.3025
- 0.3034
- 0.3044
- 0.304
- 0.3035
- 0.3048
- 0.3068
- 0.3086
- 0.3052
- 0.3056
- 0.3058
- 0.3056
test_loss_list:
- 1.8017071723937987
- 1.6806747817993164
- 1.6287779450416564
- 1.587224130630493
- 1.5453416752815246
- 1.5226435852050781
- 1.5034351539611817
- 1.476561894416809
- 1.4712248039245606
- 1.4524222016334534
- 1.4217192578315734
- 1.4129147505760193
- 1.3964874267578125
- 1.3917696237564088
- 1.374209876060486
- 1.3626536154747009
- 1.354985430240631
- 1.3539347815513612
- 1.350430691242218
- 1.3270165300369263
- 1.3180526041984557
- 1.3160758233070373
- 1.3062374258041383
- 1.3025717115402222
- 1.3109824442863465
- 1.3029927563667298
- 1.29973712682724
- 1.279058847427368
- 1.2695932435989379
- 1.2705090498924256
- 1.2718394112586975
- 1.2671337819099426
- 1.253326678276062
- 1.2511936497688294
- 1.2485149717330932
- 1.2426889443397522
- 1.2341720747947693
- 1.2337774515151978
- 1.2357984137535096
- 1.23482590675354
- 1.2201077270507812
- 1.2188213610649108
- 1.2163718223571778
- 1.2226555299758912
- 1.2216042828559877
- 1.2170826601982117
- 1.219907021522522
- 1.2188105535507203
- 1.2079778385162354
- 1.2070342135429382
- 1.203242883682251
- 1.199318413734436
- 1.198047490119934
- 1.1932788896560669
- 1.1933537220954895
- 1.1874290204048157
- 1.1918663668632508
- 1.1944326400756835
- 1.1991674661636353
- 1.1898979330062867
- 1.1854799056053162
- 1.1834037590026856
- 1.183498990535736
- 1.1875531792640686
- 1.1856680917739868
- 1.1862163639068604
- 1.1996346354484557
- 1.193657910823822
- 1.1941078782081604
- 1.1810764646530152
- 1.1809694027900697
- 1.1788617491722106
- 1.1693721628189087
- 1.1730184507369996
- 1.1754257845878602
- 1.1688491249084472
- 1.176370506286621
- 1.168267879486084
- 1.1792423462867736
- 1.1745531010627746
- 1.1803663897514343
- 1.1761806845664977
- 1.1757327842712402
- 1.1706013441085816
- 1.1789059495925904
- 1.1746563076972962
- 1.1783175444602967
- 1.1772534847259521
- 1.1732146096229554
- 1.1715487241744995
- 1.1730756855010986
- 1.1742370080947877
- 1.1701790833473205
- 1.179152865409851
- 1.1765011620521546
- 1.1705847716331481
- 1.1764706921577455
- 1.1701490950584412
- 1.176253912448883
- 1.1754542732238769
train_accuracy:
- 0.043
- 0.159
- 0.089
- 0.107
- 0.018
- 0.044
- 0.135
- 0.157
- 0.175
- 0.156
- 0.014
- 0.165
- 0.216
- 0.21
- 0.179
- 0.019
- 0.214
- 0.187
- 0.221
- 0.001
- 0.232
- 0.041
- 0.024
- 0.028
- 0.212
- 0.216
- 0.273
- 0.194
- 0.026
- 0.045
- 0.248
- 0.005
- 0.261
- 0.017
- 0.262
- 0.013
- 0.256
- 0.061
- 0.28
- 0.279
- 0.237
- 0.049
- 0.249
- 0.276
- 0.242
- 0.261
- 0.006
- 0.248
- 0.244
- 0.269
- 0.246
- 0.287
- 0.015
- 0.254
- 0.012
- 0.302
- 0.284
- 0.227
- 0.004
- 0.003
- 0.019
- 0.305
- 0.098
- 0.259
- 0.005
- 0.289
- 0.312
- 0.254
- 0.0
- 0.004
- 0.039
- 0.049
- 0.248
- 0.063
- 0.302
- 0.027
- 0.309
- 0.086
- 0.064
- 0.033
- 0.268
- 0.125
- 0.02
- 0.317
- 0.014
- 0.118
- 0.297
- 0.318
- 0.058
- 0.328
- 0.272
- 0.303
- 0.088
- 0.085
- 0.275
- 0.257
- 0.322
- 0.286
- 0.253
- 0.012
train_loss:
- 3.229
- 2.427
- 2.323
- 2.225
- 2.602
- 2.506
- 2.846
- 2.358
- 3.068
- 2.576
- 1.809
- 2.106
- 2.076
- 2.002
- 1.655
- 1.925
- 1.912
- 2.168
- 2.109
- 1.786
- 1.429
- 1.38
- 1.675
- 1.34
- 2.156
- 1.834
- 1.773
- 1.486
- 1.242
- 1.169
- 1.643
- 1.354
- 1.137
- 1.318
- 1.314
- 1.051
- 1.246
- 1.006
- 1.417
- 1.156
- 1.197
- 0.954
- 1.128
- 1.274
- 1.078
- 1.029
- 0.995
- 0.995
- 0.991
- 0.955
- 0.939
- 0.774
- 0.753
- 0.745
- 0.73
- 0.838
- 0.842
- 0.814
- 0.771
- 0.945
- 0.795
- 0.753
- 0.636
- 0.71
- 0.708
- 0.693
- 0.906
- 0.778
- 0.629
- 0.547
- 0.544
- 0.631
- 0.619
- 0.609
- 0.582
- 0.567
- 0.467
- 0.549
- 0.621
- 0.537
- 0.528
- 0.431
- 0.423
- 0.497
- 0.471
- 0.418
- 0.387
- 0.454
- 0.432
- 0.381
- 0.419
- 0.488
- 0.408
- 0.421
- 0.396
- 0.396
- 0.373
- 0.364
- 0.384
- 0.353
unequal: 0
verbose: 1
