avg_train_accuracy: 0.048
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0334
- 0.0804
- 0.1009
- 0.115
- 0.1379
- 0.1456
- 0.1576
- 0.1594
- 0.1713
- 0.1753
- 0.1799
- 0.1841
- 0.189
- 0.194
- 0.201
- 0.2057
- 0.2072
- 0.2094
- 0.2106
- 0.2168
- 0.2228
- 0.2287
- 0.2298
- 0.2324
- 0.2356
- 0.2352
- 0.2327
- 0.2382
- 0.2387
- 0.2467
- 0.2455
- 0.2467
- 0.2435
- 0.251
- 0.252
- 0.2528
- 0.2566
- 0.2603
- 0.2612
- 0.2594
- 0.264
- 0.2636
- 0.2641
- 0.264
- 0.2684
- 0.2689
- 0.2707
- 0.2697
- 0.2767
- 0.2753
- 0.2768
- 0.2731
- 0.2739
- 0.2759
- 0.2788
- 0.2789
- 0.2791
- 0.2814
- 0.2787
- 0.2825
- 0.2834
- 0.2794
- 0.2773
- 0.2826
- 0.2842
- 0.2874
- 0.2873
- 0.289
- 0.2878
- 0.2867
- 0.2874
- 0.2873
- 0.2894
- 0.2904
- 0.2893
- 0.2936
- 0.2914
- 0.2936
- 0.2912
- 0.2937
- 0.2951
- 0.2912
- 0.2912
- 0.294
- 0.2954
- 0.2917
- 0.2979
- 0.2996
- 0.2969
- 0.298
- 0.2987
- 0.299
- 0.3
- 0.2982
- 0.2999
- 0.3007
- 0.2977
- 0.2999
- 0.3025
- 0.3027
test_loss_list:
- 1.8087540769577026
- 1.6774850273132325
- 1.6186856818199158
- 1.5740325593948363
- 1.5491324687004089
- 1.5127558159828185
- 1.481532690525055
- 1.4631143593788147
- 1.4445576429367066
- 1.4354372024536133
- 1.4293747854232788
- 1.4030752182006836
- 1.3939694118499757
- 1.3861332607269288
- 1.3787500739097596
- 1.3634515309333801
- 1.3595809531211853
- 1.34982506275177
- 1.3457401895523071
- 1.3408208107948303
- 1.330652539730072
- 1.3212850928306579
- 1.3100542283058167
- 1.301665735244751
- 1.29618656873703
- 1.29210853099823
- 1.288705496788025
- 1.2824570083618163
- 1.2799474239349364
- 1.2678398132324218
- 1.2713237762451173
- 1.2625789546966553
- 1.2645928692817687
- 1.254064266681671
- 1.2474789595603943
- 1.2458388495445252
- 1.2399993181228637
- 1.2355222773551942
- 1.2395046687126159
- 1.2362480020523072
- 1.2279914236068725
- 1.239243004322052
- 1.2190877079963685
- 1.2282707285881043
- 1.2240127992630006
- 1.2215484023094176
- 1.2237706232070922
- 1.210018334388733
- 1.20257643699646
- 1.206763575077057
- 1.2056278133392333
- 1.2018975305557251
- 1.2013957929611205
- 1.2002333045005797
- 1.1992839503288268
- 1.2019665241241455
- 1.1958386278152466
- 1.1952410006523133
- 1.1922403764724732
- 1.1839013075828553
- 1.1882402777671814
- 1.1888743185997008
- 1.1968469834327697
- 1.184261784553528
- 1.1822473621368408
- 1.1750182652473449
- 1.1913920831680298
- 1.1847237730026245
- 1.1844615888595582
- 1.1829192566871642
- 1.179414746761322
- 1.184656126499176
- 1.1787040662765502
- 1.1832059526443481
- 1.1788036394119263
- 1.1790541124343872
- 1.1800576066970825
- 1.1797578811645508
- 1.1780866980552673
- 1.1828684711456299
- 1.1845465993881226
- 1.1807029700279237
- 1.1797267889976502
- 1.1840353584289551
- 1.1743165469169616
- 1.1804554653167725
- 1.17439781665802
- 1.1779482126235963
- 1.184765465259552
- 1.1905807876586914
- 1.1941265511512755
- 1.1881754803657532
- 1.1779846930503846
- 1.1809554696083069
- 1.1781340003013612
- 1.1907849359512328
- 1.1750651359558106
- 1.1802669382095337
- 1.179508159160614
- 1.1716819667816163
train_accuracy:
- 0.035
- 0.018
- 0.0
- 0.085
- 0.151
- 0.141
- 0.017
- 0.182
- 0.156
- 0.197
- 0.171
- 0.174
- 0.198
- 0.154
- 0.147
- 0.149
- 0.017
- 0.165
- 0.005
- 0.175
- 0.247
- 0.2
- 0.029
- 0.195
- 0.246
- 0.013
- 0.171
- 0.216
- 0.201
- 0.261
- 0.253
- 0.263
- 0.248
- 0.252
- 0.249
- 0.022
- 0.04
- 0.256
- 0.015
- 0.28
- 0.201
- 0.252
- 0.301
- 0.298
- 0.246
- 0.264
- 0.26
- 0.274
- 0.222
- 0.062
- 0.218
- 0.217
- 0.217
- 0.244
- 0.294
- 0.222
- 0.254
- 0.278
- 0.281
- 0.306
- 0.053
- 0.282
- 0.302
- 0.246
- 0.232
- 0.281
- 0.256
- 0.243
- 0.253
- 0.105
- 0.07
- 0.101
- 0.283
- 0.264
- 0.027
- 0.272
- 0.251
- 0.306
- 0.266
- 0.344
- 0.011
- 0.01
- 0.289
- 0.058
- 0.287
- 0.271
- 0.349
- 0.05
- 0.348
- 0.316
- 0.29
- 0.35
- 0.253
- 0.288
- 0.321
- 0.295
- 0.312
- 0.302
- 0.302
- 0.048
train_loss:
- 3.25
- 2.934
- 2.752
- 2.652
- 3.406
- 2.442
- 2.387
- 2.303
- 2.264
- 2.559
- 2.469
- 1.744
- 1.696
- 1.647
- 2.273
- 1.603
- 1.549
- 1.851
- 1.793
- 1.742
- 1.722
- 1.984
- 1.374
- 1.632
- 1.595
- 1.293
- 1.506
- 1.257
- 1.195
- 1.432
- 1.646
- 1.13
- 1.078
- 1.317
- 1.333
- 1.037
- 1.013
- 1.263
- 1.187
- 0.975
- 1.181
- 1.321
- 1.113
- 1.274
- 1.076
- 1.065
- 1.19
- 0.997
- 0.987
- 0.794
- 0.775
- 0.915
- 0.747
- 0.91
- 1.029
- 0.854
- 0.836
- 0.794
- 0.688
- 0.807
- 0.765
- 0.766
- 0.739
- 0.73
- 0.736
- 0.696
- 0.78
- 0.66
- 0.648
- 0.554
- 0.626
- 0.497
- 0.621
- 0.676
- 0.503
- 0.652
- 0.485
- 0.655
- 0.54
- 0.588
- 0.585
- 0.5
- 0.425
- 0.396
- 0.476
- 0.383
- 0.461
- 0.527
- 0.506
- 0.479
- 0.47
- 0.471
- 0.414
- 0.392
- 0.387
- 0.476
- 0.324
- 0.314
- 0.414
- 0.38
unequal: 0
verbose: 1
