avg_train_accuracy: 0.146
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0361
- 0.0823
- 0.0988
- 0.1127
- 0.1249
- 0.141
- 0.1481
- 0.1568
- 0.1622
- 0.1693
- 0.179
- 0.1846
- 0.185
- 0.1919
- 0.1967
- 0.2043
- 0.2097
- 0.2102
- 0.2162
- 0.2183
- 0.2179
- 0.225
- 0.2251
- 0.2283
- 0.2296
- 0.2349
- 0.2356
- 0.2434
- 0.2444
- 0.2471
- 0.2518
- 0.2532
- 0.2488
- 0.2523
- 0.2555
- 0.2574
- 0.2577
- 0.2633
- 0.261
- 0.268
- 0.264
- 0.2633
- 0.2654
- 0.2672
- 0.2681
- 0.2728
- 0.27
- 0.2732
- 0.276
- 0.2729
- 0.2752
- 0.28
- 0.2768
- 0.2816
- 0.2758
- 0.2786
- 0.2792
- 0.2832
- 0.2816
- 0.286
- 0.2856
- 0.2831
- 0.2836
- 0.2888
- 0.2878
- 0.2854
- 0.2851
- 0.2911
- 0.2925
- 0.292
- 0.292
- 0.2907
- 0.288
- 0.2933
- 0.2946
- 0.2937
- 0.2964
- 0.2958
- 0.2978
- 0.2919
- 0.2963
- 0.2971
- 0.2985
- 0.2982
- 0.3024
- 0.2995
- 0.3005
- 0.2991
- 0.2995
- 0.2994
- 0.3003
- 0.3034
- 0.3017
- 0.3006
- 0.3039
- 0.3036
- 0.3014
- 0.3042
- 0.3041
- 0.3029
test_loss_list:
- 1.7999210023880006
- 1.6766401076316833
- 1.6189750194549561
- 1.576649386882782
- 1.543896460533142
- 1.512672803401947
- 1.4902401185035705
- 1.4697745156288147
- 1.454216103553772
- 1.441417760848999
- 1.4210887813568116
- 1.406250422000885
- 1.3973005437850952
- 1.3827007126808166
- 1.3752951622009277
- 1.3618152284622191
- 1.3560638856887817
- 1.343655743598938
- 1.338927583694458
- 1.3324864268302918
- 1.3269933795928954
- 1.3153477501869202
- 1.3082744574546814
- 1.299550518989563
- 1.2988362956047057
- 1.2975331497192384
- 1.2936578178405762
- 1.2881231021881103
- 1.280294280052185
- 1.273771164417267
- 1.2756084609031677
- 1.2680833911895752
- 1.2584367179870606
- 1.2493479943275452
- 1.2434720015525818
- 1.241689236164093
- 1.2385570335388183
- 1.2299013185501098
- 1.2309968209266662
- 1.2237712407112122
- 1.2265192866325378
- 1.2267186498641969
- 1.2325006365776061
- 1.2276680850982666
- 1.2148690366744994
- 1.2078192448616027
- 1.2146339583396912
- 1.211527509689331
- 1.2083348941802978
- 1.2087665629386901
- 1.213296582698822
- 1.2002866888046264
- 1.211675832271576
- 1.1978217434883118
- 1.205589964389801
- 1.2112290382385253
- 1.1993636512756347
- 1.2017923641204833
- 1.2056844711303711
- 1.1937771892547608
- 1.195684130191803
- 1.1948349952697754
- 1.1966954016685485
- 1.195977599620819
- 1.1946457457542419
- 1.1840981698036195
- 1.1929731607437133
- 1.1811623668670654
- 1.1836217975616454
- 1.1878963613510132
- 1.1792646288871764
- 1.1820240449905395
- 1.184256012439728
- 1.179806067943573
- 1.1838052201271057
- 1.1816115593910217
- 1.1871775960922242
- 1.1820850610733031
- 1.1885963582992554
- 1.184185085296631
- 1.1873704171180726
- 1.178861002922058
- 1.1809814620018004
- 1.179685778617859
- 1.186590292453766
- 1.1791159009933472
- 1.177564067840576
- 1.1796422171592713
- 1.1817000532150268
- 1.1777331709861756
- 1.1780375623703003
- 1.180359320640564
- 1.1828468251228332
- 1.1876392197608947
- 1.1829462027549744
- 1.1909651041030884
- 1.1898190307617187
- 1.183160698413849
- 1.1798890042304992
- 1.183214738368988
train_accuracy:
- 0.053
- 0.1
- 0.008
- 0.001
- 0.154
- 0.022
- 0.19
- 0.167
- 0.015
- 0.214
- 0.179
- 0.171
- 0.189
- 0.066
- 0.01
- 0.061
- 0.001
- 0.195
- 0.269
- 0.051
- 0.237
- 0.214
- 0.027
- 0.02
- 0.221
- 0.282
- 0.303
- 0.056
- 0.043
- 0.069
- 0.303
- 0.0
- 0.273
- 0.028
- 0.016
- 0.065
- 0.052
- 0.271
- 0.273
- 0.263
- 0.296
- 0.283
- 0.313
- 0.298
- 0.271
- 0.313
- 0.293
- 0.073
- 0.272
- 0.078
- 0.298
- 0.284
- 0.35
- 0.007
- 0.306
- 0.296
- 0.023
- 0.277
- 0.342
- 0.172
- 0.308
- 0.076
- 0.142
- 0.301
- 0.06
- 0.156
- 0.347
- 0.31
- 0.321
- 0.121
- 0.303
- 0.302
- 0.308
- 0.316
- 0.293
- 0.302
- 0.329
- 0.327
- 0.354
- 0.096
- 0.315
- 0.154
- 0.311
- 0.36
- 0.33
- 0.318
- 0.3
- 0.314
- 0.309
- 0.314
- 0.326
- 0.145
- 0.309
- 0.343
- 0.316
- 0.337
- 0.328
- 0.213
- 0.314
- 0.146
train_loss:
- 3.752
- 2.441
- 2.783
- 2.643
- 2.124
- 2.486
- 2.401
- 1.955
- 1.886
- 2.599
- 2.172
- 1.773
- 1.728
- 2.056
- 1.98
- 1.954
- 2.257
- 1.548
- 1.499
- 1.468
- 1.455
- 1.729
- 1.736
- 1.651
- 1.595
- 1.827
- 1.545
- 1.786
- 1.517
- 1.453
- 1.662
- 1.624
- 1.362
- 1.337
- 1.088
- 1.073
- 1.043
- 1.251
- 1.238
- 1.2
- 0.995
- 1.147
- 1.31
- 1.114
- 0.884
- 1.087
- 1.015
- 0.874
- 0.842
- 0.83
- 1.125
- 0.962
- 1.067
- 0.902
- 0.883
- 1.006
- 0.707
- 0.936
- 0.776
- 0.692
- 0.787
- 0.67
- 0.613
- 0.832
- 0.728
- 0.596
- 0.7
- 0.696
- 0.668
- 0.624
- 0.672
- 0.608
- 0.52
- 0.589
- 0.69
- 0.574
- 0.651
- 0.56
- 0.636
- 0.457
- 0.598
- 0.438
- 0.566
- 0.522
- 0.555
- 0.466
- 0.475
- 0.443
- 0.427
- 0.497
- 0.385
- 0.407
- 0.342
- 0.339
- 0.458
- 0.441
- 0.376
- 0.339
- 0.383
- 0.367
unequal: 0
verbose: 1
