avg_train_accuracy: 0.013
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0302
- 0.0807
- 0.0971
- 0.1112
- 0.1276
- 0.1376
- 0.1479
- 0.1587
- 0.1675
- 0.1718
- 0.1814
- 0.1838
- 0.191
- 0.1945
- 0.2029
- 0.203
- 0.2067
- 0.209
- 0.2181
- 0.2191
- 0.2202
- 0.2264
- 0.2305
- 0.2328
- 0.2393
- 0.2354
- 0.2413
- 0.2479
- 0.2438
- 0.2458
- 0.2481
- 0.252
- 0.2524
- 0.2527
- 0.2558
- 0.2597
- 0.262
- 0.2607
- 0.2613
- 0.2648
- 0.2642
- 0.2664
- 0.2638
- 0.269
- 0.2683
- 0.2706
- 0.2732
- 0.2699
- 0.2772
- 0.2764
- 0.2807
- 0.2754
- 0.2812
- 0.2794
- 0.2798
- 0.2803
- 0.2814
- 0.2796
- 0.286
- 0.284
- 0.2875
- 0.2865
- 0.287
- 0.2857
- 0.2864
- 0.2874
- 0.2892
- 0.2877
- 0.2882
- 0.2928
- 0.2898
- 0.2914
- 0.2901
- 0.2935
- 0.2932
- 0.2946
- 0.294
- 0.2972
- 0.2952
- 0.2966
- 0.298
- 0.2999
- 0.2986
- 0.2991
- 0.2991
- 0.2985
- 0.3008
- 0.2998
- 0.3003
- 0.3007
- 0.3006
- 0.3014
- 0.3012
- 0.3005
- 0.3046
- 0.2978
- 0.3059
- 0.3051
- 0.3056
- 0.3043
test_loss_list:
- 1.8179728412628173
- 1.6734772205352784
- 1.622247154712677
- 1.584667263031006
- 1.5525127577781677
- 1.5188267970085143
- 1.4975301623344421
- 1.4682441806793214
- 1.4468677067756652
- 1.4372225522994995
- 1.417994396686554
- 1.4078520846366882
- 1.3917349863052368
- 1.390773057937622
- 1.37157066822052
- 1.3687490105628968
- 1.3557101607322692
- 1.3442436265945434
- 1.336374785900116
- 1.3226821780204774
- 1.3130795121192933
- 1.308004038333893
- 1.3096814489364623
- 1.3009496021270752
- 1.2970916223526001
- 1.2914344406127929
- 1.2745779848098755
- 1.2765235638618468
- 1.2685026669502257
- 1.265350306034088
- 1.265196807384491
- 1.2531115818023681
- 1.246616702079773
- 1.2453494000434875
- 1.240364921092987
- 1.2468288326263428
- 1.2364360666275025
- 1.2398800158500671
- 1.23726345539093
- 1.2328283643722535
- 1.2352150344848634
- 1.2184010982513427
- 1.2143861269950866
- 1.2140864109992981
- 1.2152422046661377
- 1.212431709766388
- 1.2191983723640443
- 1.2021372127532959
- 1.210114722251892
- 1.1992886686325073
- 1.2037543630599976
- 1.2015106439590455
- 1.1958096051216125
- 1.1937657546997071
- 1.192797908782959
- 1.1870310354232787
- 1.1909756255149841
- 1.1935377383232117
- 1.1889091563224792
- 1.1881101679801942
- 1.1943250942230224
- 1.1817402601242066
- 1.1773511719703675
- 1.184395592212677
- 1.181338632106781
- 1.1810489296913147
- 1.177095160484314
- 1.1801355957984925
- 1.1834292459487914
- 1.175109395980835
- 1.1766106414794921
- 1.1789016437530517
- 1.1745269083976746
- 1.1809251022338867
- 1.1689395236968994
- 1.1827973675727845
- 1.1834841465950012
- 1.169911983013153
- 1.1787663578987122
- 1.1815695905685424
- 1.1677153062820436
- 1.1717445635795594
- 1.176949667930603
- 1.172637701034546
- 1.1734593749046325
- 1.1649765872955322
- 1.1722813510894776
- 1.176609387397766
- 1.1746582078933716
- 1.1754588317871093
- 1.1711792063713073
- 1.1777040886878967
- 1.1754174518585205
- 1.1723856663703918
- 1.1716995024681092
- 1.1737256836891174
- 1.173538076877594
- 1.1733459973335265
- 1.1697697734832764
- 1.1769277262687683
train_accuracy:
- 0.035
- 0.093
- 0.07
- 0.082
- 0.123
- 0.138
- 0.012
- 0.168
- 0.152
- 0.161
- 0.177
- 0.009
- 0.176
- 0.204
- 0.19
- 0.212
- 0.228
- 0.0
- 0.002
- 0.02
- 0.238
- 0.208
- 0.225
- 0.003
- 0.226
- 0.252
- 0.235
- 0.009
- 0.005
- 0.004
- 0.244
- 0.002
- 0.255
- 0.234
- 0.262
- 0.248
- 0.259
- 0.278
- 0.289
- 0.261
- 0.245
- 0.0
- 0.01
- 0.271
- 0.298
- 0.259
- 0.007
- 0.293
- 0.267
- 0.017
- 0.271
- 0.291
- 0.28
- 0.268
- 0.271
- 0.293
- 0.058
- 0.065
- 0.101
- 0.279
- 0.278
- 0.01
- 0.015
- 0.277
- 0.295
- 0.298
- 0.286
- 0.266
- 0.027
- 0.031
- 0.279
- 0.257
- 0.289
- 0.044
- 0.301
- 0.291
- 0.29
- 0.286
- 0.036
- 0.268
- 0.302
- 0.309
- 0.002
- 0.285
- 0.322
- 0.326
- 0.315
- 0.29
- 0.311
- 0.159
- 0.288
- 0.276
- 0.122
- 0.034
- 0.281
- 0.318
- 0.03
- 0.264
- 0.324
- 0.013
train_loss:
- 3.23
- 2.945
- 2.298
- 2.205
- 2.117
- 2.49
- 2.406
- 2.369
- 1.897
- 1.843
- 2.215
- 2.126
- 2.071
- 2.371
- 1.997
- 2.276
- 1.875
- 1.893
- 2.119
- 1.774
- 1.417
- 1.681
- 1.944
- 1.637
- 1.893
- 1.546
- 1.533
- 1.754
- 1.439
- 1.438
- 1.403
- 1.384
- 1.096
- 1.074
- 1.271
- 1.477
- 1.288
- 1.423
- 1.193
- 1.148
- 1.136
- 1.133
- 0.954
- 0.902
- 1.051
- 1.032
- 1.186
- 0.818
- 1.145
- 0.808
- 1.107
- 0.767
- 0.912
- 0.727
- 0.724
- 0.849
- 0.685
- 0.701
- 0.791
- 0.788
- 0.903
- 0.644
- 0.742
- 0.583
- 0.739
- 0.605
- 0.57
- 0.661
- 0.553
- 0.645
- 0.652
- 0.499
- 0.597
- 0.626
- 0.599
- 0.676
- 0.661
- 0.476
- 0.518
- 0.544
- 0.565
- 0.514
- 0.573
- 0.501
- 0.501
- 0.494
- 0.452
- 0.444
- 0.39
- 0.377
- 0.416
- 0.465
- 0.438
- 0.334
- 0.394
- 0.354
- 0.479
- 0.401
- 0.367
- 0.362
unequal: 0
verbose: 1
