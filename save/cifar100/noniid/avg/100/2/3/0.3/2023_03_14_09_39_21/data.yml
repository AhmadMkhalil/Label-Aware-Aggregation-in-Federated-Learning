avg_train_accuracy: 0.287
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0129
- 0.0345
- 0.0582
- 0.0564
- 0.029
- 0.1335
- 0.1011
- 0.147
- 0.1175
- 0.1439
- 0.1739
- 0.1835
- 0.1727
- 0.1665
- 0.1679
- 0.188
- 0.0744
- 0.1621
- 0.1151
- 0.2153
- 0.2161
- 0.2265
- 0.2302
- 0.2333
- 0.2003
- 0.2357
- 0.1707
- 0.2078
- 0.2095
- 0.2115
- 0.169
- 0.2076
- 0.2532
- 0.2272
- 0.23
- 0.2305
- 0.2417
- 0.2311
- 0.247
- 0.2644
- 0.2391
- 0.2456
- 0.2002
- 0.2674
- 0.2517
- 0.2201
- 0.2801
- 0.2743
- 0.2805
- 0.2558
- 0.267
- 0.2617
- 0.2625
- 0.2553
- 0.2741
- 0.2752
- 0.2929
- 0.2379
- 0.2653
- 0.2945
- 0.2695
- 0.2669
- 0.2281
- 0.2944
- 0.2696
- 0.2758
- 0.2657
- 0.2785
- 0.2273
- 0.2046
- 0.2858
- 0.3005
- 0.2526
- 0.2722
- 0.2819
- 0.2652
- 0.2798
- 0.279
- 0.2844
- 0.301
- 0.2725
- 0.2819
- 0.3083
- 0.2864
- 0.3005
- 0.2877
- 0.2788
- 0.2785
- 0.3074
- 0.2822
- 0.2849
- 0.2943
- 0.2735
- 0.3091
- 0.2736
- 0.3115
- 0.2899
- 0.2908
- 0.3062
- 0.2915
test_loss_list:
- 1.8404872274398805
- 1.7304829883575439
- 1.6781427812576295
- 1.6430245661735534
- 1.8764467239379883
- 1.554112753868103
- 1.561503517627716
- 1.5174253726005553
- 1.5374345636367799
- 1.4827510523796081
- 1.4686310029029845
- 1.4492655634880065
- 1.4465345931053162
- 1.4350961279869079
- 1.431614818572998
- 1.3951086902618408
- 1.686502184867859
- 1.4185024833679198
- 1.5242428517341613
- 1.3578961658477784
- 1.3634277486801147
- 1.359076063632965
- 1.3543644165992736
- 1.3592508268356323
- 1.3632531785964965
- 1.3181392431259156
- 1.4012751913070678
- 1.318098123073578
- 1.3198059272766114
- 1.3194145250320435
- 1.3878736424446105
- 1.3142912220954894
- 1.275558512210846
- 1.3175316166877746
- 1.3054094457626342
- 1.315626745223999
- 1.2804698324203492
- 1.3034055614471436
- 1.269713225364685
- 1.2499729156494142
- 1.2798197317123412
- 1.2710706329345702
- 1.3262367153167725
- 1.2236309242248535
- 1.2511361384391784
- 1.3003056168556213
- 1.217077805995941
- 1.2332424330711365
- 1.233316888809204
- 1.266487865447998
- 1.2258233475685119
- 1.23234858751297
- 1.243197751045227
- 1.236271984577179
- 1.2183566880226135
- 1.2267499589920043
- 1.2080713295936585
- 1.2888181734085082
- 1.2288598942756652
- 1.196851623058319
- 1.2325560140609741
- 1.2381959676742553
- 1.3086867785453797
- 1.2026629996299745
- 1.245968737602234
- 1.2088352394104005
- 1.2241878867149354
- 1.2182938027381898
- 1.2926987528800964
- 1.3558777260780335
- 1.1947785854339599
- 1.188337254524231
- 1.261463303565979
- 1.2264831280708313
- 1.201645336151123
- 1.2320189785957336
- 1.2095186638832092
- 1.2130850100517272
- 1.2124884271621703
- 1.1908920216560364
- 1.2449730348587036
- 1.2145832395553589
- 1.1868879723548889
- 1.2120896339416505
- 1.188368215560913
- 1.2184320521354675
- 1.2183399677276612
- 1.237628333568573
- 1.1837606191635133
- 1.2443278622627258
- 1.2296604990959168
- 1.1855426216125489
- 1.2343191242218017
- 1.1864768552780152
- 1.2399671506881713
- 1.1744479823112488
- 1.2155304503440858
- 1.2191715550422668
- 1.1815142130851746
- 1.2128060531616212
train_accuracy:
- 0.0
- 0.025
- 0.017
- 0.858
- 0.017
- 0.106
- 0.073
- 0.104
- 0.079
- 0.143
- 0.182
- 0.15
- 0.124
- 0.166
- 0.121
- 0.176
- 0.709
- 0.144
- 0.491
- 0.226
- 0.221
- 0.23
- 0.198
- 0.233
- 0.131
- 0.235
- 0.69
- 0.137
- 0.502
- 0.151
- 0.145
- 0.222
- 0.214
- 0.2
- 0.175
- 0.161
- 0.191
- 0.491
- 0.183
- 0.229
- 0.196
- 0.377
- 0.599
- 0.28
- 0.521
- 0.2
- 0.259
- 0.278
- 0.313
- 0.165
- 0.269
- 0.235
- 0.625
- 0.259
- 0.276
- 0.269
- 0.26
- 0.545
- 0.21
- 0.304
- 0.479
- 0.26
- 0.169
- 0.275
- 0.25
- 0.294
- 0.657
- 0.273
- 0.154
- 0.606
- 0.28
- 0.316
- 0.231
- 0.377
- 0.522
- 0.291
- 0.28
- 0.498
- 0.265
- 0.327
- 0.253
- 0.285
- 0.285
- 0.291
- 0.265
- 0.298
- 0.29
- 0.243
- 0.278
- 0.243
- 0.4
- 0.304
- 0.297
- 0.314
- 0.204
- 0.268
- 0.279
- 0.272
- 0.247
- 0.287
train_loss:
- 3.043
- 2.856
- 2.604
- 2.619
- 0.394
- 3.5
- 2.36
- 3.154
- 2.198
- 2.141
- 2.832
- 2.938
- 1.961
- 1.913
- 1.956
- 1.857
- 0.28
- 1.672
- 0.948
- 2.671
- 2.378
- 2.314
- 2.374
- 2.136
- 1.073
- 2.159
- 0.888
- 1.639
- 1.432
- 1.41
- 0.86
- 1.273
- 1.992
- 1.236
- 1.275
- 1.321
- 1.216
- 1.187
- 1.263
- 1.577
- 1.064
- 1.17
- 0.717
- 1.687
- 1.05
- 0.725
- 1.497
- 1.503
- 1.44
- 0.921
- 0.977
- 0.873
- 0.852
- 0.901
- 0.981
- 0.851
- 1.177
- 0.546
- 0.823
- 1.236
- 0.795
- 0.721
- 0.438
- 0.947
- 0.726
- 0.836
- 0.724
- 0.66
- 0.453
- 0.4
- 0.715
- 0.942
- 0.408
- 0.63
- 0.648
- 0.595
- 0.616
- 0.555
- 0.513
- 0.696
- 0.44
- 0.649
- 0.84
- 0.483
- 0.729
- 0.513
- 0.53
- 0.488
- 0.689
- 0.441
- 0.437
- 0.473
- 0.388
- 0.561
- 0.358
- 0.574
- 0.352
- 0.334
- 0.641
- 0.39
unequal: 0
verbose: 1
