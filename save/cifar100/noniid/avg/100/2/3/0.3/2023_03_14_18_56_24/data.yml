avg_train_accuracy: 0.496
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0145
- 0.0444
- 0.0301
- 0.0668
- 0.0661
- 0.1411
- 0.1486
- 0.1356
- 0.0812
- 0.1663
- 0.1151
- 0.1439
- 0.1398
- 0.1916
- 0.1944
- 0.1993
- 0.1887
- 0.1622
- 0.1751
- 0.171
- 0.2178
- 0.1864
- 0.1922
- 0.218
- 0.1565
- 0.2046
- 0.1906
- 0.2042
- 0.2123
- 0.2147
- 0.2161
- 0.1537
- 0.2268
- 0.2226
- 0.2202
- 0.2254
- 0.2185
- 0.2538
- 0.2559
- 0.1987
- 0.2397
- 0.2307
- 0.2611
- 0.2599
- 0.2129
- 0.2431
- 0.2237
- 0.2639
- 0.254
- 0.269
- 0.242
- 0.2659
- 0.2583
- 0.2525
- 0.2522
- 0.273
- 0.2744
- 0.2502
- 0.2616
- 0.2628
- 0.2771
- 0.2813
- 0.2356
- 0.2809
- 0.2575
- 0.2649
- 0.2267
- 0.2865
- 0.2897
- 0.2396
- 0.2886
- 0.2891
- 0.2912
- 0.2712
- 0.2687
- 0.2759
- 0.2233
- 0.265
- 0.2662
- 0.2963
- 0.2429
- 0.2939
- 0.269
- 0.2303
- 0.2966
- 0.2752
- 0.2724
- 0.274
- 0.2761
- 0.2258
- 0.2177
- 0.2715
- 0.2702
- 0.2711
- 0.2651
- 0.2776
- 0.2712
- 0.2767
- 0.3016
- 0.2409
test_loss_list:
- 1.8361431503295897
- 1.7407837867736817
- 1.7922108745574952
- 1.6490077209472656
- 1.6223405838012694
- 1.5506225728988647
- 1.5327517795562744
- 1.5279739451408387
- 1.6071156978607177
- 1.4781186962127686
- 1.5368530893325805
- 1.4741065096855164
- 1.4780084156990052
- 1.4319147610664367
- 1.4341029191017152
- 1.4297843861579895
- 1.418674921989441
- 1.4370083737373351
- 1.4096638536453248
- 1.4088712978363036
- 1.3692221593856813
- 1.3973277759552003
- 1.3920882749557495
- 1.362392497062683
- 1.4599597835540772
- 1.3604655051231385
- 1.3685706615448
- 1.3586845469474793
- 1.3425128412246705
- 1.3373524379730224
- 1.33594318151474
- 1.4630904579162598
- 1.317706413269043
- 1.3347791123390198
- 1.3197505855560303
- 1.323360471725464
- 1.3223204970359803
- 1.2897720980644225
- 1.2919229245185853
- 1.3870945930480958
- 1.3011789727210998
- 1.3157288527488709
- 1.2768782091140747
- 1.2896075630187989
- 1.3526105046272279
- 1.3085165953636169
- 1.3138111996650697
- 1.2661991763114928
- 1.2809327006340028
- 1.2618284821510315
- 1.309306206703186
- 1.2724122214317322
- 1.2853952312469483
- 1.2939291453361512
- 1.2648287200927735
- 1.2572062635421752
- 1.256464385986328
- 1.3010819387435912
- 1.274090392589569
- 1.2824560689926148
- 1.2492399525642395
- 1.2514912819862365
- 1.3068566417694092
- 1.233054413795471
- 1.2809672260284424
- 1.2708421540260315
- 1.3576119613647462
- 1.2255166602134704
- 1.2369935774803162
- 1.334941394329071
- 1.2198741030693054
- 1.229962673187256
- 1.237897744178772
- 1.27160391330719
- 1.2474371933937072
- 1.2449432659149169
- 1.3706882333755492
- 1.2564917278289796
- 1.2530546498298645
- 1.214607400894165
- 1.3348207211494445
- 1.2125166034698487
- 1.2575620913505554
- 1.369118230342865
- 1.2097077345848084
- 1.2742528295516968
- 1.2525400924682617
- 1.2615164518356323
- 1.2401857495307922
- 1.365009627342224
- 1.3787265586853028
- 1.2379792213439942
- 1.2445935988426209
- 1.250647099018097
- 1.2604412317276001
- 1.2477370643615722
- 1.2630785965919495
- 1.2482262873649597
- 1.2172037148475647
- 1.3518737316131593
train_accuracy:
- 0.0
- 0.02
- 0.023
- 0.382
- 0.797
- 0.135
- 0.133
- 0.094
- 0.781
- 0.157
- 0.661
- 0.108
- 0.118
- 0.141
- 0.203
- 0.19
- 0.146
- 0.139
- 0.699
- 0.148
- 0.213
- 0.547
- 0.651
- 0.167
- 0.613
- 0.161
- 0.157
- 0.559
- 0.188
- 0.163
- 0.214
- 0.628
- 0.208
- 0.35
- 0.203
- 0.506
- 0.21
- 0.202
- 0.238
- 0.506
- 0.562
- 0.223
- 0.259
- 0.242
- 0.161
- 0.214
- 0.206
- 0.253
- 0.392
- 0.254
- 0.225
- 0.237
- 0.441
- 0.53
- 0.476
- 0.23
- 0.242
- 0.21
- 0.518
- 0.195
- 0.241
- 0.259
- 0.345
- 0.253
- 0.217
- 0.235
- 0.648
- 0.253
- 0.265
- 0.643
- 0.257
- 0.251
- 0.255
- 0.247
- 0.234
- 0.466
- 0.565
- 0.602
- 0.578
- 0.28
- 0.444
- 0.251
- 0.569
- 0.684
- 0.254
- 0.25
- 0.461
- 0.466
- 0.26
- 0.444
- 0.631
- 0.249
- 0.243
- 0.594
- 0.241
- 0.242
- 0.542
- 0.251
- 0.291
- 0.496
train_loss:
- 3.071
- 2.741
- 1.487
- 2.602
- 2.569
- 3.456
- 3.248
- 2.28
- 1.289
- 3.053
- 1.253
- 2.046
- 1.915
- 2.886
- 2.665
- 2.499
- 1.941
- 1.077
- 1.793
- 1.721
- 2.316
- 1.651
- 1.515
- 2.279
- 0.957
- 1.575
- 1.529
- 1.406
- 1.58
- 1.468
- 1.49
- 0.897
- 1.377
- 1.34
- 1.415
- 1.34
- 1.229
- 1.743
- 1.706
- 0.77
- 1.127
- 1.024
- 1.73
- 1.529
- 0.727
- 0.986
- 1.112
- 1.507
- 1.094
- 1.349
- 0.986
- 1.235
- 0.963
- 0.998
- 0.915
- 1.131
- 1.308
- 0.826
- 0.874
- 0.811
- 1.062
- 1.01
- 0.649
- 1.1
- 0.718
- 0.715
- 0.474
- 1.022
- 0.875
- 0.454
- 0.973
- 0.917
- 0.841
- 0.609
- 0.676
- 0.568
- 0.35
- 0.572
- 0.619
- 0.778
- 0.356
- 0.674
- 0.481
- 0.29
- 0.792
- 0.491
- 0.47
- 0.407
- 0.614
- 0.292
- 0.298
- 0.432
- 0.459
- 0.451
- 0.394
- 0.462
- 0.414
- 0.437
- 0.573
- 0.296
unequal: 0
verbose: 1
