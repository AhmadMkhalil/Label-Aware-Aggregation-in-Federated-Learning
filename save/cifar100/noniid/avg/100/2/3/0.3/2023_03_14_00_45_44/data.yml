avg_train_accuracy: 0.309
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0217
- 0.0379
- 0.0435
- 0.072
- 0.0459
- 0.0953
- 0.0984
- 0.1478
- 0.1017
- 0.0674
- 0.0565
- 0.1658
- 0.1812
- 0.1844
- 0.1508
- 0.1072
- 0.1687
- 0.102
- 0.0634
- 0.1985
- 0.1732
- 0.2153
- 0.1936
- 0.1872
- 0.2243
- 0.1751
- 0.1949
- 0.2022
- 0.1977
- 0.2322
- 0.1848
- 0.2104
- 0.1785
- 0.2157
- 0.1648
- 0.2458
- 0.2532
- 0.2279
- 0.2371
- 0.1895
- 0.2257
- 0.258
- 0.2033
- 0.2242
- 0.2639
- 0.263
- 0.2742
- 0.2262
- 0.252
- 0.2401
- 0.2388
- 0.2395
- 0.2589
- 0.2015
- 0.1994
- 0.2778
- 0.25
- 0.2178
- 0.2559
- 0.2851
- 0.2546
- 0.2701
- 0.2855
- 0.1981
- 0.2859
- 0.2547
- 0.2915
- 0.2752
- 0.2903
- 0.2681
- 0.1811
- 0.1952
- 0.2959
- 0.2696
- 0.2666
- 0.294
- 0.2995
- 0.2768
- 0.2967
- 0.2998
- 0.3
- 0.2884
- 0.2794
- 0.2983
- 0.2853
- 0.286
- 0.3038
- 0.3019
- 0.3032
- 0.3022
- 0.2864
- 0.2878
- 0.2849
- 0.3042
- 0.2805
- 0.2853
- 0.2837
- 0.3072
- 0.3119
test_loss_list:
- 1.79581711769104
- 1.8619750785827636
- 1.7059212064743041
- 1.6745571041107177
- 1.633145167827606
- 1.7243528509140014
- 1.5863779044151307
- 1.5627665781974793
- 1.5199821281433106
- 1.5708973455429076
- 1.6230183243751526
- 1.6738961505889893
- 1.4681336760520936
- 1.4474514412879944
- 1.4422207641601563
- 1.462305748462677
- 1.5219831037521363
- 1.4131651854515075
- 1.550445864200592
- 1.7723751258850098
- 1.390041296482086
- 1.4172319746017457
- 1.3677194571495057
- 1.3829590272903443
- 1.3903188991546631
- 1.3434445691108703
- 1.4046953177452088
- 1.3543050384521484
- 1.3415815544128418
- 1.3629254651069642
- 1.3167837429046632
- 1.3856361079216004
- 1.3473696732521057
- 1.4048854970932008
- 1.3311592721939087
- 1.4401115036010743
- 1.295772590637207
- 1.2948069524765016
- 1.3262199020385743
- 1.2921475601196288
- 1.362078251838684
- 1.2817941641807555
- 1.2734630799293518
- 1.3569746899604798
- 1.2937126398086547
- 1.2572115516662599
- 1.2663475251197815
- 1.255028703212738
- 1.3081324005126953
- 1.2551648712158203
- 1.2844785165786743
- 1.2855169200897216
- 1.2710511374473572
- 1.2397078275680542
- 1.3478198266029358
- 1.3476401495933532
- 1.2230370926856995
- 1.2704034376144409
- 1.325393669605255
- 1.2485928535461426
- 1.2151549315452577
- 1.2554764819145203
- 1.2237812972068787
- 1.2113601088523864
- 1.3760906863212585
- 1.2040014529228211
- 1.2601982045173645
- 1.2117380094528198
- 1.2313530874252319
- 1.2143676090240478
- 1.2428333210945128
- 1.4240478849411011
- 1.378371160030365
- 1.1925356769561768
- 1.2334526371955872
- 1.2362236332893373
- 1.193935124874115
- 1.2042040014266968
- 1.2320746779441833
- 1.1955080103874207
- 1.207473750114441
- 1.2112921452522278
- 1.2107875442504883
- 1.2397148203849793
- 1.2034488940238952
- 1.217350971698761
- 1.2108143782615661
- 1.1902599382400512
- 1.1942096424102784
- 1.2102525734901428
- 1.2167939519882203
- 1.2328662729263307
- 1.2268551993370056
- 1.2457282900810243
- 1.1947158288955688
- 1.241738736629486
- 1.2394499611854553
- 1.2355199003219604
- 1.200993983745575
- 1.2005809950828552
train_accuracy:
- 0.05
- 0.255
- 0.016
- 0.022
- 0.055
- 0.246
- 0.06
- 0.609
- 0.152
- 0.056
- 0.174
- 0.025
- 0.17
- 0.18
- 0.149
- 0.385
- 0.074
- 0.506
- 0.626
- 0.572
- 0.2
- 0.541
- 0.221
- 0.176
- 0.152
- 0.2
- 0.385
- 0.204
- 0.188
- 0.191
- 0.248
- 0.533
- 0.185
- 0.231
- 0.189
- 0.431
- 0.233
- 0.231
- 0.26
- 0.228
- 0.407
- 0.222
- 0.242
- 0.396
- 0.334
- 0.235
- 0.244
- 0.281
- 0.217
- 0.388
- 0.495
- 0.253
- 0.522
- 0.223
- 0.692
- 0.6
- 0.243
- 0.239
- 0.442
- 0.525
- 0.262
- 0.312
- 0.469
- 0.305
- 0.528
- 0.311
- 0.225
- 0.261
- 0.234
- 0.326
- 0.272
- 0.383
- 0.15
- 0.333
- 0.633
- 0.362
- 0.322
- 0.305
- 0.241
- 0.285
- 0.298
- 0.279
- 0.392
- 0.254
- 0.327
- 0.252
- 0.244
- 0.319
- 0.296
- 0.303
- 0.298
- 0.324
- 0.271
- 0.424
- 0.327
- 0.516
- 0.462
- 0.27
- 0.284
- 0.309
train_loss:
- 4.321
- 0.661
- 2.708
- 2.623
- 2.663
- 1.465
- 2.52
- 2.335
- 3.226
- 1.386
- 1.246
- 1.104
- 2.928
- 3.001
- 2.859
- 1.36
- 1.063
- 1.775
- 1.064
- 0.281
- 2.649
- 1.905
- 2.568
- 1.782
- 1.725
- 2.428
- 0.905
- 1.788
- 1.576
- 1.581
- 2.097
- 0.886
- 1.308
- 0.808
- 1.449
- 0.75
- 1.996
- 1.846
- 1.358
- 1.282
- 0.707
- 1.311
- 1.586
- 0.755
- 1.278
- 1.589
- 1.617
- 1.719
- 0.677
- 0.99
- 0.944
- 0.987
- 1.202
- 0.997
- 0.647
- 0.425
- 1.327
- 1.086
- 0.521
- 1.038
- 1.268
- 1.026
- 0.888
- 1.272
- 0.225
- 1.072
- 0.827
- 1.175
- 0.691
- 1.08
- 0.871
- 0.198
- 0.369
- 0.914
- 0.744
- 0.688
- 0.924
- 0.887
- 0.674
- 0.863
- 0.846
- 0.75
- 0.629
- 0.474
- 0.873
- 0.556
- 0.661
- 0.672
- 0.73
- 0.627
- 0.563
- 0.534
- 0.445
- 0.373
- 0.645
- 0.49
- 0.382
- 0.445
- 0.616
- 0.483
unequal: 0
verbose: 1
