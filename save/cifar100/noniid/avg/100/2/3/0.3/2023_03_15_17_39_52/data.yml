avg_train_accuracy: 0.238
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0166
- 0.0269
- 0.0515
- 0.0659
- 0.0938
- 0.137
- 0.1033
- 0.1267
- 0.1596
- 0.1392
- 0.175
- 0.1519
- 0.1859
- 0.1455
- 0.1517
- 0.1622
- 0.1994
- 0.2065
- 0.1549
- 0.1098
- 0.1734
- 0.1143
- 0.1054
- 0.1938
- 0.225
- 0.1993
- 0.1969
- 0.1906
- 0.237
- 0.239
- 0.2124
- 0.1878
- 0.2245
- 0.2051
- 0.2147
- 0.2105
- 0.2135
- 0.2166
- 0.2563
- 0.2247
- 0.2245
- 0.2464
- 0.2604
- 0.2627
- 0.2461
- 0.2407
- 0.2321
- 0.2361
- 0.2704
- 0.2454
- 0.2514
- 0.2498
- 0.255
- 0.248
- 0.2437
- 0.24
- 0.2817
- 0.252
- 0.2119
- 0.2851
- 0.246
- 0.2235
- 0.2817
- 0.2141
- 0.2671
- 0.2053
- 0.1361
- 0.1595
- 0.2852
- 0.2861
- 0.2232
- 0.1997
- 0.1892
- 0.2658
- 0.2887
- 0.2891
- 0.2642
- 0.2888
- 0.2628
- 0.2967
- 0.2632
- 0.2968
- 0.2983
- 0.2751
- 0.283
- 0.2921
- 0.2976
- 0.2685
- 0.2434
- 0.2972
- 0.2981
- 0.3041
- 0.3001
- 0.2601
- 0.2776
- 0.2787
- 0.2817
- 0.2912
- 0.2811
- 0.2774
test_loss_list:
- 1.9230736255645753
- 1.790288166999817
- 1.7132464933395386
- 1.666180021762848
- 1.5994418263435364
- 1.5563866519927978
- 1.570189278125763
- 1.528227400779724
- 1.499116175174713
- 1.5086721801757812
- 1.4722792792320252
- 1.4861516332626343
- 1.444027395248413
- 1.4892516398429871
- 1.4789295482635498
- 1.4599762892723083
- 1.4173125743865966
- 1.3890778636932373
- 1.4521878004074096
- 1.565209491252899
- 1.3958118677139282
- 1.524186623096466
- 1.5641168904304505
- 1.366936423778534
- 1.3511880230903626
- 1.3590497064590454
- 1.3573575901985169
- 1.3703057098388671
- 1.32504887342453
- 1.3277336549758911
- 1.3535378694534301
- 1.3753077936172486
- 1.315724127292633
- 1.3485052132606505
- 1.3434878730773925
- 1.3323404669761658
- 1.333989908695221
- 1.3290392327308655
- 1.2737535405158997
- 1.3254037833213805
- 1.3246584939956665
- 1.279306743144989
- 1.268738558292389
- 1.2702033090591431
- 1.2756314086914062
- 1.2798814344406129
- 1.305901825428009
- 1.306845338344574
- 1.2542242646217345
- 1.301933126449585
- 1.2615626454353333
- 1.2686721968650818
- 1.2658452320098876
- 1.2783901333808898
- 1.290770366191864
- 1.2837748050689697
- 1.235195894241333
- 1.2842468428611755
- 1.3469874715805055
- 1.2157627177238464
- 1.278868625164032
- 1.3133385491371155
- 1.2223041367530822
- 1.347102255821228
- 1.2342275619506835
- 1.3782390570640564
- 1.6364741539955139
- 1.503902587890625
- 1.2101900577545166
- 1.2222319340705872
- 1.3641059374809266
- 1.3772531151771545
- 1.4228016781806945
- 1.231269953250885
- 1.2107265925407409
- 1.2210672450065614
- 1.2602137756347656
- 1.2268476915359496
- 1.2693838930130006
- 1.2205969095230103
- 1.272779188156128
- 1.229904260635376
- 1.2379049801826476
- 1.2762279415130615
- 1.229590563774109
- 1.2255564498901368
- 1.2270994997024536
- 1.2674488615989685
- 1.3307269597053528
- 1.226121289730072
- 1.2369872903823853
- 1.2389102363586426
- 1.2349760961532592
- 1.2973038721084595
- 1.2556439280509948
- 1.2598367047309875
- 1.2625580883026124
- 1.2142050957679749
- 1.2596960401535033
- 1.2446314549446107
train_accuracy:
- 0.298
- 0.013
- 0.03
- 0.032
- 0.758
- 0.13
- 0.078
- 0.446
- 0.155
- 0.147
- 0.147
- 0.4
- 0.189
- 0.609
- 0.127
- 0.518
- 0.23
- 0.212
- 0.28
- 0.523
- 0.123
- 0.088
- 0.474
- 0.655
- 0.187
- 0.603
- 0.178
- 0.142
- 0.224
- 0.23
- 0.637
- 0.135
- 0.607
- 0.175
- 0.199
- 0.41
- 0.468
- 0.208
- 0.251
- 0.423
- 0.25
- 0.495
- 0.253
- 0.248
- 0.676
- 0.2
- 0.265
- 0.44
- 0.254
- 0.216
- 0.241
- 0.188
- 0.265
- 0.364
- 0.245
- 0.247
- 0.284
- 0.233
- 0.418
- 0.217
- 0.222
- 0.185
- 0.275
- 0.18
- 0.592
- 0.171
- 0.648
- 0.553
- 0.28
- 0.324
- 0.23
- 0.512
- 0.173
- 0.293
- 0.22
- 0.273
- 0.245
- 0.322
- 0.609
- 0.284
- 0.255
- 0.286
- 0.295
- 0.252
- 0.495
- 0.297
- 0.286
- 0.245
- 0.442
- 0.295
- 0.278
- 0.313
- 0.278
- 0.238
- 0.53
- 0.248
- 0.254
- 0.333
- 0.263
- 0.238
train_loss:
- 1.875
- 2.811
- 2.664
- 2.631
- 2.598
- 3.443
- 2.275
- 2.324
- 3.105
- 2.202
- 3.013
- 2.022
- 2.751
- 1.851
- 1.758
- 1.81
- 2.644
- 1.773
- 0.982
- 0.796
- 1.832
- 0.989
- 0.882
- 1.704
- 2.277
- 1.757
- 1.574
- 1.639
- 2.044
- 2.129
- 1.437
- 0.927
- 1.249
- 1.327
- 1.179
- 1.412
- 1.197
- 1.19
- 1.903
- 1.268
- 1.142
- 1.117
- 1.642
- 1.757
- 1.204
- 1.076
- 0.968
- 0.961
- 1.383
- 0.985
- 1.027
- 1.042
- 0.859
- 0.812
- 0.773
- 0.821
- 1.347
- 0.809
- 0.545
- 1.213
- 0.765
- 0.491
- 1.013
- 0.438
- 0.759
- 0.38
- 0.148
- 0.439
- 1.041
- 0.831
- 0.346
- 0.366
- 0.36
- 0.668
- 0.948
- 1.032
- 0.651
- 0.861
- 0.659
- 0.876
- 0.584
- 0.899
- 0.762
- 0.626
- 0.552
- 0.769
- 0.684
- 0.532
- 0.317
- 0.645
- 0.607
- 0.643
- 0.584
- 0.418
- 0.375
- 0.435
- 0.431
- 0.41
- 0.361
- 0.429
unequal: 0
verbose: 1
