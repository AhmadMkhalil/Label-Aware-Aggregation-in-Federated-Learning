avg_train_accuracy: 0.256
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0148
- 0.0318
- 0.0311
- 0.1126
- 0.0889
- 0.1343
- 0.1296
- 0.1564
- 0.1491
- 0.1422
- 0.1219
- 0.145
- 0.1813
- 0.1702
- 0.1939
- 0.1974
- 0.2021
- 0.1648
- 0.2056
- 0.1858
- 0.2035
- 0.1878
- 0.18
- 0.1741
- 0.2071
- 0.1789
- 0.2035
- 0.1554
- 0.1568
- 0.2369
- 0.2384
- 0.2389
- 0.2423
- 0.2004
- 0.2219
- 0.1615
- 0.2404
- 0.2224
- 0.2355
- 0.2559
- 0.2565
- 0.2226
- 0.2267
- 0.2324
- 0.2208
- 0.2577
- 0.2259
- 0.2496
- 0.2635
- 0.2546
- 0.238
- 0.2677
- 0.2487
- 0.2124
- 0.1843
- 0.2467
- 0.2292
- 0.2448
- 0.2377
- 0.2428
- 0.2735
- 0.2297
- 0.2337
- 0.2698
- 0.2506
- 0.2597
- 0.276
- 0.2624
- 0.2561
- 0.263
- 0.2592
- 0.2851
- 0.2311
- 0.2448
- 0.2664
- 0.2503
- 0.2657
- 0.275
- 0.273
- 0.2706
- 0.2854
- 0.2694
- 0.2662
- 0.2827
- 0.2611
- 0.2565
- 0.2247
- 0.207
- 0.2908
- 0.2191
- 0.2282
- 0.2737
- 0.2888
- 0.2742
- 0.2649
- 0.2604
- 0.2894
- 0.2823
- 0.2726
- 0.259
test_loss_list:
- 1.8459201097488402
- 1.7302049207687378
- 1.7538414430618285
- 1.609562678337097
- 1.6134855580329894
- 1.5559208106994629
- 1.537564480304718
- 1.5066256403923035
- 1.501579349040985
- 1.4911521124839782
- 1.5244691371917725
- 1.503468849658966
- 1.4529188299179077
- 1.4525940799713135
- 1.4301424646377563
- 1.4232172656059265
- 1.4186818742752074
- 1.4540904927253724
- 1.3913287806510926
- 1.415795910358429
- 1.3777182364463807
- 1.3882115769386292
- 1.4005438804626464
- 1.4036433005332947
- 1.3468442630767823
- 1.3977714109420776
- 1.360899260044098
- 1.4424452257156373
- 1.4359066653251649
- 1.3046312355995178
- 1.31309463262558
- 1.3136900901794433
- 1.3167420196533204
- 1.3743633699417115
- 1.3208136415481568
- 1.455332555770874
- 1.3052687048912048
- 1.3287155032157898
- 1.30835622549057
- 1.2910596656799316
- 1.295852665901184
- 1.320372064113617
- 1.3139971137046813
- 1.306254358291626
- 1.3069971680641175
- 1.2685904502868652
- 1.324758665561676
- 1.2628221917152405
- 1.255377757549286
- 1.2755982542037965
- 1.3022646450996398
- 1.2582031035423278
- 1.286304178237915
- 1.3517897725105286
- 1.4154791331291199
- 1.2751494503021241
- 1.303628544807434
- 1.2839151620864868
- 1.2931474351882934
- 1.3025608253479004
- 1.250199921131134
- 1.3158324551582337
- 1.2923128509521484
- 1.246046097278595
- 1.2887604069709777
- 1.2605303740501403
- 1.2481365036964416
- 1.259177601337433
- 1.2702638363838197
- 1.2614321088790894
- 1.2677986907958985
- 1.223446674346924
- 1.3114651155471801
- 1.2894426894187927
- 1.2456250286102295
- 1.2836696219444275
- 1.2526262307167053
- 1.250406527519226
- 1.2524393963813782
- 1.2585406947135924
- 1.2349724578857422
- 1.2698374891281128
- 1.2642096948623658
- 1.2377890276908874
- 1.2685556030273437
- 1.274006152153015
- 1.3230166745185852
- 1.389687922000885
- 1.211017587184906
- 1.3691358041763306
- 1.3399500131607056
- 1.2294237399101258
- 1.2192774295806885
- 1.2527398133277894
- 1.2713908910751344
- 1.2628987169265746
- 1.226368477344513
- 1.235381293296814
- 1.2627301335334777
- 1.269465012550354
train_accuracy:
- 0.912
- 0.628
- 0.007
- 0.121
- 0.674
- 0.148
- 0.118
- 0.157
- 0.169
- 0.124
- 0.103
- 0.14
- 0.182
- 0.148
- 0.212
- 0.231
- 0.205
- 0.117
- 0.233
- 0.172
- 0.216
- 0.333
- 0.412
- 0.159
- 0.193
- 0.161
- 0.193
- 0.243
- 0.125
- 0.226
- 0.231
- 0.249
- 0.255
- 0.167
- 0.204
- 0.436
- 0.233
- 0.658
- 0.229
- 0.267
- 0.271
- 0.185
- 0.231
- 0.407
- 0.206
- 0.239
- 0.374
- 0.589
- 0.251
- 0.604
- 0.205
- 0.259
- 0.203
- 0.301
- 0.428
- 0.257
- 0.202
- 0.168
- 0.198
- 0.213
- 0.249
- 0.363
- 0.217
- 0.263
- 0.235
- 0.225
- 0.303
- 0.242
- 0.241
- 0.228
- 0.243
- 0.298
- 0.611
- 0.225
- 0.281
- 0.546
- 0.637
- 0.279
- 0.544
- 0.283
- 0.292
- 0.597
- 0.235
- 0.286
- 0.271
- 0.24
- 0.299
- 0.409
- 0.271
- 0.314
- 0.53
- 0.268
- 0.275
- 0.268
- 0.256
- 0.27
- 0.316
- 0.28
- 0.264
- 0.256
train_loss:
- 3.135
- 2.801
- 1.518
- 3.708
- 2.415
- 3.319
- 2.379
- 3.196
- 2.271
- 2.172
- 2.167
- 2.096
- 2.744
- 1.993
- 2.624
- 2.586
- 2.559
- 1.114
- 2.515
- 1.612
- 1.645
- 1.8
- 1.689
- 1.663
- 1.579
- 1.508
- 1.669
- 0.875
- 0.876
- 2.081
- 2.073
- 1.908
- 1.917
- 0.815
- 1.204
- 0.663
- 1.637
- 1.176
- 1.254
- 1.746
- 1.7
- 0.777
- 1.018
- 1.157
- 1.2
- 1.392
- 0.934
- 1.175
- 1.405
- 1.034
- 0.955
- 1.284
- 0.906
- 0.468
- 0.551
- 0.866
- 0.91
- 0.952
- 0.8
- 0.834
- 1.111
- 0.536
- 0.694
- 0.91
- 0.915
- 0.7
- 0.873
- 0.804
- 0.741
- 0.726
- 0.744
- 0.988
- 0.46
- 0.592
- 0.669
- 0.672
- 0.592
- 0.557
- 0.594
- 0.532
- 0.766
- 0.484
- 0.523
- 0.683
- 0.646
- 0.465
- 0.404
- 0.229
- 0.632
- 0.344
- 0.285
- 0.532
- 0.612
- 0.44
- 0.393
- 0.449
- 0.583
- 0.508
- 0.377
- 0.442
unequal: 0
verbose: 1
