avg_train_accuracy: 0.517
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0204
- 0.0241
- 0.0483
- 0.0661
- 0.1227
- 0.1066
- 0.0901
- 0.1537
- 0.1633
- 0.1692
- 0.1417
- 0.182
- 0.1839
- 0.1914
- 0.1687
- 0.163
- 0.1355
- 0.2118
- 0.1841
- 0.1868
- 0.1943
- 0.2253
- 0.2199
- 0.1992
- 0.2074
- 0.2101
- 0.202
- 0.2333
- 0.2364
- 0.1866
- 0.2144
- 0.2208
- 0.192
- 0.2251
- 0.217
- 0.1723
- 0.251
- 0.2305
- 0.228
- 0.1777
- 0.259
- 0.2532
- 0.2408
- 0.2083
- 0.1739
- 0.2577
- 0.2325
- 0.2601
- 0.2645
- 0.2497
- 0.2441
- 0.2439
- 0.2523
- 0.2499
- 0.2049
- 0.2493
- 0.2504
- 0.2645
- 0.2731
- 0.2584
- 0.2505
- 0.2086
- 0.2538
- 0.2518
- 0.2589
- 0.2193
- 0.2579
- 0.2485
- 0.2584
- 0.2733
- 0.2771
- 0.27
- 0.2793
- 0.2685
- 0.2763
- 0.2338
- 0.277
- 0.2611
- 0.2633
- 0.2532
- 0.2539
- 0.2672
- 0.221
- 0.2805
- 0.263
- 0.2841
- 0.2644
- 0.2837
- 0.26
- 0.2204
- 0.2672
- 0.257
- 0.2884
- 0.2882
- 0.2484
- 0.269
- 0.2696
- 0.2872
- 0.2878
- 0.2675
test_loss_list:
- 1.8368368864059448
- 1.819015097618103
- 1.689468641281128
- 1.6540168929100036
- 1.579984223842621
- 1.574212064743042
- 1.588099067211151
- 1.5009764623641968
- 1.4938448929786683
- 1.4809359860420228
- 1.5037355780601502
- 1.4428994607925416
- 1.4431279730796813
- 1.4398161244392396
- 1.453561019897461
- 1.4641447973251343
- 1.4944405221939088
- 1.3852246618270874
- 1.4174464917182923
- 1.3983397269248963
- 1.393305048942566
- 1.3616699695587158
- 1.3527788066864013
- 1.3711696672439575
- 1.3628710961341859
- 1.340067801475525
- 1.367512481212616
- 1.3266055274009705
- 1.331285903453827
- 1.3972218656539916
- 1.3383378505706787
- 1.3294087147712708
- 1.3818654894828797
- 1.317562654018402
- 1.3202878952026367
- 1.4465443229675292
- 1.2814318966865539
- 1.3414420461654664
- 1.3038000535964966
- 1.4359515309333801
- 1.2797292423248292
- 1.2905061554908752
- 1.2927246713638305
- 1.3453304028511048
- 1.4318603014945983
- 1.2573832368850708
- 1.2999664449691772
- 1.2675281357765198
- 1.2688139629364015
- 1.298387243747711
- 1.2795982718467713
- 1.2654176807403565
- 1.2775691199302672
- 1.2890521478652954
- 1.3772061109542846
- 1.2569665932655334
- 1.2798089909553527
- 1.2529176926612855
- 1.254241554737091
- 1.2868311977386475
- 1.2668769121170045
- 1.395880024433136
- 1.2735326290130615
- 1.2847542238235474
- 1.288070011138916
- 1.3682441926002502
- 1.288958683013916
- 1.2851084637641907
- 1.2797893571853638
- 1.2548363518714905
- 1.2598529720306397
- 1.2321735262870788
- 1.245386791229248
- 1.2745501828193664
- 1.2375573658943175
- 1.3151055407524108
- 1.2247455716133118
- 1.2582152557373047
- 1.2624096965789795
- 1.2657025313377381
- 1.2594208574295045
- 1.2529150414466859
- 1.3659320640563966
- 1.228262813091278
- 1.2491619062423707
- 1.2240931463241578
- 1.262323832511902
- 1.2290894794464111
- 1.2651492071151733
- 1.3714973902702332
- 1.2568608927726745
- 1.255374653339386
- 1.2131912207603455
- 1.222691307067871
- 1.3096505975723267
- 1.2407966423034669
- 1.2506009030342102
- 1.2256808590888977
- 1.2234826016426086
- 1.2585136127471923
train_accuracy:
- 0.574
- 0.004
- 0.037
- 0.048
- 0.083
- 0.117
- 0.059
- 0.163
- 0.141
- 0.15
- 0.48
- 0.126
- 0.192
- 0.17
- 0.102
- 0.123
- 0.695
- 0.199
- 0.54
- 0.146
- 0.132
- 0.249
- 0.468
- 0.153
- 0.485
- 0.144
- 0.177
- 0.223
- 0.183
- 0.563
- 0.151
- 0.236
- 0.645
- 0.474
- 0.204
- 0.76
- 0.259
- 0.224
- 0.212
- 0.709
- 0.242
- 0.266
- 0.417
- 0.455
- 0.595
- 0.271
- 0.209
- 0.274
- 0.276
- 0.188
- 0.481
- 0.233
- 0.22
- 0.171
- 0.622
- 0.241
- 0.391
- 0.261
- 0.304
- 0.251
- 0.192
- 0.132
- 0.2
- 0.197
- 0.26
- 0.582
- 0.259
- 0.267
- 0.241
- 0.28
- 0.281
- 0.301
- 0.313
- 0.214
- 0.311
- 0.398
- 0.262
- 0.584
- 0.247
- 0.668
- 0.482
- 0.285
- 0.146
- 0.288
- 0.213
- 0.229
- 0.265
- 0.275
- 0.547
- 0.412
- 0.209
- 0.613
- 0.314
- 0.315
- 0.448
- 0.214
- 0.221
- 0.275
- 0.285
- 0.517
train_loss:
- 3.061
- 1.686
- 2.727
- 2.578
- 3.526
- 2.332
- 1.458
- 3.329
- 3.046
- 2.948
- 1.299
- 3.008
- 2.729
- 2.786
- 1.898
- 1.712
- 1.159
- 2.659
- 1.747
- 1.738
- 1.601
- 2.436
- 1.647
- 1.652
- 1.549
- 1.564
- 1.5
- 2.006
- 1.912
- 0.877
- 1.239
- 1.53
- 0.857
- 1.38
- 1.344
- 0.758
- 1.859
- 1.227
- 1.221
- 0.606
- 1.623
- 1.571
- 1.244
- 0.599
- 0.619
- 1.521
- 1.075
- 1.392
- 1.49
- 1.011
- 0.98
- 0.929
- 1.05
- 0.887
- 0.525
- 0.978
- 0.803
- 1.049
- 1.201
- 0.916
- 0.751
- 0.458
- 0.768
- 0.643
- 0.75
- 0.479
- 0.719
- 0.791
- 0.635
- 0.837
- 0.801
- 0.833
- 0.802
- 0.599
- 0.758
- 0.416
- 0.959
- 0.592
- 0.666
- 0.583
- 0.587
- 0.509
- 0.314
- 0.689
- 0.649
- 0.66
- 0.462
- 0.596
- 0.435
- 0.246
- 0.438
- 0.534
- 0.663
- 0.58
- 0.259
- 0.458
- 0.395
- 0.485
- 0.599
- 0.449
unequal: 0
verbose: 1
