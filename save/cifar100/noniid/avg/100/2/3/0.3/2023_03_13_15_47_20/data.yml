avg_train_accuracy: 0.191
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0133
- 0.0773
- 0.0521
- 0.1182
- 0.1318
- 0.1241
- 0.1483
- 0.1391
- 0.1641
- 0.1374
- 0.1441
- 0.1409
- 0.1957
- 0.1934
- 0.1394
- 0.1593
- 0.2065
- 0.2117
- 0.1709
- 0.1186
- 0.1764
- 0.1896
- 0.1977
- 0.1851
- 0.1964
- 0.2014
- 0.211
- 0.1974
- 0.2217
- 0.2053
- 0.2197
- 0.1608
- 0.2157
- 0.1671
- 0.2432
- 0.2206
- 0.2452
- 0.2072
- 0.2535
- 0.2271
- 0.2224
- 0.2295
- 0.2574
- 0.2204
- 0.2599
- 0.2367
- 0.2658
- 0.2551
- 0.2649
- 0.2414
- 0.1994
- 0.1999
- 0.2402
- 0.2663
- 0.2456
- 0.2081
- 0.2701
- 0.2681
- 0.2741
- 0.2255
- 0.2436
- 0.2782
- 0.2794
- 0.2762
- 0.2633
- 0.2774
- 0.2702
- 0.2558
- 0.2293
- 0.2125
- 0.1919
- 0.262
- 0.284
- 0.2562
- 0.2248
- 0.2213
- 0.2011
- 0.2642
- 0.1677
- 0.2799
- 0.2542
- 0.2617
- 0.2946
- 0.2917
- 0.2927
- 0.2615
- 0.2909
- 0.2971
- 0.2461
- 0.2725
- 0.2767
- 0.2939
- 0.2941
- 0.295
- 0.2534
- 0.2184
- 0.2661
- 0.2978
- 0.2708
- 0.2327
test_loss_list:
- 1.95554931640625
- 1.7046009159088136
- 1.6959997701644898
- 1.6068941569328308
- 1.5776935863494872
- 1.5715985250473024
- 1.5015891456604005
- 1.4982996082305908
- 1.4769765520095826
- 1.5040930223464966
- 1.4853643202781677
- 1.4830302834510802
- 1.4266013646125792
- 1.4256280589103698
- 1.5051696038246154
- 1.4558326816558838
- 1.3956388235092163
- 1.388354411125183
- 1.4072973132133484
- 1.538656597137451
- 1.4027689170837403
- 1.3742794942855836
- 1.3670575070381163
- 1.3804261326789855
- 1.379448733329773
- 1.3609667420387268
- 1.3483643293380738
- 1.385909342765808
- 1.3209952569007875
- 1.362139482498169
- 1.3162741780281066
- 1.4489362001419068
- 1.3338220596313477
- 1.4241445994377135
- 1.2987651133537292
- 1.3397277331352233
- 1.295425465106964
- 1.348613440990448
- 1.2795018982887267
- 1.3241470789909362
- 1.319686074256897
- 1.3179793381690978
- 1.2785401940345764
- 1.335175712108612
- 1.2721836423873902
- 1.3242326498031616
- 1.2734282875061036
- 1.2777398824691772
- 1.267683548927307
- 1.2965052509307862
- 1.3736821842193603
- 1.3660784077644348
- 1.278936469554901
- 1.2471322655677795
- 1.2823454880714416
- 1.3576167631149292
- 1.241623134613037
- 1.2520831537246704
- 1.2510959577560425
- 1.3385320830345153
- 1.2994049930572509
- 1.2450383830070495
- 1.2457606077194214
- 1.2593676257133484
- 1.2711290669441224
- 1.241574022769928
- 1.2448404049873352
- 1.2596373987197875
- 1.328714988231659
- 1.3594657921791076
- 1.3976625847816466
- 1.246978030204773
- 1.212502429485321
- 1.2709024214744569
- 1.3332203769683837
- 1.3413632750511169
- 1.3989126706123352
- 1.2562347650527954
- 1.5234713339805603
- 1.220932786464691
- 1.2909358072280883
- 1.2851012253761291
- 1.2102737855911254
- 1.2272323322296144
- 1.2280191707611083
- 1.263486886024475
- 1.2106859040260316
- 1.2200516533851624
- 1.3086082601547242
- 1.2601134490966797
- 1.24407235622406
- 1.223853931427002
- 1.2313772249221802
- 1.2290369820594789
- 1.297761800289154
- 1.3700974702835083
- 1.262854266166687
- 1.2081444883346557
- 1.277561047077179
- 1.354732391834259
train_accuracy:
- 0.001
- 0.069
- 0.034
- 0.103
- 0.141
- 0.316
- 0.359
- 0.257
- 0.199
- 0.456
- 0.134
- 0.142
- 0.195
- 0.227
- 0.311
- 0.175
- 0.193
- 0.204
- 0.112
- 0.446
- 0.158
- 0.172
- 0.694
- 0.414
- 0.177
- 0.194
- 0.576
- 0.384
- 0.237
- 0.172
- 0.209
- 0.108
- 0.311
- 0.152
- 0.23
- 0.188
- 0.242
- 0.211
- 0.237
- 0.221
- 0.228
- 0.256
- 0.223
- 0.221
- 0.264
- 0.237
- 0.252
- 0.475
- 0.257
- 0.3
- 0.508
- 0.631
- 0.212
- 0.235
- 0.237
- 0.21
- 0.267
- 0.307
- 0.263
- 0.225
- 0.233
- 0.261
- 0.262
- 0.291
- 0.214
- 0.292
- 0.467
- 0.303
- 0.73
- 0.544
- 0.179
- 0.376
- 0.279
- 0.249
- 0.205
- 0.286
- 0.613
- 0.251
- 0.202
- 0.286
- 0.341
- 0.322
- 0.321
- 0.315
- 0.317
- 0.278
- 0.258
- 0.315
- 0.583
- 0.281
- 0.617
- 0.317
- 0.26
- 0.269
- 0.208
- 0.165
- 0.442
- 0.343
- 0.238
- 0.191
train_loss:
- 1.855
- 4.091
- 2.703
- 3.647
- 3.388
- 2.38
- 2.349
- 2.279
- 3.049
- 2.202
- 2.098
- 2.035
- 2.758
- 2.634
- 1.19
- 1.8
- 2.466
- 2.674
- 1.217
- 1.029
- 1.751
- 1.656
- 1.646
- 1.568
- 1.499
- 1.575
- 1.527
- 1.483
- 1.66
- 1.421
- 1.423
- 0.707
- 1.238
- 0.803
- 1.809
- 1.346
- 1.828
- 0.888
- 1.735
- 1.153
- 1.192
- 1.167
- 1.815
- 1.176
- 1.485
- 0.966
- 1.443
- 0.905
- 1.3
- 0.871
- 0.698
- 0.625
- 0.818
- 1.297
- 0.796
- 0.477
- 1.331
- 1.097
- 1.279
- 0.485
- 0.797
- 1.041
- 1.18
- 1.042
- 0.974
- 1.086
- 0.731
- 0.729
- 0.45
- 0.373
- 0.396
- 0.558
- 1.054
- 0.659
- 0.353
- 0.495
- 0.309
- 0.457
- 0.155
- 0.72
- 0.493
- 0.568
- 0.967
- 0.743
- 0.74
- 0.384
- 0.742
- 0.591
- 0.314
- 0.331
- 0.422
- 0.564
- 0.666
- 0.566
- 0.344
- 0.245
- 0.352
- 0.612
- 0.388
- 0.268
unequal: 0
verbose: 1
