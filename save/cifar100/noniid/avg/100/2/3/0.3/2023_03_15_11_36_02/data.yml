avg_train_accuracy: 0.494
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0168
- 0.0405
- 0.1063
- 0.0873
- 0.097
- 0.0561
- 0.1161
- 0.1577
- 0.1305
- 0.1724
- 0.178
- 0.1562
- 0.1589
- 0.1875
- 0.1928
- 0.1779
- 0.2077
- 0.196
- 0.1345
- 0.2188
- 0.1879
- 0.2203
- 0.1998
- 0.2318
- 0.201
- 0.2348
- 0.207
- 0.2157
- 0.1696
- 0.2209
- 0.217
- 0.2208
- 0.2536
- 0.2258
- 0.2526
- 0.2295
- 0.2574
- 0.2438
- 0.2612
- 0.2139
- 0.271
- 0.2363
- 0.2691
- 0.2454
- 0.2429
- 0.2214
- 0.1749
- 0.1932
- 0.2527
- 0.2777
- 0.2814
- 0.2785
- 0.2793
- 0.2608
- 0.2871
- 0.2867
- 0.2896
- 0.2781
- 0.2499
- 0.2671
- 0.2576
- 0.161
- 0.271
- 0.2598
- 0.2662
- 0.2726
- 0.2719
- 0.2703
- 0.2939
- 0.2638
- 0.2963
- 0.2704
- 0.2642
- 0.2749
- 0.2684
- 0.2666
- 0.2338
- 0.2787
- 0.2605
- 0.3003
- 0.3039
- 0.2822
- 0.2398
- 0.3046
- 0.2483
- 0.2179
- 0.2836
- 0.2733
- 0.284
- 0.3023
- 0.2834
- 0.2853
- 0.2788
- 0.3086
- 0.2841
- 0.2834
- 0.2874
- 0.2408
- 0.3067
- 0.2497
test_loss_list:
- 1.8330837821960448
- 1.730935082435608
- 1.6209234595298767
- 1.624134726524353
- 1.5862331128120422
- 1.7022091054916382
- 1.5557627201080322
- 1.497242877483368
- 1.5246833539009095
- 1.4736762309074403
- 1.4699732279777527
- 1.4865914177894592
- 1.4376855444908143
- 1.4145562314987183
- 1.4178650236129762
- 1.4420174908638002
- 1.3942920994758605
- 1.3989648938179016
- 1.5200972318649293
- 1.3619325280189514
- 1.410405421257019
- 1.364161922931671
- 1.3911416673660277
- 1.3526993107795715
- 1.3891503095626831
- 1.3444705939292907
- 1.3877730202674865
- 1.3830357742309571
- 1.464819574356079
- 1.3521373867988586
- 1.3575857186317444
- 1.3475588631629944
- 1.3077286219596862
- 1.3465376591682434
- 1.3061586093902589
- 1.3445679545402527
- 1.303871808052063
- 1.3160453677177428
- 1.2922473287582397
- 1.3259633421897887
- 1.255465886592865
- 1.3070838809013368
- 1.2676568579673768
- 1.3150085401535034
- 1.3148789620399475
- 1.3195210456848145
- 1.4339032435417176
- 1.3796908831596375
- 1.2556440043449402
- 1.2433930683135985
- 1.2428484129905701
- 1.249670398235321
- 1.2571763491630554
- 1.2771298861503602
- 1.2444074082374572
- 1.2544394135475159
- 1.251911768913269
- 1.261691391468048
- 1.2683161568641663
- 1.2369983792304993
- 1.258353569507599
- 1.5414531207084656
- 1.2244601225852967
- 1.2630753469467164
- 1.2449493551254271
- 1.242530198097229
- 1.2595453810691835
- 1.2345734453201294
- 1.2167919564247132
- 1.2595158910751343
- 1.2209674143791198
- 1.2567878293991088
- 1.2597279310226441
- 1.2484456610679626
- 1.2454887461662292
- 1.2506414985656737
- 1.3365412163734436
- 1.2352268409729004
- 1.2575455188751221
- 1.2102328085899352
- 1.2080616188049316
- 1.2468866395950318
- 1.33515930891037
- 1.2052972674369813
- 1.3211619210243226
- 1.3994938516616822
- 1.229914276599884
- 1.2438366508483887
- 1.2454953646659852
- 1.2180591607093811
- 1.2407203340530395
- 1.2381939792633057
- 1.242206859588623
- 1.2062417769432068
- 1.2481202578544617
- 1.2492718172073365
- 1.2324767732620239
- 1.3443335223197936
- 1.199180474281311
- 1.3130003333091735
train_accuracy:
- 0.0
- 0.018
- 0.106
- 0.073
- 0.056
- 0.707
- 0.077
- 0.161
- 0.075
- 0.167
- 0.164
- 0.156
- 0.105
- 0.205
- 0.207
- 0.141
- 0.204
- 0.208
- 0.483
- 0.197
- 0.142
- 0.234
- 0.155
- 0.207
- 0.147
- 0.192
- 0.768
- 0.191
- 0.254
- 0.44
- 0.214
- 0.434
- 0.225
- 0.178
- 0.267
- 0.229
- 0.263
- 0.212
- 0.251
- 0.007
- 0.263
- 0.552
- 0.266
- 0.646
- 0.462
- 0.177
- 0.617
- 0.65
- 0.237
- 0.28
- 0.291
- 0.26
- 0.296
- 0.249
- 0.281
- 0.23
- 0.298
- 0.273
- 0.195
- 0.516
- 0.565
- 0.388
- 0.502
- 0.502
- 0.285
- 0.519
- 0.255
- 0.231
- 0.311
- 0.267
- 0.294
- 0.266
- 0.593
- 0.25
- 0.196
- 0.498
- 0.58
- 0.479
- 0.267
- 0.314
- 0.315
- 0.271
- 0.206
- 0.307
- 0.197
- 0.585
- 0.41
- 0.601
- 0.551
- 0.281
- 0.262
- 0.271
- 0.288
- 0.273
- 0.597
- 0.546
- 0.473
- 0.227
- 0.296
- 0.494
train_loss:
- 2.981
- 2.838
- 3.734
- 2.534
- 2.431
- 1.361
- 2.204
- 3.252
- 2.117
- 2.948
- 2.771
- 1.9
- 1.304
- 2.622
- 2.529
- 1.789
- 2.586
- 1.907
- 0.982
- 2.43
- 1.535
- 2.178
- 1.542
- 2.106
- 1.549
- 2.03
- 1.415
- 1.277
- 0.808
- 1.337
- 1.254
- 1.375
- 1.744
- 1.403
- 1.847
- 1.231
- 1.597
- 1.146
- 1.464
- 0.834
- 1.675
- 1.006
- 1.54
- 0.922
- 0.892
- 0.738
- 0.531
- 0.469
- 0.953
- 1.34
- 1.444
- 1.216
- 1.083
- 0.797
- 1.342
- 1.079
- 1.156
- 0.711
- 0.562
- 0.735
- 0.76
- 0.168
- 0.685
- 0.632
- 0.863
- 0.648
- 0.654
- 0.649
- 0.899
- 0.641
- 0.846
- 0.594
- 0.594
- 0.578
- 0.609
- 0.625
- 0.394
- 0.484
- 0.486
- 0.68
- 0.706
- 0.469
- 0.295
- 0.706
- 0.335
- 0.224
- 0.444
- 0.464
- 0.38
- 0.556
- 0.397
- 0.469
- 0.38
- 0.635
- 0.417
- 0.311
- 0.507
- 0.267
- 0.523
- 0.292
unequal: 0
verbose: 1
