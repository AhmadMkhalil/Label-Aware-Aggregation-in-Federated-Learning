avg_train_accuracy: 0.334
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0332
- 0.0887
- 0.1007
- 0.1141
- 0.136
- 0.148
- 0.1642
- 0.1669
- 0.1698
- 0.1707
- 0.1782
- 0.1921
- 0.1932
- 0.1998
- 0.2057
- 0.2119
- 0.2112
- 0.2168
- 0.2177
- 0.1981
- 0.2121
- 0.2163
- 0.2241
- 0.2241
- 0.2339
- 0.2387
- 0.2305
- 0.2399
- 0.2367
- 0.2369
- 0.22
- 0.2407
- 0.2504
- 0.2491
- 0.2546
- 0.2578
- 0.2461
- 0.2592
- 0.2605
- 0.2588
- 0.259
- 0.2559
- 0.2659
- 0.2639
- 0.2486
- 0.2666
- 0.2736
- 0.2607
- 0.27
- 0.2769
- 0.2693
- 0.2711
- 0.2714
- 0.2766
- 0.2709
- 0.2734
- 0.2728
- 0.2779
- 0.2795
- 0.2781
- 0.2782
- 0.2735
- 0.2624
- 0.2812
- 0.2803
- 0.2871
- 0.2871
- 0.2859
- 0.2886
- 0.2882
- 0.2914
- 0.2923
- 0.2842
- 0.2889
- 0.2882
- 0.2883
- 0.2916
- 0.2883
- 0.2865
- 0.2861
- 0.2975
- 0.2958
- 0.2987
- 0.2882
- 0.2736
- 0.2827
- 0.2897
- 0.3016
- 0.2842
- 0.299
- 0.2943
- 0.2947
- 0.2965
- 0.295
- 0.2993
- 0.2941
- 0.2938
- 0.2931
- 0.2988
- 0.3027
test_loss_list:
- 1.7978984689712525
- 1.6646900224685668
- 1.6165979719161987
- 1.587634642124176
- 1.5501007890701295
- 1.5117742705345154
- 1.4937205529212951
- 1.462035937309265
- 1.4592066812515259
- 1.4471506690979004
- 1.4357577347755432
- 1.419033079147339
- 1.4140577936172485
- 1.4029091548919679
- 1.3985751295089721
- 1.3726164841651916
- 1.356562888622284
- 1.3476068496704101
- 1.33388516664505
- 1.3682243418693543
- 1.3421588730812073
- 1.3278070378303528
- 1.3249567675590515
- 1.3239878439903259
- 1.3065175819396972
- 1.2966315937042237
- 1.307205798625946
- 1.284087061882019
- 1.2882941198348998
- 1.288307514190674
- 1.3210504031181336
- 1.2836890387535096
- 1.2756368327140808
- 1.2751958250999451
- 1.2567431831359863
- 1.2568016362190246
- 1.277142310142517
- 1.2479648637771605
- 1.2521177768707275
- 1.2589551496505738
- 1.2372508764266967
- 1.246571228504181
- 1.244401330947876
- 1.2336179518699646
- 1.2637864542007446
- 1.2309793162345886
- 1.2235023880004883
- 1.242039852142334
- 1.230887017250061
- 1.2180799436569214
- 1.24440048456192
- 1.2176407146453858
- 1.2188137078285217
- 1.2231667494773866
- 1.229349467754364
- 1.2342575287818909
- 1.2359818243980407
- 1.2222261238098144
- 1.2265076732635498
- 1.2173461389541627
- 1.2018005561828613
- 1.220928792953491
- 1.2483018326759339
- 1.2038004302978516
- 1.209171724319458
- 1.2020817756652833
- 1.216822829246521
- 1.2044097924232482
- 1.2054336643218995
- 1.213647813796997
- 1.2054638528823853
- 1.222904326915741
- 1.2032442092895508
- 1.2059416484832763
- 1.2078676581382752
- 1.2034275555610656
- 1.196071789264679
- 1.2017767095565797
- 1.2088845229148866
- 1.2138089394569398
- 1.1811833834648133
- 1.2025467586517333
- 1.192985200881958
- 1.2105566549301148
- 1.2417145729064942
- 1.2115420246124267
- 1.19603679895401
- 1.1795078611373901
- 1.2208204102516174
- 1.185520510673523
- 1.1963706779479981
- 1.1951228880882263
- 1.1971500515937805
- 1.2019161415100097
- 1.1968053698539733
- 1.205957489013672
- 1.2127733111381531
- 1.1981076550483705
- 1.1998608422279358
- 1.1883479642868042
train_accuracy:
- 0.267
- 0.028
- 0.002
- 0.104
- 0.15
- 0.183
- 0.157
- 0.053
- 0.186
- 0.187
- 0.179
- 0.184
- 0.178
- 0.219
- 0.177
- 0.221
- 0.169
- 0.031
- 0.165
- 0.332
- 0.218
- 0.232
- 0.036
- 0.134
- 0.255
- 0.238
- 0.102
- 0.182
- 0.208
- 0.009
- 0.393
- 0.117
- 0.014
- 0.237
- 0.156
- 0.295
- 0.015
- 0.254
- 0.276
- 0.074
- 0.245
- 0.288
- 0.284
- 0.271
- 0.345
- 0.256
- 0.244
- 0.05
- 0.284
- 0.304
- 0.276
- 0.266
- 0.284
- 0.261
- 0.023
- 0.247
- 0.278
- 0.278
- 0.277
- 0.292
- 0.074
- 0.297
- 0.211
- 0.313
- 0.285
- 0.08
- 0.078
- 0.265
- 0.319
- 0.291
- 0.29
- 0.323
- 0.21
- 0.311
- 0.251
- 0.301
- 0.318
- 0.331
- 0.28
- 0.287
- 0.317
- 0.345
- 0.258
- 0.226
- 0.351
- 0.173
- 0.298
- 0.095
- 0.093
- 0.293
- 0.302
- 0.02
- 0.253
- 0.043
- 0.218
- 0.294
- 0.31
- 0.168
- 0.251
- 0.334
train_loss:
- 3.544
- 3.21
- 2.376
- 2.227
- 2.749
- 2.674
- 3.197
- 2.01
- 1.918
- 1.888
- 1.852
- 2.266
- 2.169
- 2.194
- 2.081
- 2.123
- 2.064
- 1.537
- 1.499
- 1.025
- 1.405
- 1.393
- 1.425
- 1.345
- 1.735
- 1.77
- 1.275
- 1.41
- 1.245
- 1.191
- 0.839
- 1.19
- 1.565
- 1.235
- 1.515
- 1.481
- 1.062
- 1.349
- 1.321
- 1.295
- 1.042
- 1.056
- 1.583
- 0.922
- 0.732
- 1.236
- 1.174
- 0.637
- 0.894
- 1.071
- 0.78
- 0.866
- 0.866
- 1.195
- 0.74
- 0.814
- 0.745
- 0.971
- 0.869
- 0.904
- 0.725
- 0.613
- 0.425
- 0.911
- 0.657
- 0.843
- 0.801
- 0.597
- 0.742
- 0.683
- 0.734
- 0.873
- 0.396
- 0.783
- 0.716
- 0.628
- 0.672
- 0.648
- 0.45
- 0.509
- 0.528
- 0.681
- 0.603
- 0.365
- 0.349
- 0.4
- 0.438
- 0.492
- 0.336
- 0.516
- 0.392
- 0.404
- 0.45
- 0.434
- 0.458
- 0.363
- 0.324
- 0.358
- 0.37
- 0.421
unequal: 0
verbose: 1
