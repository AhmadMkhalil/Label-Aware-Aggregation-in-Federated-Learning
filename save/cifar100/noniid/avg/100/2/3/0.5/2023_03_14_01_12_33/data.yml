avg_train_accuracy: 0.288
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0186
- 0.0877
- 0.1083
- 0.1137
- 0.1236
- 0.1299
- 0.1511
- 0.1626
- 0.1667
- 0.1737
- 0.1736
- 0.1791
- 0.1916
- 0.1967
- 0.1962
- 0.2049
- 0.2097
- 0.209
- 0.2192
- 0.2226
- 0.2243
- 0.2232
- 0.2242
- 0.2327
- 0.2334
- 0.2316
- 0.233
- 0.2181
- 0.229
- 0.2338
- 0.2419
- 0.2438
- 0.2488
- 0.2554
- 0.2515
- 0.2573
- 0.2615
- 0.2637
- 0.2628
- 0.2667
- 0.2643
- 0.2663
- 0.2683
- 0.2711
- 0.2752
- 0.2783
- 0.2774
- 0.2728
- 0.2732
- 0.272
- 0.2775
- 0.2758
- 0.2776
- 0.2759
- 0.2796
- 0.2799
- 0.2815
- 0.2838
- 0.286
- 0.2854
- 0.2852
- 0.2825
- 0.2779
- 0.2768
- 0.2831
- 0.2848
- 0.2873
- 0.2892
- 0.2834
- 0.2899
- 0.2873
- 0.2895
- 0.2882
- 0.2924
- 0.2931
- 0.2948
- 0.2944
- 0.293
- 0.2913
- 0.295
- 0.2905
- 0.2978
- 0.3005
- 0.2954
- 0.2819
- 0.2924
- 0.2943
- 0.2952
- 0.2985
- 0.2925
- 0.2948
- 0.2807
- 0.3052
- 0.3079
- 0.2979
- 0.2935
- 0.2972
- 0.2973
- 0.2983
- 0.2975
test_loss_list:
- 1.8232005214691163
- 1.6847667026519775
- 1.627048659324646
- 1.5924325728416442
- 1.5487795424461366
- 1.531905152797699
- 1.4998687529563903
- 1.4796100401878356
- 1.4632591104507446
- 1.4416552042961122
- 1.4323018240928649
- 1.4242941427230835
- 1.4068079829216003
- 1.4096792006492616
- 1.3780012702941895
- 1.3750751662254332
- 1.3661552333831788
- 1.3586602783203126
- 1.345957419872284
- 1.3459201097488402
- 1.343713366985321
- 1.3231271338462829
- 1.3284994745254517
- 1.3035771298408507
- 1.3129449248313905
- 1.313696973323822
- 1.2955710887908936
- 1.321991858482361
- 1.2990634751319885
- 1.2941445684432984
- 1.293117609024048
- 1.2708919167518615
- 1.2725629782676697
- 1.2760777640342713
- 1.2608419060707092
- 1.254728879928589
- 1.250774049758911
- 1.254216856956482
- 1.252966547012329
- 1.2520819687843323
- 1.2658225345611571
- 1.2384183764457704
- 1.2530930995941163
- 1.2378888893127442
- 1.2350257062911987
- 1.236736261844635
- 1.246187994480133
- 1.2394928526878357
- 1.241912579536438
- 1.2267122459411621
- 1.2089337682724
- 1.2116475486755371
- 1.206681616306305
- 1.210070264339447
- 1.2096451354026794
- 1.210205466747284
- 1.2026048660278321
- 1.201447970867157
- 1.2002633714675903
- 1.217902147769928
- 1.1983884263038636
- 1.209468216896057
- 1.213979995250702
- 1.2008880186080932
- 1.206948721408844
- 1.2032449507713319
- 1.2053265810012816
- 1.2059689021110536
- 1.1995856833457947
- 1.1945418953895568
- 1.20729487657547
- 1.2109736442565917
- 1.193301067352295
- 1.1944862771034241
- 1.1887004995346069
- 1.1898052453994752
- 1.1948717641830444
- 1.1998212695121766
- 1.2088932299613953
- 1.1914180135726928
- 1.1879945135116576
- 1.196141221523285
- 1.1903831219673158
- 1.187672028541565
- 1.221740756034851
- 1.2000246238708496
- 1.2001449537277222
- 1.1957575941085816
- 1.1878826451301574
- 1.2009904956817627
- 1.1940541648864746
- 1.230645706653595
- 1.1795393896102906
- 1.1901583552360535
- 1.183964991569519
- 1.2020707988739014
- 1.1958018517494202
- 1.1990499687194824
- 1.1920944356918335
- 1.201526279449463
train_accuracy:
- 0.012
- 0.086
- 0.103
- 0.113
- 0.112
- 0.112
- 0.04
- 0.145
- 0.181
- 0.137
- 0.18
- 0.183
- 0.167
- 0.185
- 0.214
- 0.042
- 0.201
- 0.209
- 0.208
- 0.189
- 0.227
- 0.202
- 0.031
- 0.011
- 0.192
- 0.225
- 0.208
- 0.167
- 0.077
- 0.228
- 0.192
- 0.246
- 0.215
- 0.279
- 0.028
- 0.01
- 0.071
- 0.241
- 0.212
- 0.224
- 0.254
- 0.251
- 0.24
- 0.27
- 0.298
- 0.262
- 0.258
- 0.259
- 0.248
- 0.284
- 0.223
- 0.271
- 0.225
- 0.112
- 0.283
- 0.295
- 0.032
- 0.289
- 0.287
- 0.233
- 0.043
- 0.275
- 0.273
- 0.295
- 0.273
- 0.299
- 0.296
- 0.036
- 0.284
- 0.295
- 0.224
- 0.288
- 0.233
- 0.178
- 0.079
- 0.026
- 0.282
- 0.032
- 0.304
- 0.057
- 0.111
- 0.265
- 0.291
- 0.286
- 0.13
- 0.312
- 0.104
- 0.242
- 0.065
- 0.23
- 0.026
- 0.282
- 0.172
- 0.328
- 0.3
- 0.085
- 0.287
- 0.104
- 0.336
- 0.288
train_loss:
- 2.851
- 3.286
- 3.035
- 2.329
- 2.299
- 2.237
- 2.707
- 2.621
- 2.526
- 1.993
- 1.94
- 1.842
- 2.388
- 2.74
- 1.311
- 2.282
- 1.687
- 1.673
- 2.092
- 1.995
- 1.52
- 2.024
- 1.918
- 1.46
- 1.406
- 1.331
- 1.427
- 1.002
- 1.312
- 1.661
- 1.651
- 1.374
- 1.256
- 1.893
- 0.88
- 1.457
- 1.52
- 1.387
- 1.376
- 1.376
- 1.612
- 1.091
- 1.583
- 1.037
- 1.181
- 1.186
- 1.362
- 1.178
- 1.099
- 0.894
- 0.946
- 1.039
- 0.891
- 0.821
- 0.941
- 1.032
- 0.77
- 0.934
- 0.855
- 1.102
- 0.755
- 0.843
- 0.659
- 0.647
- 0.629
- 0.649
- 0.615
- 0.761
- 0.622
- 0.572
- 0.571
- 0.537
- 0.558
- 0.559
- 0.552
- 0.657
- 0.67
- 0.512
- 0.472
- 0.524
- 0.539
- 0.711
- 0.433
- 0.474
- 0.313
- 0.445
- 0.424
- 0.535
- 0.404
- 0.438
- 0.426
- 0.3
- 0.541
- 0.444
- 0.384
- 0.378
- 0.353
- 0.396
- 0.452
- 0.476
unequal: 0
verbose: 1
