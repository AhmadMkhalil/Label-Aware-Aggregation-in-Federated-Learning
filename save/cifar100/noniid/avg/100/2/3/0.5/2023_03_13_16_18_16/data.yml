avg_train_accuracy: 0.296
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0187
- 0.0587
- 0.0781
- 0.1161
- 0.1307
- 0.1368
- 0.1221
- 0.1599
- 0.1571
- 0.1673
- 0.1718
- 0.1892
- 0.1955
- 0.1991
- 0.2033
- 0.2051
- 0.2115
- 0.1966
- 0.2079
- 0.2189
- 0.2246
- 0.2272
- 0.2352
- 0.2258
- 0.2404
- 0.2384
- 0.2387
- 0.2321
- 0.2301
- 0.2474
- 0.2539
- 0.254
- 0.2501
- 0.2476
- 0.2515
- 0.2549
- 0.2377
- 0.2662
- 0.2624
- 0.2674
- 0.2607
- 0.2644
- 0.2708
- 0.276
- 0.2758
- 0.2624
- 0.2681
- 0.2799
- 0.2818
- 0.2793
- 0.2826
- 0.2883
- 0.2831
- 0.2789
- 0.2885
- 0.2924
- 0.2792
- 0.2922
- 0.2869
- 0.2839
- 0.2981
- 0.2851
- 0.2876
- 0.2916
- 0.287
- 0.2901
- 0.2952
- 0.2849
- 0.2766
- 0.2999
- 0.2977
- 0.2935
- 0.2945
- 0.2909
- 0.2937
- 0.307
- 0.2973
- 0.2982
- 0.2997
- 0.3058
- 0.3067
- 0.289
- 0.2967
- 0.2879
- 0.2949
- 0.3066
- 0.3047
- 0.3071
- 0.3101
- 0.2906
- 0.3103
- 0.3052
- 0.3078
- 0.3053
- 0.2911
- 0.3066
- 0.3066
- 0.2878
- 0.3094
- 0.3074
test_loss_list:
- 1.829443440437317
- 1.7033272314071655
- 1.6508543109893798
- 1.586885735988617
- 1.5551594924926757
- 1.538424894809723
- 1.5323956656455993
- 1.477587730884552
- 1.472363600730896
- 1.4536822605133057
- 1.4391199731826783
- 1.4155821228027343
- 1.4000879454612731
- 1.3907922172546388
- 1.3887271499633789
- 1.3855232667922974
- 1.3823211359977723
- 1.3636285638809205
- 1.3457707691192626
- 1.3381293797492981
- 1.3237475061416626
- 1.3244162750244142
- 1.3217748308181763
- 1.3174080967903137
- 1.2896862030029297
- 1.2952207517623902
- 1.2947009658813478
- 1.2888681936264037
- 1.2962266850471496
- 1.271824941635132
- 1.270399844646454
- 1.2783664560317993
- 1.2547732305526733
- 1.2674110412597657
- 1.2632800555229187
- 1.2475783467292785
- 1.2789402723312377
- 1.2327141523361207
- 1.229240620136261
- 1.2355399799346924
- 1.2432999229431152
- 1.2280177116394042
- 1.2227289509773254
- 1.23421217918396
- 1.2150028872489929
- 1.245221335887909
- 1.2234110140800476
- 1.22395001411438
- 1.207013669013977
- 1.218371067047119
- 1.2150294828414916
- 1.217267553806305
- 1.2123022317886352
- 1.214748842716217
- 1.1922223687171936
- 1.1878686928749085
- 1.2099293899536132
- 1.191019859313965
- 1.197629187107086
- 1.2076388549804689
- 1.1740757989883424
- 1.1975858402252197
- 1.191960563659668
- 1.1895579671859742
- 1.1868267154693604
- 1.1902976632118225
- 1.1879263138771057
- 1.1978961396217347
- 1.2211077737808227
- 1.173560345172882
- 1.1838935542106628
- 1.1889315843582153
- 1.1933748936653137
- 1.1889381337165832
- 1.1922250175476075
- 1.1712894535064697
- 1.1976768755912781
- 1.19892644405365
- 1.1756728887557983
- 1.1809867572784425
- 1.1811998677253723
- 1.199400587081909
- 1.1879855871200562
- 1.2183200550079345
- 1.1908719754219055
- 1.173743827342987
- 1.1856213784217835
- 1.1796455454826356
- 1.1852919673919677
- 1.2028075933456421
- 1.1733842873573304
- 1.1834871673583984
- 1.1695169401168823
- 1.1760102415084839
- 1.2150170254707335
- 1.178912808895111
- 1.1840723657608032
- 1.2212654590606689
- 1.1770152831077576
- 1.1775820517539979
train_accuracy:
- 0.014
- 0.426
- 0.061
- 0.11
- 0.135
- 0.126
- 0.367
- 0.08
- 0.155
- 0.174
- 0.158
- 0.07
- 0.208
- 0.206
- 0.196
- 0.22
- 0.216
- 0.014
- 0.223
- 0.234
- 0.21
- 0.226
- 0.114
- 0.238
- 0.237
- 0.214
- 0.165
- 0.022
- 0.124
- 0.23
- 0.274
- 0.244
- 0.037
- 0.078
- 0.101
- 0.269
- 0.241
- 0.034
- 0.166
- 0.156
- 0.265
- 0.241
- 0.301
- 0.285
- 0.077
- 0.22
- 0.287
- 0.253
- 0.116
- 0.266
- 0.174
- 0.308
- 0.008
- 0.101
- 0.26
- 0.26
- 0.264
- 0.103
- 0.249
- 0.245
- 0.286
- 0.274
- 0.268
- 0.286
- 0.269
- 0.269
- 0.12
- 0.21
- 0.233
- 0.317
- 0.254
- 0.255
- 0.277
- 0.125
- 0.154
- 0.283
- 0.09
- 0.255
- 0.096
- 0.305
- 0.116
- 0.176
- 0.318
- 0.206
- 0.279
- 0.327
- 0.268
- 0.107
- 0.274
- 0.122
- 0.152
- 0.06
- 0.266
- 0.325
- 0.271
- 0.327
- 0.194
- 0.242
- 0.315
- 0.296
train_loss:
- 2.737
- 2.543
- 2.412
- 2.985
- 2.776
- 2.1
- 1.498
- 2.575
- 1.923
- 2.418
- 1.866
- 2.368
- 2.273
- 2.226
- 2.141
- 2.096
- 2.035
- 1.164
- 1.556
- 1.902
- 1.874
- 1.868
- 1.833
- 1.389
- 1.767
- 1.671
- 1.318
- 1.299
- 1.214
- 1.572
- 1.528
- 1.498
- 1.174
- 1.108
- 1.107
- 1.147
- 0.772
- 1.349
- 1.039
- 1.245
- 1.011
- 0.971
- 1.17
- 1.412
- 0.924
- 0.691
- 0.841
- 1.349
- 0.842
- 0.993
- 0.919
- 1.225
- 0.966
- 0.725
- 0.974
- 0.933
- 0.558
- 0.932
- 0.726
- 0.627
- 0.871
- 0.582
- 0.669
- 0.763
- 0.595
- 0.649
- 0.626
- 0.588
- 0.407
- 0.747
- 0.611
- 0.544
- 0.572
- 0.477
- 0.491
- 0.731
- 0.517
- 0.478
- 0.479
- 0.696
- 0.613
- 0.313
- 0.511
- 0.348
- 0.462
- 0.546
- 0.483
- 0.535
- 0.514
- 0.342
- 0.508
- 0.396
- 0.474
- 0.359
- 0.289
- 0.363
- 0.348
- 0.248
- 0.426
- 0.326
unequal: 0
verbose: 1
