avg_train_accuracy: 0.317
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0185
- 0.0487
- 0.0742
- 0.1101
- 0.1009
- 0.1361
- 0.1453
- 0.1483
- 0.1525
- 0.158
- 0.1747
- 0.1806
- 0.189
- 0.1987
- 0.2019
- 0.2059
- 0.2163
- 0.2176
- 0.2214
- 0.2228
- 0.2268
- 0.2217
- 0.2332
- 0.2297
- 0.2352
- 0.2327
- 0.2345
- 0.2491
- 0.2465
- 0.2492
- 0.25
- 0.2509
- 0.2535
- 0.2467
- 0.2503
- 0.2492
- 0.2594
- 0.265
- 0.2568
- 0.258
- 0.2628
- 0.264
- 0.2723
- 0.2694
- 0.2636
- 0.2515
- 0.2729
- 0.2717
- 0.2632
- 0.2689
- 0.2708
- 0.2676
- 0.2608
- 0.2768
- 0.2754
- 0.286
- 0.286
- 0.2779
- 0.2862
- 0.2875
- 0.2843
- 0.2723
- 0.2863
- 0.2874
- 0.2906
- 0.2756
- 0.2886
- 0.2875
- 0.2903
- 0.294
- 0.2884
- 0.2739
- 0.2829
- 0.291
- 0.2959
- 0.2873
- 0.2926
- 0.2939
- 0.2956
- 0.2939
- 0.2934
- 0.2996
- 0.2986
- 0.2981
- 0.3012
- 0.3003
- 0.2973
- 0.3017
- 0.3032
- 0.2991
- 0.3035
- 0.3004
- 0.3009
- 0.2968
- 0.2967
- 0.3007
- 0.3061
- 0.3039
- 0.3038
- 0.3118
test_loss_list:
- 1.840139775276184
- 1.7264995193481445
- 1.659552025794983
- 1.5945219945907594
- 1.5808869075775147
- 1.5417200350761413
- 1.515202910900116
- 1.4826080870628358
- 1.476646478176117
- 1.460205683708191
- 1.4319933223724366
- 1.4319653558731078
- 1.42282555103302
- 1.4121531963348388
- 1.4017165088653565
- 1.3862510633468628
- 1.3776564621925353
- 1.355571551322937
- 1.3629545617103576
- 1.3330788278579713
- 1.3359894728660584
- 1.3214668607711793
- 1.3105818033218384
- 1.3086496996879577
- 1.3033613872528076
- 1.3003972864151
- 1.2901249051094055
- 1.2862258124351502
- 1.279779839515686
- 1.2734444665908813
- 1.2688880014419555
- 1.2754896903038024
- 1.2666617918014527
- 1.2741611671447755
- 1.2709536385536193
- 1.2641219425201415
- 1.2674817442893982
- 1.2582783246040343
- 1.2535976123809816
- 1.2388760256767273
- 1.2377657675743103
- 1.2391458249092102
- 1.228829004764557
- 1.23414204120636
- 1.2461017322540284
- 1.2438893032073974
- 1.2171304941177368
- 1.221345570087433
- 1.2281487846374513
- 1.2203098678588866
- 1.2112191343307495
- 1.2277980399131776
- 1.236331307888031
- 1.2168116927146913
- 1.220588619709015
- 1.2219239568710327
- 1.2118301129341125
- 1.2254590749740601
- 1.2066257452964784
- 1.2160416293144225
- 1.2035542130470276
- 1.210327091217041
- 1.1929160022735597
- 1.1939822959899902
- 1.185682008266449
- 1.2106258487701416
- 1.1841298031806946
- 1.189168336391449
- 1.184968695640564
- 1.1868030095100404
- 1.1816476964950562
- 1.2090328049659729
- 1.1888940048217773
- 1.190162696838379
- 1.1875604724884032
- 1.1958978152275086
- 1.1800496315956115
- 1.1870218086242676
- 1.1861812806129455
- 1.1880579710006713
- 1.180643720626831
- 1.1850829648971557
- 1.1675508832931518
- 1.1824766993522644
- 1.179563500881195
- 1.1770626854896546
- 1.1744959664344787
- 1.1856804823875426
- 1.1758331227302552
- 1.1900680780410766
- 1.1828473973274232
- 1.1994812178611756
- 1.1800369572639466
- 1.1934771275520324
- 1.1768247961997986
- 1.1821075081825256
- 1.173380823135376
- 1.1820070385932921
- 1.179315719604492
- 1.179092650413513
train_accuracy:
- 0.145
- 0.326
- 0.072
- 0.096
- 0.493
- 0.115
- 0.163
- 0.184
- 0.128
- 0.183
- 0.19
- 0.018
- 0.187
- 0.196
- 0.202
- 0.206
- 0.191
- 0.244
- 0.243
- 0.021
- 0.021
- 0.002
- 0.006
- 0.021
- 0.248
- 0.176
- 0.156
- 0.244
- 0.184
- 0.257
- 0.028
- 0.102
- 0.181
- 0.033
- 0.198
- 0.191
- 0.259
- 0.248
- 0.253
- 0.236
- 0.124
- 0.231
- 0.251
- 0.268
- 0.19
- 0.009
- 0.287
- 0.214
- 0.323
- 0.262
- 0.251
- 0.187
- 0.235
- 0.289
- 0.251
- 0.308
- 0.301
- 0.091
- 0.316
- 0.315
- 0.066
- 0.273
- 0.191
- 0.295
- 0.309
- 0.247
- 0.074
- 0.297
- 0.293
- 0.267
- 0.233
- 0.249
- 0.273
- 0.289
- 0.289
- 0.085
- 0.304
- 0.257
- 0.241
- 0.28
- 0.239
- 0.079
- 0.293
- 0.326
- 0.288
- 0.269
- 0.296
- 0.319
- 0.104
- 0.309
- 0.059
- 0.251
- 0.257
- 0.246
- 0.275
- 0.113
- 0.294
- 0.324
- 0.292
- 0.317
train_loss:
- 2.868
- 2.604
- 2.439
- 3.077
- 1.695
- 3.413
- 2.682
- 2.108
- 2.022
- 1.913
- 2.527
- 2.387
- 2.355
- 2.731
- 2.206
- 2.141
- 2.539
- 2.08
- 2.375
- 1.584
- 1.93
- 1.502
- 1.825
- 1.481
- 1.409
- 1.333
- 1.343
- 1.725
- 1.306
- 1.586
- 1.324
- 1.226
- 1.486
- 1.177
- 1.456
- 1.191
- 1.689
- 1.476
- 1.05
- 1.02
- 1.087
- 1.08
- 1.296
- 1.198
- 0.925
- 0.702
- 1.204
- 1.16
- 0.671
- 0.853
- 0.852
- 0.77
- 0.695
- 1.216
- 0.971
- 1.21
- 1.039
- 0.854
- 0.905
- 1.092
- 0.69
- 0.544
- 0.749
- 0.876
- 0.806
- 0.458
- 0.803
- 0.634
- 0.583
- 0.833
- 0.566
- 0.389
- 0.52
- 0.743
- 0.771
- 0.446
- 0.673
- 0.655
- 0.64
- 0.506
- 0.573
- 0.639
- 0.53
- 0.567
- 0.582
- 0.479
- 0.447
- 0.643
- 0.44
- 0.576
- 0.516
- 0.527
- 0.357
- 0.37
- 0.386
- 0.465
- 0.444
- 0.403
- 0.445
- 0.443
unequal: 0
verbose: 1
