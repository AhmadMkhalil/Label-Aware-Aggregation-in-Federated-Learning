avg_train_accuracy: 0.024
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0265
- 0.0405
- 0.0965
- 0.1061
- 0.1234
- 0.1372
- 0.1454
- 0.152
- 0.1633
- 0.1629
- 0.1754
- 0.182
- 0.1896
- 0.1867
- 0.1893
- 0.1904
- 0.1968
- 0.1899
- 0.1795
- 0.2008
- 0.2064
- 0.2132
- 0.2211
- 0.2209
- 0.2298
- 0.2233
- 0.2325
- 0.2294
- 0.221
- 0.2299
- 0.241
- 0.2406
- 0.2448
- 0.2302
- 0.2519
- 0.2533
- 0.2509
- 0.2501
- 0.2546
- 0.2629
- 0.2671
- 0.2622
- 0.2635
- 0.2678
- 0.2706
- 0.2734
- 0.2782
- 0.2765
- 0.2725
- 0.2782
- 0.2712
- 0.2796
- 0.2817
- 0.2798
- 0.2813
- 0.2864
- 0.2817
- 0.2797
- 0.2894
- 0.288
- 0.2849
- 0.2823
- 0.2874
- 0.2925
- 0.2882
- 0.2908
- 0.2886
- 0.2898
- 0.2935
- 0.2959
- 0.2936
- 0.2781
- 0.2993
- 0.297
- 0.2973
- 0.3019
- 0.2989
- 0.3007
- 0.3028
- 0.2997
- 0.2974
- 0.3039
- 0.2996
- 0.3023
- 0.299
- 0.3008
- 0.308
- 0.3001
- 0.3061
- 0.2971
- 0.2986
- 0.3039
- 0.3033
- 0.3021
- 0.3028
- 0.303
- 0.305
- 0.3001
- 0.3063
- 0.3044
test_loss_list:
- 1.8316472625732423
- 1.7510608100891114
- 1.6388688707351684
- 1.6045552253723145
- 1.5621385788917541
- 1.5269074630737305
- 1.5112167167663575
- 1.4846141576766967
- 1.466018433570862
- 1.4602943062782288
- 1.4413548803329468
- 1.4317977261543273
- 1.4312196850776673
- 1.4149655938148498
- 1.3820572423934936
- 1.3809249711036682
- 1.3766087150573731
- 1.3771355104446412
- 1.395292146205902
- 1.3626541686058045
- 1.35747088432312
- 1.3398645448684692
- 1.3311476707458496
- 1.313902246952057
- 1.3100405287742616
- 1.3192861008644103
- 1.3057217192649841
- 1.3054919528961182
- 1.3195277547836304
- 1.2962730813026428
- 1.2951054549217225
- 1.2811925292015076
- 1.2732075929641724
- 1.300843164920807
- 1.2684426355361937
- 1.2600336289405822
- 1.267586531639099
- 1.2582806587219237
- 1.2516814184188843
- 1.2436225128173828
- 1.245191843509674
- 1.2469555234909058
- 1.2394927549362182
- 1.2268972659111024
- 1.2426834225654602
- 1.226103744506836
- 1.2179579615592957
- 1.2226970815658569
- 1.2266857051849365
- 1.2237510037422181
- 1.2194911074638366
- 1.2104975867271424
- 1.2030573534965514
- 1.216846194267273
- 1.2043526315689086
- 1.2063084864616394
- 1.2032999205589294
- 1.2151361870765687
- 1.1957835054397583
- 1.1970188164710998
- 1.1970514702796935
- 1.199658465385437
- 1.1960452747344972
- 1.210877182483673
- 1.2279815220832824
- 1.196119291782379
- 1.1952760934829711
- 1.200597596168518
- 1.1854582381248475
- 1.188667697906494
- 1.1862636017799377
- 1.2211058115959168
- 1.1772651815414428
- 1.1853879261016846
- 1.199472713470459
- 1.2087118864059447
- 1.194550461769104
- 1.1782145929336547
- 1.1949202513694763
- 1.1966272568702698
- 1.2027508640289306
- 1.2124326753616332
- 1.1872156953811646
- 1.2034802746772766
- 1.1958183884620666
- 1.1759800720214844
- 1.1846201252937316
- 1.2001605606079102
- 1.18849552154541
- 1.1987304496765137
- 1.19004385471344
- 1.1875299859046935
- 1.181878080368042
- 1.1959342098236083
- 1.1951353335380555
- 1.1986898064613343
- 1.1970419573783875
- 1.2024040699005127
- 1.2072029066085816
- 1.1985032892227172
train_accuracy:
- 0.013
- 0.351
- 0.107
- 0.108
- 0.084
- 0.124
- 0.163
- 0.154
- 0.151
- 0.155
- 0.144
- 0.186
- 0.166
- 0.179
- 0.169
- 0.043
- 0.193
- 0.175
- 0.169
- 0.192
- 0.13
- 0.22
- 0.228
- 0.204
- 0.09
- 0.209
- 0.241
- 0.116
- 0.207
- 0.275
- 0.034
- 0.217
- 0.224
- 0.203
- 0.032
- 0.218
- 0.017
- 0.06
- 0.085
- 0.227
- 0.271
- 0.006
- 0.253
- 0.242
- 0.254
- 0.245
- 0.258
- 0.251
- 0.259
- 0.009
- 0.116
- 0.065
- 0.265
- 0.269
- 0.263
- 0.28
- 0.271
- 0.269
- 0.277
- 0.278
- 0.257
- 0.27
- 0.017
- 0.274
- 0.273
- 0.059
- 0.265
- 0.274
- 0.077
- 0.133
- 0.294
- 0.265
- 0.311
- 0.067
- 0.296
- 0.277
- 0.301
- 0.019
- 0.298
- 0.297
- 0.283
- 0.287
- 0.289
- 0.32
- 0.036
- 0.322
- 0.316
- 0.282
- 0.176
- 0.283
- 0.258
- 0.317
- 0.277
- 0.29
- 0.279
- 0.309
- 0.03
- 0.295
- 0.299
- 0.024
train_loss:
- 2.801
- 1.908
- 3.188
- 2.398
- 2.865
- 2.809
- 2.725
- 2.07
- 2.524
- 1.941
- 2.396
- 2.325
- 2.753
- 2.267
- 1.836
- 1.753
- 2.116
- 1.217
- 1.175
- 1.55
- 1.511
- 1.967
- 1.895
- 1.544
- 1.828
- 1.348
- 1.803
- 1.365
- 0.946
- 1.312
- 1.675
- 1.238
- 1.269
- 0.889
- 1.605
- 1.496
- 1.13
- 1.137
- 1.155
- 1.343
- 1.312
- 1.276
- 1.355
- 1.026
- 1.544
- 0.998
- 1.151
- 1.159
- 1.101
- 1.122
- 0.686
- 0.882
- 1.058
- 0.828
- 0.857
- 1.078
- 0.775
- 0.997
- 0.953
- 0.785
- 0.727
- 0.72
- 0.909
- 1.031
- 0.936
- 0.684
- 0.703
- 0.619
- 0.649
- 0.757
- 0.605
- 0.412
- 0.735
- 0.622
- 0.813
- 0.787
- 0.652
- 0.537
- 0.728
- 0.578
- 0.584
- 0.682
- 0.498
- 0.633
- 0.445
- 0.576
- 0.504
- 0.381
- 0.486
- 0.369
- 0.421
- 0.457
- 0.441
- 0.468
- 0.392
- 0.452
- 0.417
- 0.38
- 0.485
- 0.361
unequal: 0
verbose: 1
