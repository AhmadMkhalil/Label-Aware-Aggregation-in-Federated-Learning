avg_train_accuracy: 0.248
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0451
- 0.0904
- 0.1019
- 0.1124
- 0.1045
- 0.1437
- 0.1568
- 0.1621
- 0.1551
- 0.1715
- 0.1752
- 0.1785
- 0.1837
- 0.1901
- 0.19
- 0.1981
- 0.2003
- 0.2102
- 0.2145
- 0.2146
- 0.2191
- 0.2217
- 0.2251
- 0.2331
- 0.2239
- 0.2358
- 0.2424
- 0.241
- 0.2451
- 0.2478
- 0.2385
- 0.2483
- 0.2472
- 0.2352
- 0.2542
- 0.2475
- 0.2541
- 0.2525
- 0.2576
- 0.2456
- 0.2609
- 0.2634
- 0.2641
- 0.2623
- 0.2692
- 0.2609
- 0.2529
- 0.2644
- 0.2692
- 0.268
- 0.2734
- 0.2751
- 0.2725
- 0.2786
- 0.2837
- 0.2763
- 0.2777
- 0.2763
- 0.2761
- 0.2789
- 0.2656
- 0.2835
- 0.2809
- 0.2861
- 0.2908
- 0.2912
- 0.2956
- 0.2914
- 0.2877
- 0.2926
- 0.2875
- 0.2898
- 0.2934
- 0.2883
- 0.2932
- 0.2883
- 0.2896
- 0.2973
- 0.2956
- 0.2958
- 0.2968
- 0.2944
- 0.2949
- 0.2918
- 0.2931
- 0.2873
- 0.2994
- 0.2938
- 0.2951
- 0.3012
- 0.2943
- 0.2948
- 0.2959
- 0.302
- 0.2997
- 0.2999
- 0.298
- 0.2995
- 0.2928
- 0.3021
test_loss_list:
- 1.7900672912597657
- 1.6670149612426757
- 1.609033854007721
- 1.5773991179466247
- 1.584633481502533
- 1.5216831398010253
- 1.5065870428085326
- 1.4867290544509888
- 1.4681740593910217
- 1.4383979630470276
- 1.4354226851463319
- 1.4126440167427063
- 1.4126289248466493
- 1.3937632274627685
- 1.39613600730896
- 1.374309136867523
- 1.3754389047622682
- 1.3524612021446227
- 1.3625583362579345
- 1.3564135694503785
- 1.3383857035636901
- 1.3273637700080871
- 1.3255990290641784
- 1.3243983793258667
- 1.307200689315796
- 1.3008404779434204
- 1.3074435687065125
- 1.300579707622528
- 1.3069919872283935
- 1.2895872020721435
- 1.2839070916175843
- 1.2768191599845886
- 1.2738986039161682
- 1.29234836101532
- 1.2593702673912048
- 1.2675622725486755
- 1.247672667503357
- 1.250390543937683
- 1.2524186706542968
- 1.2680362486839294
- 1.2334371972084046
- 1.2390114188194274
- 1.2426037192344666
- 1.243120493888855
- 1.2222280430793762
- 1.2351505088806152
- 1.261478352546692
- 1.2289642405509948
- 1.219457712173462
- 1.2273062872886658
- 1.2226663827896118
- 1.2345060515403747
- 1.2208156871795655
- 1.2072377276420594
- 1.217226092815399
- 1.2266322875022888
- 1.2203038597106934
- 1.2327851963043213
- 1.199215362071991
- 1.2062990140914918
- 1.2289004516601563
- 1.2046967458724975
- 1.2057911491394042
- 1.1940750193595886
- 1.1895041394233703
- 1.1978865575790405
- 1.1985326957702638
- 1.2107054257392884
- 1.215704438686371
- 1.1921290707588197
- 1.1928994512557984
- 1.1901801872253417
- 1.1883163189888
- 1.1848745250701904
- 1.1816939878463746
- 1.197879512310028
- 1.1949204397201538
- 1.1743870949745179
- 1.182242407798767
- 1.1990724277496339
- 1.1972857737541198
- 1.1876288199424743
- 1.18004625082016
- 1.1889407014846802
- 1.1828740191459657
- 1.2037884569168091
- 1.1745154356956482
- 1.181246964931488
- 1.1809168648719788
- 1.173208532333374
- 1.1944145154953003
- 1.1821148848533631
- 1.1862334489822388
- 1.1797257518768312
- 1.187667636871338
- 1.1895633912086487
- 1.1843626928329467
- 1.1800796723365783
- 1.2045332193374634
- 1.1779008841514587
train_accuracy:
- 0.037
- 0.107
- 0.094
- 0.084
- 0.038
- 0.128
- 0.16
- 0.059
- 0.001
- 0.166
- 0.008
- 0.021
- 0.278
- 0.18
- 0.09
- 0.034
- 0.061
- 0.193
- 0.2
- 0.21
- 0.227
- 0.226
- 0.223
- 0.211
- 0.216
- 0.025
- 0.238
- 0.029
- 0.225
- 0.231
- 0.111
- 0.269
- 0.027
- 0.206
- 0.251
- 0.21
- 0.237
- 0.227
- 0.239
- 0.221
- 0.242
- 0.235
- 0.244
- 0.019
- 0.085
- 0.269
- 0.169
- 0.253
- 0.225
- 0.186
- 0.127
- 0.264
- 0.239
- 0.097
- 0.267
- 0.287
- 0.237
- 0.254
- 0.257
- 0.071
- 0.227
- 0.256
- 0.255
- 0.101
- 0.255
- 0.253
- 0.126
- 0.295
- 0.267
- 0.291
- 0.009
- 0.284
- 0.289
- 0.198
- 0.28
- 0.21
- 0.251
- 0.184
- 0.12
- 0.25
- 0.261
- 0.286
- 0.192
- 0.275
- 0.066
- 0.154
- 0.097
- 0.152
- 0.272
- 0.295
- 0.283
- 0.112
- 0.342
- 0.312
- 0.256
- 0.297
- 0.312
- 0.304
- 0.054
- 0.248
train_loss:
- 4.275
- 3.152
- 2.405
- 2.287
- 1.546
- 2.773
- 3.258
- 2.566
- 1.436
- 2.455
- 2.388
- 1.857
- 1.791
- 2.264
- 1.685
- 1.669
- 1.639
- 2.109
- 2.438
- 1.942
- 1.887
- 1.877
- 1.762
- 1.803
- 1.419
- 1.704
- 2.005
- 1.632
- 1.965
- 1.613
- 0.885
- 1.791
- 1.158
- 0.767
- 1.414
- 1.073
- 1.067
- 1.069
- 1.319
- 0.719
- 1.306
- 1.047
- 0.956
- 1.229
- 0.956
- 1.006
- 0.732
- 0.883
- 0.904
- 0.839
- 1.004
- 1.244
- 0.73
- 0.977
- 0.991
- 1.084
- 0.739
- 0.658
- 0.769
- 0.763
- 0.507
- 1.068
- 0.694
- 0.736
- 0.783
- 0.811
- 0.806
- 0.921
- 0.872
- 0.642
- 0.557
- 0.564
- 0.604
- 0.558
- 0.654
- 0.519
- 0.616
- 0.518
- 0.598
- 0.69
- 0.542
- 0.637
- 0.442
- 0.457
- 0.545
- 0.397
- 0.544
- 0.418
- 0.491
- 0.488
- 0.388
- 0.368
- 0.462
- 0.464
- 0.363
- 0.519
- 0.429
- 0.407
- 0.297
- 0.347
unequal: 0
verbose: 1
