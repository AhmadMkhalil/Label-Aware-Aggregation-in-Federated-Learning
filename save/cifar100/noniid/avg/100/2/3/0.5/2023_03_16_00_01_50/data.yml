avg_train_accuracy: 0.272
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0376
- 0.0859
- 0.0913
- 0.1051
- 0.1215
- 0.1421
- 0.1407
- 0.1537
- 0.166
- 0.1664
- 0.1795
- 0.1918
- 0.1947
- 0.1986
- 0.2043
- 0.1961
- 0.208
- 0.2171
- 0.2179
- 0.2272
- 0.2284
- 0.2315
- 0.2378
- 0.2359
- 0.2218
- 0.2335
- 0.2441
- 0.2451
- 0.2492
- 0.2493
- 0.2444
- 0.2527
- 0.259
- 0.253
- 0.2588
- 0.2612
- 0.2592
- 0.2697
- 0.2673
- 0.2718
- 0.2736
- 0.2715
- 0.2705
- 0.2623
- 0.2729
- 0.2715
- 0.2719
- 0.2732
- 0.2733
- 0.2792
- 0.2795
- 0.2842
- 0.2824
- 0.2781
- 0.2785
- 0.2774
- 0.2868
- 0.283
- 0.2843
- 0.284
- 0.2877
- 0.2873
- 0.2835
- 0.2891
- 0.2759
- 0.2872
- 0.2895
- 0.2938
- 0.2949
- 0.2989
- 0.2971
- 0.2984
- 0.2971
- 0.2964
- 0.2892
- 0.2976
- 0.2927
- 0.2973
- 0.2916
- 0.2925
- 0.2944
- 0.3018
- 0.2946
- 0.2996
- 0.2971
- 0.2944
- 0.2987
- 0.2936
- 0.301
- 0.3012
- 0.299
- 0.3024
- 0.3024
- 0.3043
- 0.2993
- 0.2986
- 0.2996
- 0.2987
- 0.2965
- 0.2975
test_loss_list:
- 1.7867709827423095
- 1.6705856227874756
- 1.6362636995315551
- 1.5993586158752442
- 1.5438846254348755
- 1.5166634130477905
- 1.5047387981414795
- 1.4776643228530884
- 1.4607954573631288
- 1.4484175086021422
- 1.4270979690551757
- 1.4239435195922852
- 1.408819694519043
- 1.397309331893921
- 1.377646656036377
- 1.380106885433197
- 1.3579979681968688
- 1.348938021659851
- 1.3399323844909667
- 1.3329955005645753
- 1.324281644821167
- 1.3182028317451477
- 1.324691641330719
- 1.308508722782135
- 1.32192435503006
- 1.2977012300491333
- 1.2847825932502746
- 1.2849564957618713
- 1.288059685230255
- 1.2812682962417603
- 1.2873421669006349
- 1.2562153291702272
- 1.2651088285446166
- 1.255430142879486
- 1.26401713848114
- 1.2611137652397155
- 1.2520913767814636
- 1.2314829277992247
- 1.2402073454856872
- 1.23782310962677
- 1.2327023100852967
- 1.242523624897003
- 1.2231990480422974
- 1.235992443561554
- 1.2181001162528993
- 1.2229496264457702
- 1.2208454966545106
- 1.2189830112457276
- 1.2184803223609924
- 1.2016476941108705
- 1.207692139148712
- 1.2056264615058898
- 1.2160282635688782
- 1.2219065093994141
- 1.2047637724876403
- 1.2091631627082824
- 1.19594078540802
- 1.2059183597564698
- 1.1910463380813598
- 1.1934829020500184
- 1.193163652420044
- 1.188836200237274
- 1.2044742226600647
- 1.1903706622123718
- 1.2235332250595092
- 1.1945449924468994
- 1.1847854685783386
- 1.1943340015411377
- 1.1889447617530822
- 1.1859817695617676
- 1.1974628400802612
- 1.1759448838233948
- 1.183756856918335
- 1.1879065585136415
- 1.1897745156288146
- 1.1792824983596801
- 1.1871640157699586
- 1.1827837347984314
- 1.200979290008545
- 1.1825439453125
- 1.182273540496826
- 1.1876833534240723
- 1.1813161206245422
- 1.1780656599998474
- 1.1770215582847596
- 1.190420799255371
- 1.1782971668243407
- 1.1870346117019652
- 1.1927378940582276
- 1.1866309976577758
- 1.1919343161582947
- 1.179215166568756
- 1.180521502494812
- 1.1824241733551026
- 1.1863982748985291
- 1.1784358382225038
- 1.1777257561683654
- 1.1894003295898437
- 1.1813027596473693
- 1.1920124697685242
train_accuracy:
- 0.023
- 0.075
- 0.056
- 0.097
- 0.379
- 0.055
- 0.165
- 0.227
- 0.146
- 0.186
- 0.159
- 0.201
- 0.192
- 0.198
- 0.193
- 0.233
- 0.182
- 0.229
- 0.259
- 0.206
- 0.224
- 0.099
- 0.212
- 0.05
- 0.162
- 0.227
- 0.247
- 0.258
- 0.229
- 0.032
- 0.227
- 0.212
- 0.279
- 0.242
- 0.289
- 0.226
- 0.261
- 0.286
- 0.256
- 0.278
- 0.257
- 0.251
- 0.279
- 0.263
- 0.172
- 0.19
- 0.027
- 0.283
- 0.288
- 0.024
- 0.048
- 0.256
- 0.113
- 0.288
- 0.037
- 0.228
- 0.288
- 0.18
- 0.091
- 0.153
- 0.235
- 0.249
- 0.274
- 0.096
- 0.351
- 0.204
- 0.241
- 0.273
- 0.122
- 0.313
- 0.283
- 0.27
- 0.123
- 0.108
- 0.298
- 0.265
- 0.127
- 0.281
- 0.022
- 0.239
- 0.107
- 0.315
- 0.253
- 0.278
- 0.287
- 0.289
- 0.309
- 0.313
- 0.284
- 0.282
- 0.286
- 0.08
- 0.32
- 0.281
- 0.117
- 0.283
- 0.321
- 0.096
- 0.265
- 0.272
train_loss:
- 4.301
- 2.48
- 2.322
- 2.255
- 2.259
- 2.685
- 2.045
- 2.02
- 2.447
- 1.957
- 2.39
- 2.848
- 2.261
- 2.148
- 2.186
- 1.193
- 2.036
- 2.1
- 1.563
- 1.968
- 1.522
- 1.864
- 2.198
- 1.417
- 0.958
- 1.362
- 1.683
- 1.628
- 1.95
- 1.245
- 1.183
- 1.173
- 1.802
- 1.182
- 1.676
- 1.355
- 1.113
- 1.391
- 1.246
- 1.33
- 1.273
- 1.443
- 0.942
- 0.707
- 0.9
- 0.882
- 0.841
- 0.83
- 1.05
- 0.845
- 1.031
- 1.024
- 0.979
- 0.689
- 0.675
- 0.692
- 1.054
- 0.681
- 0.705
- 0.866
- 0.651
- 0.676
- 0.617
- 0.581
- 0.496
- 0.619
- 0.601
- 0.94
- 0.784
- 0.742
- 0.823
- 0.561
- 0.689
- 0.732
- 0.56
- 0.592
- 0.501
- 0.657
- 0.355
- 0.459
- 0.482
- 0.674
- 0.488
- 0.51
- 0.447
- 0.447
- 0.404
- 0.406
- 0.607
- 0.48
- 0.382
- 0.406
- 0.452
- 0.448
- 0.348
- 0.335
- 0.437
- 0.334
- 0.357
- 0.31
unequal: 0
verbose: 1
