avg_train_accuracy: 0.273
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.038
- 0.0888
- 0.1046
- 0.1132
- 0.1194
- 0.1404
- 0.1454
- 0.0186
- 0.0194
- 0.1513
- 0.1521
- 0.1619
- 0.1532
- 0.1645
- 0.1677
- 0.1718
- 0.1792
- 0.1783
- 0.1781
- 0.016
- 0.1899
- 0.2039
- 0.2005
- 0.0143
- 0.1949
- 0.0195
- 0.2024
- 0.0175
- 0.0187
- 0.2113
- 0.2184
- 0.218
- 0.2309
- 0.0196
- 0.0191
- 0.2288
- 0.0189
- 0.2283
- 0.23
- 0.0163
- 0.2333
- 0.0198
- 0.0143
- 0.2338
- 0.0174
- 0.0175
- 0.0197
- 0.0192
- 0.2328
- 0.2402
- 0.2302
- 0.0192
- 0.2302
- 0.2406
- 0.017
- 0.2366
- 0.2469
- 0.0176
- 0.0192
- 0.2474
- 0.2456
- 0.2491
- 0.0201
- 0.2546
- 0.2552
- 0.2487
- 0.2528
- 0.2603
- 0.2583
- 0.2548
- 0.2593
- 0.2604
- 0.2494
- 0.0199
- 0.2531
- 0.267
- 0.2639
- 0.27
- 0.0207
- 0.2773
- 0.2769
- 0.2676
- 0.2738
- 0.2666
- 0.0204
- 0.2803
- 0.2775
- 0.2838
- 0.0186
- 0.2766
- 0.2768
- 0.2871
- 0.2885
- 0.2784
- 0.0209
- 0.2834
- 0.29
- 0.2861
- 0.2942
- 0.2889
test_loss_list:
- 1.8196436071395874
- 1.7122183847427368
- 1.663517837524414
- 1.635131676197052
- 1.6220095205307006
- 1.5979990315437318
- 1.5833925890922547
- 4.613037347793579
- 4.742038106918335
- 1.555184578895569
- 1.551450731754303
- 1.5419037318229676
- 1.5566856932640076
- 1.5362495303153991
- 1.5402066278457642
- 1.516188654899597
- 1.5153084230422973
- 1.5190205240249635
- 1.514826250076294
- 4.450122957229614
- 1.4811836194992065
- 1.4561746406555176
- 1.4693259739875792
- 4.785336322784424
- 1.4754820847511292
- 4.621395101547241
- 1.4489492392539978
- 4.376846008300781
- 4.415731296539307
- 1.4140092658996581
- 1.395166256427765
- 1.3975375938415526
- 1.3781058740615846
- 4.646548547744751
- 4.316126766204834
- 1.3714176392555237
- 4.195980167388916
- 1.364292802810669
- 1.3766230511665345
- 4.359432191848755
- 1.3644183802604675
- 4.2986327648162845
- 4.70442400932312
- 1.36735089302063
- 4.332819356918335
- 4.439666137695313
- 4.304290523529053
- 4.253821220397949
- 1.3446184492111206
- 1.333412787914276
- 1.3605660676956177
- 4.12549599647522
- 1.352207942008972
- 1.3583371758460998
- 4.375467939376831
- 1.366434714794159
- 1.3420843005180358
- 4.19257438659668
- 4.118197746276856
- 1.3183979821205138
- 1.344201261997223
- 1.3460247349739074
- 4.246314630508423
- 1.3298543691635132
- 1.3167129921913148
- 1.3326825594902039
- 1.3352322793006897
- 1.324020230770111
- 1.3254321670532228
- 1.3491056632995606
- 1.363544192314148
- 1.3392517948150635
- 1.3870656204223633
- 4.259331712722778
- 1.3593718361854554
- 1.3326875829696656
- 1.3449411058425904
- 1.3236409163475036
- 4.06039945602417
- 1.3062964177131653
- 1.3117814350128174
- 1.3412897324562072
- 1.3212304139137268
- 1.3317192006111145
- 4.078600931167602
- 1.2946893167495728
- 1.3116317391395569
- 1.3081653642654418
- 4.156152334213257
- 1.3042138314247131
- 1.3108432054519654
- 1.2975511646270752
- 1.2941300344467164
- 1.3037700152397156
- 3.8414745140075683
- 1.2892439675331115
- 1.2825683760643005
- 1.2867503547668457
- 1.2751499581336976
- 1.302716805934906
train_accuracy:
- 0.031
- 0.092
- 0.087
- 0.116
- 0.121
- 0.146
- 0.142
- 0.872
- 0.938
- 0.123
- 0.144
- 0.129
- 0.152
- 0.166
- 0.175
- 0.146
- 0.171
- 0.155
- 0.171
- 0.935
- 0.186
- 0.192
- 0.206
- 0.513
- 0.21
- 0.965
- 0.181
- 0.839
- 0.871
- 0.185
- 0.208
- 0.221
- 0.244
- 0.994
- 0.881
- 0.197
- 0.878
- 0.25
- 0.245
- 0.697
- 0.233
- 0.975
- 0.515
- 0.222
- 0.86
- 0.893
- 0.982
- 0.935
- 0.225
- 0.239
- 0.224
- 0.922
- 0.241
- 0.234
- 0.787
- 0.231
- 0.219
- 0.831
- 0.929
- 0.241
- 0.245
- 0.239
- 0.99
- 0.242
- 0.269
- 0.264
- 0.236
- 0.26
- 0.255
- 0.24
- 0.269
- 0.285
- 0.26
- 0.986
- 0.266
- 0.27
- 0.256
- 0.275
- 0.989
- 0.278
- 0.263
- 0.27
- 0.291
- 0.258
- 0.942
- 0.295
- 0.255
- 0.27
- 0.905
- 0.258
- 0.235
- 0.269
- 0.271
- 0.274
- 0.96
- 0.245
- 0.265
- 0.268
- 0.284
- 0.273
train_loss:
- 4.294
- 3.852
- 3.69
- 3.52
- 3.333
- 3.083
- 3.308
- 0.614
- 0.783
- 3.569
- 2.918
- 2.781
- 2.6
- 2.995
- 2.513
- 2.536
- 2.274
- 2.174
- 2.365
- 0.861
- 3.008
- 2.829
- 2.308
- 0.633
- 2.293
- 0.483
- 2.381
- 0.537
- 0.774
- 2.624
- 2.624
- 2.158
- 2.444
- 0.385
- 0.736
- 2.054
- 0.393
- 2.244
- 1.469
- 0.519
- 2.352
- 0.342
- 0.686
- 1.832
- 0.379
- 0.082
- 0.587
- 0.652
- 2.403
- 1.887
- 1.669
- 0.355
- 1.548
- 1.562
- 0.379
- 1.411
- 2.035
- 0.324
- 0.575
- 1.828
- 1.081
- 1.625
- 0.353
- 1.251
- 1.815
- 1.249
- 1.461
- 1.386
- 0.975
- 0.661
- 0.519
- 1.236
- 0.831
- 0.309
- 2.356
- 0.828
- 1.295
- 1.558
- 0.272
- 1.518
- 0.988
- 0.656
- 1.309
- 1.216
- 0.389
- 1.089
- 1.023
- 0.779
- 0.42
- 0.677
- 1.395
- 0.802
- 0.501
- 0.934
- 0.293
- 1.294
- 0.648
- 0.875
- 0.468
- 0.499
unequal: 0
verbose: 1
