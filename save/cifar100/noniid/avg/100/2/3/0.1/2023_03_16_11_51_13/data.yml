avg_train_accuracy: 0.975
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0394
- 0.0843
- 0.0184
- 0.0986
- 0.1138
- 0.1267
- 0.1302
- 0.1475
- 0.0197
- 0.1628
- 0.1584
- 0.0182
- 0.1574
- 0.0168
- 0.1615
- 0.1692
- 0.1754
- 0.0189
- 0.1858
- 0.0179
- 0.1845
- 0.1868
- 0.1805
- 0.203
- 0.018
- 0.199
- 0.0199
- 0.193
- 0.2069
- 0.2158
- 0.2158
- 0.0189
- 0.0198
- 0.019
- 0.222
- 0.2134
- 0.2188
- 0.2243
- 0.2322
- 0.2288
- 0.2391
- 0.0198
- 0.223
- 0.0189
- 0.2395
- 0.019
- 0.2383
- 0.0187
- 0.0191
- 0.019
- 0.243
- 0.2387
- 0.2454
- 0.2493
- 0.2462
- 0.2513
- 0.2486
- 0.0198
- 0.0188
- 0.0198
- 0.0191
- 0.2522
- 0.248
- 0.2545
- 0.2569
- 0.2669
- 0.2581
- 0.2547
- 0.2566
- 0.2704
- 0.0189
- 0.2699
- 0.0193
- 0.2635
- 0.2737
- 0.2695
- 0.2594
- 0.2738
- 0.0199
- 0.2733
- 0.0202
- 0.2789
- 0.2676
- 0.2782
- 0.2643
- 0.2665
- 0.2785
- 0.0194
- 0.2748
- 0.2804
- 0.282
- 0.2778
- 0.0204
- 0.2808
- 0.0206
- 0.0198
- 0.2804
- 0.0214
- 0.021
- 0.02
test_loss_list:
- 1.8164086198806764
- 1.7201592922210693
- 4.5782762718200685
- 1.671984577178955
- 1.6367166209220887
- 1.6075199127197266
- 1.600909571647644
- 1.5751177191734314
- 4.781321630477906
- 1.5524910521507262
- 1.5576723861694335
- 4.483341932296753
- 1.5530478739738465
- 4.741528663635254
- 1.5340514779090881
- 1.5294663548469543
- 1.5108500719070435
- 4.414834718704224
- 1.4860108661651612
- 4.557635564804077
- 1.4882238507270813
- 1.4915827441215515
- 1.466138243675232
- 1.4581960701942445
- 4.586198444366455
- 1.4629356050491333
- 4.706748266220092
- 1.4778172326087953
- 1.435403244495392
- 1.4197948741912843
- 1.4084479379653931
- 4.49980299949646
- 4.620075902938843
- 4.262628660202027
- 1.371337764263153
- 1.39092205286026
- 1.386134991645813
- 1.3889043784141542
- 1.3768729186058044
- 1.3898807525634767
- 1.382479748725891
- 4.469315242767334
- 1.3653417038917541
- 4.232773904800415
- 1.3644318175315857
- 4.097390346527099
- 1.3562001204490661
- 4.409222249984741
- 4.124576253890991
- 4.156544713973999
- 1.3404597377777099
- 1.3588436675071716
- 1.3434909534454347
- 1.3335570549964906
- 1.3534197878837586
- 1.33892103433609
- 1.3423597264289855
- 4.428680467605591
- 4.122475938796997
- 4.587445297241211
- 4.391064462661743
- 1.3056896448135376
- 1.324754912853241
- 1.323975305557251
- 1.3093066477775575
- 1.3081242275238036
- 1.33440016746521
- 1.3441072869300843
- 1.317838282585144
- 1.311759066581726
- 4.252851352691651
- 1.3071407318115233
- 4.211684265136719
- 1.3141966128349305
- 1.3133204984664917
- 1.3186192321777344
- 1.3147168684005737
- 1.299323732852936
- 4.310804882049561
- 1.2943470549583436
- 3.9373502254486086
- 1.2812391352653503
- 1.2881517314910889
- 1.2850710892677306
- 1.3088048267364503
- 1.309014389514923
- 1.2880444860458373
- 4.137528076171875
- 1.288411717414856
- 1.2944887351989747
- 1.2898125553131103
- 1.2922106671333313
- 3.8828844165802003
- 1.284977331161499
- 4.014020776748657
- 4.637164382934571
- 1.2777669787406922
- 3.9860164451599123
- 4.034240131378174
- 4.315595560073852
train_accuracy:
- 0.035
- 0.057
- 0.888
- 0.111
- 0.135
- 0.12
- 0.157
- 0.156
- 0.976
- 0.172
- 0.168
- 0.757
- 0.179
- 0.637
- 0.19
- 0.181
- 0.194
- 0.918
- 0.17
- 0.713
- 0.175
- 0.182
- 0.192
- 0.213
- 0.735
- 0.24
- 0.984
- 0.218
- 0.216
- 0.202
- 0.173
- 0.898
- 0.986
- 0.942
- 0.212
- 0.175
- 0.237
- 0.221
- 0.2
- 0.262
- 0.223
- 0.984
- 0.234
- 0.936
- 0.236
- 0.941
- 0.276
- 0.848
- 0.919
- 0.932
- 0.233
- 0.267
- 0.265
- 0.216
- 0.272
- 0.219
- 0.264
- 0.982
- 0.938
- 0.99
- 0.918
- 0.234
- 0.264
- 0.277
- 0.211
- 0.257
- 0.273
- 0.257
- 0.285
- 0.281
- 0.781
- 0.285
- 0.957
- 0.263
- 0.284
- 0.247
- 0.239
- 0.274
- 0.988
- 0.275
- 0.992
- 0.243
- 0.288
- 0.261
- 0.292
- 0.278
- 0.326
- 0.841
- 0.259
- 0.299
- 0.309
- 0.248
- 0.975
- 0.287
- 0.885
- 0.964
- 0.29
- 0.892
- 0.886
- 0.975
train_loss:
- 4.369
- 3.912
- 0.631
- 4.023
- 3.617
- 3.466
- 3.392
- 3.222
- 0.485
- 3.395
- 2.668
- 0.607
- 2.672
- 0.708
- 3.26
- 2.21
- 2.972
- 0.483
- 3.152
- 0.595
- 2.645
- 2.036
- 3.042
- 2.6
- 0.553
- 2.355
- 0.491
- 2.075
- 2.099
- 2.629
- 2.767
- 0.516
- 0.628
- 0.771
- 2.47
- 2.364
- 1.894
- 1.925
- 2.071
- 1.556
- 1.693
- 0.348
- 2.779
- 0.417
- 1.701
- 0.352
- 2.56
- 0.508
- 0.631
- 0.057
- 1.52
- 1.451
- 1.792
- 1.77
- 1.227
- 1.383
- 1.965
- 0.349
- 0.6
- 0.529
- 0.707
- 1.548
- 1.079
- 1.59
- 2.053
- 1.306
- 0.934
- 0.657
- 2.053
- 1.51
- 0.41
- 1.697
- 0.369
- 1.38
- 0.745
- 1.088
- 1.706
- 1.037
- 0.335
- 1.049
- 0.225
- 1.424
- 1.737
- 0.903
- 1.245
- 1.437
- 1.31
- 0.392
- 1.319
- 0.779
- 0.956
- 0.897
- 0.284
- 1.014
- 0.355
- 0.443
- 1.259
- 0.279
- 0.058
- 0.442
unequal: 0
verbose: 1
