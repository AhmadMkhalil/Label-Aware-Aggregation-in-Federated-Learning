avg_train_accuracy: 0.266
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0429
- 0.0853
- 0.1015
- 0.1149
- 0.1253
- 0.1287
- 0.1459
- 0.1535
- 0.151
- 0.17
- 0.1758
- 0.0151
- 0.1755
- 0.1782
- 0.0142
- 0.0142
- 0.0177
- 0.0191
- 0.1802
- 0.1894
- 0.0191
- 0.1827
- 0.017
- 0.1949
- 0.1903
- 0.19
- 0.2025
- 0.1997
- 0.21
- 0.0192
- 0.2041
- 0.2116
- 0.2122
- 0.2147
- 0.2096
- 0.2157
- 0.2184
- 0.2206
- 0.2272
- 0.2335
- 0.2262
- 0.0152
- 0.2321
- 0.0162
- 0.0193
- 0.2277
- 0.2392
- 0.2331
- 0.2464
- 0.2385
- 0.0148
- 0.0192
- 0.2465
- 0.2449
- 0.2396
- 0.2381
- 0.2419
- 0.248
- 0.2571
- 0.0162
- 0.2482
- 0.2526
- 0.2592
- 0.2587
- 0.2596
- 0.2553
- 0.0193
- 0.258
- 0.2496
- 0.2464
- 0.2481
- 0.0216
- 0.2628
- 0.0164
- 0.2577
- 0.0219
- 0.0173
- 0.2612
- 0.2632
- 0.2696
- 0.2585
- 0.2554
- 0.257
- 0.2578
- 0.0181
- 0.2639
- 0.0161
- 0.2632
- 0.2598
- 0.2719
- 0.2725
- 0.2671
- 0.0168
- 0.2689
- 0.2776
- 0.271
- 0.0201
- 0.2729
- 0.2625
- 0.2701
test_loss_list:
- 1.8041996383666992
- 1.707644717693329
- 1.6633999943733215
- 1.6446467232704163
- 1.6291195416450501
- 1.6294664549827576
- 1.5983908033370973
- 1.5803728771209717
- 1.5742822861671448
- 1.5417245483398438
- 1.5453217673301696
- 4.858447055816651
- 1.5333664894104004
- 1.519604322910309
- 4.713338413238525
- 4.872422533035278
- 4.484463586807251
- 4.580815172195434
- 1.4869946241378784
- 1.4779126286506652
- 4.465236291885376
- 1.488625602722168
- 4.347798471450806
- 1.4768519973754883
- 1.4872105503082276
- 1.4924235606193543
- 1.460970275402069
- 1.477603325843811
- 1.444080548286438
- 4.535890636444091
- 1.4548490929603577
- 1.4406600689888
- 1.4363039565086364
- 1.4573096466064452
- 1.4718128418922425
- 1.458447229862213
- 1.4314108777046204
- 1.4364531207084656
- 1.4269896697998048
- 1.4206712555885315
- 1.4284517216682433
- 4.33693112373352
- 1.4027886986732483
- 4.378191375732422
- 4.322101850509643
- 1.3915335130691528
- 1.3861851811408996
- 1.3937996888160706
- 1.377567422389984
- 1.3989509797096253
- 4.476245594024658
- 4.415180110931397
- 1.36627299785614
- 1.384445035457611
- 1.3904990863800049
- 1.4045508193969727
- 1.3959116291999818
- 1.3732164573669434
- 1.3651863503456116
- 4.439844617843628
- 1.3758237528800965
- 1.355028440952301
- 1.3554893684387208
- 1.365882670879364
- 1.3613252878189086
- 1.365665636062622
- 4.2081828117370605
- 1.3559914326667786
- 1.379683973789215
- 1.400146450996399
- 1.4153983211517334
- 4.036437244415283
- 1.3555679297447205
- 4.2580538082122805
- 1.3563594937324523
- 3.9200916957855223
- 4.3706684398651126
- 1.334268000125885
- 1.3227753949165344
- 1.3409400391578674
- 1.3596164441108705
- 1.3841111755371094
- 1.3665774440765381
- 1.3767857980728149
- 4.26735478401184
- 1.339889452457428
- 4.281010465621948
- 1.3458435869216918
- 1.3588814115524293
- 1.3421620655059814
- 1.3436567616462707
- 1.3648339915275574
- 4.361865558624268
- 1.3468319511413573
- 1.338548333644867
- 1.3581892704963685
- 4.105051145553589
- 1.329532995223999
- 1.3458021211624145
- 1.3404815435409545
train_accuracy:
- 0.06
- 0.091
- 0.079
- 0.102
- 0.14
- 0.137
- 0.119
- 0.154
- 0.152
- 0.159
- 0.146
- 0.66
- 0.174
- 0.178
- 0.521
- 0.343
- 0.795
- 0.94
- 0.178
- 0.182
- 0.912
- 0.204
- 0.841
- 0.193
- 0.178
- 0.205
- 0.189
- 0.19
- 0.184
- 0.949
- 0.185
- 0.196
- 0.187
- 0.186
- 0.176
- 0.214
- 0.199
- 0.207
- 0.217
- 0.221
- 0.214
- 0.64
- 0.212
- 0.782
- 0.899
- 0.221
- 0.215
- 0.221
- 0.222
- 0.221
- 0.477
- 0.934
- 0.212
- 0.227
- 0.21
- 0.229
- 0.256
- 0.239
- 0.231
- 0.768
- 0.249
- 0.232
- 0.233
- 0.229
- 0.234
- 0.256
- 0.907
- 0.272
- 0.247
- 0.261
- 0.251
- 0.924
- 0.25
- 0.79
- 0.252
- 0.919
- 0.751
- 0.235
- 0.247
- 0.242
- 0.257
- 0.234
- 0.273
- 0.258
- 0.854
- 0.257
- 0.568
- 0.263
- 0.244
- 0.264
- 0.253
- 0.261
- 0.791
- 0.248
- 0.271
- 0.254
- 0.919
- 0.251
- 0.256
- 0.266
train_loss:
- 4.203
- 3.859
- 3.703
- 3.228
- 3.257
- 2.808
- 3.369
- 2.903
- 3.191
- 3.117
- 2.616
- 0.976
- 3.372
- 2.635
- 0.832
- 1.125
- 0.863
- 0.166
- 3.058
- 2.644
- 0.433
- 2.43
- 0.661
- 2.587
- 1.884
- 2.041
- 2.441
- 1.949
- 2.404
- 0.421
- 2.163
- 2.726
- 1.732
- 1.353
- 1.129
- 1.925
- 2.533
- 2.315
- 1.232
- 2.465
- 1.814
- 0.816
- 2.417
- 0.629
- 0.656
- 1.964
- 1.885
- 1.366
- 1.678
- 1.165
- 0.57
- 0.583
- 1.471
- 1.06
- 0.929
- 0.912
- 1.88
- 1.982
- 1.383
- 0.549
- 1.766
- 1.84
- 1.122
- 1.613
- 0.852
- 1.456
- 0.354
- 1.608
- 0.898
- 0.695
- 0.541
- 0.313
- 1.242
- 0.546
- 0.885
- 0.266
- 0.86
- 1.674
- 1.308
- 0.964
- 0.66
- 0.497
- 0.713
- 0.417
- 0.539
- 1.36
- 0.49
- 0.854
- 0.981
- 0.671
- 0.672
- 0.483
- 0.439
- 0.971
- 1.056
- 0.624
- 0.328
- 0.778
- 0.38
- 0.53
unequal: 0
verbose: 1
