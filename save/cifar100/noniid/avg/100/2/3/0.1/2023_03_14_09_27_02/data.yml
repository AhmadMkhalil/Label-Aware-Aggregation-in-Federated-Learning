avg_train_accuracy: 0.269
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0175
- 0.0174
- 0.0177
- 0.0181
- 0.0585
- 0.0169
- 0.084
- 0.0879
- 0.1137
- 0.0177
- 0.1207
- 0.1119
- 0.1371
- 0.0182
- 0.1473
- 0.1536
- 0.1607
- 0.154
- 0.0179
- 0.1715
- 0.1785
- 0.0178
- 0.1817
- 0.1804
- 0.1829
- 0.1939
- 0.0187
- 0.0192
- 0.1899
- 0.1936
- 0.2062
- 0.2136
- 0.0192
- 0.2063
- 0.2178
- 0.2145
- 0.2099
- 0.2062
- 0.018
- 0.2099
- 0.2243
- 0.2214
- 0.2311
- 0.237
- 0.2386
- 0.2404
- 0.2345
- 0.0188
- 0.245
- 0.2464
- 0.0197
- 0.2436
- 0.2488
- 0.2453
- 0.2506
- 0.2484
- 0.2509
- 0.257
- 0.2547
- 0.2535
- 0.0189
- 0.2512
- 0.2549
- 0.2642
- 0.0189
- 0.2586
- 0.2658
- 0.2692
- 0.2643
- 0.0188
- 0.2706
- 0.2722
- 0.2707
- 0.2752
- 0.2732
- 0.0181
- 0.2603
- 0.2697
- 0.021
- 0.0202
- 0.2727
- 0.0197
- 0.2745
- 0.2705
- 0.2748
- 0.0191
- 0.273
- 0.2727
- 0.0196
- 0.272
- 0.0225
- 0.0189
- 0.2778
- 0.2787
- 0.2842
- 0.2816
- 0.2782
- 0.291
- 0.0195
- 0.283
test_loss_list:
- 3.519077787399292
- 4.643397207260132
- 4.835603733062744
- 5.879202651977539
- 1.757261791229248
- 4.511978511810303
- 1.7203209590911865
- 1.6800866937637329
- 1.6533982729911805
- 4.460003471374511
- 1.6028073716163636
- 1.618444492816925
- 1.579110951423645
- 4.5087834739685055
- 1.5587915802001953
- 1.5575472545623779
- 1.5317260313034058
- 1.548040008544922
- 4.538604145050049
- 1.5069115662574768
- 1.4993816256523131
- 4.490691604614258
- 1.4823555660247802
- 1.4968471717834473
- 1.499515016078949
- 1.4766932940483093
- 4.4357934665679934
- 4.552464599609375
- 1.4728625226020813
- 1.4511368799209594
- 1.4438496685028077
- 1.4311754274368287
- 4.485098609924316
- 1.431245002746582
- 1.4132477617263794
- 1.433691508769989
- 1.450669972896576
- 1.4679532742500305
- 4.430221862792969
- 1.450523750782013
- 1.4098517537117004
- 1.416137659549713
- 1.3911036491394042
- 1.388420374393463
- 1.3797379326820374
- 1.380366599559784
- 1.4082554697990417
- 4.817644643783569
- 1.3710521602630614
- 1.369518804550171
- 4.3679506301879885
- 1.3729492783546449
- 1.3646055197715758
- 1.3559580254554748
- 1.3535199642181397
- 1.3750805807113649
- 1.3597516083717347
- 1.3493898034095764
- 1.3680704784393312
- 1.3555474543571473
- 4.422051696777344
- 1.3760303306579589
- 1.361295027732849
- 1.3610993933677673
- 4.31839729309082
- 1.3317536902427674
- 1.336988844871521
- 1.319928138256073
- 1.3397454881668092
- 4.310534811019897
- 1.3271032643318177
- 1.3419291353225709
- 1.328029510974884
- 1.3374603509902954
- 1.322568883895874
- 4.412284622192383
- 1.3758574295043946
- 1.3341492342948913
- 4.1774796199798585
- 4.216574831008911
- 1.316725368499756
- 4.157433128356933
- 1.3220941591262818
- 1.3086969375610351
- 1.3307367157936096
- 4.240924882888794
- 1.3327803301811219
- 1.3396417689323425
- 4.082394561767578
- 1.329150788784027
- 3.9452174377441405
- 4.306339836120605
- 1.2988289761543275
- 1.2944062328338624
- 1.308446033000946
- 1.3095722937583922
- 1.3203535413742065
- 1.2977733373641969
- 4.067565307617188
- 1.3163244485855103
train_accuracy:
- 0.802
- 0.905
- 0.87
- 0.9
- 0.064
- 0.602
- 0.067
- 0.09
- 0.102
- 0.81
- 0.12
- 0.106
- 0.11
- 0.908
- 0.115
- 0.131
- 0.139
- 0.138
- 0.905
- 0.149
- 0.144
- 0.984
- 0.173
- 0.163
- 0.154
- 0.171
- 0.889
- 0.92
- 0.161
- 0.167
- 0.169
- 0.19
- 0.912
- 0.169
- 0.197
- 0.19
- 0.202
- 0.191
- 0.924
- 0.194
- 0.196
- 0.188
- 0.228
- 0.18
- 0.223
- 0.208
- 0.209
- 0.971
- 0.187
- 0.218
- 0.905
- 0.226
- 0.193
- 0.216
- 0.233
- 0.213
- 0.22
- 0.213
- 0.245
- 0.235
- 0.891
- 0.235
- 0.216
- 0.201
- 0.946
- 0.283
- 0.221
- 0.259
- 0.237
- 0.922
- 0.259
- 0.212
- 0.29
- 0.225
- 0.248
- 0.92
- 0.256
- 0.267
- 0.911
- 0.868
- 0.229
- 0.939
- 0.233
- 0.263
- 0.275
- 0.95
- 0.273
- 0.272
- 0.922
- 0.26
- 0.939
- 0.931
- 0.282
- 0.299
- 0.28
- 0.262
- 0.303
- 0.26
- 0.952
- 0.269
train_loss:
- 0.588
- 0.796
- 0.181
- 0.744
- 4.785
- 0.502
- 4.176
- 3.703
- 3.32
- 0.581
- 3.651
- 3.171
- 2.979
- 0.615
- 3.524
- 2.9
- 2.704
- 2.301
- 0.511
- 3.481
- 2.864
- 0.495
- 2.956
- 2.295
- 2.485
- 2.255
- 0.531
- 0.093
- 2.803
- 2.607
- 2.76
- 2.236
- 0.422
- 2.527
- 2.001
- 1.549
- 1.279
- 1.114
- 0.484
- 2.432
- 2.248
- 2.05
- 2.651
- 2.326
- 1.985
- 1.301
- 1.798
- 0.496
- 2.275
- 1.623
- 0.43
- 1.787
- 1.678
- 1.733
- 1.158
- 1.418
- 0.948
- 1.833
- 1.364
- 1.435
- 0.402
- 1.328
- 1.487
- 1.295
- 0.456
- 2.373
- 1.024
- 1.35
- 0.883
- 0.368
- 1.223
- 0.906
- 1.68
- 0.729
- 0.936
- 0.444
- 1.76
- 0.923
- 0.374
- 0.04
- 0.984
- 0.329
- 0.662
- 0.872
- 1.042
- 0.315
- 1.147
- 0.591
- 0.381
- 0.668
- 0.258
- 0.475
- 1.013
- 1.483
- 0.882
- 0.596
- 1.069
- 0.481
- 0.316
- 0.901
unequal: 0
verbose: 1
