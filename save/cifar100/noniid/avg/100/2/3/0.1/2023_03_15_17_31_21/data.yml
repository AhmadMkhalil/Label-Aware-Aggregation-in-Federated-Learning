avg_train_accuracy: 0.879
avg_train_loss: 0.0
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0405
- 0.0174
- 0.0749
- 0.0183
- 0.1023
- 0.0172
- 0.1089
- 0.1207
- 0.1229
- 0.0188
- 0.0187
- 0.1377
- 0.1556
- 0.1588
- 0.1605
- 0.1704
- 0.1804
- 0.1846
- 0.1855
- 0.019
- 0.0187
- 0.1808
- 0.1933
- 0.1985
- 0.1938
- 0.1967
- 0.2038
- 0.0174
- 0.1977
- 0.0182
- 0.0186
- 0.2015
- 0.2117
- 0.0189
- 0.0183
- 0.2199
- 0.2192
- 0.2156
- 0.2224
- 0.2246
- 0.2214
- 0.2288
- 0.224
- 0.231
- 0.2299
- 0.0192
- 0.2335
- 0.0181
- 0.2374
- 0.0187
- 0.0188
- 0.243
- 0.0192
- 0.2483
- 0.2394
- 0.2425
- 0.2565
- 0.2474
- 0.0191
- 0.2517
- 0.2501
- 0.2539
- 0.2556
- 0.2593
- 0.2617
- 0.0195
- 0.2602
- 0.0206
- 0.2613
- 0.2575
- 0.0201
- 0.2647
- 0.267
- 0.262
- 0.0191
- 0.2672
- 0.0199
- 0.0186
- 0.2691
- 0.2703
- 0.2694
- 0.0203
- 0.2712
- 0.0185
- 0.0195
- 0.2772
- 0.0197
- 0.0187
- 0.2736
- 0.0211
- 0.0192
- 0.285
- 0.2727
- 0.2722
- 0.2714
- 0.0191
- 0.2741
- 0.0204
- 0.0202
- 0.0207
test_loss_list:
- 1.8018160915374757
- 4.666530075073243
- 1.7182085275650025
- 4.424680700302124
- 1.683283576965332
- 4.5866048049926755
- 1.6645809149742126
- 1.6552716493606567
- 1.6205153274536133
- 4.518008499145508
- 4.5529611301422115
- 1.5681526780128479
- 1.547265808582306
- 1.543651783466339
- 1.5390905547142029
- 1.5193128204345703
- 1.5013329219818115
- 1.503145046234131
- 1.4941127514839172
- 4.473445081710816
- 4.492108020782471
- 1.4761994290351867
- 1.4788133025169372
- 1.472828528881073
- 1.4792863869667052
- 1.473052008152008
- 1.4655355978012086
- 4.58689167022705
- 1.4604241824150086
- 4.520780344009399
- 4.566368494033814
- 1.4418302488327026
- 1.4274838042259217
- 4.3486817264556885
- 4.459993486404419
- 1.3902302408218383
- 1.4053742814064025
- 1.4138068151474
- 1.4012337517738342
- 1.4003043723106385
- 1.4169431018829346
- 1.397447862625122
- 1.4151032853126526
- 1.4003539085388184
- 1.398408250808716
- 4.271115789413452
- 1.3892429494857788
- 4.536721048355102
- 1.3854219818115234
- 4.276381330490112
- 4.416731500625611
- 1.3454373836517335
- 4.135125904083252
- 1.338192491531372
- 1.3633415603637695
- 1.3566800498962401
- 1.3440390586853028
- 1.3604500532150268
- 4.281976890563965
- 1.3394891548156738
- 1.3527426624298096
- 1.3478590035438538
- 1.33353862285614
- 1.3329294300079346
- 1.344193000793457
- 4.239588813781738
- 1.3375202703475952
- 3.8900310134887697
- 1.3290918898582458
- 1.3222048330307006
- 4.2171563625335695
- 1.3154884195327758
- 1.312989466190338
- 1.3360589742660522
- 4.197526168823242
- 1.3087747550010682
- 3.9173208045959473
- 4.228008451461792
- 1.2952299904823303
- 1.3122554636001587
- 1.3158486557006837
- 4.135901937484741
- 1.2904353284835814
- 4.234801635742188
- 4.220631370544433
- 1.2647861886024474
- 3.8860143184661866
- 4.284041185379028
- 1.2807857418060302
- 3.556053457260132
- 4.096145811080933
- 1.2494046473503113
- 1.2867558932304382
- 1.2947558188438415
- 1.3097690725326538
- 4.229262142181397
- 1.2951989197731018
- 3.9324313831329345
- 4.070379734039307
- 4.029199857711792
train_accuracy:
- 0.035
- 0.806
- 0.089
- 0.84
- 0.089
- 0.867
- 0.101
- 0.094
- 0.14
- 0.886
- 0.875
- 0.125
- 0.135
- 0.147
- 0.123
- 0.221
- 0.148
- 0.144
- 0.157
- 0.9
- 0.864
- 0.177
- 0.159
- 0.16
- 0.16
- 0.183
- 0.254
- 0.725
- 0.187
- 0.73
- 0.868
- 0.184
- 0.187
- 0.896
- 0.831
- 0.193
- 0.273
- 0.215
- 0.202
- 0.214
- 0.198
- 0.189
- 0.199
- 0.228
- 0.23
- 0.917
- 0.203
- 0.799
- 0.224
- 0.9
- 0.883
- 0.215
- 0.902
- 0.199
- 0.257
- 0.288
- 0.205
- 0.302
- 0.891
- 0.244
- 0.293
- 0.217
- 0.229
- 0.313
- 0.247
- 0.919
- 0.323
- 0.933
- 0.236
- 0.237
- 0.856
- 0.287
- 0.303
- 0.266
- 0.947
- 0.243
- 0.892
- 0.932
- 0.336
- 0.231
- 0.279
- 0.854
- 0.265
- 0.766
- 0.904
- 0.273
- 0.933
- 0.928
- 0.264
- 0.924
- 0.931
- 0.266
- 0.256
- 0.256
- 0.251
- 0.988
- 0.331
- 0.939
- 0.901
- 0.879
train_loss:
- 4.292
- 0.656
- 4.233
- 0.658
- 3.778
- 0.698
- 3.352
- 2.732
- 3.305
- 0.573
- 0.841
- 3.663
- 3.221
- 2.591
- 3.066
- 3.076
- 2.856
- 2.703
- 2.727
- 0.505
- 0.12
- 2.589
- 2.297
- 2.382
- 2.053
- 2.01
- 2.566
- 0.6
- 2.033
- 0.649
- 0.129
- 2.218
- 2.558
- 0.425
- 0.766
- 2.731
- 2.207
- 1.998
- 1.701
- 1.719
- 1.399
- 2.211
- 1.214
- 1.534
- 1.679
- 0.394
- 1.574
- 0.483
- 2.325
- 0.373
- 0.067
- 2.797
- 0.322
- 2.121
- 1.411
- 1.897
- 1.535
- 1.496
- 0.519
- 1.963
- 1.217
- 1.337
- 2.056
- 1.103
- 1.414
- 0.353
- 1.102
- 0.265
- 1.863
- 1.345
- 0.437
- 1.513
- 0.844
- 0.982
- 0.435
- 1.454
- 0.272
- 0.557
- 1.016
- 0.876
- 1.044
- 0.409
- 1.54
- 0.33
- 0.516
- 1.735
- 0.308
- 0.608
- 1.263
- 0.253
- 0.45
- 1.122
- 0.84
- 0.567
- 0.454
- 0.362
- 1.003
- 0.31
- 0.449
- 0.018
unequal: 0
verbose: 1
