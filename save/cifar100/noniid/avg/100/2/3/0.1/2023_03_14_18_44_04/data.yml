avg_train_accuracy: 0.286
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0152
- 0.0643
- 0.0843
- 0.0161
- 0.103
- 0.1174
- 0.1244
- 0.1272
- 0.0124
- 0.1425
- 0.1443
- 0.1525
- 0.1708
- 0.1648
- 0.015
- 0.1733
- 0.1744
- 0.0185
- 0.1764
- 0.019
- 0.1867
- 0.1893
- 0.1871
- 0.1945
- 0.199
- 0.0191
- 0.2065
- 0.2092
- 0.2064
- 0.2129
- 0.2119
- 0.019
- 0.214
- 0.2246
- 0.2236
- 0.2268
- 0.2218
- 0.0171
- 0.2239
- 0.2249
- 0.2359
- 0.2298
- 0.2305
- 0.0171
- 0.2285
- 0.0196
- 0.2344
- 0.229
- 0.019
- 0.2504
- 0.2456
- 0.2354
- 0.2482
- 0.2446
- 0.2442
- 0.2536
- 0.0191
- 0.2565
- 0.0179
- 0.2572
- 0.0197
- 0.2545
- 0.0152
- 0.0193
- 0.2543
- 0.0203
- 0.2526
- 0.2592
- 0.2642
- 0.2566
- 0.0198
- 0.2659
- 0.2642
- 0.2631
- 0.27
- 0.2627
- 0.2723
- 0.2716
- 0.2771
- 0.2673
- 0.2826
- 0.2776
- 0.0228
- 0.0164
- 0.2779
- 0.2805
- 0.2787
- 0.0174
- 0.2761
- 0.2883
- 0.2825
- 0.2762
- 0.2766
- 0.2892
- 0.0178
- 0.2835
- 0.2806
- 0.0242
- 0.2854
- 0.2891
test_loss_list:
- 3.472446947097778
- 1.7797941970825195
- 1.7166524839401245
- 4.448336372375488
- 1.6650227952003478
- 1.6336952090263366
- 1.63442045211792
- 1.6151799726486207
- 4.8469260311126705
- 1.581988172531128
- 1.5859926462173461
- 1.5593385100364685
- 1.5521402263641357
- 1.5412343907356263
- 4.492710247039795
- 1.5244454765319824
- 1.5197199368476868
- 4.392699661254883
- 1.5240630912780762
- 4.238826656341553
- 1.4718152451515198
- 1.502674205303192
- 1.4894923710823058
- 1.4781455183029175
- 1.4853988599777221
- 4.1495618724823
- 1.4638200139999389
- 1.4439481806755066
- 1.4609630155563353
- 1.44324649810791
- 1.4349646735191346
- 4.276289529800415
- 1.4263929080963136
- 1.4198385739326478
- 1.4327505564689635
- 1.4388041853904725
- 1.4413519287109375
- 4.388584394454956
- 1.4001323699951171
- 1.4093641352653503
- 1.403110191822052
- 1.4045463061332704
- 1.4267831468582153
- 4.394374170303345
- 1.412651937007904
- 4.021224689483643
- 1.384406363964081
- 1.3999473881721496
- 3.999465961456299
- 1.355801317691803
- 1.372328782081604
- 1.4004467558860778
- 1.3809581351280213
- 1.3947646498680115
- 1.390715618133545
- 1.3724967765808105
- 3.9174560928344726
- 1.351465015411377
- 4.316893424987793
- 1.3514481830596923
- 3.842106342315674
- 1.3461296725273133
- 4.414073333740235
- 4.291555347442627
- 1.3086292028427124
- 3.624325351715088
- 1.320027039051056
- 1.3143268060684203
- 1.3153738760948182
- 1.3305369734764099
- 3.5648225116729737
- 1.3088087439537048
- 1.30989741563797
- 1.3363427519798279
- 1.316394443511963
- 1.3379876232147216
- 1.3198878049850464
- 1.3186431002616883
- 1.309167332649231
- 1.3370559644699096
- 1.3152070045471191
- 1.3309416604042053
- 3.7710776424407957
- 4.468576908111572
- 1.3061610078811645
- 1.3067648649215697
- 1.3164051580429077
- 4.0855515193939205
- 1.30678649187088
- 1.2924566316604613
- 1.3065650963783264
- 1.3193422174453735
- 1.3188526439666748
- 1.2945269870758056
- 4.151040697097779
- 1.3077126622200013
- 1.3173049330711364
- 3.686849145889282
- 1.2969321846961974
- 1.2909849095344543
train_accuracy:
- 0.575
- 0.092
- 0.059
- 0.855
- 0.087
- 0.133
- 0.116
- 0.084
- 0.181
- 0.154
- 0.145
- 0.142
- 0.174
- 0.128
- 0.841
- 0.164
- 0.175
- 0.881
- 0.162
- 0.934
- 0.179
- 0.193
- 0.169
- 0.23
- 0.189
- 0.907
- 0.186
- 0.199
- 0.204
- 0.211
- 0.206
- 0.938
- 0.2
- 0.208
- 0.192
- 0.251
- 0.199
- 0.718
- 0.21
- 0.235
- 0.216
- 0.213
- 0.204
- 0.708
- 0.209
- 0.934
- 0.252
- 0.247
- 0.903
- 0.233
- 0.229
- 0.231
- 0.235
- 0.232
- 0.212
- 0.237
- 0.892
- 0.24
- 0.773
- 0.246
- 0.94
- 0.281
- 0.615
- 0.931
- 0.258
- 0.919
- 0.268
- 0.273
- 0.236
- 0.268
- 0.916
- 0.24
- 0.29
- 0.25
- 0.233
- 0.266
- 0.238
- 0.281
- 0.286
- 0.248
- 0.255
- 0.281
- 0.93
- 0.597
- 0.269
- 0.245
- 0.287
- 0.751
- 0.303
- 0.267
- 0.253
- 0.295
- 0.253
- 0.309
- 0.762
- 0.303
- 0.287
- 0.935
- 0.258
- 0.286
train_loss:
- 0.504
- 4.533
- 3.8
- 0.792
- 4.03
- 3.577
- 3.525
- 3.152
- 0.907
- 3.398
- 3.113
- 3.098
- 3.011
- 2.739
- 0.813
- 3.335
- 2.672
- 0.576
- 2.534
- 0.413
- 2.956
- 2.061
- 2.354
- 2.895
- 1.903
- 0.38
- 2.324
- 2.557
- 2.017
- 2.59
- 2.555
- 0.369
- 2.181
- 1.896
- 1.598
- 2.424
- 1.398
- 0.761
- 2.498
- 2.071
- 1.327
- 1.844
- 1.372
- 0.602
- 1.45
- 0.374
- 2.374
- 1.583
- 0.301
- 2.029
- 1.361
- 1.007
- 1.477
- 0.92
- 1.105
- 1.723
- 0.31
- 2.308
- 0.53
- 1.594
- 0.272
- 1.822
- 0.835
- 0.499
- 1.973
- 0.243
- 1.914
- 1.32
- 1.246
- 1.034
- 0.238
- 1.107
- 1.376
- 0.898
- 0.846
- 1.417
- 1.502
- 0.959
- 1.081
- 1.152
- 0.804
- 1.086
- 0.251
- 0.723
- 1.342
- 0.987
- 0.889
- 0.659
- 1.278
- 0.681
- 0.425
- 0.97
- 0.858
- 0.815
- 0.537
- 0.962
- 0.867
- 0.268
- 0.696
- 0.671
unequal: 0
verbose: 1
