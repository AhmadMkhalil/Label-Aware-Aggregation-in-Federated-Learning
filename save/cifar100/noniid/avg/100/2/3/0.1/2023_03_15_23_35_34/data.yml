avg_train_accuracy: 0.988
avg_train_loss: 0.0
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0199
- 0.0626
- 0.0198
- 0.017
- 0.0178
- 0.0724
- 0.0932
- 0.1079
- 0.1345
- 0.1362
- 0.1476
- 0.1521
- 0.1644
- 0.1602
- 0.0185
- 0.1704
- 0.0199
- 0.0196
- 0.1691
- 0.1725
- 0.1765
- 0.184
- 0.0177
- 0.181
- 0.1941
- 0.2013
- 0.0187
- 0.1982
- 0.0185
- 0.2101
- 0.0182
- 0.0198
- 0.2022
- 0.205
- 0.2121
- 0.2069
- 0.2176
- 0.2156
- 0.2248
- 0.2281
- 0.2321
- 0.2268
- 0.229
- 0.239
- 0.2311
- 0.2306
- 0.2414
- 0.2335
- 0.236
- 0.2478
- 0.2426
- 0.2409
- 0.2482
- 0.2467
- 0.256
- 0.2588
- 0.02
- 0.0187
- 0.2515
- 0.2522
- 0.0191
- 0.0198
- 0.258
- 0.2648
- 0.2599
- 0.0187
- 0.019
- 0.0191
- 0.0192
- 0.2523
- 0.0207
- 0.019
- 0.0195
- 0.2616
- 0.2604
- 0.2725
- 0.019
- 0.0199
- 0.2631
- 0.2621
- 0.2713
- 0.0203
- 0.0199
- 0.2709
- 0.2744
- 0.2734
- 0.2791
- 0.272
- 0.0201
- 0.2652
- 0.2735
- 0.2739
- 0.2846
- 0.2737
- 0.2812
- 0.2788
- 0.2833
- 0.2791
- 0.0208
- 0.0207
test_loss_list:
- 3.461684627532959
- 1.7615368890762328
- 4.225124006271362
- 4.722555103302002
- 4.620641450881958
- 1.7114600515365601
- 1.6758715009689331
- 1.63810968875885
- 1.591468415260315
- 1.57788827419281
- 1.560869107246399
- 1.561740629673004
- 1.5408241033554078
- 1.5511970376968385
- 4.398321285247802
- 1.51508056640625
- 4.618870334625244
- 4.537788190841675
- 1.494125897884369
- 1.4885014915466308
- 1.4951625442504883
- 1.4865957808494568
- 4.6241586399078365
- 1.4697177743911742
- 1.4596010422706605
- 1.4466932201385498
- 4.349349746704101
- 1.4467755889892577
- 4.24218789100647
- 1.43105881690979
- 4.513887214660644
- 4.271776170730591
- 1.4150360894203187
- 1.4288060426712037
- 1.4111985611915587
- 1.4154901146888732
- 1.4017898106575013
- 1.4046676325798035
- 1.4001212692260743
- 1.380586075782776
- 1.376704306602478
- 1.3813528251647949
- 1.3803654742240905
- 1.388167290687561
- 1.3868260955810547
- 1.385467917919159
- 1.3792341423034669
- 1.3974444890022277
- 1.3774810361862182
- 1.3740311813354493
- 1.3905050921440125
- 1.3880520558357239
- 1.3815007972717286
- 1.3878247380256652
- 1.373037841320038
- 1.3776872324943543
- 4.446520128250122
- 4.311618795394898
- 1.3344104099273681
- 1.3456913566589355
- 4.206474132537842
- 4.45864670753479
- 1.3185775208473205
- 1.3215176749229431
- 1.3377022218704224
- 4.355194692611694
- 4.437959127426147
- 4.211420803070069
- 4.543362092971802
- 1.3141499853134155
- 3.8979875469207763
- 4.210122804641724
- 4.115544548034668
- 1.284003086090088
- 1.3026856207847595
- 1.2908573484420776
- 4.099717273712158
- 4.326938457489014
- 1.3048648166656494
- 1.3209186100959778
- 1.3039642882347107
- 3.994837236404419
- 4.358142261505127
- 1.2920032382011413
- 1.286759741306305
- 1.2928898811340332
- 1.2874291920661927
- 1.3320165395736694
- 4.293307361602783
- 1.3166657423973083
- 1.2952925539016724
- 1.2984211683273315
- 1.276925277709961
- 1.3121252965927124
- 1.3010758996009826
- 1.3112421822547913
- 1.2749032020568847
- 1.312128574848175
- 3.8863456630706787
- 4.091188077926636
train_accuracy:
- 0.974
- 0.064
- 0.958
- 0.588
- 0.67
- 0.086
- 0.102
- 0.139
- 0.102
- 0.12
- 0.15
- 0.173
- 0.165
- 0.189
- 0.888
- 0.163
- 0.982
- 0.919
- 0.151
- 0.196
- 0.185
- 0.15
- 0.887
- 0.221
- 0.194
- 0.187
- 0.874
- 0.19
- 0.854
- 0.172
- 0.899
- 0.977
- 0.187
- 0.18
- 0.242
- 0.233
- 0.194
- 0.216
- 0.238
- 0.262
- 0.23
- 0.226
- 0.223
- 0.251
- 0.232
- 0.249
- 0.223
- 0.253
- 0.255
- 0.266
- 0.257
- 0.255
- 0.273
- 0.252
- 0.268
- 0.217
- 0.977
- 0.898
- 0.271
- 0.323
- 0.881
- 0.988
- 0.259
- 0.258
- 0.263
- 0.835
- 0.932
- 0.885
- 0.94
- 0.274
- 0.884
- 0.907
- 0.872
- 0.264
- 0.276
- 0.289
- 0.893
- 0.983
- 0.342
- 0.329
- 0.243
- 0.899
- 0.989
- 0.287
- 0.235
- 0.252
- 0.301
- 0.291
- 0.987
- 0.313
- 0.256
- 0.272
- 0.249
- 0.308
- 0.244
- 0.302
- 0.315
- 0.37
- 0.972
- 0.988
train_loss:
- 0.494
- 4.574
- 0.441
- 0.886
- 0.85
- 4.258
- 3.426
- 3.572
- 3.411
- 3.191
- 3.278
- 2.983
- 3.167
- 2.61
- 0.584
- 3.13
- 0.455
- 0.069
- 3.353
- 2.819
- 2.347
- 2.508
- 0.634
- 3.093
- 2.643
- 2.627
- 0.493
- 2.435
- 0.383
- 2.473
- 0.557
- 0.666
- 2.231
- 1.606
- 2.576
- 2.051
- 1.993
- 1.608
- 2.226
- 2.338
- 2.262
- 1.461
- 1.92
- 1.905
- 1.27
- 1.625
- 1.732
- 1.914
- 1.406
- 1.664
- 1.578
- 1.209
- 1.385
- 1.846
- 1.17
- 1.508
- 0.416
- 0.706
- 1.423
- 1.981
- 0.356
- 0.593
- 1.52
- 1.521
- 0.961
- 0.513
- 0.068
- 0.596
- 0.541
- 1.826
- 0.259
- 0.548
- 0.5
- 1.334
- 0.664
- 1.112
- 0.33
- 0.585
- 1.906
- 1.101
- 1.325
- 0.296
- 0.506
- 1.508
- 0.965
- 1.328
- 0.968
- 0.632
- 0.27
- 0.675
- 1.065
- 1.007
- 0.87
- 0.567
- 0.627
- 1.02
- 0.799
- 1.15
- 0.235
- 0.01
unequal: 0
verbose: 1
