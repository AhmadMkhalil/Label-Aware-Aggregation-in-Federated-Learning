avg_train_accuracy: 0.297
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0416
- 0.089
- 0.1109
- 0.1271
- 0.1407
- 0.1455
- 0.1614
- 0.1708
- 0.1805
- 0.1862
- 0.194
- 0.2025
- 0.2103
- 0.2136
- 0.2175
- 0.2212
- 0.2246
- 0.2337
- 0.232
- 0.2386
- 0.242
- 0.2486
- 0.2504
- 0.2501
- 0.2569
- 0.2545
- 0.2612
- 0.2636
- 0.2616
- 0.2683
- 0.2724
- 0.2755
- 0.2784
- 0.2715
- 0.2748
- 0.2799
- 0.2763
- 0.2846
- 0.2851
- 0.2798
- 0.2826
- 0.2891
- 0.2883
- 0.2915
- 0.2886
- 0.291
- 0.2923
- 0.2929
- 0.2953
- 0.2946
- 0.2966
- 0.2955
- 0.2988
- 0.3012
- 0.2991
- 0.2982
- 0.3038
- 0.3055
- 0.3053
- 0.305
- 0.3082
- 0.3061
- 0.3065
- 0.3105
- 0.3079
- 0.3133
- 0.3138
- 0.3148
- 0.3137
- 0.3127
- 0.3146
- 0.3132
- 0.3149
- 0.3151
- 0.3159
- 0.3205
- 0.3194
- 0.3197
- 0.3188
- 0.3182
- 0.3194
- 0.3211
- 0.3187
- 0.3201
- 0.3239
- 0.3206
- 0.3214
- 0.3223
- 0.3259
- 0.3209
- 0.3252
- 0.3228
- 0.3271
- 0.32
- 0.3248
- 0.3232
- 0.3266
- 0.324
- 0.3263
- 0.3272
test_loss_list:
- 1.78815185546875
- 1.6542015600204467
- 1.5962968587875366
- 1.5518085741996765
- 1.5248445892333984
- 1.5079130911827088
- 1.489474585056305
- 1.4404803276062013
- 1.421619188785553
- 1.4161887884140014
- 1.3876739811897278
- 1.3734076452255248
- 1.3603141713142395
- 1.3507424640655517
- 1.3534519267082215
- 1.3519805884361267
- 1.3239607262611388
- 1.3265901136398315
- 1.3294916105270387
- 1.3244659900665283
- 1.2867063641548158
- 1.2940350365638733
- 1.297049150466919
- 1.2946583390235902
- 1.2938187003135682
- 1.2604996013641356
- 1.2451040625572205
- 1.2422472429275513
- 1.2516628909111023
- 1.225902831554413
- 1.2234697794914247
- 1.2178883504867555
- 1.2151918721199035
- 1.235399899482727
- 1.217776789665222
- 1.207416400909424
- 1.2232175183296203
- 1.2017644810676575
- 1.195930359363556
- 1.2128316140174866
- 1.2208782458305358
- 1.1936989998817444
- 1.1857236123085022
- 1.1870525336265565
- 1.2045796084403992
- 1.206911129951477
- 1.2097526931762694
- 1.2134801578521728
- 1.2186875104904176
- 1.2217949604988099
- 1.222343204021454
- 1.2198650336265564
- 1.215631091594696
- 1.2162222647666932
- 1.1798806810379028
- 1.1932233572006226
- 1.1666353702545167
- 1.1596788191795349
- 1.179829602241516
- 1.1848538208007813
- 1.186840262413025
- 1.167972710132599
- 1.1800540924072265
- 1.1840747570991517
- 1.1584583926200867
- 1.1519647145271301
- 1.17049382686615
- 1.1511073994636536
- 1.1585156440734863
- 1.1717015862464906
- 1.1547789096832275
- 1.153558976650238
- 1.1675670146942139
- 1.1537283873558044
- 1.1544685387611389
- 1.1534000039100647
- 1.149777147769928
- 1.1630199837684632
- 1.1739416885375977
- 1.150083601474762
- 1.1686498880386353
- 1.171094479560852
- 1.177947642803192
- 1.1814252305030823
- 1.186716992855072
- 1.1924285793304443
- 1.1566140604019166
- 1.1716308975219727
- 1.1531196665763854
- 1.171868953704834
- 1.175507140159607
- 1.15053781747818
- 1.1474302649497985
- 1.1508539772033692
- 1.1538267064094543
- 1.166355550289154
- 1.1492967748641967
- 1.166960916519165
- 1.1753604221343994
- 1.1769646382331849
train_accuracy:
- 0.036
- 0.087
- 0.11
- 0.119
- 0.116
- 0.151
- 0.14
- 0.185
- 0.182
- 0.192
- 0.154
- 0.204
- 0.195
- 0.175
- 0.202
- 0.241
- 0.228
- 0.199
- 0.254
- 0.25
- 0.0
- 0.257
- 0.276
- 0.221
- 0.218
- 0.256
- 0.272
- 0.262
- 0.231
- 0.285
- 0.271
- 0.223
- 0.285
- 0.277
- 0.249
- 0.0
- 0.297
- 0.0
- 0.302
- 0.308
- 0.255
- 0.291
- 0.0
- 0.266
- 0.318
- 0.298
- 0.258
- 0.327
- 0.318
- 0.262
- 0.304
- 0.294
- 0.326
- 0.326
- 0.318
- 0.309
- 0.0
- 0.279
- 0.325
- 0.286
- 0.312
- 0.293
- 0.289
- 0.31
- 0.266
- 0.319
- 0.29
- 0.294
- 0.304
- 0.32
- 0.272
- 0.3
- 0.338
- 0.0
- 0.311
- 0.272
- 0.352
- 0.337
- 0.315
- 0.309
- 0.336
- 0.285
- 0.332
- 0.307
- 0.339
- 0.319
- 0.297
- 0.362
- 0.0
- 0.325
- 0.305
- 0.29
- 0.34
- 0.348
- 0.0
- 0.338
- 0.305
- 0.322
- 0.346
- 0.297
train_loss:
- 4.337
- 3.301
- 3.134
- 3.007
- 3.392
- 3.269
- 3.156
- 2.672
- 2.546
- 2.957
- 2.407
- 2.337
- 2.313
- 2.208
- 2.663
- 2.563
- 2.072
- 2.478
- 2.332
- 2.372
- 1.934
- 2.264
- 2.186
- 2.139
- 2.085
- 1.726
- 1.684
- 1.623
- 1.974
- 1.608
- 1.563
- 1.587
- 1.499
- 1.768
- 1.424
- 1.432
- 1.674
- 1.339
- 1.338
- 1.558
- 1.534
- 1.245
- 1.238
- 1.207
- 1.417
- 1.347
- 1.299
- 1.314
- 1.231
- 1.168
- 1.164
- 1.201
- 1.204
- 1.116
- 1.009
- 1.066
- 0.899
- 0.844
- 1.001
- 0.985
- 0.952
- 0.818
- 0.86
- 0.935
- 0.731
- 0.756
- 0.875
- 0.655
- 0.629
- 0.804
- 0.679
- 0.661
- 0.723
- 0.582
- 0.558
- 0.637
- 0.613
- 0.647
- 0.645
- 0.588
- 0.623
- 0.654
- 0.612
- 0.583
- 0.556
- 0.528
- 0.443
- 0.554
- 0.455
- 0.505
- 0.539
- 0.439
- 0.455
- 0.421
- 0.419
- 0.445
- 0.411
- 0.405
- 0.413
- 0.453
unequal: 0
verbose: 1
