avg_train_accuracy: 0.338
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0324
- 0.0956
- 0.1171
- 0.136
- 0.1502
- 0.1594
- 0.1674
- 0.1829
- 0.1874
- 0.1912
- 0.2005
- 0.2068
- 0.2164
- 0.2204
- 0.2241
- 0.2327
- 0.2396
- 0.2398
- 0.245
- 0.2443
- 0.2516
- 0.2548
- 0.262
- 0.2631
- 0.2683
- 0.2688
- 0.2677
- 0.2739
- 0.2753
- 0.281
- 0.2808
- 0.2849
- 0.2881
- 0.2877
- 0.2908
- 0.2953
- 0.2924
- 0.2988
- 0.3006
- 0.2979
- 0.2998
- 0.3033
- 0.3001
- 0.3056
- 0.3021
- 0.3018
- 0.3075
- 0.3105
- 0.311
- 0.3113
- 0.3128
- 0.3134
- 0.3149
- 0.3119
- 0.3171
- 0.3137
- 0.3219
- 0.3195
- 0.3236
- 0.3227
- 0.3286
- 0.3237
- 0.3238
- 0.3263
- 0.3282
- 0.3304
- 0.3283
- 0.3294
- 0.3269
- 0.3279
- 0.3283
- 0.3287
- 0.3288
- 0.3318
- 0.329
- 0.3303
- 0.3339
- 0.3342
- 0.3344
- 0.3326
- 0.332
- 0.3338
- 0.3347
- 0.3357
- 0.3348
- 0.3358
- 0.3355
- 0.3371
- 0.3342
- 0.3376
- 0.3387
- 0.3356
- 0.337
- 0.3386
- 0.3335
- 0.3415
- 0.3368
- 0.3414
- 0.3387
- 0.3388
test_loss_list:
- 1.8000994873046876
- 1.6525469160079955
- 1.5969693875312805
- 1.5373799538612365
- 1.5179408192634583
- 1.474566442966461
- 1.467627854347229
- 1.4482201528549195
- 1.4097950553894043
- 1.4111220622062683
- 1.401355140209198
- 1.3934798979759215
- 1.3842143654823302
- 1.340909161567688
- 1.3476901316642762
- 1.3418948364257812
- 1.3328841257095336
- 1.2980374145507811
- 1.300643711090088
- 1.3024903464317321
- 1.2978714942932128
- 1.2940650272369385
- 1.2895735311508179
- 1.2892490363121032
- 1.2855477666854858
- 1.2866171455383302
- 1.2452080249786377
- 1.2498096418380737
- 1.2216504836082458
- 1.207926971912384
- 1.2040717387199402
- 1.200105140209198
- 1.1944249534606934
- 1.206196391582489
- 1.2104796051979065
- 1.2122804617881775
- 1.18393150806427
- 1.191937701702118
- 1.1723977088928224
- 1.186252112388611
- 1.1948375606536865
- 1.1702226328849792
- 1.1814267897605897
- 1.183021547794342
- 1.160355610847473
- 1.1706275868415832
- 1.1509361815452577
- 1.1685544085502624
- 1.1466836071014403
- 1.149431128501892
- 1.1484981727600099
- 1.1566598629951477
- 1.1715779995918274
- 1.1477276158332825
- 1.1440679693222047
- 1.1434954071044923
- 1.1369092750549317
- 1.1487010717391968
- 1.1377326703071595
- 1.1397288751602173
- 1.1329668283462524
- 1.1379773902893067
- 1.150514898300171
- 1.1324070858955384
- 1.1292377281188966
- 1.1251348805427552
- 1.1370273876190184
- 1.1296399188041688
- 1.1349923133850097
- 1.14769611120224
- 1.1567148208618163
- 1.1325327110290528
- 1.1495918345451355
- 1.1284008979797364
- 1.142169816493988
- 1.1511405301094055
- 1.1574810147285461
- 1.1349374485015868
- 1.1449561381340028
- 1.15127272605896
- 1.1386799287796021
- 1.1470726585388185
- 1.129917106628418
- 1.1434672594070434
- 1.1512215566635131
- 1.1545941925048828
- 1.156592733860016
- 1.1620621824264525
- 1.170870804786682
- 1.168811435699463
- 1.1347966480255127
- 1.1302875638008119
- 1.1450142073631286
- 1.1506338548660278
- 1.136865222454071
- 1.1413035440444945
- 1.1558600902557372
- 1.1271865701675414
- 1.1479728889465333
- 1.1545815205574035
train_accuracy:
- 0.0
- 0.113
- 0.136
- 0.133
- 0.142
- 0.18
- 0.149
- 0.169
- 0.0
- 0.176
- 0.161
- 0.198
- 0.232
- 0.2
- 0.234
- 0.204
- 0.216
- 0.206
- 0.238
- 0.241
- 0.229
- 0.257
- 0.231
- 0.238
- 0.304
- 0.263
- 0.256
- 0.289
- 0.0
- 0.258
- 0.268
- 0.269
- 0.0
- 0.312
- 0.277
- 0.294
- 0.322
- 0.274
- 0.282
- 0.289
- 0.281
- 0.0
- 0.287
- 0.3
- 0.298
- 0.293
- 0.312
- 0.299
- 0.279
- 0.293
- 0.327
- 0.311
- 0.297
- 0.299
- 0.0
- 0.314
- 0.0
- 0.29
- 0.297
- 0.302
- 0.307
- 0.0
- 0.297
- 0.0
- 0.35
- 0.0
- 0.312
- 0.305
- 0.336
- 0.34
- 0.336
- 0.325
- 0.319
- 0.326
- 0.323
- 0.324
- 0.311
- 0.0
- 0.36
- 0.307
- 0.329
- 0.299
- 0.293
- 0.363
- 0.323
- 0.328
- 0.328
- 0.324
- 0.32
- 0.369
- 0.322
- 0.303
- 0.304
- 0.328
- 0.348
- 0.385
- 0.316
- 0.305
- 0.374
- 0.338
train_loss:
- 3.672
- 3.897
- 3.634
- 2.939
- 3.274
- 2.761
- 3.101
- 3.05
- 2.536
- 2.841
- 2.858
- 2.684
- 2.589
- 2.224
- 2.55
- 2.436
- 2.465
- 2.039
- 2.313
- 2.247
- 2.173
- 2.194
- 2.084
- 2.004
- 1.972
- 1.919
- 1.605
- 1.847
- 1.517
- 1.596
- 1.492
- 1.455
- 1.477
- 1.652
- 1.609
- 1.549
- 1.343
- 1.559
- 1.217
- 1.485
- 1.41
- 1.198
- 1.369
- 1.313
- 1.155
- 1.237
- 1.08
- 1.208
- 1.021
- 1.035
- 0.982
- 1.108
- 1.1
- 0.952
- 0.877
- 0.887
- 0.845
- 0.997
- 0.827
- 0.771
- 0.788
- 0.757
- 0.907
- 0.733
- 0.747
- 0.711
- 0.682
- 0.672
- 0.636
- 0.747
- 0.74
- 0.624
- 0.718
- 0.632
- 0.682
- 0.713
- 0.63
- 0.521
- 0.657
- 0.629
- 0.505
- 0.585
- 0.499
- 0.608
- 0.55
- 0.56
- 0.514
- 0.51
- 0.482
- 0.519
- 0.432
- 0.424
- 0.471
- 0.464
- 0.376
- 0.467
- 0.452
- 0.371
- 0.425
- 0.406
unequal: 0
verbose: 1
