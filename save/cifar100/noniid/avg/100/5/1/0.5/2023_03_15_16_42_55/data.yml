avg_train_accuracy: 0.327
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0516
- 0.1017
- 0.1207
- 0.1312
- 0.1486
- 0.1612
- 0.1714
- 0.1789
- 0.1864
- 0.193
- 0.2
- 0.2095
- 0.2127
- 0.2206
- 0.2265
- 0.2278
- 0.2318
- 0.2341
- 0.2402
- 0.2455
- 0.2475
- 0.2504
- 0.2486
- 0.25
- 0.257
- 0.256
- 0.2587
- 0.2593
- 0.2625
- 0.2667
- 0.267
- 0.2685
- 0.2678
- 0.2763
- 0.2755
- 0.2804
- 0.2756
- 0.2799
- 0.2805
- 0.2812
- 0.2855
- 0.2897
- 0.2853
- 0.2873
- 0.2897
- 0.2863
- 0.2911
- 0.2917
- 0.2942
- 0.2909
- 0.2969
- 0.2947
- 0.2921
- 0.3015
- 0.3028
- 0.2951
- 0.3003
- 0.2987
- 0.3038
- 0.2964
- 0.2995
- 0.302
- 0.3044
- 0.3077
- 0.3047
- 0.3102
- 0.3035
- 0.3013
- 0.3097
- 0.3097
- 0.3048
- 0.3149
- 0.3141
- 0.3132
- 0.3151
- 0.3188
- 0.3099
- 0.3157
- 0.3197
- 0.315
- 0.318
- 0.3136
- 0.3131
- 0.3249
- 0.3209
- 0.3196
- 0.3198
- 0.3183
- 0.3215
- 0.321
- 0.3193
- 0.3194
- 0.3242
- 0.3174
- 0.3245
- 0.3195
- 0.3232
- 0.3236
- 0.3242
- 0.3207
test_loss_list:
- 1.7705716848373414
- 1.644768934249878
- 1.5890762543678283
- 1.5566934370994567
- 1.5264128017425538
- 1.5091807270050048
- 1.4546063590049743
- 1.4509606885910034
- 1.4109690880775452
- 1.410812087059021
- 1.3818042707443237
- 1.3859318852424622
- 1.3555318808555603
- 1.342916328907013
- 1.3501399612426759
- 1.3475100517272949
- 1.3435765743255614
- 1.3390270447731019
- 1.3291773438453673
- 1.2904285788536072
- 1.2973757624626159
- 1.300416259765625
- 1.2659068250656127
- 1.2605517935752868
- 1.2520352077484131
- 1.2687530303001404
- 1.2695562624931336
- 1.2458637261390686
- 1.2535365271568297
- 1.2590031981468202
- 1.2577475547790526
- 1.2623450207710265
- 1.2298054480552674
- 1.2363556742668151
- 1.215015835762024
- 1.206540997028351
- 1.2272280192375182
- 1.2014657926559449
- 1.2027934217453002
- 1.2110732078552247
- 1.219542007446289
- 1.2215050077438354
- 1.229717457294464
- 1.1876311659812928
- 1.2043255400657653
- 1.212744324207306
- 1.214400110244751
- 1.2190362048149108
- 1.2222900867462159
- 1.1875319719314574
- 1.201067566871643
- 1.2063435554504394
- 1.182460572719574
- 1.1664659523963927
- 1.169348864555359
- 1.1900018906593324
- 1.1974769067764282
- 1.1749027848243714
- 1.1912633800506591
- 1.2042414593696593
- 1.2040023851394652
- 1.1782954478263854
- 1.187069640159607
- 1.165139720439911
- 1.180151765346527
- 1.158437306880951
- 1.1836956071853637
- 1.1831135511398316
- 1.191018714904785
- 1.1594413661956786
- 1.1854846358299256
- 1.1557454681396484
- 1.1744344544410705
- 1.1568729496002197
- 1.160471556186676
- 1.157211253643036
- 1.1807548022270202
- 1.1577867341041566
- 1.1524485564231872
- 1.1680488562583924
- 1.1579596281051636
- 1.1790684342384339
- 1.1854550266265869
- 1.1525617814064026
- 1.1472906899452209
- 1.1551532697677613
- 1.160408525466919
- 1.156273820400238
- 1.155268542766571
- 1.1554124402999877
- 1.1712564468383788
- 1.1717586588859559
- 1.1512307214736939
- 1.17104154586792
- 1.1558090019226075
- 1.1750410676002503
- 1.1576434254646302
- 1.1612306809425355
- 1.1605275964736939
- 1.1695434546470642
train_accuracy:
- 0.061
- 0.0
- 0.0
- 0.114
- 0.178
- 0.165
- 0.166
- 0.154
- 0.169
- 0.194
- 0.197
- 0.198
- 0.206
- 0.192
- 0.211
- 0.22
- 0.223
- 0.246
- 0.241
- 0.227
- 0.236
- 0.274
- 0.286
- 0.0
- 0.259
- 0.271
- 0.254
- 0.257
- 0.292
- 0.284
- 0.282
- 0.315
- 0.292
- 0.299
- 0.267
- 0.295
- 0.287
- 0.278
- 0.273
- 0.283
- 0.281
- 0.298
- 0.274
- 0.0
- 0.299
- 0.265
- 0.263
- 0.256
- 0.301
- 0.311
- 0.273
- 0.314
- 0.303
- 0.28
- 0.34
- 0.346
- 0.344
- 0.269
- 0.299
- 0.292
- 0.299
- 0.26
- 0.339
- 0.345
- 0.297
- 0.28
- 0.336
- 0.302
- 0.329
- 0.32
- 0.311
- 0.305
- 0.376
- 0.31
- 0.277
- 0.276
- 0.332
- 0.312
- 0.296
- 0.319
- 0.317
- 0.388
- 0.32
- 0.383
- 0.325
- 0.357
- 0.303
- 0.352
- 0.34
- 0.306
- 0.321
- 0.401
- 0.0
- 0.3
- 0.302
- 0.392
- 0.0
- 0.32
- 0.324
- 0.327
train_loss:
- 4.283
- 3.306
- 3.112
- 3.509
- 3.339
- 3.217
- 2.729
- 3.039
- 2.544
- 2.905
- 2.372
- 2.795
- 2.287
- 2.223
- 2.541
- 2.513
- 2.439
- 2.395
- 2.37
- 1.932
- 2.168
- 2.237
- 1.79
- 1.737
- 1.76
- 2.04
- 1.963
- 1.645
- 1.926
- 1.814
- 1.77
- 1.698
- 1.419
- 1.672
- 1.464
- 1.366
- 1.561
- 1.308
- 1.407
- 1.565
- 1.499
- 1.391
- 1.47
- 1.229
- 1.327
- 1.295
- 1.311
- 1.239
- 1.192
- 1.014
- 1.151
- 1.103
- 1.001
- 0.902
- 0.899
- 1.002
- 0.998
- 0.822
- 0.881
- 0.888
- 0.808
- 0.723
- 0.943
- 0.779
- 0.913
- 0.753
- 0.859
- 0.883
- 0.75
- 0.762
- 0.781
- 0.678
- 0.664
- 0.597
- 0.533
- 0.602
- 0.622
- 0.573
- 0.52
- 0.64
- 0.517
- 0.53
- 0.612
- 0.539
- 0.58
- 0.475
- 0.481
- 0.505
- 0.477
- 0.456
- 0.519
- 0.515
- 0.427
- 0.464
- 0.406
- 0.478
- 0.346
- 0.332
- 0.395
- 0.439
unequal: 0
verbose: 1
