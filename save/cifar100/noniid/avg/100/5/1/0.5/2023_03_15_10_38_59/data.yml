avg_train_accuracy: 0.34
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0367
- 0.0943
- 0.1116
- 0.1208
- 0.1405
- 0.1525
- 0.1616
- 0.172
- 0.1746
- 0.1881
- 0.1916
- 0.199
- 0.2016
- 0.2103
- 0.2122
- 0.2152
- 0.2251
- 0.2274
- 0.2291
- 0.2283
- 0.2401
- 0.2383
- 0.2455
- 0.2454
- 0.2502
- 0.2506
- 0.2507
- 0.2559
- 0.2588
- 0.2609
- 0.2641
- 0.2689
- 0.2691
- 0.2678
- 0.2722
- 0.2716
- 0.2761
- 0.2793
- 0.2774
- 0.2852
- 0.2849
- 0.281
- 0.2852
- 0.2888
- 0.2869
- 0.2878
- 0.2848
- 0.2907
- 0.2903
- 0.2898
- 0.2952
- 0.2936
- 0.296
- 0.2995
- 0.2979
- 0.3024
- 0.3023
- 0.3031
- 0.3035
- 0.3015
- 0.3021
- 0.3009
- 0.3
- 0.3072
- 0.3089
- 0.3094
- 0.3074
- 0.3114
- 0.3086
- 0.3089
- 0.3119
- 0.3085
- 0.3097
- 0.3125
- 0.3181
- 0.3157
- 0.3138
- 0.3154
- 0.3193
- 0.3145
- 0.3114
- 0.3163
- 0.3182
- 0.3183
- 0.318
- 0.3249
- 0.3257
- 0.3192
- 0.3204
- 0.3277
- 0.3271
- 0.327
- 0.3271
- 0.3273
- 0.3279
- 0.3264
- 0.3281
- 0.3261
- 0.3271
- 0.329
test_loss_list:
- 1.7940479135513305
- 1.6499393939971925
- 1.6020520734786987
- 1.546756730079651
- 1.5074629020690917
- 1.4945332741737365
- 1.4563073873519898
- 1.4379908728599549
- 1.436097514629364
- 1.4273957228660583
- 1.4182115578651429
- 1.3774703741073608
- 1.3834391808509827
- 1.3852653670310975
- 1.3756849718093873
- 1.3360744881629945
- 1.3203452348709106
- 1.3335486578941345
- 1.3065492033958435
- 1.3218638181686402
- 1.294007797241211
- 1.2909582042694092
- 1.2810087704658508
- 1.2936469841003417
- 1.2915056085586547
- 1.2939608788490295
- 1.2959335517883301
- 1.2594730734825135
- 1.245855939388275
- 1.236943781375885
- 1.2512914204597474
- 1.2289762663841248
- 1.2281552648544312
- 1.2447169995307923
- 1.218686785697937
- 1.2380099081993103
- 1.238201825618744
- 1.2414021563529969
- 1.2103902435302734
- 1.1993771266937256
- 1.1994866800308228
- 1.2185692143440248
- 1.1914356398582457
- 1.1953964233398438
- 1.2123762083053589
- 1.1911565899848937
- 1.2051173186302184
- 1.2111601042747497
- 1.2173050117492676
- 1.2151185584068298
- 1.1811294865608215
- 1.1773210287094116
- 1.1930998325347901
- 1.1716678977012633
- 1.1748330736160277
- 1.181883156299591
- 1.1612061309814452
- 1.1644484066963197
- 1.1817229056358338
- 1.1884068202972413
- 1.1953299045562744
- 1.2000830602645873
- 1.1641222214698792
- 1.153931932449341
- 1.1538482785224915
- 1.1494990587234497
- 1.17189918756485
- 1.1535592031478883
- 1.176654748916626
- 1.178641996383667
- 1.1522215962409974
- 1.1701341414451598
- 1.1837184095382691
- 1.1814916777610778
- 1.14710143327713
- 1.146325421333313
- 1.1663568663597106
- 1.1512692642211915
- 1.1503454184532165
- 1.1643741488456727
- 1.1725586247444153
- 1.1790197730064391
- 1.1808349990844726
- 1.1863695788383484
- 1.1865469932556152
- 1.143694875240326
- 1.1427377486228942
- 1.1681223821640014
- 1.1780132102966308
- 1.1450025963783264
- 1.1376801991462708
- 1.145327272415161
- 1.1446737360954284
- 1.1416906905174256
- 1.1478673243522644
- 1.149595286846161
- 1.1470725774765014
- 1.1568954992294311
- 1.1454599928855895
- 1.1464656352996827
train_accuracy:
- 0.0
- 0.087
- 0.085
- 0.116
- 0.16
- 0.174
- 0.154
- 0.0
- 0.174
- 0.175
- 0.224
- 0.0
- 0.19
- 0.244
- 0.251
- 0.207
- 0.204
- 0.229
- 0.209
- 0.283
- 0.226
- 0.191
- 0.0
- 0.251
- 0.244
- 0.227
- 0.264
- 0.248
- 0.242
- 0.212
- 0.301
- 0.293
- 0.242
- 0.277
- 0.298
- 0.228
- 0.314
- 0.307
- 0.273
- 0.304
- 0.261
- 0.246
- 0.0
- 0.271
- 0.275
- 0.306
- 0.29
- 0.295
- 0.315
- 0.327
- 0.283
- 0.274
- 0.279
- 0.0
- 0.249
- 0.302
- 0.0
- 0.302
- 0.291
- 0.352
- 0.307
- 0.296
- 0.335
- 0.307
- 0.314
- 0.316
- 0.306
- 0.334
- 0.33
- 0.285
- 0.304
- 0.326
- 0.334
- 0.321
- 0.303
- 0.325
- 0.354
- 0.0
- 0.336
- 0.306
- 0.324
- 0.333
- 0.303
- 0.342
- 0.307
- 0.339
- 0.331
- 0.309
- 0.329
- 0.0
- 0.285
- 0.34
- 0.292
- 0.314
- 0.296
- 0.329
- 0.342
- 0.344
- 0.0
- 0.34
train_loss:
- 3.606
- 3.833
- 3.604
- 2.933
- 2.814
- 3.173
- 2.643
- 2.542
- 3.017
- 2.881
- 2.829
- 2.374
- 2.643
- 2.545
- 2.644
- 2.153
- 2.032
- 2.339
- 2.023
- 2.266
- 1.946
- 1.838
- 1.84
- 2.102
- 2.126
- 1.98
- 1.872
- 1.599
- 1.645
- 1.618
- 1.879
- 1.529
- 1.421
- 1.671
- 1.365
- 1.611
- 1.656
- 1.535
- 1.311
- 1.231
- 1.181
- 1.38
- 1.358
- 1.131
- 1.284
- 1.156
- 1.297
- 1.285
- 1.155
- 1.281
- 1.051
- 1.016
- 1.102
- 0.907
- 0.976
- 1.183
- 0.899
- 0.822
- 1.045
- 0.951
- 0.927
- 0.863
- 0.783
- 0.789
- 0.811
- 0.733
- 0.808
- 0.715
- 0.748
- 0.841
- 0.71
- 0.746
- 0.709
- 0.702
- 0.637
- 0.622
- 0.658
- 0.552
- 0.528
- 0.636
- 0.631
- 0.601
- 0.577
- 0.555
- 0.539
- 0.513
- 0.485
- 0.53
- 0.51
- 0.446
- 0.454
- 0.43
- 0.42
- 0.424
- 0.374
- 0.376
- 0.413
- 0.453
- 0.4
- 0.358
unequal: 0
verbose: 1
