avg_train_accuracy: 0.312
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0504
- 0.0988
- 0.1168
- 0.1312
- 0.1446
- 0.1532
- 0.166
- 0.1759
- 0.1797
- 0.1876
- 0.1931
- 0.1988
- 0.2058
- 0.2055
- 0.2106
- 0.2157
- 0.2222
- 0.2318
- 0.2332
- 0.2392
- 0.2424
- 0.2457
- 0.2502
- 0.2512
- 0.2562
- 0.2542
- 0.2585
- 0.2606
- 0.2642
- 0.2645
- 0.2666
- 0.2719
- 0.2761
- 0.2799
- 0.2809
- 0.2856
- 0.285
- 0.2861
- 0.2887
- 0.2886
- 0.2944
- 0.2913
- 0.2922
- 0.2898
- 0.2959
- 0.2969
- 0.3007
- 0.3043
- 0.3024
- 0.3051
- 0.3059
- 0.3045
- 0.3097
- 0.304
- 0.3124
- 0.3097
- 0.3123
- 0.3128
- 0.3159
- 0.3117
- 0.3165
- 0.3163
- 0.3148
- 0.3179
- 0.3129
- 0.3202
- 0.3211
- 0.3162
- 0.3206
- 0.3186
- 0.3172
- 0.3222
- 0.3258
- 0.32
- 0.3239
- 0.3261
- 0.3262
- 0.3274
- 0.3248
- 0.324
- 0.3232
- 0.3262
- 0.3292
- 0.325
- 0.3206
- 0.3278
- 0.3257
- 0.3299
- 0.3255
- 0.3322
- 0.3247
- 0.324
- 0.3304
- 0.3274
- 0.3316
- 0.3342
- 0.3281
- 0.3336
- 0.3321
- 0.3363
test_loss_list:
- 1.7887232303619385
- 1.6736102819442749
- 1.6214618968963623
- 1.583265588283539
- 1.5248522853851318
- 1.4892374229431153
- 1.4626291179656983
- 1.4437635946273804
- 1.4366480803489685
- 1.4078560876846313
- 1.3968753004074097
- 1.3826187324523926
- 1.3683659100532533
- 1.375293514728546
- 1.3675819158554077
- 1.3686565470695495
- 1.3614536643028259
- 1.3478632879257202
- 1.343429684638977
- 1.3000501275062561
- 1.2827612662315369
- 1.297528157234192
- 1.272076072692871
- 1.2845670628547667
- 1.2835026931762696
- 1.2900177121162415
- 1.286029109954834
- 1.283797800540924
- 1.2402175307273864
- 1.2529800367355346
- 1.2574162006378173
- 1.2503416728973389
- 1.2202214407920837
- 1.2121436047554015
- 1.2060214972496033
- 1.2027038788795472
- 1.214836492538452
- 1.192994725704193
- 1.1924944972991944
- 1.2059948086738586
- 1.181931390762329
- 1.2030325508117676
- 1.2078464198112489
- 1.2101912474632264
- 1.2086501574516297
- 1.2118438482284546
- 1.2119633078575134
- 1.2041188812255859
- 1.171766984462738
- 1.1642594718933106
- 1.178227128982544
- 1.1573695349693298
- 1.173822021484375
- 1.185239553451538
- 1.1518446040153503
- 1.1733266806602478
- 1.1567637419700623
- 1.1556953191757202
- 1.147627830505371
- 1.1689822959899903
- 1.148121953010559
- 1.146211814880371
- 1.1671860718727112
- 1.143875741958618
- 1.162849862575531
- 1.1433053421974182
- 1.1399159193038941
- 1.1596542811393737
- 1.1446200394630432
- 1.1569449758529664
- 1.1697871899604797
- 1.1701308155059815
- 1.141238384246826
- 1.162422287464142
- 1.1683316540718078
- 1.1389978265762328
- 1.1428645133972168
- 1.1400547218322754
- 1.144281485080719
- 1.1438644170761108
- 1.14483122587204
- 1.1435595536231995
- 1.1403895974159242
- 1.1470863008499146
- 1.1595653200149536
- 1.1357168936729432
- 1.156978726387024
- 1.1427074265480042
- 1.1605975317955017
- 1.1415888619422914
- 1.1616551661491394
- 1.1557017803192138
- 1.1409492254257203
- 1.160735239982605
- 1.1410055661201477
- 1.1451230478286742
- 1.1578416967391967
- 1.1432113695144652
- 1.1480093336105346
- 1.1389057731628418
train_accuracy:
- 0.051
- 0.095
- 0.098
- 0.155
- 0.137
- 0.14
- 0.167
- 0.171
- 0.176
- 0.0
- 0.0
- 0.0
- 0.187
- 0.189
- 0.206
- 0.176
- 0.22
- 0.237
- 0.257
- 0.0
- 0.232
- 0.226
- 0.239
- 0.231
- 0.246
- 0.282
- 0.245
- 0.249
- 0.272
- 0.254
- 0.245
- 0.255
- 0.0
- 0.251
- 0.267
- 0.266
- 0.278
- 0.0
- 0.279
- 0.267
- 0.275
- 0.282
- 0.295
- 0.279
- 0.287
- 0.266
- 0.295
- 0.294
- 0.297
- 0.287
- 0.314
- 0.0
- 0.293
- 0.291
- 0.293
- 0.283
- 0.0
- 0.283
- 0.318
- 0.289
- 0.287
- 0.286
- 0.309
- 0.0
- 0.299
- 0.32
- 0.299
- 0.308
- 0.295
- 0.295
- 0.304
- 0.334
- 0.338
- 0.34
- 0.335
- 0.305
- 0.331
- 0.0
- 0.294
- 0.305
- 0.344
- 0.289
- 0.0
- 0.331
- 0.338
- 0.308
- 0.316
- 0.332
- 0.293
- 0.297
- 0.31
- 0.304
- 0.0
- 0.316
- 0.0
- 0.0
- 0.338
- 0.326
- 0.332
- 0.312
train_loss:
- 4.33
- 3.837
- 3.633
- 3.452
- 2.838
- 2.744
- 2.659
- 2.591
- 2.991
- 2.447
- 2.353
- 2.292
- 2.272
- 2.592
- 2.569
- 2.428
- 2.396
- 2.466
- 2.278
- 1.916
- 1.918
- 2.222
- 1.837
- 2.058
- 2.081
- 1.979
- 1.881
- 1.83
- 1.662
- 1.794
- 1.788
- 1.744
- 1.481
- 1.387
- 1.413
- 1.313
- 1.604
- 1.388
- 1.262
- 1.481
- 1.205
- 1.384
- 1.359
- 1.34
- 1.308
- 1.254
- 1.271
- 1.258
- 1.08
- 0.99
- 1.124
- 0.957
- 1.093
- 1.094
- 0.897
- 0.982
- 0.775
- 0.787
- 0.926
- 0.888
- 0.8
- 0.759
- 0.925
- 0.807
- 0.813
- 0.724
- 0.637
- 0.782
- 0.69
- 0.78
- 0.74
- 0.713
- 0.637
- 0.679
- 0.659
- 0.589
- 0.559
- 0.52
- 0.552
- 0.523
- 0.465
- 0.516
- 0.528
- 0.479
- 0.546
- 0.481
- 0.504
- 0.471
- 0.53
- 0.434
- 0.5
- 0.421
- 0.442
- 0.464
- 0.4
- 0.398
- 0.424
- 0.376
- 0.345
- 0.372
unequal: 0
verbose: 1
