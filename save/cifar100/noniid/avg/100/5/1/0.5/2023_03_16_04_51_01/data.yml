avg_train_accuracy: 0.387
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0366
- 0.0881
- 0.1139
- 0.1211
- 0.1394
- 0.1446
- 0.1593
- 0.1709
- 0.1722
- 0.1823
- 0.1926
- 0.1968
- 0.2032
- 0.2072
- 0.2142
- 0.2174
- 0.2222
- 0.227
- 0.2265
- 0.2356
- 0.2367
- 0.2425
- 0.2464
- 0.2476
- 0.2508
- 0.249
- 0.2536
- 0.256
- 0.2605
- 0.2587
- 0.265
- 0.2678
- 0.2697
- 0.2739
- 0.2787
- 0.2754
- 0.2798
- 0.2791
- 0.2844
- 0.285
- 0.2847
- 0.2879
- 0.287
- 0.2914
- 0.2947
- 0.2911
- 0.2895
- 0.292
- 0.2958
- 0.2947
- 0.2987
- 0.2988
- 0.2999
- 0.2978
- 0.2998
- 0.3016
- 0.2986
- 0.3047
- 0.3059
- 0.3006
- 0.3027
- 0.3077
- 0.3101
- 0.307
- 0.3056
- 0.3082
- 0.3082
- 0.3118
- 0.3107
- 0.3131
- 0.3108
- 0.31
- 0.317
- 0.3168
- 0.3178
- 0.3156
- 0.3138
- 0.3108
- 0.3142
- 0.3165
- 0.3185
- 0.3174
- 0.3184
- 0.3161
- 0.32
- 0.3264
- 0.3237
- 0.3208
- 0.3248
- 0.3242
- 0.3309
- 0.3202
- 0.3222
- 0.3259
- 0.3198
- 0.3217
- 0.3285
- 0.3225
- 0.3264
- 0.3271
test_loss_list:
- 1.8005343437194825
- 1.6675095796585082
- 1.6102637457847595
- 1.561054744720459
- 1.5347977995872497
- 1.5233882331848145
- 1.475822069644928
- 1.4474773955345155
- 1.4491299033164977
- 1.4144180464744567
- 1.3974344897270203
- 1.3849076056480407
- 1.3727875542640686
- 1.373363835811615
- 1.3485344195365905
- 1.3544682502746581
- 1.3489967370033265
- 1.3209592509269714
- 1.3330658555030823
- 1.3281081533432006
- 1.2965250492095948
- 1.2856029653549195
- 1.2948604798316956
- 1.2955233550071716
- 1.266536045074463
- 1.2781301403045655
- 1.2542791414260863
- 1.2679431104660035
- 1.2694381308555602
- 1.2715407037734985
- 1.2744562482833863
- 1.2652666974067688
- 1.2348130178451537
- 1.2231000924110413
- 1.2313296103477478
- 1.2198621654510498
- 1.2296693301200867
- 1.232962532043457
- 1.2320184779167176
- 1.2002508378028869
- 1.1956344270706176
- 1.188748278617859
- 1.1899685740470887
- 1.186511251926422
- 1.1982626175880433
- 1.1793025302886964
- 1.1919311237335206
- 1.1776743125915528
- 1.192032527923584
- 1.1974778151512147
- 1.171903564929962
- 1.1860042715072632
- 1.1988618969917297
- 1.1731062197685242
- 1.1885895800590516
- 1.1682790064811706
- 1.1814770936965941
- 1.1621006369590758
- 1.155411388874054
- 1.1799088048934936
- 1.1644916772842406
- 1.1566571021080017
- 1.1547832775115967
- 1.1754920125007629
- 1.1808108282089234
- 1.1590467286109924
- 1.1741272807121277
- 1.1733927631378174
- 1.1795323288440704
- 1.1541042399406434
- 1.1479499864578246
- 1.173514748811722
- 1.1443780589103698
- 1.1618135523796083
- 1.1465633702278137
- 1.16465181350708
- 1.1535312509536744
- 1.1682859945297241
- 1.1511228728294371
- 1.1675611543655395
- 1.1746702313423156
- 1.180428569316864
- 1.173958464860916
- 1.1497477078437806
- 1.1672398519515992
- 1.144395921230316
- 1.1489348244667053
- 1.1544844794273377
- 1.1459957146644593
- 1.1555308151245116
- 1.1423308920860291
- 1.1585154795646668
- 1.1671538496017455
- 1.1416898655891419
- 1.1643525743484497
- 1.1701886034011841
- 1.1494150161743164
- 1.1711485004425048
- 1.148399738073349
- 1.1512570238113404
train_accuracy:
- 0.05
- 0.087
- 0.126
- 0.144
- 0.154
- 0.144
- 0.11
- 0.154
- 0.169
- 0.189
- 0.21
- 0.126
- 0.0
- 0.208
- 0.206
- 0.216
- 0.138
- 0.231
- 0.221
- 0.253
- 0.164
- 0.249
- 0.227
- 0.251
- 0.246
- 0.23
- 0.229
- 0.248
- 0.241
- 0.246
- 0.196
- 0.275
- 0.245
- 0.249
- 0.27
- 0.0
- 0.279
- 0.274
- 0.336
- 0.229
- 0.273
- 0.274
- 0.277
- 0.257
- 0.219
- 0.259
- 0.292
- 0.325
- 0.281
- 0.218
- 0.0
- 0.299
- 0.301
- 0.28
- 0.25
- 0.346
- 0.295
- 0.292
- 0.301
- 0.297
- 0.0
- 0.0
- 0.303
- 0.307
- 0.307
- 0.272
- 0.3
- 0.247
- 0.308
- 0.0
- 0.312
- 0.315
- 0.227
- 0.257
- 0.299
- 0.302
- 0.312
- 0.375
- 0.303
- 0.313
- 0.287
- 0.383
- 0.248
- 0.0
- 0.306
- 0.309
- 0.0
- 0.295
- 0.314
- 0.319
- 0.311
- 0.326
- 0.249
- 0.0
- 0.309
- 0.32
- 0.392
- 0.377
- 0.326
- 0.387
train_loss:
- 3.65
- 3.323
- 3.706
- 2.978
- 3.43
- 3.294
- 2.717
- 2.59
- 3.027
- 2.446
- 2.385
- 2.342
- 2.305
- 2.698
- 2.251
- 2.635
- 2.493
- 2.106
- 2.386
- 2.313
- 2.003
- 1.918
- 2.175
- 2.131
- 1.792
- 2.042
- 1.777
- 2.023
- 1.928
- 1.867
- 1.791
- 1.784
- 1.444
- 1.429
- 1.746
- 1.437
- 1.66
- 1.623
- 1.553
- 1.29
- 1.223
- 1.347
- 1.187
- 1.179
- 1.438
- 1.177
- 1.359
- 1.086
- 1.241
- 1.208
- 0.984
- 1.276
- 1.101
- 0.99
- 1.077
- 0.886
- 1.078
- 0.878
- 0.892
- 0.946
- 0.791
- 0.811
- 0.812
- 0.866
- 0.887
- 0.733
- 0.879
- 0.894
- 0.84
- 0.701
- 0.668
- 0.71
- 0.643
- 0.776
- 0.638
- 0.69
- 0.569
- 0.628
- 0.571
- 0.673
- 0.591
- 0.587
- 0.637
- 0.537
- 0.576
- 0.499
- 0.457
- 0.424
- 0.504
- 0.541
- 0.443
- 0.519
- 0.504
- 0.452
- 0.458
- 0.474
- 0.411
- 0.426
- 0.38
- 0.367
unequal: 0
verbose: 1
