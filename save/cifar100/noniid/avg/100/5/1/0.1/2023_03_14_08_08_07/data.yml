avg_train_accuracy: 0.286
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0446
- 0.0805
- 0.0995
- 0.1145
- 0.1269
- 0.1326
- 0.1395
- 0.1435
- 0.149
- 0.1604
- 0.1644
- 0.1636
- 0.1686
- 0.186
- 0.1832
- 0.1921
- 0.1937
- 0.2049
- 0.204
- 0.2137
- 0.0323
- 0.214
- 0.0346
- 0.2202
- 0.2207
- 0.035
- 0.2222
- 0.2244
- 0.2303
- 0.2252
- 0.2284
- 0.2436
- 0.2358
- 0.2471
- 0.0349
- 0.248
- 0.2475
- 0.2507
- 0.2578
- 0.2449
- 0.2616
- 0.2538
- 0.2619
- 0.268
- 0.2639
- 0.0374
- 0.2647
- 0.2725
- 0.2734
- 0.2819
- 0.276
- 0.279
- 0.2799
- 0.2791
- 0.0394
- 0.2859
- 0.2843
- 0.2775
- 0.2899
- 0.2899
- 0.2908
- 0.2885
- 0.2818
- 0.2963
- 0.2947
- 0.3017
- 0.2951
- 0.2731
- 0.3001
- 0.0379
- 0.2963
- 0.3041
- 0.3007
- 0.3012
- 0.2997
- 0.295
- 0.287
- 0.2997
- 0.2883
- 0.3083
- 0.2916
- 0.306
- 0.0436
- 0.2953
- 0.3075
- 0.3076
- 0.05
- 0.309
- 0.3059
- 0.3062
- 0.3157
- 0.3071
- 0.3052
- 0.3099
- 0.3065
- 0.3077
- 0.3125
- 0.3108
- 0.3128
- 0.315
test_loss_list:
- 1.7984118604660033
- 1.7018725156784058
- 1.6555367851257323
- 1.6220711183547973
- 1.5918194317817689
- 1.5820181274414062
- 1.5873307800292968
- 1.5657222700119018
- 1.5530739951133727
- 1.514632740020752
- 1.5128842639923095
- 1.514462411403656
- 1.5225894236564637
- 1.4843883323669433
- 1.4881839561462402
- 1.4601869297027588
- 1.4611528420448303
- 1.436263725757599
- 1.442348370552063
- 1.4509859204292297
- 3.7086128044128417
- 1.3730648016929627
- 3.4858465576171875
- 1.3521730041503905
- 1.3611611390113831
- 3.416616506576538
- 1.3501697421073913
- 1.3539143157005311
- 1.3406610822677612
- 1.3598852705955506
- 1.3499712252616882
- 1.3452571201324464
- 1.3514194703102111
- 1.3203383350372315
- 3.3509732818603517
- 1.2924026012420655
- 1.2967601680755616
- 1.2963106751441955
- 1.2921213173866273
- 1.3288829803466797
- 1.296184651851654
- 1.2981006717681884
- 1.3044729828834534
- 1.292061414718628
- 1.3039005970954896
- 3.1526686000823974
- 1.2563147473335265
- 1.2682176923751831
- 1.2622823452949523
- 1.2615988802909852
- 1.27920236825943
- 1.2671898365020753
- 1.2743695259094239
- 1.2749343371391297
- 3.146878366470337
- 1.233205831050873
- 1.237913749217987
- 1.2500618171691895
- 1.231936104297638
- 1.2381718468666076
- 1.233739242553711
- 1.2320115756988526
- 1.2470357704162598
- 1.2442457151412964
- 1.2478817439079284
- 1.2441478705406188
- 1.2449836659431457
- 1.2889841556549073
- 1.2433108139038085
- 3.212016682624817
- 1.2115264654159545
- 1.2135371518135072
- 1.2137127065658568
- 1.2337450551986695
- 1.231971549987793
- 1.2380088686943054
- 1.2621269607543946
- 1.2382922625541688
- 1.2634378790855407
- 1.2350089693069457
- 1.2662650847434997
- 1.248920533657074
- 3.096556363105774
- 1.2240675115585327
- 1.2127914690971375
- 1.22133775472641
- 2.9655710077285766
- 1.215491030216217
- 1.226154520511627
- 1.2175209045410156
- 1.2163281178474425
- 1.2344175028800963
- 1.2385343647003173
- 1.2361226463317871
- 1.225017387866974
- 1.2511765003204345
- 1.2329047632217407
- 1.2439673161506652
- 1.2387418341636658
- 1.23535706281662
train_accuracy:
- 0.065
- 0.081
- 0.117
- 0.108
- 0.16
- 0.11
- 0.119
- 0.133
- 0.153
- 0.169
- 0.162
- 0.173
- 0.185
- 0.169
- 0.196
- 0.185
- 0.23
- 0.176
- 0.195
- 0.216
- 0.0
- 0.199
- 0.0
- 0.258
- 0.219
- 0.0
- 0.258
- 0.229
- 0.232
- 0.224
- 0.237
- 0.239
- 0.227
- 0.231
- 0.0
- 0.237
- 0.271
- 0.267
- 0.257
- 0.247
- 0.226
- 0.275
- 0.268
- 0.266
- 0.266
- 0.0
- 0.251
- 0.267
- 0.289
- 0.275
- 0.267
- 0.307
- 0.278
- 0.291
- 0.0
- 0.308
- 0.259
- 0.275
- 0.297
- 0.333
- 0.238
- 0.298
- 0.282
- 0.311
- 0.297
- 0.294
- 0.334
- 0.281
- 0.25
- 0.0
- 0.334
- 0.299
- 0.311
- 0.356
- 0.314
- 0.288
- 0.302
- 0.319
- 0.282
- 0.327
- 0.29
- 0.311
- 0.0
- 0.296
- 0.264
- 0.346
- 0.0
- 0.332
- 0.333
- 0.271
- 0.371
- 0.348
- 0.316
- 0.346
- 0.3
- 0.329
- 0.312
- 0.328
- 0.316
- 0.286
train_loss:
- 4.325
- 3.919
- 3.521
- 3.557
- 3.469
- 3.075
- 2.703
- 3.295
- 3.116
- 3.168
- 2.842
- 3.088
- 2.551
- 2.566
- 2.648
- 2.695
- 2.718
- 2.73
- 2.833
- 2.333
- 1.021
- 2.588
- 0.65
- 2.645
- 2.437
- 0.58
- 2.218
- 2.296
- 2.296
- 1.871
- 1.862
- 2.112
- 2.228
- 2.226
- 0.598
- 2.756
- 1.774
- 2.203
- 1.764
- 1.277
- 1.869
- 1.529
- 1.852
- 1.836
- 1.819
- 0.577
- 2.322
- 1.453
- 1.351
- 1.814
- 1.297
- 1.769
- 1.61
- 1.318
- 0.478
- 1.564
- 1.555
- 1.809
- 1.362
- 1.43
- 1.607
- 1.226
- 1.447
- 1.342
- 1.177
- 1.013
- 1.238
- 1.231
- 1.329
- 0.486
- 1.127
- 0.901
- 1.015
- 0.775
- 1.189
- 1.062
- 0.693
- 0.906
- 0.625
- 0.715
- 0.535
- 1.175
- 0.438
- 0.634
- 1.159
- 0.613
- 0.301
- 1.027
- 0.89
- 0.864
- 0.526
- 0.313
- 0.615
- 0.871
- 0.562
- 1.025
- 0.627
- 0.713
- 0.954
- 0.631
unequal: 0
verbose: 1
