avg_train_accuracy: 0.249
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0363
- 0.0772
- 0.0936
- 0.1175
- 0.1328
- 0.1344
- 0.1497
- 0.1493
- 0.1613
- 0.1655
- 0.1798
- 0.1785
- 0.1898
- 0.1836
- 0.1936
- 0.1933
- 0.1986
- 0.1953
- 0.1988
- 0.2043
- 0.2175
- 0.2141
- 0.2268
- 0.2244
- 0.2256
- 0.2269
- 0.2321
- 0.2353
- 0.2424
- 0.2456
- 0.2421
- 0.2368
- 0.2359
- 0.0341
- 0.2389
- 0.2448
- 0.2473
- 0.2417
- 0.2516
- 0.2484
- 0.2538
- 0.0346
- 0.2613
- 0.2543
- 0.2635
- 0.0367
- 0.2602
- 0.263
- 0.2633
- 0.2684
- 0.2653
- 0.0383
- 0.2718
- 0.2714
- 0.2819
- 0.2752
- 0.2771
- 0.0374
- 0.2805
- 0.2779
- 0.2772
- 0.286
- 0.2838
- 0.2777
- 0.2779
- 0.2881
- 0.2899
- 0.2887
- 0.2833
- 0.2829
- 0.2883
- 0.2905
- 0.2861
- 0.2869
- 0.2856
- 0.2865
- 0.2888
- 0.2851
- 0.2875
- 0.2932
- 0.289
- 0.2987
- 0.2945
- 0.2951
- 0.2928
- 0.3056
- 0.3032
- 0.3073
- 0.3016
- 0.3008
- 0.2969
- 0.3021
- 0.3083
- 0.2943
- 0.307
- 0.3023
- 0.3083
- 0.0441
- 0.3066
- 0.2987
test_loss_list:
- 1.795342617034912
- 1.697199890613556
- 1.6574538111686707
- 1.6167339181900025
- 1.59370414018631
- 1.5785310769081116
- 1.5556062722206117
- 1.5545097184181214
- 1.5433763766288757
- 1.5218310713768006
- 1.5087504196166992
- 1.4969238877296447
- 1.481615695953369
- 1.4871769332885743
- 1.474087314605713
- 1.4765477561950684
- 1.4749704313278198
- 1.4637748408317566
- 1.4448976945877074
- 1.4497417736053466
- 1.4250905585289002
- 1.4291233730316162
- 1.4192542982101441
- 1.4181027221679687
- 1.4214543771743775
- 1.4043796920776368
- 1.4057639455795288
- 1.4135513520240783
- 1.394246096611023
- 1.3765089011192322
- 1.4013561248779296
- 1.390474054813385
- 1.4051877021789552
- 3.677739391326904
- 1.3163974714279174
- 1.3226258945465088
- 1.3174157595634461
- 1.3360841131210328
- 1.329520227909088
- 1.3340480065345763
- 1.32545396566391
- 3.481209411621094
- 1.2851972794532776
- 1.30185608625412
- 1.286139041185379
- 3.28772488117218
- 1.2796321654319762
- 1.27392502784729
- 1.2768410229682923
- 1.2833375501632691
- 1.2776349306106567
- 3.2403392457962035
- 1.2514795446395874
- 1.260462670326233
- 1.259613983631134
- 1.26833025932312
- 1.2781536483764648
- 3.2489962673187254
- 1.2394842624664306
- 1.2599916124343873
- 1.2483641862869264
- 1.2368979930877686
- 1.2627901220321656
- 1.2654023814201354
- 1.2847033715248108
- 1.2592824292182923
- 1.2556744623184204
- 1.276309881210327
- 1.2851601767539977
- 1.279886281490326
- 1.275933369398117
- 1.267162721157074
- 1.287226083278656
- 1.2759913229942321
- 1.290862729549408
- 1.2958177709579468
- 1.2852880954742432
- 1.2985101008415223
- 1.2893171834945678
- 1.2783767008781433
- 1.3022485423088073
- 1.2734204506874085
- 1.295592486858368
- 1.2908716535568237
- 1.3105913591384888
- 1.2740753865242005
- 1.2843073010444641
- 1.2745589900016785
- 1.2928147089481354
- 1.2965023636817932
- 1.2949243760108948
- 1.284271469116211
- 1.2913891863822937
- 1.2996676969528198
- 1.270078387260437
- 1.2849559450149537
- 1.2825574946403504
- 3.1660714387893676
- 1.2174023699760437
- 1.270082938671112
train_accuracy:
- 0.05
- 0.069
- 0.09
- 0.139
- 0.128
- 0.117
- 0.133
- 0.133
- 0.148
- 0.145
- 0.202
- 0.157
- 0.183
- 0.168
- 0.172
- 0.147
- 0.162
- 0.18
- 0.168
- 0.154
- 0.206
- 0.198
- 0.205
- 0.207
- 0.186
- 0.181
- 0.193
- 0.197
- 0.2
- 0.221
- 0.214
- 0.251
- 0.199
- 0.0
- 0.181
- 0.223
- 0.209
- 0.196
- 0.239
- 0.206
- 0.273
- 0.0
- 0.231
- 0.251
- 0.261
- 0.0
- 0.23
- 0.241
- 0.254
- 0.23
- 0.247
- 0.0
- 0.253
- 0.227
- 0.241
- 0.237
- 0.24
- 0.0
- 0.227
- 0.272
- 0.228
- 0.279
- 0.245
- 0.291
- 0.218
- 0.316
- 0.26
- 0.247
- 0.238
- 0.297
- 0.3
- 0.271
- 0.267
- 0.259
- 0.263
- 0.299
- 0.286
- 0.307
- 0.285
- 0.305
- 0.285
- 0.248
- 0.309
- 0.255
- 0.243
- 0.321
- 0.281
- 0.309
- 0.302
- 0.274
- 0.287
- 0.266
- 0.295
- 0.237
- 0.258
- 0.235
- 0.298
- 0.0
- 0.307
- 0.249
train_loss:
- 4.296
- 3.853
- 3.701
- 3.631
- 3.315
- 3.482
- 3.292
- 3.231
- 2.869
- 3.108
- 3.023
- 2.972
- 2.75
- 2.561
- 2.406
- 2.717
- 2.5
- 2.758
- 2.766
- 2.269
- 2.219
- 2.827
- 2.331
- 1.861
- 2.338
- 2.16
- 2.381
- 2.101
- 2.427
- 1.693
- 1.989
- 2.3
- 1.801
- 1.053
- 2.26
- 2.022
- 1.572
- 1.214
- 1.98
- 2.038
- 1.567
- 0.712
- 1.882
- 1.315
- 1.555
- 0.568
- 2.124
- 2.204
- 1.247
- 1.715
- 1.948
- 0.527
- 1.749
- 1.377
- 1.478
- 1.296
- 1.127
- 0.466
- 1.372
- 1.821
- 1.397
- 1.322
- 1.552
- 1.611
- 1.131
- 1.249
- 1.198
- 0.782
- 0.571
- 0.939
- 1.054
- 1.536
- 0.935
- 0.716
- 0.424
- 0.872
- 0.868
- 0.582
- 1.389
- 0.523
- 0.329
- 0.559
- 0.304
- 0.391
- 1.108
- 0.752
- 1.109
- 0.547
- 0.34
- 0.756
- 1.134
- 0.593
- 0.497
- 1.137
- 0.514
- 0.718
- 0.517
- 0.572
- 0.554
- 0.895
unequal: 0
verbose: 1
