avg_train_accuracy: 0.306
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0387
- 0.09
- 0.0984
- 0.1084
- 0.1138
- 0.1398
- 0.1417
- 0.1449
- 0.16
- 0.1563
- 0.1695
- 0.1716
- 0.1709
- 0.1769
- 0.1882
- 0.1858
- 0.1888
- 0.1977
- 0.2034
- 0.2098
- 0.2084
- 0.2019
- 0.2
- 0.2092
- 0.2117
- 0.2134
- 0.2278
- 0.2333
- 0.2219
- 0.2242
- 0.2318
- 0.225
- 0.2398
- 0.2457
- 0.2419
- 0.2485
- 0.2477
- 0.2494
- 0.2565
- 0.2436
- 0.036
- 0.2526
- 0.2437
- 0.2515
- 0.2418
- 0.2525
- 0.2528
- 0.2627
- 0.2631
- 0.2726
- 0.2619
- 0.2668
- 0.2659
- 0.2744
- 0.2665
- 0.271
- 0.2642
- 0.2782
- 0.2824
- 0.2658
- 0.2697
- 0.2732
- 0.27
- 0.2817
- 0.2786
- 0.2889
- 0.2876
- 0.2776
- 0.037
- 0.2827
- 0.2869
- 0.2889
- 0.2854
- 0.2855
- 0.299
- 0.2843
- 0.29
- 0.0369
- 0.2948
- 0.2895
- 0.2904
- 0.3021
- 0.2952
- 0.2997
- 0.2966
- 0.2952
- 0.2928
- 0.2972
- 0.3018
- 0.3025
- 0.2841
- 0.2902
- 0.3052
- 0.3011
- 0.3037
- 0.3085
- 0.3093
- 0.0397
- 0.3114
- 0.3008
test_loss_list:
- 1.8040744495391845
- 1.6976207494735718
- 1.6532241463661195
- 1.6387032651901245
- 1.6276543498039246
- 1.5935660982131958
- 1.569995892047882
- 1.5576841735839844
- 1.5399783754348755
- 1.5452357864379882
- 1.5230088925361633
- 1.5349242997169494
- 1.5206165981292725
- 1.4921438574790955
- 1.4808097767829895
- 1.4892650294303893
- 1.4802939677238465
- 1.4673161673545838
- 1.4590313959121703
- 1.4541088986396788
- 1.4578575944900514
- 1.4711491751670838
- 1.4874538111686706
- 1.445789270401001
- 1.4557984447479249
- 1.4418108415603639
- 1.407103362083435
- 1.4006068754196166
- 1.4360462522506714
- 1.4229798221588135
- 1.419002366065979
- 1.4251838326454163
- 1.4024535632133484
- 1.3805275106430053
- 1.4026168060302735
- 1.3854720091819763
- 1.3882149863243103
- 1.3647456192970275
- 1.3743032121658325
- 1.405600163936615
- 3.7414849281311033
- 1.3048149752616882
- 1.335352771282196
- 1.338610098361969
- 1.3525220680236816
- 1.3257634520530701
- 1.3456313371658326
- 1.3252466320991516
- 1.3179131746292114
- 1.3052344179153443
- 1.3190741372108459
- 1.3194313073158264
- 1.3249941730499268
- 1.2956292176246642
- 1.3388181328773499
- 1.321462116241455
- 1.3347772693634032
- 1.306050293445587
- 1.312938630580902
- 1.3265807676315307
- 1.327714376449585
- 1.3265027785301209
- 1.33988214969635
- 1.297701699733734
- 1.3260772824287415
- 1.297134976387024
- 1.3136258697509766
- 1.3275016331672669
- 3.473555631637573
- 1.2616167855262757
- 1.2664501976966858
- 1.2496065545082091
- 1.2610169458389282
- 1.272963376045227
- 1.2474010586738586
- 1.2765933752059937
- 1.2783047342300415
- 3.4127133178710936
- 1.2277481937408448
- 1.2630178713798523
- 1.2663067364692688
- 1.242166473865509
- 1.2512159633636475
- 1.255274486541748
- 1.2552615189552307
- 1.2823174047470092
- 1.2898497843742371
- 1.2808965253829956
- 1.2666774702072143
- 1.27785489320755
- 1.3002815675735473
- 1.2959334063529968
- 1.2579175686836244
- 1.2644451546669007
- 1.2695063948631287
- 1.2716274285316467
- 1.2783002829551697
- 3.2848771381378175
- 1.2155287981033325
- 1.243435685634613
train_accuracy:
- 0.055
- 0.085
- 0.081
- 0.103
- 0.129
- 0.128
- 0.13
- 0.138
- 0.149
- 0.166
- 0.16
- 0.15
- 0.191
- 0.174
- 0.201
- 0.188
- 0.194
- 0.188
- 0.185
- 0.2
- 0.188
- 0.196
- 0.189
- 0.209
- 0.23
- 0.227
- 0.21
- 0.225
- 0.208
- 0.206
- 0.228
- 0.21
- 0.219
- 0.252
- 0.239
- 0.231
- 0.277
- 0.254
- 0.231
- 0.222
- 0.0
- 0.234
- 0.236
- 0.24
- 0.23
- 0.216
- 0.246
- 0.247
- 0.241
- 0.285
- 0.274
- 0.284
- 0.284
- 0.265
- 0.252
- 0.251
- 0.244
- 0.297
- 0.319
- 0.263
- 0.283
- 0.29
- 0.285
- 0.298
- 0.319
- 0.266
- 0.272
- 0.286
- 0.0
- 0.306
- 0.295
- 0.335
- 0.309
- 0.304
- 0.271
- 0.297
- 0.33
- 0.0
- 0.318
- 0.295
- 0.289
- 0.291
- 0.301
- 0.319
- 0.32
- 0.304
- 0.267
- 0.291
- 0.245
- 0.266
- 0.327
- 0.341
- 0.322
- 0.338
- 0.321
- 0.338
- 0.337
- 0.0
- 0.323
- 0.306
train_loss:
- 4.316
- 3.888
- 3.736
- 3.234
- 3.568
- 3.183
- 3.344
- 3.343
- 2.912
- 3.205
- 2.773
- 2.35
- 2.95
- 2.988
- 2.885
- 2.4
- 2.796
- 2.266
- 2.545
- 2.854
- 1.967
- 1.565
- 1.342
- 2.648
- 2.404
- 2.632
- 2.512
- 2.205
- 1.707
- 2.139
- 2.258
- 1.805
- 2.42
- 2.25
- 1.932
- 2.117
- 2.075
- 1.751
- 1.52
- 1.089
- 1.076
- 2.043
- 1.264
- 1.085
- 0.77
- 1.835
- 1.265
- 2.021
- 1.556
- 1.84
- 2.231
- 1.807
- 1.219
- 1.839
- 1.202
- 1.024
- 1.044
- 1.663
- 1.552
- 1.799
- 1.21
- 1.309
- 0.825
- 1.37
- 0.741
- 1.382
- 1.151
- 1.297
- 0.821
- 1.014
- 1.128
- 1.331
- 1.037
- 0.871
- 1.357
- 0.855
- 0.696
- 0.607
- 1.596
- 0.792
- 1.045
- 1.042
- 0.774
- 0.84
- 0.822
- 0.768
- 1.149
- 0.653
- 0.884
- 0.525
- 1.069
- 0.647
- 0.71
- 0.704
- 0.464
- 0.685
- 0.695
- 0.587
- 0.99
- 0.565
unequal: 0
verbose: 1
