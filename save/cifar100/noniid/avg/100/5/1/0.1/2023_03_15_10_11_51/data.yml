avg_train_accuracy: 0.322
avg_train_loss: 0.008
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0427
- 0.0802
- 0.0905
- 0.116
- 0.1143
- 0.1207
- 0.1377
- 0.1427
- 0.1522
- 0.1512
- 0.0318
- 0.1659
- 0.1713
- 0.0329
- 0.1713
- 0.1715
- 0.1791
- 0.1806
- 0.1954
- 0.1903
- 0.1994
- 0.2081
- 0.2038
- 0.2174
- 0.221
- 0.0332
- 0.2182
- 0.2253
- 0.2346
- 0.2296
- 0.2364
- 0.2366
- 0.2478
- 0.239
- 0.2396
- 0.2436
- 0.2482
- 0.2471
- 0.2518
- 0.2549
- 0.2463
- 0.0355
- 0.2406
- 0.2532
- 0.2627
- 0.258
- 0.2753
- 0.2713
- 0.2684
- 0.2776
- 0.2802
- 0.2598
- 0.2796
- 0.2805
- 0.2811
- 0.2791
- 0.2851
- 0.2875
- 0.2839
- 0.2822
- 0.2879
- 0.2867
- 0.2847
- 0.2856
- 0.2859
- 0.2928
- 0.2836
- 0.0376
- 0.2791
- 0.0453
- 0.2767
- 0.293
- 0.289
- 0.2896
- 0.2951
- 0.2961
- 0.2962
- 0.2846
- 0.2927
- 0.3058
- 0.3088
- 0.3025
- 0.3066
- 0.289
- 0.0432
- 0.2942
- 0.2985
- 0.2974
- 0.299
- 0.3004
- 0.3062
- 0.3149
- 0.3045
- 0.3145
- 0.0455
- 0.3094
- 0.3033
- 0.3009
- 0.3054
- 0.3141
test_loss_list:
- 1.7966250467300415
- 1.6956433701515197
- 1.6655464839935303
- 1.618315794467926
- 1.6187441992759704
- 1.5919794821739197
- 1.5761363506317139
- 1.5559194993972778
- 1.54743155002594
- 1.5571932077407837
- 3.9027164649963377
- 1.4834817147254944
- 1.472302737236023
- 3.5520487594604493
- 1.4656493806838988
- 1.4582316184043884
- 1.4560379672050476
- 1.461235544681549
- 1.4322321677207948
- 1.4438979244232177
- 1.4184878635406495
- 1.4168617272377013
- 1.4162932753562927
- 1.4010981941223144
- 1.390879123210907
- 3.4706202125549317
- 1.3497950887680055
- 1.351933217048645
- 1.3530903553962708
- 1.353613588809967
- 1.3402997398376464
- 1.3494048810005188
- 1.3326411247253418
- 1.3483030986785889
- 1.3520243000984191
- 1.3348627758026124
- 1.3341984391212462
- 1.3382139253616332
- 1.3413666844367982
- 1.3253523588180542
- 1.3552759552001954
- 3.4675465202331544
- 1.3282356905937194
- 1.299249210357666
- 1.2778654384613037
- 1.309899389743805
- 1.2775790452957154
- 1.2866298174858093
- 1.2905440020561219
- 1.2791552925109864
- 1.2819066739082337
- 1.3255457139015199
- 1.2810034680366515
- 1.285205454826355
- 1.2823118877410888
- 1.287877507209778
- 1.2866167640686035
- 1.2818243956565858
- 1.2874287867546081
- 1.289653286933899
- 1.2928841137886047
- 1.2826678943634033
- 1.300061390399933
- 1.295685338973999
- 1.2962354564666747
- 1.2895025491714478
- 1.3039919495582581
- 3.331297001838684
- 1.2647484159469604
- 3.0149760150909426
- 1.2715300941467285
- 1.2401864838600158
- 1.2580839681625366
- 1.2544597721099853
- 1.2526522707939147
- 1.2480530142784119
- 1.2499762463569641
- 1.2914809465408326
- 1.2646084880828858
- 1.2389135718345643
- 1.2438504266738892
- 1.2617545676231385
- 1.2622767400741577
- 1.284120421409607
- 3.1448084545135497
- 1.2355869388580323
- 1.2334858560562134
- 1.2448932147026062
- 1.2468306159973144
- 1.246108078956604
- 1.2417398118972778
- 1.2340514087677001
- 1.2624103212356568
- 1.2268706774711609
- 3.0308303117752073
- 1.2133391499519348
- 1.2490094351768493
- 1.2519008588790894
- 1.2404350185394286
- 1.2294215202331542
train_accuracy:
- 0.069
- 0.092
- 0.092
- 0.105
- 0.117
- 0.119
- 0.152
- 0.145
- 0.165
- 0.17
- 0.0
- 0.19
- 0.174
- 0.0
- 0.188
- 0.165
- 0.192
- 0.166
- 0.237
- 0.192
- 0.172
- 0.223
- 0.226
- 0.265
- 0.206
- 0.0
- 0.225
- 0.225
- 0.237
- 0.235
- 0.289
- 0.293
- 0.267
- 0.251
- 0.269
- 0.241
- 0.279
- 0.249
- 0.255
- 0.261
- 0.252
- 0.0
- 0.232
- 0.24
- 0.251
- 0.261
- 0.306
- 0.283
- 0.312
- 0.29
- 0.266
- 0.247
- 0.288
- 0.293
- 0.273
- 0.296
- 0.344
- 0.291
- 0.305
- 0.314
- 0.315
- 0.299
- 0.286
- 0.249
- 0.296
- 0.321
- 0.308
- 0.0
- 0.255
- 0.0
- 0.291
- 0.277
- 0.271
- 0.3
- 0.344
- 0.306
- 0.295
- 0.292
- 0.303
- 0.359
- 0.35
- 0.369
- 0.338
- 0.266
- 0.0
- 0.275
- 0.286
- 0.3
- 0.292
- 0.33
- 0.3
- 0.305
- 0.319
- 0.344
- 0.0
- 0.354
- 0.343
- 0.341
- 0.272
- 0.322
train_loss:
- 4.311
- 3.914
- 3.622
- 3.653
- 3.256
- 3.424
- 3.339
- 3.306
- 2.912
- 2.533
- 1.074
- 3.401
- 2.965
- 0.746
- 2.658
- 2.744
- 2.782
- 2.358
- 2.943
- 2.068
- 2.538
- 2.411
- 2.568
- 2.543
- 2.729
- 0.732
- 2.81
- 2.235
- 1.964
- 2.125
- 2.15
- 2.058
- 2.619
- 1.828
- 1.704
- 2.334
- 1.901
- 1.951
- 1.606
- 2.198
- 1.664
- 0.708
- 1.638
- 1.94
- 2.136
- 1.541
- 1.645
- 2.004
- 1.774
- 1.493
- 1.403
- 0.97
- 1.679
- 1.653
- 1.679
- 1.268
- 1.497
- 1.336
- 1.092
- 1.419
- 1.269
- 1.132
- 0.71
- 1.787
- 1.446
- 1.171
- 0.769
- 0.654
- 1.299
- 0.356
- 1.021
- 1.104
- 0.725
- 1.438
- 1.3
- 1.106
- 1.474
- 0.773
- 1.025
- 1.053
- 0.921
- 0.695
- 0.604
- 1.031
- 0.473
- 0.813
- 0.833
- 1.158
- 0.618
- 0.817
- 1.02
- 0.638
- 0.789
- 0.665
- 0.405
- 0.838
- 0.387
- 0.281
- 0.583
- 0.825
unequal: 0
verbose: 1
