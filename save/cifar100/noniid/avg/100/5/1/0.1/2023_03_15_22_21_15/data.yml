avg_train_accuracy: 0.291
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0436
- 0.08
- 0.0911
- 0.1148
- 0.0301
- 0.12
- 0.0316
- 0.1381
- 0.1535
- 0.1594
- 0.16
- 0.1638
- 0.1746
- 0.1691
- 0.1837
- 0.1805
- 0.1847
- 0.2005
- 0.205
- 0.2048
- 0.2031
- 0.2071
- 0.2087
- 0.2193
- 0.2267
- 0.2285
- 0.2288
- 0.2411
- 0.2347
- 0.2372
- 0.2461
- 0.2433
- 0.2391
- 0.2516
- 0.2506
- 0.2502
- 0.2488
- 0.2635
- 0.2612
- 0.2632
- 0.2605
- 0.0319
- 0.2625
- 0.2768
- 0.2658
- 0.2704
- 0.2714
- 0.2707
- 0.2771
- 0.2821
- 0.2758
- 0.2672
- 0.0353
- 0.2816
- 0.2806
- 0.2814
- 0.2801
- 0.2899
- 0.2864
- 0.2873
- 0.2859
- 0.2869
- 0.2837
- 0.2864
- 0.2849
- 0.283
- 0.2923
- 0.2918
- 0.2875
- 0.2849
- 0.2955
- 0.2801
- 0.2863
- 0.3029
- 0.3053
- 0.3028
- 0.299
- 0.0382
- 0.3026
- 0.297
- 0.2999
- 0.2913
- 0.042
- 0.0394
- 0.2984
- 0.0471
- 0.31
- 0.3088
- 0.3005
- 0.0492
- 0.3111
- 0.3178
- 0.3091
- 0.3172
- 0.3078
- 0.2998
- 0.3015
- 0.3079
- 0.3204
- 0.3162
test_loss_list:
- 1.8101486444473267
- 1.6993739414215088
- 1.6703207302093506
- 1.622295961380005
- 3.659107789993286
- 1.5933453154563904
- 3.574289960861206
- 1.548120493888855
- 1.521509473323822
- 1.5158437967300415
- 1.5111778998374938
- 1.5217690086364746
- 1.4928479051589967
- 1.5074824905395507
- 1.4694829845428468
- 1.482198257446289
- 1.4777703595161438
- 1.4465667176246644
- 1.4268541431427002
- 1.4336074090003967
- 1.4446305799484254
- 1.4365560340881347
- 1.4200346159934998
- 1.397547070980072
- 1.3961681270599364
- 1.388772258758545
- 1.3946822381019592
- 1.3844518423080445
- 1.3793699979782104
- 1.388808672428131
- 1.3705378556251526
- 1.364122793674469
- 1.368357527256012
- 1.3581295228004455
- 1.3675672650337218
- 1.3575270700454711
- 1.3679057216644288
- 1.3382692909240723
- 1.351858355998993
- 1.3472290325164795
- 1.3306537699699401
- 3.5402364349365234
- 1.279684283733368
- 1.2725646948814393
- 1.2729593157768249
- 1.2741015338897705
- 1.2927439403533936
- 1.2939069223403932
- 1.2859527230262757
- 1.2673456954956055
- 1.2943817400932311
- 1.31497323513031
- 3.279626712799072
- 1.233575222492218
- 1.2500706887245179
- 1.2680156517028809
- 1.251674964427948
- 1.2441500091552735
- 1.2645518565177918
- 1.2569976735115052
- 1.2539228129386901
- 1.2709670090675353
- 1.2727331399917603
- 1.2907750153541564
- 1.285022439956665
- 1.28144912481308
- 1.2720825171470642
- 1.2800057101249696
- 1.2880207324028015
- 1.2766634345054626
- 1.2762609362602233
- 1.3239245462417601
- 1.308135848045349
- 1.2736686515808104
- 1.250494511127472
- 1.2787586236000061
- 1.2850826025009154
- 3.374313402175903
- 1.217825059890747
- 1.248653564453125
- 1.2297147822380066
- 1.2531554436683654
- 3.121037721633911
- 3.2581713962554932
- 1.2133243083953857
- 2.9376159381866453
- 1.1928883790969849
- 1.2102496480941773
- 1.228287124633789
- 2.9960081815719604
- 1.2112043905258179
- 1.1939773488044738
- 1.2158716416358948
- 1.197468376159668
- 1.2221395564079285
- 1.2560280442237854
- 1.2472431111335753
- 1.2492676854133606
- 1.2116164660453796
- 1.2386935186386108
train_accuracy:
- 0.049
- 0.091
- 0.104
- 0.105
- 0.0
- 0.119
- 0.0
- 0.148
- 0.114
- 0.182
- 0.164
- 0.17
- 0.176
- 0.187
- 0.147
- 0.199
- 0.185
- 0.147
- 0.159
- 0.157
- 0.178
- 0.183
- 0.212
- 0.203
- 0.224
- 0.157
- 0.226
- 0.168
- 0.232
- 0.242
- 0.222
- 0.257
- 0.244
- 0.255
- 0.252
- 0.225
- 0.242
- 0.235
- 0.233
- 0.251
- 0.233
- 0.0
- 0.264
- 0.237
- 0.277
- 0.293
- 0.265
- 0.272
- 0.298
- 0.271
- 0.269
- 0.276
- 0.0
- 0.267
- 0.28
- 0.297
- 0.227
- 0.3
- 0.284
- 0.273
- 0.265
- 0.277
- 0.265
- 0.305
- 0.282
- 0.273
- 0.282
- 0.288
- 0.299
- 0.319
- 0.303
- 0.277
- 0.275
- 0.305
- 0.296
- 0.285
- 0.308
- 0.0
- 0.293
- 0.307
- 0.229
- 0.251
- 0.0
- 0.0
- 0.291
- 0.0
- 0.33
- 0.301
- 0.307
- 0.0
- 0.332
- 0.326
- 0.317
- 0.324
- 0.306
- 0.305
- 0.303
- 0.301
- 0.306
- 0.291
train_loss:
- 4.291
- 3.892
- 3.699
- 3.572
- 1.093
- 3.389
- 0.741
- 3.48
- 3.348
- 3.332
- 2.83
- 2.444
- 3.044
- 2.276
- 3.157
- 2.038
- 2.824
- 2.961
- 2.891
- 2.355
- 2.021
- 2.747
- 2.567
- 2.647
- 2.435
- 2.488
- 1.961
- 1.983
- 2.082
- 1.671
- 2.272
- 2.388
- 2.081
- 1.861
- 1.93
- 2.225
- 1.78
- 1.776
- 1.886
- 1.545
- 2.332
- 0.853
- 1.541
- 1.626
- 1.849
- 1.763
- 1.144
- 1.624
- 1.403
- 1.55
- 1.008
- 1.574
- 0.645
- 2.216
- 0.887
- 1.551
- 1.972
- 1.312
- 0.757
- 1.323
- 1.637
- 0.686
- 1.214
- 1.284
- 0.616
- 1.387
- 1.17
- 0.745
- 1.027
- 1.129
- 0.565
- 0.797
- 1.102
- 0.828
- 1.267
- 0.867
- 0.963
- 0.616
- 1.595
- 0.816
- 1.607
- 1.017
- 0.457
- 0.13
- 1.495
- 0.302
- 0.821
- 0.847
- 0.64
- 0.3
- 0.618
- 0.762
- 1.097
- 1.045
- 0.753
- 0.48
- 0.539
- 0.295
- 0.785
- 0.474
unequal: 0
verbose: 1
