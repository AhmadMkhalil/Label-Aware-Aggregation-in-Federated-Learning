avg_train_accuracy: 0.281
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037
- 0.0749
- 0.0957
- 0.1057
- 0.1183
- 0.14
- 0.0293
- 0.1343
- 0.1434
- 0.1628
- 0.1629
- 0.0334
- 0.1709
- 0.174
- 0.1804
- 0.185
- 0.1821
- 0.1963
- 0.2046
- 0.2053
- 0.205
- 0.1998
- 0.2024
- 0.2088
- 0.2164
- 0.208
- 0.0346
- 0.2163
- 0.2377
- 0.2267
- 0.2365
- 0.2379
- 0.2302
- 0.2394
- 0.2452
- 0.2568
- 0.2494
- 0.2457
- 0.2567
- 0.2616
- 0.2459
- 0.259
- 0.2613
- 0.2481
- 0.2642
- 0.2626
- 0.2695
- 0.2674
- 0.267
- 0.2632
- 0.2673
- 0.2692
- 0.2719
- 0.275
- 0.289
- 0.277
- 0.0364
- 0.277
- 0.2792
- 0.2813
- 0.2848
- 0.2789
- 0.2795
- 0.2841
- 0.2823
- 0.2881
- 0.2943
- 0.2952
- 0.2759
- 0.2878
- 0.28
- 0.285
- 0.3005
- 0.285
- 0.2974
- 0.3027
- 0.2852
- 0.2911
- 0.2949
- 0.0403
- 0.3005
- 0.3028
- 0.2998
- 0.3006
- 0.3017
- 0.3051
- 0.3014
- 0.2987
- 0.2993
- 0.3038
- 0.3071
- 0.3056
- 0.3022
- 0.306
- 0.3086
- 0.3097
- 0.307
- 0.3071
- 0.3138
- 0.3059
test_loss_list:
- 1.8061657381057739
- 1.7058583784103394
- 1.6796327590942384
- 1.6410099530220033
- 1.6273348832130432
- 1.5998675775527955
- 3.8722544956207274
- 1.5437852835655212
- 1.5469444370269776
- 1.5224539375305175
- 1.5023146152496338
- 3.630103130340576
- 1.4751455688476562
- 1.4654189443588257
- 1.460496542453766
- 1.4552052664756774
- 1.4516623330116272
- 1.4335251641273499
- 1.4407418155670166
- 1.4195902419090272
- 1.4305411434173585
- 1.4560856676101686
- 1.434378011226654
- 1.4228645992279052
- 1.4031039190292358
- 1.4299795174598693
- 3.444660472869873
- 1.3690682578086852
- 1.354014084339142
- 1.3505082941055297
- 1.3681794166564942
- 1.3524831938743591
- 1.3748935556411743
- 1.3479295539855958
- 1.3383582186698915
- 1.3241856145858764
- 1.343492705821991
- 1.3364584231376648
- 1.3257427763938905
- 1.3281505513191223
- 1.3508278226852417
- 1.313139898777008
- 1.3226417684555054
- 1.3577323579788207
- 1.3257905697822572
- 1.322155933380127
- 1.338080940246582
- 1.3202522945404054
- 1.3233038640022279
- 1.332673604488373
- 1.3250498032569886
- 1.327557122707367
- 1.3176816773414612
- 1.3088239979743959
- 1.3011966133117676
- 1.319563739299774
- 3.25577166557312
- 1.262599973678589
- 1.2529864263534547
- 1.276371476650238
- 1.2536043691635133
- 1.2760403537750244
- 1.265215129852295
- 1.2660924482345581
- 1.2842921900749207
- 1.2642863941192628
- 1.2563259482383728
- 1.2678204560279847
- 1.3167926359176636
- 1.3020972681045533
- 1.2915121459960937
- 1.2834189558029174
- 1.2582700610160829
- 1.2942158055305482
- 1.2630296111106873
- 1.2650918340682984
- 1.30796382188797
- 1.303192572593689
- 1.2962153053283691
- 3.145448431968689
- 1.223608009815216
- 1.228806664943695
- 1.2462900590896606
- 1.2503078317642211
- 1.244621181488037
- 1.2473645496368408
- 1.2546581983566285
- 1.2612917447090148
- 1.2800871086120607
- 1.2682820439338685
- 1.263305788040161
- 1.2646445846557617
- 1.2803518986701965
- 1.2661218357086181
- 1.2540490198135377
- 1.2538159918785095
- 1.2670750427246094
- 1.2766864132881164
- 1.2582272386550903
- 1.2905937767028808
train_accuracy:
- 0.027
- 0.076
- 0.093
- 0.086
- 0.104
- 0.121
- 0.0
- 0.114
- 0.144
- 0.139
- 0.17
- 0.0
- 0.149
- 0.153
- 0.201
- 0.178
- 0.151
- 0.163
- 0.197
- 0.212
- 0.204
- 0.206
- 0.148
- 0.191
- 0.188
- 0.176
- 0.0
- 0.216
- 0.21
- 0.185
- 0.218
- 0.239
- 0.198
- 0.216
- 0.271
- 0.288
- 0.276
- 0.218
- 0.2
- 0.224
- 0.214
- 0.265
- 0.264
- 0.246
- 0.259
- 0.223
- 0.241
- 0.223
- 0.257
- 0.264
- 0.22
- 0.274
- 0.27
- 0.236
- 0.273
- 0.216
- 0.0
- 0.236
- 0.314
- 0.287
- 0.291
- 0.261
- 0.263
- 0.233
- 0.322
- 0.239
- 0.306
- 0.309
- 0.282
- 0.282
- 0.25
- 0.279
- 0.26
- 0.244
- 0.329
- 0.255
- 0.253
- 0.262
- 0.297
- 0.0
- 0.267
- 0.316
- 0.307
- 0.318
- 0.309
- 0.269
- 0.284
- 0.311
- 0.264
- 0.329
- 0.275
- 0.283
- 0.299
- 0.291
- 0.297
- 0.265
- 0.301
- 0.291
- 0.306
- 0.281
train_loss:
- 4.326
- 3.949
- 3.401
- 3.408
- 3.047
- 3.396
- 1.052
- 3.334
- 3.245
- 2.959
- 3.205
- 0.842
- 2.985
- 2.701
- 3.033
- 3.051
- 2.897
- 2.426
- 2.572
- 2.61
- 2.127
- 1.817
- 2.55
- 2.586
- 2.586
- 2.053
- 0.782
- 2.444
- 2.239
- 2.152
- 1.82
- 1.838
- 1.903
- 2.2
- 2.567
- 2.414
- 2.094
- 1.74
- 2.109
- 1.737
- 1.415
- 1.621
- 1.929
- 1.4
- 1.497
- 1.856
- 1.136
- 1.74
- 1.434
- 1.304
- 1.422
- 1.479
- 1.171
- 1.83
- 1.11
- 1.534
- 0.727
- 1.687
- 1.933
- 1.33
- 1.027
- 1.783
- 1.171
- 1.337
- 1.568
- 1.351
- 0.893
- 1.147
- 0.703
- 0.557
- 1.147
- 1.236
- 1.148
- 1.197
- 1.299
- 1.295
- 0.806
- 0.581
- 0.855
- 0.622
- 1.103
- 0.606
- 0.388
- 1.086
- 1.071
- 0.756
- 0.748
- 0.851
- 0.78
- 0.583
- 0.625
- 0.63
- 0.587
- 1.011
- 0.549
- 0.989
- 0.81
- 0.447
- 0.49
- 0.542
unequal: 0
verbose: 1
