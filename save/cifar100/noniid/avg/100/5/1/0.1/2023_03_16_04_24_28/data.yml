avg_train_accuracy: 0.314
avg_train_loss: 0.01
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0483
- 0.0803
- 0.0892
- 0.1056
- 0.1266
- 0.1338
- 0.1401
- 0.1458
- 0.1506
- 0.1669
- 0.1706
- 0.1759
- 0.1886
- 0.1869
- 0.1826
- 0.1925
- 0.2041
- 0.1994
- 0.0301
- 0.2104
- 0.2106
- 0.2194
- 0.2196
- 0.0334
- 0.2248
- 0.2243
- 0.2337
- 0.2295
- 0.2271
- 0.237
- 0.2335
- 0.2427
- 0.2368
- 0.2291
- 0.2383
- 0.2431
- 0.0356
- 0.2368
- 0.2441
- 0.2411
- 0.2447
- 0.2445
- 0.2536
- 0.2592
- 0.2646
- 0.2577
- 0.2655
- 0.2661
- 0.265
- 0.2698
- 0.275
- 0.2654
- 0.035
- 0.2752
- 0.278
- 0.2715
- 0.2732
- 0.2733
- 0.2807
- 0.2843
- 0.2792
- 0.2821
- 0.2807
- 0.2846
- 0.2888
- 0.278
- 0.2816
- 0.2838
- 0.2816
- 0.2826
- 0.2984
- 0.0375
- 0.3002
- 0.2904
- 0.0431
- 0.2956
- 0.046
- 0.2987
- 0.3088
- 0.3014
- 0.3015
- 0.0448
- 0.3059
- 0.2995
- 0.2989
- 0.3022
- 0.2974
- 0.3051
- 0.0473
- 0.307
- 0.0516
- 0.3058
- 0.3083
- 0.3024
- 0.3128
- 0.3066
- 0.3121
- 0.3111
- 0.3085
- 0.3029
test_loss_list:
- 1.7875471544265746
- 1.6886089086532592
- 1.6751336431503296
- 1.6468509721755982
- 1.6121651029586792
- 1.579184045791626
- 1.5571877574920654
- 1.5593356585502625
- 1.5561127257347107
- 1.531137673854828
- 1.5217142152786254
- 1.504039499759674
- 1.474206392765045
- 1.4800518894195556
- 1.4890643405914306
- 1.4619364500045777
- 1.4554825949668884
- 1.4633455204963683
- 3.7800571155548095
- 1.3816235327720643
- 1.393025300502777
- 1.3923893928527833
- 1.38495263338089
- 3.4602508449554445
- 1.3515752720832825
- 1.3729133439064025
- 1.353253924846649
- 1.369621956348419
- 1.3611804461479187
- 1.364769675731659
- 1.3534259104728699
- 1.3584055185317994
- 1.3868521165847778
- 1.4127367734909058
- 1.3649011158943176
- 1.3686567783355712
- 3.409277791976929
- 1.3397470951080321
- 1.3221452522277832
- 1.3378453397750854
- 1.335819616317749
- 1.3429914975166322
- 1.3492977380752564
- 1.321541986465454
- 1.3044280624389648
- 1.3076495933532715
- 1.3134781885147095
- 1.3080115270614625
- 1.3261290574073792
- 1.310640573501587
- 1.2979472732543946
- 1.3242017459869384
- 3.316267852783203
- 1.2640616226196288
- 1.262165777683258
- 1.2780069231987
- 1.2705149531364441
- 1.2721147894859315
- 1.2664691162109376
- 1.2818920755386352
- 1.2786647248268128
- 1.2660331082344056
- 1.2766787195205689
- 1.2820308780670167
- 1.2773696160316468
- 1.3084365797042847
- 1.2775001621246338
- 1.2899121952056884
- 1.288001127243042
- 1.2987336707115174
- 1.265069568157196
- 3.293518238067627
- 1.2129817700386047
- 1.2401828932762147
- 3.1317055463790893
- 1.2166041469573974
- 3.0097177982330323
- 1.2180285811424256
- 1.2154611992835997
- 1.2317176961898804
- 1.2378943538665772
- 3.089360656738281
- 1.201414656639099
- 1.23911705493927
- 1.2231492280960083
- 1.2184302091598511
- 1.2534358024597168
- 1.233905155658722
- 3.054355387687683
- 1.2172890043258666
- 3.029607348442078
- 1.2289822340011596
- 1.218471360206604
- 1.2395165681838989
- 1.2289989757537843
- 1.2397996473312378
- 1.2165323162078858
- 1.240989360809326
- 1.2374129843711854
- 1.2495032787322997
train_accuracy:
- 0.056
- 0.064
- 0.074
- 0.138
- 0.142
- 0.141
- 0.158
- 0.162
- 0.177
- 0.152
- 0.183
- 0.197
- 0.204
- 0.17
- 0.185
- 0.17
- 0.215
- 0.153
- 0.0
- 0.218
- 0.249
- 0.18
- 0.188
- 0.0
- 0.23
- 0.201
- 0.244
- 0.188
- 0.235
- 0.249
- 0.203
- 0.243
- 0.256
- 0.241
- 0.223
- 0.213
- 0.0
- 0.208
- 0.239
- 0.245
- 0.212
- 0.218
- 0.251
- 0.214
- 0.237
- 0.238
- 0.306
- 0.286
- 0.294
- 0.238
- 0.253
- 0.244
- 0.0
- 0.246
- 0.248
- 0.291
- 0.269
- 0.233
- 0.25
- 0.325
- 0.229
- 0.275
- 0.253
- 0.255
- 0.271
- 0.259
- 0.29
- 0.262
- 0.258
- 0.264
- 0.271
- 0.0
- 0.273
- 0.271
- 0.0
- 0.266
- 0.0
- 0.324
- 0.273
- 0.273
- 0.291
- 0.0
- 0.269
- 0.333
- 0.304
- 0.272
- 0.287
- 0.264
- 0.0
- 0.343
- 0.0
- 0.344
- 0.261
- 0.295
- 0.367
- 0.336
- 0.302
- 0.361
- 0.271
- 0.314
train_loss:
- 4.27
- 3.863
- 3.361
- 3.323
- 3.441
- 3.361
- 3.349
- 2.874
- 2.873
- 2.884
- 2.861
- 2.843
- 3.025
- 2.588
- 2.481
- 2.972
- 2.45
- 2.47
- 1.054
- 2.911
- 2.534
- 2.812
- 2.281
- 0.766
- 2.989
- 2.406
- 2.13
- 2.032
- 1.989
- 2.142
- 2.232
- 1.848
- 1.38
- 1.13
- 2.215
- 1.893
- 0.723
- 1.646
- 2.374
- 1.736
- 1.923
- 1.389
- 1.341
- 1.381
- 1.823
- 2.251
- 1.141
- 1.8
- 0.865
- 1.702
- 1.523
- 1.047
- 0.627
- 2.296
- 1.314
- 1.53
- 1.881
- 1.506
- 1.4
- 1.217
- 1.148
- 1.525
- 0.891
- 1.141
- 1.685
- 1.089
- 1.277
- 0.972
- 1.716
- 1.12
- 0.879
- 0.595
- 1.27
- 0.687
- 0.383
- 1.422
- 0.292
- 1.145
- 1.121
- 0.692
- 1.148
- 0.333
- 1.024
- 1.153
- 1.162
- 0.648
- 0.398
- 0.979
- 0.335
- 0.925
- 0.251
- 0.576
- 0.702
- 0.965
- 0.444
- 0.929
- 0.73
- 0.397
- 0.912
- 0.957
unequal: 0
verbose: 1
