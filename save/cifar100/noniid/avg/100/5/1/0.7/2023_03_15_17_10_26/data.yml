avg_train_accuracy: 0.321
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0396
- 0.0899
- 0.1139
- 0.1288
- 0.1473
- 0.158
- 0.1661
- 0.1726
- 0.1823
- 0.1906
- 0.1949
- 0.1997
- 0.2046
- 0.2102
- 0.2125
- 0.224
- 0.2286
- 0.2264
- 0.2319
- 0.2367
- 0.2418
- 0.2438
- 0.2453
- 0.249
- 0.2477
- 0.2543
- 0.2576
- 0.2582
- 0.2642
- 0.2624
- 0.2642
- 0.2659
- 0.2722
- 0.2705
- 0.2706
- 0.2757
- 0.2793
- 0.2813
- 0.2821
- 0.2803
- 0.2841
- 0.2866
- 0.2924
- 0.2887
- 0.2934
- 0.2913
- 0.293
- 0.2957
- 0.2962
- 0.2946
- 0.2952
- 0.2985
- 0.3
- 0.2971
- 0.3025
- 0.3047
- 0.3032
- 0.3037
- 0.304
- 0.3033
- 0.3064
- 0.3115
- 0.3057
- 0.3079
- 0.3088
- 0.3091
- 0.315
- 0.3108
- 0.3126
- 0.3151
- 0.3107
- 0.3123
- 0.3149
- 0.3153
- 0.3164
- 0.3152
- 0.3172
- 0.3197
- 0.3156
- 0.3153
- 0.3178
- 0.3192
- 0.32
- 0.3186
- 0.3195
- 0.3197
- 0.3245
- 0.3211
- 0.3204
- 0.3209
- 0.3215
- 0.3224
- 0.3231
- 0.3219
- 0.321
- 0.3224
- 0.3232
- 0.3247
- 0.3263
- 0.3247
test_loss_list:
- 1.78914635181427
- 1.6503921389579772
- 1.5910238099098206
- 1.5449054479598998
- 1.523605465888977
- 1.5010017848014832
- 1.46154878616333
- 1.4388327622413635
- 1.4179418611526489
- 1.4193869519233704
- 1.3910961651802063
- 1.376857454776764
- 1.3661257767677306
- 1.3505609917640686
- 1.3417589783668518
- 1.3279198098182678
- 1.3211574149131775
- 1.3330782985687255
- 1.306574375629425
- 1.2931007647514343
- 1.2832991695404052
- 1.2764649558067322
- 1.2899212670326232
- 1.292406566143036
- 1.267400872707367
- 1.2557262468338013
- 1.2481060886383057
- 1.2587622022628784
- 1.2412765622138977
- 1.255844647884369
- 1.2321785664558411
- 1.2244818663597108
- 1.2180268621444703
- 1.2140176606178283
- 1.2316494870185852
- 1.2107634091377257
- 1.204319429397583
- 1.1992743635177612
- 1.194934377670288
- 1.21168776512146
- 1.1945005321502686
- 1.1881918716430664
- 1.1841815900802612
- 1.1837430667877198
- 1.179851632118225
- 1.1927964186668396
- 1.2024474430084229
- 1.1773300790786743
- 1.170087378025055
- 1.189997398853302
- 1.1703792190551758
- 1.1654752492904663
- 1.1633454251289368
- 1.1661290001869202
- 1.1641876673698426
- 1.1579048037528992
- 1.1588099551200868
- 1.170823907852173
- 1.1803619956970215
- 1.1626965117454529
- 1.155307309627533
- 1.1540092206001282
- 1.1696665334701537
- 1.155381019115448
- 1.1510532236099242
- 1.1676751112937926
- 1.1500118112564086
- 1.1495733118057252
- 1.1460183334350587
- 1.1455376195907592
- 1.1661150312423707
- 1.1753669047355653
- 1.151510672569275
- 1.1469126534461975
- 1.1640833282470704
- 1.1753996396064759
- 1.1507280135154725
- 1.1452092671394347
- 1.1649203181266785
- 1.148760542869568
- 1.1683148670196533
- 1.1505949521064758
- 1.1473245096206666
- 1.1656507325172425
- 1.1505068564414977
- 1.1495648193359376
- 1.145536699295044
- 1.1648526740074159
- 1.1758902859687805
- 1.153278293609619
- 1.1673227524757386
- 1.1495943093299865
- 1.1482771039009094
- 1.1650857996940613
- 1.172632086277008
- 1.154204924106598
- 1.172392725944519
- 1.152460627555847
- 1.1488217782974244
- 1.1507010960578918
train_accuracy:
- 0.036
- 0.104
- 0.104
- 0.159
- 0.116
- 0.153
- 0.2
- 0.166
- 0.197
- 0.178
- 0.22
- 0.209
- 0.202
- 0.236
- 0.223
- 0.215
- 0.238
- 0.235
- 0.261
- 0.173
- 0.248
- 0.251
- 0.262
- 0.272
- 0.0
- 0.272
- 0.208
- 0.26
- 0.296
- 0.246
- 0.275
- 0.0
- 0.229
- 0.264
- 0.301
- 0.0
- 0.273
- 0.305
- 0.316
- 0.314
- 0.294
- 0.308
- 0.27
- 0.234
- 0.299
- 0.289
- 0.332
- 0.265
- 0.33
- 0.277
- 0.285
- 0.321
- 0.277
- 0.0
- 0.305
- 0.291
- 0.339
- 0.266
- 0.286
- 0.321
- 0.329
- 0.346
- 0.291
- 0.338
- 0.32
- 0.322
- 0.352
- 0.307
- 0.267
- 0.317
- 0.314
- 0.313
- 0.307
- 0.347
- 0.329
- 0.339
- 0.354
- 0.312
- 0.284
- 0.35
- 0.357
- 0.343
- 0.334
- 0.361
- 0.328
- 0.33
- 0.314
- 0.296
- 0.314
- 0.356
- 0.35
- 0.293
- 0.335
- 0.362
- 0.356
- 0.349
- 0.338
- 0.346
- 0.325
- 0.321
train_loss:
- 3.873
- 3.458
- 3.26
- 3.126
- 3.378
- 3.24
- 2.775
- 2.7
- 2.631
- 2.877
- 2.494
- 2.41
- 2.352
- 2.349
- 2.267
- 2.284
- 2.156
- 2.365
- 2.096
- 2.064
- 2.028
- 1.96
- 2.154
- 2.099
- 1.833
- 1.807
- 1.765
- 1.963
- 1.707
- 1.859
- 1.599
- 1.585
- 1.55
- 1.532
- 1.668
- 1.469
- 1.424
- 1.398
- 1.358
- 1.491
- 1.322
- 1.268
- 1.232
- 1.228
- 1.18
- 1.323
- 1.273
- 1.123
- 1.086
- 1.201
- 1.031
- 0.998
- 1.007
- 0.953
- 0.953
- 0.938
- 0.927
- 0.994
- 0.954
- 0.868
- 0.846
- 0.804
- 0.904
- 0.76
- 0.749
- 0.842
- 0.733
- 0.717
- 0.685
- 0.716
- 0.736
- 0.744
- 0.648
- 0.626
- 0.685
- 0.663
- 0.597
- 0.562
- 0.603
- 0.554
- 0.576
- 0.503
- 0.521
- 0.568
- 0.495
- 0.46
- 0.486
- 0.528
- 0.506
- 0.465
- 0.49
- 0.428
- 0.422
- 0.435
- 0.448
- 0.406
- 0.422
- 0.392
- 0.37
- 0.364
unequal: 0
verbose: 1
