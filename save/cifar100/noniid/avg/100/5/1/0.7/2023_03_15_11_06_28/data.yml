avg_train_accuracy: 0.366
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0484
- 0.0959
- 0.1237
- 0.1354
- 0.1466
- 0.1591
- 0.1666
- 0.1801
- 0.1853
- 0.1926
- 0.1987
- 0.2049
- 0.2093
- 0.2121
- 0.2214
- 0.2201
- 0.2284
- 0.231
- 0.2365
- 0.2389
- 0.24
- 0.2456
- 0.2549
- 0.2516
- 0.2551
- 0.2586
- 0.2603
- 0.2615
- 0.2659
- 0.2702
- 0.2709
- 0.2737
- 0.2742
- 0.2803
- 0.2817
- 0.2783
- 0.2817
- 0.2849
- 0.2855
- 0.2928
- 0.2928
- 0.2903
- 0.2918
- 0.2936
- 0.2954
- 0.2948
- 0.3019
- 0.3015
- 0.3029
- 0.3025
- 0.2995
- 0.303
- 0.3041
- 0.3092
- 0.3102
- 0.306
- 0.3105
- 0.3121
- 0.3113
- 0.3136
- 0.3156
- 0.3149
- 0.3188
- 0.3205
- 0.3174
- 0.321
- 0.3225
- 0.3229
- 0.3191
- 0.3232
- 0.3201
- 0.3252
- 0.3206
- 0.3224
- 0.3275
- 0.3239
- 0.3245
- 0.3257
- 0.327
- 0.3256
- 0.3275
- 0.329
- 0.3259
- 0.3278
- 0.3304
- 0.3302
- 0.3332
- 0.3305
- 0.3291
- 0.3302
- 0.3315
- 0.3329
- 0.3341
- 0.3373
- 0.3357
- 0.3343
- 0.3379
- 0.3382
- 0.3354
- 0.3348
test_loss_list:
- 1.7918366813659667
- 1.650242142677307
- 1.6040889430046081
- 1.5497299480438231
- 1.5130738258361816
- 1.4950609350204467
- 1.461585876941681
- 1.4360265111923218
- 1.4191620802879334
- 1.403601644039154
- 1.405947723388672
- 1.3998364639282226
- 1.3926935267448426
- 1.3622433137893677
- 1.3627386498451233
- 1.335973677635193
- 1.320982699394226
- 1.3150031065940857
- 1.3048652935028076
- 1.310916187763214
- 1.290572829246521
- 1.2971896576881408
- 1.2950283908843994
- 1.2746320009231566
- 1.258725836277008
- 1.270709481239319
- 1.2489586067199707
- 1.2420459079742432
- 1.23486168384552
- 1.225267345905304
- 1.2210422110557557
- 1.21605135679245
- 1.2097216057777405
- 1.2067154717445374
- 1.2030954122543336
- 1.199862015247345
- 1.2000518822669983
- 1.190767116546631
- 1.189862141609192
- 1.1822252917289733
- 1.178503577709198
- 1.1771079087257386
- 1.1924821758270263
- 1.1755984258651733
- 1.170977191925049
- 1.1851221132278442
- 1.1667020392417908
- 1.164769208431244
- 1.1614532470703125
- 1.1607084250450135
- 1.1771884894371032
- 1.1819508147239686
- 1.1577349376678467
- 1.1693794417381287
- 1.1756923818588256
- 1.1598984599113464
- 1.1506078481674193
- 1.1628707766532898
- 1.1749407458305359
- 1.1546552801132202
- 1.1453977227210999
- 1.1448797512054443
- 1.1420921516418456
- 1.1402015089988708
- 1.1403623461723327
- 1.1397571468353271
- 1.140342457294464
- 1.1393121027946471
- 1.1591344451904297
- 1.1607522416114806
- 1.1434952878952027
- 1.13803071975708
- 1.1578900027275085
- 1.1455621027946472
- 1.1369720816612243
- 1.1536042618751525
- 1.141656551361084
- 1.1367996430397034
- 1.1501402711868287
- 1.1613414454460145
- 1.1426427841186524
- 1.1371208477020263
- 1.1372871732711791
- 1.157496509552002
- 1.1394449830055238
- 1.1414993071556092
- 1.1367273998260499
- 1.1523499631881713
- 1.139535186290741
- 1.138320255279541
- 1.1544160437583924
- 1.1382187461853028
- 1.1369438934326173
- 1.136293616294861
- 1.1366581296920777
- 1.1380613803863526
- 1.1398668909072875
- 1.1387156653404236
- 1.1415539956092835
- 1.153246955871582
train_accuracy:
- 0.039
- 0.127
- 0.113
- 0.128
- 0.129
- 0.167
- 0.0
- 0.169
- 0.0
- 0.209
- 0.215
- 0.202
- 0.205
- 0.17
- 0.179
- 0.236
- 0.184
- 0.258
- 0.214
- 0.25
- 0.239
- 0.271
- 0.255
- 0.276
- 0.218
- 0.295
- 0.27
- 0.286
- 0.237
- 0.263
- 0.0
- 0.0
- 0.0
- 0.324
- 0.301
- 0.279
- 0.274
- 0.287
- 0.28
- 0.326
- 0.286
- 0.344
- 0.288
- 0.339
- 0.269
- 0.306
- 0.3
- 0.305
- 0.331
- 0.33
- 0.346
- 0.33
- 0.0
- 0.324
- 0.312
- 0.361
- 0.335
- 0.276
- 0.349
- 0.349
- 0.352
- 0.315
- 0.348
- 0.0
- 0.342
- 0.29
- 0.351
- 0.338
- 0.328
- 0.344
- 0.365
- 0.357
- 0.325
- 0.335
- 0.0
- 0.361
- 0.346
- 0.358
- 0.385
- 0.356
- 0.384
- 0.361
- 0.355
- 0.352
- 0.358
- 0.356
- 0.342
- 0.356
- 0.356
- 0.358
- 0.352
- 0.347
- 0.323
- 0.37
- 0.369
- 0.358
- 0.388
- 0.34
- 0.328
- 0.366
train_loss:
- 4.314
- 3.461
- 3.655
- 3.104
- 2.986
- 3.252
- 2.786
- 2.711
- 2.662
- 2.574
- 2.834
- 2.749
- 2.664
- 2.311
- 2.556
- 2.228
- 2.155
- 2.104
- 2.065
- 2.308
- 1.978
- 2.179
- 2.126
- 1.851
- 1.795
- 1.957
- 1.74
- 1.714
- 1.668
- 1.616
- 1.568
- 1.555
- 1.516
- 1.487
- 1.453
- 1.439
- 1.407
- 1.37
- 1.327
- 1.288
- 1.301
- 1.233
- 1.368
- 1.183
- 1.191
- 1.306
- 1.114
- 1.13
- 1.091
- 1.024
- 1.179
- 1.116
- 0.986
- 1.102
- 1.039
- 0.913
- 0.897
- 0.969
- 0.955
- 0.818
- 0.843
- 0.806
- 0.775
- 0.763
- 0.736
- 0.726
- 0.703
- 0.687
- 0.765
- 0.76
- 0.682
- 0.636
- 0.717
- 0.617
- 0.608
- 0.681
- 0.572
- 0.558
- 0.626
- 0.6
- 0.522
- 0.528
- 0.49
- 0.554
- 0.511
- 0.475
- 0.467
- 0.513
- 0.449
- 0.44
- 0.501
- 0.43
- 0.407
- 0.43
- 0.402
- 0.403
- 0.382
- 0.373
- 0.375
- 0.406
unequal: 0
verbose: 1
