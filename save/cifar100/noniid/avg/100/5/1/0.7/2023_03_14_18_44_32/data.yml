avg_train_accuracy: 0.336
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0434
- 0.0982
- 0.1208
- 0.1335
- 0.1521
- 0.1629
- 0.1708
- 0.177
- 0.1798
- 0.1872
- 0.1951
- 0.202
- 0.2054
- 0.2109
- 0.2188
- 0.2221
- 0.2249
- 0.228
- 0.2325
- 0.2344
- 0.2384
- 0.2417
- 0.2447
- 0.2496
- 0.2538
- 0.2559
- 0.2576
- 0.2608
- 0.2654
- 0.2614
- 0.2702
- 0.2699
- 0.2712
- 0.2714
- 0.2752
- 0.2786
- 0.2803
- 0.2836
- 0.2795
- 0.2863
- 0.2834
- 0.2821
- 0.284
- 0.2882
- 0.2907
- 0.2915
- 0.2943
- 0.296
- 0.2925
- 0.2978
- 0.3009
- 0.2983
- 0.2997
- 0.3022
- 0.2992
- 0.3033
- 0.3034
- 0.3016
- 0.3054
- 0.3065
- 0.3064
- 0.3075
- 0.3082
- 0.3085
- 0.31
- 0.3147
- 0.3135
- 0.3103
- 0.3106
- 0.3132
- 0.3139
- 0.3139
- 0.3127
- 0.318
- 0.3162
- 0.3149
- 0.316
- 0.3215
- 0.3208
- 0.3161
- 0.3201
- 0.3181
- 0.317
- 0.3171
- 0.3206
- 0.3163
- 0.3204
- 0.317
- 0.3225
- 0.3215
- 0.3214
- 0.3216
- 0.3184
- 0.3211
- 0.3213
- 0.3235
- 0.3286
- 0.3246
- 0.3259
- 0.3238
test_loss_list:
- 1.7765011310577392
- 1.6372957062721252
- 1.5874814009666443
- 1.5380489587783814
- 1.5015433526039124
- 1.4725456047058105
- 1.4497761011123658
- 1.4458118891716003
- 1.4186775946617127
- 1.4010894012451172
- 1.402059805393219
- 1.3755489420890807
- 1.3624766397476196
- 1.3506183242797851
- 1.3401066493988036
- 1.3272676682472229
- 1.3212665963172912
- 1.3127554440498352
- 1.298610200881958
- 1.2913841700553894
- 1.2859139156341552
- 1.278218891620636
- 1.2718207144737244
- 1.2651178026199341
- 1.2756300449371338
- 1.2770272588729858
- 1.255515887737274
- 1.240424087047577
- 1.2363846731185912
- 1.2486622834205627
- 1.2300698232650757
- 1.2222398900985718
- 1.2198541617393495
- 1.2190184831619262
- 1.2129267859458923
- 1.20859943151474
- 1.2070363640785218
- 1.2035839200019836
- 1.2170648193359375
- 1.2018726396560668
- 1.1960521578788756
- 1.2118206429481506
- 1.1973802971839904
- 1.1888038444519042
- 1.1877990031242371
- 1.1841959977149963
- 1.180860803127289
- 1.1807097625732421
- 1.1779342365264893
- 1.1773556900024413
- 1.171958363056183
- 1.1755544590950011
- 1.173359022140503
- 1.1709402084350586
- 1.1894453144073487
- 1.1712067198753358
- 1.1693748879432677
- 1.1846429419517517
- 1.1704679131507874
- 1.167826406955719
- 1.181715009212494
- 1.1661165070533752
- 1.1821308398246766
- 1.1656835627555848
- 1.162445855140686
- 1.1597187328338623
- 1.1595599675178527
- 1.1603723764419556
- 1.1632622933387757
- 1.176689748764038
- 1.1632654762268066
- 1.1571358966827392
- 1.1773073697090148
- 1.1598355150222779
- 1.1575031280517578
- 1.1754714822769166
- 1.1606585669517517
- 1.1568535590171813
- 1.1559748291969298
- 1.1765354299545288
- 1.1603521823883056
- 1.1756984186172486
- 1.1632287096977234
- 1.1797680735588074
- 1.1577626824378968
- 1.1803414726257324
- 1.1622500610351563
- 1.1825553393363952
- 1.182572205066681
- 1.1857530355453492
- 1.192706835269928
- 1.2014577722549438
- 1.173236002922058
- 1.1887723803520203
- 1.1915471839904785
- 1.168016083240509
- 1.1641872859001159
- 1.1586037850379944
- 1.1647686076164245
- 1.161481945514679
train_accuracy:
- 0.032
- 0.0
- 0.118
- 0.0
- 0.165
- 0.0
- 0.128
- 0.141
- 0.159
- 0.222
- 0.15
- 0.0
- 0.212
- 0.184
- 0.195
- 0.212
- 0.166
- 0.218
- 0.248
- 0.192
- 0.237
- 0.208
- 0.24
- 0.217
- 0.271
- 0.212
- 0.281
- 0.22
- 0.265
- 0.225
- 0.228
- 0.298
- 0.212
- 0.213
- 0.0
- 0.0
- 0.273
- 0.295
- 0.257
- 0.26
- 0.299
- 0.24
- 0.311
- 0.259
- 0.288
- 0.269
- 0.308
- 0.328
- 0.241
- 0.261
- 0.267
- 0.269
- 0.274
- 0.325
- 0.321
- 0.319
- 0.0
- 0.287
- 0.278
- 0.281
- 0.336
- 0.299
- 0.287
- 0.323
- 0.264
- 0.275
- 0.0
- 0.305
- 0.27
- 0.306
- 0.292
- 0.358
- 0.342
- 0.273
- 0.328
- 0.322
- 0.343
- 0.0
- 0.314
- 0.304
- 0.276
- 0.33
- 0.353
- 0.296
- 0.279
- 0.32
- 0.368
- 0.309
- 0.307
- 0.348
- 0.318
- 0.339
- 0.3
- 0.296
- 0.348
- 0.287
- 0.294
- 0.305
- 0.0
- 0.336
train_loss:
- 3.819
- 3.443
- 3.639
- 3.095
- 2.964
- 2.871
- 2.77
- 3.032
- 2.658
- 2.576
- 2.802
- 2.436
- 2.379
- 2.288
- 2.275
- 2.213
- 2.141
- 2.113
- 2.124
- 2.014
- 2.004
- 1.96
- 1.896
- 1.875
- 2.045
- 2.021
- 1.756
- 1.752
- 1.679
- 1.866
- 1.615
- 1.565
- 1.553
- 1.498
- 1.486
- 1.448
- 1.421
- 1.402
- 1.534
- 1.342
- 1.331
- 1.446
- 1.241
- 1.205
- 1.211
- 1.155
- 1.168
- 1.135
- 1.111
- 1.093
- 1.057
- 1.018
- 1.021
- 1.019
- 1.088
- 0.962
- 0.962
- 1.038
- 0.889
- 0.836
- 0.978
- 0.841
- 0.905
- 0.801
- 0.773
- 0.769
- 0.756
- 0.735
- 0.709
- 0.778
- 0.689
- 0.679
- 0.743
- 0.642
- 0.649
- 0.699
- 0.604
- 0.578
- 0.57
- 0.608
- 0.549
- 0.628
- 0.531
- 0.579
- 0.516
- 0.533
- 0.475
- 0.532
- 0.52
- 0.513
- 0.483
- 0.471
- 0.437
- 0.439
- 0.463
- 0.425
- 0.392
- 0.39
- 0.366
- 0.387
unequal: 0
verbose: 1
