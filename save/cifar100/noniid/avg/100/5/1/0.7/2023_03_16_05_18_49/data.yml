avg_train_accuracy: 0.316
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0988
- 0.1182
- 0.134
- 0.1427
- 0.1626
- 0.1678
- 0.1761
- 0.1856
- 0.1971
- 0.199
- 0.2058
- 0.2102
- 0.2134
- 0.2199
- 0.2226
- 0.2256
- 0.232
- 0.234
- 0.2394
- 0.244
- 0.2492
- 0.2519
- 0.257
- 0.2567
- 0.2612
- 0.2663
- 0.2667
- 0.2707
- 0.2719
- 0.2751
- 0.2764
- 0.2786
- 0.2838
- 0.2823
- 0.2866
- 0.2886
- 0.2905
- 0.2918
- 0.2948
- 0.296
- 0.2967
- 0.298
- 0.298
- 0.3022
- 0.3021
- 0.3041
- 0.3031
- 0.3038
- 0.3054
- 0.3086
- 0.3058
- 0.3067
- 0.3075
- 0.3054
- 0.3102
- 0.3091
- 0.3108
- 0.3131
- 0.3112
- 0.3111
- 0.3146
- 0.318
- 0.3165
- 0.3175
- 0.3187
- 0.3164
- 0.3192
- 0.3208
- 0.3186
- 0.3217
- 0.3214
- 0.3229
- 0.3198
- 0.3238
- 0.325
- 0.3175
- 0.3223
- 0.3265
- 0.3264
- 0.3221
- 0.3244
- 0.3264
- 0.3254
- 0.3264
- 0.3281
- 0.3248
- 0.328
- 0.331
- 0.33
- 0.3313
- 0.3325
- 0.3338
- 0.3276
- 0.3331
- 0.3309
- 0.3278
- 0.3312
- 0.3339
- 0.3307
test_loss_list:
- 1.7850825548171998
- 1.6450943660736084
- 1.584294352531433
- 1.5482040786743163
- 1.5038298916816712
- 1.4841591024398804
- 1.4516256761550903
- 1.4283856797218322
- 1.4220814466476441
- 1.3938153624534606
- 1.3768746590614318
- 1.3766268658638001
- 1.3723018550872803
- 1.3439499163627624
- 1.3265155363082886
- 1.315436282157898
- 1.3068732833862304
- 1.2960311031341554
- 1.305206983089447
- 1.2826905465126037
- 1.2724063467979432
- 1.2634549283981322
- 1.2729773831367492
- 1.2725510835647582
- 1.2511207222938538
- 1.2394344663619996
- 1.231260633468628
- 1.2445644426345825
- 1.2251808071136474
- 1.2190062856674195
- 1.2127683401107787
- 1.2090723180770875
- 1.2170812106132507
- 1.2222437024116517
- 1.2051071310043335
- 1.1906454586982727
- 1.1895713710784912
- 1.2005692267417907
- 1.1853323245048524
- 1.1808466124534607
- 1.1744545245170592
- 1.1739291858673095
- 1.172343134880066
- 1.1687417435646057
- 1.1654478907585144
- 1.1641571974754334
- 1.1590754246711732
- 1.1611898446083069
- 1.15893150806427
- 1.1577161931991578
- 1.156415762901306
- 1.1691956281661988
- 1.1776809191703796
- 1.1575936150550843
- 1.1744077181816102
- 1.174935748577118
- 1.184032175540924
- 1.1857516479492187
- 1.1564620566368102
- 1.1512045192718505
- 1.1480343794822694
- 1.1449634265899657
- 1.1428048586845398
- 1.1469758653640747
- 1.142129466533661
- 1.1446999955177306
- 1.1415426015853882
- 1.1436057496070862
- 1.1408991384506226
- 1.1468434882164003
- 1.1396671199798585
- 1.137488603591919
- 1.1389772486686707
- 1.1552249908447265
- 1.1437319064140319
- 1.1421699285507203
- 1.160307421684265
- 1.1411636638641358
- 1.138203661441803
- 1.1380120635032653
- 1.1577725887298584
- 1.1656775903701782
- 1.1435743951797486
- 1.1426466369628907
- 1.1407651829719543
- 1.1397285771369934
- 1.1588841199874877
- 1.1432498836517333
- 1.1422849321365356
- 1.1379851078987122
- 1.139809126853943
- 1.1428779816627503
- 1.138457736968994
- 1.1596275806427
- 1.1411910009384156
- 1.143386471271515
- 1.1580688762664795
- 1.1458387660980225
- 1.1449797439575196
- 1.159736065864563
train_accuracy:
- 0.047
- 0.0
- 0.105
- 0.131
- 0.137
- 0.163
- 0.14
- 0.174
- 0.156
- 0.189
- 0.193
- 0.177
- 0.195
- 0.247
- 0.166
- 0.258
- 0.228
- 0.192
- 0.198
- 0.0
- 0.283
- 0.227
- 0.222
- 0.239
- 0.212
- 0.259
- 0.251
- 0.255
- 0.27
- 0.0
- 0.0
- 0.0
- 0.31
- 0.235
- 0.271
- 0.287
- 0.232
- 0.247
- 0.254
- 0.315
- 0.254
- 0.227
- 0.259
- 0.267
- 0.283
- 0.278
- 0.262
- 0.233
- 0.309
- 0.311
- 0.275
- 0.289
- 0.308
- 0.308
- 0.294
- 0.274
- 0.251
- 0.3
- 0.348
- 0.3
- 0.287
- 0.281
- 0.282
- 0.347
- 0.356
- 0.301
- 0.254
- 0.301
- 0.33
- 0.318
- 0.309
- 0.286
- 0.366
- 0.302
- 0.318
- 0.323
- 0.261
- 0.3
- 0.367
- 0.298
- 0.315
- 0.31
- 0.0
- 0.0
- 0.282
- 0.333
- 0.381
- 0.0
- 0.0
- 0.318
- 0.271
- 0.376
- 0.0
- 0.331
- 0.0
- 0.0
- 0.311
- 0.394
- 0.309
- 0.316
train_loss:
- 3.847
- 3.453
- 3.246
- 3.467
- 2.94
- 3.23
- 2.736
- 2.684
- 2.934
- 2.544
- 2.483
- 2.709
- 2.647
- 2.273
- 2.211
- 2.154
- 2.101
- 2.071
- 2.272
- 2.008
- 1.923
- 1.896
- 2.064
- 2.017
- 1.751
- 1.735
- 1.665
- 1.859
- 1.619
- 1.559
- 1.534
- 1.485
- 1.697
- 1.598
- 1.427
- 1.384
- 1.339
- 1.493
- 1.298
- 1.232
- 1.248
- 1.209
- 1.19
- 1.145
- 1.135
- 1.136
- 1.112
- 1.045
- 1.025
- 1.013
- 0.981
- 1.104
- 1.054
- 0.95
- 1.008
- 0.989
- 0.971
- 0.929
- 0.826
- 0.776
- 0.816
- 0.754
- 0.757
- 0.732
- 0.735
- 0.704
- 0.688
- 0.674
- 0.64
- 0.611
- 0.667
- 0.634
- 0.639
- 0.662
- 0.544
- 0.558
- 0.635
- 0.557
- 0.573
- 0.552
- 0.582
- 0.575
- 0.495
- 0.473
- 0.443
- 0.5
- 0.529
- 0.419
- 0.428
- 0.473
- 0.429
- 0.433
- 0.404
- 0.421
- 0.392
- 0.395
- 0.437
- 0.388
- 0.364
- 0.39
unequal: 0
verbose: 1
