avg_train_accuracy: 0.335
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0363
- 0.0954
- 0.1148
- 0.1354
- 0.1487
- 0.1566
- 0.1653
- 0.171
- 0.1853
- 0.1897
- 0.1932
- 0.2014
- 0.2057
- 0.213
- 0.214
- 0.2211
- 0.2243
- 0.2287
- 0.2324
- 0.2398
- 0.2385
- 0.2453
- 0.2473
- 0.2504
- 0.2539
- 0.2569
- 0.2571
- 0.2578
- 0.2598
- 0.2628
- 0.2636
- 0.2678
- 0.2695
- 0.2737
- 0.2782
- 0.2739
- 0.2817
- 0.2807
- 0.2852
- 0.2875
- 0.2849
- 0.2866
- 0.2871
- 0.2905
- 0.2917
- 0.2969
- 0.2932
- 0.2967
- 0.2987
- 0.3005
- 0.2991
- 0.2993
- 0.3035
- 0.3028
- 0.3033
- 0.308
- 0.3054
- 0.3044
- 0.3076
- 0.3078
- 0.3096
- 0.3085
- 0.3138
- 0.3123
- 0.3108
- 0.3152
- 0.3127
- 0.3115
- 0.3156
- 0.3139
- 0.3172
- 0.3183
- 0.3165
- 0.316
- 0.3165
- 0.3234
- 0.3212
- 0.3237
- 0.3219
- 0.3206
- 0.3211
- 0.3197
- 0.3214
- 0.3259
- 0.3204
- 0.3212
- 0.3227
- 0.3208
- 0.3226
- 0.3237
- 0.3267
- 0.3265
- 0.3238
- 0.3272
- 0.3234
- 0.3248
- 0.3248
- 0.3231
- 0.3234
- 0.3253
test_loss_list:
- 1.7917461156845094
- 1.655442454814911
- 1.6014402103424072
- 1.5625431394577027
- 1.5139334726333618
- 1.4819955468177795
- 1.4567818093299865
- 1.436280426979065
- 1.432320773601532
- 1.4269294881820678
- 1.3961068201065063
- 1.3781021404266358
- 1.3612962198257446
- 1.3487920999526977
- 1.3411435294151306
- 1.3320010018348694
- 1.321658751964569
- 1.3278255248069764
- 1.3070070719718934
- 1.293735601902008
- 1.285013029575348
- 1.2956826567649842
- 1.2744828844070435
- 1.265887725353241
- 1.2600325107574464
- 1.2538711786270142
- 1.2494483304023742
- 1.2466988229751588
- 1.2403893876075744
- 1.2333233070373535
- 1.2290078496932983
- 1.2374738216400147
- 1.2225331473350525
- 1.2149269962310791
- 1.2096739411354065
- 1.2266895604133605
- 1.2068840312957763
- 1.199634234905243
- 1.1977077722549438
- 1.19090895652771
- 1.206174874305725
- 1.2112757205963134
- 1.1918574237823487
- 1.1862383723258971
- 1.181101679801941
- 1.1916419219970704
- 1.1815615940093993
- 1.188050308227539
- 1.169889886379242
- 1.1682957196235657
- 1.166471664905548
- 1.1649806356430055
- 1.1640692043304444
- 1.177950575351715
- 1.165661005973816
- 1.1577075982093812
- 1.1766444182395934
- 1.1602899789810182
- 1.1567297077178955
- 1.1531812787055968
- 1.1539771199226379
- 1.1553015661239625
- 1.1502746200561524
- 1.1673750066757203
- 1.1574510622024536
- 1.1491269087791443
- 1.1672880053520203
- 1.152997555732727
- 1.150436782836914
- 1.1508554553985595
- 1.147105977535248
- 1.1481097531318665
- 1.1652508807182311
- 1.1706000304222106
- 1.1537535333633422
- 1.1492789530754088
- 1.1622409057617187
- 1.1507639360427857
- 1.1443246030807495
- 1.1633128261566161
- 1.15075541973114
- 1.164524474143982
- 1.15177001953125
- 1.1470370054244996
- 1.1500918388366699
- 1.1493900299072266
- 1.1612877893447875
- 1.1752240252494812
- 1.1745184898376464
- 1.155201358795166
- 1.1531219863891602
- 1.1489645290374755
- 1.1666870999336243
- 1.149247136116028
- 1.1658309888839722
- 1.1731140851974486
- 1.1534028959274292
- 1.1700097465515136
- 1.1779567670822144
- 1.1548336553573608
train_accuracy:
- 0.049
- 0.104
- 0.132
- 0.126
- 0.0
- 0.0
- 0.163
- 0.0
- 0.17
- 0.166
- 0.181
- 0.176
- 0.18
- 0.204
- 0.199
- 0.201
- 0.241
- 0.203
- 0.0
- 0.221
- 0.222
- 0.22
- 0.0
- 0.26
- 0.261
- 0.223
- 0.233
- 0.235
- 0.23
- 0.241
- 0.247
- 0.264
- 0.28
- 0.254
- 0.253
- 0.302
- 0.255
- 0.302
- 0.0
- 0.305
- 0.316
- 0.312
- 0.0
- 0.267
- 0.326
- 0.3
- 0.0
- 0.273
- 0.276
- 0.281
- 0.307
- 0.266
- 0.271
- 0.311
- 0.312
- 0.34
- 0.288
- 0.301
- 0.0
- 0.285
- 0.314
- 0.294
- 0.323
- 0.282
- 0.308
- 0.317
- 0.346
- 0.299
- 0.289
- 0.351
- 0.299
- 0.36
- 0.29
- 0.285
- 0.296
- 0.321
- 0.349
- 0.354
- 0.317
- 0.295
- 0.32
- 0.335
- 0.296
- 0.0
- 0.294
- 0.312
- 0.323
- 0.355
- 0.311
- 0.357
- 0.356
- 0.296
- 0.37
- 0.365
- 0.353
- 0.302
- 0.355
- 0.356
- 0.309
- 0.335
train_loss:
- 3.871
- 3.508
- 3.675
- 3.53
- 2.988
- 2.906
- 2.788
- 2.768
- 3.005
- 2.89
- 2.522
- 2.414
- 2.389
- 2.356
- 2.286
- 2.234
- 2.221
- 2.42
- 2.092
- 2.057
- 2.007
- 2.207
- 1.919
- 1.876
- 1.813
- 1.8
- 1.741
- 1.699
- 1.699
- 1.653
- 1.589
- 1.804
- 1.544
- 1.513
- 1.485
- 1.625
- 1.436
- 1.399
- 1.333
- 1.307
- 1.478
- 1.418
- 1.228
- 1.202
- 1.174
- 1.291
- 1.128
- 1.277
- 1.095
- 1.074
- 1.045
- 1.006
- 0.963
- 1.082
- 0.976
- 0.931
- 1.034
- 0.876
- 0.874
- 0.872
- 0.836
- 0.823
- 0.81
- 0.909
- 0.758
- 0.726
- 0.809
- 0.715
- 0.685
- 0.708
- 0.651
- 0.651
- 0.726
- 0.7
- 0.627
- 0.62
- 0.655
- 0.588
- 0.567
- 0.632
- 0.529
- 0.596
- 0.527
- 0.506
- 0.509
- 0.497
- 0.517
- 0.521
- 0.506
- 0.448
- 0.416
- 0.437
- 0.46
- 0.436
- 0.452
- 0.432
- 0.406
- 0.427
- 0.423
- 0.377
unequal: 0
verbose: 1
