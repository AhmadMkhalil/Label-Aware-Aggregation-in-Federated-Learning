avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0377
- 0.0887
- 0.1124
- 0.1262
- 0.1422
- 0.1553
- 0.1693
- 0.1792
- 0.1882
- 0.1906
- 0.1967
- 0.2049
- 0.2133
- 0.2132
- 0.2211
- 0.2273
- 0.2322
- 0.2348
- 0.239
- 0.2427
- 0.2472
- 0.251
- 0.2534
- 0.2587
- 0.2597
- 0.2665
- 0.2676
- 0.2713
- 0.2714
- 0.2758
- 0.2791
- 0.2805
- 0.285
- 0.2888
- 0.2884
- 0.2915
- 0.2932
- 0.2969
- 0.3008
- 0.2958
- 0.3021
- 0.3008
- 0.304
- 0.3037
- 0.3075
- 0.3068
- 0.3106
- 0.3072
- 0.3126
- 0.3158
- 0.3156
- 0.3103
- 0.3155
- 0.3193
- 0.3244
- 0.3227
- 0.3245
- 0.3218
- 0.3271
- 0.3277
- 0.3229
- 0.3242
- 0.3265
- 0.3272
- 0.3268
- 0.3273
- 0.331
- 0.3283
- 0.3247
- 0.3302
- 0.3289
- 0.3339
- 0.3303
- 0.3358
- 0.3311
- 0.3302
- 0.3324
- 0.3305
- 0.3349
- 0.3367
- 0.3389
- 0.3364
- 0.3412
- 0.3391
- 0.3424
- 0.3391
- 0.3417
- 0.3414
- 0.3371
- 0.3415
- 0.3405
- 0.3375
- 0.3389
- 0.3454
- 0.338
- 0.3396
- 0.3419
- 0.3426
- 0.3418
- 0.344
test_loss_list:
- 1.7968392419815062
- 1.6562157487869262
- 1.5953926515579224
- 1.5475538635253907
- 1.509186692237854
- 1.477324559688568
- 1.4527668237686158
- 1.4315317177772522
- 1.4120023512840272
- 1.3970155429840088
- 1.3936485052108765
- 1.369223074913025
- 1.3671378874778748
- 1.341467218399048
- 1.3443032145500182
- 1.3366084671020508
- 1.332267520427704
- 1.3044184803962708
- 1.2848237800598143
- 1.275781192779541
- 1.2684713888168335
- 1.275855975151062
- 1.2564012384414673
- 1.2608395910263062
- 1.240990436077118
- 1.2469508528709412
- 1.2297542428970336
- 1.2238837742805482
- 1.231546449661255
- 1.2317385411262511
- 1.2081863689422607
- 1.2000861549377442
- 1.1921654415130616
- 1.191938681602478
- 1.1839167833328248
- 1.179271469116211
- 1.1759489798545837
- 1.1709393334388734
- 1.166387495994568
- 1.1850505757331848
- 1.1659887862205505
- 1.1616800618171692
- 1.170490207672119
- 1.1571583700180055
- 1.169655122756958
- 1.1747174334526063
- 1.1763383960723877
- 1.184153745174408
- 1.1528189444541932
- 1.1400453114509583
- 1.1560985136032105
- 1.1699115300178529
- 1.1424842166900635
- 1.1359770321846008
- 1.1295362687110901
- 1.1296002769470215
- 1.1295218467712402
- 1.131663990020752
- 1.124003405570984
- 1.1251088500022888
- 1.1383543229103088
- 1.1453292298316955
- 1.127852690219879
- 1.1233297562599183
- 1.1223496723175048
- 1.137939796447754
- 1.1206949520111085
- 1.1421878480911254
- 1.1276287508010865
- 1.1368543243408202
- 1.1418945097923279
- 1.1451902770996094
- 1.1545437574386597
- 1.1515058946609498
- 1.1299241185188293
- 1.1452252554893494
- 1.1254619193077087
- 1.1472082471847533
- 1.142893249988556
- 1.148887143135071
- 1.1230940175056459
- 1.1214504408836365
- 1.1197210144996643
- 1.1166597270965577
- 1.1135089421272277
- 1.1167489290237427
- 1.1150446152687072
- 1.1150580906867982
- 1.131373610496521
- 1.1183803391456604
- 1.1361400437355043
- 1.1400059747695923
- 1.1271177124977112
- 1.120567524433136
- 1.1338157653808594
- 1.125492935180664
- 1.11717458486557
- 1.1205955958366394
- 1.13792644739151
- 1.1196088123321533
train_accuracy:
- 0.046
- 0.082
- 0.118
- 0.143
- 0.124
- 0.133
- 0.177
- 0.157
- 0.168
- 0.174
- 0.188
- 0.193
- 0.217
- 0.202
- 0.212
- 0.218
- 0.202
- 0.212
- 0.0
- 0.216
- 0.205
- 0.242
- 0.215
- 0.217
- 0.263
- 0.244
- 0.233
- 0.275
- 0.236
- 0.239
- 0.295
- 0.286
- 0.0
- 0.236
- 0.243
- 0.295
- 0.292
- 0.309
- 0.283
- 0.257
- 0.257
- 0.301
- 0.29
- 0.282
- 0.304
- 0.303
- 0.275
- 0.297
- 0.298
- 0.325
- 0.328
- 0.267
- 0.282
- 0.301
- 0.303
- 0.314
- 0.297
- 0.307
- 0.338
- 0.0
- 0.321
- 0.326
- 0.338
- 0.0
- 0.0
- 0.314
- 0.322
- 0.319
- 0.307
- 0.332
- 0.317
- 0.324
- 0.306
- 0.321
- 0.332
- 0.338
- 0.351
- 0.304
- 0.324
- 0.323
- 0.0
- 0.345
- 0.361
- 0.316
- 0.366
- 0.336
- 0.317
- 0.371
- 0.356
- 0.333
- 0.338
- 0.324
- 0.321
- 0.349
- 0.361
- 0.321
- 0.327
- 0.341
- 0.356
- 0.0
train_loss:
- 3.865
- 3.481
- 3.285
- 3.11
- 2.996
- 2.917
- 2.798
- 2.717
- 2.664
- 2.595
- 2.826
- 2.428
- 2.714
- 2.305
- 2.572
- 2.497
- 2.403
- 2.114
- 2.111
- 1.99
- 1.988
- 2.152
- 1.898
- 2.123
- 1.809
- 1.957
- 1.692
- 1.659
- 1.888
- 1.797
- 1.558
- 1.541
- 1.537
- 1.422
- 1.47
- 1.402
- 1.398
- 1.35
- 1.309
- 1.478
- 1.293
- 1.268
- 1.406
- 1.221
- 1.322
- 1.28
- 1.248
- 1.205
- 1.055
- 1.067
- 1.128
- 1.099
- 0.974
- 0.906
- 0.96
- 0.878
- 0.878
- 0.852
- 0.906
- 0.835
- 0.929
- 0.861
- 0.809
- 0.745
- 0.721
- 0.839
- 0.716
- 0.78
- 0.687
- 0.779
- 0.755
- 0.712
- 0.673
- 0.68
- 0.602
- 0.618
- 0.563
- 0.585
- 0.609
- 0.599
- 0.572
- 0.537
- 0.489
- 0.495
- 0.501
- 0.498
- 0.466
- 0.46
- 0.493
- 0.463
- 0.474
- 0.46
- 0.42
- 0.427
- 0.441
- 0.397
- 0.393
- 0.372
- 0.406
- 0.371
unequal: 0
verbose: 1
