avg_train_accuracy: 0.341
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0415
- 0.0942
- 0.1125
- 0.1325
- 0.1469
- 0.1594
- 0.1672
- 0.1767
- 0.1857
- 0.1954
- 0.1992
- 0.2076
- 0.2149
- 0.2206
- 0.2254
- 0.2291
- 0.235
- 0.2433
- 0.2437
- 0.2516
- 0.251
- 0.257
- 0.2595
- 0.2626
- 0.2612
- 0.2652
- 0.2664
- 0.2725
- 0.2746
- 0.2735
- 0.2722
- 0.2783
- 0.2808
- 0.2799
- 0.2837
- 0.2902
- 0.284
- 0.2912
- 0.2945
- 0.2929
- 0.2956
- 0.2992
- 0.2999
- 0.2984
- 0.3034
- 0.3033
- 0.3074
- 0.3047
- 0.3056
- 0.3063
- 0.3098
- 0.3099
- 0.3104
- 0.3125
- 0.3082
- 0.3117
- 0.3137
- 0.3143
- 0.3166
- 0.3167
- 0.3191
- 0.3208
- 0.3206
- 0.3238
- 0.3231
- 0.3226
- 0.3243
- 0.3238
- 0.3218
- 0.3215
- 0.3226
- 0.3283
- 0.3247
- 0.3289
- 0.3255
- 0.3234
- 0.3272
- 0.3273
- 0.3299
- 0.3284
- 0.3304
- 0.3292
- 0.3286
- 0.331
- 0.3288
- 0.3315
- 0.3317
- 0.3319
- 0.336
- 0.3326
- 0.3354
- 0.3352
- 0.3317
- 0.3366
- 0.3336
- 0.3372
- 0.3355
- 0.3386
- 0.3355
- 0.3382
test_loss_list:
- 1.7901036405563355
- 1.646918396949768
- 1.5867001390457154
- 1.550860707759857
- 1.5244888496398925
- 1.4788303327560426
- 1.46664311170578
- 1.4320595717430116
- 1.407777636051178
- 1.4049907994270325
- 1.3782704496383666
- 1.3630330443382264
- 1.3650036716461182
- 1.340307502746582
- 1.3288899922370911
- 1.315968713760376
- 1.306105570793152
- 1.2959040760993958
- 1.2858495783805848
- 1.2768860960006714
- 1.28448970079422
- 1.284010934829712
- 1.2588711023330688
- 1.2657400226593019
- 1.27120126247406
- 1.2681337475776673
- 1.2649140310287477
- 1.2342045521736145
- 1.2207012343406678
- 1.2130310678482055
- 1.2280633640289307
- 1.2294666433334351
- 1.2309945845603942
- 1.2056490564346314
- 1.19358478307724
- 1.186102876663208
- 1.204106171131134
- 1.1867211198806762
- 1.176135401725769
- 1.1962136697769166
- 1.1731953096389771
- 1.1660171723365784
- 1.1624461221694946
- 1.1810541915893555
- 1.162057819366455
- 1.1574813723564148
- 1.152322015762329
- 1.1528902411460877
- 1.1711327338218689
- 1.1749995279312133
- 1.1530219316482544
- 1.1512395596504212
- 1.1484686470031737
- 1.1455174851417542
- 1.1616397404670715
- 1.1701293921470641
- 1.1465757608413696
- 1.1414178347587585
- 1.1382801485061647
- 1.1373598599433898
- 1.1378754210472106
- 1.1363254690170288
- 1.133037052154541
- 1.132349488735199
- 1.1354783272743225
- 1.1341745710372926
- 1.132554361820221
- 1.1364162516593934
- 1.1473861312866211
- 1.1352165627479553
- 1.133527717590332
- 1.1325529432296753
- 1.1303924965858458
- 1.132488384246826
- 1.1510476899147033
- 1.1519418478012085
- 1.158558259010315
- 1.139136164188385
- 1.1334791016578674
- 1.1336233305931092
- 1.1484258794784545
- 1.1536735677719117
- 1.1605912399291993
- 1.1615535068511962
- 1.164781231880188
- 1.1383674907684327
- 1.1338969564437866
- 1.1297962880134582
- 1.1280554294586183
- 1.1274080133438111
- 1.12808495759964
- 1.1299075150489808
- 1.1441967058181763
- 1.1328364491462708
- 1.149114317893982
- 1.1310035800933838
- 1.1293863534927369
- 1.132899932861328
- 1.1462523126602173
- 1.1332654190063476
train_accuracy:
- 0.054
- 0.123
- 0.103
- 0.147
- 0.133
- 0.164
- 0.181
- 0.148
- 0.186
- 0.163
- 0.196
- 0.215
- 0.221
- 0.204
- 0.21
- 0.225
- 0.0
- 0.235
- 0.249
- 0.211
- 0.202
- 0.242
- 0.257
- 0.237
- 0.263
- 0.252
- 0.221
- 0.271
- 0.277
- 0.0
- 0.271
- 0.273
- 0.311
- 0.3
- 0.279
- 0.286
- 0.265
- 0.317
- 0.242
- 0.293
- 0.265
- 0.3
- 0.0
- 0.26
- 0.0
- 0.321
- 0.294
- 0.291
- 0.265
- 0.331
- 0.307
- 0.293
- 0.316
- 0.305
- 0.317
- 0.302
- 0.311
- 0.317
- 0.308
- 0.295
- 0.305
- 0.323
- 0.0
- 0.0
- 0.275
- 0.345
- 0.309
- 0.291
- 0.336
- 0.327
- 0.312
- 0.318
- 0.0
- 0.304
- 0.283
- 0.347
- 0.335
- 0.327
- 0.349
- 0.321
- 0.323
- 0.327
- 0.335
- 0.332
- 0.345
- 0.318
- 0.333
- 0.354
- 0.336
- 0.345
- 0.318
- 0.331
- 0.367
- 0.338
- 0.364
- 0.338
- 0.334
- 0.365
- 0.293
- 0.341
train_loss:
- 3.827
- 3.453
- 3.266
- 3.491
- 3.331
- 2.887
- 3.126
- 2.674
- 2.614
- 2.87
- 2.5
- 2.403
- 2.651
- 2.272
- 2.23
- 2.203
- 2.197
- 2.098
- 2.061
- 2.009
- 2.236
- 2.2
- 1.913
- 2.084
- 2.02
- 1.988
- 1.907
- 1.683
- 1.63
- 1.611
- 1.762
- 1.722
- 1.682
- 1.464
- 1.43
- 1.398
- 1.56
- 1.354
- 1.326
- 1.45
- 1.282
- 1.243
- 1.194
- 1.292
- 1.183
- 1.12
- 1.116
- 1.094
- 1.172
- 1.161
- 1.025
- 1.007
- 0.977
- 0.978
- 1.074
- 1.005
- 0.911
- 0.836
- 0.863
- 0.834
- 0.819
- 0.82
- 0.776
- 0.78
- 0.733
- 0.738
- 0.724
- 0.699
- 0.795
- 0.675
- 0.646
- 0.63
- 0.659
- 0.617
- 0.654
- 0.671
- 0.612
- 0.608
- 0.585
- 0.56
- 0.611
- 0.605
- 0.582
- 0.564
- 0.531
- 0.499
- 0.454
- 0.476
- 0.455
- 0.467
- 0.442
- 0.42
- 0.479
- 0.43
- 0.444
- 0.428
- 0.396
- 0.377
- 0.408
- 0.371
unequal: 0
verbose: 1
