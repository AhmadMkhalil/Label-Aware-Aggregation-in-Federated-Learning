avg_train_accuracy: 0.344
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0312
- 0.0918
- 0.1176
- 0.133
- 0.1523
- 0.1612
- 0.17
- 0.1779
- 0.1888
- 0.1928
- 0.1999
- 0.2064
- 0.2112
- 0.2129
- 0.2212
- 0.2247
- 0.2315
- 0.2349
- 0.2393
- 0.2451
- 0.2454
- 0.2487
- 0.2496
- 0.2555
- 0.2551
- 0.2591
- 0.2624
- 0.2673
- 0.266
- 0.2661
- 0.2693
- 0.2741
- 0.2712
- 0.2753
- 0.2765
- 0.277
- 0.2795
- 0.2809
- 0.2825
- 0.2829
- 0.2829
- 0.2868
- 0.2908
- 0.2878
- 0.2896
- 0.2925
- 0.29
- 0.2933
- 0.296
- 0.2986
- 0.2981
- 0.2997
- 0.3023
- 0.3033
- 0.3044
- 0.3047
- 0.3073
- 0.3113
- 0.3087
- 0.3104
- 0.3096
- 0.3089
- 0.3114
- 0.311
- 0.3126
- 0.3137
- 0.3107
- 0.316
- 0.3173
- 0.3146
- 0.3183
- 0.3175
- 0.3222
- 0.3188
- 0.3202
- 0.3186
- 0.3194
- 0.3241
- 0.3226
- 0.3243
- 0.3255
- 0.3224
- 0.3224
- 0.3231
- 0.3264
- 0.3228
- 0.3256
- 0.3262
- 0.3295
- 0.3249
- 0.3273
- 0.3258
- 0.3283
- 0.3295
- 0.3263
- 0.3273
- 0.3301
- 0.3337
- 0.3333
- 0.3334
test_loss_list:
- 1.7983463907241821
- 1.6500280332565307
- 1.586816201210022
- 1.5404636788368224
- 1.5152563595771789
- 1.4754879903793334
- 1.4508451271057128
- 1.4400607538223267
- 1.4099075531959533
- 1.3949619841575622
- 1.3770706629753113
- 1.3622985911369323
- 1.3500240325927735
- 1.3410965061187745
- 1.3246676063537597
- 1.3176988005638122
- 1.3113178372383119
- 1.302404887676239
- 1.306530842781067
- 1.285962963104248
- 1.278775670528412
- 1.2710908555984497
- 1.2638630485534668
- 1.253176281452179
- 1.2491121649742127
- 1.2424217963218689
- 1.2399773216247558
- 1.2335317087173463
- 1.2299244856834413
- 1.2265342688560485
- 1.222501187324524
- 1.216699800491333
- 1.2158882069587706
- 1.210804352760315
- 1.2056727886199952
- 1.2094241786003113
- 1.2026419591903688
- 1.1970386266708375
- 1.1916012287139892
- 1.2049009203910828
- 1.1901778149604798
- 1.1849850702285767
- 1.1817800784111023
- 1.1778267550468444
- 1.1788845920562745
- 1.1746635150909424
- 1.1722888517379761
- 1.1854188799858094
- 1.1678974056243896
- 1.1615622305870057
- 1.1603406524658204
- 1.1780084919929505
- 1.1561066699028015
- 1.163706796169281
- 1.1549154710769653
- 1.149766764640808
- 1.147494969367981
- 1.1487533235549927
- 1.1450073909759522
- 1.1619270277023315
- 1.1463433957099916
- 1.145623824596405
- 1.1604034399986267
- 1.1483283424377442
- 1.1635938215255737
- 1.1411027097702027
- 1.1669806432724
- 1.1672813892364502
- 1.1478127598762513
- 1.1421628379821778
- 1.137851595878601
- 1.138081591129303
- 1.1394032382965087
- 1.156753706932068
- 1.1663472151756287
- 1.141510524749756
- 1.158505973815918
- 1.141601574420929
- 1.1382152104377747
- 1.137963321208954
- 1.134593780040741
- 1.1541093325614928
- 1.1614047503471374
- 1.1393647027015685
- 1.1382607483863831
- 1.1570039653778077
- 1.1407815766334535
- 1.1410128211975097
- 1.1356918382644654
- 1.1548921394348144
- 1.140045018196106
- 1.1561154103279114
- 1.1426118040084838
- 1.138836019039154
- 1.1553005480766296
- 1.141481010913849
- 1.1571090841293334
- 1.1402224969863892
- 1.138876690864563
- 1.1403728771209716
train_accuracy:
- 0.0
- 0.104
- 0.102
- 0.135
- 0.148
- 0.127
- 0.187
- 0.161
- 0.207
- 0.19
- 0.221
- 0.0
- 0.237
- 0.224
- 0.179
- 0.235
- 0.222
- 0.236
- 0.225
- 0.206
- 0.217
- 0.0
- 0.272
- 0.219
- 0.267
- 0.278
- 0.247
- 0.0
- 0.254
- 0.0
- 0.275
- 0.236
- 0.248
- 0.303
- 0.299
- 0.275
- 0.282
- 0.299
- 0.235
- 0.293
- 0.0
- 0.291
- 0.305
- 0.264
- 0.26
- 0.303
- 0.298
- 0.317
- 0.334
- 0.32
- 0.281
- 0.312
- 0.257
- 0.327
- 0.0
- 0.311
- 0.339
- 0.314
- 0.307
- 0.28
- 0.332
- 0.312
- 0.274
- 0.274
- 0.275
- 0.312
- 0.303
- 0.329
- 0.315
- 0.32
- 0.317
- 0.316
- 0.333
- 0.349
- 0.339
- 0.344
- 0.334
- 0.0
- 0.316
- 0.275
- 0.31
- 0.28
- 0.357
- 0.284
- 0.295
- 0.293
- 0.293
- 0.335
- 0.328
- 0.332
- 0.289
- 0.336
- 0.353
- 0.342
- 0.302
- 0.286
- 0.278
- 0.354
- 0.0
- 0.344
train_loss:
- 3.842
- 3.459
- 3.237
- 3.111
- 3.328
- 2.883
- 2.768
- 3.065
- 2.634
- 2.54
- 2.486
- 2.429
- 2.355
- 2.296
- 2.29
- 2.199
- 2.147
- 2.073
- 2.338
- 2.02
- 1.957
- 1.943
- 1.897
- 1.856
- 1.856
- 1.765
- 1.735
- 1.696
- 1.659
- 1.622
- 1.579
- 1.57
- 1.558
- 1.494
- 1.477
- 1.416
- 1.401
- 1.364
- 1.396
- 1.556
- 1.316
- 1.265
- 1.244
- 1.258
- 1.206
- 1.187
- 1.123
- 1.278
- 1.138
- 1.093
- 1.071
- 1.168
- 1.007
- 0.976
- 0.952
- 0.982
- 0.937
- 0.901
- 0.875
- 0.97
- 0.86
- 0.819
- 0.912
- 0.789
- 0.879
- 0.765
- 0.81
- 0.812
- 0.706
- 0.682
- 0.687
- 0.654
- 0.636
- 0.712
- 0.7
- 0.623
- 0.651
- 0.577
- 0.567
- 0.568
- 0.553
- 0.596
- 0.584
- 0.528
- 0.502
- 0.541
- 0.478
- 0.458
- 0.466
- 0.492
- 0.459
- 0.483
- 0.419
- 0.42
- 0.447
- 0.41
- 0.437
- 0.384
- 0.388
- 0.364
unequal: 0
verbose: 1
