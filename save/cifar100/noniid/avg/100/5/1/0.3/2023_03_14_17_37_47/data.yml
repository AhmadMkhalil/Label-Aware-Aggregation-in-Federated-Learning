avg_train_accuracy: 0.377
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0776
- 0.1077
- 0.111
- 0.1363
- 0.1506
- 0.1658
- 0.1716
- 0.1775
- 0.1889
- 0.188
- 0.201
- 0.2112
- 0.2126
- 0.2188
- 0.2048
- 0.2273
- 0.2291
- 0.2329
- 0.2341
- 0.2378
- 0.246
- 0.2443
- 0.2471
- 0.2513
- 0.2513
- 0.2535
- 0.254
- 0.2516
- 0.2494
- 0.2662
- 0.2621
- 0.2538
- 0.2687
- 0.2741
- 0.275
- 0.2735
- 0.284
- 0.2813
- 0.2815
- 0.2837
- 0.2862
- 0.284
- 0.2858
- 0.2923
- 0.2891
- 0.2923
- 0.2925
- 0.2872
- 0.2959
- 0.2923
- 0.298
- 0.2999
- 0.2989
- 0.3006
- 0.3013
- 0.3044
- 0.3037
- 0.305
- 0.3089
- 0.2999
- 0.3024
- 0.31
- 0.3081
- 0.3101
- 0.3046
- 0.3041
- 0.3111
- 0.3155
- 0.3129
- 0.3109
- 0.3192
- 0.3137
- 0.3176
- 0.3134
- 0.3194
- 0.3188
- 0.3092
- 0.3117
- 0.3204
- 0.323
- 0.3143
- 0.3211
- 0.3213
- 0.3231
- 0.3266
- 0.3218
- 0.3284
- 0.3248
- 0.3274
- 0.3237
- 0.3194
- 0.326
- 0.3278
- 0.3257
- 0.3289
- 0.3278
- 0.3233
- 0.329
- 0.3273
test_loss_list:
- 1.7987675094604492
- 1.6773312282562256
- 1.6158846068382262
- 1.5742215538024902
- 1.5315990495681762
- 1.5029532265663148
- 1.4846558117866515
- 1.467547631263733
- 1.4589080595970154
- 1.4087409472465515
- 1.4067049312591553
- 1.3950250816345215
- 1.3874598836898804
- 1.38200208902359
- 1.3383864307403563
- 1.3563721132278443
- 1.3318187236785888
- 1.3386624479293823
- 1.334929518699646
- 1.3275867438316344
- 1.322664270401001
- 1.3180333662033081
- 1.3153431797027588
- 1.3166530156135559
- 1.3030312967300415
- 1.2538226461410522
- 1.2686889147758484
- 1.2723336386680604
- 1.2516160821914672
- 1.2557581710815429
- 1.243022813796997
- 1.2382233428955078
- 1.2561460661888122
- 1.234058964252472
- 1.2381351828575133
- 1.208153567314148
- 1.221751847267151
- 1.2141230010986328
- 1.2231663942337037
- 1.2242294263839721
- 1.216503233909607
- 1.22359778881073
- 1.2286582255363465
- 1.1875386643409729
- 1.1808232474327087
- 1.1859459590911865
- 1.1857866168022155
- 1.1802997040748595
- 1.1946447730064391
- 1.1769782161712647
- 1.1812666392326354
- 1.1702588534355163
- 1.1818292927742005
- 1.1808074450492858
- 1.1870227479934692
- 1.188340151309967
- 1.193736035823822
- 1.1922877740859985
- 1.189651312828064
- 1.1408590507507324
- 1.1607973623275756
- 1.1628400349617005
- 1.148109257221222
- 1.156007297039032
- 1.1458102941513062
- 1.1529660654067992
- 1.158887002468109
- 1.1453174996376037
- 1.1477034652233125
- 1.1452113199234009
- 1.1621483731269837
- 1.1532015562057496
- 1.1638926577568054
- 1.1683760643005372
- 1.1701494693756103
- 1.1698985004425049
- 1.1447782874107362
- 1.158463830947876
- 1.1531056261062622
- 1.1505791163444519
- 1.1546251940727235
- 1.1603579759597777
- 1.1591213083267211
- 1.135483455657959
- 1.1435788869857788
- 1.1463062214851378
- 1.1655837798118591
- 1.134140934944153
- 1.1393692803382873
- 1.1479400432109832
- 1.1576725006103517
- 1.1667208802700042
- 1.1654258871078491
- 1.1643655741214751
- 1.1780903911590577
- 1.1755715692043305
- 1.1671230101585388
- 1.1766899478435517
- 1.1720451521873474
- 1.1820801031589507
train_accuracy:
- 0.033
- 0.0
- 0.12
- 0.086
- 0.119
- 0.128
- 0.155
- 0.142
- 0.189
- 0.0
- 0.21
- 0.181
- 0.206
- 0.21
- 0.192
- 0.0
- 0.203
- 0.218
- 0.216
- 0.223
- 0.221
- 0.251
- 0.255
- 0.245
- 0.253
- 0.226
- 0.26
- 0.247
- 0.225
- 0.235
- 0.269
- 0.233
- 0.249
- 0.274
- 0.275
- 0.0
- 0.275
- 0.311
- 0.273
- 0.271
- 0.293
- 0.298
- 0.296
- 0.28
- 0.274
- 0.251
- 0.292
- 0.0
- 0.223
- 0.302
- 0.283
- 0.289
- 0.302
- 0.277
- 0.296
- 0.287
- 0.333
- 0.277
- 0.288
- 0.305
- 0.0
- 0.316
- 0.316
- 0.297
- 0.358
- 0.0
- 0.285
- 0.275
- 0.277
- 0.0
- 0.335
- 0.305
- 0.356
- 0.344
- 0.308
- 0.32
- 0.308
- 0.0
- 0.311
- 0.362
- 0.327
- 0.319
- 0.288
- 0.0
- 0.288
- 0.333
- 0.324
- 0.305
- 0.334
- 0.36
- 0.345
- 0.342
- 0.332
- 0.356
- 0.336
- 0.336
- 0.364
- 0.33
- 0.354
- 0.377
train_loss:
- 4.31
- 2.931
- 3.723
- 2.665
- 3.394
- 3.323
- 3.103
- 3.115
- 2.895
- 2.173
- 2.857
- 2.863
- 2.674
- 2.673
- 1.948
- 1.851
- 2.469
- 2.331
- 2.284
- 2.291
- 2.212
- 2.173
- 2.074
- 2.068
- 2.106
- 1.552
- 1.861
- 1.839
- 1.356
- 1.558
- 1.725
- 1.323
- 1.162
- 1.826
- 1.507
- 1.32
- 1.61
- 1.746
- 1.492
- 1.521
- 1.683
- 1.443
- 1.403
- 0.987
- 1.514
- 0.868
- 1.263
- 1.025
- 0.9
- 1.285
- 0.857
- 1.182
- 1.121
- 1.258
- 1.082
- 1.104
- 1.0
- 1.009
- 1.039
- 0.795
- 0.867
- 0.724
- 1.04
- 0.735
- 0.998
- 0.679
- 0.673
- 0.891
- 0.866
- 0.604
- 0.824
- 0.857
- 0.765
- 0.696
- 0.757
- 0.709
- 0.488
- 0.52
- 0.658
- 0.745
- 0.649
- 0.697
- 0.653
- 0.513
- 0.568
- 0.608
- 0.469
- 0.526
- 0.582
- 0.58
- 0.476
- 0.498
- 0.446
- 0.491
- 0.429
- 0.428
- 0.529
- 0.415
- 0.493
- 0.4
unequal: 0
verbose: 1
