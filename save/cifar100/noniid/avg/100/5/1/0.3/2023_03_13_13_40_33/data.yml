avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0436
- 0.0934
- 0.1221
- 0.1364
- 0.1423
- 0.1534
- 0.1645
- 0.1634
- 0.1525
- 0.1854
- 0.1874
- 0.1938
- 0.1942
- 0.2038
- 0.2183
- 0.2248
- 0.2221
- 0.2253
- 0.2297
- 0.2356
- 0.2343
- 0.229
- 0.248
- 0.2392
- 0.2367
- 0.2292
- 0.2479
- 0.2579
- 0.2597
- 0.2561
- 0.2596
- 0.2617
- 0.2698
- 0.2697
- 0.2731
- 0.273
- 0.2735
- 0.264
- 0.2634
- 0.2807
- 0.2799
- 0.2804
- 0.2826
- 0.2839
- 0.2852
- 0.2851
- 0.291
- 0.2946
- 0.2913
- 0.2897
- 0.2885
- 0.2954
- 0.2935
- 0.2985
- 0.2919
- 0.3011
- 0.2919
- 0.2978
- 0.3036
- 0.307
- 0.307
- 0.3077
- 0.3035
- 0.3075
- 0.303
- 0.3038
- 0.3107
- 0.3111
- 0.3164
- 0.313
- 0.3163
- 0.3176
- 0.3188
- 0.3141
- 0.3091
- 0.3159
- 0.3133
- 0.311
- 0.3215
- 0.3209
- 0.3224
- 0.3221
- 0.3174
- 0.3172
- 0.3177
- 0.3185
- 0.3211
- 0.3194
- 0.3236
- 0.3196
- 0.3119
- 0.3241
- 0.3253
- 0.3261
- 0.319
- 0.328
- 0.3248
- 0.3222
- 0.3234
- 0.3171
test_loss_list:
- 1.7913957738876343
- 1.6647182941436767
- 1.611230616569519
- 1.5748409700393677
- 1.515841076374054
- 1.503299479484558
- 1.489308204650879
- 1.450738911628723
- 1.4532617950439453
- 1.421825864315033
- 1.4225687408447265
- 1.3929720139503479
- 1.3875317978858948
- 1.3791013383865356
- 1.3722706174850463
- 1.3638129377365111
- 1.3641541862487794
- 1.319818482398987
- 1.3230482339859009
- 1.322221474647522
- 1.3066133165359497
- 1.3101012182235718
- 1.2897638130187987
- 1.285423882007599
- 1.2861115860939025
- 1.295339822769165
- 1.2746778798103333
- 1.2712019872665405
- 1.2681927227973937
- 1.2548793959617615
- 1.2507753801345824
- 1.2582893085479736
- 1.2581879639625548
- 1.2584418940544129
- 1.25064617395401
- 1.2534123134613038
- 1.2158913826942443
- 1.2282308006286622
- 1.2301156306266785
- 1.2142435431480407
- 1.219736273288727
- 1.2254727268218994
- 1.2270188927650452
- 1.2277414727210998
- 1.225248682498932
- 1.2308861923217773
- 1.227833104133606
- 1.2291260552406311
- 1.2325542521476747
- 1.2342128944396973
- 1.2464812779426575
- 1.2311597490310668
- 1.228848967552185
- 1.166144368648529
- 1.192484118938446
- 1.1853619766235353
- 1.1996166253089904
- 1.1761016535758972
- 1.191325843334198
- 1.1908605480194092
- 1.1586654877662659
- 1.1735212922096252
- 1.1831307458877562
- 1.1850070810317994
- 1.1946260046958923
- 1.2022663640975952
- 1.192027838230133
- 1.194719135761261
- 1.191117238998413
- 1.1953360104560853
- 1.1939582991600037
- 1.1479225540161133
- 1.1672397184371948
- 1.1566399598121644
- 1.1748821973800658
- 1.165851459503174
- 1.1658823084831238
- 1.1742234635353088
- 1.1579960799217224
- 1.154903440475464
- 1.1604626369476319
- 1.1743784070014953
- 1.1894080114364625
- 1.1635629177093505
- 1.1640496015548707
- 1.1749087762832642
- 1.1744023394584655
- 1.1612464094161987
- 1.1644589376449586
- 1.1719222211837768
- 1.1849845933914185
- 1.1737847876548768
- 1.1729324769973755
- 1.1774436116218567
- 1.1699560046195985
- 1.1728772878646851
- 1.1764947938919068
- 1.1897216844558716
- 1.1638259720802306
- 1.1880934238433838
train_accuracy:
- 0.034
- 0.102
- 0.103
- 0.137
- 0.0
- 0.112
- 0.152
- 0.141
- 0.158
- 0.167
- 0.189
- 0.0
- 0.185
- 0.171
- 0.23
- 0.203
- 0.25
- 0.255
- 0.235
- 0.262
- 0.168
- 0.201
- 0.255
- 0.191
- 0.197
- 0.188
- 0.212
- 0.206
- 0.218
- 0.0
- 0.305
- 0.239
- 0.246
- 0.31
- 0.258
- 0.31
- 0.252
- 0.0
- 0.0
- 0.259
- 0.267
- 0.311
- 0.285
- 0.291
- 0.26
- 0.29
- 0.338
- 0.267
- 0.277
- 0.253
- 0.248
- 0.322
- 0.325
- 0.27
- 0.288
- 0.306
- 0.281
- 0.317
- 0.297
- 0.334
- 0.0
- 0.327
- 0.272
- 0.344
- 0.266
- 0.353
- 0.297
- 0.328
- 0.309
- 0.314
- 0.35
- 0.245
- 0.301
- 0.34
- 0.312
- 0.347
- 0.223
- 0.314
- 0.234
- 0.301
- 0.251
- 0.316
- 0.355
- 0.264
- 0.309
- 0.294
- 0.309
- 0.318
- 0.357
- 0.0
- 0.289
- 0.311
- 0.294
- 0.357
- 0.0
- 0.307
- 0.322
- 0.38
- 0.0
- 0.0
train_loss:
- 4.3
- 3.807
- 3.647
- 3.454
- 2.496
- 3.235
- 3.067
- 2.337
- 2.253
- 2.887
- 2.815
- 2.004
- 2.823
- 2.607
- 2.544
- 2.523
- 2.435
- 1.855
- 2.315
- 2.232
- 1.723
- 1.614
- 2.088
- 1.63
- 1.485
- 1.423
- 1.88
- 1.993
- 1.974
- 1.281
- 1.806
- 1.676
- 1.896
- 1.699
- 1.636
- 1.681
- 1.24
- 1.164
- 1.185
- 1.482
- 1.36
- 1.583
- 1.415
- 1.431
- 1.311
- 1.322
- 1.3
- 1.197
- 1.087
- 1.115
- 1.285
- 1.296
- 1.019
- 0.822
- 0.817
- 1.077
- 0.745
- 1.13
- 0.878
- 1.048
- 0.844
- 0.882
- 0.772
- 0.752
- 0.934
- 0.682
- 1.096
- 0.922
- 0.73
- 0.636
- 0.902
- 0.482
- 0.796
- 0.525
- 0.459
- 0.713
- 0.412
- 0.674
- 0.665
- 0.564
- 0.618
- 0.664
- 0.497
- 0.475
- 0.666
- 0.514
- 0.558
- 0.493
- 0.515
- 0.456
- 0.362
- 0.486
- 0.517
- 0.48
- 0.329
- 0.502
- 0.46
- 0.465
- 0.38
- 0.266
unequal: 0
verbose: 1
