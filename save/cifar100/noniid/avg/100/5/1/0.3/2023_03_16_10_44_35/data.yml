avg_train_accuracy: 0.404
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0362
- 0.0953
- 0.1208
- 0.1324
- 0.1464
- 0.1559
- 0.1689
- 0.1745
- 0.1818
- 0.1869
- 0.1797
- 0.199
- 0.2062
- 0.2045
- 0.2183
- 0.221
- 0.226
- 0.2332
- 0.2314
- 0.2417
- 0.2418
- 0.2427
- 0.2503
- 0.2518
- 0.2538
- 0.2625
- 0.2582
- 0.263
- 0.2598
- 0.2574
- 0.2775
- 0.2673
- 0.2757
- 0.2726
- 0.2851
- 0.2844
- 0.2868
- 0.2892
- 0.2862
- 0.2743
- 0.2922
- 0.2934
- 0.2929
- 0.2937
- 0.2956
- 0.2931
- 0.3014
- 0.3014
- 0.2993
- 0.302
- 0.3062
- 0.3056
- 0.3075
- 0.3078
- 0.2998
- 0.2914
- 0.294
- 0.3118
- 0.3143
- 0.3115
- 0.3115
- 0.307
- 0.3011
- 0.3149
- 0.3205
- 0.3155
- 0.3168
- 0.3143
- 0.3091
- 0.3175
- 0.3116
- 0.3175
- 0.3109
- 0.3184
- 0.3156
- 0.3245
- 0.3294
- 0.3215
- 0.3244
- 0.3193
- 0.3222
- 0.3295
- 0.3299
- 0.3276
- 0.3268
- 0.325
- 0.3283
- 0.3207
- 0.312
- 0.3321
- 0.3302
- 0.3278
- 0.332
- 0.3305
- 0.325
- 0.3316
- 0.3342
- 0.3339
- 0.3309
- 0.3338
test_loss_list:
- 1.7989990091323853
- 1.6658740067481994
- 1.6118092823028565
- 1.5737193298339844
- 1.547839002609253
- 1.5193271684646605
- 1.5011410593986512
- 1.4898701190948487
- 1.4717168927192688
- 1.4058668828010559
- 1.4058797216415406
- 1.3924076223373414
- 1.3854765748977662
- 1.3560994815826417
- 1.3570838570594788
- 1.3543424415588379
- 1.354338345527649
- 1.3415891170501708
- 1.347068088054657
- 1.336788957118988
- 1.3305178213119506
- 1.2825757408142089
- 1.2878097891807556
- 1.2878926968574524
- 1.2894488525390626
- 1.2840632939338683
- 1.2423381257057189
- 1.2630973720550538
- 1.2535173773765564
- 1.2514828252792358
- 1.2297051382064819
- 1.2298549818992615
- 1.2282551169395446
- 1.217176616191864
- 1.215753231048584
- 1.2257202529907227
- 1.2257202196121215
- 1.2321649146080018
- 1.1913113188743591
- 1.2149762201309204
- 1.203342583179474
- 1.1960975265502929
- 1.1856470918655395
- 1.1982770347595215
- 1.201042730808258
- 1.212799789905548
- 1.2053660130500794
- 1.2096107816696167
- 1.2058345246315003
- 1.2142426323890687
- 1.2132439923286438
- 1.2132829546928405
- 1.2179540467262269
- 1.1685778951644898
- 1.1799722218513489
- 1.1954638504981994
- 1.1892007541656495
- 1.1720734667778014
- 1.1767921233177185
- 1.1823418402671815
- 1.1801136231422424
- 1.1542834115028382
- 1.1735024785995483
- 1.1595263528823851
- 1.1720003294944763
- 1.1734558653831482
- 1.169257278442383
- 1.1463552260398864
- 1.1746959567070008
- 1.164444055557251
- 1.162319016456604
- 1.1585247039794921
- 1.1718316102027893
- 1.1566597652435302
- 1.1598781061172485
- 1.154807813167572
- 1.160927770137787
- 1.1700993442535401
- 1.1676110744476318
- 1.1814561367034913
- 1.182099244594574
- 1.1321355247497558
- 1.1578047752380372
- 1.1653203749656678
- 1.1688046145439148
- 1.1449301362037658
- 1.1568035197257995
- 1.1527043890953064
- 1.1813385820388793
- 1.1460607504844667
- 1.1545644330978393
- 1.1680096912384033
- 1.164861526489258
- 1.1746568822860717
- 1.149341516494751
- 1.1595947575569152
- 1.1659581565856934
- 1.1701257824897766
- 1.149152455329895
- 1.1493164086341858
train_accuracy:
- 0.032
- 0.087
- 0.145
- 0.141
- 0.196
- 0.119
- 0.197
- 0.141
- 0.212
- 0.0
- 0.0
- 0.227
- 0.158
- 0.0
- 0.206
- 0.201
- 0.208
- 0.274
- 0.201
- 0.192
- 0.201
- 0.297
- 0.213
- 0.286
- 0.255
- 0.223
- 0.245
- 0.263
- 0.23
- 0.0
- 0.236
- 0.234
- 0.272
- 0.231
- 0.231
- 0.271
- 0.271
- 0.283
- 0.278
- 0.0
- 0.352
- 0.295
- 0.0
- 0.363
- 0.279
- 0.358
- 0.247
- 0.283
- 0.267
- 0.296
- 0.369
- 0.364
- 0.281
- 0.0
- 0.0
- 0.246
- 0.254
- 0.297
- 0.291
- 0.29
- 0.311
- 0.285
- 0.28
- 0.283
- 0.311
- 0.309
- 0.39
- 0.301
- 0.271
- 0.39
- 0.0
- 0.315
- 0.277
- 0.261
- 0.0
- 0.349
- 0.332
- 0.321
- 0.32
- 0.399
- 0.294
- 0.291
- 0.402
- 0.285
- 0.32
- 0.0
- 0.317
- 0.271
- 0.0
- 0.332
- 0.315
- 0.296
- 0.288
- 0.329
- 0.0
- 0.331
- 0.302
- 0.284
- 0.33
- 0.404
train_loss:
- 4.401
- 3.894
- 3.67
- 3.445
- 3.274
- 3.31
- 3.056
- 3.022
- 2.94
- 2.278
- 2.2
- 2.751
- 2.75
- 2.021
- 2.55
- 2.533
- 2.463
- 2.422
- 2.272
- 2.25
- 2.207
- 1.675
- 2.095
- 2.049
- 1.992
- 2.037
- 1.664
- 1.837
- 1.377
- 1.475
- 2.045
- 1.366
- 1.813
- 1.352
- 1.745
- 1.669
- 1.627
- 1.553
- 1.236
- 1.082
- 1.49
- 1.573
- 1.075
- 1.466
- 1.272
- 1.187
- 1.335
- 1.219
- 1.198
- 1.171
- 1.114
- 1.216
- 1.031
- 0.963
- 0.765
- 0.674
- 0.672
- 1.059
- 1.209
- 1.158
- 1.057
- 0.819
- 0.651
- 0.977
- 0.88
- 0.994
- 0.916
- 0.717
- 0.579
- 0.78
- 0.58
- 0.767
- 0.46
- 0.693
- 0.655
- 0.765
- 0.739
- 0.708
- 0.764
- 0.676
- 0.646
- 0.565
- 0.628
- 0.596
- 0.667
- 0.503
- 0.587
- 0.469
- 0.354
- 0.572
- 0.481
- 0.53
- 0.537
- 0.501
- 0.395
- 0.505
- 0.459
- 0.363
- 0.453
- 0.435
unequal: 0
verbose: 1
