avg_train_accuracy: 0.264
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0446
- 0.0782
- 0.0794
- 0.093
- 0.1034
- 0.1322
- 0.1537
- 0.1646
- 0.1695
- 0.1806
- 0.1889
- 0.1946
- 0.2014
- 0.2043
- 0.2118
- 0.2162
- 0.2207
- 0.2192
- 0.2304
- 0.2325
- 0.2316
- 0.2371
- 0.2432
- 0.2491
- 0.2454
- 0.2567
- 0.2588
- 0.2445
- 0.2616
- 0.2562
- 0.25
- 0.2625
- 0.2676
- 0.2685
- 0.2719
- 0.2759
- 0.2769
- 0.2753
- 0.2774
- 0.2773
- 0.2855
- 0.2835
- 0.2856
- 0.2835
- 0.2883
- 0.2876
- 0.2934
- 0.2948
- 0.2925
- 0.2961
- 0.2969
- 0.2877
- 0.2811
- 0.3009
- 0.29
- 0.3005
- 0.3103
- 0.3035
- 0.2952
- 0.2937
- 0.3081
- 0.2967
- 0.3043
- 0.3065
- 0.3098
- 0.3156
- 0.3158
- 0.3201
- 0.3161
- 0.3164
- 0.3142
- 0.3197
- 0.3214
- 0.3187
- 0.3216
- 0.3109
- 0.3081
- 0.3125
- 0.3202
- 0.321
- 0.318
- 0.3237
- 0.3176
- 0.3159
- 0.3199
- 0.3169
- 0.3189
- 0.3169
- 0.323
- 0.3238
- 0.3222
- 0.3313
- 0.3246
- 0.3248
- 0.3127
- 0.3297
- 0.3216
- 0.3312
- 0.3291
- 0.3299
test_loss_list:
- 1.7914972448348998
- 1.6701705646514893
- 1.6306036877632142
- 1.5951005363464354
- 1.564348304271698
- 1.5168133306503295
- 1.4973570203781128
- 1.4796874189376832
- 1.4703955841064453
- 1.458310799598694
- 1.4395126366615296
- 1.4253140115737915
- 1.4135815405845642
- 1.4143553018569945
- 1.4001939702033996
- 1.3397806692123413
- 1.343616135120392
- 1.3324907779693604
- 1.3255945110321046
- 1.32630136013031
- 1.3231681752204896
- 1.3255241084098817
- 1.3252384924888612
- 1.3084984254837035
- 1.3128953289985656
- 1.3004860377311707
- 1.2475326204299926
- 1.2728034996986388
- 1.2598149371147156
- 1.256361870765686
- 1.2648238635063171
- 1.2461902213096618
- 1.2459388542175294
- 1.228957040309906
- 1.230663537979126
- 1.237318036556244
- 1.2361849737167359
- 1.2403543996810913
- 1.2425664210319518
- 1.2448753213882446
- 1.2328186416625977
- 1.1962445163726807
- 1.207063879966736
- 1.2172629284858703
- 1.2133139944076539
- 1.2240011191368103
- 1.2136615109443665
- 1.2158993983268738
- 1.2201505947113036
- 1.2168836069107056
- 1.180722143650055
- 1.1979940915107727
- 1.2140454721450806
- 1.1851351404190062
- 1.190589394569397
- 1.1754167032241822
- 1.176380250453949
- 1.166204297542572
- 1.1827401041984558
- 1.187550163269043
- 1.166173369884491
- 1.181777422428131
- 1.1628145575523376
- 1.1735122108459473
- 1.1807756519317627
- 1.1779390573501587
- 1.1488618993759154
- 1.155267617702484
- 1.1703531455993652
- 1.1706329870224
- 1.1749044418334962
- 1.1788801527023316
- 1.177804067134857
- 1.17990966796875
- 1.1436904764175415
- 1.1695457792282105
- 1.1779186725616455
- 1.1710694670677184
- 1.1564267539978028
- 1.1589694380760194
- 1.1578069233894348
- 1.1592776894569397
- 1.168857023715973
- 1.1805984497070312
- 1.159061486721039
- 1.1607631874084472
- 1.1652205538749696
- 1.1719749331474305
- 1.156438980102539
- 1.1621721649169923
- 1.167062382698059
- 1.163423192501068
- 1.1792496037483216
- 1.1461227083206176
- 1.178447265625
- 1.1507453441619873
- 1.1651981663703919
- 1.1580598759651184
- 1.1498744440078736
- 1.170764811038971
train_accuracy:
- 0.046
- 0.066
- 0.0
- 0.061
- 0.072
- 0.118
- 0.147
- 0.115
- 0.131
- 0.18
- 0.136
- 0.186
- 0.205
- 0.182
- 0.158
- 0.0
- 0.244
- 0.0
- 0.268
- 0.271
- 0.193
- 0.174
- 0.167
- 0.226
- 0.226
- 0.243
- 0.0
- 0.184
- 0.243
- 0.0
- 0.218
- 0.224
- 0.215
- 0.233
- 0.327
- 0.263
- 0.289
- 0.252
- 0.241
- 0.197
- 0.26
- 0.0
- 0.294
- 0.342
- 0.256
- 0.28
- 0.332
- 0.263
- 0.246
- 0.246
- 0.241
- 0.241
- 0.233
- 0.248
- 0.192
- 0.302
- 0.312
- 0.0
- 0.235
- 0.259
- 0.265
- 0.0
- 0.268
- 0.283
- 0.305
- 0.28
- 0.34
- 0.271
- 0.321
- 0.301
- 0.265
- 0.258
- 0.38
- 0.31
- 0.214
- 0.0
- 0.244
- 0.28
- 0.263
- 0.289
- 0.0
- 0.38
- 0.293
- 0.249
- 0.267
- 0.322
- 0.217
- 0.0
- 0.293
- 0.273
- 0.279
- 0.317
- 0.305
- 0.314
- 0.285
- 0.313
- 0.243
- 0.392
- 0.33
- 0.264
train_loss:
- 4.345
- 2.89
- 2.753
- 2.58
- 2.458
- 3.383
- 3.259
- 3.153
- 2.969
- 2.864
- 2.817
- 2.895
- 2.757
- 2.598
- 2.53
- 1.961
- 2.475
- 1.888
- 2.393
- 2.392
- 2.192
- 2.224
- 2.188
- 2.251
- 2.114
- 2.198
- 1.502
- 1.396
- 1.856
- 1.494
- 1.249
- 1.829
- 1.842
- 1.385
- 1.774
- 1.797
- 1.657
- 1.485
- 1.516
- 1.488
- 1.695
- 1.168
- 1.567
- 1.309
- 1.4
- 1.4
- 1.443
- 1.277
- 1.349
- 1.197
- 0.844
- 0.887
- 0.745
- 1.132
- 0.891
- 1.418
- 1.186
- 0.856
- 0.726
- 0.782
- 1.105
- 0.722
- 1.002
- 1.013
- 0.889
- 0.955
- 0.747
- 0.882
- 0.834
- 0.911
- 0.857
- 0.719
- 0.78
- 0.793
- 0.539
- 0.578
- 0.473
- 0.546
- 0.661
- 0.618
- 0.572
- 0.658
- 0.586
- 0.572
- 0.584
- 0.571
- 0.463
- 0.424
- 0.467
- 0.433
- 0.587
- 0.593
- 0.534
- 0.534
- 0.339
- 0.501
- 0.404
- 0.546
- 0.507
- 0.453
unequal: 0
verbose: 1
