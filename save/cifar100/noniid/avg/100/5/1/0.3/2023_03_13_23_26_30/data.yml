avg_train_accuracy: 0.299
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0233
- 0.0479
- 0.0764
- 0.1216
- 0.1391
- 0.1487
- 0.1629
- 0.1581
- 0.174
- 0.1798
- 0.1917
- 0.1968
- 0.2037
- 0.2055
- 0.2074
- 0.2128
- 0.223
- 0.221
- 0.2242
- 0.2335
- 0.2379
- 0.2387
- 0.2457
- 0.2516
- 0.2521
- 0.2425
- 0.2448
- 0.2556
- 0.2564
- 0.2578
- 0.2591
- 0.2635
- 0.2675
- 0.2646
- 0.257
- 0.2585
- 0.2649
- 0.2722
- 0.2727
- 0.2794
- 0.2798
- 0.2817
- 0.2848
- 0.285
- 0.2874
- 0.2878
- 0.2871
- 0.2866
- 0.2946
- 0.2898
- 0.2816
- 0.287
- 0.2982
- 0.2974
- 0.2985
- 0.2958
- 0.301
- 0.2994
- 0.3011
- 0.2985
- 0.3022
- 0.3019
- 0.302
- 0.304
- 0.3067
- 0.3076
- 0.3129
- 0.3025
- 0.3122
- 0.3056
- 0.3096
- 0.308
- 0.3107
- 0.3126
- 0.3085
- 0.2975
- 0.3059
- 0.3192
- 0.3132
- 0.3133
- 0.3202
- 0.3146
- 0.3146
- 0.32
- 0.3094
- 0.3198
- 0.32
- 0.3185
- 0.3169
- 0.3248
- 0.3196
- 0.3166
- 0.3238
- 0.3157
- 0.3197
- 0.3219
- 0.317
- 0.3191
- 0.3206
- 0.3259
test_loss_list:
- 1.831913824081421
- 1.7184796047210693
- 1.6571655917167663
- 1.5747676420211791
- 1.5420012283325195
- 1.4957894611358642
- 1.4762307476997376
- 1.4621778535842895
- 1.4451931023597717
- 1.4328154349327087
- 1.4211463284492494
- 1.4178477144241333
- 1.3750811743736266
- 1.372659947872162
- 1.3673283505439757
- 1.3621320176124572
- 1.3274150443077088
- 1.3370750212669373
- 1.3375419211387634
- 1.3251958107948303
- 1.3277075862884522
- 1.324438772201538
- 1.3122756361961365
- 1.3079520106315612
- 1.2660792231559754
- 1.277998170852661
- 1.2741353273391725
- 1.2667496252059935
- 1.275107650756836
- 1.2520028471946716
- 1.2568716502189636
- 1.2638300442695618
- 1.2649698734283448
- 1.2426911473274231
- 1.2519806718826294
- 1.2465458846092223
- 1.2361395835876465
- 1.2321102333068847
- 1.2361138248443604
- 1.2375553345680237
- 1.240388252735138
- 1.206163158416748
- 1.2083200669288636
- 1.2218588614463806
- 1.221274003982544
- 1.2287466883659364
- 1.2309156560897827
- 1.1945377922058105
- 1.1967662167549133
- 1.1948132419586182
- 1.2051227879524231
- 1.1987122678756714
- 1.1864125418663025
- 1.1991876077651977
- 1.1972173619270325
- 1.2098075008392335
- 1.2098379349708557
- 1.2143739151954651
- 1.2091787981987
- 1.2241490054130555
- 1.209848279953003
- 1.2195973658561707
- 1.220115964412689
- 1.2162422013282777
- 1.2180724239349365
- 1.2191939902305604
- 1.1644027519226074
- 1.1802595782279968
- 1.1769114351272583
- 1.192342975139618
- 1.1975871849060058
- 1.2022069239616393
- 1.1936414575576781
- 1.194892361164093
- 1.1715065765380859
- 1.2010621404647828
- 1.184678077697754
- 1.1662344145774841
- 1.185154914855957
- 1.1704356455802918
- 1.1688058304786682
- 1.183685028553009
- 1.1769774413108827
- 1.1637211561203002
- 1.1770970916748047
- 1.163181276321411
- 1.1763101029396057
- 1.1828496694564818
- 1.1665698552131654
- 1.1679286718368531
- 1.1735959219932557
- 1.1786600136756897
- 1.1723386502265931
- 1.185309853553772
- 1.1724147415161132
- 1.176198742389679
- 1.183099272251129
- 1.185330936908722
- 1.1960444712638856
- 1.2010641980171204
train_accuracy:
- 0.0
- 0.014
- 0.023
- 0.13
- 0.102
- 0.089
- 0.161
- 0.0
- 0.142
- 0.168
- 0.158
- 0.214
- 0.0
- 0.19
- 0.234
- 0.196
- 0.146
- 0.183
- 0.187
- 0.246
- 0.199
- 0.211
- 0.183
- 0.24
- 0.0
- 0.159
- 0.0
- 0.217
- 0.22
- 0.0
- 0.207
- 0.218
- 0.239
- 0.217
- 0.0
- 0.0
- 0.179
- 0.271
- 0.257
- 0.232
- 0.269
- 0.272
- 0.242
- 0.227
- 0.27
- 0.257
- 0.268
- 0.229
- 0.29
- 0.239
- 0.253
- 0.226
- 0.25
- 0.304
- 0.283
- 0.285
- 0.251
- 0.296
- 0.275
- 0.304
- 0.257
- 0.26
- 0.255
- 0.288
- 0.29
- 0.304
- 0.257
- 0.0
- 0.313
- 0.314
- 0.309
- 0.326
- 0.303
- 0.258
- 0.252
- 0.239
- 0.256
- 0.271
- 0.287
- 0.295
- 0.301
- 0.319
- 0.248
- 0.295
- 0.27
- 0.335
- 0.311
- 0.325
- 0.252
- 0.305
- 0.269
- 0.291
- 0.327
- 0.264
- 0.32
- 0.33
- 0.308
- 0.335
- 0.324
- 0.299
train_loss:
- 3.232
- 2.881
- 2.709
- 3.611
- 3.415
- 2.489
- 3.249
- 2.255
- 2.993
- 2.971
- 2.914
- 2.694
- 2.086
- 2.706
- 2.71
- 2.573
- 1.843
- 2.38
- 2.284
- 2.428
- 2.337
- 2.322
- 2.17
- 2.116
- 1.611
- 1.588
- 1.441
- 1.999
- 1.882
- 1.443
- 1.794
- 1.811
- 1.765
- 1.153
- 1.273
- 1.29
- 1.169
- 1.568
- 1.628
- 1.492
- 1.684
- 1.287
- 1.507
- 1.468
- 1.425
- 1.334
- 1.409
- 0.993
- 1.393
- 1.004
- 0.905
- 0.956
- 1.227
- 1.158
- 1.134
- 1.062
- 1.076
- 0.98
- 0.958
- 1.049
- 0.929
- 0.847
- 0.823
- 1.072
- 0.868
- 0.995
- 0.631
- 0.661
- 0.729
- 0.818
- 0.661
- 0.619
- 0.909
- 0.889
- 0.722
- 0.59
- 0.609
- 0.706
- 0.648
- 0.498
- 0.668
- 0.626
- 0.428
- 0.62
- 0.404
- 0.592
- 0.497
- 0.517
- 0.448
- 0.645
- 0.553
- 0.381
- 0.41
- 0.337
- 0.43
- 0.594
- 0.412
- 0.41
- 0.391
- 0.385
unequal: 0
verbose: 1
