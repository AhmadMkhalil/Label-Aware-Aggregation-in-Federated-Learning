avg_train_accuracy: 0.326
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0278
- 0.0968
- 0.1209
- 0.1252
- 0.1199
- 0.1311
- 0.1398
- 0.1674
- 0.1809
- 0.1891
- 0.1873
- 0.1946
- 0.2045
- 0.2097
- 0.2103
- 0.2157
- 0.221
- 0.2219
- 0.2174
- 0.2325
- 0.2379
- 0.2401
- 0.2445
- 0.2424
- 0.2508
- 0.2453
- 0.2533
- 0.2559
- 0.2578
- 0.2646
- 0.2596
- 0.2624
- 0.2695
- 0.2682
- 0.2659
- 0.2656
- 0.269
- 0.2767
- 0.2713
- 0.2806
- 0.2764
- 0.2814
- 0.2859
- 0.2741
- 0.2732
- 0.2746
- 0.2882
- 0.2863
- 0.2811
- 0.2856
- 0.2966
- 0.2941
- 0.2942
- 0.2929
- 0.2968
- 0.2984
- 0.3012
- 0.2965
- 0.2988
- 0.2972
- 0.3035
- 0.3036
- 0.3071
- 0.3074
- 0.3062
- 0.304
- 0.3078
- 0.305
- 0.3106
- 0.307
- 0.307
- 0.3105
- 0.312
- 0.3131
- 0.312
- 0.3108
- 0.3118
- 0.3046
- 0.31
- 0.3073
- 0.3153
- 0.3074
- 0.3151
- 0.3166
- 0.3138
- 0.3129
- 0.3135
- 0.3161
- 0.3131
- 0.3204
- 0.3184
- 0.3178
- 0.3203
- 0.3155
- 0.3203
- 0.3186
- 0.3202
- 0.3211
- 0.3224
- 0.3231
test_loss_list:
- 1.8151945447921753
- 1.6568399691581726
- 1.6081656670570375
- 1.5533749556541443
- 1.547630832195282
- 1.5218481731414795
- 1.4985870480537415
- 1.4708805942535401
- 1.4592278122901916
- 1.4480608439445495
- 1.4220289087295532
- 1.4087086009979248
- 1.3986429834365846
- 1.3947418308258057
- 1.3664600133895874
- 1.3661681532859802
- 1.3623081851005554
- 1.3487435603141784
- 1.345177586078644
- 1.3246107959747315
- 1.32568199634552
- 1.3300213313102722
- 1.317910566329956
- 1.3256046390533447
- 1.2886872124671935
- 1.2970677137374877
- 1.2819640994071961
- 1.288954017162323
- 1.2922989106178284
- 1.281872396469116
- 1.2971514916419984
- 1.282588040828705
- 1.2789331030845643
- 1.2816281819343567
- 1.286543996334076
- 1.2871779298782349
- 1.239277756214142
- 1.2407907772064208
- 1.2546449208259582
- 1.241550896167755
- 1.2581905579566957
- 1.250470938682556
- 1.2096273016929626
- 1.2292827486991882
- 1.2349186491966249
- 1.2317849326133727
- 1.2137913250923156
- 1.2050224709510804
- 1.216258943080902
- 1.2109942388534547
- 1.200571916103363
- 1.2102726888656616
- 1.2012241888046264
- 1.2040437579154968
- 1.2071224904060365
- 1.2096350026130676
- 1.2151473045349122
- 1.2251438617706298
- 1.2200031089782715
- 1.2256873559951782
- 1.219927077293396
- 1.1785325026512146
- 1.1876979565620422
- 1.1977812242507935
- 1.205495593547821
- 1.1751222586631775
- 1.193579614162445
- 1.2001017236709595
- 1.198733501434326
- 1.2038336777687073
- 1.2085790920257569
- 1.1961884903907776
- 1.2086413407325745
- 1.2143969869613647
- 1.1701077222824097
- 1.1813696479797364
- 1.1945799708366394
- 1.2100923085212707
- 1.178035020828247
- 1.1830456900596618
- 1.1758866119384765
- 1.1859391021728516
- 1.183706395626068
- 1.1874352145195006
- 1.1995480847358704
- 1.2081731867790222
- 1.1695957565307618
- 1.1808629608154297
- 1.196188359260559
- 1.178262186050415
- 1.184376561641693
- 1.1956085133552552
- 1.1920776963233948
- 1.1897833919525147
- 1.187722134590149
- 1.196608669757843
- 1.2041892051696776
- 1.1979609775543212
- 1.2062037420272826
- 1.2043907451629638
train_accuracy:
- 0.002
- 0.114
- 0.118
- 0.0
- 0.0
- 0.086
- 0.094
- 0.18
- 0.151
- 0.169
- 0.12
- 0.176
- 0.216
- 0.219
- 0.198
- 0.195
- 0.182
- 0.154
- 0.0
- 0.21
- 0.218
- 0.208
- 0.244
- 0.242
- 0.222
- 0.176
- 0.251
- 0.261
- 0.224
- 0.244
- 0.225
- 0.262
- 0.266
- 0.278
- 0.287
- 0.299
- 0.264
- 0.3
- 0.285
- 0.267
- 0.272
- 0.261
- 0.259
- 0.233
- 0.0
- 0.239
- 0.299
- 0.26
- 0.245
- 0.0
- 0.285
- 0.313
- 0.244
- 0.319
- 0.297
- 0.337
- 0.293
- 0.293
- 0.274
- 0.312
- 0.311
- 0.269
- 0.283
- 0.277
- 0.287
- 0.0
- 0.317
- 0.311
- 0.31
- 0.311
- 0.321
- 0.311
- 0.29
- 0.325
- 0.303
- 0.347
- 0.319
- 0.319
- 0.308
- 0.271
- 0.331
- 0.315
- 0.328
- 0.334
- 0.352
- 0.33
- 0.285
- 0.288
- 0.338
- 0.294
- 0.346
- 0.32
- 0.321
- 0.297
- 0.338
- 0.322
- 0.357
- 0.328
- 0.331
- 0.326
train_loss:
- 3.155
- 3.837
- 3.589
- 2.635
- 2.467
- 2.358
- 2.275
- 3.076
- 3.057
- 2.854
- 2.003
- 2.895
- 2.723
- 2.616
- 1.961
- 2.51
- 2.532
- 1.762
- 1.741
- 2.469
- 2.379
- 2.18
- 2.258
- 2.052
- 1.501
- 1.475
- 2.128
- 1.904
- 1.882
- 1.981
- 1.845
- 1.855
- 1.738
- 1.772
- 1.594
- 1.634
- 1.239
- 1.582
- 1.553
- 1.591
- 1.373
- 1.48
- 1.169
- 1.025
- 0.899
- 0.977
- 1.371
- 1.129
- 0.948
- 0.968
- 1.264
- 1.228
- 0.849
- 1.205
- 1.086
- 1.061
- 1.084
- 1.051
- 1.077
- 0.946
- 1.013
- 0.711
- 1.062
- 0.847
- 0.848
- 0.75
- 0.823
- 0.811
- 0.921
- 0.82
- 0.781
- 0.856
- 0.696
- 0.66
- 0.679
- 0.69
- 0.774
- 0.698
- 0.521
- 0.576
- 0.621
- 0.558
- 0.657
- 0.579
- 0.519
- 0.591
- 0.511
- 0.547
- 0.47
- 0.459
- 0.555
- 0.436
- 0.509
- 0.397
- 0.46
- 0.466
- 0.495
- 0.456
- 0.409
- 0.506
unequal: 0
verbose: 1
