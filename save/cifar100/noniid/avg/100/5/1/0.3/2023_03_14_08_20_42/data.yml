avg_train_accuracy: 0.279
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0227
- 0.1035
- 0.0949
- 0.1311
- 0.1308
- 0.1279
- 0.1698
- 0.1664
- 0.1719
- 0.187
- 0.1788
- 0.1953
- 0.1994
- 0.2021
- 0.2117
- 0.2159
- 0.2159
- 0.2219
- 0.2261
- 0.2332
- 0.2335
- 0.2256
- 0.2357
- 0.2285
- 0.2303
- 0.2537
- 0.2489
- 0.2511
- 0.2463
- 0.2558
- 0.2525
- 0.2573
- 0.2644
- 0.2693
- 0.2691
- 0.2713
- 0.2699
- 0.2762
- 0.2704
- 0.2809
- 0.2799
- 0.2824
- 0.2694
- 0.2736
- 0.2925
- 0.2899
- 0.2885
- 0.2873
- 0.2961
- 0.2974
- 0.2927
- 0.2897
- 0.2931
- 0.3024
- 0.2999
- 0.2977
- 0.2994
- 0.3049
- 0.2974
- 0.301
- 0.3057
- 0.3008
- 0.2975
- 0.3066
- 0.3068
- 0.3047
- 0.305
- 0.3041
- 0.3027
- 0.3033
- 0.3074
- 0.3034
- 0.3032
- 0.3101
- 0.316
- 0.3179
- 0.3167
- 0.3116
- 0.3145
- 0.3155
- 0.3181
- 0.3196
- 0.3218
- 0.3215
- 0.3226
- 0.3223
- 0.3142
- 0.312
- 0.3191
- 0.3171
- 0.3221
- 0.3224
- 0.323
- 0.3227
- 0.3138
- 0.3205
- 0.3245
- 0.3175
- 0.3284
- 0.3203
test_loss_list:
- 1.8269301462173462
- 1.660354552268982
- 1.6188182640075683
- 1.5648192954063416
- 1.535379137992859
- 1.5219441604614259
- 1.4787672901153563
- 1.4703858304023742
- 1.4365993165969848
- 1.4258458518981934
- 1.4201921439170837
- 1.4033650183677673
- 1.4046846890449525
- 1.3815555882453918
- 1.3634615516662598
- 1.3670210671424865
- 1.3656519079208373
- 1.360502805709839
- 1.323308756351471
- 1.3226159977912904
- 1.3103299260139465
- 1.3238098120689392
- 1.3085067057609558
- 1.3153627514839172
- 1.3061357831954956
- 1.2812045621871948
- 1.287803156375885
- 1.2737431240081787
- 1.2797650003433227
- 1.2626260018348694
- 1.2652415776252746
- 1.2628329634666442
- 1.2639800214767456
- 1.2642289566993714
- 1.265804431438446
- 1.2650021862983705
- 1.2702440762519835
- 1.2682900023460388
- 1.2715771365165711
- 1.263255126476288
- 1.2547510766983032
- 1.212303855419159
- 1.2327508449554443
- 1.230543670654297
- 1.2056667375564576
- 1.2190952897071838
- 1.1988322949409485
- 1.2098749828338624
- 1.2062023282051086
- 1.2088571095466614
- 1.2181447649002075
- 1.2231308674812318
- 1.2251602125167846
- 1.218470230102539
- 1.2229190039634705
- 1.226095163822174
- 1.2281188917160035
- 1.1715371799468994
- 1.1907241654396057
- 1.1887324094772338
- 1.1912622117996217
- 1.187726378440857
- 1.1833196687698364
- 1.182358148097992
- 1.1906857204437256
- 1.1743221926689147
- 1.1877574300765992
- 1.196143352985382
- 1.1982261323928833
- 1.2200579524040223
- 1.181073136329651
- 1.1886375451087952
- 1.190310914516449
- 1.1809725546836853
- 1.1766163110733032
- 1.183760826587677
- 1.1649108695983887
- 1.1738489389419555
- 1.1836245322227479
- 1.1844599890708922
- 1.1656203889846801
- 1.1671658873558044
- 1.1830514764785767
- 1.1830959582328797
- 1.1869861483573914
- 1.1648219156265258
- 1.181845908164978
- 1.1776698184013368
- 1.1766760563850402
- 1.1785736966133118
- 1.179604890346527
- 1.177378273010254
- 1.1820347356796264
- 1.165856840610504
- 1.1922782802581786
- 1.1785886430740355
- 1.1806849288940429
- 1.1866974878311156
- 1.1691612362861634
- 1.1864526295661926
train_accuracy:
- 0.0
- 0.084
- 0.055
- 0.116
- 0.0
- 0.104
- 0.16
- 0.164
- 0.137
- 0.187
- 0.164
- 0.194
- 0.167
- 0.0
- 0.22
- 0.15
- 0.197
- 0.204
- 0.0
- 0.228
- 0.172
- 0.0
- 0.221
- 0.222
- 0.186
- 0.243
- 0.243
- 0.165
- 0.2
- 0.262
- 0.204
- 0.275
- 0.266
- 0.246
- 0.253
- 0.248
- 0.264
- 0.242
- 0.249
- 0.289
- 0.271
- 0.214
- 0.175
- 0.225
- 0.29
- 0.246
- 0.273
- 0.296
- 0.289
- 0.268
- 0.292
- 0.279
- 0.321
- 0.314
- 0.294
- 0.296
- 0.302
- 0.0
- 0.0
- 0.308
- 0.279
- 0.267
- 0.255
- 0.268
- 0.312
- 0.0
- 0.299
- 0.303
- 0.268
- 0.28
- 0.28
- 0.258
- 0.231
- 0.294
- 0.322
- 0.268
- 0.0
- 0.32
- 0.32
- 0.271
- 0.271
- 0.314
- 0.318
- 0.32
- 0.29
- 0.0
- 0.338
- 0.272
- 0.295
- 0.287
- 0.284
- 0.267
- 0.319
- 0.315
- 0.0
- 0.304
- 0.331
- 0.241
- 0.306
- 0.279
train_loss:
- 3.238
- 3.931
- 2.69
- 3.473
- 2.528
- 2.413
- 3.239
- 3.052
- 2.299
- 2.885
- 2.021
- 2.691
- 2.699
- 1.979
- 2.694
- 2.472
- 2.359
- 2.398
- 1.679
- 2.245
- 1.81
- 1.578
- 2.164
- 1.411
- 1.548
- 2.181
- 2.096
- 1.505
- 1.468
- 1.953
- 1.265
- 2.0
- 1.847
- 1.711
- 1.703
- 1.644
- 1.556
- 1.535
- 1.463
- 1.569
- 1.6
- 1.137
- 1.096
- 0.97
- 1.591
- 1.323
- 0.997
- 1.201
- 1.379
- 1.287
- 1.239
- 1.125
- 1.091
- 1.128
- 1.111
- 0.976
- 0.942
- 0.976
- 0.722
- 1.082
- 0.981
- 0.625
- 0.716
- 0.881
- 0.98
- 0.671
- 0.73
- 0.84
- 0.95
- 0.726
- 0.591
- 0.585
- 0.504
- 0.753
- 0.841
- 0.786
- 0.733
- 0.695
- 0.869
- 0.742
- 0.598
- 0.718
- 0.652
- 0.596
- 0.691
- 0.483
- 0.573
- 0.419
- 0.548
- 0.403
- 0.59
- 0.562
- 0.481
- 0.444
- 0.329
- 0.46
- 0.607
- 0.392
- 0.541
- 0.485
unequal: 0
verbose: 1
