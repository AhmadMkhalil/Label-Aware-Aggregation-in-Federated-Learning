avg_train_accuracy: 0.293
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0279
- 0.0559
- 0.074
- 0.1242
- 0.1298
- 0.1499
- 0.1571
- 0.1645
- 0.1516
- 0.1828
- 0.1948
- 0.1991
- 0.2045
- 0.2046
- 0.2128
- 0.2205
- 0.2247
- 0.2236
- 0.2303
- 0.2396
- 0.24
- 0.2467
- 0.246
- 0.2503
- 0.2506
- 0.2508
- 0.2515
- 0.2566
- 0.2584
- 0.2596
- 0.2528
- 0.2606
- 0.2572
- 0.2682
- 0.2697
- 0.2717
- 0.2726
- 0.2699
- 0.2634
- 0.2712
- 0.2843
- 0.2787
- 0.2803
- 0.2875
- 0.2843
- 0.286
- 0.2862
- 0.2883
- 0.2836
- 0.2905
- 0.2932
- 0.2989
- 0.2981
- 0.2971
- 0.2995
- 0.2999
- 0.2997
- 0.3005
- 0.3024
- 0.2981
- 0.2971
- 0.3001
- 0.3066
- 0.3052
- 0.3089
- 0.3104
- 0.3089
- 0.3151
- 0.3018
- 0.3082
- 0.3104
- 0.3096
- 0.3129
- 0.3125
- 0.3125
- 0.3166
- 0.3156
- 0.3205
- 0.3189
- 0.3142
- 0.316
- 0.3099
- 0.3169
- 0.3169
- 0.3164
- 0.3205
- 0.3088
- 0.3199
- 0.3214
- 0.3196
- 0.3205
- 0.3242
- 0.3163
- 0.3276
- 0.3176
- 0.3216
- 0.3237
- 0.3275
- 0.3253
- 0.3266
test_loss_list:
- 1.828751940727234
- 1.7210774850845336
- 1.6604257249832153
- 1.5836212277412414
- 1.5561762952804565
- 1.516179096698761
- 1.5035422921180726
- 1.4729099345207215
- 1.4706671047210693
- 1.4372308373451232
- 1.4246683406829834
- 1.4149993968009948
- 1.3839208960533143
- 1.3801850509643554
- 1.3742091941833496
- 1.3711029052734376
- 1.366364061832428
- 1.3661341214179992
- 1.325942144393921
- 1.317291145324707
- 1.3203104829788208
- 1.3212311601638793
- 1.3171953916549684
- 1.2820086836814881
- 1.2869728636741637
- 1.289280710220337
- 1.2694196820259094
- 1.2734838581085206
- 1.2805142188072205
- 1.2566712880134583
- 1.2769672966003418
- 1.2641742753982543
- 1.2702817964553832
- 1.2472824954986572
- 1.2566804790496826
- 1.239347553253174
- 1.2478122806549072
- 1.244559772014618
- 1.2574721908569335
- 1.2487723207473755
- 1.2242534852027893
- 1.222511489391327
- 1.2194044780731201
- 1.2147124814987182
- 1.2231964874267578
- 1.225590741634369
- 1.2026620101928711
- 1.2038618993759156
- 1.2095038104057312
- 1.2056284499168397
- 1.2093062925338744
- 1.1985467791557312
- 1.2043911147117614
- 1.2127705669403077
- 1.2152976036071776
- 1.2087281227111817
- 1.2147954964637757
- 1.2200293731689453
- 1.17579612493515
- 1.1877955627441406
- 1.193125774860382
- 1.1775375771522523
- 1.1756387543678284
- 1.1751111125946045
- 1.1725123190879823
- 1.179730942249298
- 1.179501028060913
- 1.161565089225769
- 1.1817821383476257
- 1.1679866647720336
- 1.177225613594055
- 1.1693144965171813
- 1.1699441409111022
- 1.1673850560188292
- 1.1594941306114197
- 1.1616612625122071
- 1.1689959025382997
- 1.165358967781067
- 1.169170331954956
- 1.1772846388816833
- 1.171149640083313
- 1.1900299501419067
- 1.1700853300094605
- 1.1672665405273437
- 1.1784971737861634
- 1.1726376271247865
- 1.1885545611381532
- 1.1724743819236756
- 1.1687885427474975
- 1.1757428669929504
- 1.1768428659439087
- 1.154883987903595
- 1.1709917306900024
- 1.1550429439544678
- 1.1748243832588197
- 1.1669227004051208
- 1.1743050837516784
- 1.1789007520675658
- 1.172199330329895
- 1.1827219367027282
train_accuracy:
- 0.005
- 0.027
- 0.037
- 0.109
- 0.121
- 0.152
- 0.151
- 0.109
- 0.134
- 0.161
- 0.171
- 0.135
- 0.0
- 0.176
- 0.241
- 0.152
- 0.198
- 0.177
- 0.0
- 0.176
- 0.24
- 0.197
- 0.192
- 0.0
- 0.181
- 0.268
- 0.0
- 0.227
- 0.24
- 0.0
- 0.0
- 0.0
- 0.207
- 0.219
- 0.245
- 0.0
- 0.222
- 0.0
- 0.0
- 0.0
- 0.31
- 0.0
- 0.235
- 0.233
- 0.239
- 0.275
- 0.247
- 0.268
- 0.0
- 0.28
- 0.235
- 0.346
- 0.239
- 0.298
- 0.274
- 0.246
- 0.303
- 0.298
- 0.273
- 0.275
- 0.257
- 0.232
- 0.251
- 0.22
- 0.291
- 0.259
- 0.336
- 0.0
- 0.325
- 0.328
- 0.275
- 0.0
- 0.291
- 0.248
- 0.29
- 0.329
- 0.358
- 0.292
- 0.321
- 0.0
- 0.324
- 0.297
- 0.237
- 0.297
- 0.304
- 0.0
- 0.27
- 0.317
- 0.342
- 0.364
- 0.334
- 0.34
- 0.0
- 0.312
- 0.288
- 0.327
- 0.336
- 0.326
- 0.27
- 0.293
train_loss:
- 3.242
- 2.879
- 2.723
- 3.581
- 2.519
- 3.393
- 3.135
- 2.287
- 2.282
- 2.948
- 2.962
- 2.801
- 2.048
- 2.722
- 2.648
- 2.51
- 2.419
- 2.313
- 1.804
- 2.34
- 2.359
- 2.315
- 2.238
- 1.609
- 2.017
- 2.025
- 1.444
- 1.953
- 1.953
- 1.39
- 1.221
- 1.395
- 1.196
- 1.816
- 1.597
- 1.196
- 1.48
- 1.079
- 1.073
- 1.194
- 1.622
- 1.338
- 1.099
- 1.332
- 1.625
- 1.387
- 1.112
- 1.288
- 0.892
- 1.516
- 1.347
- 1.473
- 1.208
- 1.121
- 1.17
- 1.184
- 1.101
- 0.993
- 0.773
- 0.805
- 0.724
- 0.953
- 1.097
- 0.697
- 0.983
- 1.007
- 0.908
- 0.701
- 0.687
- 0.922
- 0.858
- 0.606
- 0.799
- 0.893
- 0.75
- 0.838
- 0.785
- 0.522
- 0.692
- 0.509
- 0.595
- 0.572
- 0.6
- 0.632
- 0.574
- 0.449
- 0.433
- 0.576
- 0.745
- 0.558
- 0.669
- 0.467
- 0.468
- 0.469
- 0.355
- 0.598
- 0.544
- 0.511
- 0.593
- 0.444
unequal: 0
verbose: 1
