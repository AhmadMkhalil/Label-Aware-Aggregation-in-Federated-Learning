avg_train_accuracy: 0.309
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0436
- 0.0948
- 0.1105
- 0.1333
- 0.1189
- 0.1487
- 0.1588
- 0.1684
- 0.1828
- 0.1825
- 0.1937
- 0.1981
- 0.1998
- 0.205
- 0.2217
- 0.2172
- 0.217
- 0.2293
- 0.233
- 0.2333
- 0.2324
- 0.2376
- 0.2455
- 0.2491
- 0.2547
- 0.2527
- 0.2571
- 0.2573
- 0.2615
- 0.2635
- 0.2656
- 0.2611
- 0.2706
- 0.275
- 0.2788
- 0.2781
- 0.284
- 0.2817
- 0.2802
- 0.2757
- 0.2865
- 0.279
- 0.2934
- 0.2909
- 0.2837
- 0.2971
- 0.2948
- 0.2954
- 0.2951
- 0.3008
- 0.3004
- 0.3035
- 0.2997
- 0.3021
- 0.3002
- 0.2986
- 0.304
- 0.3057
- 0.3075
- 0.3052
- 0.3102
- 0.3097
- 0.3162
- 0.2946
- 0.2976
- 0.3003
- 0.313
- 0.3097
- 0.3127
- 0.3149
- 0.3109
- 0.3162
- 0.306
- 0.321
- 0.3133
- 0.3116
- 0.3241
- 0.3096
- 0.3141
- 0.3171
- 0.3219
- 0.3204
- 0.3236
- 0.3235
- 0.3265
- 0.3195
- 0.3237
- 0.3255
- 0.3271
- 0.3237
- 0.3153
- 0.321
- 0.3286
- 0.3231
- 0.3135
- 0.3112
- 0.3142
- 0.3298
- 0.3225
- 0.3124
test_loss_list:
- 1.7919649505615234
- 1.6688329124450683
- 1.6193896889686585
- 1.544750473499298
- 1.5502762222290039
- 1.506375663280487
- 1.4940240263938904
- 1.4769477033615113
- 1.4596389412879944
- 1.4307280111312866
- 1.416495246887207
- 1.409270327091217
- 1.4096722054481505
- 1.3978664231300355
- 1.3515922260284423
- 1.3588923621177673
- 1.3528868579864501
- 1.33623211145401
- 1.3406784987449647
- 1.3424517869949342
- 1.33724351644516
- 1.2978032851219177
- 1.2976845407485962
- 1.301322910785675
- 1.3038110947608947
- 1.269931480884552
- 1.2683391761779785
- 1.2803283953666686
- 1.2539867234230042
- 1.2572476434707642
- 1.2653529357910156
- 1.268902497291565
- 1.261727330684662
- 1.2570910501480101
- 1.2554665946960448
- 1.2531457757949829
- 1.2511965441703796
- 1.214908275604248
- 1.22529061794281
- 1.223515305519104
- 1.2083399105072021
- 1.2188996815681457
- 1.2016719126701354
- 1.2129415249824524
- 1.203749041557312
- 1.1959953165054322
- 1.2007919692993163
- 1.20818505525589
- 1.2131370496749878
- 1.209829761981964
- 1.1806314373016358
- 1.183711540699005
- 1.2024414038658142
- 1.200598406791687
- 1.2114902830123901
- 1.1830871057510377
- 1.1795714092254639
- 1.1756395435333251
- 1.1784906435012816
- 1.1873947834968568
- 1.1883190751075745
- 1.1918309903144837
- 1.1591435146331788
- 1.1961886262893677
- 1.1907188892364502
- 1.190089566707611
- 1.1697522354125978
- 1.179360191822052
- 1.191759295463562
- 1.1609820437431335
- 1.1725170278549195
- 1.1673090934753418
- 1.1820964193344117
- 1.161557159423828
- 1.1679193592071533
- 1.168604600429535
- 1.1596230149269104
- 1.1730744409561158
- 1.1734551477432251
- 1.1697397804260254
- 1.1614737105369568
- 1.1680442214012146
- 1.1717643022537232
- 1.1726809763908386
- 1.1745414423942566
- 1.164374542236328
- 1.167062952518463
- 1.1822886872291565
- 1.179468355178833
- 1.1602674698829651
- 1.1776282477378845
- 1.1805218863487243
- 1.1621870732307433
- 1.1775428795814513
- 1.198719711303711
- 1.1998352456092833
- 1.1977701234817504
- 1.165793743133545
- 1.1871603727340698
- 1.1984542036056518
train_accuracy:
- 0.052
- 0.092
- 0.067
- 0.0
- 0.087
- 0.164
- 0.166
- 0.214
- 0.196
- 0.145
- 0.202
- 0.226
- 0.214
- 0.214
- 0.0
- 0.178
- 0.0
- 0.195
- 0.189
- 0.185
- 0.261
- 0.0
- 0.161
- 0.245
- 0.24
- 0.232
- 0.285
- 0.245
- 0.178
- 0.261
- 0.264
- 0.221
- 0.219
- 0.196
- 0.258
- 0.198
- 0.204
- 0.265
- 0.254
- 0.251
- 0.236
- 0.0
- 0.244
- 0.293
- 0.255
- 0.328
- 0.253
- 0.315
- 0.252
- 0.242
- 0.0
- 0.298
- 0.268
- 0.261
- 0.285
- 0.289
- 0.299
- 0.314
- 0.279
- 0.299
- 0.269
- 0.263
- 0.0
- 0.294
- 0.0
- 0.283
- 0.302
- 0.221
- 0.293
- 0.304
- 0.32
- 0.337
- 0.0
- 0.326
- 0.268
- 0.275
- 0.281
- 0.3
- 0.348
- 0.297
- 0.308
- 0.298
- 0.278
- 0.343
- 0.349
- 0.306
- 0.353
- 0.354
- 0.28
- 0.212
- 0.309
- 0.32
- 0.334
- 0.324
- 0.29
- 0.309
- 0.0
- 0.319
- 0.0
- 0.309
train_loss:
- 4.313
- 3.866
- 3.599
- 2.685
- 2.429
- 3.274
- 3.158
- 3.137
- 2.976
- 2.154
- 2.868
- 2.753
- 2.62
- 2.637
- 2.002
- 2.46
- 1.785
- 2.395
- 2.191
- 2.153
- 2.311
- 1.639
- 2.34
- 2.007
- 2.051
- 1.511
- 2.016
- 1.805
- 1.659
- 1.784
- 1.713
- 1.662
- 1.614
- 1.91
- 1.66
- 1.708
- 1.791
- 1.223
- 1.482
- 1.092
- 1.555
- 1.11
- 1.506
- 1.247
- 1.021
- 1.511
- 1.269
- 1.257
- 1.175
- 1.334
- 0.989
- 1.19
- 1.187
- 1.072
- 0.991
- 0.864
- 1.06
- 0.856
- 1.0
- 1.104
- 1.004
- 0.926
- 0.739
- 0.634
- 0.67
- 0.605
- 0.828
- 0.897
- 0.919
- 0.619
- 0.745
- 0.787
- 0.559
- 0.815
- 0.583
- 0.519
- 0.732
- 0.547
- 0.753
- 0.605
- 0.526
- 0.639
- 0.681
- 0.608
- 0.587
- 0.501
- 0.654
- 0.571
- 0.534
- 0.553
- 0.414
- 0.355
- 0.527
- 0.378
- 0.348
- 0.317
- 0.299
- 0.475
- 0.381
- 0.305
unequal: 0
verbose: 1
