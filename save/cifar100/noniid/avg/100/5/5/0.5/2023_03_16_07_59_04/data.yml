avg_train_accuracy: 0.326
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0214
- 0.0526
- 0.0514
- 0.0588
- 0.1091
- 0.1218
- 0.1283
- 0.1367
- 0.146
- 0.1503
- 0.1575
- 0.1629
- 0.1724
- 0.1756
- 0.1844
- 0.1887
- 0.1888
- 0.1894
- 0.1931
- 0.1928
- 0.2129
- 0.2086
- 0.2049
- 0.2054
- 0.204
- 0.2137
- 0.2203
- 0.2232
- 0.221
- 0.2224
- 0.2206
- 0.2314
- 0.2252
- 0.2292
- 0.2316
- 0.2224
- 0.2335
- 0.2478
- 0.2463
- 0.2467
- 0.239
- 0.2414
- 0.2428
- 0.2487
- 0.2464
- 0.2506
- 0.2545
- 0.2507
- 0.2496
- 0.2566
- 0.2585
- 0.2685
- 0.2633
- 0.2702
- 0.2648
- 0.2566
- 0.2638
- 0.2447
- 0.2643
- 0.2619
- 0.2675
- 0.2726
- 0.2724
- 0.2648
- 0.2687
- 0.2805
- 0.2747
- 0.2769
- 0.2772
- 0.2662
- 0.2664
- 0.2751
- 0.2816
- 0.2661
- 0.2845
- 0.2688
- 0.2798
- 0.2736
- 0.2748
- 0.2777
- 0.2854
- 0.2922
- 0.278
- 0.274
- 0.2825
- 0.2863
- 0.2857
- 0.2851
- 0.2841
- 0.2702
- 0.2753
- 0.2778
- 0.2837
- 0.2797
- 0.277
- 0.2959
- 0.2946
- 0.2852
- 0.2924
- 0.282
test_loss_list:
- 1.845526614189148
- 1.7736988162994385
- 1.734142370223999
- 1.723474726676941
- 1.6336226844787598
- 1.642414517402649
- 1.583687391281128
- 1.57101327419281
- 1.5579519033432008
- 1.531636996269226
- 1.5386294364929198
- 1.5257324934005738
- 1.4844084000587463
- 1.4808732295036315
- 1.4467075967788696
- 1.4533227205276489
- 1.4619420051574707
- 1.4458548402786255
- 1.4118103098869323
- 1.467136974334717
- 1.386772005558014
- 1.4038415145874024
- 1.411022264957428
- 1.4348153281211853
- 1.3875215458869934
- 1.388568069934845
- 1.3846684575080872
- 1.3957655692100526
- 1.3604267430305481
- 1.3855384635925292
- 1.4187277269363403
- 1.3951841187477112
- 1.435877878665924
- 1.377083384990692
- 1.3734599471092224
- 1.334997317790985
- 1.3224583053588868
- 1.306941704750061
- 1.31441956281662
- 1.3176517868041993
- 1.3150011205673218
- 1.3174642872810365
- 1.3517004990577697
- 1.321346070766449
- 1.315070128440857
- 1.2938383960723876
- 1.2957022833824157
- 1.3055701804161073
- 1.2992140889167785
- 1.3004137802124023
- 1.2993782687187194
- 1.2895447134971618
- 1.2910603642463685
- 1.282393789291382
- 1.2862057614326476
- 1.2897945380210876
- 1.2750380945205688
- 1.32122545003891
- 1.2895312571525575
- 1.2948245429992675
- 1.280629813671112
- 1.2830144023895265
- 1.2923598790168762
- 1.2845832896232605
- 1.2814216542243957
- 1.2561428380012511
- 1.2555991530418396
- 1.2690646076202392
- 1.2735739684104919
- 1.3077279567718505
- 1.3346543550491332
- 1.2947689604759216
- 1.2593131613731385
- 1.2769948840141296
- 1.2503932094573975
- 1.278096115589142
- 1.255211079120636
- 1.2751608347892762
- 1.2684334588050843
- 1.2537430620193482
- 1.2510122895240783
- 1.2443698596954347
- 1.2500823688507081
- 1.30147381067276
- 1.2729233932495116
- 1.2439244318008422
- 1.2698409533500672
- 1.2721239376068114
- 1.2904680681228637
- 1.3775001955032349
- 1.2987788438796997
- 1.2775594425201415
- 1.2809550952911377
- 1.284459433555603
- 1.2608447194099426
- 1.2402753973007201
- 1.2434968423843384
- 1.2493451285362243
- 1.2712200736999513
- 1.3162415933609009
train_accuracy:
- 0.033
- 0.04
- 0.0
- 0.075
- 0.145
- 0.137
- 0.166
- 0.001
- 0.006
- 0.164
- 0.189
- 0.0
- 0.185
- 0.0
- 0.0
- 0.107
- 0.185
- 0.161
- 0.2
- 0.029
- 0.028
- 0.106
- 0.0
- 0.258
- 0.169
- 0.245
- 0.02
- 0.238
- 0.0
- 0.226
- 0.258
- 0.264
- 0.062
- 0.241
- 0.206
- 0.368
- 0.0
- 0.251
- 0.216
- 0.272
- 0.0
- 0.138
- 0.306
- 0.23
- 0.0
- 0.26
- 0.258
- 0.0
- 0.011
- 0.135
- 0.044
- 0.27
- 0.0
- 0.0
- 0.0
- 0.0
- 0.255
- 0.305
- 0.209
- 0.281
- 0.14
- 0.249
- 0.0
- 0.0
- 0.291
- 0.249
- 0.174
- 0.293
- 0.0
- 0.296
- 0.318
- 0.0
- 0.0
- 0.233
- 0.244
- 0.0
- 0.28
- 0.253
- 0.264
- 0.0
- 0.276
- 0.264
- 0.291
- 0.312
- 0.268
- 0.289
- 0.275
- 0.315
- 0.2
- 0.319
- 0.289
- 0.279
- 0.0
- 0.289
- 0.232
- 0.307
- 0.0
- 0.0
- 0.0
- 0.326
train_loss:
- 2.956
- 2.142
- 1.482
- 1.355
- 2.527
- 2.753
- 1.816
- 2.176
- 2.039
- 1.531
- 1.905
- 1.92
- 1.547
- 1.896
- 1.419
- 1.358
- 1.38
- 1.411
- 1.305
- 2.073
- 0.924
- 1.178
- 1.553
- 1.514
- 0.899
- 1.515
- 1.409
- 1.401
- 1.12
- 1.404
- 1.635
- 1.335
- 1.532
- 1.001
- 0.99
- 0.695
- 0.919
- 0.902
- 0.843
- 1.14
- 0.599
- 0.804
- 1.327
- 0.798
- 0.832
- 0.996
- 0.754
- 0.955
- 0.934
- 0.954
- 0.889
- 0.67
- 0.883
- 0.667
- 0.616
- 0.471
- 0.63
- 0.435
- 0.6
- 0.788
- 0.632
- 0.548
- 0.752
- 0.751
- 0.706
- 0.569
- 0.555
- 0.688
- 0.514
- 0.813
- 0.774
- 0.605
- 0.468
- 0.387
- 0.47
- 0.299
- 0.555
- 0.43
- 0.427
- 0.447
- 0.534
- 0.423
- 0.536
- 0.645
- 0.43
- 0.522
- 0.452
- 0.474
- 0.442
- 0.62
- 0.47
- 0.278
- 0.42
- 0.323
- 0.29
- 0.423
- 0.323
- 0.406
- 0.377
- 0.431
unequal: 0
verbose: 1
