avg_train_accuracy: 0.32
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0234
- 0.0477
- 0.0683
- 0.0867
- 0.1126
- 0.1233
- 0.1384
- 0.1322
- 0.1477
- 0.1568
- 0.1651
- 0.167
- 0.1712
- 0.178
- 0.188
- 0.1763
- 0.1983
- 0.1912
- 0.1983
- 0.2052
- 0.2045
- 0.1958
- 0.1765
- 0.208
- 0.2215
- 0.2134
- 0.2079
- 0.22
- 0.2229
- 0.2211
- 0.2324
- 0.2301
- 0.2103
- 0.2344
- 0.2328
- 0.2414
- 0.2412
- 0.2432
- 0.2302
- 0.2365
- 0.2365
- 0.2506
- 0.2553
- 0.2561
- 0.2405
- 0.2502
- 0.2537
- 0.2481
- 0.2541
- 0.2501
- 0.2487
- 0.258
- 0.2578
- 0.2421
- 0.2532
- 0.2573
- 0.2586
- 0.2552
- 0.2519
- 0.2535
- 0.2583
- 0.2507
- 0.2576
- 0.2566
- 0.2626
- 0.2639
- 0.2673
- 0.2637
- 0.2602
- 0.2568
- 0.2602
- 0.2599
- 0.2762
- 0.2712
- 0.2555
- 0.272
- 0.2597
- 0.2651
- 0.271
- 0.2672
- 0.2664
- 0.2777
- 0.2647
- 0.2651
- 0.2684
- 0.2629
- 0.276
- 0.2722
- 0.2759
- 0.2742
- 0.2727
- 0.2784
- 0.2785
- 0.279
- 0.2795
- 0.2751
- 0.2737
- 0.2768
- 0.268
- 0.2836
test_loss_list:
- 1.871875638961792
- 1.7689746236801147
- 1.7291226935386659
- 1.6835371661186218
- 1.631919322013855
- 1.6088473582267762
- 1.6051802492141725
- 1.5700574374198915
- 1.559071831703186
- 1.5290704202651977
- 1.5333070015907289
- 1.55461354970932
- 1.5275623393058777
- 1.515336310863495
- 1.5164339351654053
- 1.4481327867507934
- 1.4235408592224121
- 1.446600387096405
- 1.4272100043296814
- 1.40861341714859
- 1.4228376936912537
- 1.4393506240844727
- 1.449041895866394
- 1.4109751033782958
- 1.374357988834381
- 1.3859323382377624
- 1.3858736777305602
- 1.369563729763031
- 1.3961824083328247
- 1.397974464893341
- 1.372923607826233
- 1.3955928683280945
- 1.406930387020111
- 1.3830859088897705
- 1.3307959365844726
- 1.3325506663322448
- 1.334507565498352
- 1.3321949458122253
- 1.3898309922218324
- 1.4122000122070313
- 1.3659576106071472
- 1.3324253582954406
- 1.309041028022766
- 1.3044509053230287
- 1.3689032149314881
- 1.3442344069480896
- 1.2989253091812134
- 1.324692702293396
- 1.3095618033409118
- 1.3144522714614868
- 1.320999391078949
- 1.3180400323867798
- 1.3165498924255372
- 1.3347296690940857
- 1.3214592599868775
- 1.3264172220230102
- 1.3496398115158081
- 1.3457493138313295
- 1.3835759329795838
- 1.3207596468925475
- 1.3129764294624329
- 1.4262220931053162
- 1.3601360130310058
- 1.3728963422775269
- 1.293452742099762
- 1.30323983669281
- 1.3034906697273254
- 1.3250449323654174
- 1.3076570868492126
- 1.3652721643447876
- 1.3790135741233827
- 1.3294453287124635
- 1.3264235997200011
- 1.3135867428779602
- 1.328066153526306
- 1.2935010957717896
- 1.3474054288864137
- 1.3149765563011169
- 1.3164209365844726
- 1.3350127482414245
- 1.3064874053001403
- 1.2888915920257569
- 1.3496749305725098
- 1.3168273615837096
- 1.335829474925995
- 1.372058024406433
- 1.2919004082679748
- 1.3024393367767333
- 1.3016727352142334
- 1.3144555830955504
- 1.321812024116516
- 1.3205545568466186
- 1.3282682704925537
- 1.305068507194519
- 1.2843355226516724
- 1.3148907208442688
- 1.3165290021896363
- 1.3037330508232117
- 1.3468305635452271
- 1.3100919222831726
train_accuracy:
- 0.0
- 0.0
- 0.038
- 0.007
- 0.014
- 0.129
- 0.147
- 0.165
- 0.0
- 0.0
- 0.205
- 0.213
- 0.0
- 0.243
- 0.211
- 0.009
- 0.059
- 0.264
- 0.0
- 0.0
- 0.216
- 0.0
- 0.0
- 0.199
- 0.207
- 0.0
- 0.219
- 0.269
- 0.268
- 0.0
- 0.26
- 0.273
- 0.0
- 0.0
- 0.303
- 0.093
- 0.251
- 0.0
- 0.294
- 0.318
- 0.315
- 0.0
- 0.0
- 0.0
- 0.293
- 0.0
- 0.0
- 0.0
- 0.316
- 0.0
- 0.0
- 0.0
- 0.285
- 0.0
- 0.253
- 0.31
- 0.311
- 0.0
- 0.317
- 0.325
- 0.326
- 0.329
- 0.334
- 0.317
- 0.038
- 0.259
- 0.0
- 0.299
- 0.328
- 0.359
- 0.321
- 0.0
- 0.0
- 0.307
- 0.193
- 0.329
- 0.323
- 0.0
- 0.0
- 0.0
- 0.34
- 0.301
- 0.35
- 0.088
- 0.0
- 0.092
- 0.0
- 0.364
- 0.314
- 0.334
- 0.0
- 0.0
- 0.0
- 0.0
- 0.28
- 0.0
- 0.329
- 0.355
- 0.373
- 0.32
train_loss:
- 2.265
- 2.176
- 1.983
- 1.97
- 2.402
- 1.794
- 2.192
- 1.618
- 1.605
- 2.015
- 1.894
- 2.312
- 1.823
- 1.787
- 1.712
- 1.056
- 1.331
- 1.62
- 1.22
- 1.291
- 1.588
- 0.822
- 0.852
- 1.097
- 1.127
- 1.403
- 0.782
- 1.427
- 1.318
- 1.329
- 1.002
- 1.218
- 0.682
- 1.221
- 0.941
- 0.957
- 0.902
- 0.878
- 1.42
- 1.298
- 1.121
- 0.825
- 0.829
- 0.753
- 1.186
- 0.734
- 0.789
- 0.503
- 0.951
- 0.508
- 0.666
- 0.837
- 0.633
- 0.453
- 0.65
- 0.793
- 0.749
- 0.818
- 0.896
- 0.636
- 0.812
- 1.03
- 0.681
- 0.689
- 0.46
- 0.526
- 0.678
- 0.642
- 0.68
- 0.748
- 0.712
- 0.597
- 0.414
- 0.476
- 0.347
- 0.563
- 0.626
- 0.505
- 0.398
- 0.469
- 0.544
- 0.43
- 0.565
- 0.49
- 0.442
- 0.551
- 0.371
- 0.444
- 0.419
- 0.404
- 0.364
- 0.299
- 0.397
- 0.363
- 0.338
- 0.292
- 0.381
- 0.341
- 0.432
- 0.283
unequal: 0
verbose: 1
