avg_train_accuracy: 0.281
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0224
- 0.0698
- 0.0954
- 0.1121
- 0.128
- 0.1329
- 0.1393
- 0.1442
- 0.1539
- 0.1673
- 0.1633
- 0.1712
- 0.1743
- 0.1766
- 0.1852
- 0.1973
- 0.1893
- 0.1952
- 0.1976
- 0.2027
- 0.2145
- 0.2087
- 0.2083
- 0.2142
- 0.2255
- 0.2286
- 0.2296
- 0.2329
- 0.2278
- 0.2294
- 0.2326
- 0.2364
- 0.2409
- 0.2435
- 0.2386
- 0.2398
- 0.2432
- 0.2413
- 0.2492
- 0.2521
- 0.2474
- 0.249
- 0.2523
- 0.2575
- 0.2494
- 0.2563
- 0.247
- 0.2454
- 0.2583
- 0.2647
- 0.2653
- 0.2652
- 0.26
- 0.2586
- 0.2596
- 0.2595
- 0.2623
- 0.2587
- 0.268
- 0.2618
- 0.2717
- 0.2725
- 0.2659
- 0.2746
- 0.2773
- 0.2702
- 0.2724
- 0.2662
- 0.2776
- 0.2725
- 0.2812
- 0.2829
- 0.2792
- 0.2755
- 0.2831
- 0.2831
- 0.275
- 0.2714
- 0.2727
- 0.2738
- 0.2755
- 0.2765
- 0.2776
- 0.2893
- 0.2827
- 0.2868
- 0.2809
- 0.2868
- 0.2836
- 0.286
- 0.2846
- 0.2731
- 0.2731
- 0.2822
- 0.2912
- 0.2898
- 0.2924
- 0.2893
- 0.2848
- 0.2846
test_loss_list:
- 1.86083571434021
- 1.7225515842437744
- 1.6676355576515198
- 1.639127917289734
- 1.5920321679115295
- 1.5776393365859986
- 1.5813296031951904
- 1.5334718704223633
- 1.5266640925407409
- 1.5043121981620788
- 1.5333222794532775
- 1.5049837946891784
- 1.4816628527641296
- 1.473034553527832
- 1.441922664642334
- 1.4335072684288024
- 1.4641013383865356
- 1.477567608356476
- 1.425740602016449
- 1.4223521041870117
- 1.3977351117134094
- 1.403932182788849
- 1.4399600219726563
- 1.4142028737068175
- 1.369247682094574
- 1.3743518018722534
- 1.3663041377067566
- 1.3635316896438598
- 1.3672629308700561
- 1.3821286749839783
- 1.3541253805160522
- 1.3499381613731385
- 1.3411833930015564
- 1.3382153058052062
- 1.3465572667121888
- 1.3486197423934936
- 1.3301779556274413
- 1.3483656764030456
- 1.3216676449775695
- 1.3195544457435608
- 1.335123565196991
- 1.3427662420272828
- 1.3177499198913574
- 1.3193460559844972
- 1.3297531342506408
- 1.3171536970138549
- 1.3594084644317628
- 1.3390353751182555
- 1.3103920030593872
- 1.3027851533889772
- 1.3032577061653137
- 1.3114648842811585
- 1.3289873147010802
- 1.3248198270797729
- 1.3547386670112609
- 1.3393062019348145
- 1.3305810284614563
- 1.3228146958351135
- 1.298787443637848
- 1.3053839254379271
- 1.288258557319641
- 1.2861404156684875
- 1.3068830490112304
- 1.2993440103530884
- 1.2862399101257325
- 1.3015070915222169
- 1.295762026309967
- 1.3261933541297912
- 1.2787780809402465
- 1.2954532718658447
- 1.2757962846755981
- 1.2758162784576417
- 1.2899454617500306
- 1.3009845328330993
- 1.2787421178817748
- 1.2826481509208678
- 1.2870990800857545
- 1.3214994955062866
- 1.3024199557304383
- 1.3026508378982544
- 1.3033972597122192
- 1.2981514811515809
- 1.297856411933899
- 1.2747283387184143
- 1.2822182297706604
- 1.27820942401886
- 1.284432876110077
- 1.2841528344154358
- 1.286647810935974
- 1.28420480966568
- 1.2871594262123107
- 1.3192423748970032
- 1.3248772501945496
- 1.3063602614402772
- 1.2770495533943176
- 1.2783235955238341
- 1.2737297463417052
- 1.2911480832099915
- 1.2923283576965332
- 1.283845353126526
train_accuracy:
- 0.011
- 0.0
- 0.123
- 0.138
- 0.157
- 0.0
- 0.0
- 0.0
- 0.218
- 0.0
- 0.186
- 0.0
- 0.0
- 0.221
- 0.227
- 0.0
- 0.003
- 0.241
- 0.0
- 0.245
- 0.245
- 0.0
- 0.249
- 0.248
- 0.252
- 0.0
- 0.006
- 0.223
- 0.0
- 0.265
- 0.0
- 0.0
- 0.0
- 0.0
- 0.276
- 0.249
- 0.236
- 0.278
- 0.0
- 0.0
- 0.0
- 0.244
- 0.277
- 0.245
- 0.0
- 0.0
- 0.317
- 0.297
- 0.305
- 0.0
- 0.065
- 0.0
- 0.0
- 0.333
- 0.307
- 0.03
- 0.289
- 0.302
- 0.0
- 0.293
- 0.066
- 0.0
- 0.32
- 0.33
- 0.285
- 0.0
- 0.317
- 0.308
- 0.281
- 0.0
- 0.0
- 0.261
- 0.268
- 0.263
- 0.041
- 0.0
- 0.068
- 0.286
- 0.0
- 0.301
- 0.279
- 0.358
- 0.333
- 0.0
- 0.0
- 0.295
- 0.0
- 0.291
- 0.0
- 0.0
- 0.336
- 0.285
- 0.322
- 0.312
- 0.0
- 0.0
- 0.285
- 0.325
- 0.362
- 0.281
train_loss:
- 2.388
- 2.563
- 2.411
- 2.266
- 1.842
- 2.085
- 2.331
- 1.668
- 1.855
- 1.546
- 2.081
- 1.788
- 1.737
- 1.636
- 1.401
- 1.3
- 1.858
- 1.738
- 1.267
- 1.442
- 1.262
- 1.412
- 1.546
- 1.302
- 0.95
- 1.049
- 1.094
- 1.011
- 1.218
- 1.166
- 0.999
- 0.953
- 0.948
- 0.938
- 1.084
- 1.05
- 0.853
- 0.993
- 0.686
- 0.851
- 0.952
- 0.931
- 0.782
- 0.763
- 0.876
- 0.722
- 0.986
- 0.856
- 0.715
- 0.668
- 0.682
- 0.758
- 0.72
- 0.752
- 0.846
- 0.712
- 0.689
- 0.687
- 0.573
- 0.667
- 0.535
- 0.546
- 0.625
- 0.5
- 0.527
- 0.581
- 0.573
- 0.663
- 0.427
- 0.525
- 0.465
- 0.438
- 0.535
- 0.483
- 0.419
- 0.398
- 0.501
- 0.538
- 0.463
- 0.458
- 0.427
- 0.429
- 0.436
- 0.309
- 0.416
- 0.33
- 0.394
- 0.347
- 0.4
- 0.323
- 0.381
- 0.404
- 0.407
- 0.355
- 0.262
- 0.308
- 0.292
- 0.326
- 0.33
- 0.308
unequal: 0
verbose: 1
