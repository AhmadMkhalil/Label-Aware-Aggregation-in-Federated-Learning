avg_train_accuracy: 0.085
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0261
- 0.0653
- 0.0865
- 0.1044
- 0.1212
- 0.1312
- 0.141
- 0.1429
- 0.1528
- 0.1572
- 0.167
- 0.171
- 0.1819
- 0.1867
- 0.1942
- 0.1878
- 0.1981
- 0.1967
- 0.2039
- 0.2092
- 0.2116
- 0.2113
- 0.2143
- 0.2133
- 0.2201
- 0.2212
- 0.2262
- 0.2381
- 0.2283
- 0.2265
- 0.2421
- 0.2444
- 0.2476
- 0.2429
- 0.2396
- 0.2492
- 0.2536
- 0.2464
- 0.2504
- 0.2541
- 0.2594
- 0.2589
- 0.2594
- 0.2608
- 0.2592
- 0.2548
- 0.2537
- 0.2678
- 0.2628
- 0.2691
- 0.2675
- 0.2706
- 0.2637
- 0.2634
- 0.2711
- 0.2671
- 0.2617
- 0.2668
- 0.2603
- 0.2674
- 0.2678
- 0.2684
- 0.2737
- 0.271
- 0.2758
- 0.2741
- 0.2774
- 0.28
- 0.2835
- 0.2835
- 0.277
- 0.283
- 0.2825
- 0.2791
- 0.2783
- 0.2771
- 0.286
- 0.2809
- 0.2856
- 0.2822
- 0.2847
- 0.2837
- 0.281
- 0.2767
- 0.2765
- 0.285
- 0.2886
- 0.2911
- 0.2916
- 0.2894
- 0.2789
- 0.286
- 0.2882
- 0.2854
- 0.2895
- 0.286
- 0.288
- 0.2832
- 0.2911
- 0.2935
test_loss_list:
- 1.8329620170593262
- 1.7326677083969115
- 1.6782847738265991
- 1.6318323135375976
- 1.6101109600067138
- 1.5812370419502257
- 1.5425606155395508
- 1.5363249278068543
- 1.5309377193450928
- 1.5536048769950868
- 1.5201941633224487
- 1.496141095161438
- 1.4623058438301086
- 1.4461246562004089
- 1.43313068151474
- 1.4654915022850037
- 1.4308381748199464
- 1.4352271962165832
- 1.4026557660102845
- 1.4141901111602784
- 1.395084137916565
- 1.4097769737243653
- 1.3817815208435058
- 1.3923544836044313
- 1.3965191841125488
- 1.399586021900177
- 1.3657405114173888
- 1.355501070022583
- 1.3640640568733216
- 1.397324619293213
- 1.3377052021026612
- 1.334836037158966
- 1.3281108713150025
- 1.3322245240211488
- 1.3369137835502625
- 1.319695999622345
- 1.3153220129013061
- 1.3310024976730346
- 1.3173963975906373
- 1.3084935927391053
- 1.302237219810486
- 1.300277485847473
- 1.2976399874687194
- 1.2958569145202636
- 1.3116547536849976
- 1.3205376720428468
- 1.3193558382987975
- 1.2892056941986083
- 1.3002673745155335
- 1.2943172836303711
- 1.285310652256012
- 1.2805826592445373
- 1.3020039415359497
- 1.3049534916877747
- 1.2770241284370423
- 1.2924565553665162
- 1.3321871328353883
- 1.3069136762619018
- 1.313661708831787
- 1.3099256944656372
- 1.299694423675537
- 1.301543779373169
- 1.2761714196205138
- 1.2871803617477418
- 1.2871860718727113
- 1.2917365646362304
- 1.271659471988678
- 1.26820449590683
- 1.265524559020996
- 1.2634722208976745
- 1.2747924160957336
- 1.261624641418457
- 1.2701702189445496
- 1.2779622173309326
- 1.2803321957588196
- 1.2860414242744447
- 1.2602968859672545
- 1.271659061908722
- 1.2654726338386535
- 1.2772571182250976
- 1.2650868487358093
- 1.2712180233001709
- 1.2818941688537597
- 1.3188125586509705
- 1.2841659355163575
- 1.2699914145469666
- 1.2608003425598144
- 1.2618350315093994
- 1.269386224746704
- 1.2588922214508056
- 1.3002262806892395
- 1.2711155533790588
- 1.2641562986373902
- 1.2768995761871338
- 1.2763661336898804
- 1.2690190172195435
- 1.275102641582489
- 1.2822537994384766
- 1.2672023940086365
- 1.2567594742774963
train_accuracy:
- 0.031
- 0.06
- 0.0
- 0.018
- 0.0
- 0.155
- 0.058
- 0.158
- 0.0
- 0.208
- 0.193
- 0.191
- 0.0
- 0.221
- 0.17
- 0.221
- 0.256
- 0.0
- 0.0
- 0.0
- 0.0
- 0.239
- 0.0
- 0.261
- 0.237
- 0.25
- 0.25
- 0.241
- 0.0
- 0.293
- 0.246
- 0.0
- 0.0
- 0.275
- 0.297
- 0.0
- 0.0
- 0.273
- 0.0
- 0.278
- 0.0
- 0.27
- 0.0
- 0.015
- 0.269
- 0.0
- 0.004
- 0.045
- 0.282
- 0.299
- 0.296
- 0.0
- 0.033
- 0.0
- 0.326
- 0.302
- 0.331
- 0.295
- 0.0
- 0.0
- 0.027
- 0.0
- 0.32
- 0.309
- 0.342
- 0.0
- 0.298
- 0.0
- 0.286
- 0.0
- 0.326
- 0.0
- 0.0
- 0.017
- 0.0
- 0.314
- 0.0
- 0.05
- 0.0
- 0.0
- 0.0
- 0.286
- 0.305
- 0.323
- 0.321
- 0.308
- 0.324
- 0.0
- 0.319
- 0.315
- 0.325
- 0.336
- 0.095
- 0.29
- 0.0
- 0.335
- 0.327
- 0.295
- 0.287
- 0.085
train_loss:
- 2.849
- 2.16
- 2.079
- 1.979
- 2.244
- 2.173
- 1.459
- 2.032
- 1.991
- 2.213
- 1.846
- 1.813
- 1.498
- 1.454
- 1.144
- 1.911
- 1.357
- 1.58
- 1.056
- 1.525
- 1.264
- 1.441
- 1.215
- 1.391
- 1.362
- 1.303
- 1.094
- 1.069
- 1.259
- 1.424
- 0.829
- 0.987
- 0.971
- 0.957
- 1.12
- 0.907
- 0.879
- 1.074
- 0.886
- 0.871
- 0.668
- 0.822
- 0.784
- 0.767
- 0.91
- 0.904
- 0.923
- 0.587
- 0.851
- 0.704
- 0.701
- 0.673
- 0.797
- 0.779
- 0.679
- 0.743
- 0.859
- 0.759
- 0.699
- 0.696
- 0.652
- 0.667
- 0.547
- 0.634
- 0.647
- 0.622
- 0.501
- 0.514
- 0.418
- 0.459
- 0.564
- 0.467
- 0.443
- 0.554
- 0.526
- 0.514
- 0.378
- 0.497
- 0.328
- 0.318
- 0.422
- 0.471
- 0.457
- 0.502
- 0.453
- 0.354
- 0.381
- 0.339
- 0.338
- 0.36
- 0.464
- 0.328
- 0.349
- 0.372
- 0.303
- 0.363
- 0.369
- 0.366
- 0.285
- 0.301
unequal: 0
verbose: 1
