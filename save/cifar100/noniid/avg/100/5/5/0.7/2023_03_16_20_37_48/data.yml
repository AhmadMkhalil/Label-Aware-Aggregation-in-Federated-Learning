avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0237
- 0.0776
- 0.0953
- 0.1149
- 0.1251
- 0.1387
- 0.1432
- 0.154
- 0.1571
- 0.1627
- 0.1719
- 0.1766
- 0.184
- 0.1858
- 0.1984
- 0.1894
- 0.1965
- 0.2056
- 0.2004
- 0.2169
- 0.2268
- 0.2206
- 0.2111
- 0.2219
- 0.2256
- 0.2208
- 0.223
- 0.2331
- 0.2316
- 0.2346
- 0.2337
- 0.2424
- 0.2484
- 0.2498
- 0.2472
- 0.2425
- 0.2429
- 0.2464
- 0.2481
- 0.2513
- 0.2575
- 0.2534
- 0.2637
- 0.2653
- 0.2549
- 0.2665
- 0.2483
- 0.2706
- 0.2715
- 0.275
- 0.277
- 0.2773
- 0.2767
- 0.2685
- 0.2731
- 0.2595
- 0.2649
- 0.2754
- 0.2692
- 0.278
- 0.2726
- 0.2719
- 0.2726
- 0.2801
- 0.2834
- 0.2746
- 0.2789
- 0.2784
- 0.2703
- 0.2638
- 0.2734
- 0.2859
- 0.2694
- 0.2719
- 0.2854
- 0.2899
- 0.286
- 0.2888
- 0.2937
- 0.2902
- 0.2888
- 0.2872
- 0.2864
- 0.2853
- 0.2852
- 0.2924
- 0.2952
- 0.2967
- 0.2942
- 0.293
- 0.2929
- 0.2957
- 0.296
- 0.2899
- 0.2964
- 0.293
- 0.2943
- 0.2953
- 0.2909
- 0.2991
test_loss_list:
- 1.8498991775512694
- 1.7395799922943116
- 1.6818374919891357
- 1.6677683973312378
- 1.6272473192214967
- 1.5781293797492981
- 1.545154836177826
- 1.5244542121887208
- 1.5190097141265868
- 1.5110703301429749
- 1.4830193734169006
- 1.4776573944091798
- 1.4529260611534118
- 1.4603563022613526
- 1.4398131251335144
- 1.4375965476036072
- 1.4310742044448852
- 1.4028164291381835
- 1.4460841488838196
- 1.3855719065666199
- 1.3807151627540588
- 1.3871578884124756
- 1.3864791584014893
- 1.365804889202118
- 1.360048053264618
- 1.368326063156128
- 1.3734769296646119
- 1.3507370924949647
- 1.3622832345962523
- 1.3333700132369994
- 1.3488822650909424
- 1.336068434715271
- 1.3226828265190125
- 1.3185908150672914
- 1.3322954177856445
- 1.3386470079421997
- 1.3303548049926759
- 1.3355188298225402
- 1.334076120853424
- 1.3051600193977355
- 1.2982171702384948
- 1.317963788509369
- 1.288196430206299
- 1.2895835161209106
- 1.2931404209136963
- 1.276435945034027
- 1.3221431708335876
- 1.2705461311340331
- 1.2739307260513306
- 1.2732508635520936
- 1.2620559906959534
- 1.2698111248016357
- 1.2669110250473024
- 1.2771152758598328
- 1.263675229549408
- 1.3065846800804137
- 1.2888793897628785
- 1.2660895419120788
- 1.2725463390350342
- 1.25578697681427
- 1.2716957879066468
- 1.2704478573799134
- 1.2703580570220947
- 1.2493239045143127
- 1.2502176761627197
- 1.2617346954345703
- 1.266830596923828
- 1.2603165698051453
- 1.2924647617340088
- 1.3060208249092102
- 1.2781761026382445
- 1.2413125658035278
- 1.2906029796600342
- 1.2753766322135924
- 1.2430068635940552
- 1.2400130796432496
- 1.2517967462539672
- 1.240656087398529
- 1.2367322945594788
- 1.2412746524810792
- 1.2383267164230347
- 1.2464214444160462
- 1.2470403265953065
- 1.2436456441879273
- 1.2520655727386474
- 1.2380309724807739
- 1.232351438999176
- 1.2374712300300599
- 1.2429090094566346
- 1.2420967793464661
- 1.2336692357063292
- 1.2435582447052003
- 1.2366439557075501
- 1.2395204854011537
- 1.236603662967682
- 1.2397548937797547
- 1.2334114956855773
- 1.2387449526786805
- 1.2401740741729737
- 1.2380689907073974
train_accuracy:
- 0.0
- 0.081
- 0.0
- 0.125
- 0.166
- 0.0
- 0.148
- 0.0
- 0.176
- 0.219
- 0.181
- 0.226
- 0.0
- 0.0
- 0.041
- 0.216
- 0.01
- 0.218
- 0.011
- 0.202
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.237
- 0.252
- 0.251
- 0.0
- 0.256
- 0.038
- 0.092
- 0.0
- 0.0
- 0.295
- 0.0
- 0.26
- 0.0
- 0.0
- 0.0
- 0.257
- 0.0
- 0.0
- 0.349
- 0.0
- 0.297
- 0.0
- 0.281
- 0.0
- 0.141
- 0.0
- 0.156
- 0.0
- 0.113
- 0.307
- 0.0
- 0.295
- 0.312
- 0.048
- 0.066
- 0.11
- 0.0
- 0.261
- 0.0
- 0.082
- 0.28
- 0.271
- 0.39
- 0.321
- 0.32
- 0.321
- 0.387
- 0.0
- 0.065
- 0.149
- 0.285
- 0.0
- 0.322
- 0.293
- 0.0
- 0.0
- 0.0
- 0.129
- 0.0
- 0.093
- 0.307
- 0.143
- 0.277
- 0.322
- 0.0
- 0.233
- 0.202
- 0.299
- 0.27
- 0.299
- 0.273
- 0.196
- 0.077
- 0.0
train_loss:
- 2.438
- 2.643
- 2.097
- 2.72
- 2.244
- 1.865
- 1.76
- 1.698
- 2.033
- 1.938
- 1.578
- 1.839
- 1.541
- 1.731
- 1.399
- 1.681
- 1.651
- 1.362
- 1.815
- 1.05
- 1.022
- 1.466
- 1.435
- 1.203
- 1.139
- 1.39
- 1.318
- 1.07
- 1.248
- 1.064
- 1.203
- 1.035
- 0.806
- 0.934
- 1.122
- 1.086
- 1.107
- 1.036
- 1.026
- 0.837
- 0.832
- 0.965
- 0.655
- 0.771
- 0.977
- 0.77
- 1.036
- 0.595
- 0.733
- 0.604
- 0.703
- 0.541
- 0.685
- 0.759
- 0.629
- 0.885
- 0.775
- 0.644
- 0.744
- 0.611
- 0.698
- 0.676
- 0.689
- 0.551
- 0.553
- 0.635
- 0.615
- 0.504
- 0.682
- 0.666
- 0.576
- 0.492
- 0.635
- 0.523
- 0.475
- 0.362
- 0.488
- 0.45
- 0.415
- 0.397
- 0.393
- 0.412
- 0.338
- 0.473
- 0.434
- 0.383
- 0.372
- 0.361
- 0.297
- 0.413
- 0.354
- 0.271
- 0.322
- 0.379
- 0.336
- 0.304
- 0.308
- 0.312
- 0.377
- 0.256
unequal: 0
verbose: 1
