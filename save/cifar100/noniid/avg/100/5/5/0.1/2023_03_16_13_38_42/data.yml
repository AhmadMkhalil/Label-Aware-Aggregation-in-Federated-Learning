avg_train_accuracy: 0.262
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0387
- 0.0902
- 0.0322
- 0.0978
- 0.1152
- 0.0208
- 0.0253
- 0.1269
- 0.1366
- 0.0253
- 0.1438
- 0.1512
- 0.0292
- 0.0269
- 0.1507
- 0.0273
- 0.0274
- 0.1606
- 0.1621
- 0.1571
- 0.1661
- 0.1679
- 0.0287
- 0.1756
- 0.1789
- 0.1846
- 0.1919
- 0.1962
- 0.1982
- 0.1953
- 0.1881
- 0.0314
- 0.1893
- 0.1975
- 0.0304
- 0.0339
- 0.0251
- 0.0342
- 0.1966
- 0.0321
- 0.0348
- 0.0344
- 0.1958
- 0.1935
- 0.03
- 0.2045
- 0.2014
- 0.0357
- 0.0362
- 0.0355
- 0.0306
- 0.2049
- 0.0283
- 0.0334
- 0.2007
- 0.2093
- 0.0296
- 0.0365
- 0.2139
- 0.2126
- 0.2109
- 0.0374
- 0.2091
- 0.0407
- 0.2169
- 0.2162
- 0.2153
- 0.0366
- 0.2117
- 0.034
- 0.0369
- 0.2243
- 0.0381
- 0.2142
- 0.0415
- 0.2197
- 0.2146
- 0.2192
- 0.2169
- 0.0372
- 0.0331
- 0.0369
- 0.219
- 0.038
- 0.2247
- 0.2266
- 0.0354
- 0.2309
- 0.2343
- 0.2334
- 0.0442
- 0.2357
- 0.0446
- 0.2318
- 0.0418
- 0.0397
- 0.0401
- 0.0396
- 0.2336
- 0.2333
test_loss_list:
- 1.8717390966415406
- 1.8695362854003905
- 3.929333276748657
- 1.8642864418029785
- 1.8778994131088256
- 3.9303479290008543
- 3.55344780921936
- 1.7966258811950684
- 1.8137243795394897
- 3.8377936553955077
- 1.812291193008423
- 1.8045232677459717
- 3.4710028553009034
- 3.906457862854004
- 1.7623940753936767
- 3.6817379856109618
- 3.9222285842895506
- 1.7745701336860658
- 1.7975239777565002
- 1.830902419090271
- 1.827449116706848
- 1.8449579524993895
- 3.807443389892578
- 1.766101109981537
- 1.8000946760177612
- 1.7931787967681885
- 1.7955107140541076
- 1.8041858959197998
- 1.811407904624939
- 1.835179431438446
- 1.849344892501831
- 3.7114341926574705
- 1.8125765061378478
- 1.8125550866127014
- 3.636577215194702
- 3.7451627254486084
- 3.567935619354248
- 3.6713622856140136
- 1.6209733724594115
- 3.3928785800933836
- 3.5775347328186036
- 3.591180419921875
- 1.6278422951698304
- 1.6749522972106934
- 3.4727109050750733
- 1.6435215806961059
- 1.6910610270500184
- 3.522312936782837
- 3.4906769752502442
- 3.704834499359131
- 3.194203429222107
- 1.5614699578285218
- 3.3558486700057983
- 3.239966268539429
- 1.5674273657798767
- 1.5969866728782653
- 3.460154342651367
- 3.331504812240601
- 1.5666228437423706
- 1.598918011188507
- 1.6478390645980836
- 3.187465190887451
- 1.6354819488525392
- 3.1137050867080687
- 1.6119587755203246
- 1.6432916355133056
- 1.6696286249160766
- 3.405775442123413
- 1.6377460718154908
- 3.275443639755249
- 3.462273349761963
- 1.5996076369285583
- 3.1720580673217773
- 1.6310130119323731
- 3.22989209651947
- 1.5983809566497802
- 1.6368926548957825
- 1.6445133090019226
- 1.6781667470932007
- 3.285115180015564
- 3.4423760175704956
- 3.3979769420623778
- 1.5772094488143922
- 3.1164368772506714
- 1.5765770769119263
- 1.59953946352005
- 3.2970546817779542
- 1.5856153678894043
- 1.6144041848182678
- 1.6377483582496644
- 3.1262910318374635
- 1.5988236999511718
- 3.006569576263428
- 1.5570678901672363
- 3.0974308347702024
- 3.255780930519104
- 3.1276261472702025
- 3.198482103347778
- 1.5051389694213868
- 1.5412470531463622
train_accuracy:
- 0.038
- 0.106
- 0.0
- 0.13
- 0.123
- 0.0
- 0.158
- 0.154
- 0.166
- 0.0
- 0.161
- 0.202
- 0.57
- 0.0
- 0.196
- 0.0
- 0.0
- 0.227
- 0.207
- 0.222
- 0.188
- 0.192
- 0.0
- 0.206
- 0.208
- 0.252
- 0.212
- 0.222
- 0.223
- 0.237
- 0.198
- 0.0
- 0.267
- 0.218
- 0.0
- 0.0
- 0.0
- 0.0
- 0.218
- 0.0
- 0.0
- 0.0
- 0.223
- 0.244
- 0.0
- 0.222
- 0.247
- 0.0
- 0.0
- 0.0
- 0.334
- 0.224
- 0.0
- 0.455
- 0.243
- 0.229
- 0.0
- 0.0
- 0.297
- 0.297
- 0.223
- 0.401
- 0.202
- 0.546
- 0.237
- 0.247
- 0.268
- 0.0
- 0.257
- 0.0
- 0.0
- 0.243
- 0.0
- 0.265
- 0.0
- 0.222
- 0.249
- 0.265
- 0.245
- 0.0
- 0.0
- 0.0
- 0.249
- 0.0
- 0.247
- 0.262
- 0.0
- 0.324
- 0.276
- 0.255
- 0.0
- 0.312
- 0.515
- 0.254
- 0.425
- 0.0
- 0.544
- 0.0
- 0.277
- 0.262
train_loss:
- 4.129
- 3.574
- 1.056
- 3.751
- 3.314
- 1.463
- 1.73
- 3.27
- 3.066
- 1.082
- 2.817
- 2.878
- 1.195
- 1.106
- 3.169
- 0.795
- 0.427
- 2.767
- 2.115
- 2.473
- 2.282
- 1.849
- 1.232
- 2.881
- 2.195
- 2.063
- 2.208
- 2.396
- 1.915
- 1.958
- 1.759
- 0.885
- 1.895
- 1.711
- 0.65
- 1.188
- 1.084
- 1.088
- 1.894
- 0.577
- 0.724
- 0.782
- 1.844
- 1.171
- 0.59
- 2.291
- 1.125
- 0.542
- 0.728
- 0.214
- 1.363
- 2.0
- 0.628
- 0.928
- 1.28
- 1.438
- 0.507
- 0.625
- 2.006
- 1.315
- 1.472
- 0.781
- 1.255
- 0.532
- 1.862
- 1.331
- 0.916
- 0.551
- 0.968
- 0.548
- 0.481
- 1.28
- 0.351
- 1.208
- 0.487
- 0.977
- 0.794
- 1.387
- 0.913
- 0.429
- 0.864
- 0.591
- 0.982
- 0.34
- 0.934
- 0.917
- 0.453
- 1.519
- 0.813
- 0.714
- 0.355
- 1.144
- 0.725
- 0.88
- 0.398
- 0.554
- 0.443
- 0.607
- 0.933
- 0.535
unequal: 0
verbose: 1
