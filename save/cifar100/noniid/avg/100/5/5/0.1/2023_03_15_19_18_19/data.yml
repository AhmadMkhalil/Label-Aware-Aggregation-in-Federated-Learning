avg_train_accuracy: 0.249
avg_train_loss: 0.008
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0265
- 0.0281
- 0.0669
- 0.0885
- 0.0927
- 0.0313
- 0.0342
- 0.0298
- 0.0286
- 0.1022
- 0.128
- 0.1447
- 0.03
- 0.1471
- 0.1496
- 0.0338
- 0.0303
- 0.0312
- 0.0342
- 0.1463
- 0.1425
- 0.0316
- 0.0337
- 0.031
- 0.1704
- 0.0354
- 0.1716
- 0.1721
- 0.1664
- 0.0381
- 0.1824
- 0.032
- 0.1848
- 0.0361
- 0.0332
- 0.0324
- 0.1746
- 0.0386
- 0.0375
- 0.0329
- 0.0348
- 0.1891
- 0.0381
- 0.1851
- 0.0396
- 0.1979
- 0.0411
- 0.2015
- 0.0339
- 0.0327
- 0.1936
- 0.2078
- 0.1937
- 0.0384
- 0.209
- 0.0328
- 0.2082
- 0.2135
- 0.0414
- 0.0395
- 0.0346
- 0.0391
- 0.2234
- 0.0347
- 0.2142
- 0.2086
- 0.2065
- 0.218
- 0.0457
- 0.035
- 0.0339
- 0.0418
- 0.0342
- 0.0336
- 0.0399
- 0.0341
- 0.2223
- 0.2205
- 0.2288
- 0.0453
- 0.22
- 0.2321
- 0.2334
- 0.0435
- 0.2273
- 0.0403
- 0.2346
- 0.0362
- 0.229
- 0.0474
- 0.0354
- 0.2338
- 0.0515
- 0.2228
- 0.041
- 0.0475
- 0.044
- 0.0478
- 0.2383
- 0.2325
test_loss_list:
- 2.9670345163345337
- 4.309808397293091
- 1.8628092336654662
- 1.865658450126648
- 1.8874181699752808
- 3.5702415466308595
- 3.803595266342163
- 3.9346542072296145
- 4.22601734161377
- 1.806694416999817
- 1.8062748432159423
- 1.8205384826660156
- 3.7524781894683836
- 1.7752066946029663
- 1.7977325201034546
- 3.4682773208618163
- 3.854314022064209
- 3.689292993545532
- 3.457616853713989
- 1.695174696445465
- 1.742949924468994
- 3.7529710292816163
- 3.45923397064209
- 3.7799236297607424
- 1.6547644448280334
- 3.3116891193389892
- 1.6573853254318238
- 1.7011445593833923
- 1.7210865116119385
- 3.2712675094604493
- 1.7001487946510314
- 3.603640594482422
- 1.6858970928192138
- 3.2708627128601075
- 3.6149668216705324
- 3.5283369398117066
- 1.5739660739898682
- 3.0799994611740114
- 3.3566704845428466
- 3.460899338722229
- 3.3063961839675904
- 1.5450053739547729
- 3.043271961212158
- 1.5911476063728331
- 3.0458701181411745
- 1.5885428810119628
- 3.0701103258132934
- 1.616233036518097
- 3.3472405767440794
- 3.4516223430633546
- 1.577716817855835
- 1.6113949632644653
- 1.6380391097068787
- 3.21956485748291
- 1.5826616263389588
- 3.509678478240967
- 1.5806533598899841
- 1.6055680322647095
- 3.0581917095184328
- 3.1421418380737305
- 3.4240946912765504
- 3.0611822986602784
- 1.5033627343177796
- 3.186140546798706
- 1.5023662590980529
- 1.565577826499939
- 1.5879997324943542
- 1.59341698884964
- 2.8731517934799196
- 3.3898786449432374
- 3.3119284296035767
- 2.9805364990234375
- 3.3412197923660276
- 3.4086812496185304
- 2.9917213821411135
- 3.2394459772109987
- 1.4585226726531983
- 1.4831015944480896
- 1.5158468437194825
- 2.8849232625961303
- 1.5305733847618104
- 1.5413065958023071
- 1.5690542483329772
- 3.113811092376709
- 1.5349592518806459
- 3.119126124382019
- 1.514032588005066
- 3.317515182495117
- 1.5260772562026979
- 2.9202697229385377
- 3.3374854946136474
- 1.5017065811157226
- 2.797104153633118
- 1.512480833530426
- 3.0132691621780396
- 2.885715103149414
- 3.090271944999695
- 2.852392272949219
- 1.4776228475570679
- 1.5239807748794556
train_accuracy:
- 0.154
- 0.0
- 0.081
- 0.121
- 0.098
- 0.405
- 0.366
- 0.0
- 0.0
- 0.116
- 0.175
- 0.179
- 0.0
- 0.153
- 0.231
- 0.397
- 0.0
- 0.0
- 0.335
- 0.157
- 0.159
- 0.0
- 0.306
- 0.0
- 0.208
- 0.409
- 0.181
- 0.177
- 0.213
- 0.49
- 0.245
- 0.0
- 0.203
- 0.618
- 0.0
- 0.0
- 0.203
- 0.55
- 0.477
- 0.0
- 0.568
- 0.23
- 0.504
- 0.21
- 0.521
- 0.208
- 0.48
- 0.201
- 0.0
- 0.0
- 0.231
- 0.281
- 0.222
- 0.583
- 0.235
- 0.0
- 0.208
- 0.276
- 0.545
- 0.643
- 0.0
- 0.52
- 0.301
- 0.0
- 0.252
- 0.251
- 0.248
- 0.272
- 0.582
- 0.0
- 0.0
- 0.492
- 0.0
- 0.0
- 0.669
- 0.0
- 0.282
- 0.262
- 0.252
- 0.623
- 0.263
- 0.311
- 0.318
- 0.657
- 0.27
- 0.0
- 0.257
- 0.0
- 0.297
- 0.726
- 0.0
- 0.262
- 0.547
- 0.278
- 0.0
- 0.711
- 0.711
- 0.587
- 0.317
- 0.249
train_loss:
- 1.213
- 1.231
- 4.383
- 3.523
- 3.161
- 1.433
- 0.704
- 1.384
- 0.504
- 3.252
- 3.128
- 2.884
- 0.977
- 3.237
- 2.618
- 1.058
- 1.325
- 0.951
- 0.919
- 2.815
- 2.147
- 0.813
- 0.947
- 1.024
- 2.845
- 0.635
- 3.012
- 2.248
- 2.046
- 0.612
- 2.315
- 0.75
- 2.338
- 1.269
- 0.947
- 0.919
- 2.105
- 0.559
- 0.205
- 0.71
- 0.981
- 2.669
- 0.421
- 1.791
- 0.364
- 2.103
- 0.334
- 1.644
- 0.532
- 0.821
- 1.665
- 2.15
- 1.202
- 0.798
- 2.195
- 0.697
- 1.703
- 1.874
- 0.474
- 0.771
- 0.745
- 0.416
- 2.031
- 0.52
- 1.317
- 0.818
- 0.659
- 1.571
- 0.376
- 0.611
- 0.572
- 0.337
- 0.708
- 0.363
- 0.742
- 0.356
- 1.515
- 1.645
- 1.316
- 0.331
- 0.945
- 1.058
- 1.54
- 0.577
- 0.85
- 0.378
- 1.233
- 0.512
- 1.173
- 0.422
- 0.479
- 1.07
- 0.346
- 0.761
- 0.298
- 0.463
- 0.115
- 0.343
- 1.433
- 0.786
unequal: 0
verbose: 1
