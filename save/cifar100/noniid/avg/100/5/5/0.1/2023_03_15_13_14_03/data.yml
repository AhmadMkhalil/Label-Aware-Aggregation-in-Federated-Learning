avg_train_accuracy: 0.259
avg_train_loss: 0.01
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0218
- 0.0644
- 0.0316
- 0.0904
- 0.0316
- 0.1047
- 0.1148
- 0.1181
- 0.1264
- 0.0325
- 0.1357
- 0.0316
- 0.0291
- 0.1437
- 0.1524
- 0.029
- 0.0315
- 0.034
- 0.033
- 0.0352
- 0.1456
- 0.1678
- 0.025
- 0.1618
- 0.0305
- 0.1708
- 0.173
- 0.0364
- 0.0288
- 0.1715
- 0.0381
- 0.1751
- 0.0305
- 0.1792
- 0.0354
- 0.0386
- 0.1811
- 0.0308
- 0.1853
- 0.1876
- 0.1869
- 0.0312
- 0.1903
- 0.0319
- 0.0354
- 0.1988
- 0.0369
- 0.0351
- 0.0321
- 0.1958
- 0.192
- 0.0418
- 0.0317
- 0.2051
- 0.0353
- 0.0354
- 0.0349
- 0.0353
- 0.0312
- 0.2022
- 0.1968
- 0.0427
- 0.0377
- 0.2008
- 0.206
- 0.0426
- 0.2104
- 0.212
- 0.0371
- 0.034
- 0.21
- 0.2143
- 0.0442
- 0.0388
- 0.0401
- 0.0351
- 0.2143
- 0.2089
- 0.2207
- 0.0454
- 0.227
- 0.0432
- 0.0374
- 0.0374
- 0.0326
- 0.2229
- 0.0367
- 0.0359
- 0.0404
- 0.2307
- 0.2303
- 0.0436
- 0.2291
- 0.224
- 0.2348
- 0.0408
- 0.2233
- 0.0462
- 0.2344
- 0.2376
test_loss_list:
- 3.13446307182312
- 1.8609423637390137
- 3.7347784423828125
- 1.8455836296081543
- 3.738967342376709
- 1.8480817651748658
- 1.8598331356048583
- 1.879232873916626
- 1.8820000982284546
- 3.7387142753601075
- 1.8606645154953003
- 3.875704708099365
- 3.7587184143066406
- 1.7663235187530517
- 1.7936611890792846
- 3.862821092605591
- 3.9478304195404053
- 3.4249597644805907
- 3.689203157424927
- 3.507060127258301
- 1.7036514019966125
- 1.6938635468482972
- 3.8787723922729493
- 1.684662070274353
- 3.6254007148742677
- 1.6663321447372437
- 1.706092481613159
- 3.29771737575531
- 3.7666415977478027
- 1.6627854704856873
- 3.239866223335266
- 1.6773303151130676
- 3.6435854721069334
- 1.6702670979499816
- 3.3925438690185548
- 3.2082734060287477
- 1.6382246923446655
- 3.5637833499908447
- 1.6477627396583556
- 1.6662509274482726
- 1.7026141571998596
- 3.482349100112915
- 1.6561455631256103
- 3.4996574974060057
- 3.48913366317749
- 1.6154531145095825
- 3.303553524017334
- 3.4566735076904296
- 3.552081308364868
- 1.5722402358055114
- 1.6357149004936218
- 3.0280213165283203
- 3.45376070022583
- 1.545309407711029
- 3.3678607177734374
- 3.210233459472656
- 3.4319914817810058
- 3.430074939727783
- 3.3919794273376467
- 1.5329241013526917
- 1.5789530158042908
- 3.119764790534973
- 3.360697560310364
- 1.5993232011795044
- 1.588692078590393
- 3.0637723636627197
- 1.5794332575798036
- 1.5853067564964294
- 3.278117241859436
- 3.3260956716537478
- 1.5589477872848512
- 1.571315860748291
- 3.1178360319137575
- 3.323611125946045
- 3.4533765172958373
- 3.355112729072571
- 1.5584781241416932
- 1.5951781129837037
- 1.5957956385612488
- 2.956352081298828
- 1.5579112935066224
- 3.068224754333496
- 3.2094028425216674
- 3.3964892864227294
- 3.2045223474502564
- 1.5044084644317628
- 3.1648354387283324
- 3.3488647031784056
- 3.1343088579177856
- 1.4856382417678833
- 1.5117459511756897
- 3.096481432914734
- 1.5282961630821228
- 1.5709349346160888
- 1.5757682728767395
- 3.204683575630188
- 1.588045403957367
- 2.9303435039520265
- 1.5029144597053528
- 1.5427296924591065
train_accuracy:
- 0.0
- 0.067
- 0.0
- 0.086
- 0.0
- 0.14
- 0.148
- 0.157
- 0.156
- 0.0
- 0.183
- 0.0
- 0.0
- 0.169
- 0.222
- 0.0
- 0.0
- 0.505
- 0.0
- 0.436
- 0.194
- 0.165
- 0.0
- 0.14
- 0.0
- 0.237
- 0.241
- 0.585
- 0.0
- 0.245
- 0.641
- 0.247
- 0.0
- 0.214
- 0.0
- 0.662
- 0.256
- 0.0
- 0.271
- 0.235
- 0.248
- 0.0
- 0.259
- 0.0
- 0.0
- 0.258
- 0.0
- 0.0
- 0.0
- 0.267
- 0.275
- 0.69
- 0.0
- 0.217
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.271
- 0.271
- 0.0
- 0.0
- 0.252
- 0.287
- 0.679
- 0.276
- 0.236
- 0.0
- 0.0
- 0.281
- 0.319
- 0.0
- 0.0
- 0.0
- 0.0
- 0.269
- 0.265
- 0.265
- 0.697
- 0.32
- 0.0
- 0.0
- 0.0
- 0.0
- 0.299
- 0.0
- 0.0
- 0.0
- 0.315
- 0.272
- 0.0
- 0.315
- 0.274
- 0.291
- 0.0
- 0.279
- 0.645
- 0.349
- 0.259
train_loss:
- 1.019
- 4.377
- 1.062
- 3.849
- 0.884
- 3.615
- 3.045
- 2.628
- 3.066
- 0.857
- 2.889
- 1.102
- 1.351
- 2.736
- 2.749
- 0.867
- 0.413
- 1.55
- 0.937
- 0.872
- 2.73
- 2.88
- 1.309
- 2.716
- 0.701
- 2.929
- 2.166
- 0.887
- 1.102
- 2.253
- 0.639
- 1.875
- 0.723
- 2.447
- 0.7
- 0.768
- 1.956
- 0.625
- 1.846
- 1.544
- 1.246
- 0.707
- 1.642
- 0.568
- 0.782
- 2.317
- 0.445
- 0.935
- 0.675
- 1.532
- 0.95
- 0.655
- 0.554
- 2.383
- 0.532
- 0.635
- 0.148
- 0.464
- 0.582
- 1.18
- 0.682
- 0.334
- 0.098
- 0.767
- 1.371
- 0.542
- 1.907
- 1.773
- 0.469
- 0.601
- 0.89
- 1.118
- 0.368
- 0.08
- 0.062
- 0.509
- 0.753
- 0.394
- 1.45
- 0.518
- 2.167
- 0.309
- 0.55
- 0.089
- 0.865
- 1.688
- 0.386
- 0.089
- 0.474
- 0.738
- 1.431
- 0.274
- 0.563
- 1.216
- 1.124
- 0.369
- 0.932
- 0.506
- 1.235
- 1.005
unequal: 0
verbose: 1
