avg_train_accuracy: 0.323
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0204
- 0.0622
- 0.094
- 0.1026
- 0.0292
- 0.1122
- 0.0304
- 0.1132
- 0.0289
- 0.1213
- 0.0328
- 0.0316
- 0.1185
- 0.0286
- 0.0323
- 0.1395
- 0.1578
- 0.1511
- 0.0314
- 0.1643
- 0.1576
- 0.0327
- 0.033
- 0.1673
- 0.0324
- 0.0321
- 0.0315
- 0.1704
- 0.0339
- 0.1686
- 0.1734
- 0.0334
- 0.1822
- 0.0334
- 0.185
- 0.0345
- 0.1878
- 0.1976
- 0.1999
- 0.193
- 0.0355
- 0.0333
- 0.1949
- 0.1957
- 0.0333
- 0.2079
- 0.0363
- 0.0337
- 0.1995
- 0.2075
- 0.2043
- 0.2097
- 0.2066
- 0.2113
- 0.036
- 0.2075
- 0.2148
- 0.2162
- 0.2111
- 0.2152
- 0.2146
- 0.2156
- 0.2209
- 0.2176
- 0.0392
- 0.2171
- 0.2248
- 0.0368
- 0.2153
- 0.2226
- 0.2255
- 0.0356
- 0.2229
- 0.0397
- 0.2253
- 0.0392
- 0.2242
- 0.2211
- 0.2205
- 0.2297
- 0.0407
- 0.037
- 0.0368
- 0.0396
- 0.0338
- 0.229
- 0.2281
- 0.2324
- 0.0421
- 0.2326
- 0.234
- 0.2333
- 0.037
- 0.2365
- 0.0384
- 0.0395
- 0.0369
- 0.2394
- 0.0401
- 0.2354
test_loss_list:
- 3.023530192375183
- 1.866061897277832
- 1.873842430114746
- 1.876107702255249
- 3.895182237625122
- 1.8605453491210937
- 3.8902405071258546
- 1.830405697822571
- 3.746451425552368
- 1.842631974220276
- 3.4364136123657225
- 3.8162024211883545
- 1.7742255783081056
- 3.7891333293914795
- 3.832410984039307
- 1.7082501530647278
- 1.73568621635437
- 1.7488451647758483
- 3.7996615886688234
- 1.7387323379516602
- 1.764083936214447
- 3.6776862239837644
- 3.8878587532043456
- 1.7396364212036133
- 3.696245803833008
- 3.6983388328552245
- 3.2621743869781494
- 1.6254796361923218
- 3.2573743629455567
- 1.6663922262191773
- 1.6737704634666444
- 3.5103547096252443
- 1.6631252026557923
- 3.609456329345703
- 1.646292634010315
- 3.457977294921875
- 1.655490469932556
- 1.6648661923408508
- 1.6762339496612548
- 1.7123196458816528
- 3.5414153957366943
- 3.5680274629592894
- 1.622002956867218
- 1.6640465784072875
- 3.507981925010681
- 1.6562249660491943
- 3.3968004894256594
- 3.3934588479995726
- 1.6476604294776918
- 1.6397945427894591
- 1.6830268502235413
- 1.6768780636787415
- 1.7143929648399352
- 1.7120189595222473
- 3.5281622886657713
- 1.6613792991638183
- 1.675096833705902
- 1.6810290265083312
- 1.71247389793396
- 1.7220640563964844
- 1.750794186592102
- 1.7429070949554444
- 1.7462357234954835
- 1.7706304121017455
- 3.4759764289855957
- 1.718924901485443
- 1.7104917788505554
- 3.5552813816070556
- 1.7124366068840027
- 1.719114224910736
- 1.7257052206993102
- 3.399626498222351
- 1.6814667749404908
- 3.1455670261383055
- 1.6319065403938293
- 3.3438098096847533
- 1.6236088943481446
- 1.6625176429748536
- 1.6663953280448913
- 1.6591207337379457
- 3.2234735918045043
- 3.378649663925171
- 3.5578404808044435
- 3.1505089521408083
- 3.3398255062103273
- 1.5091975283622743
- 1.5529264068603517
- 1.5771226263046265
- 3.210497374534607
- 1.5850467610359191
- 1.6033134269714355
- 1.6307447695732116
- 3.267596879005432
- 1.5749391865730287
- 3.10788321018219
- 3.2891302347183227
- 3.2911856508255006
- 1.5157418966293335
- 3.1699516010284423
- 1.5498015546798707
train_accuracy:
- 0.099
- 0.071
- 0.098
- 0.159
- 0.0
- 0.146
- 0.0
- 0.145
- 0.0
- 0.165
- 0.516
- 0.0
- 0.139
- 0.0
- 0.0
- 0.224
- 0.194
- 0.203
- 0.0
- 0.177
- 0.245
- 0.0
- 0.0
- 0.248
- 0.0
- 0.0
- 0.507
- 0.204
- 0.594
- 0.202
- 0.241
- 0.0
- 0.249
- 0.0
- 0.241
- 0.0
- 0.271
- 0.289
- 0.262
- 0.252
- 0.0
- 0.0
- 0.289
- 0.245
- 0.0
- 0.266
- 0.0
- 0.0
- 0.244
- 0.272
- 0.242
- 0.255
- 0.292
- 0.279
- 0.0
- 0.267
- 0.25
- 0.31
- 0.296
- 0.271
- 0.248
- 0.281
- 0.244
- 0.299
- 0.0
- 0.314
- 0.297
- 0.0
- 0.306
- 0.308
- 0.311
- 0.0
- 0.278
- 0.724
- 0.302
- 0.0
- 0.318
- 0.32
- 0.305
- 0.307
- 0.698
- 0.0
- 0.0
- 0.546
- 0.0
- 0.325
- 0.311
- 0.328
- 0.0
- 0.265
- 0.281
- 0.265
- 0.0
- 0.323
- 0.0
- 0.0
- 0.0
- 0.319
- 0.0
- 0.323
train_loss:
- 1.248
- 4.369
- 3.513
- 3.381
- 1.267
- 3.232
- 1.109
- 3.454
- 0.758
- 3.001
- 1.244
- 1.24
- 2.791
- 0.937
- 1.353
- 2.999
- 2.799
- 2.842
- 0.818
- 2.618
- 2.822
- 0.791
- 0.325
- 2.638
- 0.68
- 0.994
- 1.308
- 2.521
- 0.791
- 2.065
- 2.461
- 0.621
- 2.456
- 0.922
- 2.346
- 0.512
- 2.403
- 2.187
- 1.831
- 1.424
- 0.658
- 0.901
- 2.138
- 1.362
- 0.493
- 1.988
- 0.56
- 0.529
- 1.515
- 1.908
- 1.406
- 1.317
- 1.816
- 1.043
- 0.801
- 1.571
- 1.337
- 1.683
- 1.172
- 1.077
- 0.761
- 1.194
- 0.707
- 1.525
- 0.541
- 1.238
- 1.208
- 0.349
- 1.177
- 0.666
- 0.966
- 0.534
- 1.246
- 1.002
- 1.313
- 0.356
- 0.847
- 0.541
- 0.771
- 0.857
- 0.682
- 0.835
- 0.156
- 0.58
- 0.87
- 1.177
- 0.572
- 0.672
- 0.496
- 1.082
- 0.517
- 0.401
- 0.441
- 0.797
- 0.269
- 0.592
- 0.623
- 0.795
- 0.297
- 0.657
unequal: 0
verbose: 1
