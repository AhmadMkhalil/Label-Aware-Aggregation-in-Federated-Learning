avg_train_accuracy: 0.224
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024
- 0.0862
- 0.1065
- 0.1217
- 0.1043
- 0.103
- 0.1338
- 0.1301
- 0.1096
- 0.1101
- 0.1055
- 0.1561
- 0.1695
- 0.183
- 0.1619
- 0.1336
- 0.1433
- 0.188
- 0.195
- 0.1873
- 0.1591
- 0.1509
- 0.1741
- 0.2019
- 0.2124
- 0.2111
- 0.2012
- 0.1216
- 0.1431
- 0.1203
- 0.2078
- 0.1945
- 0.2227
- 0.2144
- 0.223
- 0.2261
- 0.2252
- 0.2253
- 0.232
- 0.2402
- 0.2195
- 0.1665
- 0.2313
- 0.2323
- 0.2407
- 0.2299
- 0.2268
- 0.2459
- 0.174
- 0.1903
- 0.2114
- 0.2226
- 0.2491
- 0.2415
- 0.2486
- 0.2424
- 0.2325
- 0.2214
- 0.228
- 0.2069
- 0.2456
- 0.2554
- 0.2553
- 0.2379
- 0.2514
- 0.2662
- 0.2603
- 0.2635
- 0.2514
- 0.2618
- 0.2566
- 0.2636
- 0.2607
- 0.1829
- 0.2562
- 0.251
- 0.2538
- 0.2357
- 0.2175
- 0.2417
- 0.271
- 0.2638
- 0.2632
- 0.2469
- 0.2676
- 0.259
- 0.2332
- 0.2695
- 0.2763
- 0.272
- 0.2661
- 0.2494
- 0.2417
- 0.1939
- 0.1591
- 0.2715
- 0.2075
- 0.2623
- 0.2568
- 0.2453
test_loss_list:
- 1.9368406677246093
- 1.8128265047073364
- 1.7594312286376954
- 1.7204083800315857
- 1.6743340110778808
- 1.643705723285675
- 1.6388496994972228
- 1.619595432281494
- 1.6731551861763
- 1.5947239685058594
- 1.6248448443412782
- 1.538375186920166
- 1.6124316024780274
- 1.523148329257965
- 1.503059413433075
- 1.5266935729980469
- 1.5232446932792663
- 1.550334804058075
- 1.5390337634086608
- 1.4950167679786681
- 1.5010445237159729
- 1.5358362674713135
- 1.4493352246284485
- 1.4515859127044677
- 1.456885368824005
- 1.4587196135520935
- 1.454356575012207
- 1.6241177701950074
- 1.5415867757797241
- 1.609840772151947
- 1.406537537574768
- 1.4362388563156128
- 1.4156085443496704
- 1.5014747619628905
- 1.4743959951400756
- 1.4388938856124878
- 1.4163617134094237
- 1.495080327987671
- 1.4692319107055665
- 1.4259616136550903
- 1.4342681074142456
- 1.5233074307441712
- 1.38111355304718
- 1.4109547662734985
- 1.3695626091957092
- 1.4067123937606811
- 1.362506287097931
- 1.3442715430259704
- 1.484340455532074
- 1.4240093922615051
- 1.366744544506073
- 1.3577705907821656
- 1.332015450000763
- 1.3720282530784607
- 1.3616944575309753
- 1.3886298274993896
- 1.3964046907424927
- 1.3744261908531188
- 1.3564511227607727
- 1.436708984375
- 1.4105985903739928
- 1.3942955756187438
- 1.3384124302864076
- 1.3663118600845336
- 1.3616437268257142
- 1.3579404950141907
- 1.3905468106269836
- 1.3093300724029542
- 1.357920069694519
- 1.376149787902832
- 1.3998379778862
- 1.3188489174842835
- 1.321923065185547
- 1.493656930923462
- 1.3181065249443054
- 1.3292434287071229
- 1.3260492849349976
- 1.3638083386421203
- 1.4225648713111878
- 1.3592086744308471
- 1.3153329181671143
- 1.3420442867279052
- 1.3275859904289247
- 1.3477988982200622
- 1.2986964654922486
- 1.3394531679153443
- 1.4014232492446899
- 1.330451662540436
- 1.3077237939834594
- 1.3461474013328552
- 1.3864059662818908
- 1.3786972451210022
- 1.3799758887290954
- 1.5011219954490662
- 1.6562858605384827
- 1.3293005108833313
- 1.4472554397583008
- 1.326735188961029
- 1.3585776042938233
- 1.3911667561531067
train_accuracy:
- 0.119
- 0.102
- 0.121
- 0.142
- 0.0
- 0.0
- 0.21
- 0.2
- 0.253
- 0.0
- 0.0
- 0.0
- 0.177
- 0.196
- 0.15
- 0.0
- 0.125
- 0.253
- 0.216
- 0.197
- 0.0
- 0.13
- 0.0
- 0.181
- 0.234
- 0.233
- 0.42
- 0.0
- 0.115
- 0.0
- 0.0
- 0.17
- 0.297
- 0.25
- 0.245
- 0.072
- 0.282
- 0.28
- 0.0
- 0.281
- 0.204
- 0.679
- 0.29
- 0.292
- 0.279
- 0.394
- 0.0
- 0.275
- 0.129
- 0.168
- 0.195
- 0.27
- 0.315
- 0.0
- 0.301
- 0.0
- 0.0
- 0.241
- 0.194
- 0.444
- 0.304
- 0.343
- 0.283
- 0.259
- 0.279
- 0.323
- 0.3
- 0.262
- 0.274
- 0.212
- 0.275
- 0.348
- 0.299
- 0.357
- 0.299
- 0.233
- 0.232
- 0.457
- 0.226
- 0.268
- 0.298
- 0.312
- 0.378
- 0.0
- 0.316
- 0.306
- 0.0
- 0.292
- 0.374
- 0.309
- 0.311
- 0.0
- 0.28
- 0.0
- 0.0
- 0.326
- 0.0
- 0.0
- 0.335
- 0.224
train_loss:
- 2.12
- 3.851
- 2.687
- 2.508
- 1.738
- 1.706
- 2.239
- 1.523
- 1.461
- 1.445
- 1.479
- 2.146
- 2.745
- 1.41
- 1.323
- 1.313
- 1.257
- 2.461
- 1.669
- 1.191
- 1.111
- 1.035
- 1.068
- 1.712
- 1.612
- 1.513
- 0.992
- 0.502
- 0.901
- 0.458
- 1.335
- 1.027
- 1.348
- 1.703
- 1.153
- 1.391
- 1.451
- 1.614
- 1.079
- 1.179
- 0.89
- 0.363
- 1.215
- 1.06
- 1.128
- 0.691
- 0.764
- 0.935
- 0.394
- 0.596
- 0.759
- 0.719
- 0.982
- 0.891
- 1.021
- 0.84
- 0.503
- 0.736
- 0.536
- 0.423
- 1.145
- 0.847
- 0.637
- 0.521
- 0.707
- 0.803
- 0.701
- 0.597
- 0.635
- 0.684
- 0.682
- 0.491
- 0.482
- 0.245
- 0.619
- 0.42
- 0.374
- 0.408
- 0.345
- 0.406
- 0.65
- 0.569
- 0.404
- 0.356
- 0.632
- 0.541
- 0.342
- 0.517
- 0.481
- 0.604
- 0.436
- 0.334
- 0.289
- 0.202
- 0.137
- 0.452
- 0.173
- 0.364
- 0.319
- 0.303
unequal: 0
verbose: 1
