avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0301
- 0.0685
- 0.0983
- 0.0932
- 0.1076
- 0.1014
- 0.1243
- 0.1404
- 0.1419
- 0.115
- 0.1337
- 0.1166
- 0.1549
- 0.117
- 0.1664
- 0.1278
- 0.1639
- 0.1257
- 0.1743
- 0.1836
- 0.1792
- 0.1907
- 0.1948
- 0.1974
- 0.2039
- 0.1725
- 0.2026
- 0.1746
- 0.1769
- 0.1767
- 0.1874
- 0.2078
- 0.2106
- 0.2157
- 0.2162
- 0.2195
- 0.2202
- 0.2191
- 0.2281
- 0.2248
- 0.2212
- 0.2278
- 0.2283
- 0.232
- 0.2242
- 0.2134
- 0.2074
- 0.2336
- 0.2112
- 0.2318
- 0.2102
- 0.2399
- 0.217
- 0.2262
- 0.2365
- 0.2224
- 0.2332
- 0.2196
- 0.2398
- 0.2359
- 0.2396
- 0.2206
- 0.2172
- 0.1808
- 0.2342
- 0.2274
- 0.2234
- 0.2482
- 0.2083
- 0.2126
- 0.2074
- 0.2416
- 0.2271
- 0.2246
- 0.2348
- 0.2294
- 0.2482
- 0.2432
- 0.2492
- 0.2441
- 0.2475
- 0.2478
- 0.2494
- 0.2446
- 0.2549
- 0.248
- 0.2539
- 0.2529
- 0.2483
- 0.1909
- 0.247
- 0.2364
- 0.2503
- 0.2597
- 0.2549
- 0.2313
- 0.2536
- 0.2496
- 0.2609
- 0.2595
test_loss_list:
- 1.8986790132522584
- 1.7759073162078858
- 1.7781526279449462
- 1.7364271688461304
- 1.7247565793991089
- 1.6915521955490112
- 1.6798826360702515
- 1.6364214301109314
- 1.6549732446670533
- 1.6522370314598083
- 1.590716519355774
- 1.5938318514823913
- 1.5679126358032227
- 1.6380733680725097
- 1.5247763228416442
- 1.6118866729736328
- 1.5565191650390624
- 1.6182385635375978
- 1.5117179894447326
- 1.5078066205978393
- 1.5275834536552428
- 1.583039207458496
- 1.6213152861595155
- 1.6399064445495606
- 1.5818381643295287
- 1.5887334895133973
- 1.5546789002418517
- 1.6185385394096374
- 1.5521329307556153
- 1.4891166520118713
- 1.440443024635315
- 1.447529227733612
- 1.4679827427864074
- 1.5036373257637023
- 1.4943790197372437
- 1.468768639564514
- 1.4577538990974426
- 1.4627005004882812
- 1.4405987238883973
- 1.4509054803848267
- 1.5220437741279602
- 1.5058076977729797
- 1.4227917838096618
- 1.4112617421150206
- 1.4464700603485108
- 1.454968183040619
- 1.437863414287567
- 1.4154552602767945
- 1.474994535446167
- 1.4774109244346618
- 1.4715235257148742
- 1.3703765773773193
- 1.4351661038398742
- 1.3935556983947754
- 1.3949984407424927
- 1.4151261734962464
- 1.3925648379325866
- 1.4315939879417419
- 1.3911760783195495
- 1.4060244679450988
- 1.3942784595489501
- 1.4302969193458557
- 1.4409423112869262
- 1.5076232862472534
- 1.381978361606598
- 1.4039321756362915
- 1.4118109107017518
- 1.3831383609771728
- 1.4415316081047058
- 1.421045560836792
- 1.445161099433899
- 1.3868950271606446
- 1.4217259740829469
- 1.4164224171638489
- 1.38679550409317
- 1.3998678207397461
- 1.355814573764801
- 1.3979121351242065
- 1.3919338440895082
- 1.3885876178741454
- 1.3743571639060974
- 1.4440421414375306
- 1.4396673774719237
- 1.4846761965751647
- 1.4385993242263795
- 1.4926742911338806
- 1.4181235122680664
- 1.3826279497146607
- 1.4243738865852356
- 1.5618605136871337
- 1.4116297674179077
- 1.4196098923683167
- 1.4128797507286073
- 1.3718328428268434
- 1.40027583360672
- 1.4497132921218872
- 1.4209476685523987
- 1.458663809299469
- 1.409061393737793
- 1.413127942085266
train_accuracy:
- 0.0
- 0.0
- 0.14
- 0.086
- 0.142
- 0.033
- 0.141
- 0.179
- 0.158
- 0.0
- 0.0
- 0.0
- 0.2
- 0.297
- 0.0
- 0.0
- 0.161
- 0.0
- 0.355
- 0.0
- 0.288
- 0.244
- 0.227
- 0.259
- 0.092
- 0.173
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.247
- 0.0
- 0.283
- 0.286
- 0.173
- 0.0
- 0.0
- 0.284
- 0.271
- 0.281
- 0.0
- 0.0
- 0.287
- 0.0
- 0.206
- 0.191
- 0.259
- 0.0
- 0.323
- 0.0
- 0.146
- 0.238
- 0.227
- 0.0
- 0.334
- 0.312
- 0.212
- 0.309
- 0.0
- 0.272
- 0.576
- 0.559
- 0.0
- 0.0
- 0.192
- 0.536
- 0.29
- 0.0
- 0.0
- 0.0
- 0.299
- 0.345
- 0.266
- 0.224
- 0.235
- 0.23
- 0.335
- 0.221
- 0.0
- 0.217
- 0.366
- 0.232
- 0.247
- 0.307
- 0.244
- 0.0
- 0.323
- 0.0
- 0.0
- 0.0
- 0.268
- 0.399
- 0.0
- 0.0
- 0.0
- 0.0
- 0.33
- 0.253
- 0.0
train_loss:
- 2.122
- 2.895
- 3.456
- 1.724
- 2.395
- 1.777
- 2.339
- 2.258
- 2.141
- 1.638
- 1.443
- 1.287
- 2.037
- 0.766
- 2.036
- 1.281
- 1.835
- 0.706
- 1.965
- 1.825
- 1.704
- 2.254
- 2.054
- 1.919
- 1.602
- 0.996
- 1.464
- 0.889
- 1.013
- 1.015
- 1.124
- 1.391
- 1.411
- 1.28
- 1.19
- 1.239
- 1.262
- 1.217
- 1.118
- 0.973
- 1.294
- 1.013
- 0.873
- 1.231
- 0.991
- 0.689
- 0.696
- 0.99
- 0.592
- 1.193
- 0.424
- 1.026
- 0.665
- 0.626
- 0.793
- 0.598
- 0.725
- 0.554
- 0.805
- 0.685
- 0.868
- 0.51
- 0.509
- 0.303
- 0.719
- 0.581
- 0.477
- 0.754
- 0.301
- 0.495
- 0.532
- 0.646
- 0.433
- 0.389
- 0.482
- 0.451
- 0.618
- 0.571
- 0.623
- 0.374
- 0.658
- 0.675
- 0.501
- 0.664
- 0.511
- 0.548
- 0.406
- 0.494
- 0.426
- 0.236
- 0.435
- 0.447
- 0.398
- 0.498
- 0.443
- 0.351
- 0.358
- 0.492
- 0.406
- 0.419
unequal: 0
verbose: 1
