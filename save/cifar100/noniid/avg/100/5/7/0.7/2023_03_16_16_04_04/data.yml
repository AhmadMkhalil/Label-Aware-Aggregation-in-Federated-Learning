avg_train_accuracy: 0.282
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0208
- 0.0475
- 0.0683
- 0.1001
- 0.1164
- 0.1244
- 0.1302
- 0.1383
- 0.1533
- 0.1597
- 0.155
- 0.1615
- 0.1621
- 0.1539
- 0.1645
- 0.179
- 0.1765
- 0.166
- 0.1818
- 0.1934
- 0.1944
- 0.1917
- 0.194
- 0.1969
- 0.1948
- 0.2077
- 0.2002
- 0.2002
- 0.2101
- 0.2071
- 0.2135
- 0.212
- 0.2093
- 0.2117
- 0.2114
- 0.2165
- 0.2209
- 0.2191
- 0.2207
- 0.2238
- 0.2241
- 0.2174
- 0.2163
- 0.2231
- 0.2219
- 0.2246
- 0.2273
- 0.2268
- 0.2295
- 0.2334
- 0.2303
- 0.2278
- 0.2347
- 0.2298
- 0.2329
- 0.2308
- 0.2254
- 0.2297
- 0.2294
- 0.2378
- 0.2291
- 0.2341
- 0.2378
- 0.2418
- 0.2305
- 0.2414
- 0.2422
- 0.2433
- 0.2453
- 0.2427
- 0.2308
- 0.2306
- 0.2448
- 0.2451
- 0.2459
- 0.2487
- 0.252
- 0.2516
- 0.2504
- 0.2509
- 0.2453
- 0.2432
- 0.2528
- 0.2546
- 0.249
- 0.2381
- 0.2465
- 0.2481
- 0.2555
- 0.2457
- 0.2526
- 0.2532
- 0.2404
- 0.254
- 0.2554
- 0.2555
- 0.2567
- 0.2554
- 0.2488
- 0.2609
test_loss_list:
- 1.8775240755081177
- 1.7944095754623413
- 1.739018726348877
- 1.6847633838653564
- 1.6596332097053528
- 1.6331135773658751
- 1.6177743458747864
- 1.5924583768844605
- 1.5803006982803345
- 1.5801533579826355
- 1.5671006441116333
- 1.5335080027580261
- 1.5306315088272096
- 1.5343167996406555
- 1.5119211173057556
- 1.5076194906234741
- 1.498049807548523
- 1.5116808032989502
- 1.4834875392913818
- 1.4773051381111144
- 1.4768257236480713
- 1.4655721974372864
- 1.4677603769302368
- 1.4588433289527893
- 1.4596603965759278
- 1.4508161568641662
- 1.4408499383926392
- 1.447598557472229
- 1.4278305530548097
- 1.4361826419830321
- 1.414340648651123
- 1.427379810810089
- 1.4262265467643738
- 1.4136841583251953
- 1.4173360586166381
- 1.4077577471733094
- 1.4237707376480102
- 1.41625102519989
- 1.3977975940704346
- 1.405548505783081
- 1.3961042308807372
- 1.4030891394615173
- 1.416867744922638
- 1.3979097843170165
- 1.3943120741844177
- 1.3870596694946289
- 1.3894105768203735
- 1.3967446160316468
- 1.3765229988098144
- 1.3803155159950256
- 1.3767534947395326
- 1.3957038831710815
- 1.3822365260124208
- 1.3996255612373352
- 1.3762379312515258
- 1.3925877737998962
- 1.3968224430084228
- 1.3923194932937621
- 1.4118111968040465
- 1.3830192494392395
- 1.394601786136627
- 1.3945283055305482
- 1.3921074438095093
- 1.3897776460647584
- 1.396524260044098
- 1.3794408011436463
- 1.3950109910964965
- 1.378792676925659
- 1.3673338460922242
- 1.3673272728919983
- 1.3936240410804748
- 1.3994979667663574
- 1.3545392322540284
- 1.3732192349433898
- 1.3569414949417113
- 1.3683744668960571
- 1.355722599029541
- 1.3629209470748902
- 1.3591014647483826
- 1.3595849299430847
- 1.3632131481170655
- 1.3745293807983399
- 1.3550186586380004
- 1.3522189617156983
- 1.3643984127044677
- 1.3958903884887695
- 1.3649918961524963
- 1.3647823691368104
- 1.3527135467529297
- 1.3819444489479065
- 1.3554708051681519
- 1.3572489762306212
- 1.3872063064575195
- 1.3659726476669312
- 1.354949038028717
- 1.360145139694214
- 1.3627089643478394
- 1.3812496089935302
- 1.3719762063026428
- 1.3548047733306885
train_accuracy:
- 0.016
- 0.0
- 0.042
- 0.0
- 0.003
- 0.0
- 0.0
- 0.069
- 0.041
- 0.086
- 0.046
- 0.035
- 0.0
- 0.0
- 0.13
- 0.168
- 0.0
- 0.0
- 0.0
- 0.201
- 0.118
- 0.0
- 0.0
- 0.0
- 0.282
- 0.0
- 0.203
- 0.075
- 0.132
- 0.198
- 0.0
- 0.0
- 0.287
- 0.0
- 0.185
- 0.223
- 0.056
- 0.117
- 0.298
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.106
- 0.134
- 0.189
- 0.166
- 0.0
- 0.149
- 0.0
- 0.0
- 0.146
- 0.208
- 0.0
- 0.273
- 0.302
- 0.0
- 0.0
- 0.0
- 0.33
- 0.305
- 0.293
- 0.0
- 0.119
- 0.175
- 0.325
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.149
- 0.315
- 0.273
- 0.103
- 0.304
- 0.279
- 0.25
- 0.0
- 0.146
- 0.0
- 0.256
- 0.0
- 0.0
- 0.172
- 0.14
- 0.15
- 0.217
- 0.233
- 0.0
- 0.0
- 0.274
- 0.095
- 0.311
- 0.0
- 0.161
- 0.086
- 0.282
train_loss:
- 1.894
- 1.854
- 1.682
- 1.939
- 1.817
- 1.504
- 1.39
- 1.434
- 1.616
- 1.296
- 1.561
- 1.254
- 1.181
- 0.888
- 1.142
- 1.314
- 1.105
- 0.787
- 1.043
- 1.248
- 0.98
- 0.964
- 0.919
- 1.161
- 1.143
- 0.885
- 1.06
- 0.666
- 0.863
- 1.004
- 0.792
- 0.914
- 0.91
- 0.78
- 0.731
- 0.898
- 0.575
- 0.707
- 0.853
- 0.526
- 0.651
- 0.647
- 0.622
- 0.767
- 0.487
- 0.627
- 0.573
- 0.588
- 0.563
- 0.56
- 0.548
- 0.421
- 0.553
- 0.422
- 0.649
- 0.636
- 0.62
- 0.518
- 0.595
- 0.488
- 0.569
- 0.554
- 0.47
- 0.435
- 0.36
- 0.524
- 0.424
- 0.5
- 0.409
- 0.397
- 0.303
- 0.306
- 0.453
- 0.374
- 0.454
- 0.426
- 0.362
- 0.358
- 0.41
- 0.346
- 0.333
- 0.321
- 0.34
- 0.315
- 0.3
- 0.236
- 0.306
- 0.371
- 0.306
- 0.237
- 0.351
- 0.293
- 0.218
- 0.278
- 0.264
- 0.321
- 0.323
- 0.314
- 0.221
- 0.296
unequal: 0
verbose: 1
