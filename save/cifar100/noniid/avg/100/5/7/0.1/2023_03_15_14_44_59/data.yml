avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0298
- 0.0343
- 0.0685
- 0.0955
- 0.0257
- 0.1084
- 0.0228
- 0.126
- 0.0248
- 0.0275
- 0.0294
- 0.1268
- 0.1344
- 0.1422
- 0.1514
- 0.1529
- 0.0346
- 0.1591
- 0.0308
- 0.0295
- 0.0324
- 0.0357
- 0.1615
- 0.0288
- 0.0368
- 0.1688
- 0.1674
- 0.1761
- 0.1787
- 0.0345
- 0.1774
- 0.1761
- 0.0319
- 0.1862
- 0.0307
- 0.0368
- 0.0363
- 0.0318
- 0.0322
- 0.1822
- 0.028
- 0.033
- 0.0307
- 0.1827
- 0.031
- 0.0333
- 0.0314
- 0.0316
- 0.1866
- 0.0304
- 0.0338
- 0.0343
- 0.0315
- 0.1823
- 0.0333
- 0.182
- 0.0346
- 0.0402
- 0.0379
- 0.0386
- 0.0394
- 0.04
- 0.0336
- 0.1957
- 0.1966
- 0.0357
- 0.0411
- 0.0306
- 0.0314
- 0.0406
- 0.0321
- 0.0316
- 0.0402
- 0.1972
- 0.202
- 0.0392
- 0.0312
- 0.0355
- 0.0326
- 0.042
- 0.1977
- 0.0434
- 0.042
- 0.0405
- 0.0324
- 0.0325
- 0.0428
- 0.0316
- 0.2042
- 0.0481
- 0.0381
- 0.0359
- 0.0343
- 0.0352
- 0.2046
- 0.2077
- 0.0375
- 0.0338
- 0.0331
- 0.0349
test_loss_list:
- 3.082043228149414
- 3.6909492301940916
- 1.9271392393112183
- 1.9674302339553833
- 3.8604508304595946
- 1.9697850370407104
- 3.8370680618286133
- 1.931886487007141
- 3.796607885360718
- 3.930450496673584
- 3.75708384513855
- 1.9140303993225098
- 1.9383005857467652
- 1.9642972755432129
- 1.9906153678894043
- 2.019486231803894
- 3.7071147632598875
- 1.9342837142944336
- 3.573860778808594
- 3.989538354873657
- 3.9934820461273195
- 3.2842265462875364
- 1.7583762693405152
- 3.7319977474212647
- 3.460144491195679
- 1.7519208812713623
- 1.8102847671508788
- 1.8340256214141846
- 1.8607134437561035
- 3.458062810897827
- 1.8399751281738281
- 1.8933775854110717
- 3.5871810913085938
- 1.8706905364990234
- 3.848701009750366
- 3.5096323013305666
- 3.2832759141922
- 3.4426792907714843
- 3.6056001949310303
- 1.7061734318733215
- 3.821778678894043
- 3.3576391553878784
- 3.6589945220947264
- 1.6735033011436462
- 3.612741026878357
- 3.2870135593414305
- 3.6191596603393554
- 3.7807508277893067
- 1.6866622066497803
- 3.6289902400970457
- 3.6378330516815187
- 3.26661425113678
- 3.5969624519348145
- 1.6935261797904968
- 3.3675197410583495
- 1.7179639363288879
- 3.4644746017456054
- 3.3113409662246704
- 3.139624905586243
- 3.3626694679260254
- 3.423918581008911
- 3.344586744308472
- 3.265207166671753
- 1.6138520216941834
- 1.6786677432060242
- 3.504351177215576
- 3.0227287673950194
- 3.5475139093399046
- 3.435696592330933
- 3.1282411670684813
- 3.650747766494751
- 3.520167770385742
- 3.174920654296875
- 1.5881227040290833
- 1.6480119037628174
- 3.123846254348755
- 3.5683795261383056
- 3.273784976005554
- 3.398674101829529
- 2.959309539794922
- 1.585505771636963
- 3.173165807723999
- 3.4042019271850585
- 3.5093750190734863
- 3.547907485961914
- 3.3547666454315186
- 3.3103344345092776
- 3.491030788421631
- 1.5630732011795043
- 2.8404244947433472
- 2.990010132789612
- 3.2657196521759033
- 3.373692932128906
- 3.5095318603515624
- 1.601032967567444
- 1.6605430579185485
- 3.367925910949707
- 3.344214940071106
- 3.527926115989685
- 3.2632217979431153
train_accuracy:
- 0.0
- 0.577
- 0.099
- 0.135
- 0.0
- 0.137
- 0.164
- 0.199
- 0.222
- 0.0
- 0.509
- 0.191
- 0.198
- 0.191
- 0.229
- 0.188
- 0.486
- 0.235
- 0.415
- 0.0
- 0.0
- 0.447
- 0.254
- 0.0
- 0.579
- 0.235
- 0.248
- 0.235
- 0.278
- 0.566
- 0.256
- 0.239
- 0.539
- 0.274
- 0.0
- 0.486
- 0.432
- 0.461
- 0.0
- 0.267
- 0.0
- 0.578
- 0.0
- 0.254
- 0.0
- 0.541
- 0.0
- 0.0
- 0.251
- 0.0
- 0.0
- 0.556
- 0.0
- 0.271
- 0.0
- 0.274
- 0.0
- 0.677
- 0.581
- 0.541
- 0.673
- 0.589
- 0.552
- 0.292
- 0.282
- 0.0
- 0.653
- 0.0
- 0.0
- 0.582
- 0.0
- 0.0
- 0.669
- 0.285
- 0.33
- 0.566
- 0.0
- 0.557
- 0.0
- 0.658
- 0.277
- 0.619
- 0.664
- 0.691
- 0.0
- 0.0
- 0.668
- 0.0
- 0.319
- 0.608
- 0.598
- 0.621
- 0.569
- 0.635
- 0.301
- 0.286
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 0.96
- 1.308
- 4.139
- 3.375
- 1.432
- 3.216
- 1.609
- 3.326
- 1.183
- 1.367
- 1.174
- 2.926
- 2.77
- 2.539
- 2.37
- 2.156
- 1.307
- 2.549
- 1.095
- 1.445
- 1.143
- 1.331
- 2.304
- 1.162
- 1.072
- 2.469
- 1.763
- 1.951
- 1.765
- 0.973
- 1.851
- 1.321
- 0.767
- 1.767
- 0.96
- 1.065
- 1.11
- 0.85
- 0.929
- 1.66
- 0.961
- 0.807
- 1.104
- 2.043
- 0.711
- 0.759
- 0.605
- 0.241
- 1.545
- 0.681
- 0.806
- 0.643
- 0.618
- 1.242
- 0.485
- 0.964
- 0.503
- 0.885
- 0.967
- 0.302
- 0.591
- 0.492
- 0.686
- 1.794
- 1.519
- 0.483
- 0.643
- 0.736
- 0.966
- 0.512
- 0.576
- 0.605
- 0.407
- 1.177
- 1.248
- 0.489
- 0.542
- 0.432
- 0.675
- 0.561
- 0.972
- 0.569
- 0.145
- 0.111
- 0.52
- 0.537
- 0.342
- 0.716
- 1.354
- 0.357
- 0.512
- 0.124
- 0.094
- 0.089
- 1.554
- 0.9
- 0.497
- 0.537
- 0.108
- 0.576
unequal: 0
verbose: 1
