avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0274
- 0.0743
- 0.0279
- 0.0294
- 0.0869
- 0.0254
- 0.1084
- 0.1282
- 0.0325
- 0.0302
- 0.0242
- 0.0322
- 0.0331
- 0.034
- 0.0299
- 0.034
- 0.034
- 0.0301
- 0.1241
- 0.0287
- 0.0307
- 0.1397
- 0.1395
- 0.0338
- 0.0337
- 0.0335
- 0.1521
- 0.0353
- 0.0354
- 0.0352
- 0.0311
- 0.1562
- 0.0344
- 0.0303
- 0.0354
- 0.032
- 0.1659
- 0.0331
- 0.1619
- 0.0362
- 0.0326
- 0.0297
- 0.0301
- 0.0304
- 0.0297
- 0.0356
- 0.1688
- 0.031
- 0.0324
- 0.0306
- 0.0351
- 0.0304
- 0.0329
- 0.174
- 0.0357
- 0.1782
- 0.1785
- 0.0315
- 0.0357
- 0.0313
- 0.1904
- 0.0352
- 0.0371
- 0.0347
- 0.0337
- 0.031
- 0.0351
- 0.1802
- 0.0322
- 0.0371
- 0.0325
- 0.0363
- 0.1938
- 0.0316
- 0.0374
- 0.0316
- 0.1942
- 0.0417
- 0.0384
- 0.0368
- 0.0319
- 0.0354
- 0.0365
- 0.0363
- 0.1998
- 0.0374
- 0.0364
- 0.1956
- 0.1985
- 0.1995
- 0.1961
- 0.0349
- 0.2007
- 0.0339
- 0.1933
- 0.0462
- 0.0385
- 0.0375
- 0.2111
- 0.0324
test_loss_list:
- 3.1317473030090333
- 1.936745557785034
- 3.660835075378418
- 3.7569600677490236
- 1.9199556112289429
- 3.996744785308838
- 1.9434054374694825
- 1.9567221975326539
- 3.941264247894287
- 3.5853214836120606
- 4.017998704910278
- 3.6832095527648927
- 3.921322202682495
- 4.084172601699829
- 4.033198680877685
- 3.784388055801392
- 3.959448022842407
- 3.922490301132202
- 1.8009908771514893
- 3.7318944835662844
- 3.8710829830169677
- 1.8132869911193847
- 1.8511408519744874
- 3.4825723934173585
- 3.703765449523926
- 3.9016414165496824
- 1.850012378692627
- 3.4813472843170166
- 3.431185073852539
- 3.6505835819244385
- 3.536144094467163
- 1.764574842453003
- 3.394915714263916
- 3.612266321182251
- 3.522936611175537
- 3.716112508773804
- 1.7716206789016724
- 3.491762981414795
- 1.80427104473114
- 3.3323754501342773
- 3.5481518363952635
- 3.6656840324401854
- 3.581909513473511
- 3.805613136291504
- 3.97896466255188
- 3.4754232692718507
- 1.6837039709091186
- 3.4906894302368165
- 3.4278809595108033
- 3.6372564029693604
- 3.2541894912719727
- 3.6990845680236815
- 3.394765329360962
- 1.6453140592575073
- 3.1606717920303344
- 1.6926941466331482
- 1.7414737033843994
- 3.5615353870391844
- 3.2667992639541628
- 3.3794958353042603
- 1.7006770491600036
- 3.253895411491394
- 3.2227044200897215
- 3.5042930698394774
- 3.3696407747268675
- 3.4664912319183347
- 3.6236717319488525
- 1.6408477592468262
- 3.414621753692627
- 3.125861487388611
- 3.4882151603698732
- 3.4407678270339965
- 1.6240644240379334
- 3.376231060028076
- 3.0575208377838137
- 3.307696557044983
- 1.6181079959869384
- 3.0370402431488035
- 3.132125835418701
- 3.350945763587952
- 3.394115743637085
- 3.3658639574050904
- 3.217584977149963
- 3.4291554832458497
- 1.6002596139907836
- 3.1636560440063475
- 3.3134398460388184
- 1.6037756180763245
- 1.6631370377540589
- 1.7019436407089232
- 1.7307514262199402
- 3.2916383266448976
- 1.7103237009048462
- 3.372571783065796
- 1.7320087051391602
- 3.0085963344573976
- 3.1032817935943604
- 3.2371054553985594
- 1.6066620206832887
- 3.334574465751648
train_accuracy:
- 0.0
- 0.11
- 0.312
- 0.526
- 0.141
- 0.0
- 0.165
- 0.233
- 0.0
- 0.42
- 0.0
- 0.397
- 0.0
- 0.0
- 0.0
- 0.484
- 0.0
- 0.0
- 0.146
- 0.0
- 0.0
- 0.214
- 0.178
- 0.425
- 0.444
- 0.509
- 0.249
- 0.0
- 0.526
- 0.0
- 0.475
- 0.222
- 0.0
- 0.0
- 0.0
- 0.0
- 0.286
- 0.477
- 0.276
- 0.626
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.267
- 0.0
- 0.0
- 0.0
- 0.641
- 0.0
- 0.517
- 0.216
- 0.0
- 0.259
- 0.245
- 0.0
- 0.0
- 0.0
- 0.314
- 0.0
- 0.529
- 0.0
- 0.0
- 0.0
- 0.0
- 0.258
- 0.0
- 0.548
- 0.0
- 0.0
- 0.327
- 0.0
- 0.0
- 0.0
- 0.249
- 0.61
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.332
- 0.539
- 0.0
- 0.341
- 0.329
- 0.258
- 0.274
- 0.0
- 0.276
- 0.0
- 0.269
- 0.566
- 0.0
- 0.539
- 0.362
- 0.0
train_loss:
- 1.176
- 4.234
- 1.579
- 1.619
- 3.668
- 1.207
- 3.107
- 2.813
- 1.044
- 1.606
- 1.409
- 1.189
- 0.859
- 0.307
- 0.985
- 1.051
- 0.546
- 1.188
- 3.388
- 0.774
- 1.137
- 2.834
- 2.551
- 0.982
- 0.507
- 0.4
- 2.459
- 0.575
- 0.799
- 0.481
- 1.535
- 2.707
- 0.394
- 0.945
- 0.441
- 0.575
- 2.242
- 1.008
- 1.862
- 0.675
- 0.726
- 1.323
- 1.107
- 0.365
- 0.274
- 0.586
- 1.824
- 0.485
- 0.678
- 0.92
- 0.782
- 0.65
- 1.118
- 2.588
- 0.365
- 2.21
- 1.859
- 0.629
- 0.498
- 0.648
- 1.643
- 0.397
- 0.736
- 0.966
- 0.504
- 0.636
- 0.541
- 2.082
- 0.578
- 0.655
- 0.464
- 0.61
- 1.523
- 0.465
- 0.478
- 0.488
- 1.923
- 0.462
- 0.344
- 0.063
- 0.555
- 0.583
- 0.282
- 0.306
- 1.354
- 0.931
- 0.322
- 1.058
- 0.684
- 1.471
- 1.494
- 0.459
- 1.271
- 0.486
- 1.032
- 0.538
- 0.386
- 0.885
- 1.0
- 0.382
unequal: 0
verbose: 1
