avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0339
- 0.0874
- 0.1094
- 0.1231
- 0.1427
- 0.1528
- 0.1601
- 0.1639
- 0.1723
- 0.1792
- 0.1768
- 0.1868
- 0.1955
- 0.1984
- 0.2024
- 0.2088
- 0.2126
- 0.2151
- 0.2186
- 0.226
- 0.2319
- 0.2314
- 0.2327
- 0.2392
- 0.2399
- 0.2475
- 0.2457
- 0.2475
- 0.2512
- 0.2513
- 0.2536
- 0.2535
- 0.2545
- 0.2551
- 0.2599
- 0.2612
- 0.2618
- 0.26
- 0.2659
- 0.2681
- 0.2659
- 0.2662
- 0.271
- 0.2695
- 0.2727
- 0.271
- 0.2778
- 0.2781
- 0.2732
- 0.2824
- 0.28
- 0.2795
- 0.2813
- 0.2825
- 0.2851
- 0.283
- 0.2879
- 0.2886
- 0.2857
- 0.2887
- 0.2873
- 0.2889
- 0.2943
- 0.2941
- 0.2935
- 0.2941
- 0.2953
- 0.296
- 0.2954
- 0.2962
- 0.2972
- 0.2981
- 0.2993
- 0.2982
- 0.2969
- 0.2957
- 0.3029
- 0.3013
- 0.3055
- 0.3006
- 0.2984
- 0.2996
- 0.3041
- 0.3026
- 0.3058
- 0.3053
- 0.3009
- 0.3069
- 0.3071
- 0.3019
- 0.3038
- 0.306
- 0.3021
- 0.3017
- 0.3069
- 0.3049
- 0.305
- 0.3044
- 0.3047
- 0.3065
test_loss_list:
- 1.8304994630813598
- 1.7194890689849853
- 1.641934974193573
- 1.5925221538543701
- 1.5797667479515076
- 1.5702652907371522
- 1.537668490409851
- 1.5363828682899474
- 1.5345925498008728
- 1.4873949813842773
- 1.4577688574790955
- 1.4477197265625
- 1.4240090489387511
- 1.4331335043907165
- 1.470967001914978
- 1.4847553706169128
- 1.4569439458847047
- 1.433305423259735
- 1.432910702228546
- 1.4599775981903076
- 1.3962197017669677
- 1.4084009265899657
- 1.3696455192565917
- 1.368859360218048
- 1.3465523147583007
- 1.3289648056030274
- 1.3504406094551087
- 1.35268883228302
- 1.3664752769470214
- 1.3102788949012756
- 1.3137627363204956
- 1.3051734066009522
- 1.3125669384002685
- 1.3584171104431153
- 1.3060036563873292
- 1.3040606713294982
- 1.2841281270980835
- 1.3432329726219177
- 1.3256830048561097
- 1.3325902247428894
- 1.3668525576591493
- 1.3335304522514344
- 1.2881418371200561
- 1.3419050097465515
- 1.2808686351776124
- 1.266872980594635
- 1.2596851801872253
- 1.2610548639297485
- 1.2725459218025208
- 1.2842150568962096
- 1.2919828939437865
- 1.2860337400436401
- 1.29176034450531
- 1.2498841905593872
- 1.264607331752777
- 1.3171627259254455
- 1.2547954392433167
- 1.2469627380371093
- 1.2992062592506408
- 1.2892032432556153
- 1.2775099515914916
- 1.2821168041229247
- 1.2376746225357056
- 1.2609267830848694
- 1.261057937145233
- 1.2608754134178162
- 1.244566798210144
- 1.2402975010871886
- 1.2875624465942384
- 1.2731732487678529
- 1.2571724629402161
- 1.2613710975646972
- 1.2674028706550597
- 1.263105115890503
- 1.276076169013977
- 1.3129789519309998
- 1.262043421268463
- 1.2813941168785095
- 1.268817174434662
- 1.2442088556289672
- 1.2584373545646668
- 1.2623884057998658
- 1.2480228924751282
- 1.2376481461524964
- 1.230766978263855
- 1.2384338402748107
- 1.2873990797996522
- 1.2399090480804444
- 1.245723114013672
- 1.2416761136054992
- 1.2376299738883971
- 1.2354553484916686
- 1.2498829460144043
- 1.2429744267463685
- 1.2487961888313293
- 1.2673694729804992
- 1.2432996201515198
- 1.237416410446167
- 1.2443348479270935
- 1.2354128861427307
train_accuracy:
- 0.035
- 0.084
- 0.108
- 0.0
- 0.185
- 0.0
- 0.171
- 0.159
- 0.0
- 0.0
- 0.0
- 0.187
- 0.217
- 0.256
- 0.259
- 0.252
- 0.26
- 0.255
- 0.266
- 0.227
- 0.0
- 0.0
- 0.238
- 0.281
- 0.0
- 0.0
- 0.291
- 0.0
- 0.299
- 0.0
- 0.249
- 0.259
- 0.0
- 0.316
- 0.276
- 0.0
- 0.0
- 0.287
- 0.273
- 0.278
- 0.289
- 0.301
- 0.314
- 0.299
- 0.0
- 0.32
- 0.0
- 0.288
- 0.0
- 0.339
- 0.0
- 0.0
- 0.0
- 0.299
- 0.0
- 0.324
- 0.0
- 0.0
- 0.346
- 0.282
- 0.0
- 0.291
- 0.0
- 0.0
- 0.334
- 0.295
- 0.324
- 0.301
- 0.361
- 0.328
- 0.0
- 0.268
- 0.32
- 0.0
- 0.333
- 0.328
- 0.0
- 0.317
- 0.0
- 0.336
- 0.33
- 0.351
- 0.314
- 0.251
- 0.29
- 0.315
- 0.352
- 0.0
- 0.288
- 0.0
- 0.35
- 0.0
- 0.256
- 0.303
- 0.299
- 0.0
- 0.339
- 0.0
- 0.307
- 0.0
train_loss:
- 2.979
- 2.663
- 3.113
- 2.397
- 2.769
- 2.688
- 2.145
- 2.545
- 2.428
- 2.088
- 1.557
- 1.883
- 1.948
- 2.266
- 2.531
- 2.437
- 2.04
- 1.946
- 1.881
- 2.183
- 1.576
- 1.813
- 1.493
- 1.782
- 1.429
- 1.457
- 1.65
- 1.576
- 1.551
- 1.103
- 1.245
- 1.235
- 1.181
- 1.718
- 1.15
- 1.145
- 1.166
- 1.572
- 1.295
- 1.211
- 1.373
- 1.159
- 1.089
- 1.303
- 0.995
- 0.984
- 0.9
- 0.863
- 0.86
- 1.034
- 0.977
- 0.982
- 1.005
- 0.693
- 0.914
- 1.022
- 0.749
- 0.593
- 0.963
- 0.83
- 0.883
- 0.807
- 0.678
- 0.756
- 0.627
- 0.779
- 0.582
- 0.465
- 0.803
- 0.693
- 0.52
- 0.479
- 0.631
- 0.518
- 0.621
- 0.676
- 0.549
- 0.592
- 0.466
- 0.476
- 0.55
- 0.559
- 0.433
- 0.389
- 0.415
- 0.432
- 0.561
- 0.392
- 0.377
- 0.315
- 0.37
- 0.35
- 0.281
- 0.326
- 0.427
- 0.39
- 0.419
- 0.369
- 0.344
- 0.387
unequal: 0
verbose: 1
