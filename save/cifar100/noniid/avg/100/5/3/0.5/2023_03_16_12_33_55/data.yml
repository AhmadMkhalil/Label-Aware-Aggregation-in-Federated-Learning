avg_train_accuracy: 0.336
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0296
- 0.0986
- 0.1156
- 0.1303
- 0.1422
- 0.1502
- 0.1648
- 0.1724
- 0.1742
- 0.1809
- 0.1834
- 0.1933
- 0.1966
- 0.204
- 0.2057
- 0.2111
- 0.217
- 0.2153
- 0.2211
- 0.2223
- 0.2256
- 0.2309
- 0.2284
- 0.2317
- 0.2393
- 0.2368
- 0.2411
- 0.2407
- 0.2453
- 0.2496
- 0.2513
- 0.248
- 0.2543
- 0.25
- 0.256
- 0.2551
- 0.2579
- 0.2563
- 0.2628
- 0.2651
- 0.2641
- 0.2687
- 0.2624
- 0.2641
- 0.2671
- 0.2667
- 0.2706
- 0.2693
- 0.2686
- 0.2717
- 0.2744
- 0.2753
- 0.2815
- 0.2754
- 0.2809
- 0.2854
- 0.2869
- 0.2848
- 0.2803
- 0.278
- 0.2835
- 0.2848
- 0.2902
- 0.2861
- 0.2872
- 0.2881
- 0.2854
- 0.2866
- 0.2865
- 0.2949
- 0.2883
- 0.2923
- 0.2886
- 0.2884
- 0.2903
- 0.2888
- 0.2939
- 0.2949
- 0.2939
- 0.2945
- 0.2959
- 0.2953
- 0.2924
- 0.2943
- 0.2936
- 0.2976
- 0.2989
- 0.2979
- 0.2958
- 0.2933
- 0.3007
- 0.3021
- 0.3035
- 0.3019
- 0.3084
- 0.3011
- 0.3048
- 0.3063
- 0.3067
- 0.3023
test_loss_list:
- 1.814236512184143
- 1.7124200916290284
- 1.641003646850586
- 1.642895176410675
- 1.6114180827140807
- 1.5824478125572206
- 1.5312830805778503
- 1.505259897708893
- 1.4809753942489623
- 1.4862046313285828
- 1.4851003527641295
- 1.45979163646698
- 1.4372426962852478
- 1.4273100566864014
- 1.4694854068756102
- 1.4186817765235902
- 1.3905105090141296
- 1.4054282450675963
- 1.3777018070220948
- 1.4261083388328553
- 1.408652482032776
- 1.4020158743858337
- 1.4362750816345216
- 1.4051535677909852
- 1.3672354960441588
- 1.4148180818557738
- 1.392166178226471
- 1.4002118992805481
- 1.3271774125099183
- 1.3211429905891419
- 1.3469156646728515
- 1.3883209538459778
- 1.300490641593933
- 1.3341869950294494
- 1.372489731311798
- 1.3515748524665832
- 1.294544644355774
- 1.3280614972114564
- 1.2884798288345336
- 1.2895560669898987
- 1.2870178365707396
- 1.2944774889945985
- 1.3148104858398437
- 1.3057003045082092
- 1.3105209422111512
- 1.3125685501098632
- 1.2814048647880554
- 1.3089494943618774
- 1.326183159351349
- 1.2854833221435547
- 1.3021041774749755
- 1.2743294715881348
- 1.263466854095459
- 1.3244110655784607
- 1.246562762260437
- 1.259211025238037
- 1.2534858322143554
- 1.2522744560241699
- 1.2829408216476441
- 1.2819163489341736
- 1.2974294829368591
- 1.2502593994140625
- 1.2543090343475343
- 1.2745396828651427
- 1.271151282787323
- 1.2457616305351258
- 1.305568244457245
- 1.286538667678833
- 1.2466741752624513
- 1.2455852842330932
- 1.3070091223716735
- 1.2584079813957214
- 1.2719266033172607
- 1.2814197278022765
- 1.280079996585846
- 1.2752366399765014
- 1.2429203057289124
- 1.269048538208008
- 1.2718334531784057
- 1.2862398219108582
- 1.2621266436576843
- 1.2856946277618408
- 1.2977769041061402
- 1.2719423174858093
- 1.282692894935608
- 1.264828200340271
- 1.243018138408661
- 1.2543856763839722
- 1.270633451938629
- 1.2759357738494872
- 1.2717157840728759
- 1.2391773414611817
- 1.2499909496307373
- 1.2413787603378297
- 1.2418372106552125
- 1.2480110025405884
- 1.2434227180480957
- 1.239126045703888
- 1.2431715798377991
- 1.244125189781189
train_accuracy:
- 0.013
- 0.1
- 0.131
- 0.113
- 0.152
- 0.15
- 0.124
- 0.0
- 0.185
- 0.193
- 0.193
- 0.152
- 0.166
- 0.185
- 0.226
- 0.0
- 0.185
- 0.182
- 0.0
- 0.253
- 0.22
- 0.229
- 0.253
- 0.223
- 0.0
- 0.276
- 0.279
- 0.274
- 0.0
- 0.0
- 0.241
- 0.279
- 0.0
- 0.236
- 0.257
- 0.0
- 0.0
- 0.238
- 0.293
- 0.285
- 0.259
- 0.274
- 0.289
- 0.283
- 0.0
- 0.313
- 0.308
- 0.27
- 0.256
- 0.0
- 0.286
- 0.31
- 0.0
- 0.318
- 0.321
- 0.0
- 0.0
- 0.293
- 0.284
- 0.297
- 0.299
- 0.321
- 0.0
- 0.317
- 0.26
- 0.0
- 0.29
- 0.298
- 0.308
- 0.0
- 0.32
- 0.0
- 0.304
- 0.297
- 0.308
- 0.329
- 0.305
- 0.283
- 0.37
- 0.285
- 0.0
- 0.277
- 0.312
- 0.285
- 0.32
- 0.321
- 0.262
- 0.328
- 0.0
- 0.314
- 0.359
- 0.274
- 0.284
- 0.276
- 0.0
- 0.277
- 0.278
- 0.353
- 0.0
- 0.336
train_loss:
- 2.921
- 3.818
- 2.55
- 3.407
- 2.754
- 2.662
- 2.133
- 2.081
- 2.063
- 2.357
- 2.323
- 1.853
- 1.402
- 1.737
- 2.572
- 1.747
- 1.333
- 2.053
- 1.277
- 2.298
- 1.881
- 1.834
- 2.138
- 1.76
- 1.366
- 1.982
- 1.688
- 1.57
- 1.413
- 1.26
- 1.469
- 1.692
- 1.008
- 1.461
- 1.578
- 1.352
- 1.194
- 1.29
- 1.105
- 1.05
- 1.032
- 0.934
- 1.193
- 1.153
- 1.08
- 1.138
- 0.974
- 1.066
- 1.008
- 0.888
- 1.05
- 0.819
- 0.817
- 1.077
- 0.631
- 0.58
- 0.805
- 0.694
- 0.853
- 0.846
- 0.796
- 0.649
- 0.677
- 0.596
- 0.629
- 0.682
- 0.901
- 0.726
- 0.609
- 0.617
- 0.813
- 0.556
- 0.635
- 0.675
- 0.59
- 0.571
- 0.544
- 0.636
- 0.555
- 0.586
- 0.489
- 0.533
- 0.545
- 0.528
- 0.528
- 0.427
- 0.362
- 0.496
- 0.455
- 0.464
- 0.475
- 0.374
- 0.342
- 0.372
- 0.376
- 0.336
- 0.38
- 0.36
- 0.317
- 0.319
unequal: 0
verbose: 1
