avg_train_accuracy: 0.33
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0263
- 0.0866
- 0.1168
- 0.1312
- 0.1396
- 0.152
- 0.1586
- 0.1708
- 0.1752
- 0.1825
- 0.1951
- 0.1989
- 0.2056
- 0.2091
- 0.2108
- 0.2186
- 0.2188
- 0.2227
- 0.2284
- 0.2317
- 0.2328
- 0.2408
- 0.246
- 0.2429
- 0.2456
- 0.2496
- 0.2494
- 0.2489
- 0.2483
- 0.2543
- 0.2582
- 0.2638
- 0.264
- 0.265
- 0.264
- 0.2621
- 0.2693
- 0.2726
- 0.2757
- 0.274
- 0.2788
- 0.2732
- 0.2735
- 0.2782
- 0.2775
- 0.2755
- 0.281
- 0.2774
- 0.2791
- 0.2816
- 0.282
- 0.2836
- 0.288
- 0.2919
- 0.2941
- 0.2951
- 0.2936
- 0.2969
- 0.2972
- 0.2931
- 0.2945
- 0.298
- 0.2973
- 0.2961
- 0.2955
- 0.3039
- 0.2989
- 0.2972
- 0.298
- 0.3049
- 0.3012
- 0.3019
- 0.2995
- 0.3078
- 0.3088
- 0.3045
- 0.3044
- 0.3064
- 0.3115
- 0.3108
- 0.3122
- 0.3039
- 0.3079
- 0.3129
- 0.3038
- 0.3095
- 0.3025
- 0.3037
- 0.3073
- 0.302
- 0.3132
- 0.312
- 0.3092
- 0.3133
- 0.3116
- 0.3064
- 0.3148
- 0.3168
- 0.3159
- 0.3168
test_loss_list:
- 1.8294693517684937
- 1.7300268125534057
- 1.7009496545791627
- 1.6523297238349914
- 1.629230136871338
- 1.5872214317321778
- 1.5362853813171387
- 1.498133089542389
- 1.4991575121879577
- 1.4764946150779723
- 1.477342746257782
- 1.4318362760543824
- 1.4412190079689027
- 1.4469137597084045
- 1.4754182505607605
- 1.4441432547569275
- 1.4422606992721558
- 1.442924313545227
- 1.3719023036956788
- 1.3863876223564149
- 1.386825771331787
- 1.3763221144676208
- 1.3483337759971619
- 1.32987455368042
- 1.3482530546188354
- 1.3522790002822875
- 1.3197307395935058
- 1.3067182111740112
- 1.3137377309799194
- 1.2974032878875732
- 1.2890185928344726
- 1.2879926371574402
- 1.284762191772461
- 1.2820300269126892
- 1.3091514348983764
- 1.308911190032959
- 1.2688976287841798
- 1.2708327054977417
- 1.2606374955177306
- 1.2651931190490722
- 1.2606568074226379
- 1.276058645248413
- 1.2919980835914613
- 1.2461040568351747
- 1.267829613685608
- 1.2859740161895752
- 1.266973741054535
- 1.3157874679565429
- 1.2907708835601808
- 1.2976300930976867
- 1.2419585943222047
- 1.307793686389923
- 1.2857283663749695
- 1.2574139404296876
- 1.2283039093017578
- 1.2274797368049621
- 1.2407082200050354
- 1.2267171049118042
- 1.2295505261421205
- 1.245012526512146
- 1.2629037952423097
- 1.233679792881012
- 1.2516815972328186
- 1.2665272235870362
- 1.2692442560195922
- 1.2160272669792176
- 1.245605411529541
- 1.2880635023117066
- 1.2662229323387146
- 1.2375011682510375
- 1.2220508456230164
- 1.238369164466858
- 1.2480692267417908
- 1.2315148282051087
- 1.2376794815063477
- 1.2152493119239807
- 1.2357135033607483
- 1.2301572036743165
- 1.2141630363464355
- 1.2178360676765443
- 1.2039992141723632
- 1.240494477748871
- 1.2403515362739563
- 1.2194937682151794
- 1.2802365040779113
- 1.2302266025543214
- 1.2933063101768494
- 1.3112108707427979
- 1.235522894859314
- 1.2971766376495362
- 1.2257426357269288
- 1.2115134549140931
- 1.2409194946289062
- 1.2204986810684204
- 1.2319834280014037
- 1.2759711122512818
- 1.2260568833351135
- 1.2117065787315369
- 1.2166186833381654
- 1.2190556693077088
train_accuracy:
- 0.035
- 0.108
- 0.146
- 0.159
- 0.178
- 0.186
- 0.198
- 0.0
- 0.204
- 0.164
- 0.214
- 0.17
- 0.233
- 0.213
- 0.195
- 0.231
- 0.0
- 0.233
- 0.251
- 0.212
- 0.273
- 0.255
- 0.221
- 0.0
- 0.277
- 0.27
- 0.268
- 0.0
- 0.0
- 0.252
- 0.0
- 0.23
- 0.0
- 0.283
- 0.295
- 0.291
- 0.282
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.283
- 0.317
- 0.308
- 0.305
- 0.306
- 0.0
- 0.307
- 0.307
- 0.321
- 0.296
- 0.0
- 0.341
- 0.0
- 0.28
- 0.0
- 0.298
- 0.0
- 0.321
- 0.329
- 0.0
- 0.0
- 0.336
- 0.0
- 0.341
- 0.332
- 0.299
- 0.313
- 0.314
- 0.319
- 0.335
- 0.0
- 0.334
- 0.349
- 0.354
- 0.0
- 0.0
- 0.0
- 0.331
- 0.321
- 0.34
- 0.331
- 0.341
- 0.36
- 0.337
- 0.354
- 0.0
- 0.343
- 0.327
- 0.33
- 0.338
- 0.0
- 0.0
- 0.35
- 0.301
- 0.0
- 0.0
- 0.33
train_loss:
- 3.657
- 3.258
- 3.571
- 2.881
- 2.703
- 2.733
- 2.253
- 2.132
- 2.474
- 1.996
- 2.32
- 1.937
- 2.221
- 2.178
- 2.444
- 2.05
- 1.973
- 1.89
- 1.691
- 1.885
- 1.862
- 1.821
- 1.506
- 1.442
- 1.709
- 1.64
- 1.377
- 1.018
- 0.983
- 1.205
- 1.303
- 1.248
- 0.933
- 1.21
- 1.435
- 1.419
- 0.888
- 1.111
- 1.073
- 1.07
- 1.073
- 1.274
- 1.22
- 0.776
- 1.161
- 1.113
- 0.961
- 1.319
- 1.089
- 1.051
- 0.871
- 1.192
- 0.979
- 0.813
- 0.796
- 0.585
- 0.944
- 0.735
- 0.723
- 0.869
- 0.824
- 0.668
- 0.788
- 0.757
- 0.782
- 0.528
- 0.733
- 0.838
- 0.728
- 0.598
- 0.591
- 0.658
- 0.629
- 0.577
- 0.495
- 0.508
- 0.597
- 0.471
- 0.505
- 0.477
- 0.466
- 0.545
- 0.527
- 0.437
- 0.63
- 0.411
- 0.591
- 0.55
- 0.402
- 0.537
- 0.38
- 0.438
- 0.42
- 0.409
- 0.426
- 0.47
- 0.361
- 0.283
- 0.319
- 0.327
unequal: 0
verbose: 1
