avg_train_accuracy: 0.321
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0266
- 0.0752
- 0.1069
- 0.1078
- 0.1277
- 0.1499
- 0.1556
- 0.1684
- 0.1772
- 0.1837
- 0.1866
- 0.1915
- 0.2003
- 0.2015
- 0.2088
- 0.2075
- 0.2138
- 0.2128
- 0.2199
- 0.2231
- 0.226
- 0.2251
- 0.2311
- 0.2331
- 0.2338
- 0.2369
- 0.2414
- 0.2411
- 0.2457
- 0.2484
- 0.2496
- 0.2548
- 0.2558
- 0.254
- 0.2576
- 0.2592
- 0.2648
- 0.2607
- 0.268
- 0.2716
- 0.2733
- 0.2716
- 0.2679
- 0.2759
- 0.2772
- 0.2802
- 0.28
- 0.2795
- 0.2807
- 0.284
- 0.2868
- 0.2829
- 0.2797
- 0.2854
- 0.2878
- 0.2873
- 0.2824
- 0.2885
- 0.2885
- 0.2914
- 0.2916
- 0.2903
- 0.2957
- 0.2976
- 0.2899
- 0.2945
- 0.2937
- 0.2889
- 0.2918
- 0.2944
- 0.2976
- 0.2918
- 0.303
- 0.2892
- 0.2996
- 0.2985
- 0.301
- 0.2979
- 0.2974
- 0.2978
- 0.2979
- 0.3004
- 0.2979
- 0.2979
- 0.3015
- 0.304
- 0.3101
- 0.3026
- 0.3026
- 0.3063
- 0.3082
- 0.3101
- 0.3058
- 0.3058
- 0.3077
- 0.3054
- 0.3077
- 0.3042
- 0.3081
- 0.3052
test_loss_list:
- 1.8403018951416015
- 1.7036845254898072
- 1.6460646438598632
- 1.60185631275177
- 1.5727151179313659
- 1.5446440982818603
- 1.5427556228637695
- 1.5348204445838929
- 1.502071840763092
- 1.5269864845275878
- 1.4664168334007264
- 1.4704660868644714
- 1.4995515108108521
- 1.4361695194244384
- 1.4776567649841308
- 1.4149564504623413
- 1.4204021716117858
- 1.3805366587638854
- 1.3820707678794861
- 1.3788672018051147
- 1.3803917860984802
- 1.3861519289016724
- 1.3547958540916443
- 1.408499937057495
- 1.389631872177124
- 1.3914172387123107
- 1.356731779575348
- 1.3524590921401978
- 1.3622847867012025
- 1.3293369865417481
- 1.3160454058647155
- 1.325122721195221
- 1.3012432193756103
- 1.3325628113746644
- 1.2929482626914979
- 1.2974656176567079
- 1.2988710737228393
- 1.2873986315727235
- 1.2856049156188964
- 1.2881942176818848
- 1.2729079556465148
- 1.3011406564712524
- 1.3067896223068238
- 1.27056165933609
- 1.2687590193748475
- 1.260537612438202
- 1.2860381531715392
- 1.25133873462677
- 1.2562872052192688
- 1.2648890376091004
- 1.2660577058792115
- 1.2928713154792786
- 1.328986692428589
- 1.264028594493866
- 1.2443841338157653
- 1.2431316518783568
- 1.247785804271698
- 1.2596073389053344
- 1.2654353976249695
- 1.2497405099868775
- 1.2402287650108337
- 1.2933264231681825
- 1.236525332927704
- 1.231530990600586
- 1.2515539455413818
- 1.2549558782577515
- 1.2648802089691162
- 1.2774569392204285
- 1.2882068490982055
- 1.2750388169288636
- 1.260597631931305
- 1.236011447906494
- 1.2209021830558777
- 1.292620425224304
- 1.2394428324699402
- 1.2429975771903992
- 1.2527978348731994
- 1.2254508686065675
- 1.2834589004516601
- 1.2404294681549073
- 1.2538713383674622
- 1.2431449222564697
- 1.2457300901412964
- 1.25615430355072
- 1.2496212100982667
- 1.2418555283546449
- 1.2381363916397095
- 1.2200718998908997
- 1.2496060848236084
- 1.236433732509613
- 1.2234177374839783
- 1.2280513405799867
- 1.2472678804397583
- 1.2593363952636718
- 1.2355955696105958
- 1.2470909690856933
- 1.244587185382843
- 1.2816918921470641
- 1.2716892409324645
- 1.254781174659729
train_accuracy:
- 0.032
- 0.0
- 0.139
- 0.117
- 0.147
- 0.156
- 0.195
- 0.147
- 0.0
- 0.184
- 0.187
- 0.208
- 0.205
- 0.0
- 0.206
- 0.237
- 0.215
- 0.202
- 0.206
- 0.21
- 0.239
- 0.0
- 0.26
- 0.271
- 0.225
- 0.231
- 0.227
- 0.262
- 0.294
- 0.0
- 0.245
- 0.29
- 0.0
- 0.28
- 0.0
- 0.274
- 0.266
- 0.0
- 0.238
- 0.282
- 0.262
- 0.264
- 0.324
- 0.283
- 0.0
- 0.0
- 0.0
- 0.274
- 0.305
- 0.0
- 0.0
- 0.0
- 0.347
- 0.282
- 0.0
- 0.302
- 0.281
- 0.286
- 0.287
- 0.338
- 0.275
- 0.315
- 0.285
- 0.0
- 0.0
- 0.0
- 0.3
- 0.327
- 0.326
- 0.0
- 0.284
- 0.307
- 0.308
- 0.307
- 0.0
- 0.34
- 0.331
- 0.299
- 0.3
- 0.32
- 0.309
- 0.288
- 0.291
- 0.311
- 0.317
- 0.293
- 0.344
- 0.306
- 0.32
- 0.297
- 0.314
- 0.32
- 0.333
- 0.363
- 0.0
- 0.324
- 0.0
- 0.313
- 0.33
- 0.321
train_loss:
- 2.99
- 2.683
- 3.091
- 1.87
- 2.333
- 2.772
- 2.626
- 2.534
- 2.026
- 2.872
- 1.961
- 2.314
- 2.607
- 1.821
- 2.475
- 1.752
- 2.01
- 1.259
- 1.551
- 1.574
- 1.491
- 1.421
- 1.567
- 2.15
- 1.786
- 1.703
- 1.392
- 1.631
- 1.566
- 1.306
- 1.224
- 1.554
- 1.218
- 1.461
- 0.914
- 1.131
- 1.14
- 0.863
- 1.019
- 1.066
- 1.078
- 1.225
- 1.215
- 1.003
- 0.937
- 0.955
- 1.077
- 0.975
- 0.858
- 0.839
- 0.808
- 1.082
- 1.154
- 0.782
- 0.821
- 0.815
- 0.636
- 0.908
- 0.871
- 0.697
- 0.735
- 0.979
- 0.666
- 0.672
- 0.586
- 0.603
- 0.757
- 0.783
- 0.74
- 0.71
- 0.558
- 0.624
- 0.541
- 0.767
- 0.568
- 0.656
- 0.621
- 0.428
- 0.704
- 0.488
- 0.593
- 0.444
- 0.585
- 0.542
- 0.538
- 0.433
- 0.408
- 0.433
- 0.475
- 0.405
- 0.405
- 0.366
- 0.469
- 0.423
- 0.362
- 0.425
- 0.341
- 0.476
- 0.373
- 0.393
unequal: 0
verbose: 1
