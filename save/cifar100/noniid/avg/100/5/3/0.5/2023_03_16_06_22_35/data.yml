avg_train_accuracy: 0.307
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0252
- 0.0724
- 0.1058
- 0.1158
- 0.1371
- 0.145
- 0.1563
- 0.1654
- 0.1756
- 0.1831
- 0.1895
- 0.189
- 0.1958
- 0.2023
- 0.2037
- 0.2059
- 0.2063
- 0.2109
- 0.2155
- 0.2222
- 0.2187
- 0.2233
- 0.2327
- 0.2341
- 0.2334
- 0.2399
- 0.2385
- 0.2426
- 0.2368
- 0.2421
- 0.2469
- 0.2478
- 0.2487
- 0.2584
- 0.2567
- 0.2535
- 0.2581
- 0.2565
- 0.2589
- 0.2604
- 0.2582
- 0.2644
- 0.2646
- 0.2677
- 0.2656
- 0.2743
- 0.2749
- 0.2719
- 0.2752
- 0.2747
- 0.2719
- 0.2717
- 0.2693
- 0.2746
- 0.279
- 0.2741
- 0.2777
- 0.2752
- 0.2761
- 0.2747
- 0.2731
- 0.2794
- 0.2862
- 0.2856
- 0.2863
- 0.2891
- 0.2844
- 0.2913
- 0.2882
- 0.282
- 0.2896
- 0.288
- 0.2911
- 0.2907
- 0.2807
- 0.2891
- 0.2808
- 0.2857
- 0.2941
- 0.2927
- 0.2836
- 0.2924
- 0.2992
- 0.2913
- 0.2998
- 0.3003
- 0.2937
- 0.2937
- 0.3009
- 0.2916
- 0.2873
- 0.2983
- 0.2906
- 0.2978
- 0.2986
- 0.2935
- 0.3019
- 0.2987
- 0.2947
- 0.2944
test_loss_list:
- 1.8322701692581176
- 1.7179585695266724
- 1.667891068458557
- 1.6208841323852539
- 1.623121705055237
- 1.5642980790138246
- 1.5376480579376222
- 1.5276851439476014
- 1.5104165983200073
- 1.4635139536857604
- 1.4464571213722228
- 1.461134741306305
- 1.459028296470642
- 1.4326565766334534
- 1.4098835182189942
- 1.4046403026580812
- 1.4188487219810486
- 1.428643078804016
- 1.4184234023094178
- 1.3822788047790526
- 1.4315637731552124
- 1.4100081658363341
- 1.4358348608016969
- 1.4058853387832642
- 1.373714532852173
- 1.34395911693573
- 1.3682029175758361
- 1.348700623512268
- 1.3977653884887695
- 1.3690106511116027
- 1.3592001271247864
- 1.3542135310173036
- 1.346462013721466
- 1.320376811027527
- 1.307774634361267
- 1.317034730911255
- 1.3329172182083129
- 1.343552975654602
- 1.3193566441535949
- 1.2951174545288087
- 1.3174469351768494
- 1.324137201309204
- 1.3178446674346924
- 1.3190293025970459
- 1.2818415474891662
- 1.2797665476799012
- 1.2726140761375426
- 1.2703257775306702
- 1.2745823097229003
- 1.2820061802864076
- 1.2839938473701478
- 1.301586570739746
- 1.3415512537956238
- 1.2871272921562196
- 1.2630759501457214
- 1.288603551387787
- 1.2764162182807923
- 1.29910089969635
- 1.3017256784439086
- 1.2787977743148804
- 1.328358964920044
- 1.3108704805374145
- 1.278923134803772
- 1.3007264947891235
- 1.2584828567504882
- 1.2540500450134278
- 1.2739391446113586
- 1.2658466386795044
- 1.281721396446228
- 1.2778453350067138
- 1.2635679817199708
- 1.256394965648651
- 1.261530818939209
- 1.258146722316742
- 1.3045476913452148
- 1.2862896060943603
- 1.335183126926422
- 1.298248324394226
- 1.271123161315918
- 1.2947488141059875
- 1.2821250438690186
- 1.2600852155685425
- 1.2486519312858582
- 1.264645926952362
- 1.2478015947341918
- 1.2557407903671265
- 1.2712624478340149
- 1.2877390885353088
- 1.2632730460166932
- 1.2714662671089172
- 1.315548198223114
- 1.2594428968429565
- 1.319338092803955
- 1.2587751388549804
- 1.2486176347732545
- 1.2761615228652954
- 1.2763556361198425
- 1.273177146911621
- 1.2796879673004151
- 1.3156324529647827
train_accuracy:
- 0.0
- 0.095
- 0.113
- 0.102
- 0.156
- 0.156
- 0.157
- 0.179
- 0.197
- 0.0
- 0.201
- 0.0
- 0.19
- 0.188
- 0.215
- 0.207
- 0.241
- 0.0
- 0.207
- 0.216
- 0.246
- 0.0
- 0.247
- 0.258
- 0.249
- 0.0
- 0.0
- 0.0
- 0.273
- 0.0
- 0.283
- 0.273
- 0.278
- 0.25
- 0.236
- 0.277
- 0.282
- 0.266
- 0.0
- 0.274
- 0.269
- 0.281
- 0.259
- 0.289
- 0.281
- 0.0
- 0.0
- 0.264
- 0.0
- 0.0
- 0.0
- 0.285
- 0.294
- 0.284
- 0.0
- 0.301
- 0.273
- 0.317
- 0.297
- 0.0
- 0.311
- 0.284
- 0.297
- 0.0
- 0.0
- 0.0
- 0.285
- 0.0
- 0.0
- 0.314
- 0.295
- 0.311
- 0.0
- 0.0
- 0.298
- 0.3
- 0.284
- 0.299
- 0.0
- 0.32
- 0.313
- 0.317
- 0.0
- 0.289
- 0.308
- 0.0
- 0.299
- 0.282
- 0.0
- 0.326
- 0.307
- 0.324
- 0.305
- 0.301
- 0.0
- 0.315
- 0.324
- 0.311
- 0.321
- 0.307
train_loss:
- 2.992
- 2.716
- 3.107
- 2.425
- 3.29
- 2.248
- 2.624
- 2.523
- 2.493
- 2.001
- 1.911
- 2.288
- 2.2
- 1.773
- 1.767
- 1.74
- 2.088
- 2.01
- 1.933
- 1.592
- 2.142
- 1.776
- 2.114
- 1.74
- 1.389
- 1.38
- 1.606
- 1.284
- 1.85
- 1.507
- 1.538
- 1.44
- 1.391
- 1.175
- 0.826
- 1.387
- 1.332
- 1.269
- 1.019
- 1.02
- 1.14
- 1.215
- 1.173
- 1.142
- 0.988
- 0.95
- 0.887
- 0.844
- 0.675
- 0.684
- 0.936
- 1.029
- 1.136
- 0.8
- 0.76
- 0.954
- 0.757
- 0.88
- 0.881
- 0.699
- 0.944
- 0.788
- 0.684
- 0.731
- 0.488
- 0.646
- 0.701
- 0.591
- 0.733
- 0.686
- 0.543
- 0.55
- 0.502
- 0.399
- 0.706
- 0.665
- 0.717
- 0.592
- 0.457
- 0.512
- 0.611
- 0.492
- 0.376
- 0.491
- 0.431
- 0.322
- 0.447
- 0.491
- 0.441
- 0.494
- 0.521
- 0.407
- 0.49
- 0.402
- 0.323
- 0.382
- 0.424
- 0.407
- 0.377
- 0.439
unequal: 0
verbose: 1
