avg_train_accuracy: 0.309
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0272
- 0.0525
- 0.0585
- 0.1118
- 0.1317
- 0.1406
- 0.1554
- 0.1666
- 0.1713
- 0.1793
- 0.1833
- 0.1919
- 0.1924
- 0.1977
- 0.207
- 0.2103
- 0.211
- 0.2227
- 0.226
- 0.2299
- 0.235
- 0.2377
- 0.2367
- 0.2411
- 0.2451
- 0.2473
- 0.2506
- 0.2545
- 0.2557
- 0.2547
- 0.2619
- 0.2585
- 0.2604
- 0.2645
- 0.2685
- 0.2673
- 0.2714
- 0.2731
- 0.2807
- 0.2778
- 0.2716
- 0.2802
- 0.2758
- 0.2828
- 0.2809
- 0.2814
- 0.285
- 0.2882
- 0.284
- 0.2879
- 0.2863
- 0.2904
- 0.2896
- 0.2928
- 0.2924
- 0.2924
- 0.2927
- 0.2934
- 0.2949
- 0.2945
- 0.2961
- 0.2947
- 0.2956
- 0.2965
- 0.3025
- 0.3053
- 0.3059
- 0.3043
- 0.3002
- 0.2975
- 0.3055
- 0.3035
- 0.3044
- 0.3099
- 0.3071
- 0.3097
- 0.3107
- 0.3096
- 0.3058
- 0.3151
- 0.3156
- 0.3093
- 0.3133
- 0.3135
- 0.3144
- 0.3071
- 0.3084
- 0.3111
- 0.3156
- 0.3156
- 0.3155
- 0.3174
- 0.3204
- 0.3201
- 0.3203
- 0.3236
- 0.3156
- 0.3152
- 0.3201
- 0.3169
test_loss_list:
- 1.8402528762817383
- 1.750937385559082
- 1.7079161500930786
- 1.6543909430503845
- 1.6452432584762573
- 1.5749450397491456
- 1.5646922898292541
- 1.5380879497528077
- 1.5298984813690186
- 1.52837539434433
- 1.4937775802612305
- 1.4914766907691956
- 1.4824634885787964
- 1.4432880234718324
- 1.4404906368255614
- 1.47830872297287
- 1.4466252470016479
- 1.4693668961524964
- 1.434910101890564
- 1.3733819222450256
- 1.3831038212776183
- 1.3868428421020509
- 1.3779668879508973
- 1.4158451128005982
- 1.3233808636665345
- 1.3480574250221253
- 1.3588861083984376
- 1.3147388291358948
- 1.331400671005249
- 1.3811972784996032
- 1.32165696144104
- 1.3022321724891663
- 1.319618718624115
- 1.284934344291687
- 1.305423367023468
- 1.285130271911621
- 1.3408718371391297
- 1.2899292707443237
- 1.2936800146102905
- 1.3059118366241456
- 1.303259379863739
- 1.3005544972419738
- 1.3456647443771361
- 1.2789293241500854
- 1.3366810727119445
- 1.2726556277275085
- 1.269666829109192
- 1.2703671193122863
- 1.25262775182724
- 1.274037446975708
- 1.2744287371635437
- 1.282605266571045
- 1.2423843121528626
- 1.2388092589378357
- 1.2662999439239502
- 1.2458667683601379
- 1.233346130847931
- 1.2292022442817687
- 1.2909304666519166
- 1.2760209798812867
- 1.2808747434616088
- 1.2309054327011109
- 1.286607871055603
- 1.2443040275573731
- 1.258808307647705
- 1.217997214794159
- 1.242284255027771
- 1.2602224111557008
- 1.2663192796707152
- 1.237831907272339
- 1.2202466654777526
- 1.2235555529594422
- 1.2745175743103028
- 1.2058537888526917
- 1.2309191584587098
- 1.2354089283943177
- 1.227557110786438
- 1.2169324135780335
- 1.2333418726921082
- 1.2134304904937745
- 1.2086141657829286
- 1.222423083782196
- 1.226148407459259
- 1.2120723581314088
- 1.215298488140106
- 1.271976969242096
- 1.260657262802124
- 1.2311134839057922
- 1.2330388689041138
- 1.2361416506767273
- 1.2073505663871764
- 1.2217022228240966
- 1.2114341473579406
- 1.2108960700035096
- 1.2113960409164428
- 1.2101161694526672
- 1.2671359157562256
- 1.2268730592727661
- 1.2203137040138246
- 1.2627123808860778
train_accuracy:
- 0.024
- 0.0
- 0.02
- 0.108
- 0.137
- 0.163
- 0.0
- 0.184
- 0.2
- 0.189
- 0.176
- 0.16
- 0.0
- 0.0
- 0.0
- 0.199
- 0.189
- 0.227
- 0.0
- 0.235
- 0.256
- 0.0
- 0.244
- 0.235
- 0.0
- 0.231
- 0.284
- 0.0
- 0.256
- 0.287
- 0.237
- 0.263
- 0.248
- 0.254
- 0.266
- 0.235
- 0.26
- 0.0
- 0.272
- 0.275
- 0.274
- 0.309
- 0.288
- 0.0
- 0.298
- 0.295
- 0.267
- 0.0
- 0.0
- 0.283
- 0.274
- 0.297
- 0.326
- 0.0
- 0.29
- 0.283
- 0.0
- 0.264
- 0.331
- 0.296
- 0.292
- 0.0
- 0.298
- 0.287
- 0.341
- 0.298
- 0.295
- 0.0
- 0.293
- 0.0
- 0.28
- 0.0
- 0.335
- 0.0
- 0.0
- 0.31
- 0.306
- 0.0
- 0.27
- 0.302
- 0.285
- 0.271
- 0.345
- 0.0
- 0.3
- 0.328
- 0.328
- 0.314
- 0.325
- 0.304
- 0.0
- 0.293
- 0.345
- 0.0
- 0.0
- 0.311
- 0.312
- 0.0
- 0.0
- 0.309
train_loss:
- 3.038
- 2.189
- 2.038
- 3.638
- 3.346
- 2.288
- 2.656
- 2.621
- 2.471
- 2.388
- 1.927
- 2.286
- 2.251
- 1.865
- 2.201
- 2.434
- 2.044
- 2.311
- 1.969
- 1.588
- 1.872
- 1.793
- 1.746
- 1.999
- 1.163
- 1.7
- 1.68
- 1.348
- 1.545
- 1.787
- 1.27
- 1.187
- 1.474
- 0.895
- 1.339
- 1.061
- 1.602
- 1.084
- 1.016
- 1.27
- 1.212
- 1.159
- 1.306
- 0.94
- 1.294
- 0.862
- 0.848
- 0.842
- 0.665
- 0.943
- 1.004
- 1.03
- 0.855
- 0.763
- 0.896
- 0.718
- 0.598
- 0.768
- 0.989
- 0.798
- 0.768
- 0.555
- 0.875
- 0.581
- 0.763
- 0.645
- 0.731
- 0.658
- 0.623
- 0.568
- 0.447
- 0.514
- 0.733
- 0.485
- 0.418
- 0.58
- 0.472
- 0.488
- 0.447
- 0.514
- 0.431
- 0.352
- 0.565
- 0.441
- 0.382
- 0.568
- 0.5
- 0.385
- 0.494
- 0.494
- 0.394
- 0.35
- 0.384
- 0.379
- 0.398
- 0.361
- 0.477
- 0.335
- 0.291
- 0.465
unequal: 0
verbose: 1
