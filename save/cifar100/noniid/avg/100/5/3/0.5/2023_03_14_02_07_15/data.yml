avg_train_accuracy: 0.312
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027
- 0.1001
- 0.1116
- 0.1311
- 0.1434
- 0.1507
- 0.16
- 0.168
- 0.1727
- 0.1781
- 0.1803
- 0.1879
- 0.1884
- 0.1926
- 0.201
- 0.2075
- 0.2145
- 0.2145
- 0.2157
- 0.2256
- 0.2252
- 0.2345
- 0.2301
- 0.2318
- 0.2342
- 0.2372
- 0.242
- 0.2456
- 0.2474
- 0.2426
- 0.2474
- 0.2505
- 0.253
- 0.2522
- 0.2598
- 0.2571
- 0.261
- 0.2607
- 0.2634
- 0.263
- 0.268
- 0.2691
- 0.2713
- 0.2738
- 0.2735
- 0.2742
- 0.2705
- 0.2749
- 0.2749
- 0.2776
- 0.2752
- 0.2818
- 0.2805
- 0.2809
- 0.2815
- 0.2891
- 0.2889
- 0.2834
- 0.2844
- 0.2921
- 0.2839
- 0.2881
- 0.2882
- 0.2877
- 0.2898
- 0.2929
- 0.2965
- 0.2931
- 0.2887
- 0.2891
- 0.2959
- 0.2913
- 0.2988
- 0.2943
- 0.2903
- 0.2954
- 0.2886
- 0.2956
- 0.2989
- 0.2978
- 0.2964
- 0.2974
- 0.2939
- 0.3015
- 0.3054
- 0.304
- 0.3026
- 0.3001
- 0.3067
- 0.3014
- 0.3034
- 0.304
- 0.3051
- 0.303
- 0.3083
- 0.3028
- 0.3062
- 0.3065
- 0.3062
- 0.3043
test_loss_list:
- 1.8272831487655639
- 1.7125823974609375
- 1.6589171123504638
- 1.6549725151062011
- 1.6108617973327637
- 1.5745094108581543
- 1.5651004362106322
- 1.5041616153717041
- 1.4813191628456115
- 1.4785042595863342
- 1.4676768565177918
- 1.4724312973022462
- 1.4308428835868836
- 1.4178292083740234
- 1.4658654808998108
- 1.4821481966972352
- 1.4513755774497985
- 1.408085389137268
- 1.3770941996574402
- 1.3874850535392762
- 1.3925972008705139
- 1.3766785168647766
- 1.3542293977737427
- 1.3476560044288635
- 1.3503074717521668
- 1.363422794342041
- 1.3678727173805236
- 1.3718945860862732
- 1.3426083111763
- 1.3873492360115052
- 1.402983820438385
- 1.3733560299873353
- 1.308580379486084
- 1.3282412219047546
- 1.3050525307655334
- 1.3277512907981872
- 1.2850602865219116
- 1.2996033096313477
- 1.3163247680664063
- 1.3570851373672486
- 1.335892140865326
- 1.338896689414978
- 1.300749626159668
- 1.263783323764801
- 1.2707575893402099
- 1.2640781450271605
- 1.3179212021827698
- 1.3031502175331116
- 1.2874274063110351
- 1.2765236711502075
- 1.290271644592285
- 1.2990436053276062
- 1.311926782131195
- 1.2517434406280517
- 1.2676126623153687
- 1.2406910228729249
- 1.2390551471710205
- 1.266489119529724
- 1.2638432145118714
- 1.2424288964271546
- 1.2688743376731872
- 1.259835226535797
- 1.2677908444404602
- 1.2424662160873412
- 1.2447618794441224
- 1.2530798935890197
- 1.2318393111228942
- 1.2379510378837586
- 1.2833758282661438
- 1.2709084939956665
- 1.267741310596466
- 1.233037633895874
- 1.2406713151931763
- 1.2472307682037354
- 1.2594303035736083
- 1.2439602398872376
- 1.2968026447296142
- 1.2776257514953613
- 1.2308184671401978
- 1.2555555343627929
- 1.2550400710105896
- 1.268726146221161
- 1.3086396479606628
- 1.2518363642692565
- 1.2289850330352783
- 1.2381188654899598
- 1.2433612513542176
- 1.2510426497459413
- 1.237868766784668
- 1.249007956981659
- 1.26092214345932
- 1.253766553401947
- 1.2492366313934327
- 1.2542818260192872
- 1.2553735613822936
- 1.2454908895492554
- 1.2649880361557007
- 1.2551242804527283
- 1.2695221018791198
- 1.2621684193611145
train_accuracy:
- 0.0
- 0.085
- 0.128
- 0.123
- 0.153
- 0.14
- 0.151
- 0.0
- 0.0
- 0.182
- 0.144
- 0.0
- 0.0
- 0.176
- 0.214
- 0.212
- 0.204
- 0.0
- 0.245
- 0.253
- 0.0
- 0.22
- 0.0
- 0.198
- 0.232
- 0.273
- 0.26
- 0.251
- 0.283
- 0.268
- 0.254
- 0.304
- 0.275
- 0.262
- 0.0
- 0.316
- 0.237
- 0.263
- 0.265
- 0.25
- 0.288
- 0.302
- 0.0
- 0.273
- 0.279
- 0.278
- 0.306
- 0.0
- 0.0
- 0.281
- 0.0
- 0.31
- 0.0
- 0.0
- 0.287
- 0.0
- 0.275
- 0.321
- 0.285
- 0.271
- 0.313
- 0.294
- 0.279
- 0.33
- 0.315
- 0.342
- 0.326
- 0.247
- 0.327
- 0.355
- 0.336
- 0.33
- 0.0
- 0.283
- 0.336
- 0.291
- 0.29
- 0.0
- 0.0
- 0.34
- 0.344
- 0.344
- 0.349
- 0.0
- 0.0
- 0.324
- 0.301
- 0.344
- 0.287
- 0.292
- 0.0
- 0.0
- 0.349
- 0.299
- 0.353
- 0.346
- 0.338
- 0.34
- 0.342
- 0.312
train_loss:
- 3.007
- 3.824
- 2.99
- 3.301
- 2.774
- 2.62
- 2.553
- 2.183
- 1.674
- 2.474
- 1.944
- 2.305
- 1.508
- 1.793
- 2.556
- 2.428
- 2.093
- 1.691
- 1.652
- 1.934
- 1.927
- 1.513
- 1.469
- 1.155
- 1.786
- 1.705
- 1.661
- 1.571
- 1.291
- 1.807
- 1.784
- 1.519
- 1.287
- 1.43
- 1.183
- 1.37
- 0.907
- 1.288
- 1.286
- 1.421
- 1.24
- 1.203
- 1.007
- 0.973
- 0.971
- 0.922
- 1.304
- 1.029
- 0.842
- 1.015
- 0.947
- 0.986
- 0.91
- 0.858
- 0.915
- 0.602
- 0.825
- 0.822
- 0.887
- 0.666
- 0.792
- 0.677
- 0.673
- 0.671
- 0.528
- 0.726
- 0.665
- 0.513
- 0.825
- 0.695
- 0.714
- 0.557
- 0.551
- 0.618
- 0.622
- 0.51
- 0.677
- 0.57
- 0.508
- 0.564
- 0.516
- 0.532
- 0.596
- 0.463
- 0.426
- 0.422
- 0.538
- 0.474
- 0.386
- 0.456
- 0.456
- 0.461
- 0.418
- 0.435
- 0.421
- 0.396
- 0.4
- 0.409
- 0.377
- 0.381
unequal: 0
verbose: 1
