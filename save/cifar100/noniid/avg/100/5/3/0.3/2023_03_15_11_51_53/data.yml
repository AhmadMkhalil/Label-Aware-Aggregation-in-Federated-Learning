avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0421
- 0.0941
- 0.1093
- 0.1252
- 0.1362
- 0.0906
- 0.1494
- 0.1033
- 0.1442
- 0.1582
- 0.1639
- 0.1841
- 0.1756
- 0.1819
- 0.1968
- 0.2012
- 0.2108
- 0.2115
- 0.216
- 0.2087
- 0.224
- 0.2292
- 0.1792
- 0.16
- 0.2166
- 0.2266
- 0.2376
- 0.2132
- 0.2388
- 0.2325
- 0.2409
- 0.2445
- 0.2488
- 0.2475
- 0.2449
- 0.2592
- 0.2481
- 0.2558
- 0.2565
- 0.2617
- 0.2591
- 0.2605
- 0.254
- 0.2652
- 0.2579
- 0.2673
- 0.2602
- 0.2648
- 0.2608
- 0.2743
- 0.2713
- 0.2711
- 0.2698
- 0.2407
- 0.2452
- 0.28
- 0.2794
- 0.2679
- 0.2682
- 0.2767
- 0.2879
- 0.2893
- 0.2875
- 0.2869
- 0.2906
- 0.2799
- 0.2869
- 0.291
- 0.2847
- 0.2903
- 0.2957
- 0.2936
- 0.2929
- 0.2913
- 0.29
- 0.2956
- 0.2954
- 0.2928
- 0.2988
- 0.3002
- 0.2977
- 0.2993
- 0.2963
- 0.293
- 0.3025
- 0.2903
- 0.2941
- 0.293
- 0.302
- 0.2934
- 0.2893
- 0.2654
- 0.2986
- 0.2958
- 0.3014
- 0.3119
- 0.3051
- 0.3051
- 0.2976
- 0.3055
test_loss_list:
- 1.8157267808914184
- 1.7448149251937866
- 1.6938313937187195
- 1.6398644042015076
- 1.5826087641716002
- 1.6531887745857239
- 1.5450541615486144
- 1.626371648311615
- 1.5506406569480895
- 1.546183590888977
- 1.5462803959846496
- 1.4965988421440124
- 1.4903722786903382
- 1.4824166488647461
- 1.4471361637115479
- 1.4734810519218444
- 1.481381390094757
- 1.4935540342330933
- 1.4567266702651978
- 1.4792748999595642
- 1.4123717045783997
- 1.380743842124939
- 1.4603664875030518
- 1.52324152469635
- 1.4061981487274169
- 1.3957943987846375
- 1.4194787645339966
- 1.4224983358383179
- 1.3470008373260498
- 1.3751274585723876
- 1.3577674221992493
- 1.3939019823074341
- 1.3710929703712464
- 1.400631594657898
- 1.3886353588104248
- 1.3391483855247497
- 1.3657519555091857
- 1.3471215796470641
- 1.378127360343933
- 1.359983162879944
- 1.3210944151878357
- 1.3070375394821168
- 1.3214901280403137
- 1.3457240653038025
- 1.31394775390625
- 1.287048053741455
- 1.3009827685356141
- 1.3208762669563294
- 1.3302504086494447
- 1.3436153984069825
- 1.295493676662445
- 1.3063025236129762
- 1.3137776708602906
- 1.3620303535461427
- 1.3149071264266967
- 1.3047073698043823
- 1.3353485941886902
- 1.301461899280548
- 1.3094110584259033
- 1.3226397228240967
- 1.286363492012024
- 1.2746350359916687
- 1.2624278092384338
- 1.3099231696128846
- 1.284801080226898
- 1.312936487197876
- 1.2808148288726806
- 1.315711839199066
- 1.3446106553077697
- 1.350818359851837
- 1.3454109168052673
- 1.3083015894889831
- 1.2408193969726562
- 1.2664057517051697
- 1.294735279083252
- 1.3083550095558167
- 1.3188519382476807
- 1.3403588390350343
- 1.2915016222000122
- 1.2616162252426149
- 1.3062707948684693
- 1.3289929771423339
- 1.3005131196975708
- 1.344622881412506
- 1.288861792087555
- 1.2609798192977906
- 1.2632995128631592
- 1.2873843479156495
- 1.269102737903595
- 1.285815577507019
- 1.3041006970405578
- 1.3622210025787354
- 1.286323938369751
- 1.2880854034423828
- 1.2881483769416808
- 1.2341057634353638
- 1.2870658087730407
- 1.3037037873268127
- 1.2910816168785095
- 1.2840956568717956
train_accuracy:
- 0.054
- 0.152
- 0.0
- 0.0
- 0.198
- 0.0
- 0.108
- 0.08
- 0.162
- 0.098
- 0.18
- 0.138
- 0.15
- 0.153
- 0.275
- 0.21
- 0.252
- 0.243
- 0.0
- 0.195
- 0.257
- 0.295
- 0.0
- 0.114
- 0.202
- 0.0
- 0.238
- 0.0
- 0.202
- 0.171
- 0.223
- 0.279
- 0.0
- 0.302
- 0.279
- 0.0
- 0.28
- 0.0
- 0.294
- 0.0
- 0.284
- 0.194
- 0.263
- 0.316
- 0.0
- 0.309
- 0.0
- 0.0
- 0.297
- 0.294
- 0.0
- 0.0
- 0.306
- 0.0
- 0.0
- 0.327
- 0.229
- 0.0
- 0.0
- 0.331
- 0.312
- 0.0
- 0.219
- 0.241
- 0.0
- 0.284
- 0.0
- 0.251
- 0.285
- 0.334
- 0.309
- 0.301
- 0.0
- 0.0
- 0.268
- 0.405
- 0.349
- 0.351
- 0.0
- 0.0
- 0.345
- 0.418
- 0.362
- 0.304
- 0.342
- 0.0
- 0.294
- 0.295
- 0.324
- 0.294
- 0.344
- 0.0
- 0.22
- 0.0
- 0.0
- 0.355
- 0.358
- 0.316
- 0.295
- 0.0
train_loss:
- 4.192
- 3.69
- 2.754
- 2.632
- 2.55
- 1.549
- 2.461
- 1.572
- 2.183
- 2.07
- 1.985
- 2.14
- 2.094
- 2.024
- 2.036
- 2.634
- 2.504
- 2.339
- 1.702
- 1.634
- 1.812
- 1.678
- 1.09
- 0.96
- 1.516
- 1.628
- 1.938
- 1.077
- 1.438
- 1.479
- 1.358
- 1.777
- 1.491
- 1.692
- 1.193
- 1.465
- 1.18
- 1.135
- 1.632
- 1.298
- 1.258
- 1.205
- 1.0
- 1.372
- 0.719
- 1.111
- 1.093
- 1.012
- 0.942
- 1.237
- 0.727
- 0.862
- 0.845
- 0.734
- 0.568
- 1.147
- 1.26
- 0.564
- 0.756
- 1.075
- 0.853
- 0.73
- 0.907
- 1.053
- 0.794
- 0.697
- 0.809
- 0.899
- 0.809
- 0.855
- 0.846
- 0.679
- 0.473
- 0.583
- 0.578
- 0.731
- 0.7
- 0.717
- 0.518
- 0.572
- 0.656
- 0.62
- 0.517
- 0.55
- 0.5
- 0.44
- 0.508
- 0.403
- 0.492
- 0.387
- 0.391
- 0.267
- 0.44
- 0.483
- 0.354
- 0.519
- 0.441
- 0.379
- 0.331
- 0.444
unequal: 0
verbose: 1
