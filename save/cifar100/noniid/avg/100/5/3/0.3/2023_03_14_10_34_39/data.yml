avg_train_accuracy: 0.335
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0506
- 0.0493
- 0.1006
- 0.1065
- 0.1139
- 0.1441
- 0.134
- 0.1449
- 0.1701
- 0.165
- 0.1819
- 0.1413
- 0.1883
- 0.1783
- 0.1912
- 0.1991
- 0.2038
- 0.2035
- 0.2097
- 0.2225
- 0.1721
- 0.1573
- 0.2119
- 0.1955
- 0.2156
- 0.22
- 0.2319
- 0.2383
- 0.2446
- 0.2352
- 0.2416
- 0.2505
- 0.2445
- 0.2442
- 0.2066
- 0.2064
- 0.2444
- 0.2532
- 0.2587
- 0.2618
- 0.2602
- 0.2537
- 0.2639
- 0.2324
- 0.263
- 0.2633
- 0.2685
- 0.2717
- 0.2616
- 0.2732
- 0.2798
- 0.2675
- 0.2819
- 0.2801
- 0.2816
- 0.286
- 0.2494
- 0.2763
- 0.2855
- 0.2842
- 0.2831
- 0.2847
- 0.2887
- 0.2918
- 0.2869
- 0.2855
- 0.2891
- 0.2907
- 0.2953
- 0.2826
- 0.2939
- 0.2973
- 0.2977
- 0.2908
- 0.2898
- 0.2941
- 0.2934
- 0.3006
- 0.3019
- 0.2599
- 0.2941
- 0.2902
- 0.2925
- 0.2968
- 0.2952
- 0.2952
- 0.2844
- 0.303
- 0.2968
- 0.3051
- 0.2922
- 0.3013
- 0.2952
- 0.2973
- 0.2878
- 0.2925
- 0.2673
- 0.3015
- 0.2796
- 0.3009
test_loss_list:
- 1.8109023809432983
- 1.7581888246536255
- 1.6891215896606446
- 1.6671946597099305
- 1.661911699771881
- 1.6404184412956238
- 1.5836310625076293
- 1.5710187292098998
- 1.5063389801979066
- 1.5126874732971192
- 1.5282815718650817
- 1.5171039700508118
- 1.4867390656471253
- 1.4802456545829772
- 1.4621493482589722
- 1.4502090334892273
- 1.446875901222229
- 1.438304054737091
- 1.43411527633667
- 1.3869427609443665
- 1.442984504699707
- 1.5034320330619813
- 1.4034221982955932
- 1.4050914812088013
- 1.379246039390564
- 1.380507469177246
- 1.4082325148582457
- 1.3756961512565613
- 1.351355528831482
- 1.3699695348739624
- 1.3680913043022156
- 1.3304370641708374
- 1.3375380611419678
- 1.3543100214004518
- 1.400499255657196
- 1.3737295532226563
- 1.3293319988250731
- 1.3637012696266175
- 1.3345808744430543
- 1.3673039412498473
- 1.3387996315956117
- 1.3041204595565796
- 1.2928805708885194
- 1.339222948551178
- 1.2879006624221803
- 1.3105838131904601
- 1.3122743248939515
- 1.3420734119415283
- 1.3129035067558288
- 1.330482213497162
- 1.2871058511734008
- 1.324167640209198
- 1.3293167638778687
- 1.3069199848175048
- 1.3362118482589722
- 1.283117036819458
- 1.3422295475006103
- 1.2956207370758057
- 1.2532156705856323
- 1.3123140335083008
- 1.3358603310585022
- 1.304761950969696
- 1.3222833466529846
- 1.2902337288856507
- 1.2900802445411683
- 1.327953474521637
- 1.3393624067306518
- 1.3065692353248597
- 1.2828097987174987
- 1.3204586458206178
- 1.3298935079574585
- 1.2746396851539612
- 1.2524867010116578
- 1.2895265889167786
- 1.2969266486167907
- 1.2708429169654847
- 1.3159749555587767
- 1.2899559354782104
- 1.2617323637008666
- 1.3522109913825988
- 1.278169996738434
- 1.3148703145980836
- 1.3042962527275086
- 1.3270818138122558
- 1.2886901545524596
- 1.323764910697937
- 1.2934307694435119
- 1.2341806530952453
- 1.264630627632141
- 1.2601701545715331
- 1.3017542552947998
- 1.2613765239715575
- 1.2896926856040956
- 1.303078169822693
- 1.2856222534179687
- 1.2936473894119263
- 1.3324605178833009
- 1.2936439824104309
- 1.31847309589386
- 1.2951150226593018
train_accuracy:
- 0.062
- 0.0
- 0.096
- 0.091
- 0.116
- 0.159
- 0.0
- 0.131
- 0.213
- 0.0
- 0.22
- 0.0
- 0.209
- 0.0
- 0.0
- 0.0
- 0.197
- 0.182
- 0.0
- 0.267
- 0.0
- 0.0
- 0.225
- 0.0
- 0.234
- 0.243
- 0.249
- 0.0
- 0.237
- 0.225
- 0.263
- 0.251
- 0.196
- 0.193
- 0.0
- 0.0
- 0.216
- 0.321
- 0.0
- 0.235
- 0.291
- 0.0
- 0.0
- 0.0
- 0.206
- 0.223
- 0.0
- 0.293
- 0.0
- 0.34
- 0.229
- 0.209
- 0.303
- 0.289
- 0.321
- 0.0
- 0.0
- 0.291
- 0.254
- 0.336
- 0.338
- 0.0
- 0.277
- 0.0
- 0.311
- 0.298
- 0.257
- 0.242
- 0.259
- 0.27
- 0.328
- 0.291
- 0.339
- 0.0
- 0.0
- 0.251
- 0.347
- 0.0
- 0.282
- 0.0
- 0.0
- 0.316
- 0.299
- 0.334
- 0.242
- 0.337
- 0.0
- 0.0
- 0.0
- 0.282
- 0.0
- 0.268
- 0.0
- 0.294
- 0.0
- 0.237
- 0.0
- 0.364
- 0.281
- 0.335
train_loss:
- 4.298
- 2.004
- 3.605
- 2.528
- 2.375
- 3.076
- 1.657
- 2.315
- 2.25
- 2.19
- 2.809
- 0.789
- 2.742
- 1.28
- 1.878
- 2.022
- 1.783
- 1.878
- 1.767
- 1.755
- 1.218
- 0.999
- 1.5
- 0.967
- 1.582
- 1.501
- 2.075
- 1.606
- 1.517
- 1.424
- 1.293
- 1.372
- 1.361
- 1.233
- 0.757
- 0.761
- 1.289
- 1.642
- 1.261
- 1.601
- 1.044
- 0.789
- 1.173
- 0.695
- 1.12
- 1.071
- 1.135
- 1.348
- 0.633
- 1.413
- 1.145
- 0.957
- 1.226
- 0.839
- 1.278
- 0.941
- 0.474
- 0.715
- 1.044
- 0.987
- 0.954
- 0.691
- 1.141
- 0.688
- 0.603
- 0.914
- 0.98
- 0.712
- 0.777
- 0.589
- 0.858
- 0.764
- 0.651
- 0.625
- 0.489
- 0.596
- 0.754
- 0.563
- 0.574
- 0.31
- 0.451
- 0.628
- 0.392
- 0.573
- 0.485
- 0.709
- 0.453
- 0.541
- 0.466
- 0.503
- 0.414
- 0.537
- 0.435
- 0.565
- 0.346
- 0.369
- 0.302
- 0.506
- 0.293
- 0.475
unequal: 0
verbose: 1
