avg_train_accuracy: 0.326
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0233
- 0.0734
- 0.1133
- 0.1244
- 0.1366
- 0.1477
- 0.1389
- 0.162
- 0.1628
- 0.1748
- 0.1857
- 0.1933
- 0.1491
- 0.1905
- 0.1688
- 0.1953
- 0.2068
- 0.2092
- 0.214
- 0.1684
- 0.1511
- 0.167
- 0.222
- 0.2282
- 0.2327
- 0.2052
- 0.2247
- 0.2346
- 0.2385
- 0.2358
- 0.2402
- 0.2433
- 0.2395
- 0.2555
- 0.2518
- 0.2489
- 0.2459
- 0.2185
- 0.1432
- 0.2499
- 0.2563
- 0.2561
- 0.2209
- 0.26
- 0.2543
- 0.2618
- 0.2594
- 0.259
- 0.2545
- 0.2704
- 0.2558
- 0.2624
- 0.2804
- 0.2686
- 0.2755
- 0.2795
- 0.2789
- 0.2825
- 0.2759
- 0.2681
- 0.2449
- 0.2851
- 0.2838
- 0.2821
- 0.2769
- 0.2504
- 0.2889
- 0.2849
- 0.2876
- 0.2625
- 0.2374
- 0.2825
- 0.2843
- 0.2761
- 0.2876
- 0.2819
- 0.293
- 0.2903
- 0.2929
- 0.2942
- 0.2945
- 0.2689
- 0.2959
- 0.2784
- 0.2943
- 0.2948
- 0.2836
- 0.2948
- 0.3005
- 0.295
- 0.3002
- 0.3011
- 0.2743
- 0.2996
- 0.2867
- 0.2079
- 0.2983
- 0.2812
- 0.2648
- 0.303
test_loss_list:
- 1.8334897947311402
- 1.7479900884628297
- 1.6927700281143188
- 1.635571162700653
- 1.5826506233215332
- 1.5963060140609742
- 1.555766146183014
- 1.562930974960327
- 1.5499678182601928
- 1.559672989845276
- 1.5636867451667786
- 1.5266841387748717
- 1.54928617477417
- 1.4958643412590027
- 1.448252408504486
- 1.4507579374313355
- 1.4694030451774598
- 1.434491970539093
- 1.4176279783248902
- 1.4635671639442445
- 1.5289358878135682
- 1.4545931601524353
- 1.4055373239517213
- 1.4001870274543762
- 1.3737808084487915
- 1.3836258053779602
- 1.3672660493850708
- 1.4000139427185059
- 1.3729108500480651
- 1.362115879058838
- 1.3602146434783935
- 1.3536107206344605
- 1.3600383973121644
- 1.3259053611755371
- 1.36843731880188
- 1.3426775383949279
- 1.3648565411567688
- 1.390518856048584
- 1.5764152312278747
- 1.3016933012008667
- 1.3504286766052247
- 1.3469811248779298
- 1.3727286815643311
- 1.3160356664657593
- 1.3261041951179504
- 1.2925863194465637
- 1.3159908318519593
- 1.3211228775978088
- 1.334953818321228
- 1.3499215126037598
- 1.3211914968490601
- 1.3143076610565185
- 1.2591405487060547
- 1.2940303468704224
- 1.324638843536377
- 1.3359689688682557
- 1.30588365316391
- 1.2726882481575013
- 1.2856459522247314
- 1.3112034440040587
- 1.3485681366920472
- 1.2513507866859437
- 1.3133229684829713
- 1.289129946231842
- 1.3067568278312682
- 1.339020380973816
- 1.251397569179535
- 1.2614548873901368
- 1.2516233277320863
- 1.2838560080528258
- 1.3549884796142577
- 1.265745632648468
- 1.2862226629257203
- 1.2687278985977173
- 1.286755042076111
- 1.2843166780471802
- 1.2515576887130737
- 1.2821930408477784
- 1.3114008164405824
- 1.3248600029945374
- 1.286892421245575
- 1.3032749390602112
- 1.296163101196289
- 1.289560978412628
- 1.296655900478363
- 1.275033118724823
- 1.264740469455719
- 1.263341054916382
- 1.2560474157333374
- 1.2673038291931151
- 1.2906850242614747
- 1.277155795097351
- 1.2973518443107606
- 1.2926917839050294
- 1.2709540128707886
- 1.484080195426941
- 1.26426705121994
- 1.2946803998947143
- 1.3150415086746217
- 1.2673139762878418
train_accuracy:
- 0.004
- 0.044
- 0.121
- 0.119
- 0.137
- 0.161
- 0.118
- 0.165
- 0.0
- 0.199
- 0.199
- 0.181
- 0.0
- 0.208
- 0.0
- 0.0
- 0.218
- 0.0
- 0.226
- 0.0
- 0.106
- 0.123
- 0.222
- 0.242
- 0.237
- 0.0
- 0.235
- 0.284
- 0.229
- 0.0
- 0.0
- 0.241
- 0.251
- 0.308
- 0.282
- 0.0
- 0.259
- 0.0
- 0.0
- 0.228
- 0.317
- 0.302
- 0.0
- 0.283
- 0.0
- 0.249
- 0.3
- 0.252
- 0.0
- 0.315
- 0.0
- 0.0
- 0.305
- 0.0
- 0.292
- 0.319
- 0.286
- 0.0
- 0.309
- 0.0
- 0.0
- 0.291
- 0.292
- 0.0
- 0.0
- 0.0
- 0.304
- 0.297
- 0.0
- 0.0
- 0.0
- 0.285
- 0.0
- 0.277
- 0.351
- 0.279
- 0.309
- 0.329
- 0.279
- 0.365
- 0.339
- 0.0
- 0.333
- 0.269
- 0.347
- 0.316
- 0.0
- 0.294
- 0.315
- 0.309
- 0.289
- 0.281
- 0.0
- 0.378
- 0.0
- 0.0
- 0.369
- 0.0
- 0.0
- 0.326
train_loss:
- 3.173
- 2.808
- 3.504
- 2.597
- 2.494
- 3.111
- 1.682
- 2.91
- 2.108
- 2.761
- 2.565
- 2.075
- 1.421
- 1.889
- 1.386
- 1.85
- 2.295
- 1.847
- 1.803
- 1.119
- 1.018
- 1.077
- 2.298
- 1.627
- 1.559
- 1.078
- 1.486
- 1.895
- 1.426
- 1.32
- 1.456
- 1.386
- 1.344
- 1.355
- 1.759
- 1.291
- 1.144
- 0.858
- 0.335
- 1.215
- 1.548
- 1.098
- 0.816
- 1.062
- 1.136
- 1.059
- 1.011
- 1.015
- 0.906
- 1.442
- 0.719
- 0.913
- 0.986
- 0.858
- 1.187
- 1.305
- 0.866
- 0.895
- 0.772
- 0.713
- 0.506
- 0.931
- 0.987
- 0.749
- 0.69
- 0.437
- 0.791
- 0.78
- 0.693
- 0.457
- 0.421
- 0.746
- 0.682
- 0.413
- 0.916
- 0.614
- 0.639
- 0.617
- 0.795
- 0.737
- 0.56
- 0.393
- 0.636
- 0.333
- 0.624
- 0.54
- 0.337
- 0.513
- 0.571
- 0.479
- 0.594
- 0.473
- 0.366
- 0.58
- 0.369
- 0.138
- 0.582
- 0.303
- 0.237
- 0.5
unequal: 0
verbose: 1
