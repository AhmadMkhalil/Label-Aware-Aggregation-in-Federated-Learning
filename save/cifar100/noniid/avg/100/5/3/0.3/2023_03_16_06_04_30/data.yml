avg_train_accuracy: 0.275
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0297
- 0.072
- 0.0473
- 0.1197
- 0.1308
- 0.1267
- 0.0982
- 0.1541
- 0.1519
- 0.1045
- 0.1562
- 0.1772
- 0.1694
- 0.1841
- 0.1873
- 0.1992
- 0.2047
- 0.1931
- 0.2152
- 0.2112
- 0.2087
- 0.2048
- 0.2317
- 0.2251
- 0.2288
- 0.2418
- 0.239
- 0.2309
- 0.1951
- 0.2338
- 0.2318
- 0.233
- 0.2443
- 0.2456
- 0.2429
- 0.2461
- 0.2523
- 0.2528
- 0.2564
- 0.253
- 0.2562
- 0.2554
- 0.2646
- 0.2531
- 0.2573
- 0.2632
- 0.2579
- 0.2645
- 0.2636
- 0.2721
- 0.2609
- 0.261
- 0.2698
- 0.2641
- 0.2776
- 0.2446
- 0.2701
- 0.2723
- 0.2739
- 0.2701
- 0.2655
- 0.268
- 0.2818
- 0.2723
- 0.2677
- 0.2759
- 0.2836
- 0.2833
- 0.2808
- 0.2793
- 0.2554
- 0.2841
- 0.2848
- 0.2849
- 0.2832
- 0.2846
- 0.2835
- 0.2911
- 0.274
- 0.2744
- 0.2884
- 0.2831
- 0.2934
- 0.2894
- 0.3005
- 0.2917
- 0.2782
- 0.2891
- 0.2898
- 0.2851
- 0.2602
- 0.2632
- 0.2928
- 0.2917
- 0.2953
- 0.3005
- 0.288
- 0.2877
- 0.291
- 0.2792
test_loss_list:
- 1.8297358417510987
- 1.7194999027252198
- 1.7498612213134765
- 1.653424482345581
- 1.6093724060058594
- 1.6089940667152405
- 1.6306241703033448
- 1.5796763253211976
- 1.5358662247657775
- 1.6487023878097533
- 1.5257765102386474
- 1.4827988529205323
- 1.50826523065567
- 1.5244377422332764
- 1.4901802372932433
- 1.5083614301681518
- 1.465415644645691
- 1.47813725233078
- 1.4249316430091858
- 1.467328748703003
- 1.4562939143180846
- 1.464916956424713
- 1.4012595295906067
- 1.4408910536766053
- 1.4640965795516967
- 1.397820122241974
- 1.3870281434059144
- 1.3992723274230956
- 1.4575138592720032
- 1.393328742980957
- 1.3911042785644532
- 1.4071908807754516
- 1.3502976059913636
- 1.4021057438850404
- 1.3854424118995667
- 1.4180103731155396
- 1.3819373178482055
- 1.411292769908905
- 1.4290162801742554
- 1.3430430269241334
- 1.3835256505012512
- 1.4052409100532532
- 1.3208069753646852
- 1.3526659393310547
- 1.3638646912574768
- 1.3798613858222961
- 1.378276424407959
- 1.394508810043335
- 1.3895201945304871
- 1.3267301154136657
- 1.3624399256706239
- 1.3697193264961243
- 1.3423527956008912
- 1.3625779008865357
- 1.2882019948959351
- 1.3450774264335632
- 1.3412515759468078
- 1.3667672204971313
- 1.3781298542022704
- 1.3211276984214784
- 1.3406730270385743
- 1.352448709011078
- 1.3569428682327271
- 1.3799584364891053
- 1.3418734979629516
- 1.3282204914093017
- 1.3252688336372376
- 1.3363653635978698
- 1.3603951287269593
- 1.3688547348976134
- 1.3750081729888917
- 1.3435749053955077
- 1.361070511341095
- 1.3717477130889892
- 1.309234926700592
- 1.349966266155243
- 1.3268508911132812
- 1.3099345636367798
- 1.3295671796798707
- 1.3482884740829468
- 1.3207535600662232
- 1.3380907702445983
- 1.3564718294143676
- 1.3288584733009339
- 1.2713578510284425
- 1.329654791355133
- 1.3261641120910646
- 1.3227118229866028
- 1.3494398164749146
- 1.3339604139328003
- 1.3681674361228944
- 1.3206796860694885
- 1.308431396484375
- 1.306718919277191
- 1.3251738142967224
- 1.2921596717834474
- 1.3297456526756286
- 1.3448792028427123
- 1.2985546684265137
- 1.3430614542961121
train_accuracy:
- 0.014
- 0.053
- 0.0
- 0.109
- 0.162
- 0.0
- 0.0
- 0.162
- 0.113
- 0.0
- 0.0
- 0.0
- 0.131
- 0.174
- 0.175
- 0.233
- 0.0
- 0.0
- 0.213
- 0.227
- 0.0
- 0.221
- 0.262
- 0.225
- 0.256
- 0.0
- 0.0
- 0.2
- 0.0
- 0.0
- 0.224
- 0.0
- 0.0
- 0.242
- 0.275
- 0.306
- 0.29
- 0.244
- 0.317
- 0.213
- 0.263
- 0.284
- 0.0
- 0.244
- 0.0
- 0.256
- 0.293
- 0.272
- 0.301
- 0.0
- 0.256
- 0.0
- 0.259
- 0.227
- 0.297
- 0.0
- 0.313
- 0.322
- 0.284
- 0.0
- 0.244
- 0.0
- 0.303
- 0.34
- 0.31
- 0.273
- 0.292
- 0.303
- 0.265
- 0.284
- 0.0
- 0.322
- 0.332
- 0.294
- 0.269
- 0.322
- 0.362
- 0.0
- 0.32
- 0.276
- 0.0
- 0.293
- 0.299
- 0.284
- 0.305
- 0.303
- 0.243
- 0.292
- 0.323
- 0.313
- 0.0
- 0.0
- 0.302
- 0.294
- 0.344
- 0.0
- 0.291
- 0.0
- 0.308
- 0.275
train_loss:
- 3.179
- 2.904
- 1.847
- 3.521
- 2.516
- 2.407
- 1.529
- 3.06
- 1.606
- 1.334
- 2.205
- 2.104
- 1.93
- 2.605
- 1.825
- 2.479
- 1.944
- 1.958
- 1.842
- 2.232
- 1.72
- 1.711
- 1.681
- 2.061
- 2.036
- 1.711
- 1.443
- 1.488
- 0.985
- 1.422
- 1.411
- 1.28
- 1.443
- 1.677
- 1.33
- 1.581
- 1.194
- 1.618
- 1.478
- 0.891
- 1.587
- 1.492
- 0.97
- 1.048
- 1.07
- 1.301
- 0.928
- 1.163
- 0.892
- 1.006
- 0.852
- 1.091
- 0.815
- 0.849
- 1.0
- 0.575
- 1.012
- 1.043
- 0.978
- 0.558
- 0.692
- 0.641
- 1.112
- 0.88
- 0.522
- 0.87
- 0.677
- 0.639
- 0.55
- 0.505
- 0.59
- 0.568
- 0.7
- 0.767
- 0.655
- 0.724
- 0.483
- 0.51
- 0.479
- 0.504
- 0.541
- 0.474
- 0.781
- 0.462
- 0.664
- 0.578
- 0.32
- 0.602
- 0.617
- 0.431
- 0.282
- 0.363
- 0.625
- 0.405
- 0.482
- 0.434
- 0.378
- 0.343
- 0.344
- 0.287
unequal: 0
verbose: 1
