avg_train_accuracy: 0.302
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0807
- 0.0752
- 0.054
- 0.0991
- 0.1139
- 0.1261
- 0.1308
- 0.1339
- 0.1098
- 0.1695
- 0.1759
- 0.1883
- 0.1763
- 0.1936
- 0.2015
- 0.2112
- 0.2167
- 0.2161
- 0.2248
- 0.2269
- 0.1927
- 0.229
- 0.2303
- 0.2306
- 0.2218
- 0.2373
- 0.2317
- 0.2423
- 0.2345
- 0.2462
- 0.2403
- 0.2412
- 0.24
- 0.2537
- 0.2337
- 0.2575
- 0.2576
- 0.2593
- 0.2598
- 0.2589
- 0.2633
- 0.2199
- 0.261
- 0.2735
- 0.2627
- 0.2678
- 0.2347
- 0.2718
- 0.258
- 0.2668
- 0.273
- 0.2712
- 0.2786
- 0.2804
- 0.2849
- 0.2769
- 0.2716
- 0.2868
- 0.2582
- 0.2798
- 0.2728
- 0.2741
- 0.2648
- 0.2809
- 0.288
- 0.281
- 0.287
- 0.2787
- 0.2934
- 0.2876
- 0.2855
- 0.2531
- 0.2781
- 0.2521
- 0.2887
- 0.2837
- 0.2937
- 0.293
- 0.2987
- 0.2928
- 0.2952
- 0.2942
- 0.2936
- 0.2832
- 0.2957
- 0.2992
- 0.2933
- 0.2916
- 0.291
- 0.276
- 0.2871
- 0.2977
- 0.2975
- 0.2954
- 0.2937
- 0.2978
- 0.2953
- 0.3077
- 0.3013
test_loss_list:
- 1.8151687145233155
- 1.7246618795394897
- 1.672590684890747
- 1.7337473487854005
- 1.6215996623039246
- 1.61159099817276
- 1.5988066029548644
- 1.5499974846839906
- 1.5444691801071166
- 1.5981852531433105
- 1.5289589762687683
- 1.5437259006500244
- 1.5115383601188659
- 1.5234053134918213
- 1.5269325613975524
- 1.5278571128845215
- 1.5335634326934815
- 1.4717756772041322
- 1.5013944435119628
- 1.4315607070922851
- 1.3980048632621764
- 1.4112753748893738
- 1.4181704068183898
- 1.4100965881347656
- 1.4387310481071471
- 1.3879709506034852
- 1.3545644450187684
- 1.3825163412094117
- 1.3592147374153136
- 1.3874516201019287
- 1.3577313017845154
- 1.3598462200164796
- 1.3735948300361633
- 1.3884965181350708
- 1.3441645503044128
- 1.354875671863556
- 1.3501953649520875
- 1.37631516456604
- 1.3487086820602416
- 1.3775643587112427
- 1.3649401950836182
- 1.32523104429245
- 1.4000164031982423
- 1.3315704560279846
- 1.2832090044021607
- 1.319747109413147
- 1.309095366001129
- 1.3431574416160583
- 1.329199833869934
- 1.3122628808021546
- 1.3017830300331115
- 1.332238826751709
- 1.346343114376068
- 1.3154375982284545
- 1.3019301962852479
- 1.257609679698944
- 1.2894466352462768
- 1.3170624899864196
- 1.2709184098243713
- 1.2976580715179444
- 1.2774908924102784
- 1.2996977734565736
- 1.2990892958641052
- 1.2951306080818177
- 1.303401710987091
- 1.314693305492401
- 1.3001647663116456
- 1.3314483547210694
- 1.3296170735359192
- 1.2746345019340515
- 1.2554799818992615
- 1.2835698914527893
- 1.3286547446250916
- 1.2970624661445618
- 1.32704509973526
- 1.259731171131134
- 1.2779900670051574
- 1.3032672095298767
- 1.2860093712806702
- 1.258380959033966
- 1.2907637977600097
- 1.3030783462524413
- 1.3297055292129516
- 1.2979816174507142
- 1.3339596915245056
- 1.324855523109436
- 1.2757847666740418
- 1.315985164642334
- 1.3424226140975952
- 1.2901088285446167
- 1.2795698976516723
- 1.2766800379753114
- 1.2584532690048218
- 1.2900353479385376
- 1.2945213007926941
- 1.3146664524078369
- 1.2738159775733948
- 1.2913636040687562
- 1.2438193702697753
- 1.2645544290542603
train_accuracy:
- 0.064
- 0.0
- 0.0
- 0.0
- 0.0
- 0.103
- 0.123
- 0.0
- 0.137
- 0.072
- 0.218
- 0.176
- 0.17
- 0.169
- 0.261
- 0.184
- 0.197
- 0.0
- 0.2
- 0.0
- 0.246
- 0.0
- 0.246
- 0.21
- 0.255
- 0.239
- 0.0
- 0.273
- 0.22
- 0.25
- 0.267
- 0.0
- 0.237
- 0.235
- 0.297
- 0.0
- 0.256
- 0.341
- 0.252
- 0.261
- 0.251
- 0.229
- 0.185
- 0.299
- 0.309
- 0.266
- 0.0
- 0.0
- 0.301
- 0.262
- 0.324
- 0.295
- 0.316
- 0.24
- 0.34
- 0.246
- 0.236
- 0.0
- 0.371
- 0.291
- 0.267
- 0.335
- 0.347
- 0.0
- 0.321
- 0.283
- 0.376
- 0.335
- 0.369
- 0.279
- 0.353
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.367
- 0.0
- 0.0
- 0.264
- 0.318
- 0.339
- 0.0
- 0.0
- 0.376
- 0.0
- 0.389
- 0.41
- 0.272
- 0.0
- 0.0
- 0.343
- 0.306
- 0.0
- 0.299
- 0.267
- 0.309
- 0.337
- 0.302
train_loss:
- 4.246
- 2.858
- 1.997
- 1.787
- 2.57
- 2.447
- 2.382
- 1.617
- 2.26
- 1.468
- 2.978
- 2.823
- 2.118
- 2.009
- 2.616
- 2.609
- 2.48
- 1.852
- 2.324
- 1.964
- 1.688
- 1.131
- 2.203
- 1.655
- 2.012
- 1.1
- 1.637
- 1.5
- 1.514
- 1.318
- 1.501
- 1.348
- 1.23
- 1.114
- 1.196
- 1.022
- 2.021
- 1.554
- 1.318
- 1.756
- 1.207
- 1.187
- 0.744
- 1.195
- 1.137
- 1.014
- 1.038
- 0.749
- 1.422
- 0.732
- 0.913
- 1.227
- 1.362
- 0.907
- 0.898
- 1.027
- 0.823
- 0.883
- 0.84
- 0.539
- 0.677
- 0.602
- 0.725
- 0.554
- 0.908
- 1.076
- 0.655
- 0.83
- 0.565
- 0.752
- 0.815
- 0.667
- 0.38
- 0.51
- 0.316
- 0.693
- 0.474
- 0.852
- 0.635
- 0.484
- 0.497
- 0.78
- 0.636
- 0.497
- 0.39
- 0.798
- 0.603
- 0.712
- 0.499
- 0.374
- 0.421
- 0.467
- 0.476
- 0.572
- 0.352
- 0.374
- 0.483
- 0.357
- 0.529
- 0.429
unequal: 0
verbose: 1
