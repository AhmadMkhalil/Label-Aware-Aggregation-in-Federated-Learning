avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0233
- 0.071
- 0.0497
- 0.1171
- 0.1243
- 0.1487
- 0.1466
- 0.157
- 0.1681
- 0.166
- 0.131
- 0.1664
- 0.1701
- 0.1794
- 0.1945
- 0.2017
- 0.2027
- 0.1972
- 0.2098
- 0.199
- 0.2184
- 0.21
- 0.1819
- 0.1557
- 0.2179
- 0.2169
- 0.2215
- 0.1891
- 0.2302
- 0.2348
- 0.2465
- 0.2402
- 0.2466
- 0.2454
- 0.1916
- 0.2536
- 0.2541
- 0.2542
- 0.245
- 0.2109
- 0.1947
- 0.2656
- 0.263
- 0.2639
- 0.2657
- 0.2717
- 0.2713
- 0.2636
- 0.2717
- 0.2716
- 0.2789
- 0.2814
- 0.2745
- 0.2657
- 0.2775
- 0.2837
- 0.2804
- 0.282
- 0.2857
- 0.2862
- 0.2577
- 0.2797
- 0.276
- 0.2893
- 0.2924
- 0.2827
- 0.2951
- 0.2886
- 0.2877
- 0.2934
- 0.289
- 0.29
- 0.2875
- 0.2556
- 0.289
- 0.2907
- 0.2781
- 0.2976
- 0.295
- 0.2937
- 0.2943
- 0.2975
- 0.2957
- 0.299
- 0.291
- 0.2695
- 0.2984
- 0.2952
- 0.3021
- 0.2964
- 0.2979
- 0.2998
- 0.3002
- 0.3047
- 0.2959
- 0.3046
- 0.2775
- 0.3012
- 0.2924
- 0.2901
test_loss_list:
- 1.839209794998169
- 1.7285674333572387
- 1.7865710735321045
- 1.6669556307792663
- 1.638895001411438
- 1.5786078882217407
- 1.5449704599380494
- 1.567912974357605
- 1.5861649346351623
- 1.5498143887519837
- 1.5684023022651672
- 1.5162711572647094
- 1.522698471546173
- 1.5216386890411377
- 1.4770736002922058
- 1.5032191514968871
- 1.4839360046386718
- 1.4954484581947327
- 1.4971890830993653
- 1.4294362616539003
- 1.4505417251586914
- 1.417299108505249
- 1.4393461155891418
- 1.4827100872993468
- 1.3920452356338502
- 1.3945747089385987
- 1.3937171697616577
- 1.4263955998420714
- 1.3776811122894288
- 1.3611990451812743
- 1.3931274700164795
- 1.36556307554245
- 1.3983652067184449
- 1.3360377144813538
- 1.4401224899291991
- 1.3106303191184998
- 1.3376692342758179
- 1.3225679612159729
- 1.355679395198822
- 1.4054349040985108
- 1.4546734762191773
- 1.3517165851593018
- 1.3128748512268067
- 1.312669756412506
- 1.3497960925102235
- 1.3739470720291138
- 1.3954075169563294
- 1.4017100954055786
- 1.3520477938652038
- 1.383692364692688
- 1.3302251243591308
- 1.2904168200492858
- 1.2986926460266113
- 1.3302623319625855
- 1.352165846824646
- 1.3555045247077941
- 1.3360860180854797
- 1.293858151435852
- 1.3359672212600708
- 1.2954282259941101
- 1.330436863899231
- 1.295226402282715
- 1.3169379806518555
- 1.268172721862793
- 1.3113134956359864
- 1.3033686923980712
- 1.2767385387420653
- 1.273871352672577
- 1.2718910050392152
- 1.2700016117095947
- 1.2942555093765258
- 1.3175093936920166
- 1.296884877681732
- 1.321834237575531
- 1.3146497082710267
- 1.332805986404419
- 1.3023391485214233
- 1.3118396878242493
- 1.3006263613700866
- 1.3347907209396361
- 1.2897378253936767
- 1.3274018359184265
- 1.3066421675682067
- 1.3307822751998901
- 1.2750854873657227
- 1.3297804617881774
- 1.2993423986434935
- 1.2992242288589477
- 1.318477249145508
- 1.3447935724258422
- 1.3299130296707153
- 1.347420620918274
- 1.2929282116889953
- 1.2641987323760986
- 1.2899134802818297
- 1.268020713329315
- 1.3051887130737305
- 1.3032113599777222
- 1.3018080329895019
- 1.322842218875885
train_accuracy:
- 0.017
- 0.053
- 0.01
- 0.104
- 0.0
- 0.0
- 0.0
- 0.131
- 0.178
- 0.0
- 0.0
- 0.179
- 0.199
- 0.199
- 0.0
- 0.237
- 0.0
- 0.0
- 0.218
- 0.0
- 0.266
- 0.224
- 0.0
- 0.0
- 0.193
- 0.244
- 0.215
- 0.189
- 0.213
- 0.262
- 0.328
- 0.251
- 0.303
- 0.241
- 0.0
- 0.0
- 0.293
- 0.25
- 0.0
- 0.177
- 0.151
- 0.309
- 0.275
- 0.314
- 0.242
- 0.338
- 0.334
- 0.333
- 0.322
- 0.336
- 0.0
- 0.0
- 0.321
- 0.243
- 0.353
- 0.328
- 0.0
- 0.0
- 0.319
- 0.294
- 0.0
- 0.0
- 0.0
- 0.305
- 0.366
- 0.36
- 0.31
- 0.358
- 0.286
- 0.349
- 0.0
- 0.323
- 0.0
- 0.0
- 0.354
- 0.368
- 0.28
- 0.313
- 0.258
- 0.319
- 0.351
- 0.369
- 0.367
- 0.319
- 0.0
- 0.0
- 0.279
- 0.332
- 0.324
- 0.372
- 0.342
- 0.317
- 0.0
- 0.371
- 0.0
- 0.312
- 0.0
- 0.378
- 0.0
- 0.0
train_loss:
- 3.151
- 2.946
- 1.762
- 3.482
- 2.444
- 2.457
- 2.534
- 2.99
- 2.797
- 2.194
- 1.438
- 2.052
- 1.897
- 1.904
- 1.961
- 2.457
- 1.757
- 1.783
- 2.398
- 1.329
- 2.18
- 1.127
- 1.118
- 0.998
- 1.526
- 1.605
- 1.414
- 1.077
- 1.351
- 1.557
- 1.955
- 1.392
- 1.862
- 0.902
- 0.818
- 1.381
- 1.16
- 1.286
- 1.176
- 0.778
- 0.664
- 1.707
- 1.119
- 1.127
- 1.545
- 1.444
- 1.313
- 1.292
- 0.927
- 1.257
- 0.895
- 1.086
- 0.841
- 0.886
- 1.239
- 1.297
- 0.848
- 0.845
- 1.044
- 0.706
- 0.548
- 0.883
- 0.674
- 0.911
- 0.983
- 0.672
- 0.78
- 0.708
- 0.757
- 0.639
- 0.611
- 0.777
- 0.575
- 0.476
- 0.675
- 0.767
- 0.436
- 0.742
- 0.645
- 0.613
- 0.53
- 0.661
- 0.521
- 0.6
- 0.332
- 0.358
- 0.65
- 0.398
- 0.648
- 0.48
- 0.364
- 0.6
- 0.437
- 0.46
- 0.383
- 0.436
- 0.326
- 0.435
- 0.43
- 0.342
unequal: 0
verbose: 1
