avg_train_accuracy: 0.0
avg_train_loss: 0.001
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0455
- 0.0913
- 0.104
- 0.1219
- 0.1338
- 0.0823
- 0.1327
- 0.1501
- 0.1018
- 0.1014
- 0.1558
- 0.1793
- 0.1798
- 0.192
- 0.1507
- 0.184
- 0.2013
- 0.2027
- 0.1945
- 0.2015
- 0.2149
- 0.2217
- 0.218
- 0.2226
- 0.2262
- 0.2312
- 0.2313
- 0.1874
- 0.2372
- 0.2313
- 0.1901
- 0.2356
- 0.2418
- 0.2385
- 0.2477
- 0.2498
- 0.2592
- 0.2541
- 0.2316
- 0.2026
- 0.2437
- 0.2549
- 0.2618
- 0.2626
- 0.2607
- 0.232
- 0.2689
- 0.2607
- 0.2742
- 0.2734
- 0.2656
- 0.2404
- 0.2636
- 0.2674
- 0.2817
- 0.2771
- 0.2799
- 0.2743
- 0.2823
- 0.2804
- 0.2761
- 0.2323
- 0.2347
- 0.2811
- 0.2806
- 0.2833
- 0.287
- 0.2816
- 0.2865
- 0.2883
- 0.2938
- 0.289
- 0.289
- 0.2872
- 0.2456
- 0.2862
- 0.2858
- 0.2943
- 0.28
- 0.2755
- 0.2814
- 0.2874
- 0.2517
- 0.2949
- 0.2866
- 0.2953
- 0.285
- 0.2848
- 0.2968
- 0.2975
- 0.2829
- 0.2901
- 0.2701
- 0.2988
- 0.295
- 0.2931
- 0.3019
- 0.3001
- 0.2885
- 0.1971
test_loss_list:
- 1.8103842735290527
- 1.7355119800567627
- 1.694975004196167
- 1.6314190673828124
- 1.581681294441223
- 1.6386462259292602
- 1.5660876727104187
- 1.52391752243042
- 1.5876997756958007
- 1.586791024208069
- 1.5014765214920045
- 1.5125864434242249
- 1.499943482875824
- 1.5088050532341004
- 1.494875786304474
- 1.4445247507095338
- 1.4649861478805541
- 1.4506962847709657
- 1.4768312621116637
- 1.4612106895446777
- 1.466740288734436
- 1.4169836163520813
- 1.4215861129760743
- 1.4494188046455383
- 1.4638518810272216
- 1.4121025729179382
- 1.4004895710945129
- 1.477360849380493
- 1.3377335715293883
- 1.3599646496772766
- 1.4341581177711487
- 1.366423704624176
- 1.3862534308433532
- 1.3786339592933654
- 1.402232847213745
- 1.4100429821014404
- 1.3623183155059815
- 1.3495971536636353
- 1.3293139410018922
- 1.3948917078971863
- 1.3229865407943726
- 1.3224835801124573
- 1.3036667609214783
- 1.3431618237495422
- 1.3314095735549927
- 1.365082938671112
- 1.342676568031311
- 1.3509700894355774
- 1.289815492630005
- 1.28420462846756
- 1.3118296360969544
- 1.3388237166404724
- 1.312606394290924
- 1.308764545917511
- 1.269672565460205
- 1.3031299376487733
- 1.3324009251594544
- 1.3207888078689576
- 1.3399407768249512
- 1.313265345096588
- 1.2653097057342528
- 1.363424210548401
- 1.3422751808166504
- 1.267594211101532
- 1.282564675807953
- 1.2781895184516907
- 1.2866657733917237
- 1.3067963933944702
- 1.3203773522377014
- 1.2812696242332458
- 1.2590822410583495
- 1.3048852062225342
- 1.3318892979621888
- 1.279326207637787
- 1.369514148235321
- 1.2889500427246094
- 1.2934155368804932
- 1.2582751870155335
- 1.2928463172912599
- 1.32067200422287
- 1.3220759439468384
- 1.2539907813072204
- 1.3265563344955444
- 1.2563304018974304
- 1.2757260179519654
- 1.2630217242240906
- 1.2875930404663085
- 1.2978944778442383
- 1.3108045768737793
- 1.3228790259361267
- 1.3033416271209717
- 1.3002537441253663
- 1.3062591743469238
- 1.2622389674186707
- 1.2830113506317138
- 1.2861220169067382
- 1.2969401383399963
- 1.2903781032562256
- 1.280177595615387
- 1.5358598971366881
train_accuracy:
- 0.055
- 0.11
- 0.1
- 0.159
- 0.0
- 0.0
- 0.136
- 0.148
- 0.0
- 0.086
- 0.0
- 0.196
- 0.0
- 0.25
- 0.0
- 0.0
- 0.255
- 0.197
- 0.188
- 0.184
- 0.226
- 0.0
- 0.26
- 0.274
- 0.227
- 0.239
- 0.237
- 0.143
- 0.238
- 0.0
- 0.0
- 0.208
- 0.273
- 0.293
- 0.329
- 0.334
- 0.252
- 0.227
- 0.0
- 0.177
- 0.257
- 0.0
- 0.32
- 0.333
- 0.0
- 0.0
- 0.287
- 0.279
- 0.0
- 0.289
- 0.328
- 0.0
- 0.269
- 0.0
- 0.367
- 0.324
- 0.378
- 0.338
- 0.348
- 0.341
- 0.272
- 0.0
- 0.242
- 0.274
- 0.0
- 0.303
- 0.294
- 0.0
- 0.322
- 0.277
- 0.358
- 0.314
- 0.361
- 0.0
- 0.212
- 0.352
- 0.0
- 0.315
- 0.337
- 0.332
- 0.259
- 0.317
- 0.0
- 0.0
- 0.0
- 0.0
- 0.355
- 0.322
- 0.334
- 0.337
- 0.0
- 0.315
- 0.0
- 0.309
- 0.329
- 0.0
- 0.291
- 0.268
- 0.0
- 0.0
train_loss:
- 4.25
- 3.701
- 2.672
- 2.622
- 2.478
- 1.699
- 2.289
- 2.337
- 1.593
- 1.439
- 2.116
- 2.799
- 1.897
- 2.621
- 0.768
- 1.947
- 2.571
- 1.793
- 1.714
- 1.826
- 2.27
- 1.691
- 1.649
- 2.171
- 2.104
- 1.601
- 1.5
- 1.025
- 1.503
- 1.382
- 0.848
- 1.366
- 1.76
- 1.24
- 1.585
- 1.611
- 1.391
- 1.3
- 0.89
- 0.707
- 1.092
- 1.299
- 1.04
- 1.494
- 1.049
- 0.722
- 1.345
- 0.896
- 1.015
- 0.887
- 0.78
- 0.771
- 0.875
- 0.932
- 0.909
- 0.893
- 1.198
- 0.802
- 1.096
- 0.763
- 0.634
- 0.527
- 0.519
- 0.762
- 0.669
- 0.677
- 0.575
- 0.62
- 0.94
- 0.783
- 0.617
- 0.781
- 0.841
- 0.415
- 0.445
- 0.626
- 0.483
- 0.652
- 0.629
- 0.545
- 0.58
- 0.441
- 0.339
- 0.537
- 0.495
- 0.503
- 0.519
- 0.522
- 0.597
- 0.612
- 0.331
- 0.398
- 0.33
- 0.388
- 0.389
- 0.396
- 0.564
- 0.43
- 0.319
- 0.129
unequal: 0
verbose: 1
