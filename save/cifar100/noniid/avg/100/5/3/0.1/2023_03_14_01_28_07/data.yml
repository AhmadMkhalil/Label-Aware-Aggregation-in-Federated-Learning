avg_train_accuracy: 0.0
avg_train_loss: 0.001
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0508
- 0.0299
- 0.0279
- 0.0886
- 0.1052
- 0.1168
- 0.1299
- 0.1491
- 0.1448
- 0.031
- 0.1559
- 0.1702
- 0.0265
- 0.1742
- 0.1732
- 0.1785
- 0.1798
- 0.0275
- 0.0315
- 0.1787
- 0.1933
- 0.1991
- 0.0321
- 0.0298
- 0.1975
- 0.2041
- 0.2005
- 0.2069
- 0.2128
- 0.2063
- 0.2177
- 0.2142
- 0.2222
- 0.2207
- 0.2271
- 0.0311
- 0.2267
- 0.2231
- 0.228
- 0.0362
- 0.0346
- 0.2305
- 0.0321
- 0.0346
- 0.2359
- 0.2429
- 0.0343
- 0.0338
- 0.2387
- 0.2416
- 0.0344
- 0.2394
- 0.231
- 0.2383
- 0.24
- 0.2448
- 0.2515
- 0.2492
- 0.2503
- 0.2447
- 0.2554
- 0.2596
- 0.2664
- 0.2648
- 0.0309
- 0.0384
- 0.2599
- 0.2601
- 0.0364
- 0.0377
- 0.037
- 0.2624
- 0.2596
- 0.2729
- 0.0423
- 0.2649
- 0.0425
- 0.2672
- 0.2752
- 0.2647
- 0.0407
- 0.2641
- 0.0429
- 0.2697
- 0.266
- 0.2675
- 0.2775
- 0.2698
- 0.2785
- 0.2804
- 0.272
- 0.0416
- 0.2695
- 0.2703
- 0.2681
- 0.2783
- 0.2789
- 0.2752
- 0.0493
- 0.0443
test_loss_list:
- 1.8041493368148804
- 3.659228048324585
- 3.8610170173645018
- 1.7330764245986938
- 1.7134836673736573
- 1.7078343224525452
- 1.7062537717819213
- 1.6878956055641174
- 1.6871016550064086
- 3.6429517555236814
- 1.64574675321579
- 1.6419002866744996
- 3.669766426086426
- 1.6074553585052491
- 1.616219539642334
- 1.6271645545959472
- 1.620484173297882
- 3.827786741256714
- 3.61151291847229
- 1.552104287147522
- 1.555429172515869
- 1.5586833262443542
- 3.5354182147979736
- 3.72419367313385
- 1.4935412907600403
- 1.5208787679672242
- 1.5463928174972534
- 1.533899292945862
- 1.5315767741203308
- 1.5643666338920594
- 1.5435094785690309
- 1.5666006588935852
- 1.5614851546287536
- 1.5523248219490051
- 1.5580443716049195
- 3.5611132431030272
- 1.5103053116798402
- 1.5334468722343444
- 1.5437322735786438
- 3.337942886352539
- 3.362847938537598
- 1.4468802094459534
- 3.3960563230514524
- 3.406870222091675
- 1.4189305067062379
- 1.4377866768836975
- 3.309145426750183
- 3.470623559951782
- 1.4216215991973877
- 1.4335957765579224
- 3.2740381240844725
- 1.4404458594322205
- 1.4870843863487244
- 1.4762229585647584
- 1.4714049482345581
- 1.486000669002533
- 1.4723005151748658
- 1.4999960064888
- 1.5017946910858155
- 1.5066946053504944
- 1.50721750497818
- 1.491071844100952
- 1.5030952858924866
- 1.5103135538101196
- 3.5986234998703
- 3.214014859199524
- 1.4100341296195984
- 1.4320299911499024
- 3.2676871490478514
- 3.2505817461013793
- 3.2388186073303222
- 1.3735710859298706
- 1.3955228853225707
- 1.3967533564567567
- 3.108667974472046
- 1.4038247394561767
- 3.067460980415344
- 1.3790154838562012
- 1.3871776604652404
- 1.4283232283592224
- 3.0617890977859497
- 1.4130903816223144
- 3.0539157390594482
- 1.393257715702057
- 1.4216499876976014
- 1.42960284948349
- 1.4254136514663696
- 1.43925683259964
- 1.4504158568382264
- 1.4402277135849
- 1.4653332567214965
- 3.2142507362365724
- 1.436157386302948
- 1.4565315747261047
- 1.4611413812637328
- 1.4546532487869264
- 1.4500043129920959
- 1.479913980960846
- 3.092526426315308
- 3.2351086044311526
train_accuracy:
- 0.057
- 0.0
- 0.0
- 0.088
- 0.129
- 0.091
- 0.189
- 0.184
- 0.184
- 0.0
- 0.159
- 0.143
- 0.0
- 0.161
- 0.211
- 0.161
- 0.211
- 0.0
- 0.0
- 0.227
- 0.228
- 0.187
- 0.0
- 0.0
- 0.195
- 0.174
- 0.224
- 0.194
- 0.267
- 0.201
- 0.235
- 0.247
- 0.208
- 0.227
- 0.231
- 0.0
- 0.285
- 0.208
- 0.282
- 0.0
- 0.0
- 0.192
- 0.0
- 0.0
- 0.224
- 0.271
- 0.0
- 0.0
- 0.243
- 0.224
- 0.0
- 0.243
- 0.214
- 0.285
- 0.264
- 0.265
- 0.282
- 0.295
- 0.314
- 0.289
- 0.318
- 0.274
- 0.273
- 0.291
- 0.0
- 0.0
- 0.322
- 0.321
- 0.0
- 0.0
- 0.0
- 0.288
- 0.314
- 0.32
- 0.0
- 0.321
- 0.0
- 0.27
- 0.271
- 0.258
- 0.0
- 0.276
- 0.0
- 0.278
- 0.297
- 0.265
- 0.322
- 0.325
- 0.31
- 0.3
- 0.324
- 0.0
- 0.295
- 0.308
- 0.306
- 0.35
- 0.276
- 0.303
- 0.0
- 0.0
train_loss:
- 4.121
- 1.109
- 1.461
- 4.04
- 3.551
- 3.148
- 3.229
- 3.176
- 2.988
- 0.974
- 3.381
- 2.712
- 1.125
- 2.996
- 2.912
- 2.388
- 2.469
- 1.328
- 1.13
- 2.947
- 2.645
- 2.137
- 0.835
- 1.186
- 3.056
- 2.225
- 2.33
- 2.019
- 2.263
- 1.771
- 2.246
- 1.729
- 2.285
- 2.338
- 1.861
- 0.902
- 2.184
- 1.673
- 1.595
- 0.772
- 1.031
- 1.625
- 0.696
- 0.693
- 2.235
- 1.645
- 0.609
- 0.221
- 1.844
- 1.293
- 0.442
- 1.121
- 0.734
- 2.03
- 1.734
- 1.413
- 1.936
- 1.319
- 1.538
- 1.618
- 1.223
- 0.949
- 1.174
- 1.018
- 0.745
- 0.796
- 1.471
- 0.833
- 0.493
- 0.742
- 0.511
- 1.707
- 1.413
- 1.059
- 0.405
- 1.045
- 0.411
- 1.362
- 0.84
- 0.523
- 0.379
- 1.618
- 0.383
- 1.149
- 1.192
- 1.068
- 1.102
- 0.894
- 0.759
- 0.681
- 0.719
- 0.405
- 1.079
- 0.588
- 0.635
- 0.863
- 0.566
- 0.616
- 0.347
- 0.075
unequal: 0
verbose: 1
