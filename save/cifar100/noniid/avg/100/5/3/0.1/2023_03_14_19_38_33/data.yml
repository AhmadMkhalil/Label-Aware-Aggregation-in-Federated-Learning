avg_train_accuracy: 0.341
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0252
- 0.0753
- 0.0996
- 0.0281
- 0.1057
- 0.0233
- 0.1143
- 0.1364
- 0.0274
- 0.0289
- 0.0275
- 0.144
- 0.0315
- 0.1431
- 0.1566
- 0.1576
- 0.1659
- 0.1737
- 0.0322
- 0.1747
- 0.029
- 0.1792
- 0.1788
- 0.1849
- 0.1984
- 0.034
- 0.1972
- 0.209
- 0.0287
- 0.2019
- 0.2039
- 0.2108
- 0.216
- 0.2255
- 0.0293
- 0.2269
- 0.0291
- 0.2253
- 0.2322
- 0.225
- 0.2317
- 0.0289
- 0.2276
- 0.2461
- 0.2428
- 0.0346
- 0.24
- 0.2447
- 0.0349
- 0.2379
- 0.2409
- 0.2459
- 0.0372
- 0.0359
- 0.0323
- 0.2444
- 0.247
- 0.2572
- 0.2508
- 0.2586
- 0.2578
- 0.2628
- 0.0389
- 0.2643
- 0.2578
- 0.0386
- 0.2584
- 0.2548
- 0.2602
- 0.0394
- 0.2574
- 0.2604
- 0.2708
- 0.0362
- 0.0351
- 0.0362
- 0.0347
- 0.2731
- 0.0374
- 0.0394
- 0.2698
- 0.0448
- 0.043
- 0.2728
- 0.2754
- 0.0395
- 0.0391
- 0.2702
- 0.0481
- 0.0409
- 0.2707
- 0.2759
- 0.2747
- 0.0492
- 0.2751
- 0.0568
- 0.2773
- 0.2719
- 0.2697
- 0.2788
test_loss_list:
- 3.0155239152908324
- 1.793004117012024
- 1.7638420104980468
- 3.7139804553985596
- 1.738811206817627
- 3.727203845977783
- 1.6917512273788453
- 1.691720151901245
- 3.6650008153915405
- 3.857542381286621
- 3.8158296966552734
- 1.6203550457954408
- 3.637894630432129
- 1.6259273099899292
- 1.6229866743087769
- 1.6532976937294006
- 1.641542456150055
- 1.6339035534858704
- 3.62132399559021
- 1.5981486344337463
- 3.5599345684051515
- 1.5675571036338807
- 1.5917447090148926
- 1.5846417832374573
- 1.5665552639961242
- 3.4533669185638427
- 1.567696647644043
- 1.5575378227233887
- 3.5097244453430174
- 1.539399015903473
- 1.5429072308540344
- 1.55376788854599
- 1.550141851902008
- 1.5338321828842163
- 3.452570552825928
- 1.5130163717269898
- 3.518016858100891
- 1.4756294012069702
- 1.480351722240448
- 1.5151048350334166
- 1.4995941400527955
- 3.528810157775879
- 1.4908559203147889
- 1.4675623965263367
- 1.4771124053001403
- 3.319577012062073
- 1.4713764381408692
- 1.4845947432518005
- 3.4268368816375734
- 1.4554882431030274
- 1.4690728759765626
- 1.4655367827415466
- 3.327326331138611
- 3.343360538482666
- 3.276282062530518
- 1.391137545108795
- 1.420245990753174
- 1.4239601349830628
- 1.4420120024681091
- 1.4317640233039857
- 1.4477092218399048
- 1.4619854998588562
- 3.219508213996887
- 1.427796301841736
- 1.452116379737854
- 3.3135403919219972
- 1.4350057578086852
- 1.4448203420639039
- 1.4590628218650818
- 3.1366138887405395
- 1.4363958096504212
- 1.442444655895233
- 1.4462356328964234
- 3.3202323484420777
- 3.472858304977417
- 3.287016215324402
- 3.3658119153976442
- 1.3763470792770385
- 3.2813372898101805
- 3.1618225288391115
- 1.3683137559890748
- 3.190634446144104
- 3.160148973464966
- 1.3411405348777772
- 1.3735073924064636
- 3.1555674028396608
- 3.2851399278640745
- 1.3523656916618347
- 2.904416356086731
- 3.0938711833953856
- 1.3685681867599486
- 1.3826979613304138
- 1.4005432558059692
- 2.922201075553894
- 1.39715744972229
- 2.8620727109909057
- 1.3826911401748658
- 1.4157886052131652
- 1.4283617615699769
- 1.4189962482452392
train_accuracy:
- 0.0
- 0.081
- 0.142
- 0.0
- 0.105
- 0.0
- 0.161
- 0.129
- 0.0
- 0.0
- 0.0
- 0.134
- 0.0
- 0.175
- 0.172
- 0.165
- 0.212
- 0.17
- 0.0
- 0.225
- 0.0
- 0.181
- 0.182
- 0.197
- 0.247
- 0.0
- 0.209
- 0.254
- 0.0
- 0.215
- 0.266
- 0.261
- 0.243
- 0.267
- 0.0
- 0.226
- 0.0
- 0.24
- 0.299
- 0.255
- 0.255
- 0.0
- 0.266
- 0.287
- 0.312
- 0.0
- 0.269
- 0.303
- 0.0
- 0.261
- 0.279
- 0.261
- 0.0
- 0.0
- 0.0
- 0.267
- 0.296
- 0.314
- 0.274
- 0.282
- 0.295
- 0.289
- 0.0
- 0.304
- 0.296
- 0.0
- 0.293
- 0.293
- 0.302
- 0.0
- 0.271
- 0.32
- 0.289
- 0.0
- 0.0
- 0.0
- 0.0
- 0.333
- 0.0
- 0.0
- 0.312
- 0.0
- 0.0
- 0.316
- 0.334
- 0.0
- 0.0
- 0.315
- 0.0
- 0.0
- 0.265
- 0.35
- 0.319
- 0.0
- 0.318
- 0.0
- 0.339
- 0.298
- 0.32
- 0.341
train_loss:
- 1.092
- 4.363
- 3.669
- 0.975
- 3.828
- 1.281
- 3.668
- 3.053
- 1.009
- 1.489
- 0.988
- 3.561
- 0.806
- 3.301
- 2.729
- 2.296
- 2.808
- 2.771
- 0.766
- 3.082
- 1.022
- 2.471
- 1.811
- 2.413
- 2.635
- 0.654
- 1.959
- 2.647
- 0.881
- 2.345
- 2.236
- 2.195
- 2.387
- 2.383
- 0.762
- 2.085
- 0.965
- 1.85
- 1.907
- 1.284
- 2.2
- 0.674
- 2.278
- 1.998
- 1.905
- 0.564
- 2.011
- 1.684
- 0.671
- 1.943
- 1.363
- 1.675
- 0.462
- 0.735
- 0.97
- 1.695
- 1.329
- 1.667
- 1.589
- 1.297
- 1.251
- 1.626
- 0.533
- 1.257
- 1.314
- 0.481
- 1.347
- 1.028
- 0.87
- 0.448
- 1.56
- 0.723
- 1.354
- 0.732
- 0.227
- 0.625
- 0.136
- 1.649
- 0.42
- 0.449
- 1.392
- 0.465
- 0.395
- 1.215
- 1.13
- 0.435
- 0.522
- 0.998
- 0.273
- 0.079
- 1.333
- 0.931
- 0.764
- 0.255
- 0.622
- 0.162
- 0.812
- 0.938
- 1.017
- 0.569
unequal: 0
verbose: 1
