avg_train_accuracy: 0.332
avg_train_loss: 0.008
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0379
- 0.0821
- 0.026
- 0.1085
- 0.1264
- 0.1284
- 0.0303
- 0.1427
- 0.1421
- 0.1586
- 0.1618
- 0.163
- 0.1721
- 0.0268
- 0.0276
- 0.0311
- 0.0298
- 0.173
- 0.1722
- 0.1816
- 0.0322
- 0.1878
- 0.1939
- 0.0326
- 0.2
- 0.0301
- 0.1989
- 0.2132
- 0.2077
- 0.0332
- 0.034
- 0.2083
- 0.0343
- 0.2092
- 0.0342
- 0.2184
- 0.2175
- 0.0348
- 0.0311
- 0.2228
- 0.2273
- 0.2357
- 0.035
- 0.0347
- 0.0356
- 0.2261
- 0.0348
- 0.2394
- 0.2372
- 0.0369
- 0.2458
- 0.2479
- 0.2405
- 0.0339
- 0.2441
- 0.2364
- 0.2434
- 0.254
- 0.0405
- 0.2579
- 0.2603
- 0.2501
- 0.2474
- 0.0408
- 0.2509
- 0.2553
- 0.251
- 0.2463
- 0.2643
- 0.2635
- 0.0391
- 0.2679
- 0.2687
- 0.2631
- 0.2666
- 0.2754
- 0.268
- 0.2686
- 0.0465
- 0.2696
- 0.264
- 0.2594
- 0.2712
- 0.2746
- 0.2681
- 0.2724
- 0.0342
- 0.2747
- 0.2649
- 0.0443
- 0.2716
- 0.2778
- 0.2815
- 0.2842
- 0.2722
- 0.2811
- 0.2821
- 0.2771
- 0.0404
- 0.2821
test_loss_list:
- 1.8313161087036134
- 1.7735721778869629
- 3.7628150367736817
- 1.7129951858520507
- 1.719398889541626
- 1.7260218048095703
- 3.810914363861084
- 1.6580718445777893
- 1.667882628440857
- 1.6660572719573974
- 1.6611337280273437
- 1.6628902459144592
- 1.6643285989761352
- 3.642353067398071
- 3.8273808670043947
- 3.6388444328308105
- 3.7117577838897704
- 1.539881365299225
- 1.5627111172676087
- 1.563283588886261
- 3.6717624187469484
- 1.5464423942565917
- 1.554375283718109
- 3.5937249851226807
- 1.5404814553260804
- 3.543175096511841
- 1.5036536765098572
- 1.509079098701477
- 1.523773443698883
- 3.532212677001953
- 3.5474078369140627
- 1.468833041191101
- 3.3888197135925293
- 1.473717324733734
- 3.3280709743499757
- 1.4596034097671509
- 1.4857227969169617
- 3.2765075540542603
- 3.42014666557312
- 1.4311748957633972
- 1.455661451816559
- 1.4645058441162109
- 3.346307978630066
- 3.3032483148574827
- 3.2967504835128785
- 1.4129226732254028
- 3.219419960975647
- 1.4228114128112792
- 1.4339909267425537
- 3.2370909070968628
- 1.4383305430412292
- 1.44879563331604
- 1.468542022705078
- 3.2565654420852663
- 1.4235309147834778
- 1.4588176226615905
- 1.4635541725158692
- 1.4568039727211
- 3.1257129192352293
- 1.4170508670806885
- 1.4266648292541504
- 1.467564685344696
- 1.4763289785385132
- 3.1288148880004885
- 1.4414426469802857
- 1.453909957408905
- 1.4693084192276
- 1.4875977301597596
- 1.4583374071121216
- 1.4612589883804321
- 3.1629308748245237
- 1.4206773519515992
- 1.4451337218284608
- 1.4592479348182679
- 1.4657707071304322
- 1.453039927482605
- 1.4757519197463989
- 1.497056748867035
- 3.1615622901916502
- 1.4460271644592284
- 1.461225039958954
- 1.4831927347183227
- 1.468561625480652
- 1.4821956872940063
- 1.4964408850669861
- 1.479381799697876
- 3.2576172828674315
- 1.422339015007019
- 1.4560254621505737
- 3.2754632425308228
- 1.41587753534317
- 1.413420639038086
- 1.4247453022003174
- 1.4318680024147035
- 1.4556909775733948
- 1.4641169023513794
- 1.4624137687683105
- 1.4769015765190125
- 3.1756041765213014
- 1.4303139972686767
train_accuracy:
- 0.049
- 0.106
- 0.0
- 0.092
- 0.151
- 0.15
- 0.0
- 0.164
- 0.168
- 0.189
- 0.146
- 0.239
- 0.216
- 0.0
- 0.0
- 0.0
- 0.0
- 0.224
- 0.201
- 0.166
- 0.0
- 0.222
- 0.227
- 0.0
- 0.233
- 0.0
- 0.219
- 0.216
- 0.212
- 0.0
- 0.0
- 0.229
- 0.0
- 0.261
- 0.0
- 0.258
- 0.269
- 0.0
- 0.0
- 0.254
- 0.272
- 0.249
- 0.0
- 0.0
- 0.0
- 0.253
- 0.0
- 0.248
- 0.272
- 0.0
- 0.319
- 0.272
- 0.259
- 0.0
- 0.278
- 0.281
- 0.287
- 0.276
- 0.0
- 0.276
- 0.283
- 0.284
- 0.285
- 0.0
- 0.324
- 0.304
- 0.295
- 0.297
- 0.337
- 0.314
- 0.0
- 0.358
- 0.297
- 0.294
- 0.308
- 0.298
- 0.319
- 0.332
- 0.0
- 0.332
- 0.366
- 0.329
- 0.332
- 0.316
- 0.359
- 0.309
- 0.0
- 0.34
- 0.338
- 0.0
- 0.328
- 0.315
- 0.33
- 0.344
- 0.317
- 0.305
- 0.319
- 0.368
- 0.0
- 0.332
train_loss:
- 4.228
- 3.701
- 1.257
- 3.808
- 3.195
- 2.748
- 1.144
- 3.496
- 2.856
- 3.131
- 2.997
- 2.686
- 2.517
- 1.053
- 1.462
- 1.081
- 0.949
- 2.779
- 2.903
- 2.62
- 0.845
- 2.715
- 2.234
- 0.67
- 2.601
- 0.811
- 2.801
- 2.522
- 2.281
- 0.737
- 0.834
- 2.412
- 0.481
- 2.388
- 0.539
- 2.245
- 1.573
- 0.462
- 0.899
- 2.16
- 2.139
- 2.141
- 0.474
- 0.729
- 0.471
- 2.092
- 0.367
- 2.197
- 1.682
- 0.408
- 2.058
- 1.833
- 1.564
- 0.698
- 1.803
- 1.146
- 1.291
- 1.556
- 0.482
- 1.876
- 1.263
- 1.332
- 1.115
- 0.472
- 1.941
- 0.919
- 0.628
- 1.214
- 1.395
- 1.492
- 0.435
- 1.704
- 1.009
- 1.218
- 0.776
- 1.213
- 0.78
- 1.236
- 0.466
- 1.421
- 0.809
- 0.634
- 1.013
- 0.701
- 0.624
- 1.299
- 0.697
- 1.042
- 0.54
- 0.389
- 1.153
- 1.095
- 1.103
- 0.796
- 0.778
- 0.844
- 0.806
- 0.634
- 0.542
- 0.777
unequal: 0
verbose: 1
