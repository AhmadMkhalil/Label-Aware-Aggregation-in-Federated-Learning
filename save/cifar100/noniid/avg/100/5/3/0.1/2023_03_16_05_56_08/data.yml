avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0452
- 0.0902
- 0.0324
- 0.1065
- 0.1201
- 0.0337
- 0.0336
- 0.1287
- 0.1378
- 0.1419
- 0.1524
- 0.0281
- 0.1638
- 0.1619
- 0.1676
- 0.18
- 0.1886
- 0.1904
- 0.1974
- 0.1914
- 0.0295
- 0.0352
- 0.1898
- 0.0298
- 0.1992
- 0.2082
- 0.03
- 0.0348
- 0.0309
- 0.2085
- 0.0362
- 0.2115
- 0.0315
- 0.22
- 0.0368
- 0.2214
- 0.2255
- 0.2171
- 0.0319
- 0.2277
- 0.226
- 0.2265
- 0.2277
- 0.2256
- 0.0315
- 0.0367
- 0.241
- 0.2334
- 0.2366
- 0.2333
- 0.2376
- 0.2405
- 0.2434
- 0.032
- 0.0317
- 0.2511
- 0.2449
- 0.2433
- 0.2494
- 0.2478
- 0.2496
- 0.2625
- 0.2557
- 0.2575
- 0.2652
- 0.0278
- 0.0374
- 0.2634
- 0.2583
- 0.0312
- 0.0402
- 0.0306
- 0.2594
- 0.2645
- 0.2591
- 0.0455
- 0.2604
- 0.2589
- 0.0325
- 0.2514
- 0.2706
- 0.2623
- 0.0463
- 0.2737
- 0.0346
- 0.2747
- 0.2752
- 0.2696
- 0.0388
- 0.2685
- 0.2705
- 0.2753
- 0.2731
- 0.276
- 0.2752
- 0.273
- 0.0514
- 0.0358
- 0.278
- 0.0352
test_loss_list:
- 1.8362971448898315
- 1.786781997680664
- 3.8363393783569335
- 1.738403935432434
- 1.720437891483307
- 3.5974125385284426
- 3.8682562160491942
- 1.7061092495918273
- 1.6811037707328795
- 1.6973780918121337
- 1.6983785891532899
- 3.837649173736572
- 1.6374865913391112
- 1.6468511533737182
- 1.6680576276779175
- 1.6483116197586059
- 1.6377351355552674
- 1.6344763803482056
- 1.6378253245353698
- 1.6532864689826965
- 3.7043684768676757
- 3.5486844539642335
- 1.5772443890571595
- 3.6032539653778075
- 1.564303493499756
- 1.5585902070999145
- 3.4791618061065672
- 3.410048007965088
- 3.561406764984131
- 1.5233552980422973
- 3.258459997177124
- 1.5273170351982117
- 3.3879151153564453
- 1.5250724792480468
- 3.1605219984054567
- 1.5184285378456115
- 1.5292083263397216
- 1.5602066612243652
- 3.3081691884994506
- 1.524773232936859
- 1.5439410996437073
- 1.546596200466156
- 1.5592254900932312
- 1.579576530456543
- 3.347363677024841
- 3.216927618980408
- 1.4849485349655152
- 1.51162348985672
- 1.5224071717262269
- 1.5340464639663696
- 1.5609876108169556
- 1.5472129893302917
- 1.5393997430801392
- 3.3955186653137206
- 3.5457044410705567
- 1.509172101020813
- 1.5408608222007751
- 1.5505453634262085
- 1.5472341871261597
- 1.5602901196479797
- 1.5666250920295715
- 1.5502578520774841
- 1.557922523021698
- 1.556155800819397
- 1.5553568768501282
- 3.6577348709106445
- 3.211876173019409
- 1.4132834005355834
- 1.4370759677886964
- 3.360746111869812
- 3.17479540348053
- 3.3946626234054564
- 1.406005823612213
- 1.4174814701080323
- 1.4476544618606568
- 3.0147763013839723
- 1.4279579710960388
- 1.4531989908218383
- 3.259230513572693
- 1.4562184667587281
- 1.428631317615509
- 1.4725307154655456
- 3.0543330097198487
- 1.4114473628997803
- 3.236898956298828
- 1.405182192325592
- 1.4279230690002442
- 1.4528299474716186
- 3.132126598358154
- 1.4153350853919984
- 1.4419895315170288
- 1.4431664562225341
- 1.4529287672042848
- 1.4676137638092042
- 1.4714219903945922
- 1.4885504865646362
- 3.0070565700531007
- 3.174856033325195
- 1.4088447713851928
- 3.228633694648743
train_accuracy:
- 0.059
- 0.093
- 0.0
- 0.101
- 0.13
- 0.0
- 0.0
- 0.152
- 0.121
- 0.121
- 0.135
- 0.0
- 0.163
- 0.165
- 0.157
- 0.184
- 0.229
- 0.2
- 0.182
- 0.163
- 0.0
- 0.0
- 0.142
- 0.0
- 0.199
- 0.209
- 0.0
- 0.0
- 0.0
- 0.194
- 0.0
- 0.217
- 0.0
- 0.215
- 0.0
- 0.208
- 0.232
- 0.201
- 0.0
- 0.228
- 0.199
- 0.218
- 0.235
- 0.203
- 0.0
- 0.0
- 0.225
- 0.255
- 0.253
- 0.231
- 0.236
- 0.289
- 0.268
- 0.0
- 0.0
- 0.282
- 0.291
- 0.222
- 0.266
- 0.285
- 0.269
- 0.243
- 0.272
- 0.247
- 0.273
- 0.0
- 0.0
- 0.299
- 0.293
- 0.0
- 0.0
- 0.0
- 0.302
- 0.251
- 0.262
- 0.0
- 0.29
- 0.247
- 0.0
- 0.259
- 0.336
- 0.332
- 0.0
- 0.297
- 0.0
- 0.325
- 0.33
- 0.303
- 0.0
- 0.277
- 0.304
- 0.302
- 0.341
- 0.283
- 0.284
- 0.329
- 0.0
- 0.0
- 0.313
- 0.0
train_loss:
- 4.238
- 3.737
- 1.021
- 3.821
- 3.42
- 0.723
- 0.33
- 3.24
- 3.262
- 2.76
- 3.086
- 1.192
- 3.191
- 2.478
- 2.654
- 2.622
- 2.726
- 2.496
- 2.3
- 2.328
- 0.962
- 0.901
- 2.218
- 0.696
- 2.9
- 2.08
- 0.676
- 0.679
- 0.609
- 2.912
- 0.362
- 2.492
- 0.558
- 2.044
- 0.384
- 2.454
- 1.939
- 1.908
- 0.551
- 1.826
- 1.855
- 1.697
- 1.713
- 1.539
- 0.508
- 0.591
- 1.612
- 1.44
- 2.016
- 1.559
- 1.142
- 2.197
- 1.697
- 0.554
- 0.172
- 1.932
- 1.233
- 1.463
- 1.402
- 0.997
- 1.267
- 1.355
- 1.91
- 1.238
- 1.038
- 1.349
- 0.721
- 1.322
- 1.304
- 0.812
- 0.532
- 0.668
- 1.157
- 0.913
- 0.595
- 0.293
- 1.24
- 1.236
- 0.664
- 0.998
- 1.223
- 0.758
- 0.303
- 1.744
- 0.577
- 1.087
- 0.919
- 0.553
- 0.478
- 1.288
- 0.538
- 1.236
- 0.745
- 0.875
- 0.862
- 0.589
- 0.331
- 0.651
- 1.102
- 0.613
unequal: 0
verbose: 1
