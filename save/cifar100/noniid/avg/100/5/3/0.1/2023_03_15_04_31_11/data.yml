avg_train_accuracy: 0.361
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0479
- 0.0294
- 0.0847
- 0.0927
- 0.0282
- 0.1204
- 0.0296
- 0.127
- 0.1363
- 0.0306
- 0.0305
- 0.139
- 0.0268
- 0.1493
- 0.0304
- 0.1436
- 0.1589
- 0.1657
- 0.0301
- 0.1782
- 0.1718
- 0.0329
- 0.0306
- 0.1833
- 0.1928
- 0.192
- 0.1908
- 0.0298
- 0.2025
- 0.203
- 0.1987
- 0.0336
- 0.2099
- 0.0329
- 0.2053
- 0.2097
- 0.2128
- 0.2137
- 0.2223
- 0.0307
- 0.2135
- 0.222
- 0.2203
- 0.2177
- 0.2288
- 0.2372
- 0.0356
- 0.2388
- 0.0361
- 0.2355
- 0.0361
- 0.244
- 0.037
- 0.2401
- 0.2371
- 0.0331
- 0.0328
- 0.2366
- 0.2485
- 0.2396
- 0.2383
- 0.2506
- 0.2496
- 0.2554
- 0.2518
- 0.0383
- 0.251
- 0.0348
- 0.2532
- 0.0421
- 0.2494
- 0.2475
- 0.2544
- 0.258
- 0.2549
- 0.04
- 0.2529
- 0.244
- 0.2556
- 0.2678
- 0.2707
- 0.0473
- 0.0363
- 0.2643
- 0.0424
- 0.2632
- 0.268
- 0.2593
- 0.2676
- 0.2716
- 0.2656
- 0.2646
- 0.2737
- 0.2692
- 0.0485
- 0.2753
- 0.2784
- 0.2801
- 0.2771
- 0.2775
test_loss_list:
- 1.8240898323059083
- 3.798697624206543
- 1.7737692880630493
- 1.775963592529297
- 3.9106630420684816
- 1.6952618265151977
- 3.818108539581299
- 1.6840183115005494
- 1.7041444516181945
- 3.730558042526245
- 3.96494589805603
- 1.6577085757255554
- 3.7325221920013427
- 1.600644407272339
- 3.660521774291992
- 1.6052890086174012
- 1.601293704509735
- 1.599468915462494
- 3.6251864624023438
- 1.5637652850151063
- 1.588111596107483
- 3.486543588638306
- 3.6666312503814695
- 1.5397169041633605
- 1.5436728739738463
- 1.5763102293014526
- 1.5662365818023682
- 3.6203032684326173
- 1.5254706811904908
- 1.5476243424415588
- 1.5587011575698853
- 3.4801741313934325
- 1.51886470079422
- 3.4242102098464966
- 1.515540542602539
- 1.5351230716705322
- 1.5408814120292664
- 1.5591816473007203
- 1.5307595920562744
- 3.5969745254516603
- 1.4972484040260314
- 1.5144258761405944
- 1.53670800447464
- 1.557720079421997
- 1.5314206981658935
- 1.5282869362831115
- 3.366228446960449
- 1.4893000316619873
- 3.330779848098755
- 1.4460193634033203
- 3.2348993253707885
- 1.4501172590255738
- 3.1813280248641966
- 1.4558315896987915
- 1.4876193070411683
- 3.457263174057007
- 3.6785238647460936
- 1.470753562450409
- 1.454056441783905
- 1.4872655034065247
- 1.4640627312660217
- 1.476546175479889
- 1.4894947481155396
- 1.485641794204712
- 1.4935597920417785
- 3.1854558277130125
- 1.4551450610160828
- 3.338672742843628
- 1.441335141658783
- 3.072367858886719
- 1.439976348876953
- 1.4548221468925475
- 1.4496007561683655
- 1.4653136587142945
- 1.4821374702453614
- 3.223645958900452
- 1.432219078540802
- 1.4697579836845398
- 1.462740616798401
- 1.4379481720924376
- 1.4543859410285949
- 3.0912374305725097
- 3.3402474546432495
- 1.381933295726776
- 3.1125842905044556
- 1.3797434544563294
- 1.3924206137657165
- 1.4167632126808167
- 1.4263242626190185
- 1.4244931364059448
- 1.4294833755493164
- 1.452279109954834
- 1.4461228442192078
- 1.4607340145111083
- 3.0022765254974364
- 1.4069038391113282
- 1.417558274269104
- 1.4200371503829956
- 1.4311659598350526
- 1.4418304109573363
train_accuracy:
- 0.036
- 0.0
- 0.083
- 0.079
- 0.0
- 0.141
- 0.0
- 0.138
- 0.147
- 0.0
- 0.0
- 0.122
- 0.0
- 0.143
- 0.0
- 0.135
- 0.177
- 0.165
- 0.0
- 0.182
- 0.168
- 0.0
- 0.0
- 0.217
- 0.179
- 0.236
- 0.183
- 0.0
- 0.218
- 0.222
- 0.235
- 0.0
- 0.226
- 0.0
- 0.261
- 0.222
- 0.222
- 0.227
- 0.221
- 0.0
- 0.208
- 0.211
- 0.212
- 0.196
- 0.211
- 0.26
- 0.0
- 0.241
- 0.0
- 0.23
- 0.0
- 0.237
- 0.0
- 0.255
- 0.274
- 0.0
- 0.0
- 0.254
- 0.261
- 0.264
- 0.217
- 0.251
- 0.277
- 0.305
- 0.275
- 0.0
- 0.261
- 0.0
- 0.3
- 0.0
- 0.308
- 0.291
- 0.238
- 0.307
- 0.292
- 0.0
- 0.312
- 0.279
- 0.311
- 0.283
- 0.286
- 0.0
- 0.0
- 0.322
- 0.0
- 0.322
- 0.295
- 0.249
- 0.305
- 0.321
- 0.257
- 0.25
- 0.346
- 0.264
- 0.0
- 0.332
- 0.283
- 0.334
- 0.31
- 0.361
train_loss:
- 4.246
- 1.184
- 4.079
- 3.277
- 1.237
- 3.679
- 0.937
- 3.499
- 3.192
- 1.012
- 0.438
- 3.254
- 1.233
- 3.477
- 0.903
- 2.844
- 2.796
- 2.721
- 0.747
- 2.966
- 2.347
- 0.757
- 0.828
- 3.077
- 2.153
- 2.389
- 1.895
- 1.009
- 2.973
- 2.148
- 2.374
- 0.678
- 2.133
- 0.481
- 2.377
- 1.693
- 2.049
- 1.594
- 1.758
- 0.828
- 2.437
- 1.46
- 1.115
- 0.897
- 2.193
- 2.294
- 0.586
- 1.906
- 0.756
- 1.275
- 0.445
- 1.632
- 0.374
- 2.038
- 1.337
- 0.743
- 0.26
- 1.306
- 1.36
- 0.952
- 1.941
- 1.123
- 0.953
- 1.907
- 1.087
- 0.49
- 0.888
- 0.586
- 1.727
- 0.353
- 1.234
- 1.686
- 1.626
- 1.046
- 1.263
- 0.599
- 1.01
- 0.582
- 1.052
- 1.084
- 1.534
- 0.43
- 0.746
- 1.11
- 0.444
- 0.769
- 1.184
- 1.39
- 0.812
- 0.49
- 0.996
- 0.637
- 0.725
- 1.11
- 0.431
- 0.701
- 0.871
- 0.428
- 1.022
- 0.366
unequal: 0
verbose: 1
