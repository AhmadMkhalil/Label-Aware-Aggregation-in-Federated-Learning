avg_train_accuracy: 0.315
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0377
- 0.0244
- 0.0817
- 0.1079
- 0.1139
- 0.0308
- 0.1319
- 0.1375
- 0.1517
- 0.154
- 0.0323
- 0.1565
- 0.1667
- 0.1594
- 0.1742
- 0.1806
- 0.0262
- 0.1793
- 0.185
- 0.1872
- 0.1874
- 0.2036
- 0.1999
- 0.2022
- 0.1981
- 0.0333
- 0.2067
- 0.2125
- 0.2161
- 0.2113
- 0.2024
- 0.2126
- 0.2174
- 0.2273
- 0.2369
- 0.2381
- 0.0341
- 0.0335
- 0.2295
- 0.0348
- 0.2387
- 0.2319
- 0.239
- 0.0354
- 0.2275
- 0.2425
- 0.257
- 0.0355
- 0.2453
- 0.2379
- 0.2557
- 0.2501
- 0.256
- 0.2531
- 0.2582
- 0.2475
- 0.2492
- 0.2434
- 0.2498
- 0.2542
- 0.0303
- 0.2636
- 0.2602
- 0.257
- 0.2612
- 0.2587
- 0.2703
- 0.0323
- 0.2651
- 0.262
- 0.2634
- 0.2698
- 0.2664
- 0.271
- 0.2699
- 0.2671
- 0.2634
- 0.2689
- 0.2739
- 0.2675
- 0.2759
- 0.0417
- 0.2743
- 0.2696
- 0.0484
- 0.2758
- 0.2743
- 0.0514
- 0.2704
- 0.2711
- 0.0355
- 0.2764
- 0.283
- 0.2791
- 0.2852
- 0.2893
- 0.0362
- 0.0358
- 0.2874
- 0.2897
test_loss_list:
- 1.828456892967224
- 3.8004276275634767
- 1.7701710844039917
- 1.7465897798538208
- 1.7517048025131225
- 3.9912766456604003
- 1.6874904870986938
- 1.685472798347473
- 1.6845416569709777
- 1.6903640007972718
- 3.7855702114105223
- 1.6552448773384094
- 1.6692603826522827
- 1.6648187232017517
- 1.656891667842865
- 1.6455119132995606
- 3.6885126495361327
- 1.6123573350906373
- 1.6173888397216798
- 1.6279016423225403
- 1.619307131767273
- 1.5994318270683288
- 1.6188979268074035
- 1.6154832720756531
- 1.6329280519485474
- 3.737489824295044
- 1.552104036808014
- 1.5661333465576173
- 1.5572886848449707
- 1.5744901847839357
- 1.6018668961524964
- 1.5874399423599244
- 1.5956381177902221
- 1.5664699602127075
- 1.559080126285553
- 1.5755180716514587
- 3.7137092304229737
- 3.5783965587615967
- 1.4882718229293823
- 3.4060577392578124
- 1.483921341896057
- 1.4964757204055785
- 1.5086740708351136
- 3.4985106372833252
- 1.4940409684181213
- 1.4975413632392884
- 1.489408748149872
- 3.431755428314209
- 1.4784401631355286
- 1.5090653109550476
- 1.5028804445266724
- 1.5327010440826416
- 1.5135089993476867
- 1.5307420372962952
- 1.532095766067505
- 1.5460915231704713
- 1.5548320817947388
- 1.5585846161842347
- 1.5557486152648925
- 1.5468885326385498
- 3.4875362634658815
- 1.4633003854751587
- 1.4770724940299989
- 1.4979111170768737
- 1.4889882493019104
- 1.5109578204154968
- 1.494980778694153
- 3.434543137550354
- 1.4697909092903136
- 1.4922122859954834
- 1.503396484851837
- 1.5090253973007202
- 1.512153789997101
- 1.5096655511856079
- 1.5105971527099609
- 1.5210340785980225
- 1.5638619256019592
- 1.552408413887024
- 1.518332817554474
- 1.5370313119888306
- 1.5547428846359252
- 3.315860457420349
- 1.4762868118286132
- 1.4959115266799927
- 3.2072088003158568
- 1.472490577697754
- 1.4961583590507508
- 3.1485316228866576
- 1.498149380683899
- 1.5009797811508179
- 3.407138352394104
- 1.4499773120880126
- 1.4533743810653688
- 1.4620706486701964
- 1.4753972601890564
- 1.471073532104492
- 3.4629008293151857
- 3.6227896213531494
- 1.3957403445243834
- 1.4076083111763
train_accuracy:
- 0.046
- 0.0
- 0.096
- 0.108
- 0.12
- 0.0
- 0.154
- 0.166
- 0.166
- 0.183
- 0.0
- 0.186
- 0.201
- 0.145
- 0.2
- 0.198
- 0.0
- 0.193
- 0.214
- 0.213
- 0.204
- 0.218
- 0.246
- 0.221
- 0.205
- 0.0
- 0.234
- 0.24
- 0.235
- 0.224
- 0.223
- 0.237
- 0.259
- 0.205
- 0.24
- 0.267
- 0.0
- 0.0
- 0.254
- 0.0
- 0.221
- 0.267
- 0.223
- 0.0
- 0.248
- 0.27
- 0.295
- 0.0
- 0.292
- 0.268
- 0.271
- 0.26
- 0.287
- 0.276
- 0.294
- 0.249
- 0.295
- 0.263
- 0.306
- 0.27
- 0.0
- 0.23
- 0.292
- 0.313
- 0.295
- 0.294
- 0.303
- 0.0
- 0.231
- 0.249
- 0.3
- 0.302
- 0.291
- 0.287
- 0.293
- 0.279
- 0.274
- 0.322
- 0.299
- 0.248
- 0.297
- 0.0
- 0.309
- 0.299
- 0.0
- 0.301
- 0.304
- 0.0
- 0.291
- 0.316
- 0.0
- 0.306
- 0.307
- 0.316
- 0.315
- 0.313
- 0.0
- 0.0
- 0.251
- 0.315
train_loss:
- 4.222
- 1.296
- 3.984
- 3.504
- 3.066
- 1.176
- 3.63
- 3.262
- 2.965
- 2.545
- 0.908
- 3.078
- 2.4
- 2.998
- 3.015
- 2.805
- 1.246
- 2.589
- 2.498
- 2.112
- 2.609
- 2.583
- 2.544
- 2.239
- 1.745
- 1.093
- 2.352
- 2.164
- 2.077
- 1.738
- 1.332
- 1.814
- 2.15
- 2.325
- 2.18
- 1.785
- 0.751
- 1.09
- 1.741
- 0.516
- 2.158
- 1.255
- 1.605
- 0.632
- 1.76
- 1.759
- 1.764
- 0.525
- 1.476
- 1.258
- 1.441
- 0.985
- 1.591
- 0.93
- 1.201
- 1.096
- 1.118
- 0.818
- 0.848
- 1.738
- 1.049
- 1.79
- 0.81
- 1.28
- 0.813
- 0.628
- 1.132
- 0.755
- 1.492
- 0.853
- 0.633
- 1.026
- 0.457
- 0.913
- 1.191
- 0.758
- 0.538
- 0.88
- 0.518
- 0.935
- 0.666
- 0.632
- 0.628
- 0.449
- 0.362
- 0.947
- 0.467
- 0.321
- 0.508
- 0.379
- 0.731
- 1.596
- 0.871
- 0.324
- 0.497
- 0.591
- 0.744
- 0.195
- 1.066
- 0.32
unequal: 0
verbose: 1
