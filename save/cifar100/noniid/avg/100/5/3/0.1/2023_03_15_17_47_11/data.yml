avg_train_accuracy: 0.403
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0424
- 0.0786
- 0.0256
- 0.1033
- 0.1283
- 0.0254
- 0.0262
- 0.0265
- 0.1234
- 0.0327
- 0.1349
- 0.1492
- 0.0295
- 0.151
- 0.1586
- 0.0338
- 0.1666
- 0.0261
- 0.0297
- 0.0321
- 0.0267
- 0.0305
- 0.1734
- 0.171
- 0.1867
- 0.1943
- 0.1946
- 0.2023
- 0.1972
- 0.032
- 0.2018
- 0.0299
- 0.2142
- 0.2092
- 0.2233
- 0.2177
- 0.2169
- 0.2222
- 0.0346
- 0.2269
- 0.2278
- 0.2338
- 0.2342
- 0.2307
- 0.2411
- 0.0315
- 0.2431
- 0.2399
- 0.0368
- 0.2476
- 0.2409
- 0.0328
- 0.2474
- 0.2502
- 0.0388
- 0.2527
- 0.029
- 0.0327
- 0.0336
- 0.2568
- 0.2582
- 0.0412
- 0.2614
- 0.0416
- 0.0406
- 0.0398
- 0.2604
- 0.2637
- 0.0372
- 0.2687
- 0.2612
- 0.2618
- 0.0366
- 0.0357
- 0.039
- 0.2566
- 0.2589
- 0.0445
- 0.264
- 0.2747
- 0.2657
- 0.2749
- 0.2726
- 0.2691
- 0.0426
- 0.2619
- 0.2768
- 0.281
- 0.0434
- 0.2829
- 0.0457
- 0.0404
- 0.2801
- 0.0476
- 0.2873
- 0.0419
- 0.2792
- 0.2851
- 0.2906
- 0.2892
test_loss_list:
- 1.8324800682067872
- 1.789075345993042
- 3.6900688362121583
- 1.7395828318595887
- 1.7180815482139586
- 3.825355625152588
- 4.014364204406738
- 4.189448261260987
- 1.6884853982925414
- 3.7626680755615234
- 1.6558944416046142
- 1.6481334376335144
- 3.648351526260376
- 1.6314347434043883
- 1.6455572628974915
- 3.636888017654419
- 1.5849174451828003
- 3.647365083694458
- 3.5795294857025146
- 3.7959465408325195
- 3.806963949203491
- 3.8238424396514894
- 1.5371218776702882
- 1.548402364253998
- 1.535011031627655
- 1.5671459746360779
- 1.557302761077881
- 1.5790818428993225
- 1.6070566058158875
- 3.573801326751709
- 1.5511254692077636
- 3.485923070907593
- 1.4996454882621766
- 1.5237324333190918
- 1.525019633769989
- 1.539598183631897
- 1.5756486797332763
- 1.551565248966217
- 3.4746724700927736
- 1.5096093726158142
- 1.5326743626594543
- 1.5413863897323608
- 1.5235906004905702
- 1.5481143260002137
- 1.546278464794159
- 3.397463445663452
- 1.5109704971313476
- 1.5065679144859314
- 3.5202804946899415
- 1.4255384492874146
- 1.4748425817489623
- 3.335796389579773
- 1.438793728351593
- 1.4809717655181884
- 3.3405508518218996
- 1.4317412281036377
- 3.3836918449401856
- 3.5432887744903563
- 3.320264844894409
- 1.3973894548416137
- 1.4188709044456482
- 3.248461446762085
- 1.400936212539673
- 3.1443079328536987
- 3.3547919368743897
- 3.4362243700027464
- 1.3912923645973205
- 1.413439736366272
- 3.1574113845825194
- 1.4101527214050293
- 1.431418490409851
- 1.4381007885932922
- 3.0994120264053344
- 3.305681366920471
- 3.2448367261886597
- 1.3946737360954284
- 1.4217494869232177
- 3.0121130657196047
- 1.3862669444084168
- 1.3890249800682068
- 1.4167620205879212
- 1.423058478832245
- 1.4438496232032776
- 1.447241599559784
- 3.0114117813110353
- 1.4373585963249207
- 1.4255398797988892
- 1.4313673543930054
- 3.043337035179138
- 1.4123704409599305
- 3.018640661239624
- 3.1524567890167234
- 1.4303465819358825
- 3.0669570922851563
- 1.3845224046707154
- 3.1972761011123656
- 1.3539723682403564
- 1.3637801170349122
- 1.3857642245292663
- 1.392584035396576
train_accuracy:
- 0.033
- 0.112
- 0.0
- 0.093
- 0.119
- 0.0
- 0.0
- 0.0
- 0.153
- 0.0
- 0.18
- 0.157
- 0.0
- 0.227
- 0.225
- 0.0
- 0.18
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.197
- 0.197
- 0.198
- 0.261
- 0.239
- 0.278
- 0.269
- 0.0
- 0.202
- 0.0
- 0.228
- 0.211
- 0.228
- 0.235
- 0.229
- 0.271
- 0.0
- 0.253
- 0.259
- 0.231
- 0.258
- 0.284
- 0.343
- 0.0
- 0.267
- 0.269
- 0.0
- 0.278
- 0.273
- 0.0
- 0.298
- 0.284
- 0.0
- 0.241
- 0.0
- 0.0
- 0.0
- 0.343
- 0.263
- 0.0
- 0.293
- 0.0
- 0.0
- 0.0
- 0.263
- 0.314
- 0.0
- 0.361
- 0.332
- 0.275
- 0.0
- 0.0
- 0.0
- 0.28
- 0.227
- 0.0
- 0.283
- 0.321
- 0.272
- 0.387
- 0.38
- 0.342
- 0.0
- 0.25
- 0.308
- 0.304
- 0.0
- 0.269
- 0.0
- 0.0
- 0.289
- 0.0
- 0.407
- 0.0
- 0.306
- 0.364
- 0.312
- 0.403
train_loss:
- 4.249
- 3.817
- 1.281
- 3.8
- 3.461
- 1.371
- 0.717
- 0.611
- 3.652
- 1.057
- 3.403
- 2.911
- 1.016
- 3.02
- 2.303
- 0.72
- 3.223
- 0.965
- 1.024
- 0.355
- 0.931
- 0.359
- 3.147
- 2.882
- 2.552
- 2.208
- 2.43
- 1.894
- 1.542
- 0.651
- 2.589
- 0.759
- 2.721
- 1.945
- 2.052
- 1.649
- 1.394
- 2.324
- 0.613
- 2.397
- 1.641
- 1.773
- 1.868
- 1.509
- 1.602
- 0.73
- 1.495
- 2.099
- 0.713
- 1.93
- 1.215
- 0.577
- 1.386
- 1.514
- 0.511
- 1.404
- 0.483
- 0.79
- 0.533
- 1.638
- 1.575
- 0.397
- 1.492
- 0.303
- 0.086
- 0.073
- 1.973
- 1.143
- 0.451
- 1.311
- 0.878
- 1.106
- 0.384
- 0.106
- 0.687
- 1.013
- 2.12
- 0.374
- 1.645
- 0.851
- 1.659
- 1.06
- 0.677
- 0.727
- 0.389
- 1.534
- 1.21
- 1.291
- 0.33
- 1.286
- 0.261
- 0.086
- 1.14
- 0.402
- 0.935
- 0.494
- 1.451
- 0.664
- 0.98
- 0.609
unequal: 0
verbose: 1
