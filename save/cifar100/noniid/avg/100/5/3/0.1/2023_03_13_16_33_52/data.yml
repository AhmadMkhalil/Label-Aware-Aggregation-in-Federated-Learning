avg_train_accuracy: 0.338
avg_train_loss: 0.01
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0419
- 0.0852
- 0.0892
- 0.1177
- 0.1235
- 0.0249
- 0.0255
- 0.143
- 0.0312
- 0.0339
- 0.0339
- 0.0267
- 0.1426
- 0.1491
- 0.0329
- 0.1538
- 0.1473
- 0.0328
- 0.1664
- 0.1789
- 0.0337
- 0.0348
- 0.1851
- 0.0345
- 0.1865
- 0.1971
- 0.0276
- 0.1971
- 0.0274
- 0.1914
- 0.0346
- 0.199
- 0.1961
- 0.2095
- 0.2103
- 0.214
- 0.2127
- 0.2146
- 0.2225
- 0.2326
- 0.2214
- 0.0359
- 0.0338
- 0.035
- 0.2245
- 0.2218
- 0.2337
- 0.2346
- 0.2371
- 0.2385
- 0.2406
- 0.2332
- 0.0369
- 0.0355
- 0.2317
- 0.039
- 0.229
- 0.2449
- 0.04
- 0.0387
- 0.037
- 0.2455
- 0.0396
- 0.2473
- 0.2398
- 0.0392
- 0.2478
- 0.2525
- 0.2523
- 0.2551
- 0.2632
- 0.2669
- 0.2626
- 0.2617
- 0.0397
- 0.0378
- 0.2629
- 0.2514
- 0.0402
- 0.0389
- 0.2633
- 0.2611
- 0.2643
- 0.2767
- 0.2615
- 0.2714
- 0.2711
- 0.269
- 0.277
- 0.2685
- 0.0486
- 0.2674
- 0.2776
- 0.2754
- 0.052
- 0.2713
- 0.2795
- 0.2792
- 0.2771
- 0.2741
test_loss_list:
- 1.8432631301879883
- 1.7905407524108887
- 1.7906794357299805
- 1.7533226490020752
- 1.7396435022354126
- 3.7484543132781982
- 3.836207036972046
- 1.6518584847450257
- 3.6988749217987063
- 3.854136610031128
- 4.034806890487671
- 3.8200393962860106
- 1.607405025959015
- 1.6091813564300537
- 3.5630553722381593
- 1.6029967379570007
- 1.6410935759544372
- 3.5885949897766114
- 1.5891841816902161
- 1.5851625514030456
- 3.4825140619277954
- 3.490517330169678
- 1.5425892424583436
- 3.4134512901306153
- 1.5573153710365295
- 1.5476439833641051
- 3.5530327129364014
- 1.521184232234955
- 3.50991455078125
- 1.5435708856582642
- 3.3505073404312133
- 1.4987809944152832
- 1.513751549720764
- 1.5363109040260314
- 1.5330891275405885
- 1.5328455185890197
- 1.5579970002174377
- 1.551012670993805
- 1.5529769444465638
- 1.5399604511260987
- 1.566804015636444
- 3.378213701248169
- 3.5905845260620115
- 3.3749267292022704
- 1.4692461228370666
- 1.5089278793334961
- 1.4957046627998352
- 1.511076180934906
- 1.502477114200592
- 1.5039715194702148
- 1.5288149523735046
- 1.5633664202690125
- 3.278342909812927
- 3.3860769176483156
- 1.50021418094635
- 3.2185417938232423
- 1.5175652813911438
- 1.4927286052703856
- 3.2028944063186646
- 3.4082663822174073
- 3.251055374145508
- 1.4566654539108277
- 3.1565930604934693
- 1.4682041025161743
- 1.49974023103714
- 3.2000103616714477
- 1.4610726642608642
- 1.4641150617599488
- 1.4605344581604003
- 1.4823525905609132
- 1.4801044011116027
- 1.4771580052375795
- 1.4873518252372742
- 1.501529176235199
- 3.178774814605713
- 3.388997917175293
- 1.4755247020721436
- 1.511774570941925
- 3.1444319677352905
- 3.2775863647460937
- 1.4718995785713196
- 1.495353856086731
- 1.490800302028656
- 1.495870246887207
- 1.5019588875770569
- 1.512452607154846
- 1.520822865962982
- 1.5212468552589415
- 1.5084348297119141
- 1.539404900074005
- 3.100862965583801
- 1.4881598997116088
- 1.468839008808136
- 1.4930376768112184
- 3.0873888874053956
- 1.5046579885482787
- 1.4695621275901793
- 1.485077419281006
- 1.4912986111640931
- 1.4933991932868957
train_accuracy:
- 0.038
- 0.102
- 0.094
- 0.131
- 0.127
- 0.0
- 0.0
- 0.135
- 0.0
- 0.0
- 0.0
- 0.0
- 0.15
- 0.153
- 0.0
- 0.155
- 0.16
- 0.0
- 0.161
- 0.196
- 0.0
- 0.0
- 0.177
- 0.0
- 0.178
- 0.21
- 0.0
- 0.196
- 0.0
- 0.193
- 0.0
- 0.236
- 0.183
- 0.198
- 0.19
- 0.255
- 0.263
- 0.263
- 0.255
- 0.22
- 0.262
- 0.0
- 0.0
- 0.0
- 0.277
- 0.26
- 0.293
- 0.294
- 0.258
- 0.222
- 0.274
- 0.283
- 0.0
- 0.0
- 0.283
- 0.0
- 0.278
- 0.224
- 0.0
- 0.0
- 0.0
- 0.234
- 0.0
- 0.234
- 0.249
- 0.0
- 0.255
- 0.273
- 0.281
- 0.317
- 0.293
- 0.233
- 0.297
- 0.248
- 0.0
- 0.0
- 0.317
- 0.3
- 0.0
- 0.0
- 0.313
- 0.297
- 0.308
- 0.326
- 0.302
- 0.304
- 0.284
- 0.306
- 0.333
- 0.305
- 0.0
- 0.326
- 0.277
- 0.334
- 0.0
- 0.32
- 0.322
- 0.329
- 0.343
- 0.338
train_loss:
- 4.169
- 3.847
- 3.41
- 3.454
- 3.356
- 1.406
- 1.382
- 3.593
- 1.196
- 0.486
- 0.385
- 1.286
- 3.621
- 3.213
- 0.868
- 2.998
- 2.376
- 0.671
- 3.121
- 2.823
- 0.62
- 0.925
- 2.538
- 0.543
- 2.985
- 2.677
- 1.008
- 2.485
- 0.719
- 2.13
- 0.596
- 2.663
- 2.061
- 1.79
- 2.33
- 2.068
- 1.638
- 2.445
- 2.518
- 1.696
- 2.07
- 0.589
- 0.165
- 0.879
- 2.311
- 1.774
- 1.643
- 1.721
- 2.265
- 2.082
- 1.62
- 1.169
- 0.566
- 0.678
- 1.225
- 0.33
- 0.982
- 1.766
- 0.317
- 0.08
- 0.625
- 1.506
- 0.27
- 1.161
- 0.809
- 0.389
- 2.015
- 1.584
- 1.959
- 1.631
- 1.472
- 1.005
- 1.397
- 0.743
- 0.421
- 0.099
- 1.245
- 1.321
- 0.303
- 0.085
- 1.369
- 1.043
- 0.922
- 1.251
- 1.579
- 0.956
- 1.257
- 1.222
- 0.853
- 0.916
- 0.469
- 0.938
- 0.844
- 0.556
- 0.261
- 0.501
- 1.053
- 1.068
- 0.716
- 1.006
unequal: 0
verbose: 1
