avg_train_accuracy: 0.32
avg_train_loss: 0.008
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0436
- 0.086
- 0.1043
- 0.0256
- 0.1143
- 0.1194
- 0.1418
- 0.0292
- 0.1458
- 0.1608
- 0.1522
- 0.1562
- 0.1541
- 0.0275
- 0.1702
- 0.1861
- 0.1885
- 0.1845
- 0.1926
- 0.0309
- 0.0311
- 0.1939
- 0.2023
- 0.2029
- 0.0305
- 0.0293
- 0.0313
- 0.2024
- 0.0329
- 0.2055
- 0.2115
- 0.2176
- 0.0323
- 0.0322
- 0.0323
- 0.2223
- 0.0319
- 0.0332
- 0.0326
- 0.2148
- 0.2277
- 0.2273
- 0.2274
- 0.2269
- 0.2314
- 0.2276
- 0.0351
- 0.0329
- 0.0344
- 0.2401
- 0.0344
- 0.2504
- 0.247
- 0.2498
- 0.2482
- 0.2465
- 0.2523
- 0.035
- 0.2414
- 0.2476
- 0.2526
- 0.2536
- 0.2535
- 0.036
- 0.2442
- 0.2509
- 0.2555
- 0.2511
- 0.0394
- 0.0349
- 0.2571
- 0.04
- 0.2593
- 0.2631
- 0.2668
- 0.0425
- 0.2708
- 0.2629
- 0.2704
- 0.039
- 0.2679
- 0.2664
- 0.2689
- 0.2663
- 0.2761
- 0.28
- 0.268
- 0.2757
- 0.0432
- 0.2774
- 0.2655
- 0.0478
- 0.0423
- 0.2744
- 0.2798
- 0.2818
- 0.2737
- 0.2715
- 0.2679
- 0.2815
test_loss_list:
- 1.833925151824951
- 1.7894162845611572
- 1.7600485610961913
- 3.803783197402954
- 1.7324021935462952
- 1.732502064704895
- 1.713749327659607
- 3.707589101791382
- 1.7051018404960632
- 1.6856500864028932
- 1.6892792439460755
- 1.7056236791610717
- 1.7146030426025392
- 3.728878211975098
- 1.6721626734733581
- 1.6609114933013915
- 1.6797478938102721
- 1.6616651439666748
- 1.671902186870575
- 3.554436750411987
- 3.7848067760467528
- 1.6352737641334534
- 1.6262337040901185
- 1.6303572130203248
- 3.79880895614624
- 3.975250120162964
- 3.593168468475342
- 1.5432080268859862
- 3.386792688369751
- 1.5442211103439332
- 1.5660008382797241
- 1.5802291679382323
- 3.508497939109802
- 3.7663051891326904
- 3.414426565170288
- 1.5118335914611816
- 3.7024810791015623
- 3.7876720428466797
- 3.6163651895523072
- 1.4581332993507385
- 1.4650010013580321
- 1.4908303141593933
- 1.5013104557991028
- 1.5171968626976013
- 1.4935389852523804
- 1.5345450019836426
- 3.527173318862915
- 3.297752413749695
- 3.3810384607315065
- 1.404327425956726
- 3.3144424533843995
- 1.409984185695648
- 1.4220158815383912
- 1.4395913577079773
- 1.453076009750366
- 1.4786451578140258
- 1.4676821255683898
- 3.1927029418945314
- 1.4727735686302186
- 1.459744212627411
- 1.4671054244041444
- 1.4740990066528321
- 1.4968158411979675
- 3.439208507537842
- 1.468221824169159
- 1.47073668718338
- 1.4707854533195495
- 1.4902217173576355
- 3.295909757614136
- 3.2040197134017943
- 1.4192211318016053
- 3.166974787712097
- 1.422279269695282
- 1.4356413745880128
- 1.4369233345985413
- 3.1309500980377196
- 1.3868796372413634
- 1.4136490988731385
- 1.425096457004547
- 3.0581569147109984
- 1.3911242532730101
- 1.4044996476173401
- 1.4244801688194275
- 1.4482070517539978
- 1.4448129796981812
- 1.4454980611801147
- 1.4864901471138001
- 1.4828215956687927
- 3.2107526159286497
- 1.4177884221076966
- 1.4632631826400757
- 3.1700117588043213
- 3.350685567855835
- 1.419588794708252
- 1.4208627820014954
- 1.430961434841156
- 1.4537534070014955
- 1.4583147597312927
- 1.4913312411308288
- 1.472672894001007
train_accuracy:
- 0.064
- 0.083
- 0.102
- 0.0
- 0.099
- 0.124
- 0.124
- 0.0
- 0.139
- 0.155
- 0.158
- 0.158
- 0.156
- 0.0
- 0.168
- 0.19
- 0.196
- 0.185
- 0.179
- 0.0
- 0.0
- 0.171
- 0.218
- 0.209
- 0.0
- 0.0
- 0.0
- 0.241
- 0.0
- 0.21
- 0.21
- 0.236
- 0.0
- 0.0
- 0.0
- 0.264
- 0.0
- 0.0
- 0.0
- 0.268
- 0.238
- 0.259
- 0.213
- 0.227
- 0.24
- 0.226
- 0.0
- 0.0
- 0.0
- 0.259
- 0.0
- 0.262
- 0.264
- 0.256
- 0.273
- 0.271
- 0.315
- 0.0
- 0.287
- 0.257
- 0.281
- 0.317
- 0.226
- 0.0
- 0.239
- 0.306
- 0.276
- 0.229
- 0.0
- 0.0
- 0.335
- 0.0
- 0.295
- 0.296
- 0.305
- 0.0
- 0.278
- 0.303
- 0.323
- 0.0
- 0.272
- 0.313
- 0.308
- 0.305
- 0.307
- 0.305
- 0.31
- 0.324
- 0.0
- 0.332
- 0.297
- 0.0
- 0.0
- 0.269
- 0.328
- 0.326
- 0.333
- 0.356
- 0.346
- 0.32
train_loss:
- 4.285
- 3.801
- 3.575
- 1.298
- 3.688
- 3.231
- 2.922
- 0.986
- 2.874
- 2.941
- 3.038
- 2.541
- 2.212
- 0.918
- 3.134
- 2.403
- 1.96
- 2.82
- 2.456
- 0.765
- 0.332
- 2.896
- 2.224
- 2.393
- 1.14
- 0.432
- 0.843
- 2.451
- 0.464
- 2.11
- 1.487
- 1.845
- 0.703
- 0.294
- 0.695
- 2.789
- 1.184
- 0.406
- 0.764
- 2.368
- 2.362
- 1.722
- 2.186
- 1.662
- 2.138
- 1.486
- 0.789
- 0.757
- 0.765
- 2.086
- 0.515
- 2.216
- 1.497
- 1.755
- 1.588
- 1.249
- 1.821
- 0.469
- 1.525
- 1.505
- 1.076
- 1.258
- 1.187
- 0.636
- 1.083
- 1.073
- 1.542
- 0.886
- 0.491
- 0.659
- 1.109
- 0.351
- 1.854
- 1.506
- 1.048
- 0.622
- 1.409
- 1.34
- 1.338
- 0.413
- 1.035
- 1.04
- 0.828
- 0.749
- 1.09
- 1.207
- 0.769
- 0.554
- 0.488
- 0.957
- 0.478
- 0.328
- 0.098
- 0.987
- 0.951
- 0.582
- 0.558
- 0.941
- 0.56
- 0.817
unequal: 0
verbose: 1
