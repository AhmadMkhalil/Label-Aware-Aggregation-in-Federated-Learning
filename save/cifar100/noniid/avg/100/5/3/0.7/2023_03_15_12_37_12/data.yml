avg_train_accuracy: 0.373
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0328
- 0.0953
- 0.1179
- 0.1322
- 0.143
- 0.1536
- 0.16
- 0.1672
- 0.1723
- 0.1828
- 0.1864
- 0.1909
- 0.1941
- 0.1999
- 0.2045
- 0.2113
- 0.2175
- 0.2226
- 0.2231
- 0.2287
- 0.2319
- 0.2408
- 0.2422
- 0.2475
- 0.2444
- 0.2465
- 0.2496
- 0.2567
- 0.2554
- 0.2604
- 0.2535
- 0.2614
- 0.261
- 0.2641
- 0.2656
- 0.2708
- 0.2669
- 0.2678
- 0.2718
- 0.2738
- 0.2775
- 0.2751
- 0.2748
- 0.2786
- 0.283
- 0.2844
- 0.2805
- 0.2757
- 0.2833
- 0.2831
- 0.2856
- 0.2827
- 0.2858
- 0.2894
- 0.2844
- 0.2913
- 0.2875
- 0.2865
- 0.2937
- 0.2915
- 0.294
- 0.2943
- 0.2941
- 0.3001
- 0.2953
- 0.2966
- 0.2962
- 0.2941
- 0.3014
- 0.3042
- 0.3005
- 0.3073
- 0.2999
- 0.3047
- 0.3075
- 0.3035
- 0.3047
- 0.3063
- 0.3096
- 0.3055
- 0.3054
- 0.3118
- 0.3113
- 0.3089
- 0.3058
- 0.306
- 0.3077
- 0.3087
- 0.3089
- 0.3105
- 0.3163
- 0.3132
- 0.3115
- 0.3127
- 0.3139
- 0.3095
- 0.3089
- 0.31
- 0.31
- 0.3168
test_loss_list:
- 1.8162086343765258
- 1.6941430282592773
- 1.6370112895965576
- 1.5993345522880553
- 1.5588477659225464
- 1.538506863117218
- 1.5193367028236389
- 1.526650266647339
- 1.4771016311645508
- 1.4875468468666078
- 1.4607065057754516
- 1.472305097579956
- 1.4220120978355408
- 1.4040490651130677
- 1.4057951402664184
- 1.4031483054161071
- 1.3910246777534485
- 1.403940200805664
- 1.3613142848014832
- 1.3854554724693298
- 1.3630106401443483
- 1.33207989692688
- 1.3390552663803101
- 1.3196608066558837
- 1.3462009644508361
- 1.3604553246498108
- 1.3125820207595824
- 1.2962003779411315
- 1.2921813416481018
- 1.2995731043815613
- 1.3271248126029969
- 1.3320262837409973
- 1.3324672818183898
- 1.2825246477127075
- 1.27248389005661
- 1.2626387786865234
- 1.3291165447235107
- 1.2941151428222657
- 1.2853037405014038
- 1.2899128913879394
- 1.2576180744171142
- 1.2641050791740418
- 1.2636834263801575
- 1.248345079421997
- 1.2411836552619935
- 1.2377763390541077
- 1.2506794261932372
- 1.2851734399795531
- 1.2650026273727417
- 1.2552864241600037
- 1.2364083766937255
- 1.2702096247673034
- 1.2590437698364259
- 1.2602081775665284
- 1.2830722332000732
- 1.2687724232673645
- 1.2871689319610595
- 1.2616069197654725
- 1.2543184781074523
- 1.24251060962677
- 1.2450270676612853
- 1.2421926617622376
- 1.238989408016205
- 1.218849959373474
- 1.2559334015846253
- 1.2418133950233459
- 1.2351609992980956
- 1.2587300777435302
- 1.2200965976715088
- 1.2127609086036681
- 1.2260647559165954
- 1.211511435508728
- 1.2290382671356201
- 1.2185861372947693
- 1.2145529317855834
- 1.2252365684509277
- 1.2272378540039062
- 1.2144124794006348
- 1.2115264177322387
- 1.223179578781128
- 1.2342872071266173
- 1.2125592589378358
- 1.2104172062873841
- 1.2245757961273194
- 1.2560813879966737
- 1.2412041020393372
- 1.2179764604568482
- 1.2494119691848755
- 1.260936598777771
- 1.2151576709747314
- 1.2113767814636232
- 1.2249965620040895
- 1.234011137485504
- 1.2391633248329164
- 1.2394847059249878
- 1.2639187574386597
- 1.2340589308738708
- 1.2303772568702698
- 1.2310733461380006
- 1.2124734330177307
train_accuracy:
- 0.045
- 0.115
- 0.146
- 0.154
- 0.177
- 0.175
- 0.0
- 0.177
- 0.21
- 0.208
- 0.0
- 0.224
- 0.214
- 0.0
- 0.246
- 0.25
- 0.252
- 0.25
- 0.0
- 0.276
- 0.244
- 0.271
- 0.0
- 0.0
- 0.287
- 0.303
- 0.274
- 0.307
- 0.295
- 0.295
- 0.0
- 0.262
- 0.289
- 0.0
- 0.292
- 0.0
- 0.299
- 0.338
- 0.29
- 0.0
- 0.314
- 0.33
- 0.0
- 0.32
- 0.279
- 0.292
- 0.294
- 0.334
- 0.317
- 0.316
- 0.0
- 0.324
- 0.324
- 0.306
- 0.0
- 0.0
- 0.358
- 0.328
- 0.346
- 0.347
- 0.336
- 0.341
- 0.345
- 0.325
- 0.321
- 0.332
- 0.342
- 0.0
- 0.0
- 0.339
- 0.346
- 0.0
- 0.341
- 0.338
- 0.34
- 0.343
- 0.0
- 0.0
- 0.0
- 0.291
- 0.344
- 0.0
- 0.0
- 0.0
- 0.304
- 0.327
- 0.0
- 0.378
- 0.297
- 0.0
- 0.357
- 0.35
- 0.0
- 0.377
- 0.344
- 0.0
- 0.391
- 0.346
- 0.393
- 0.373
train_loss:
- 3.329
- 2.988
- 2.875
- 2.678
- 2.266
- 2.51
- 2.389
- 2.647
- 2.026
- 2.57
- 2.168
- 2.402
- 1.822
- 1.743
- 1.982
- 1.924
- 1.854
- 2.117
- 1.562
- 2.011
- 1.777
- 1.452
- 1.623
- 1.404
- 1.813
- 1.737
- 1.333
- 1.277
- 1.236
- 1.44
- 1.575
- 1.58
- 1.509
- 1.16
- 1.101
- 1.081
- 1.563
- 1.17
- 1.149
- 1.134
- 0.995
- 1.119
- 1.096
- 0.914
- 0.903
- 0.879
- 1.002
- 1.119
- 0.981
- 0.911
- 0.789
- 1.02
- 0.871
- 0.884
- 0.966
- 0.818
- 0.906
- 0.802
- 0.797
- 0.765
- 0.748
- 0.75
- 0.694
- 0.637
- 0.778
- 0.684
- 0.667
- 0.716
- 0.552
- 0.553
- 0.607
- 0.516
- 0.585
- 0.497
- 0.515
- 0.57
- 0.553
- 0.47
- 0.46
- 0.512
- 0.501
- 0.462
- 0.419
- 0.485
- 0.539
- 0.447
- 0.414
- 0.504
- 0.476
- 0.382
- 0.383
- 0.413
- 0.399
- 0.41
- 0.397
- 0.416
- 0.395
- 0.384
- 0.363
- 0.323
unequal: 0
verbose: 1
