avg_train_accuracy: 0.334
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0313
- 0.0871
- 0.112
- 0.1293
- 0.1414
- 0.1596
- 0.1676
- 0.176
- 0.1798
- 0.1846
- 0.1936
- 0.2011
- 0.2097
- 0.2126
- 0.2173
- 0.2184
- 0.2267
- 0.2298
- 0.2367
- 0.2411
- 0.243
- 0.2438
- 0.2447
- 0.2497
- 0.2559
- 0.2586
- 0.2589
- 0.2576
- 0.2614
- 0.2658
- 0.2647
- 0.2696
- 0.2678
- 0.2714
- 0.2746
- 0.274
- 0.2815
- 0.2798
- 0.2814
- 0.2828
- 0.2842
- 0.2844
- 0.2862
- 0.2882
- 0.2931
- 0.2915
- 0.2903
- 0.2927
- 0.291
- 0.2877
- 0.295
- 0.2958
- 0.2916
- 0.2987
- 0.2981
- 0.2997
- 0.2987
- 0.3009
- 0.3068
- 0.3055
- 0.3029
- 0.3017
- 0.3015
- 0.3029
- 0.3065
- 0.3029
- 0.3037
- 0.3043
- 0.3041
- 0.3032
- 0.3061
- 0.3102
- 0.3055
- 0.3117
- 0.3148
- 0.3147
- 0.3142
- 0.3141
- 0.312
- 0.3115
- 0.3126
- 0.315
- 0.312
- 0.315
- 0.3168
- 0.3168
- 0.3188
- 0.3192
- 0.32
- 0.3211
- 0.3232
- 0.3231
- 0.3134
- 0.3158
- 0.3187
- 0.3171
- 0.3176
- 0.3182
- 0.3182
- 0.3192
test_loss_list:
- 1.8191909790039062
- 1.6962667655944825
- 1.6393237018585205
- 1.5961232161521912
- 1.5839498662948608
- 1.5920670700073243
- 1.5359556078910828
- 1.5323024582862854
- 1.4968855857849122
- 1.4490405797958374
- 1.4595040893554687
- 1.4371102023124696
- 1.4468912124633788
- 1.4190675735473632
- 1.4266167020797729
- 1.4054863500595092
- 1.3821612310409546
- 1.3737999510765075
- 1.3432849407196046
- 1.3468457293510436
- 1.3288328385353088
- 1.3341235327720642
- 1.3318837213516235
- 1.3094794631004334
- 1.3137652111053466
- 1.3121036028861999
- 1.308394591808319
- 1.3029675841331483
- 1.324352147579193
- 1.3030518651008607
- 1.3249639558792115
- 1.3311449813842773
- 1.33983455657959
- 1.3432349395751952
- 1.2810189270973205
- 1.2572672414779662
- 1.2453237628936769
- 1.2572129130363465
- 1.2593261623382568
- 1.2408237910270692
- 1.2484782099723817
- 1.253409321308136
- 1.2340322852134704
- 1.2411664390563966
- 1.226501338481903
- 1.23507483959198
- 1.223538897037506
- 1.23177636384964
- 1.2587953305244446
- 1.238964216709137
- 1.237042417526245
- 1.2399834203720093
- 1.252425389289856
- 1.214139642715454
- 1.2235620880126954
- 1.220565378665924
- 1.247429859638214
- 1.2105114912986756
- 1.2010458016395569
- 1.202681827545166
- 1.2140180563926697
- 1.2424230933189393
- 1.2497051858901977
- 1.229265947341919
- 1.2205457711219787
- 1.2447425985336305
- 1.2550686192512512
- 1.2234361147880555
- 1.2205586957931518
- 1.2463168907165527
- 1.2446904349327088
- 1.2043640232086181
- 1.2120544862747193
- 1.1971823716163634
- 1.2050395822525024
- 1.2043337297439576
- 1.21177969455719
- 1.2108124947547914
- 1.2348544573783875
- 1.2391835451126099
- 1.2173650789260864
- 1.2144755172729491
- 1.2367053055763244
- 1.2170912051200866
- 1.1999631524085999
- 1.2059311985969543
- 1.1975445294380187
- 1.1999349761009217
- 1.1918016290664672
- 1.2020317101478577
- 1.1904679703712464
- 1.1946243286132812
- 1.2234631299972534
- 1.2046473050117492
- 1.2069563889503478
- 1.21427925825119
- 1.2048605632781983
- 1.2098139023780823
- 1.2162114119529723
- 1.1979806399345398
train_accuracy:
- 0.048
- 0.0
- 0.0
- 0.15
- 0.197
- 0.147
- 0.209
- 0.205
- 0.222
- 0.0
- 0.225
- 0.222
- 0.0
- 0.0
- 0.278
- 0.265
- 0.272
- 0.281
- 0.257
- 0.297
- 0.284
- 0.0
- 0.291
- 0.293
- 0.0
- 0.0
- 0.242
- 0.318
- 0.319
- 0.242
- 0.283
- 0.332
- 0.341
- 0.293
- 0.0
- 0.321
- 0.288
- 0.0
- 0.332
- 0.0
- 0.273
- 0.268
- 0.322
- 0.338
- 0.275
- 0.277
- 0.0
- 0.0
- 0.37
- 0.278
- 0.344
- 0.0
- 0.327
- 0.341
- 0.0
- 0.33
- 0.329
- 0.34
- 0.0
- 0.375
- 0.0
- 0.328
- 0.319
- 0.363
- 0.354
- 0.359
- 0.324
- 0.317
- 0.322
- 0.342
- 0.324
- 0.356
- 0.0
- 0.0
- 0.0
- 0.338
- 0.365
- 0.0
- 0.385
- 0.336
- 0.0
- 0.325
- 0.337
- 0.329
- 0.0
- 0.351
- 0.0
- 0.359
- 0.344
- 0.397
- 0.0
- 0.323
- 0.0
- 0.3
- 0.334
- 0.363
- 0.332
- 0.301
- 0.299
- 0.334
train_loss:
- 3.313
- 3.031
- 2.828
- 2.682
- 2.933
- 3.106
- 2.419
- 2.618
- 2.246
- 1.944
- 2.443
- 2.074
- 2.257
- 1.973
- 2.189
- 1.857
- 1.88
- 1.776
- 1.54
- 1.703
- 1.458
- 1.646
- 1.597
- 1.374
- 1.557
- 1.537
- 1.503
- 1.43
- 1.637
- 1.377
- 1.497
- 1.488
- 1.414
- 1.41
- 1.121
- 1.079
- 1.071
- 1.166
- 1.119
- 0.961
- 1.11
- 1.092
- 0.934
- 1.086
- 0.881
- 1.003
- 0.833
- 0.952
- 1.057
- 0.908
- 0.88
- 0.874
- 1.005
- 0.715
- 0.857
- 0.814
- 0.911
- 0.7
- 0.679
- 0.654
- 0.758
- 0.815
- 0.779
- 0.687
- 0.671
- 0.735
- 0.721
- 0.645
- 0.616
- 0.672
- 0.671
- 0.517
- 0.55
- 0.495
- 0.559
- 0.56
- 0.53
- 0.521
- 0.552
- 0.546
- 0.492
- 0.46
- 0.494
- 0.473
- 0.397
- 0.429
- 0.363
- 0.441
- 0.371
- 0.399
- 0.359
- 0.334
- 0.44
- 0.377
- 0.371
- 0.349
- 0.362
- 0.361
- 0.326
- 0.309
unequal: 0
verbose: 1
