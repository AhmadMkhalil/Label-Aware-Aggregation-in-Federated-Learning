avg_train_accuracy: 0.31
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0303
- 0.0914
- 0.1126
- 0.1308
- 0.1414
- 0.1497
- 0.1607
- 0.1685
- 0.1748
- 0.1836
- 0.1899
- 0.1934
- 0.2034
- 0.2053
- 0.2095
- 0.2133
- 0.2159
- 0.2248
- 0.2253
- 0.2287
- 0.2323
- 0.2396
- 0.2412
- 0.2438
- 0.2479
- 0.2549
- 0.2544
- 0.257
- 0.2563
- 0.2577
- 0.2582
- 0.2615
- 0.2665
- 0.2646
- 0.2653
- 0.2674
- 0.2703
- 0.2705
- 0.2757
- 0.2777
- 0.2762
- 0.277
- 0.2809
- 0.2833
- 0.2847
- 0.288
- 0.2917
- 0.2875
- 0.2864
- 0.2898
- 0.2889
- 0.289
- 0.2961
- 0.2938
- 0.2925
- 0.2939
- 0.2932
- 0.299
- 0.2954
- 0.3002
- 0.2938
- 0.3045
- 0.3024
- 0.3011
- 0.2968
- 0.3063
- 0.3025
- 0.305
- 0.295
- 0.3032
- 0.3055
- 0.3023
- 0.3048
- 0.3049
- 0.3094
- 0.3057
- 0.3053
- 0.307
- 0.3092
- 0.3033
- 0.3032
- 0.3086
- 0.3031
- 0.3106
- 0.3103
- 0.3141
- 0.3188
- 0.3155
- 0.3117
- 0.313
- 0.3142
- 0.3151
- 0.3104
- 0.3155
- 0.3156
- 0.3183
- 0.3158
- 0.3259
- 0.3154
- 0.3193
test_loss_list:
- 1.816589822769165
- 1.6774290323257446
- 1.6214037132263184
- 1.5976617813110352
- 1.563236618041992
- 1.515717828273773
- 1.50084370136261
- 1.4717332172393798
- 1.465689675807953
- 1.454305238723755
- 1.4258347749710083
- 1.4233778095245362
- 1.418218297958374
- 1.4326239013671875
- 1.4152816367149352
- 1.406375777721405
- 1.3858402132987977
- 1.3695099210739137
- 1.3614270997047424
- 1.3822108626365661
- 1.3373895192146301
- 1.3379655241966248
- 1.3376868534088135
- 1.328573613166809
- 1.3053867626190185
- 1.2943362498283386
- 1.290349555015564
- 1.2844927883148194
- 1.296564245223999
- 1.2944010591506958
- 1.3211157965660094
- 1.302225830554962
- 1.2903925681114197
- 1.2894404768943786
- 1.3131479930877685
- 1.2872197389602662
- 1.300386996269226
- 1.3034134745597838
- 1.2530064964294434
- 1.2613957405090332
- 1.2902858138084412
- 1.268578999042511
- 1.2641006135940551
- 1.2372302031517028
- 1.2423413610458374
- 1.2429245519638061
- 1.247391595840454
- 1.2404275727272034
- 1.2463999843597413
- 1.2441780161857605
- 1.239211449623108
- 1.2333781504631043
- 1.2127850508689881
- 1.2276626777648927
- 1.2294216895103454
- 1.2529283952713013
- 1.2335461258888245
- 1.227141137123108
- 1.254395875930786
- 1.2120895290374756
- 1.2482809948921203
- 1.2074269914627076
- 1.2166878938674928
- 1.2241340732574464
- 1.2209827208518982
- 1.1981956624984742
- 1.2349767637252809
- 1.2235187578201294
- 1.2431618189811706
- 1.2203926873207092
- 1.2220587825775147
- 1.2245484280586243
- 1.2291943836212158
- 1.2308885502815246
- 1.2307866740226745
- 1.2554079103469848
- 1.229619743824005
- 1.2124674677848817
- 1.21441321849823
- 1.2723184633255005
- 1.2277840733528138
- 1.2228617024421693
- 1.277323739528656
- 1.2081339645385742
- 1.214439833164215
- 1.1984835577011108
- 1.1921745538711548
- 1.2083345651626587
- 1.209651439189911
- 1.2167490816116333
- 1.1993939995765686
- 1.210035696029663
- 1.2391221523284912
- 1.2198317694664
- 1.2086586189270019
- 1.1957019829750062
- 1.2294027280807496
- 1.1966340970993041
- 1.2324323987960815
- 1.2208376622200012
train_accuracy:
- 0.041
- 0.081
- 0.153
- 0.169
- 0.0
- 0.0
- 0.197
- 0.176
- 0.0
- 0.212
- 0.208
- 0.204
- 0.0
- 0.27
- 0.0
- 0.221
- 0.229
- 0.0
- 0.225
- 0.246
- 0.217
- 0.281
- 0.0
- 0.0
- 0.0
- 0.0
- 0.237
- 0.268
- 0.238
- 0.265
- 0.249
- 0.261
- 0.0
- 0.31
- 0.255
- 0.279
- 0.232
- 0.267
- 0.225
- 0.0
- 0.321
- 0.298
- 0.0
- 0.251
- 0.28
- 0.296
- 0.263
- 0.307
- 0.308
- 0.0
- 0.277
- 0.267
- 0.303
- 0.0
- 0.283
- 0.326
- 0.281
- 0.0
- 0.317
- 0.314
- 0.321
- 0.0
- 0.279
- 0.0
- 0.263
- 0.0
- 0.297
- 0.32
- 0.0
- 0.295
- 0.0
- 0.34
- 0.286
- 0.0
- 0.322
- 0.3
- 0.327
- 0.0
- 0.267
- 0.282
- 0.0
- 0.265
- 0.343
- 0.297
- 0.3
- 0.308
- 0.0
- 0.319
- 0.31
- 0.295
- 0.296
- 0.33
- 0.302
- 0.0
- 0.287
- 0.0
- 0.333
- 0.329
- 0.283
- 0.31
train_loss:
- 2.862
- 2.981
- 2.784
- 3.004
- 2.497
- 2.141
- 2.396
- 1.981
- 2.219
- 2.211
- 1.838
- 2.045
- 2.03
- 2.254
- 1.91
- 1.867
- 1.815
- 1.764
- 1.746
- 1.924
- 1.463
- 1.589
- 1.583
- 1.553
- 1.351
- 1.298
- 1.24
- 1.239
- 1.391
- 1.395
- 1.554
- 1.333
- 1.309
- 1.294
- 1.397
- 1.216
- 1.328
- 1.316
- 0.995
- 1.124
- 1.23
- 1.058
- 1.003
- 0.891
- 0.99
- 0.983
- 0.926
- 0.941
- 0.908
- 0.885
- 0.88
- 0.861
- 0.738
- 0.831
- 0.813
- 0.873
- 0.81
- 0.741
- 0.828
- 0.653
- 0.799
- 0.627
- 0.695
- 0.663
- 0.688
- 0.576
- 0.714
- 0.622
- 0.693
- 0.59
- 0.583
- 0.563
- 0.536
- 0.547
- 0.527
- 0.59
- 0.522
- 0.506
- 0.482
- 0.587
- 0.482
- 0.445
- 0.542
- 0.411
- 0.458
- 0.385
- 0.367
- 0.415
- 0.42
- 0.396
- 0.356
- 0.381
- 0.411
- 0.389
- 0.368
- 0.334
- 0.388
- 0.319
- 0.367
- 0.332
unequal: 0
verbose: 1
