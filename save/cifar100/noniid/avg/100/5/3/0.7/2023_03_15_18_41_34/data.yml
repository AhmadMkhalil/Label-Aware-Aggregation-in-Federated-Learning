avg_train_accuracy: 0.37
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0342
- 0.092
- 0.1133
- 0.1223
- 0.1329
- 0.1458
- 0.1535
- 0.1636
- 0.1712
- 0.1762
- 0.1852
- 0.1904
- 0.1956
- 0.1991
- 0.2046
- 0.2087
- 0.2101
- 0.2119
- 0.216
- 0.2279
- 0.2285
- 0.2323
- 0.2375
- 0.2454
- 0.247
- 0.2427
- 0.2459
- 0.2505
- 0.2534
- 0.2507
- 0.2606
- 0.2602
- 0.2575
- 0.2652
- 0.2638
- 0.2698
- 0.2679
- 0.2676
- 0.2705
- 0.2708
- 0.2749
- 0.2723
- 0.2787
- 0.2851
- 0.2824
- 0.279
- 0.2863
- 0.29
- 0.2897
- 0.2868
- 0.2914
- 0.2897
- 0.2957
- 0.2976
- 0.2921
- 0.2939
- 0.2972
- 0.2973
- 0.2933
- 0.2921
- 0.3009
- 0.2945
- 0.3009
- 0.296
- 0.3029
- 0.2977
- 0.3011
- 0.3047
- 0.3042
- 0.3031
- 0.3005
- 0.2991
- 0.3031
- 0.3022
- 0.3038
- 0.3053
- 0.3076
- 0.3078
- 0.3064
- 0.3068
- 0.3079
- 0.3109
- 0.3067
- 0.3088
- 0.3076
- 0.3125
- 0.3125
- 0.3114
- 0.3105
- 0.3098
- 0.3145
- 0.312
- 0.3091
- 0.3121
- 0.318
- 0.3206
- 0.3207
- 0.32
- 0.3206
- 0.3157
test_loss_list:
- 1.8168404388427735
- 1.689722890853882
- 1.6269194531440734
- 1.5882426238059997
- 1.5669326996803283
- 1.5435283255577088
- 1.530354413986206
- 1.5147804188728333
- 1.477624695301056
- 1.4688444590568543
- 1.442554109096527
- 1.4388440990447997
- 1.4333239889144898
- 1.427325837612152
- 1.399046859741211
- 1.4035817623138427
- 1.393842842578888
- 1.4200075840950013
- 1.4209966444969178
- 1.3824719429016112
- 1.3711839318275452
- 1.3606209468841552
- 1.3454363465309143
- 1.3233161854743958
- 1.31204735994339
- 1.348924617767334
- 1.3566890025138856
- 1.3077240705490112
- 1.2961369395256042
- 1.3057549500465393
- 1.282476577758789
- 1.2785704040527344
- 1.3153377389907837
- 1.297889873981476
- 1.3219456553459168
- 1.2726960325241088
- 1.306023783683777
- 1.3117865991592408
- 1.321238887310028
- 1.327346432209015
- 1.2663437986373902
- 1.2976258993148804
- 1.2466035199165344
- 1.2366662645339965
- 1.2774109244346619
- 1.2942527198791505
- 1.241421194076538
- 1.2293593955039979
- 1.2429099655151368
- 1.2487287831306457
- 1.228913631439209
- 1.2357694864273072
- 1.2194402885437012
- 1.2148385548591614
- 1.2327918815612793
- 1.258455891609192
- 1.217963583469391
- 1.2321132588386536
- 1.234926462173462
- 1.2341872024536134
- 1.231543493270874
- 1.2392506194114685
- 1.2096911144256592
- 1.250064594745636
- 1.211145761013031
- 1.2516740536689759
- 1.2379698061943054
- 1.2086630439758301
- 1.224523892402649
- 1.2328889393806457
- 1.2589802527427674
- 1.2702610993385315
- 1.2435255336761475
- 1.2605586123466492
- 1.2326106238365173
- 1.229692349433899
- 1.2204141211509705
- 1.2227878642082215
- 1.2523690533638
- 1.26132639169693
- 1.2379895901679994
- 1.2350645351409912
- 1.2622882413864136
- 1.233059551715851
- 1.2330025005340577
- 1.2028484201431275
- 1.2199761843681336
- 1.2450190496444702
- 1.2341296577453613
- 1.2472433829307557
- 1.2287313914299012
- 1.2224360823631286
- 1.2812135076522828
- 1.236392924785614
- 1.2067779946327208
- 1.2194551491737367
- 1.2027322816848756
- 1.2018766140937804
- 1.2151103448867797
- 1.2428803420066834
train_accuracy:
- 0.04
- 0.119
- 0.0
- 0.132
- 0.167
- 0.2
- 0.185
- 0.0
- 0.182
- 0.189
- 0.187
- 0.241
- 0.226
- 0.218
- 0.214
- 0.0
- 0.0
- 0.222
- 0.25
- 0.282
- 0.0
- 0.256
- 0.266
- 0.302
- 0.264
- 0.268
- 0.284
- 0.0
- 0.28
- 0.261
- 0.28
- 0.0
- 0.332
- 0.262
- 0.316
- 0.0
- 0.338
- 0.32
- 0.345
- 0.285
- 0.0
- 0.316
- 0.0
- 0.0
- 0.298
- 0.316
- 0.328
- 0.285
- 0.321
- 0.323
- 0.328
- 0.331
- 0.332
- 0.0
- 0.366
- 0.37
- 0.0
- 0.0
- 0.377
- 0.37
- 0.0
- 0.364
- 0.33
- 0.346
- 0.0
- 0.31
- 0.0
- 0.304
- 0.307
- 0.375
- 0.342
- 0.381
- 0.371
- 0.352
- 0.346
- 0.379
- 0.351
- 0.0
- 0.35
- 0.35
- 0.0
- 0.309
- 0.0
- 0.348
- 0.345
- 0.0
- 0.346
- 0.383
- 0.336
- 0.365
- 0.0
- 0.356
- 0.321
- 0.353
- 0.367
- 0.354
- 0.0
- 0.0
- 0.343
- 0.37
train_loss:
- 3.299
- 3.001
- 2.437
- 2.33
- 2.582
- 2.519
- 2.429
- 2.334
- 1.988
- 2.239
- 1.867
- 2.091
- 2.107
- 2.025
- 1.683
- 1.939
- 1.875
- 2.09
- 2.06
- 1.748
- 1.734
- 1.676
- 1.664
- 1.359
- 1.349
- 1.774
- 1.717
- 1.264
- 1.245
- 1.45
- 1.177
- 1.127
- 1.536
- 1.309
- 1.475
- 1.104
- 1.384
- 1.402
- 1.34
- 1.291
- 0.998
- 1.234
- 0.927
- 0.919
- 1.157
- 1.116
- 0.886
- 0.829
- 0.952
- 0.922
- 0.776
- 0.903
- 0.742
- 0.735
- 0.874
- 0.946
- 0.693
- 0.815
- 0.785
- 0.76
- 0.758
- 0.717
- 0.627
- 0.811
- 0.618
- 0.774
- 0.662
- 0.565
- 0.645
- 0.611
- 0.678
- 0.661
- 0.598
- 0.635
- 0.559
- 0.544
- 0.519
- 0.526
- 0.574
- 0.545
- 0.501
- 0.488
- 0.54
- 0.484
- 0.452
- 0.389
- 0.437
- 0.47
- 0.429
- 0.464
- 0.418
- 0.39
- 0.48
- 0.384
- 0.334
- 0.368
- 0.323
- 0.305
- 0.36
- 0.376
unequal: 0
verbose: 1
