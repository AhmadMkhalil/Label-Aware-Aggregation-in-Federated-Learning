avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0272
- 0.0968
- 0.1125
- 0.132
- 0.1437
- 0.1569
- 0.1668
- 0.1767
- 0.183
- 0.1898
- 0.1976
- 0.2031
- 0.2085
- 0.2097
- 0.2119
- 0.2191
- 0.2209
- 0.2262
- 0.2334
- 0.2356
- 0.236
- 0.2433
- 0.2381
- 0.2444
- 0.2474
- 0.2563
- 0.2528
- 0.2555
- 0.2528
- 0.2541
- 0.2589
- 0.2603
- 0.263
- 0.263
- 0.267
- 0.2695
- 0.2696
- 0.2752
- 0.27
- 0.2758
- 0.2813
- 0.2743
- 0.2789
- 0.2789
- 0.2789
- 0.2817
- 0.2818
- 0.2826
- 0.2848
- 0.2893
- 0.2915
- 0.2884
- 0.2911
- 0.2902
- 0.2913
- 0.2915
- 0.2949
- 0.2929
- 0.2934
- 0.2952
- 0.2951
- 0.2926
- 0.297
- 0.2976
- 0.3029
- 0.2977
- 0.2995
- 0.2989
- 0.3046
- 0.3035
- 0.3012
- 0.3067
- 0.3054
- 0.3041
- 0.3095
- 0.3071
- 0.3104
- 0.3125
- 0.3084
- 0.3113
- 0.3107
- 0.3111
- 0.3145
- 0.3059
- 0.3115
- 0.3112
- 0.3089
- 0.3127
- 0.3174
- 0.317
- 0.3181
- 0.3139
- 0.3166
- 0.3168
- 0.3125
- 0.3087
- 0.3116
- 0.3131
- 0.3182
- 0.3136
test_loss_list:
- 1.816049189567566
- 1.701327419281006
- 1.631488826274872
- 1.6084241414070128
- 1.5738603591918945
- 1.5404567098617554
- 1.5155109834671021
- 1.5147859621047974
- 1.4864489817619324
- 1.4913380861282348
- 1.4636492586135865
- 1.4249470520019532
- 1.4024151539802552
- 1.3910985708236694
- 1.4193394804000854
- 1.427922170162201
- 1.4231871247291565
- 1.3686122179031373
- 1.3654932260513306
- 1.3609711909294129
- 1.335356433391571
- 1.3251048231124878
- 1.3339820075035096
- 1.356047854423523
- 1.317231569290161
- 1.307259566783905
- 1.3035288858413696
- 1.335346624851227
- 1.3151161026954652
- 1.3135315823554992
- 1.333864507675171
- 1.3119916486740113
- 1.3571550631523133
- 1.2886964082717896
- 1.3145063066482543
- 1.2986534976959228
- 1.3189936685562134
- 1.2976848602294921
- 1.2803313875198363
- 1.2778059887886046
- 1.2814325714111328
- 1.3097678923606872
- 1.2595546627044678
- 1.2849519300460814
- 1.2701644015312195
- 1.2921727871894837
- 1.2981991744041443
- 1.2720325374603272
- 1.2591539525985718
- 1.234194495677948
- 1.2329363703727723
- 1.2391189670562743
- 1.2438482999801637
- 1.2441718888282776
- 1.242189257144928
- 1.2721780300140382
- 1.279071340560913
- 1.2797597670555114
- 1.2322096610069275
- 1.238028905391693
- 1.2345577192306518
- 1.2611648631095886
- 1.2688473057746887
- 1.2415828895568848
- 1.2171863675117494
- 1.2529269742965699
- 1.2361376833915712
- 1.2338858079910278
- 1.2171302795410157
- 1.2098838686943054
- 1.2481983065605164
- 1.2153046417236328
- 1.2230075812339782
- 1.2260136437416076
- 1.213501296043396
- 1.2252090358734131
- 1.2148454427719115
- 1.209351155757904
- 1.2194451761245728
- 1.209255394935608
- 1.2202276921272277
- 1.2200017476081848
- 1.2096959304809571
- 1.2440713381767272
- 1.210992832183838
- 1.2238567113876342
- 1.232297546863556
- 1.2244406628608704
- 1.209546649456024
- 1.2091894674301147
- 1.2062287902832032
- 1.216360011100769
- 1.20962251663208
- 1.2214088344573975
- 1.2229747867584229
- 1.2502454543113708
- 1.2255074310302734
- 1.2252776002883912
- 1.2090872955322265
- 1.2278770208358765
train_accuracy:
- 0.0
- 0.0
- 0.14
- 0.124
- 0.18
- 0.201
- 0.177
- 0.0
- 0.213
- 0.22
- 0.206
- 0.237
- 0.0
- 0.24
- 0.255
- 0.227
- 0.26
- 0.24
- 0.0
- 0.275
- 0.0
- 0.26
- 0.212
- 0.3
- 0.301
- 0.0
- 0.299
- 0.0
- 0.317
- 0.325
- 0.27
- 0.284
- 0.282
- 0.0
- 0.27
- 0.309
- 0.0
- 0.333
- 0.289
- 0.257
- 0.0
- 0.307
- 0.351
- 0.354
- 0.332
- 0.273
- 0.341
- 0.318
- 0.0
- 0.292
- 0.299
- 0.346
- 0.0
- 0.289
- 0.299
- 0.351
- 0.265
- 0.0
- 0.299
- 0.363
- 0.0
- 0.359
- 0.35
- 0.296
- 0.356
- 0.361
- 0.338
- 0.346
- 0.345
- 0.33
- 0.0
- 0.299
- 0.348
- 0.277
- 0.314
- 0.344
- 0.355
- 0.0
- 0.351
- 0.344
- 0.359
- 0.348
- 0.0
- 0.0
- 0.0
- 0.359
- 0.0
- 0.371
- 0.359
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.362
- 0.0
- 0.37
- 0.348
- 0.0
- 0.0
train_loss:
- 3.373
- 3.416
- 2.484
- 3.083
- 2.597
- 2.522
- 2.424
- 2.672
- 2.264
- 2.511
- 2.191
- 1.827
- 1.774
- 1.717
- 2.235
- 2.154
- 2.124
- 1.606
- 1.799
- 1.766
- 1.464
- 1.442
- 1.629
- 1.817
- 1.398
- 1.335
- 1.318
- 1.673
- 1.494
- 1.408
- 1.608
- 1.355
- 1.692
- 1.181
- 1.443
- 1.236
- 1.364
- 1.186
- 1.197
- 1.153
- 1.095
- 1.248
- 0.942
- 1.193
- 1.036
- 1.135
- 1.101
- 0.98
- 0.926
- 0.816
- 0.774
- 0.9
- 0.874
- 0.863
- 0.83
- 0.912
- 0.883
- 0.886
- 0.671
- 0.737
- 0.718
- 0.795
- 0.775
- 0.696
- 0.59
- 0.726
- 0.657
- 0.629
- 0.539
- 0.543
- 0.668
- 0.532
- 0.576
- 0.557
- 0.486
- 0.527
- 0.462
- 0.461
- 0.516
- 0.451
- 0.486
- 0.478
- 0.41
- 0.524
- 0.397
- 0.462
- 0.418
- 0.446
- 0.387
- 0.372
- 0.354
- 0.416
- 0.348
- 0.387
- 0.379
- 0.408
- 0.367
- 0.363
- 0.32
- 0.348
unequal: 0
verbose: 1
