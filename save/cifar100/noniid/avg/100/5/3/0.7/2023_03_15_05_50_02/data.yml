avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0352
- 0.095
- 0.1177
- 0.1374
- 0.1489
- 0.1562
- 0.1668
- 0.1751
- 0.1836
- 0.1919
- 0.1939
- 0.1994
- 0.2024
- 0.2049
- 0.2141
- 0.2177
- 0.2217
- 0.2218
- 0.2251
- 0.2292
- 0.2366
- 0.2378
- 0.2385
- 0.2421
- 0.2447
- 0.2513
- 0.2518
- 0.2538
- 0.2549
- 0.2608
- 0.2598
- 0.2639
- 0.2637
- 0.2666
- 0.2714
- 0.2663
- 0.2686
- 0.2707
- 0.2689
- 0.2722
- 0.2787
- 0.2839
- 0.2782
- 0.2788
- 0.2762
- 0.2756
- 0.2875
- 0.2856
- 0.287
- 0.2838
- 0.2852
- 0.2909
- 0.2879
- 0.2857
- 0.2905
- 0.2931
- 0.2916
- 0.2913
- 0.2958
- 0.2933
- 0.2922
- 0.2983
- 0.2992
- 0.2949
- 0.2968
- 0.2952
- 0.2937
- 0.2956
- 0.3035
- 0.2991
- 0.3037
- 0.3044
- 0.3072
- 0.3063
- 0.3024
- 0.3095
- 0.3119
- 0.3002
- 0.3092
- 0.3129
- 0.3088
- 0.3068
- 0.3109
- 0.3058
- 0.3086
- 0.3084
- 0.3047
- 0.3103
- 0.3088
- 0.3059
- 0.3111
- 0.3117
- 0.3059
- 0.3137
- 0.3124
- 0.3045
- 0.312
- 0.3181
- 0.3128
- 0.3212
test_loss_list:
- 1.8167724609375
- 1.688755235671997
- 1.6358167600631714
- 1.5923390221595763
- 1.5670402836799622
- 1.5365298509597778
- 1.5136323118209838
- 1.4806510496139527
- 1.4738830780982972
- 1.466401240825653
- 1.4516129326820373
- 1.424901943206787
- 1.4125519371032715
- 1.4161573576927184
- 1.4312043285369873
- 1.402870578765869
- 1.3886890840530395
- 1.4058275151252746
- 1.3822273468971253
- 1.3950395393371582
- 1.3693221807479858
- 1.3863913202285767
- 1.361043200492859
- 1.3386024284362792
- 1.328492214679718
- 1.3270130777359008
- 1.3518888902664186
- 1.327973985671997
- 1.3475144767761231
- 1.3237053894996642
- 1.3077864456176758
- 1.3033020901679992
- 1.3031974744796753
- 1.2920844650268555
- 1.266795585155487
- 1.281531538963318
- 1.2786647057533265
- 1.278260600566864
- 1.3014351654052734
- 1.2798104405403137
- 1.2539512133598327
- 1.245539608001709
- 1.2614380431175232
- 1.26714546918869
- 1.2590490627288817
- 1.2877642226219177
- 1.2396944379806518
- 1.251428029537201
- 1.2346080660820007
- 1.2476632070541382
- 1.2505199480056763
- 1.2320332193374635
- 1.2459251260757447
- 1.2708825659751892
- 1.2591096806526183
- 1.2562414288520813
- 1.245772235393524
- 1.2473546242713929
- 1.241209955215454
- 1.2450630593299865
- 1.2412625455856323
- 1.237793629169464
- 1.233166835308075
- 1.2661488556861877
- 1.2473199439048768
- 1.2633559107780457
- 1.2497220635414124
- 1.2375135564804076
- 1.23449241399765
- 1.2293537116050721
- 1.2158940148353576
- 1.2261985158920288
- 1.2106514072418213
- 1.2268420386314391
- 1.2238027667999267
- 1.2084240245819091
- 1.2099472451210023
- 1.244740924835205
- 1.2122807669639588
- 1.2108843946456909
- 1.2104762053489686
- 1.2236272406578064
- 1.2106449651718139
- 1.2445027494430543
- 1.2309895491600036
- 1.2281840801239015
- 1.2248688220977784
- 1.227600212097168
- 1.2257565975189209
- 1.25589008808136
- 1.233060348033905
- 1.2299773645401002
- 1.2488765954971313
- 1.2141377758979797
- 1.2234312772750855
- 1.25594172000885
- 1.214782063961029
- 1.2068764328956605
- 1.21966450214386
- 1.2105944967269897
train_accuracy:
- 0.049
- 0.145
- 0.0
- 0.151
- 0.154
- 0.197
- 0.17
- 0.0
- 0.217
- 0.221
- 0.196
- 0.249
- 0.0
- 0.253
- 0.238
- 0.226
- 0.262
- 0.269
- 0.235
- 0.256
- 0.259
- 0.0
- 0.248
- 0.0
- 0.304
- 0.0
- 0.311
- 0.234
- 0.249
- 0.312
- 0.241
- 0.0
- 0.305
- 0.0
- 0.293
- 0.31
- 0.292
- 0.0
- 0.297
- 0.0
- 0.0
- 0.0
- 0.325
- 0.331
- 0.311
- 0.0
- 0.346
- 0.328
- 0.0
- 0.287
- 0.0
- 0.325
- 0.0
- 0.333
- 0.322
- 0.0
- 0.318
- 0.325
- 0.0
- 0.0
- 0.27
- 0.278
- 0.34
- 0.324
- 0.337
- 0.329
- 0.353
- 0.0
- 0.328
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.283
- 0.0
- 0.352
- 0.0
- 0.282
- 0.0
- 0.0
- 0.343
- 0.0
- 0.282
- 0.36
- 0.338
- 0.0
- 0.0
- 0.0
- 0.359
- 0.365
- 0.363
- 0.341
- 0.354
- 0.344
- 0.35
- 0.0
- 0.365
- 0.374
- 0.0
train_loss:
- 3.743
- 2.979
- 2.783
- 2.675
- 2.532
- 2.471
- 2.371
- 2.019
- 2.218
- 2.158
- 2.139
- 1.799
- 1.742
- 1.945
- 2.198
- 1.92
- 1.837
- 2.053
- 1.741
- 1.961
- 1.686
- 1.843
- 1.577
- 1.605
- 1.569
- 1.509
- 1.654
- 1.413
- 1.572
- 1.339
- 1.347
- 1.305
- 1.262
- 1.26
- 1.093
- 1.237
- 1.201
- 1.161
- 1.301
- 1.116
- 0.945
- 0.899
- 1.059
- 1.017
- 1.021
- 1.115
- 0.847
- 0.919
- 0.823
- 0.901
- 0.879
- 0.739
- 0.858
- 0.948
- 0.819
- 0.802
- 0.79
- 0.755
- 0.771
- 0.73
- 0.711
- 0.718
- 0.698
- 0.753
- 0.675
- 0.725
- 0.616
- 0.614
- 0.609
- 0.617
- 0.513
- 0.561
- 0.492
- 0.535
- 0.553
- 0.469
- 0.445
- 0.582
- 0.452
- 0.421
- 0.417
- 0.468
- 0.396
- 0.527
- 0.442
- 0.431
- 0.429
- 0.431
- 0.407
- 0.453
- 0.41
- 0.404
- 0.426
- 0.334
- 0.362
- 0.391
- 0.316
- 0.327
- 0.345
- 0.307
unequal: 0
verbose: 1
