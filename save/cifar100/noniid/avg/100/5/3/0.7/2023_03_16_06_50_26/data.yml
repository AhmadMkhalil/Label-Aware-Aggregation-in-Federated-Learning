avg_train_accuracy: 0.332
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0277
- 0.0839
- 0.1063
- 0.1253
- 0.1389
- 0.1512
- 0.1622
- 0.1696
- 0.1753
- 0.1824
- 0.1911
- 0.1939
- 0.1977
- 0.1999
- 0.2048
- 0.2101
- 0.2139
- 0.2189
- 0.2257
- 0.2247
- 0.2283
- 0.2324
- 0.2353
- 0.2409
- 0.2397
- 0.2426
- 0.2408
- 0.2483
- 0.2444
- 0.2457
- 0.249
- 0.2539
- 0.2602
- 0.2582
- 0.2594
- 0.2581
- 0.2621
- 0.2677
- 0.271
- 0.2749
- 0.2656
- 0.2681
- 0.2736
- 0.2687
- 0.2724
- 0.2779
- 0.2784
- 0.2783
- 0.2744
- 0.2824
- 0.2798
- 0.2821
- 0.287
- 0.2868
- 0.2894
- 0.2926
- 0.285
- 0.2893
- 0.291
- 0.2874
- 0.2862
- 0.2926
- 0.287
- 0.2924
- 0.2957
- 0.2917
- 0.2905
- 0.2918
- 0.2952
- 0.293
- 0.2892
- 0.2955
- 0.2903
- 0.2919
- 0.3012
- 0.2985
- 0.2983
- 0.2932
- 0.2973
- 0.3018
- 0.3013
- 0.2994
- 0.3057
- 0.3026
- 0.3034
- 0.3022
- 0.3043
- 0.3042
- 0.3081
- 0.3106
- 0.3057
- 0.3053
- 0.3065
- 0.3065
- 0.3082
- 0.3051
- 0.3083
- 0.3123
- 0.3097
- 0.3087
test_loss_list:
- 1.818489809036255
- 1.6950438547134399
- 1.6429838800430299
- 1.6073900365829468
- 1.5730927634239196
- 1.5410158395767213
- 1.521411852836609
- 1.4995492815971374
- 1.4813843250274659
- 1.457112696170807
- 1.4704822516441345
- 1.4307943296432495
- 1.4280770254135131
- 1.4079183530807495
- 1.4076448059082032
- 1.404879822731018
- 1.3838035011291503
- 1.4076285529136658
- 1.3861117124557496
- 1.3582494401931762
- 1.3494153380393983
- 1.352690179347992
- 1.3522789669036865
- 1.3520556473731995
- 1.331116135120392
- 1.3360905051231384
- 1.3301039338111877
- 1.3091028928756714
- 1.3392368006706237
- 1.3495654654502869
- 1.30553382396698
- 1.330910234451294
- 1.3420797872543335
- 1.3195868229866028
- 1.2995403742790221
- 1.3225088381767274
- 1.2806204295158385
- 1.2673889994621277
- 1.2664413833618164
- 1.2624107956886292
- 1.2747985529899597
- 1.2775791668891907
- 1.2582360100746155
- 1.2950852084159852
- 1.260831823348999
- 1.287787983417511
- 1.2534561657905579
- 1.2859659433364867
- 1.2974373006820679
- 1.2511453413963318
- 1.2528064489364623
- 1.2409342908859253
- 1.2361753392219543
- 1.243716390132904
- 1.2372824454307556
- 1.2305025386810302
- 1.243398938179016
- 1.228998188972473
- 1.2407824802398681
- 1.2504219460487365
- 1.2450324988365173
- 1.2259556651115417
- 1.260560884475708
- 1.227323145866394
- 1.2249790000915528
- 1.2336912155151367
- 1.236692340373993
- 1.2354171895980834
- 1.2234651064872741
- 1.2357843542098998
- 1.2694249320030213
- 1.2502542090415956
- 1.2645656561851502
- 1.275836887359619
- 1.2263260221481322
- 1.237325541973114
- 1.2423786234855652
- 1.2705340480804443
- 1.2280227303504945
- 1.2317403960227966
- 1.2354805302619933
- 1.2618383574485779
- 1.2223580765724182
- 1.2326851749420167
- 1.230493013858795
- 1.231327714920044
- 1.221793293952942
- 1.2281120944023132
- 1.2155137157440186
- 1.2186848282814027
- 1.2280843710899354
- 1.2283492231369018
- 1.2347928833961488
- 1.2309689140319824
- 1.23314373254776
- 1.2296065545082093
- 1.2185710310935973
- 1.2163014960289003
- 1.2268841075897217
- 1.2502675366401672
train_accuracy:
- 0.0
- 0.071
- 0.096
- 0.0
- 0.153
- 0.183
- 0.117
- 0.203
- 0.0
- 0.0
- 0.174
- 0.16
- 0.0
- 0.0
- 0.256
- 0.18
- 0.185
- 0.284
- 0.0
- 0.23
- 0.0
- 0.275
- 0.209
- 0.309
- 0.211
- 0.245
- 0.283
- 0.0
- 0.262
- 0.263
- 0.22
- 0.267
- 0.0
- 0.273
- 0.307
- 0.289
- 0.252
- 0.0
- 0.248
- 0.0
- 0.0
- 0.277
- 0.29
- 0.332
- 0.32
- 0.336
- 0.284
- 0.262
- 0.249
- 0.268
- 0.0
- 0.0
- 0.0
- 0.298
- 0.0
- 0.0
- 0.305
- 0.302
- 0.263
- 0.319
- 0.307
- 0.0
- 0.319
- 0.27
- 0.299
- 0.0
- 0.289
- 0.313
- 0.279
- 0.294
- 0.298
- 0.273
- 0.286
- 0.285
- 0.0
- 0.32
- 0.0
- 0.311
- 0.0
- 0.285
- 0.297
- 0.0
- 0.313
- 0.326
- 0.289
- 0.0
- 0.29
- 0.0
- 0.0
- 0.284
- 0.322
- 0.326
- 0.29
- 0.332
- 0.286
- 0.0
- 0.335
- 0.0
- 0.322
- 0.332
train_loss:
- 2.89
- 3.046
- 2.855
- 2.694
- 2.623
- 2.54
- 2.435
- 2.402
- 2.299
- 1.954
- 2.488
- 1.868
- 2.103
- 1.757
- 2.011
- 1.956
- 1.637
- 2.153
- 1.84
- 1.543
- 1.486
- 1.722
- 1.691
- 1.629
- 1.388
- 1.583
- 1.581
- 1.302
- 1.688
- 1.654
- 1.232
- 1.58
- 1.555
- 1.306
- 1.336
- 1.442
- 1.053
- 1.08
- 1.015
- 1.011
- 1.196
- 1.144
- 0.941
- 1.243
- 0.917
- 1.211
- 0.882
- 1.126
- 1.137
- 0.847
- 0.965
- 0.775
- 0.787
- 0.929
- 0.765
- 0.736
- 0.835
- 0.719
- 0.807
- 0.776
- 0.769
- 0.661
- 0.863
- 0.632
- 0.617
- 0.689
- 0.673
- 0.683
- 0.568
- 0.644
- 0.729
- 0.648
- 0.685
- 0.669
- 0.537
- 0.578
- 0.556
- 0.602
- 0.476
- 0.545
- 0.51
- 0.551
- 0.455
- 0.498
- 0.489
- 0.468
- 0.402
- 0.448
- 0.377
- 0.379
- 0.438
- 0.425
- 0.4
- 0.416
- 0.394
- 0.387
- 0.339
- 0.349
- 0.353
- 0.39
unequal: 0
verbose: 1
