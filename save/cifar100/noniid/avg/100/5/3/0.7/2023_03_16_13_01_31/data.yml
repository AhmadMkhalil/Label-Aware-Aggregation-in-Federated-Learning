avg_train_accuracy: 0.306
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 5
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0417
- 0.0923
- 0.1136
- 0.1316
- 0.1388
- 0.1522
- 0.1588
- 0.166
- 0.1725
- 0.1804
- 0.186
- 0.191
- 0.1931
- 0.2015
- 0.2068
- 0.2091
- 0.2134
- 0.2151
- 0.2186
- 0.2233
- 0.2288
- 0.2286
- 0.2331
- 0.2356
- 0.2363
- 0.2367
- 0.2443
- 0.2456
- 0.2476
- 0.2542
- 0.2547
- 0.253
- 0.256
- 0.2576
- 0.2597
- 0.2572
- 0.2601
- 0.2618
- 0.2663
- 0.2698
- 0.2693
- 0.2728
- 0.2724
- 0.2723
- 0.2795
- 0.2759
- 0.2799
- 0.2785
- 0.2818
- 0.2789
- 0.283
- 0.2865
- 0.2813
- 0.291
- 0.2856
- 0.2894
- 0.2914
- 0.2912
- 0.2919
- 0.2913
- 0.2886
- 0.2895
- 0.2934
- 0.294
- 0.2901
- 0.2927
- 0.2941
- 0.2972
- 0.3009
- 0.2946
- 0.2969
- 0.2996
- 0.3007
- 0.298
- 0.2994
- 0.3046
- 0.298
- 0.3007
- 0.3063
- 0.3032
- 0.3075
- 0.3089
- 0.3045
- 0.3072
- 0.2985
- 0.3072
- 0.3042
- 0.3097
- 0.3089
- 0.3068
- 0.3068
- 0.312
- 0.3122
- 0.306
- 0.3082
- 0.3075
- 0.3105
- 0.3129
- 0.311
- 0.3068
test_loss_list:
- 1.811540298461914
- 1.693815951347351
- 1.6374570035934448
- 1.5959857511520386
- 1.565477464199066
- 1.539732162952423
- 1.5063634872436524
- 1.498858015537262
- 1.4846757125854493
- 1.4772588324546814
- 1.4868551039695739
- 1.45307923078537
- 1.4359350061416627
- 1.406794204711914
- 1.4082447290420532
- 1.4018215036392212
- 1.3759177565574645
- 1.408436312675476
- 1.392065818309784
- 1.3887009930610656
- 1.354750156402588
- 1.3851193761825562
- 1.3638864684104919
- 1.3568970799446105
- 1.3434273219108581
- 1.3623853039741516
- 1.3461968421936035
- 1.3629908752441406
- 1.3731678676605226
- 1.3138674521446227
- 1.313817148208618
- 1.3152258586883545
- 1.3152188205718993
- 1.3422103643417358
- 1.3177870535850524
- 1.3030039358139038
- 1.3245471954345702
- 1.305685544013977
- 1.2975304841995239
- 1.2851101541519165
- 1.284825747013092
- 1.260187065601349
- 1.276653606891632
- 1.2693476033210755
- 1.2509121346473693
- 1.2647330474853515
- 1.260115315914154
- 1.2665006136894226
- 1.2423256421089173
- 1.2532764816284179
- 1.2548361921310425
- 1.2369864106178283
- 1.254730761051178
- 1.2362982797622681
- 1.254591019153595
- 1.2458980298042297
- 1.2289371490478516
- 1.2436458134651185
- 1.2429267024993897
- 1.2792918753623963
- 1.2791410207748413
- 1.2516176319122314
- 1.22664559841156
- 1.2338416528701783
- 1.2714250946044923
- 1.2574116373062134
- 1.2447500586509705
- 1.234926130771637
- 1.2438160753250123
- 1.269856390953064
- 1.2453515219688416
- 1.2390878534317016
- 1.234529037475586
- 1.2638289213180542
- 1.2234843850135804
- 1.2142756509780883
- 1.2502926182746887
- 1.2409331059455873
- 1.2189580202102661
- 1.2338180232048035
- 1.218051700592041
- 1.2180045461654663
- 1.230019826889038
- 1.2336571717262268
- 1.2678052687644958
- 1.219121537208557
- 1.233248269557953
- 1.238010461330414
- 1.2399742102622986
- 1.2332462525367738
- 1.2325763273239136
- 1.215878028869629
- 1.2170711851119995
- 1.2309596562385559
- 1.2199436116218567
- 1.2286850786209107
- 1.2186744070053102
- 1.219390983581543
- 1.2313824605941772
- 1.2397294020652772
train_accuracy:
- 0.043
- 0.0
- 0.107
- 0.133
- 0.152
- 0.117
- 0.181
- 0.0
- 0.171
- 0.206
- 0.218
- 0.213
- 0.191
- 0.0
- 0.204
- 0.2
- 0.211
- 0.0
- 0.269
- 0.234
- 0.249
- 0.0
- 0.246
- 0.0
- 0.241
- 0.224
- 0.242
- 0.286
- 0.208
- 0.0
- 0.256
- 0.0
- 0.0
- 0.244
- 0.0
- 0.237
- 0.252
- 0.246
- 0.269
- 0.282
- 0.0
- 0.0
- 0.33
- 0.269
- 0.0
- 0.264
- 0.276
- 0.276
- 0.334
- 0.283
- 0.3
- 0.0
- 0.271
- 0.0
- 0.287
- 0.286
- 0.0
- 0.0
- 0.285
- 0.299
- 0.0
- 0.306
- 0.0
- 0.0
- 0.307
- 0.295
- 0.349
- 0.0
- 0.0
- 0.3
- 0.287
- 0.3
- 0.0
- 0.277
- 0.0
- 0.287
- 0.301
- 0.297
- 0.0
- 0.0
- 0.0
- 0.0
- 0.295
- 0.309
- 0.0
- 0.306
- 0.28
- 0.305
- 0.0
- 0.304
- 0.361
- 0.328
- 0.0
- 0.305
- 0.305
- 0.324
- 0.0
- 0.288
- 0.327
- 0.306
train_loss:
- 3.294
- 3.015
- 2.799
- 2.734
- 2.565
- 2.546
- 2.156
- 2.395
- 2.349
- 2.25
- 2.443
- 2.162
- 2.067
- 1.779
- 1.973
- 1.981
- 1.676
- 2.091
- 1.842
- 1.799
- 1.513
- 1.896
- 1.634
- 1.629
- 1.61
- 1.769
- 1.552
- 1.667
- 1.586
- 1.276
- 1.391
- 1.313
- 1.283
- 1.468
- 1.226
- 1.281
- 1.424
- 1.192
- 1.2
- 1.165
- 1.155
- 0.994
- 1.052
- 1.067
- 0.882
- 0.966
- 1.049
- 0.961
- 0.878
- 0.945
- 0.905
- 0.842
- 0.909
- 0.77
- 0.873
- 0.866
- 0.715
- 0.821
- 0.778
- 0.872
- 0.847
- 0.752
- 0.692
- 0.694
- 0.751
- 0.703
- 0.645
- 0.676
- 0.628
- 0.691
- 0.606
- 0.626
- 0.569
- 0.597
- 0.537
- 0.504
- 0.592
- 0.529
- 0.449
- 0.51
- 0.435
- 0.437
- 0.491
- 0.45
- 0.504
- 0.431
- 0.423
- 0.416
- 0.404
- 0.431
- 0.399
- 0.34
- 0.383
- 0.388
- 0.375
- 0.392
- 0.335
- 0.339
- 0.372
- 0.376
unequal: 0
verbose: 1
