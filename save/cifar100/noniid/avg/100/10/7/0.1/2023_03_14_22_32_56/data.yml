avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0442
- 0.0446
- 0.0396
- 0.0525
- 0.0848
- 0.0411
- 0.0444
- 0.0924
- 0.0495
- 0.0425
- 0.0996
- 0.0568
- 0.043
- 0.0572
- 0.1059
- 0.0585
- 0.0498
- 0.0585
- 0.11
- 0.1197
- 0.1159
- 0.1183
- 0.0508
- 0.0512
- 0.0519
- 0.0538
- 0.0608
- 0.0611
- 0.1216
- 0.0563
- 0.1262
- 0.05
- 0.0563
- 0.055
- 0.0638
- 0.129
- 0.0475
- 0.1258
- 0.0588
- 0.0626
- 0.063
- 0.1295
- 0.1302
- 0.0538
- 0.0553
- 0.0564
- 0.0609
- 0.1333
- 0.1377
- 0.0666
- 0.0651
- 0.1394
- 0.0617
- 0.0654
- 0.0634
- 0.0638
- 0.0481
- 0.0564
- 0.0644
- 0.144
- 0.0679
- 0.0518
- 0.1385
- 0.1371
- 0.068
- 0.0613
- 0.0588
- 0.0556
- 0.059
- 0.0614
- 0.1438
- 0.0696
- 0.1434
- 0.0737
- 0.1495
- 0.1468
- 0.1462
- 0.1451
- 0.1465
- 0.0567
- 0.1466
- 0.0666
- 0.1524
- 0.0702
- 0.0738
- 0.0634
- 0.0716
- 0.0667
- 0.0704
- 0.1592
- 0.0829
- 0.0703
- 0.1604
- 0.1518
- 0.0839
- 0.1614
- 0.1545
- 0.0902
- 0.0765
- 0.0799
test_loss_list:
- 2.2307867860794066
- 3.574752883911133
- 3.4530441999435424
- 3.429038906097412
- 2.4637564611434937
- 3.569563889503479
- 3.4324461460113525
- 2.4828313112258913
- 3.4736148262023927
- 3.431659107208252
- 2.4159597682952882
- 3.3821756935119627
- 3.455872001647949
- 3.3743192863464357
- 2.41229248046875
- 3.4973013019561767
- 3.4234857606887816
- 3.304762740135193
- 2.4177627515792848
- 2.5514306688308714
- 2.6639125394821166
- 2.782404580116272
- 3.5404884099960325
- 3.455498523712158
- 3.3663321495056153
- 3.2931989860534667
- 3.2296196842193603
- 3.1747330141067507
- 2.2858840799331666
- 3.250956516265869
- 2.405092172622681
- 3.3203281116485597
- 3.3280158138275144
- 3.1980820369720457
- 3.2359243297576903
- 2.3139412021636963
- 3.2916396045684815
- 2.3197686672210693
- 3.2534608173370363
- 3.2461165761947632
- 3.461369180679321
- 2.3228151559829713
- 2.4861524629592897
- 3.2633028173446657
- 3.2411917448043823
- 3.471064081192017
- 3.087118139266968
- 2.2182166385650635
- 2.3898523902893065
- 3.273110475540161
- 3.1669730281829835
- 2.316807541847229
- 3.1771155261993407
- 3.1762111616134643
- 3.394295320510864
- 3.230847601890564
- 3.183926568031311
- 3.1185896587371826
- 3.158523416519165
- 2.17852397441864
- 3.1796677017211916
- 3.2008662700653074
- 2.259919319152832
- 2.395273356437683
- 3.2359864473342896
- 3.2350276470184327
- 3.022985019683838
- 2.9729164981842042
- 3.044500150680542
- 3.0957377481460573
- 2.151144332885742
- 2.9624528455734254
- 2.2279053115844727
- 3.0744811868667603
- 2.3344853830337526
- 2.4669279050827027
- 2.5306203031539916
- 2.620978956222534
- 2.656409192085266
- 3.2700747728347777
- 2.415509943962097
- 3.0894336605072024
- 2.3250912857055663
- 3.0856424140930176
- 2.99911856174469
- 2.967526984214783
- 2.9864881324768064
- 3.1194595813751222
- 2.9049069452285767
- 2.0612356853485108
- 2.97810311794281
- 2.966616039276123
- 2.1239100885391236
- 2.3121767902374266
- 3.1005213260650635
- 2.259743299484253
- 2.432729516029358
- 3.146276912689209
- 3.0519696426391603
- 2.927004885673523
train_accuracy:
- 0.162
- 0.0
- 0.0
- 0.0
- 0.27
- 0.0
- 0.0
- 0.303
- 0.0
- 0.0
- 0.381
- 0.0
- 0.0
- 0.0
- 0.329
- 0.0
- 0.0
- 0.0
- 0.371
- 0.364
- 0.4
- 0.434
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.415
- 0.0
- 0.395
- 0.0
- 0.0
- 0.0
- 0.0
- 0.379
- 0.0
- 0.363
- 0.0
- 0.0
- 0.0
- 0.389
- 0.462
- 0.0
- 0.0
- 0.0
- 0.0
- 0.404
- 0.48
- 0.0
- 0.0
- 0.423
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.483
- 0.0
- 0.0
- 0.419
- 0.449
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.491
- 0.0
- 0.492
- 0.0
- 0.497
- 0.495
- 0.487
- 0.471
- 0.494
- 0.0
- 0.431
- 0.0
- 0.449
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.459
- 0.0
- 0.0
- 0.461
- 0.491
- 0.0
- 0.465
- 0.505
- 0.0
- 0.0
- 0.0
train_loss:
- 3.199
- 1.807
- 2.095
- 1.763
- 2.849
- 1.5
- 1.949
- 2.608
- 1.746
- 2.07
- 2.495
- 1.175
- 1.563
- 1.367
- 2.246
- 0.882
- 1.598
- 1.164
- 1.988
- 1.755
- 1.354
- 1.557
- 1.345
- 1.58
- 1.731
- 1.095
- 1.108
- 1.003
- 1.627
- 0.92
- 1.736
- 1.094
- 1.226
- 0.897
- 0.857
- 1.587
- 1.624
- 1.354
- 0.928
- 0.775
- 0.259
- 1.197
- 1.107
- 1.03
- 1.424
- 0.58
- 1.087
- 1.133
- 1.253
- 0.696
- 0.661
- 0.922
- 0.868
- 0.656
- 0.236
- 0.54
- 1.401
- 1.041
- 0.444
- 1.349
- 0.669
- 1.13
- 0.943
- 0.49
- 0.657
- 0.851
- 1.082
- 1.041
- 0.648
- 0.602
- 1.218
- 0.594
- 0.837
- 0.427
- 1.065
- 0.629
- 0.504
- 0.36
- 0.313
- 1.134
- 0.762
- 0.701
- 0.568
- 0.623
- 0.564
- 0.812
- 0.338
- 0.406
- 0.659
- 0.593
- 0.298
- 0.635
- 0.464
- 0.667
- 0.319
- 0.384
- 0.45
- 0.246
- 0.622
- 0.501
unequal: 0
verbose: 1
