avg_train_accuracy: 0.441
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0411
- 0.033
- 0.0464
- 0.076
- 0.0534
- 0.0449
- 0.0872
- 0.0502
- 0.0456
- 0.0347
- 0.0459
- 0.0517
- 0.0984
- 0.0492
- 0.053
- 0.0515
- 0.0481
- 0.1061
- 0.0526
- 0.1092
- 0.0384
- 0.0384
- 0.0389
- 0.0578
- 0.0521
- 0.0397
- 0.053
- 0.115
- 0.0568
- 0.0487
- 0.1175
- 0.1218
- 0.0546
- 0.1289
- 0.1284
- 0.0603
- 0.054
- 0.0554
- 0.0561
- 0.0592
- 0.0563
- 0.0582
- 0.1296
- 0.1316
- 0.1343
- 0.0536
- 0.04
- 0.1336
- 0.0556
- 0.0569
- 0.058
- 0.0537
- 0.0598
- 0.1367
- 0.0576
- 0.0567
- 0.1378
- 0.0485
- 0.1362
- 0.0595
- 0.1389
- 0.0649
- 0.146
- 0.0651
- 0.058
- 0.1443
- 0.1474
- 0.145
- 0.0639
- 0.1517
- 0.0646
- 0.1507
- 0.0614
- 0.066
- 0.1476
- 0.0522
- 0.1473
- 0.1482
- 0.1494
- 0.1465
- 0.0721
- 0.0628
- 0.0479
- 0.0663
- 0.0659
- 0.0589
- 0.0609
- 0.0583
- 0.0645
- 0.0582
- 0.0653
- 0.067
- 0.1561
- 0.0719
- 0.0684
- 0.0645
- 0.065
- 0.0678
- 0.0578
- 0.1553
test_loss_list:
- 2.811454453468323
- 3.4923541164398193
- 3.4450103092193602
- 2.3800685691833494
- 3.608933382034302
- 3.4487942695617675
- 2.463773603439331
- 3.431805019378662
- 3.3548825931549073
- 3.409052839279175
- 3.3272842025756835
- 3.2676276540756226
- 2.3191763162612915
- 3.399317545890808
- 3.6229637670516968
- 3.404850935935974
- 3.290593762397766
- 2.3964099311828613
- 3.375867223739624
- 2.4359371948242186
- 3.446296148300171
- 3.608629322052002
- 3.774549198150635
- 3.3672300148010255
- 3.159124903678894
- 3.300053553581238
- 3.2697338533401488
- 2.2669880628585815
- 3.25126060962677
- 3.2058393478393556
- 2.3177039766311647
- 2.482260670661926
- 3.344985384941101
- 2.4276447343826293
- 2.577223720550537
- 3.433884506225586
- 3.3031603050231935
- 3.190794997215271
- 3.2811063051223757
- 3.1148134660720825
- 3.2600644397735596
- 3.296752190589905
- 2.3202583360672
- 2.4470722007751466
- 2.5794887924194336
- 3.3200852727890013
- 3.176335000991821
- 2.3071698474884035
- 3.138414697647095
- 3.1377677440643312
- 3.0337956142425537
- 3.127204570770264
- 3.247512083053589
- 2.2450672388076782
- 3.176367874145508
- 3.325566363334656
- 2.3689906787872315
- 3.1604053163528443
- 2.376865348815918
- 3.2025326347351073
- 2.3783534479141237
- 3.113264174461365
- 2.380059881210327
- 3.140377264022827
- 3.083263792991638
- 2.244393200874329
- 2.394267134666443
- 2.508541536331177
- 3.1750513315200806
- 2.3955514574050905
- 3.2508929204940795
- 2.4545226287841797
- 3.262051830291748
- 3.071299629211426
- 2.3158856344223024
- 3.0708761167526246
- 2.3077337312698365
- 2.4392377519607544
- 2.5079965734481813
- 2.56538667678833
- 3.1997848320007325
- 3.134629611968994
- 3.1233928966522218
- 3.1485834980010985
- 2.9662038707733154
- 3.0577859115600585
- 2.876483359336853
- 3.196426420211792
- 3.0054518699646
- 2.936702404022217
- 2.906893811225891
- 3.114049735069275
- 2.049381356239319
- 2.8841005086898805
- 2.8512906074523925
- 3.0876528644561767
- 2.8554524517059328
- 2.9989605951309204
- 2.8785072994232177
- 2.0581451892852782
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.242
- 0.0
- 0.0
- 0.233
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.304
- 0.0
- 0.0
- 0.0
- 0.0
- 0.298
- 0.0
- 0.324
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.352
- 0.0
- 0.0
- 0.358
- 0.377
- 0.0
- 0.38
- 0.378
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.433
- 0.383
- 0.417
- 0.0
- 0.0
- 0.404
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.448
- 0.0
- 0.0
- 0.429
- 0.0
- 0.383
- 0.0
- 0.455
- 0.0
- 0.442
- 0.0
- 0.0
- 0.411
- 0.443
- 0.478
- 0.0
- 0.464
- 0.0
- 0.468
- 0.0
- 0.0
- 0.435
- 0.0
- 0.395
- 0.478
- 0.436
- 0.429
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.497
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.441
train_loss:
- 1.625
- 2.187
- 1.805
- 3.371
- 1.682
- 1.895
- 2.769
- 1.429
- 1.881
- 1.955
- 1.878
- 1.23
- 2.557
- 1.283
- 0.747
- 1.161
- 1.405
- 2.373
- 1.432
- 2.042
- 1.653
- 0.952
- 0.818
- 1.591
- 1.657
- 1.094
- 1.23
- 1.974
- 0.886
- 1.262
- 1.644
- 1.778
- 1.113
- 1.771
- 1.175
- 1.2
- 0.897
- 1.324
- 0.675
- 1.005
- 0.85
- 0.677
- 1.873
- 1.166
- 1.118
- 1.296
- 1.344
- 1.251
- 1.025
- 0.945
- 1.048
- 0.731
- 0.638
- 1.361
- 0.584
- 0.284
- 0.981
- 1.001
- 1.045
- 0.83
- 0.917
- 0.831
- 1.361
- 0.773
- 0.928
- 0.933
- 0.933
- 0.659
- 0.71
- 0.82
- 0.411
- 0.609
- 0.79
- 0.758
- 0.835
- 0.957
- 0.629
- 0.682
- 0.393
- 0.286
- 0.616
- 0.773
- 0.804
- 0.458
- 0.808
- 0.74
- 0.619
- 0.176
- 1.164
- 0.571
- 0.55
- 0.621
- 0.879
- 0.446
- 0.491
- 0.172
- 0.498
- 0.635
- 0.798
- 0.643
unequal: 0
verbose: 1
