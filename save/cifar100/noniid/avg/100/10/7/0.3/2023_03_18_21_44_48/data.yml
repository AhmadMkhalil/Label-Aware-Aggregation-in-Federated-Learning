avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0283
- 0.0739
- 0.0835
- 0.071
- 0.0718
- 0.0799
- 0.0628
- 0.1041
- 0.0882
- 0.1174
- 0.1204
- 0.1387
- 0.1433
- 0.1215
- 0.1178
- 0.0911
- 0.0942
- 0.127
- 0.1579
- 0.1473
- 0.156
- 0.1222
- 0.1483
- 0.1248
- 0.1189
- 0.15
- 0.1347
- 0.1224
- 0.1334
- 0.1517
- 0.1594
- 0.1219
- 0.1659
- 0.1509
- 0.1733
- 0.1346
- 0.1677
- 0.1794
- 0.1659
- 0.1735
- 0.1745
- 0.1988
- 0.1887
- 0.1791
- 0.1579
- 0.1888
- 0.1412
- 0.1374
- 0.1883
- 0.1674
- 0.182
- 0.1887
- 0.173
- 0.2031
- 0.176
- 0.1777
- 0.1768
- 0.2124
- 0.2176
- 0.1835
- 0.2065
- 0.173
- 0.2101
- 0.2092
- 0.1772
- 0.1735
- 0.201
- 0.2204
- 0.2022
- 0.2155
- 0.2102
- 0.1976
- 0.195
- 0.1732
- 0.1693
- 0.1875
- 0.2141
- 0.1903
- 0.1654
- 0.1745
- 0.2291
- 0.2131
- 0.1852
- 0.2135
- 0.1956
- 0.1771
- 0.225
- 0.1966
- 0.2038
- 0.2095
- 0.2308
- 0.1926
- 0.1892
- 0.1956
- 0.1593
- 0.2096
- 0.1952
- 0.2018
- 0.1873
- 0.1908
test_loss_list:
- 1.932440333366394
- 1.8862047386169434
- 1.947337613105774
- 1.9670201015472413
- 1.9920691680908202
- 1.8859119844436645
- 1.8059263706207276
- 1.763495135307312
- 1.8443446779251098
- 1.7655850648880005
- 1.945516209602356
- 1.827023286819458
- 1.8472753763198853
- 1.9556629180908203
- 1.8466356897354126
- 1.8734264135360719
- 1.8143218564987182
- 2.2486149168014524
- 1.772610101699829
- 1.741153826713562
- 1.734581995010376
- 1.8211017036437989
- 1.793594570159912
- 1.758618745803833
- 1.7925736379623414
- 1.6899043130874634
- 1.7999987602233887
- 1.8441141843795776
- 1.8535217714309693
- 1.6076287865638732
- 1.6586746025085448
- 1.7771935033798218
- 1.68815669298172
- 1.841008915901184
- 1.7530422353744506
- 1.7643518495559691
- 1.7277412295341492
- 1.722687282562256
- 1.6781295323371888
- 1.6977766370773315
- 1.7165192365646362
- 1.6781641340255737
- 1.6206123733520508
- 1.701723554134369
- 1.6923247742652894
- 1.6266211414337157
- 1.755091619491577
- 1.8071222686767578
- 1.6174353885650634
- 1.8006604623794555
- 1.6294379806518555
- 1.6497124719619751
- 1.8635529804229736
- 1.6759687042236329
- 1.8461565446853638
- 1.9109029865264893
- 1.9408375644683837
- 1.6747825384140014
- 1.5998902535438537
- 1.8213248682022094
- 1.7078604745864867
- 1.9072414827346802
- 1.6446338415145874
- 1.6685888624191285
- 1.7282983016967775
- 1.6443982863426208
- 1.6072333860397339
- 1.6144642925262451
- 1.6582478857040406
- 1.6558966135978699
- 1.645806393623352
- 1.7297959852218627
- 1.6733457946777344
- 1.7335756993293763
- 1.7294892072677612
- 1.655998547077179
- 1.6074059891700745
- 1.6756317949295043
- 1.771486883163452
- 1.7017474961280823
- 1.5460864472389222
- 1.6091281819343566
- 1.6759097838401795
- 1.6080514788627625
- 1.6357970929145813
- 1.7138844537734985
- 1.5916159653663635
- 1.6697010135650634
- 1.7358485674858093
- 1.7676106023788452
- 1.6273249983787537
- 1.6818739867210388
- 1.7051697039604188
- 1.7458256554603577
- 2.158341884613037
- 1.666438603401184
- 1.802943124771118
- 1.7049218201637268
- 1.843941617012024
- 1.9129419708251953
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.055
- 0.0
- 0.0
- 0.0
- 0.0
- 0.299
- 0.0
- 0.0
- 0.381
- 0.0
- 0.0
- 0.0
- 0.387
- 0.0
- 0.245
- 0.0
- 0.0
- 0.191
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.402
- 0.3
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.277
- 0.434
- 0.0
- 0.0
- 0.0
- 0.0
- 0.438
- 0.447
- 0.457
- 0.0
- 0.0
- 0.467
- 0.376
- 0.427
- 0.0
- 0.306
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.355
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.308
- 0.295
- 0.0
- 0.0
- 0.0
- 0.0
- 0.296
- 0.0
- 0.4
- 0.0
- 0.0
- 0.0
- 0.0
- 0.478
- 0.501
- 0.0
- 0.481
- 0.391
- 0.449
- 0.0
train_loss:
- 2.169
- 2.026
- 1.737
- 1.326
- 1.297
- 1.754
- 1.316
- 1.506
- 1.095
- 1.36
- 1.73
- 1.392
- 1.192
- 1.722
- 0.917
- 0.947
- 0.994
- 1.919
- 0.979
- 1.079
- 1.13
- 0.817
- 0.952
- 0.908
- 0.774
- 1.002
- 0.584
- 0.654
- 0.705
- 1.218
- 0.886
- 0.595
- 0.934
- 1.149
- 0.919
- 0.64
- 0.829
- 0.815
- 0.662
- 0.741
- 0.842
- 0.693
- 0.906
- 0.725
- 0.539
- 0.799
- 0.465
- 0.383
- 0.788
- 0.886
- 0.572
- 0.698
- 0.817
- 0.587
- 0.82
- 0.669
- 0.675
- 0.462
- 0.63
- 0.685
- 0.598
- 0.612
- 0.406
- 0.559
- 0.365
- 0.479
- 0.458
- 0.446
- 0.509
- 0.429
- 0.44
- 0.349
- 0.431
- 0.419
- 0.304
- 0.36
- 0.387
- 0.25
- 0.282
- 0.356
- 0.435
- 0.457
- 0.27
- 0.349
- 0.269
- 0.25
- 0.384
- 0.227
- 0.439
- 0.276
- 0.386
- 0.282
- 0.24
- 0.567
- 0.477
- 0.379
- 0.408
- 0.323
- 0.417
- 0.331
unequal: 0
verbose: 1
