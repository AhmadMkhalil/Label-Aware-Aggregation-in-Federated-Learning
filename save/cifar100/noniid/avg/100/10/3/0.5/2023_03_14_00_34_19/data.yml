avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.035
- 0.086
- 0.106
- 0.1211
- 0.1307
- 0.1446
- 0.1536
- 0.1628
- 0.1673
- 0.1754
- 0.182
- 0.1851
- 0.1895
- 0.2062
- 0.2048
- 0.1971
- 0.2034
- 0.2085
- 0.2082
- 0.2112
- 0.2191
- 0.2201
- 0.2221
- 0.2244
- 0.222
- 0.2261
- 0.2307
- 0.2352
- 0.2371
- 0.2325
- 0.2359
- 0.2446
- 0.2406
- 0.2423
- 0.2476
- 0.2435
- 0.2419
- 0.249
- 0.251
- 0.258
- 0.251
- 0.2614
- 0.2499
- 0.2643
- 0.265
- 0.2604
- 0.272
- 0.2764
- 0.2701
- 0.2597
- 0.2749
- 0.2604
- 0.2626
- 0.264
- 0.274
- 0.2787
- 0.2858
- 0.2817
- 0.3038
- 0.3081
- 0.3074
- 0.2731
- 0.2767
- 0.2708
- 0.2789
- 0.2728
- 0.2745
- 0.2725
- 0.2918
- 0.282
- 0.2919
- 0.2769
- 0.3055
- 0.2998
- 0.2832
- 0.3136
- 0.303
- 0.3015
- 0.3207
- 0.2892
- 0.2845
- 0.2761
- 0.2783
- 0.2768
- 0.2778
- 0.2852
- 0.2931
- 0.2872
- 0.2957
- 0.2747
- 0.2982
- 0.2882
- 0.2848
- 0.2885
- 0.3017
- 0.3066
- 0.3091
- 0.3103
- 0.2962
- 0.3003
test_loss_list:
- 1.8362046670913696
- 1.73194242477417
- 1.7338122749328613
- 1.6473235535621642
- 1.6015741872787475
- 1.5763850259780883
- 1.555631468296051
- 1.603748481273651
- 1.607957673072815
- 1.59742347240448
- 1.678464608192444
- 1.6301121139526367
- 1.5188157320022584
- 1.437956495285034
- 1.4550346374511718
- 1.5993717622756958
- 1.6460890507698058
- 1.5912836027145385
- 1.5936226558685302
- 1.5577653813362122
- 1.4597981882095337
- 1.516429488658905
- 1.5411837935447692
- 1.5552212548255921
- 1.5221325445175171
- 1.5213019847869873
- 1.5232572674751281
- 1.4308395171165467
- 1.4031696152687072
- 1.4576867938041687
- 1.4822769498825072
- 1.4220412874221802
- 1.47809326171875
- 1.5075704169273376
- 1.515879395008087
- 1.483184564113617
- 1.475006697177887
- 1.409828383922577
- 1.4642993307113648
- 1.4091549634933471
- 1.541303994655609
- 1.3346013188362122
- 1.4049797081947326
- 1.3533104538917542
- 1.3357031965255737
- 1.3963617777824402
- 1.345838530063629
- 1.3430738377571105
- 1.3197191119194032
- 1.3935408616065978
- 1.3208019375801086
- 1.4684103298187257
- 1.5216278100013734
- 1.460239324569702
- 1.3679079294204712
- 1.3245747542381288
- 1.3257855319976806
- 1.3054590797424317
- 1.2715431261062622
- 1.2734926390647887
- 1.2741877055168152
- 1.3527318477630614
- 1.3686498498916626
- 1.4759427309036255
- 1.339958381652832
- 1.397798273563385
- 1.398000750541687
- 1.3856687545776367
- 1.3252226758003234
- 1.387396945953369
- 1.3243683338165284
- 1.3679573225975037
- 1.2704979467391968
- 1.2920947504043578
- 1.3513852119445802
- 1.2655003070831299
- 1.2902116656303406
- 1.2883878755569458
- 1.2624871706962586
- 1.338059139251709
- 1.3794970512390137
- 1.4663433194160462
- 1.504605884552002
- 1.533030273914337
- 1.449906098842621
- 1.4453414249420167
- 1.3599008584022523
- 1.404165232181549
- 1.312105667591095
- 1.4646458268165587
- 1.3318544602394105
- 1.3935384392738341
- 1.4144990682601928
- 1.4269293761253357
- 1.356078712940216
- 1.3542184448242187
- 1.3576162028312684
- 1.3562330508232117
- 1.407698497772217
- 1.3113087606430054
train_accuracy:
- 0.04
- 0.096
- 0.152
- 0.0
- 0.0
- 0.213
- 0.0
- 0.218
- 0.212
- 0.248
- 0.228
- 0.238
- 0.273
- 0.0
- 0.274
- 0.255
- 0.283
- 0.265
- 0.26
- 0.286
- 0.268
- 0.285
- 0.0
- 0.302
- 0.328
- 0.328
- 0.0
- 0.334
- 0.319
- 0.3
- 0.339
- 0.0
- 0.312
- 0.347
- 0.0
- 0.327
- 0.346
- 0.355
- 0.358
- 0.0
- 0.351
- 0.0
- 0.349
- 0.31
- 0.344
- 0.353
- 0.333
- 0.339
- 0.351
- 0.358
- 0.342
- 0.368
- 0.37
- 0.351
- 0.0
- 0.323
- 0.35
- 0.0
- 0.34
- 0.343
- 0.0
- 0.0
- 0.377
- 0.371
- 0.0
- 0.396
- 0.356
- 0.384
- 0.367
- 0.384
- 0.0
- 0.354
- 0.0
- 0.363
- 0.0
- 0.308
- 0.357
- 0.371
- 0.0
- 0.392
- 0.354
- 0.347
- 0.377
- 0.369
- 0.404
- 0.39
- 0.364
- 0.337
- 0.368
- 0.388
- 0.0
- 0.0
- 0.383
- 0.386
- 0.0
- 0.379
- 0.375
- 0.0
- 0.0
- 0.0
train_loss:
- 3.575
- 2.776
- 2.909
- 2.564
- 2.356
- 2.324
- 2.18
- 2.418
- 2.434
- 2.317
- 2.513
- 2.131
- 1.888
- 1.628
- 1.747
- 2.166
- 2.103
- 1.863
- 1.757
- 1.901
- 1.592
- 1.681
- 1.637
- 1.603
- 1.621
- 1.567
- 1.552
- 1.332
- 1.321
- 1.413
- 1.412
- 1.246
- 1.328
- 1.3
- 1.274
- 1.319
- 1.203
- 1.065
- 1.189
- 1.023
- 1.231
- 0.928
- 1.091
- 0.959
- 0.952
- 1.026
- 0.899
- 0.876
- 0.862
- 0.933
- 0.828
- 0.991
- 0.919
- 0.838
- 0.76
- 0.725
- 0.681
- 0.762
- 0.59
- 0.594
- 0.574
- 0.725
- 0.713
- 0.766
- 0.624
- 0.661
- 0.627
- 0.686
- 0.593
- 0.604
- 0.532
- 0.612
- 0.49
- 0.48
- 0.562
- 0.422
- 0.51
- 0.502
- 0.415
- 0.505
- 0.467
- 0.546
- 0.508
- 0.491
- 0.448
- 0.435
- 0.417
- 0.42
- 0.434
- 0.445
- 0.387
- 0.392
- 0.352
- 0.353
- 0.348
- 0.323
- 0.31
- 0.307
- 0.346
- 0.365
unequal: 0
verbose: 1
