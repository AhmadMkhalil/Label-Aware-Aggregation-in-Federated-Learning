avg_train_accuracy: 0.388
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03
- 0.0834
- 0.1037
- 0.1216
- 0.1336
- 0.1411
- 0.1532
- 0.1587
- 0.1676
- 0.1743
- 0.1777
- 0.179
- 0.1842
- 0.1878
- 0.1999
- 0.1971
- 0.2
- 0.2095
- 0.2058
- 0.2138
- 0.2193
- 0.2159
- 0.2161
- 0.2198
- 0.2385
- 0.2272
- 0.2337
- 0.2293
- 0.2332
- 0.2291
- 0.233
- 0.2319
- 0.2411
- 0.2428
- 0.2499
- 0.254
- 0.2551
- 0.2474
- 0.2587
- 0.2531
- 0.2608
- 0.2545
- 0.2508
- 0.2514
- 0.2653
- 0.2644
- 0.2587
- 0.2692
- 0.2811
- 0.2643
- 0.2797
- 0.2562
- 0.263
- 0.2607
- 0.2636
- 0.2653
- 0.2624
- 0.2839
- 0.2682
- 0.2758
- 0.2658
- 0.2792
- 0.2844
- 0.2732
- 0.2751
- 0.275
- 0.2684
- 0.2791
- 0.3
- 0.2794
- 0.289
- 0.2924
- 0.2807
- 0.2792
- 0.2763
- 0.2787
- 0.2896
- 0.2813
- 0.2949
- 0.2928
- 0.2752
- 0.2789
- 0.2974
- 0.3103
- 0.2771
- 0.2928
- 0.2985
- 0.2808
- 0.2899
- 0.2964
- 0.2865
- 0.2981
- 0.3062
- 0.3043
- 0.3055
- 0.2907
- 0.2893
- 0.2905
- 0.3084
- 0.2938
test_loss_list:
- 1.8400874900817872
- 1.7519690895080566
- 1.748771185874939
- 1.7494455814361571
- 1.6723848271369934
- 1.6793597316741944
- 1.65510657787323
- 1.6462407183647156
- 1.576533043384552
- 1.5386326432228088
- 1.527856602668762
- 1.5820178985595703
- 1.5729497456550598
- 1.5051499390602112
- 1.4871983861923217
- 1.464066653251648
- 1.5186985802650452
- 1.4717476081848144
- 1.5021100330352783
- 1.445628161430359
- 1.4443405389785766
- 1.5029538083076477
- 1.5086936259269714
- 1.4291548538208008
- 1.3652313446998596
- 1.4497588562965393
- 1.4127344155311585
- 1.4680165672302246
- 1.3930246257781982
- 1.5438650894165038
- 1.4167820024490356
- 1.544794442653656
- 1.4124257254600525
- 1.3767209100723266
- 1.354220094680786
- 1.3553447008132935
- 1.3489608788490295
- 1.4092075443267822
- 1.3714447331428528
- 1.4281071329116821
- 1.383217008113861
- 1.3590949869155884
- 1.4126334023475646
- 1.4295569920539857
- 1.3772148275375367
- 1.345244882106781
- 1.4118437695503234
- 1.3595016598701477
- 1.3025172019004823
- 1.3819499373435975
- 1.3493832540512085
- 1.4928983449935913
- 1.4471683192253113
- 1.46242023229599
- 1.4757494592666627
- 1.4877686214447021
- 1.4456885385513305
- 1.3048125720024109
- 1.3929449105262757
- 1.3268597793579102
- 1.473905749320984
- 1.3540344548225403
- 1.3455548191070557
- 1.380964801311493
- 1.3965191006660462
- 1.4023941445350647
- 1.4997850918769837
- 1.371860704421997
- 1.2886669421195984
- 1.360823781490326
- 1.3262425994873046
- 1.3131372261047363
- 1.3759478497505189
- 1.4043710684776307
- 1.392809934616089
- 1.4018505883216859
- 1.3397009754180909
- 1.3868891978263855
- 1.3415757131576538
- 1.3115732312202453
- 1.4582741975784301
- 1.4064890694618226
- 1.320594003200531
- 1.2788739490509033
- 1.4359673142433167
- 1.3257655167579652
- 1.3283249950408935
- 1.454294912815094
- 1.3354414653778077
- 1.3106665349006652
- 1.3793633317947387
- 1.3112789607048034
- 1.310820119380951
- 1.3101512360572816
- 1.3132442712783814
- 1.3563008642196654
- 1.379667992591858
- 1.3997789692878724
- 1.2963909721374511
- 1.366128911972046
train_accuracy:
- 0.0
- 0.104
- 0.0
- 0.15
- 0.204
- 0.221
- 0.173
- 0.181
- 0.0
- 0.244
- 0.0
- 0.264
- 0.0
- 0.0
- 0.28
- 0.236
- 0.304
- 0.237
- 0.235
- 0.262
- 0.0
- 0.0
- 0.0
- 0.336
- 0.0
- 0.287
- 0.0
- 0.315
- 0.326
- 0.352
- 0.303
- 0.282
- 0.0
- 0.345
- 0.341
- 0.0
- 0.0
- 0.337
- 0.326
- 0.308
- 0.295
- 0.33
- 0.362
- 0.35
- 0.0
- 0.357
- 0.357
- 0.315
- 0.0
- 0.304
- 0.0
- 0.304
- 0.367
- 0.381
- 0.328
- 0.376
- 0.379
- 0.0
- 0.303
- 0.391
- 0.31
- 0.388
- 0.367
- 0.0
- 0.333
- 0.0
- 0.416
- 0.371
- 0.304
- 0.324
- 0.316
- 0.0
- 0.392
- 0.394
- 0.0
- 0.334
- 0.377
- 0.389
- 0.388
- 0.0
- 0.388
- 0.327
- 0.392
- 0.333
- 0.383
- 0.39
- 0.385
- 0.35
- 0.0
- 0.0
- 0.0
- 0.348
- 0.325
- 0.397
- 0.389
- 0.393
- 0.358
- 0.346
- 0.0
- 0.388
train_loss:
- 3.135
- 2.799
- 2.994
- 2.783
- 2.466
- 2.674
- 2.628
- 2.41
- 2.098
- 2.123
- 2.014
- 2.17
- 2.239
- 1.894
- 1.842
- 1.771
- 1.962
- 1.657
- 1.901
- 1.659
- 1.568
- 1.825
- 1.676
- 1.491
- 1.307
- 1.65
- 1.41
- 1.574
- 1.36
- 1.659
- 1.283
- 1.587
- 1.285
- 1.2
- 1.191
- 1.126
- 1.157
- 1.272
- 1.06
- 1.22
- 1.053
- 1.022
- 1.147
- 1.126
- 0.971
- 0.898
- 1.047
- 0.886
- 0.765
- 1.022
- 0.839
- 1.034
- 0.868
- 0.855
- 0.783
- 0.889
- 0.849
- 0.642
- 0.763
- 0.7
- 0.893
- 0.731
- 0.645
- 0.771
- 0.709
- 0.705
- 0.785
- 0.599
- 0.547
- 0.63
- 0.552
- 0.533
- 0.655
- 0.585
- 0.578
- 0.536
- 0.522
- 0.577
- 0.487
- 0.475
- 0.578
- 0.493
- 0.466
- 0.389
- 0.528
- 0.418
- 0.422
- 0.454
- 0.405
- 0.372
- 0.419
- 0.409
- 0.392
- 0.384
- 0.375
- 0.407
- 0.356
- 0.356
- 0.315
- 0.382
unequal: 0
verbose: 1
