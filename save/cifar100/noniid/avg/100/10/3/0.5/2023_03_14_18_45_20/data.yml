avg_train_accuracy: 0.386
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0323
- 0.0935
- 0.117
- 0.1306
- 0.1386
- 0.148
- 0.1557
- 0.1586
- 0.1698
- 0.1773
- 0.1916
- 0.181
- 0.1859
- 0.1953
- 0.1932
- 0.1994
- 0.2055
- 0.2191
- 0.2146
- 0.2205
- 0.2178
- 0.2189
- 0.2212
- 0.226
- 0.2298
- 0.2368
- 0.2435
- 0.2369
- 0.242
- 0.2428
- 0.2532
- 0.2448
- 0.2397
- 0.2526
- 0.2447
- 0.2468
- 0.2551
- 0.2519
- 0.2668
- 0.2615
- 0.2669
- 0.2544
- 0.261
- 0.2584
- 0.2605
- 0.2565
- 0.2613
- 0.2742
- 0.2672
- 0.2757
- 0.2658
- 0.2652
- 0.2696
- 0.2848
- 0.2691
- 0.287
- 0.2841
- 0.2852
- 0.2895
- 0.292
- 0.2881
- 0.2963
- 0.2772
- 0.2909
- 0.289
- 0.2731
- 0.2811
- 0.2767
- 0.2914
- 0.2946
- 0.2929
- 0.297
- 0.2835
- 0.2837
- 0.2867
- 0.2934
- 0.2898
- 0.305
- 0.2838
- 0.3008
- 0.3009
- 0.2995
- 0.3047
- 0.2813
- 0.3
- 0.3018
- 0.2944
- 0.2875
- 0.2843
- 0.3034
- 0.2893
- 0.3032
- 0.2873
- 0.3007
- 0.3048
- 0.2989
- 0.2959
- 0.3033
- 0.3057
- 0.3139
test_loss_list:
- 1.8373141860961915
- 1.7798284053802491
- 1.7704781770706177
- 1.740248384475708
- 1.7271899461746216
- 1.6211162877082825
- 1.5925271797180176
- 1.6359837675094604
- 1.6192077994346619
- 1.5539933586120604
- 1.4872919344902038
- 1.5482291603088378
- 1.5665814828872682
- 1.5171720027923583
- 1.4811988806724548
- 1.5327214074134827
- 1.485124523639679
- 1.4740197086334228
- 1.4393978524208069
- 1.4376865553855895
- 1.5002232122421264
- 1.5297348833084106
- 1.5108785486221314
- 1.4479879331588745
- 1.4957931971549987
- 1.427062382698059
- 1.4087143707275391
- 1.4654325151443481
- 1.3879980111122132
- 1.3753873229026794
- 1.3616978526115417
- 1.4355075073242187
- 1.4531132197380066
- 1.384263882637024
- 1.5241256618499757
- 1.4816533374786376
- 1.4838958168029786
- 1.4639036059379578
- 1.3909095001220704
- 1.3574478268623351
- 1.3358141899108886
- 1.4864071965217591
- 1.4468730902671814
- 1.4417006158828736
- 1.4435895824432372
- 1.4359425234794616
- 1.4278527045249938
- 1.3632773685455322
- 1.4146765995025634
- 1.3372707200050353
- 1.3956816840171813
- 1.5014804434776305
- 1.439192795753479
- 1.3034231781959533
- 1.38166335105896
- 1.3158023071289062
- 1.311082932949066
- 1.312789363861084
- 1.3260204529762267
- 1.3069592261314391
- 1.301917450428009
- 1.3032400298118592
- 1.3630458617210388
- 1.3109324264526367
- 1.308155219554901
- 1.4595515418052674
- 1.414345815181732
- 1.4018078231811524
- 1.317428777217865
- 1.3029989433288574
- 1.2994795560836792
- 1.2964441347122193
- 1.3542619299888612
- 1.3733461594581604
- 1.3867225170135498
- 1.3320775437355041
- 1.3889476561546326
- 1.2850316500663757
- 1.3574715065956116
- 1.3173660778999328
- 1.3247648453712464
- 1.3372682690620423
- 1.3005638146400451
- 1.441290900707245
- 1.322334361076355
- 1.3055791234970093
- 1.3664501690864563
- 1.371127688884735
- 1.3727577257156371
- 1.3035305309295655
- 1.3521145057678223
- 1.3034403443336486
- 1.3527932000160217
- 1.3109818887710571
- 1.314635283946991
- 1.3652470779418946
- 1.3924062442779541
- 1.3387980937957764
- 1.3057681012153626
- 1.3001754212379455
train_accuracy:
- 0.035
- 0.107
- 0.112
- 0.161
- 0.0
- 0.0
- 0.208
- 0.201
- 0.179
- 0.0
- 0.185
- 0.0
- 0.228
- 0.0
- 0.0
- 0.249
- 0.252
- 0.263
- 0.272
- 0.278
- 0.273
- 0.276
- 0.273
- 0.0
- 0.288
- 0.293
- 0.3
- 0.288
- 0.0
- 0.315
- 0.0
- 0.288
- 0.299
- 0.0
- 0.332
- 0.322
- 0.331
- 0.305
- 0.0
- 0.288
- 0.0
- 0.334
- 0.338
- 0.321
- 0.335
- 0.297
- 0.33
- 0.299
- 0.338
- 0.318
- 0.348
- 0.334
- 0.0
- 0.0
- 0.313
- 0.36
- 0.36
- 0.349
- 0.344
- 0.0
- 0.34
- 0.36
- 0.0
- 0.0
- 0.0
- 0.373
- 0.367
- 0.366
- 0.0
- 0.0
- 0.328
- 0.302
- 0.332
- 0.368
- 0.356
- 0.0
- 0.349
- 0.0
- 0.368
- 0.32
- 0.0
- 0.0
- 0.325
- 0.358
- 0.356
- 0.0
- 0.327
- 0.348
- 0.354
- 0.0
- 0.369
- 0.369
- 0.37
- 0.0
- 0.0
- 0.379
- 0.372
- 0.359
- 0.0
- 0.386
train_loss:
- 3.166
- 3.254
- 2.976
- 2.853
- 2.742
- 2.319
- 2.287
- 2.46
- 2.354
- 1.974
- 1.768
- 2.263
- 2.111
- 1.828
- 1.797
- 2.103
- 1.774
- 1.726
- 1.64
- 1.624
- 1.804
- 1.701
- 1.66
- 1.46
- 1.569
- 1.421
- 1.314
- 1.524
- 1.348
- 1.314
- 1.253
- 1.38
- 1.352
- 1.186
- 1.492
- 1.221
- 1.206
- 1.275
- 1.085
- 1.066
- 1.022
- 1.21
- 1.086
- 1.079
- 1.031
- 1.014
- 0.982
- 0.902
- 0.967
- 0.797
- 0.911
- 0.921
- 0.882
- 0.68
- 0.893
- 0.726
- 0.781
- 0.726
- 0.641
- 0.686
- 0.676
- 0.614
- 0.728
- 0.629
- 0.633
- 0.759
- 0.689
- 0.66
- 0.579
- 0.51
- 0.596
- 0.523
- 0.651
- 0.589
- 0.521
- 0.544
- 0.521
- 0.451
- 0.552
- 0.45
- 0.417
- 0.436
- 0.464
- 0.518
- 0.437
- 0.423
- 0.433
- 0.463
- 0.433
- 0.391
- 0.404
- 0.356
- 0.398
- 0.369
- 0.388
- 0.365
- 0.383
- 0.355
- 0.328
- 0.321
unequal: 0
verbose: 1
