avg_train_accuracy: 0.371
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0446
- 0.0903
- 0.11
- 0.1215
- 0.1314
- 0.1443
- 0.1503
- 0.1613
- 0.1638
- 0.1694
- 0.1764
- 0.1785
- 0.185
- 0.1918
- 0.1938
- 0.2001
- 0.2022
- 0.2041
- 0.2126
- 0.2079
- 0.212
- 0.2128
- 0.2182
- 0.2159
- 0.2214
- 0.2218
- 0.2222
- 0.2303
- 0.2323
- 0.2496
- 0.2459
- 0.2317
- 0.2423
- 0.2492
- 0.2393
- 0.2415
- 0.239
- 0.2432
- 0.2579
- 0.2479
- 0.2448
- 0.2563
- 0.2509
- 0.2622
- 0.274
- 0.2575
- 0.2571
- 0.2673
- 0.2625
- 0.2827
- 0.2616
- 0.2628
- 0.272
- 0.2645
- 0.2574
- 0.2573
- 0.2582
- 0.2694
- 0.2744
- 0.2764
- 0.2651
- 0.2653
- 0.2783
- 0.2816
- 0.2712
- 0.276
- 0.2812
- 0.2842
- 0.2817
- 0.2895
- 0.2879
- 0.2714
- 0.3007
- 0.2867
- 0.2767
- 0.2778
- 0.2922
- 0.2811
- 0.2818
- 0.2744
- 0.3038
- 0.2946
- 0.2867
- 0.2931
- 0.2846
- 0.2902
- 0.2878
- 0.2962
- 0.3099
- 0.2908
- 0.2977
- 0.3005
- 0.3022
- 0.3006
- 0.3137
- 0.2869
- 0.2967
- 0.2895
- 0.2988
- 0.2847
test_loss_list:
- 1.843526849746704
- 1.779855852127075
- 1.758858790397644
- 1.7372640514373778
- 1.6006962609291078
- 1.5757588744163513
- 1.6121737194061279
- 1.5173231196403503
- 1.5816721248626708
- 1.5187998867034913
- 1.5053067779541016
- 1.5656701493263245
- 1.654996883869171
- 1.695786554813385
- 1.6397814750671387
- 1.7000767946243287
- 1.7284657526016236
- 1.657677869796753
- 1.5476678371429444
- 1.4635022926330565
- 1.50212012052536
- 1.5218448972702026
- 1.5362707138061524
- 1.527982497215271
- 1.4451038527488709
- 1.4784487390518188
- 1.5796465921401976
- 1.4478629636764526
- 1.4059058403968812
- 1.3490455198287963
- 1.3676804041862487
- 1.4417800641059875
- 1.4015989542007445
- 1.3696239924430846
- 1.4301814866065978
- 1.4499847412109375
- 1.4516479682922363
- 1.4706786108016967
- 1.3412749934196473
- 1.4147725796699524
- 1.4410669636726379
- 1.3602855539321899
- 1.430221426486969
- 1.373244912624359
- 1.3114971256256103
- 1.3936252188682556
- 1.4322399616241455
- 1.3734509468078613
- 1.3413455557823182
- 1.3010700583457946
- 1.3846991348266602
- 1.4058585143089295
- 1.3461862349510192
- 1.4120767140388488
- 1.4168761086463928
- 1.5183099842071532
- 1.451824083328247
- 1.3514722537994386
- 1.335378704071045
- 1.3471731305122376
- 1.4023570346832275
- 1.4039005494117738
- 1.335026741027832
- 1.323936243057251
- 1.3899036240577698
- 1.415538763999939
- 1.35884503364563
- 1.3341306066513061
- 1.3101768493652344
- 1.310646722316742
- 1.3236198139190674
- 1.3713991904258729
- 1.2841432309150695
- 1.3128371477127074
- 1.3736291933059692
- 1.3854314064979554
- 1.3327977824211121
- 1.3934234309196472
- 1.417118058204651
- 1.4128865098953247
- 1.2882590436935424
- 1.3172972202301025
- 1.3825608348846437
- 1.3124903845787048
- 1.371895661354065
- 1.3133500623703003
- 1.3679602909088135
- 1.3223915481567383
- 1.2853353023529053
- 1.3620543766021729
- 1.3207235598564149
- 1.3124003720283508
- 1.3081328868865967
- 1.3064370036125184
- 1.2834929394721986
- 1.3515386247634888
- 1.322931191921234
- 1.379507384300232
- 1.3247115731239318
- 1.376163592338562
train_accuracy:
- 0.06
- 0.0
- 0.133
- 0.103
- 0.178
- 0.0
- 0.0
- 0.136
- 0.225
- 0.0
- 0.0
- 0.0
- 0.251
- 0.243
- 0.264
- 0.288
- 0.249
- 0.26
- 0.0
- 0.289
- 0.29
- 0.262
- 0.262
- 0.313
- 0.282
- 0.315
- 0.318
- 0.303
- 0.0
- 0.0
- 0.275
- 0.319
- 0.322
- 0.288
- 0.0
- 0.299
- 0.336
- 0.0
- 0.278
- 0.345
- 0.333
- 0.303
- 0.233
- 0.286
- 0.24
- 0.0
- 0.0
- 0.299
- 0.331
- 0.0
- 0.325
- 0.312
- 0.338
- 0.321
- 0.346
- 0.322
- 0.342
- 0.355
- 0.0
- 0.354
- 0.0
- 0.381
- 0.0
- 0.0
- 0.35
- 0.317
- 0.371
- 0.0
- 0.0
- 0.0
- 0.303
- 0.384
- 0.358
- 0.351
- 0.378
- 0.385
- 0.0
- 0.319
- 0.287
- 0.409
- 0.0
- 0.376
- 0.274
- 0.337
- 0.332
- 0.277
- 0.335
- 0.352
- 0.259
- 0.346
- 0.354
- 0.277
- 0.35
- 0.344
- 0.0
- 0.371
- 0.0
- 0.28
- 0.0
- 0.371
train_loss:
- 3.606
- 3.213
- 2.965
- 2.813
- 2.158
- 2.319
- 2.512
- 1.896
- 2.407
- 2.101
- 2.049
- 2.232
- 2.386
- 2.265
- 2.02
- 2.165
- 2.048
- 1.931
- 1.695
- 1.621
- 1.711
- 1.627
- 1.583
- 1.6
- 1.441
- 1.48
- 1.595
- 1.368
- 1.314
- 1.174
- 1.265
- 1.509
- 1.205
- 1.183
- 1.278
- 1.181
- 1.338
- 1.177
- 0.926
- 1.221
- 1.195
- 0.965
- 1.114
- 0.969
- 0.903
- 0.979
- 0.989
- 0.914
- 0.971
- 0.73
- 0.937
- 0.904
- 0.782
- 0.831
- 0.887
- 0.913
- 0.847
- 0.747
- 0.731
- 0.696
- 0.821
- 0.761
- 0.621
- 0.651
- 0.657
- 0.661
- 0.594
- 0.604
- 0.649
- 0.544
- 0.527
- 0.605
- 0.481
- 0.536
- 0.604
- 0.531
- 0.523
- 0.505
- 0.518
- 0.532
- 0.47
- 0.424
- 0.513
- 0.488
- 0.443
- 0.461
- 0.44
- 0.383
- 0.376
- 0.424
- 0.383
- 0.381
- 0.414
- 0.364
- 0.344
- 0.4
- 0.351
- 0.342
- 0.368
- 0.357
unequal: 0
verbose: 1
