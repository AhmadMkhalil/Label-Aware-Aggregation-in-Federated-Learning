avg_train_accuracy: 0.409
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0395
- 0.0908
- 0.1078
- 0.1185
- 0.1322
- 0.1412
- 0.1496
- 0.1586
- 0.1667
- 0.1719
- 0.1795
- 0.1855
- 0.1915
- 0.1957
- 0.1974
- 0.2041
- 0.2128
- 0.217
- 0.2186
- 0.2131
- 0.2134
- 0.2135
- 0.2212
- 0.2213
- 0.228
- 0.239
- 0.2421
- 0.2397
- 0.2379
- 0.2306
- 0.2337
- 0.2331
- 0.2516
- 0.2339
- 0.2513
- 0.2519
- 0.2443
- 0.2401
- 0.2559
- 0.2616
- 0.2825
- 0.2798
- 0.2723
- 0.2678
- 0.2589
- 0.2603
- 0.2547
- 0.2671
- 0.2602
- 0.2727
- 0.2699
- 0.2901
- 0.2641
- 0.275
- 0.2653
- 0.2735
- 0.2621
- 0.2635
- 0.2757
- 0.2836
- 0.2711
- 0.2652
- 0.2984
- 0.2608
- 0.2779
- 0.278
- 0.2884
- 0.2848
- 0.2747
- 0.2708
- 0.2755
- 0.2729
- 0.2879
- 0.294
- 0.2947
- 0.2799
- 0.2909
- 0.2965
- 0.2847
- 0.2916
- 0.3077
- 0.2712
- 0.2802
- 0.2939
- 0.2867
- 0.2827
- 0.2856
- 0.2975
- 0.2831
- 0.283
- 0.2918
- 0.2819
- 0.297
- 0.2887
- 0.2854
- 0.2842
- 0.2861
- 0.2869
- 0.2936
- 0.2755
test_loss_list:
- 1.8335815238952637
- 1.7296743488311768
- 1.670788447856903
- 1.679492745399475
- 1.6245960187911987
- 1.6347035074234009
- 1.6374150371551515
- 1.6285846471786498
- 1.7055781722068786
- 1.5821718859672547
- 1.58107417345047
- 1.5119905591011047
- 1.5560989999771118
- 1.5790302848815918
- 1.5654850602149963
- 1.4762119483947753
- 1.4506017613410949
- 1.4340632152557373
- 1.4299989748001098
- 1.4210165977478026
- 1.474777262210846
- 1.578773856163025
- 1.4463466572761536
- 1.4922147870063782
- 1.4385143756866454
- 1.4267697072029113
- 1.4297123861312866
- 1.387341685295105
- 1.3720341658592223
- 1.4326110291481018
- 1.4662973713874816
- 1.4564292788505555
- 1.396818881034851
- 1.4325044250488281
- 1.363540632724762
- 1.3489800429344176
- 1.4068085837364197
- 1.4243073964118957
- 1.3678269362449647
- 1.3380582380294799
- 1.2978826355934143
- 1.3023820304870606
- 1.3189770436286927
- 1.3204484534263612
- 1.3928035163879395
- 1.4174203014373778
- 1.4188239431381227
- 1.3379127168655396
- 1.3892526960372924
- 1.3422812366485595
- 1.3150005984306334
- 1.280467598438263
- 1.370785689353943
- 1.3239994144439697
- 1.3905673933029175
- 1.3334108519554138
- 1.3810949444770813
- 1.3845161485671997
- 1.3118300104141236
- 1.3167795062065124
- 1.3789722394943238
- 1.3827056288719177
- 1.2715840220451355
- 1.4526295232772828
- 1.3278171610832215
- 1.3790554523468017
- 1.33444082736969
- 1.3074646401405334
- 1.365800540447235
- 1.380395827293396
- 1.3921574473381042
- 1.38874014377594
- 1.3120181202888488
- 1.3101791763305664
- 1.2918647980690003
- 1.3620615935325622
- 1.3185641002655029
- 1.3205053901672363
- 1.38255117893219
- 1.31745445728302
- 1.2706167101860046
- 1.4327125096321105
- 1.3823768234252929
- 1.3246149325370788
- 1.3810098695755004
- 1.402467896938324
- 1.4212663769721985
- 1.3513006019592284
- 1.3950578093528747
- 1.4170423007011415
- 1.3160175967216492
- 1.3601151967048646
- 1.3105607676506041
- 1.3699626016616822
- 1.3953502583503723
- 1.4130875539779664
- 1.42613511800766
- 1.4316947555541992
- 1.3133712768554688
- 1.453883261680603
train_accuracy:
- 0.0
- 0.122
- 0.0
- 0.174
- 0.0
- 0.0
- 0.247
- 0.231
- 0.214
- 0.257
- 0.261
- 0.281
- 0.284
- 0.268
- 0.0
- 0.308
- 0.263
- 0.287
- 0.301
- 0.0
- 0.291
- 0.27
- 0.0
- 0.33
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.285
- 0.0
- 0.0
- 0.0
- 0.361
- 0.0
- 0.293
- 0.337
- 0.0
- 0.314
- 0.0
- 0.337
- 0.281
- 0.345
- 0.0
- 0.36
- 0.0
- 0.36
- 0.398
- 0.352
- 0.0
- 0.0
- 0.0
- 0.394
- 0.385
- 0.382
- 0.334
- 0.353
- 0.395
- 0.383
- 0.0
- 0.374
- 0.366
- 0.372
- 0.37
- 0.37
- 0.0
- 0.0
- 0.0
- 0.367
- 0.397
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.38
- 0.0
- 0.369
- 0.38
- 0.377
- 0.349
- 0.414
- 0.0
- 0.372
- 0.39
- 0.412
- 0.373
- 0.0
- 0.405
- 0.372
- 0.0
- 0.415
- 0.4
- 0.0
- 0.416
- 0.383
- 0.396
- 0.383
- 0.0
- 0.409
train_loss:
- 3.122
- 2.79
- 2.649
- 2.861
- 2.428
- 2.621
- 2.56
- 2.426
- 2.626
- 1.994
- 2.346
- 1.987
- 2.088
- 2.0
- 2.094
- 1.797
- 1.704
- 1.685
- 1.597
- 1.618
- 1.701
- 1.933
- 1.547
- 1.657
- 1.458
- 1.474
- 1.403
- 1.343
- 1.318
- 1.462
- 1.465
- 1.392
- 1.201
- 1.385
- 1.205
- 1.174
- 1.275
- 1.267
- 1.102
- 1.074
- 0.862
- 0.858
- 0.966
- 1.028
- 1.08
- 1.057
- 1.054
- 0.942
- 0.992
- 0.871
- 0.869
- 0.699
- 0.909
- 0.768
- 0.887
- 0.745
- 0.898
- 0.853
- 0.697
- 0.64
- 0.766
- 0.834
- 0.611
- 0.819
- 0.646
- 0.668
- 0.642
- 0.587
- 0.619
- 0.679
- 0.649
- 0.652
- 0.58
- 0.524
- 0.519
- 0.563
- 0.485
- 0.46
- 0.565
- 0.482
- 0.41
- 0.592
- 0.515
- 0.444
- 0.462
- 0.473
- 0.429
- 0.388
- 0.448
- 0.382
- 0.427
- 0.402
- 0.407
- 0.396
- 0.392
- 0.4
- 0.372
- 0.375
- 0.382
- 0.373
unequal: 0
verbose: 1
