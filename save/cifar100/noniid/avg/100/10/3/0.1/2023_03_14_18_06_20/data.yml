avg_train_accuracy: 0.398
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0419
- 0.0906
- 0.1101
- 0.0459
- 0.0414
- 0.1234
- 0.0486
- 0.133
- 0.1456
- 0.1538
- 0.1527
- 0.1622
- 0.0449
- 0.1653
- 0.1724
- 0.1701
- 0.1774
- 0.1749
- 0.0549
- 0.173
- 0.1744
- 0.1826
- 0.0566
- 0.186
- 0.0493
- 0.1846
- 0.1865
- 0.1898
- 0.1978
- 0.2017
- 0.2059
- 0.2076
- 0.2077
- 0.2077
- 0.2143
- 0.0519
- 0.2138
- 0.2147
- 0.2085
- 0.2256
- 0.2174
- 0.2199
- 0.0527
- 0.2164
- 0.0556
- 0.2245
- 0.0606
- 0.2285
- 0.2313
- 0.2307
- 0.2338
- 0.2312
- 0.2383
- 0.2404
- 0.0644
- 0.0587
- 0.0616
- 0.2464
- 0.0689
- 0.2438
- 0.2369
- 0.2471
- 0.2484
- 0.2462
- 0.0701
- 0.2494
- 0.0649
- 0.2499
- 0.2485
- 0.2529
- 0.0729
- 0.2555
- 0.2551
- 0.0775
- 0.2536
- 0.2572
- 0.2456
- 0.0756
- 0.2521
- 0.2535
- 0.2503
- 0.2556
- 0.2556
- 0.2562
- 0.0779
- 0.0696
- 0.2638
- 0.0848
- 0.2602
- 0.2571
- 0.2576
- 0.2538
- 0.2597
- 0.2618
- 0.074
- 0.2642
- 0.2646
- 0.2619
- 0.2663
test_loss_list:
- 1.888272032737732
- 3.2882988977432253
- 1.8721395111083985
- 1.8906045722961426
- 3.3182649993896485
- 3.178666296005249
- 1.7663394236564636
- 3.1924571418762206
- 1.7881867146492005
- 1.8335580253601074
- 1.839708514213562
- 1.8606397819519043
- 1.8679270887374877
- 3.162677264213562
- 1.782906174659729
- 1.8068378829956055
- 1.8435849142074585
- 1.858062686920166
- 1.885451283454895
- 3.131130256652832
- 1.7984104681015014
- 1.836591284275055
- 1.839424500465393
- 3.115045704841614
- 1.811760094165802
- 3.105382885932922
- 1.7420826292037963
- 1.7929235219955444
- 1.8067745876312256
- 1.8246616864204406
- 1.814243037700653
- 1.8308577609062195
- 1.8477615904808045
- 1.8577119135856628
- 1.862208309173584
- 1.8659769916534423
- 3.217647066116333
- 1.7024515104293823
- 1.7341207361221314
- 1.7836517691612244
- 1.7555651044845582
- 1.8003476977348327
- 1.8193190956115723
- 3.1753481101989744
- 1.7289964747428894
- 2.918592691421509
- 1.6201634740829467
- 2.980708432197571
- 1.6238904404640198
- 1.6646382856369017
- 1.6985073757171631
- 1.7109799194335937
- 1.7456014561653137
- 1.763151104450226
- 1.755970516204834
- 2.9949541807174684
- 2.9201483154296874
- 2.9635530805587766
- 1.5833957529067992
- 2.778440623283386
- 1.6099531364440918
- 1.6616685438156127
- 1.6697516345977783
- 1.6955117917060851
- 1.7265837430953979
- 2.8212624692916872
- 1.6369412684440612
- 2.7694837999343873
- 1.5299596166610718
- 1.5706784081459046
- 1.6008135843276978
- 2.688340063095093
- 1.5480126333236695
- 1.5698643851280212
- 2.7128786659240722
- 1.5625403094291688
- 1.5967996168136596
- 1.6496639466285705
- 2.782249550819397
- 1.5755610299110412
- 1.5932860684394836
- 1.6154633975028991
- 1.6452084255218506
- 1.6635094118118285
- 1.6781933760643006
- 2.812236180305481
- 3.011849365234375
- 1.6026870942115783
- 2.7430986309051515
- 1.6108876991271972
- 1.6448867297172547
- 1.682925555706024
- 1.692323567867279
- 1.676286895275116
- 1.7082104063034058
- 2.8020457887649535
- 1.5678125596046448
- 1.6135312294960023
- 1.6474470376968384
- 1.6346090412139893
train_accuracy:
- 0.067
- 0.0
- 0.106
- 0.156
- 0.0
- 0.0
- 0.194
- 0.0
- 0.19
- 0.189
- 0.229
- 0.202
- 0.237
- 0.0
- 0.206
- 0.229
- 0.229
- 0.197
- 0.231
- 0.0
- 0.244
- 0.227
- 0.226
- 0.0
- 0.24
- 0.0
- 0.212
- 0.26
- 0.227
- 0.255
- 0.251
- 0.291
- 0.296
- 0.307
- 0.322
- 0.307
- 0.0
- 0.31
- 0.327
- 0.32
- 0.261
- 0.253
- 0.321
- 0.0
- 0.314
- 0.0
- 0.299
- 0.0
- 0.327
- 0.347
- 0.334
- 0.321
- 0.326
- 0.33
- 0.339
- 0.0
- 0.0
- 0.0
- 0.309
- 0.0
- 0.333
- 0.357
- 0.347
- 0.328
- 0.35
- 0.0
- 0.374
- 0.0
- 0.365
- 0.339
- 0.346
- 0.0
- 0.367
- 0.378
- 0.0
- 0.354
- 0.34
- 0.338
- 0.0
- 0.373
- 0.36
- 0.338
- 0.332
- 0.395
- 0.324
- 0.0
- 0.0
- 0.349
- 0.0
- 0.378
- 0.368
- 0.367
- 0.373
- 0.379
- 0.364
- 0.0
- 0.378
- 0.347
- 0.384
- 0.398
train_loss:
- 4.063
- 1.827
- 3.831
- 3.22
- 1.479
- 2.061
- 3.386
- 1.203
- 3.324
- 2.844
- 2.9
- 2.549
- 2.537
- 1.538
- 3.036
- 2.578
- 2.096
- 2.366
- 1.883
- 1.288
- 1.884
- 1.395
- 2.141
- 0.98
- 2.04
- 1.332
- 1.776
- 1.421
- 1.331
- 2.053
- 2.155
- 1.281
- 2.179
- 1.71
- 2.019
- 1.807
- 1.936
- 1.976
- 1.274
- 1.019
- 1.486
- 1.016
- 1.078
- 1.272
- 1.058
- 1.213
- 1.766
- 0.982
- 1.807
- 1.763
- 1.202
- 1.74
- 1.256
- 1.243
- 1.046
- 1.005
- 1.151
- 0.71
- 1.441
- 0.584
- 1.186
- 1.441
- 1.141
- 1.042
- 1.233
- 0.806
- 1.001
- 1.137
- 1.171
- 0.932
- 0.905
- 0.734
- 1.352
- 0.757
- 0.499
- 0.717
- 0.819
- 0.514
- 0.805
- 0.714
- 0.741
- 1.019
- 0.914
- 1.002
- 0.661
- 0.676
- 0.236
- 1.062
- 0.403
- 0.95
- 0.604
- 0.634
- 0.582
- 0.588
- 0.408
- 0.851
- 0.803
- 0.614
- 0.452
- 0.413
unequal: 0
verbose: 1
