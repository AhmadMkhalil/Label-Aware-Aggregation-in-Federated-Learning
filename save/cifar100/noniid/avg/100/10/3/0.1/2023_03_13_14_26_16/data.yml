avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0423
- 0.0898
- 0.1059
- 0.0343
- 0.1223
- 0.1227
- 0.1398
- 0.0395
- 0.1462
- 0.1506
- 0.0444
- 0.1486
- 0.0485
- 0.0488
- 0.0435
- 0.1642
- 0.1693
- 0.044
- 0.0464
- 0.0492
- 0.05
- 0.0495
- 0.1736
- 0.1753
- 0.0492
- 0.18
- 0.1932
- 0.1903
- 0.1942
- 0.2069
- 0.2083
- 0.2045
- 0.0527
- 0.2098
- 0.209
- 0.2167
- 0.2064
- 0.2179
- 0.2239
- 0.2197
- 0.0558
- 0.053
- 0.2183
- 0.2128
- 0.0603
- 0.2179
- 0.2191
- 0.2247
- 0.2245
- 0.214
- 0.2333
- 0.0602
- 0.2361
- 0.0653
- 0.0607
- 0.0558
- 0.2434
- 0.0726
- 0.2406
- 0.0626
- 0.2488
- 0.0649
- 0.2533
- 0.0664
- 0.0636
- 0.2519
- 0.2491
- 0.0747
- 0.2504
- 0.0712
- 0.2482
- 0.236
- 0.2499
- 0.2597
- 0.2504
- 0.2552
- 0.2573
- 0.2555
- 0.2487
- 0.2542
- 0.2635
- 0.2528
- 0.2587
- 0.2519
- 0.2594
- 0.2554
- 0.2578
- 0.2603
- 0.2637
- 0.263
- 0.2642
- 0.093
- 0.073
- 0.2568
- 0.0922
- 0.2626
- 0.265
- 0.2704
- 0.2593
- 0.1024
test_loss_list:
- 1.9076072359085083
- 1.9322262954711915
- 1.9554262495040893
- 3.3062123441696167
- 1.870067172050476
- 1.931630620956421
- 1.9146483659744262
- 3.291583137512207
- 1.8260381841659545
- 1.8607261419296264
- 3.160617890357971
- 1.8235229825973511
- 3.166938533782959
- 3.3945351457595825
- 3.6397169971466066
- 1.7990593647956847
- 1.8362394666671753
- 3.2026264667510986
- 3.100661344528198
- 3.189490027427673
- 3.0248633813858032
- 3.2037046194076537
- 1.5952539443969727
- 1.6773728919029236
- 3.0334688234329223
- 1.6630308294296265
- 1.692596161365509
- 1.7310472512245179
- 1.744521782398224
- 1.7565763950347901
- 1.7733632969856261
- 1.7938181686401367
- 3.0684554052352904
- 1.6984037208557128
- 1.7566816186904908
- 1.76120450258255
- 1.80193217754364
- 1.7958480501174927
- 1.797477626800537
- 1.8390923595428468
- 3.0221858406066895
- 2.9976051330566404
- 1.6223167514801025
- 1.6872690081596375
- 2.8326675510406494
- 1.5987360978126526
- 1.6498959851264954
- 1.6764771223068238
- 1.6891071486473084
- 1.7398797535896302
- 1.728173484802246
- 2.9395679664611816
- 1.6197923183441163
- 2.8065029859542845
- 2.977526831626892
- 2.7903318214416504
- 1.492727406024933
- 2.7011156606674196
- 1.5523002529144287
- 2.8257427978515626
- 1.5185083913803101
- 2.7893000936508177
- 1.5291647338867187
- 2.6439797067642212
- 2.7892887783050537
- 1.494387240409851
- 1.5479806184768676
- 2.6687095499038698
- 1.513993146419525
- 2.6163879823684693
- 1.502748384475708
- 1.5965680718421935
- 1.581453764438629
- 1.606666178703308
- 1.641777663230896
- 1.633459358215332
- 1.6720388507843018
- 1.680856900215149
- 1.683926773071289
- 1.7154758477210998
- 1.7006275272369384
- 1.7253594875335694
- 1.7319228887557983
- 1.747508339881897
- 1.7565178275108337
- 1.7729120707511903
- 1.779187421798706
- 1.7824780416488648
- 1.77757737159729
- 1.8093957614898681
- 1.795194182395935
- 2.688587574958801
- 2.6614694499969485
- 1.5646975183486937
- 2.5926445055007936
- 1.5679007530212403
- 1.5988973903656005
- 1.6338738584518433
- 1.6631384158134461
- 2.6061664056777953
train_accuracy:
- 0.044
- 0.132
- 0.122
- 0.0
- 0.176
- 0.187
- 0.191
- 0.0
- 0.2
- 0.217
- 0.0
- 0.183
- 0.0
- 0.0
- 0.0
- 0.233
- 0.258
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.223
- 0.232
- 0.0
- 0.253
- 0.267
- 0.281
- 0.243
- 0.32
- 0.296
- 0.266
- 0.0
- 0.293
- 0.276
- 0.304
- 0.284
- 0.303
- 0.294
- 0.332
- 0.0
- 0.0
- 0.309
- 0.327
- 0.0
- 0.317
- 0.318
- 0.315
- 0.307
- 0.295
- 0.282
- 0.0
- 0.353
- 0.0
- 0.0
- 0.0
- 0.313
- 0.0
- 0.322
- 0.0
- 0.333
- 0.0
- 0.322
- 0.0
- 0.0
- 0.358
- 0.329
- 0.0
- 0.339
- 0.0
- 0.325
- 0.303
- 0.397
- 0.327
- 0.382
- 0.333
- 0.358
- 0.388
- 0.314
- 0.344
- 0.375
- 0.385
- 0.32
- 0.378
- 0.339
- 0.37
- 0.348
- 0.364
- 0.368
- 0.376
- 0.365
- 0.0
- 0.0
- 0.383
- 0.0
- 0.358
- 0.332
- 0.357
- 0.377
- 0.0
train_loss:
- 4.029
- 3.502
- 3.277
- 2.066
- 3.501
- 2.742
- 2.847
- 1.806
- 3.153
- 2.454
- 1.678
- 2.432
- 1.248
- 0.77
- 0.637
- 3.003
- 2.42
- 2.036
- 1.686
- 1.329
- 1.191
- 1.131
- 3.089
- 2.187
- 1.049
- 2.656
- 2.133
- 1.971
- 2.446
- 1.991
- 1.794
- 2.062
- 1.067
- 2.466
- 1.828
- 1.575
- 1.222
- 1.965
- 1.515
- 1.174
- 0.926
- 1.494
- 1.244
- 1.7
- 1.107
- 2.04
- 1.318
- 1.67
- 1.179
- 0.885
- 1.406
- 1.105
- 1.633
- 0.868
- 0.344
- 1.071
- 1.949
- 0.545
- 1.629
- 0.854
- 1.512
- 0.613
- 1.384
- 0.725
- 0.639
- 1.28
- 1.114
- 0.618
- 0.982
- 0.573
- 1.911
- 1.188
- 1.255
- 1.007
- 0.894
- 1.096
- 1.206
- 0.761
- 0.825
- 0.882
- 0.813
- 1.054
- 0.73
- 0.721
- 1.02
- 0.599
- 0.699
- 0.657
- 0.742
- 0.463
- 0.542
- 0.724
- 0.845
- 0.832
- 0.394
- 1.188
- 0.611
- 0.762
- 0.526
- 0.42
unequal: 0
verbose: 1
