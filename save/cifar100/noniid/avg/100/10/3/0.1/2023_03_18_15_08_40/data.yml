avg_train_accuracy: 0.405
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0378
- 0.0782
- 0.0287
- 0.0878
- 0.102
- 0.1102
- 0.1148
- 0.1302
- 0.1436
- 0.0514
- 0.0366
- 0.0563
- 0.1432
- 0.1568
- 0.1485
- 0.1604
- 0.1635
- 0.1637
- 0.1666
- 0.1749
- 0.0466
- 0.1834
- 0.0527
- 0.1826
- 0.0414
- 0.1865
- 0.0415
- 0.1955
- 0.0527
- 0.0447
- 0.0543
- 0.1918
- 0.1943
- 0.1991
- 0.2012
- 0.0569
- 0.0597
- 0.2033
- 0.1965
- 0.0652
- 0.2098
- 0.0583
- 0.2091
- 0.0609
- 0.0577
- 0.0635
- 0.062
- 0.2125
- 0.2134
- 0.2161
- 0.2152
- 0.2172
- 0.0708
- 0.2233
- 0.0635
- 0.2256
- 0.0491
- 0.0686
- 0.2207
- 0.0726
- 0.2245
- 0.2313
- 0.227
- 0.0501
- 0.2282
- 0.0758
- 0.0708
- 0.2411
- 0.0844
- 0.2451
- 0.2351
- 0.2287
- 0.2402
- 0.2353
- 0.241
- 0.0713
- 0.241
- 0.2351
- 0.2354
- 0.2458
- 0.2401
- 0.2442
- 0.2387
- 0.0823
- 0.247
- 0.2456
- 0.2431
- 0.2475
- 0.2452
- 0.0744
- 0.2517
- 0.248
- 0.0787
- 0.2547
- 0.2541
- 0.2545
- 0.2515
- 0.2451
- 0.2483
- 0.2517
test_loss_list:
- 1.8783858871459962
- 1.9134892749786376
- 3.1649251651763914
- 1.8715350699424744
- 1.9134228229522705
- 1.944692177772522
- 1.976646809577942
- 1.9623707008361817
- 1.956114068031311
- 3.2861631774902342
- 3.1895641040802003
- 3.2949237251281738
- 1.7743693685531616
- 1.8016720533370971
- 1.861712222099304
- 1.858816566467285
- 1.874916672706604
- 1.9032219552993774
- 1.9107199954986571
- 1.9109978342056275
- 3.246174917221069
- 1.7656614017486572
- 3.1444591379165647
- 1.7662693357467651
- 3.0931973552703855
- 1.7080328392982482
- 3.0945537090301514
- 1.7066421508789062
- 3.0654291820526125
- 3.0580522537231447
- 3.144503893852234
- 1.6640628457069397
- 1.7142758798599242
- 1.7567121982574463
- 1.762001314163208
- 2.992964210510254
- 3.0219407987594606
- 1.6063555645942689
- 1.688363687992096
- 2.9690741872787476
- 1.6336363339424134
- 2.8952653884887694
- 1.6313845610618591
- 2.8766322231292722
- 3.1259946966171266
- 2.953187861442566
- 3.1447282457351684
- 1.594367892742157
- 1.6449633836746216
- 1.6920949268341063
- 1.7075991058349609
- 1.7223428606987
- 2.8634963274002074
- 1.671438274383545
- 2.7717064571380616
- 1.6474655747413636
- 2.820662145614624
- 2.744997515678406
- 1.5423947477340698
- 2.694981017112732
- 1.5858503985404968
- 1.5899992775917053
- 1.6402294087409972
- 2.8639406156539917
- 1.591249670982361
- 2.6997814178466797
- 2.9352953910827635
- 1.5571453857421875
- 2.660291304588318
- 1.5702851176261903
- 1.6213603377342225
- 1.676248688697815
- 1.6855857062339783
- 1.677583384513855
- 1.71953444480896
- 2.7343404865264893
- 1.5945171952247619
- 1.657452142238617
- 1.6880504441261293
- 1.6814104294776917
- 1.7083820414543152
- 1.7036597204208375
- 1.72941335439682
- 2.6801268339157103
- 1.6363475489616395
- 1.68242773771286
- 1.6848160600662232
- 1.6962650179862977
- 1.7269720220565796
- 2.7370119667053223
- 1.621129767894745
- 1.6579570221900939
- 2.7314111042022704
- 1.6250229954719544
- 1.6607403254508972
- 1.7045465230941772
- 1.7190609288215637
- 1.7598874473571777
- 1.72181569814682
- 1.7652820229530335
train_accuracy:
- 0.094
- 0.112
- 0.0
- 0.131
- 0.138
- 0.138
- 0.162
- 0.207
- 0.181
- 0.0
- 0.0
- 0.0
- 0.198
- 0.184
- 0.195
- 0.259
- 0.266
- 0.279
- 0.216
- 0.21
- 0.0
- 0.241
- 0.0
- 0.282
- 0.0
- 0.32
- 0.0
- 0.262
- 0.0
- 0.0
- 0.0
- 0.336
- 0.305
- 0.243
- 0.325
- 0.0
- 0.0
- 0.261
- 0.26
- 0.0
- 0.315
- 0.0
- 0.326
- 0.0
- 0.0
- 0.0
- 0.0
- 0.318
- 0.269
- 0.266
- 0.361
- 0.326
- 0.0
- 0.328
- 0.0
- 0.257
- 0.0
- 0.0
- 0.309
- 0.0
- 0.305
- 0.336
- 0.375
- 0.0
- 0.36
- 0.0
- 0.0
- 0.276
- 0.0
- 0.355
- 0.356
- 0.343
- 0.302
- 0.371
- 0.305
- 0.0
- 0.363
- 0.372
- 0.41
- 0.32
- 0.351
- 0.282
- 0.29
- 0.0
- 0.373
- 0.289
- 0.352
- 0.303
- 0.28
- 0.0
- 0.353
- 0.406
- 0.0
- 0.366
- 0.287
- 0.311
- 0.357
- 0.387
- 0.4
- 0.405
train_loss:
- 4.082
- 3.528
- 2.137
- 3.729
- 2.957
- 2.629
- 2.337
- 2.854
- 2.9
- 1.757
- 2.071
- 1.229
- 2.721
- 2.725
- 1.984
- 2.671
- 2.369
- 2.53
- 1.826
- 2.214
- 1.861
- 2.665
- 1.187
- 2.62
- 1.689
- 2.393
- 1.205
- 2.273
- 1.141
- 1.21
- 0.959
- 2.179
- 2.033
- 1.925
- 1.57
- 0.939
- 1.463
- 2.095
- 1.721
- 0.869
- 2.522
- 0.867
- 1.714
- 0.614
- 0.305
- 0.935
- 0.331
- 2.208
- 1.596
- 1.64
- 1.746
- 1.607
- 0.683
- 1.419
- 0.696
- 1.59
- 1.266
- 0.678
- 1.734
- 0.407
- 1.217
- 1.221
- 1.903
- 1.007
- 1.59
- 0.516
- 0.148
- 1.389
- 0.309
- 1.169
- 0.697
- 0.549
- 0.993
- 1.476
- 0.733
- 0.75
- 0.803
- 1.299
- 1.362
- 0.726
- 1.05
- 1.297
- 0.838
- 0.539
- 1.309
- 0.63
- 1.191
- 0.845
- 0.54
- 0.662
- 0.863
- 0.942
- 0.436
- 0.623
- 0.597
- 0.559
- 0.868
- 1.014
- 0.789
- 0.709
unequal: 0
verbose: 1
