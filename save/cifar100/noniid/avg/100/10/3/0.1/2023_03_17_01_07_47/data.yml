avg_train_accuracy: 0.304
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0298
- 0.0398
- 0.0424
- 0.0786
- 0.1015
- 0.1091
- 0.1222
- 0.0421
- 0.1347
- 0.1409
- 0.1484
- 0.051
- 0.0425
- 0.1522
- 0.1613
- 0.1621
- 0.0464
- 0.1782
- 0.1771
- 0.1886
- 0.051
- 0.1835
- 0.1866
- 0.1943
- 0.1903
- 0.0499
- 0.1916
- 0.1952
- 0.2046
- 0.0472
- 0.052
- 0.1994
- 0.0541
- 0.2066
- 0.2054
- 0.2073
- 0.2188
- 0.2162
- 0.2167
- 0.2229
- 0.2227
- 0.0509
- 0.2188
- 0.2196
- 0.2305
- 0.2263
- 0.2307
- 0.2377
- 0.2422
- 0.2416
- 0.2398
- 0.2399
- 0.2396
- 0.2401
- 0.0611
- 0.2479
- 0.236
- 0.2382
- 0.2467
- 0.2444
- 0.0646
- 0.249
- 0.2518
- 0.0698
- 0.2472
- 0.2461
- 0.246
- 0.2462
- 0.254
- 0.2434
- 0.2532
- 0.2552
- 0.0691
- 0.0607
- 0.255
- 0.2558
- 0.2497
- 0.2507
- 0.2644
- 0.2529
- 0.2601
- 0.2551
- 0.2582
- 0.2614
- 0.0726
- 0.0637
- 0.2603
- 0.2551
- 0.2383
- 0.2506
- 0.2559
- 0.2634
- 0.0739
- 0.0693
- 0.2608
- 0.2592
- 0.2621
- 0.0801
- 0.0763
- 0.2703
test_loss_list:
- 2.8694345569610595
- 3.4933879375457764
- 3.561938123703003
- 1.8138148498535156
- 1.8520526790618896
- 1.8864271831512451
- 1.8883445644378662
- 3.1824143981933593
- 1.8233466958999633
- 1.843012523651123
- 1.855949501991272
- 3.173517723083496
- 3.1161970043182374
- 1.6896898317337037
- 1.7517758083343506
- 1.7745684957504273
- 3.10251690864563
- 1.7212906384468079
- 1.7620514726638794
- 1.7757257604599
- 3.091235671043396
- 1.711668436527252
- 1.7462261271476747
- 1.7597477149963379
- 1.7876814556121827
- 2.982249393463135
- 1.662481529712677
- 1.7230501914024352
- 1.7383222603797912
- 2.941987600326538
- 2.937663745880127
- 1.6191523933410645
- 2.881164674758911
- 1.627631766796112
- 1.6860183906555175
- 1.722072720527649
- 1.7191285157203675
- 1.7482826375961305
- 1.7426355791091919
- 1.7538165402412416
- 1.7703718185424804
- 2.942056245803833
- 1.6983679723739624
- 1.7280861616134644
- 1.7563023018836974
- 1.7678084444999695
- 1.7921171140670777
- 1.7820971488952637
- 1.7720454168319701
- 1.8102288770675659
- 1.8331197166442872
- 1.82703670501709
- 1.830683903694153
- 1.8322556591033936
- 3.0188947439193727
- 1.6542827415466308
- 1.7449143290519715
- 1.733653302192688
- 1.7334437918663026
- 1.768575689792633
- 2.8058459901809694
- 1.6511071991920472
- 1.6669494271278382
- 2.7986360931396486
- 1.6568020129203795
- 1.6801364588737489
- 1.716278269290924
- 1.7689408707618712
- 1.7286915135383607
- 1.7676417660713195
- 1.7549311208724976
- 1.785555236339569
- 2.8546688461303713
- 3.0837032556533814
- 1.6965249133110047
- 1.6953637862205506
- 1.7575916409492494
- 1.754607982635498
- 1.7635412454605102
- 1.785500783920288
- 1.8092898416519165
- 1.8124572038650513
- 1.7950160551071166
- 1.8150235223770141
- 2.7957421159744262
- 2.859136300086975
- 1.5398716187477113
- 1.58086345911026
- 1.6681213760375977
- 1.6714015102386475
- 1.6785536074638367
- 1.6718850994110108
- 2.902553677558899
- 3.07237277507782
- 1.6055473494529724
- 1.6327789521217346
- 1.653656361103058
- 2.824567966461182
- 2.6055493783950805
- 1.524059340953827
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.105
- 0.171
- 0.161
- 0.113
- 0.0
- 0.209
- 0.249
- 0.191
- 0.0
- 0.0
- 0.187
- 0.155
- 0.2
- 0.0
- 0.207
- 0.229
- 0.216
- 0.0
- 0.272
- 0.295
- 0.225
- 0.301
- 0.0
- 0.233
- 0.272
- 0.214
- 0.0
- 0.0
- 0.233
- 0.0
- 0.276
- 0.347
- 0.296
- 0.257
- 0.273
- 0.256
- 0.28
- 0.302
- 0.0
- 0.266
- 0.286
- 0.266
- 0.286
- 0.329
- 0.271
- 0.326
- 0.281
- 0.382
- 0.258
- 0.373
- 0.297
- 0.0
- 0.31
- 0.276
- 0.36
- 0.344
- 0.329
- 0.0
- 0.298
- 0.303
- 0.0
- 0.304
- 0.342
- 0.306
- 0.273
- 0.352
- 0.361
- 0.376
- 0.31
- 0.0
- 0.0
- 0.297
- 0.311
- 0.387
- 0.307
- 0.384
- 0.292
- 0.293
- 0.386
- 0.337
- 0.374
- 0.0
- 0.0
- 0.297
- 0.339
- 0.324
- 0.343
- 0.316
- 0.372
- 0.0
- 0.0
- 0.317
- 0.342
- 0.357
- 0.0
- 0.0
- 0.304
train_loss:
- 1.699
- 1.977
- 1.996
- 4.283
- 3.073
- 2.681
- 3.022
- 1.67
- 2.679
- 2.95
- 2.894
- 1.562
- 1.85
- 3.118
- 2.473
- 2.684
- 1.381
- 2.851
- 2.285
- 2.218
- 1.309
- 2.671
- 2.094
- 2.257
- 2.013
- 1.48
- 2.198
- 1.805
- 2.014
- 1.384
- 1.258
- 1.938
- 0.809
- 2.155
- 1.802
- 1.368
- 1.621
- 2.12
- 1.545
- 1.71
- 1.902
- 1.249
- 1.645
- 1.142
- 1.665
- 1.518
- 1.607
- 1.41
- 1.175
- 1.325
- 1.379
- 1.142
- 0.993
- 1.338
- 1.284
- 1.542
- 1.002
- 0.911
- 1.06
- 0.736
- 1.144
- 1.332
- 0.856
- 0.783
- 0.784
- 0.726
- 0.52
- 1.18
- 0.619
- 1.331
- 0.865
- 0.939
- 0.83
- 0.339
- 0.8
- 1.044
- 0.709
- 0.974
- 0.624
- 0.799
- 0.488
- 0.608
- 0.762
- 0.507
- 1.205
- 1.174
- 0.825
- 1.097
- 0.682
- 0.466
- 0.694
- 0.456
- 0.763
- 0.279
- 0.73
- 0.378
- 0.232
- 0.454
- 0.914
- 0.722
unequal: 0
verbose: 1
