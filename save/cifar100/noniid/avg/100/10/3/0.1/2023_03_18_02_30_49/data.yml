avg_train_accuracy: 0.293
avg_train_loss: 0.006
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0333
- 0.0388
- 0.0847
- 0.1102
- 0.1131
- 0.1222
- 0.1369
- 0.1473
- 0.1516
- 0.1579
- 0.1616
- 0.1633
- 0.0453
- 0.0465
- 0.0497
- 0.1653
- 0.173
- 0.1671
- 0.0514
- 0.0497
- 0.1741
- 0.177
- 0.1787
- 0.1836
- 0.0527
- 0.1828
- 0.1983
- 0.187
- 0.1906
- 0.1877
- 0.1921
- 0.0457
- 0.2002
- 0.2042
- 0.2043
- 0.2038
- 0.2151
- 0.2197
- 0.213
- 0.2191
- 0.2223
- 0.2249
- 0.2211
- 0.2234
- 0.2265
- 0.2247
- 0.2272
- 0.2313
- 0.2305
- 0.2334
- 0.2251
- 0.229
- 0.2404
- 0.2255
- 0.2292
- 0.2398
- 0.2385
- 0.2292
- 0.2413
- 0.0668
- 0.2344
- 0.2443
- 0.2389
- 0.0547
- 0.2387
- 0.0707
- 0.0522
- 0.2434
- 0.2457
- 0.2467
- 0.0711
- 0.0601
- 0.2466
- 0.2435
- 0.2421
- 0.2492
- 0.254
- 0.0706
- 0.0642
- 0.2506
- 0.2472
- 0.0581
- 0.0644
- 0.0637
- 0.2555
- 0.2506
- 0.2516
- 0.2465
- 0.2485
- 0.0819
- 0.2632
- 0.0773
- 0.2532
- 0.2511
- 0.2475
- 0.0825
- 0.2574
- 0.0708
- 0.0691
- 0.251
test_loss_list:
- 1.8916617965698241
- 3.215980916023254
- 1.8784041118621826
- 1.8826061153411866
- 1.916815037727356
- 1.930651068687439
- 1.9343596410751343
- 1.9539665603637695
- 1.9517769145965576
- 1.955106110572815
- 1.9725817441940308
- 1.9701549243927001
- 3.2618902492523194
- 3.509150972366333
- 3.637924065589905
- 1.8527744913101196
- 1.8735729694366454
- 1.9224568176269532
- 3.250853319168091
- 3.444058141708374
- 1.850306692123413
- 1.8940203499794006
- 1.911169605255127
- 1.9291314840316773
- 3.25469331741333
- 1.8829496145248412
- 1.8890836668014526
- 1.9318100118637085
- 1.9515458726882935
- 1.946589322090149
- 1.947857575416565
- 3.3560730838775634
- 1.7871312046051024
- 1.8253467559814454
- 1.8454886722564696
- 1.853985252380371
- 1.8533412361145019
- 1.860666069984436
- 1.9008977937698364
- 1.8860722398757934
- 1.8878311204910279
- 1.902980875968933
- 1.9106204414367676
- 1.9266987800598145
- 1.9379260396957398
- 1.9381699275970459
- 1.9484110975265503
- 1.951983985900879
- 1.9619563150405883
- 1.9626804494857788
- 1.9774429321289062
- 1.9824201440811158
- 1.9773996782302856
- 1.9982686042785645
- 2.0237733268737794
- 1.9835617303848267
- 1.9836089324951172
- 2.036967272758484
- 2.006168236732483
- 3.009364628791809
- 1.8671941709518434
- 1.8741291189193725
- 1.9222564172744752
- 3.1800749778747557
- 1.750364649295807
- 2.9092036724090575
- 3.1572918701171875
- 1.6982722806930541
- 1.7270764541625976
- 1.7592442417144776
- 2.912189774513245
- 3.0597270059585573
- 1.691062319278717
- 1.7423665380477906
- 1.7862912917137146
- 1.7927889180183412
- 1.7948675155639648
- 3.020714883804321
- 3.2309570789337156
- 1.7466316843032836
- 1.7771124386787414
- 3.0271556901931764
- 2.712154498100281
- 2.8120296382904053
- 1.4682666301727294
- 1.5473636269569397
- 1.5852675223350525
- 1.6595884370803833
- 1.6589266276359558
- 2.6596872806549072
- 1.5670256614685059
- 2.746345729827881
- 1.570344285964966
- 1.6169468712806703
- 1.6631327342987061
- 2.7484880304336547
- 1.6098763680458068
- 2.9384406185150147
- 2.8236983251571655
- 1.5319982314109801
train_accuracy:
- 0.038
- 0.0
- 0.142
- 0.085
- 0.144
- 0.186
- 0.204
- 0.185
- 0.221
- 0.149
- 0.223
- 0.138
- 0.0
- 0.0
- 0.0
- 0.24
- 0.161
- 0.161
- 0.0
- 0.0
- 0.262
- 0.177
- 0.261
- 0.171
- 0.0
- 0.163
- 0.232
- 0.195
- 0.214
- 0.299
- 0.277
- 0.0
- 0.272
- 0.21
- 0.315
- 0.282
- 0.33
- 0.33
- 0.314
- 0.341
- 0.235
- 0.316
- 0.316
- 0.255
- 0.334
- 0.292
- 0.347
- 0.314
- 0.346
- 0.33
- 0.34
- 0.334
- 0.349
- 0.346
- 0.337
- 0.314
- 0.361
- 0.324
- 0.33
- 0.0
- 0.311
- 0.346
- 0.295
- 0.0
- 0.365
- 0.0
- 0.0
- 0.371
- 0.349
- 0.386
- 0.0
- 0.0
- 0.322
- 0.377
- 0.315
- 0.378
- 0.374
- 0.0
- 0.0
- 0.377
- 0.383
- 0.0
- 0.0
- 0.0
- 0.378
- 0.374
- 0.389
- 0.391
- 0.374
- 0.0
- 0.391
- 0.0
- 0.379
- 0.39
- 0.283
- 0.0
- 0.279
- 0.0
- 0.0
- 0.293
train_loss:
- 4.066
- 1.985
- 3.828
- 3.357
- 3.006
- 2.968
- 2.604
- 2.74
- 2.903
- 2.691
- 2.726
- 2.346
- 1.752
- 0.897
- 0.696
- 2.798
- 2.165
- 1.775
- 0.987
- 0.516
- 2.438
- 1.694
- 1.834
- 1.459
- 0.818
- 1.451
- 2.144
- 1.139
- 0.88
- 2.19
- 1.699
- 1.91
- 2.192
- 1.029
- 2.196
- 2.246
- 1.585
- 1.718
- 1.276
- 1.975
- 1.004
- 1.083
- 1.474
- 0.791
- 1.512
- 1.793
- 1.044
- 1.193
- 1.243
- 0.974
- 1.655
- 1.607
- 1.026
- 1.223
- 1.26
- 1.493
- 0.988
- 1.155
- 1.02
- 1.093
- 1.104
- 0.755
- 0.678
- 1.47
- 1.285
- 0.7
- 1.022
- 1.226
- 0.712
- 0.713
- 0.59
- 0.944
- 0.999
- 0.601
- 0.533
- 0.448
- 0.781
- 0.746
- 0.305
- 0.731
- 0.44
- 1.763
- 0.786
- 0.644
- 0.592
- 0.495
- 1.056
- 0.625
- 0.454
- 0.509
- 0.494
- 0.527
- 0.792
- 0.345
- 0.906
- 0.48
- 0.638
- 1.087
- 0.547
- 0.59
unequal: 0
verbose: 1
