avg_train_accuracy: 0.348
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0236
- 0.0878
- 0.1132
- 0.13
- 0.1303
- 0.1508
- 0.1262
- 0.1177
- 0.1237
- 0.1571
- 0.1669
- 0.1907
- 0.1552
- 0.1827
- 0.1826
- 0.204
- 0.1923
- 0.1947
- 0.216
- 0.1944
- 0.1975
- 0.2075
- 0.2369
- 0.2092
- 0.2152
- 0.225
- 0.18
- 0.1824
- 0.1896
- 0.2184
- 0.2429
- 0.2464
- 0.2525
- 0.2303
- 0.2496
- 0.2054
- 0.2557
- 0.2377
- 0.2474
- 0.2384
- 0.2481
- 0.2591
- 0.238
- 0.2431
- 0.2509
- 0.2609
- 0.2591
- 0.2485
- 0.2463
- 0.2678
- 0.2725
- 0.2709
- 0.2524
- 0.2552
- 0.2686
- 0.2599
- 0.2648
- 0.265
- 0.2622
- 0.2623
- 0.2808
- 0.2811
- 0.2682
- 0.2821
- 0.2759
- 0.2786
- 0.2708
- 0.2674
- 0.282
- 0.29
- 0.2858
- 0.2939
- 0.2889
- 0.28
- 0.2912
- 0.288
- 0.2689
- 0.2711
- 0.2696
- 0.2745
- 0.2743
- 0.2732
- 0.2775
- 0.2916
- 0.2812
- 0.2915
- 0.273
- 0.2718
- 0.2941
- 0.3023
- 0.2812
- 0.2959
- 0.3055
- 0.2829
- 0.2998
- 0.2801
- 0.2757
- 0.2963
- 0.2961
- 0.2846
test_loss_list:
- 1.8872310400009156
- 1.8126211547851563
- 1.745262188911438
- 1.74973783493042
- 1.5830580401420593
- 1.6054134583473205
- 1.6211109066009521
- 1.5825578379631042
- 1.5977778124809265
- 1.6424368858337401
- 1.6892887735366822
- 1.5163362646102905
- 1.5932135391235351
- 1.54659184217453
- 1.5769952702522279
- 1.4469335889816284
- 1.4791742444038392
- 1.5195610666275023
- 1.4241760897636413
- 1.5676142406463622
- 1.620161111354828
- 1.6467644548416138
- 1.4375717329978943
- 1.571434621810913
- 1.4790519714355468
- 1.4638404321670533
- 1.497924063205719
- 1.4766095280647278
- 1.480952320098877
- 1.5140063309669494
- 1.430525529384613
- 1.4558524346351625
- 1.3404312705993653
- 1.4952165627479552
- 1.4393814635276794
- 1.4428047275543212
- 1.3691371703147888
- 1.5022533249855041
- 1.4244299483299256
- 1.5320435190200805
- 1.4398467993736268
- 1.4444679403305054
- 1.4204599452018738
- 1.511072540283203
- 1.4529144525527955
- 1.4221987867355346
- 1.3635906410217284
- 1.4917268800735473
- 1.544269871711731
- 1.43661358833313
- 1.3904333448410033
- 1.4076486420631409
- 1.5179114794731141
- 1.5599781489372253
- 1.471658034324646
- 1.3874462819099427
- 1.405080120563507
- 1.429840316772461
- 1.40340220451355
- 1.4989901328086852
- 1.4375332975387574
- 1.445217878818512
- 1.537126486301422
- 1.3826470875740051
- 1.3243119025230408
- 1.361714813709259
- 1.4757070517539979
- 1.5225838255882262
- 1.3973410058021545
- 1.3661589217185974
- 1.3845017266273498
- 1.3822449564933776
- 1.30372727394104
- 1.3590688061714173
- 1.3402189302444458
- 1.3577251839637756
- 1.4733491659164428
- 1.5116264986991883
- 1.5545983839035034
- 1.403081705570221
- 1.42595547914505
- 1.3883696365356446
- 1.4711066508293151
- 1.4109915471076966
- 1.3947265243530274
- 1.3348167538642883
- 1.4697419214248657
- 1.5167478919029236
- 1.394484302997589
- 1.349065384864807
- 1.4794263958930969
- 1.309933032989502
- 1.3210254168510438
- 1.4539620423316955
- 1.3823875379562378
- 1.4751757955551148
- 1.5248452568054198
- 1.4235456490516663
- 1.3853066086769104
- 1.4730830812454223
train_accuracy:
- 0.0
- 0.144
- 0.131
- 0.158
- 0.142
- 0.178
- 0.0
- 0.0
- 0.069
- 0.247
- 0.191
- 0.0
- 0.0
- 0.0
- 0.193
- 0.0
- 0.245
- 0.212
- 0.0
- 0.263
- 0.248
- 0.292
- 0.0
- 0.293
- 0.0
- 0.279
- 0.0
- 0.0
- 0.0
- 0.268
- 0.301
- 0.0
- 0.247
- 0.31
- 0.329
- 0.0
- 0.28
- 0.303
- 0.306
- 0.334
- 0.293
- 0.298
- 0.0
- 0.297
- 0.0
- 0.328
- 0.324
- 0.338
- 0.337
- 0.309
- 0.301
- 0.0
- 0.328
- 0.313
- 0.324
- 0.326
- 0.356
- 0.0
- 0.0
- 0.335
- 0.0
- 0.0
- 0.342
- 0.0
- 0.0
- 0.0
- 0.362
- 0.359
- 0.364
- 0.288
- 0.324
- 0.0
- 0.314
- 0.0
- 0.372
- 0.329
- 0.379
- 0.334
- 0.362
- 0.345
- 0.343
- 0.0
- 0.365
- 0.344
- 0.334
- 0.355
- 0.353
- 0.37
- 0.0
- 0.342
- 0.374
- 0.0
- 0.394
- 0.414
- 0.37
- 0.374
- 0.412
- 0.0
- 0.293
- 0.348
train_loss:
- 2.529
- 3.745
- 2.782
- 2.481
- 2.096
- 2.383
- 1.818
- 1.772
- 1.589
- 2.842
- 2.586
- 1.715
- 1.469
- 2.102
- 1.856
- 1.508
- 1.89
- 1.752
- 1.485
- 2.196
- 2.063
- 2.031
- 1.358
- 1.949
- 1.517
- 1.463
- 0.805
- 1.014
- 1.023
- 1.872
- 1.412
- 1.402
- 1.055
- 1.668
- 1.333
- 0.66
- 1.338
- 1.567
- 1.161
- 1.355
- 1.167
- 1.032
- 0.781
- 1.404
- 0.975
- 1.102
- 1.099
- 1.24
- 1.126
- 1.001
- 0.949
- 0.85
- 1.144
- 1.065
- 0.79
- 0.887
- 0.868
- 0.839
- 0.542
- 1.034
- 0.821
- 0.709
- 0.853
- 0.586
- 0.599
- 0.649
- 0.867
- 0.835
- 0.676
- 0.456
- 0.519
- 0.671
- 0.512
- 0.505
- 0.623
- 0.57
- 0.743
- 0.715
- 0.67
- 0.522
- 0.503
- 0.385
- 0.534
- 0.526
- 0.509
- 0.612
- 0.59
- 0.569
- 0.46
- 0.453
- 0.491
- 0.422
- 0.474
- 0.438
- 0.443
- 0.412
- 0.448
- 0.347
- 0.348
- 0.434
unequal: 0
verbose: 1
