avg_train_accuracy: 0.397
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0372
- 0.0993
- 0.1157
- 0.0815
- 0.1355
- 0.1522
- 0.1525
- 0.1586
- 0.173
- 0.1723
- 0.1623
- 0.1883
- 0.1944
- 0.1848
- 0.1944
- 0.2054
- 0.2001
- 0.2153
- 0.2146
- 0.2201
- 0.219
- 0.2237
- 0.2134
- 0.1514
- 0.2184
- 0.2194
- 0.2337
- 0.2267
- 0.2332
- 0.2413
- 0.2467
- 0.2326
- 0.247
- 0.2373
- 0.2522
- 0.2366
- 0.2559
- 0.2553
- 0.2433
- 0.2576
- 0.26
- 0.2653
- 0.2692
- 0.2486
- 0.2685
- 0.2498
- 0.2734
- 0.2678
- 0.254
- 0.2559
- 0.2581
- 0.2632
- 0.2701
- 0.2731
- 0.2728
- 0.278
- 0.2727
- 0.2616
- 0.2824
- 0.2744
- 0.2761
- 0.2839
- 0.282
- 0.275
- 0.286
- 0.2842
- 0.2887
- 0.283
- 0.2886
- 0.2715
- 0.2892
- 0.3002
- 0.2695
- 0.269
- 0.2737
- 0.2994
- 0.2739
- 0.2881
- 0.2742
- 0.2923
- 0.2759
- 0.2918
- 0.295
- 0.2966
- 0.2988
- 0.2788
- 0.2925
- 0.3015
- 0.3083
- 0.2832
- 0.3043
- 0.2975
- 0.2825
- 0.2971
- 0.2856
- 0.2959
- 0.3075
- 0.2995
- 0.3045
- 0.2883
test_loss_list:
- 1.8505125617980958
- 1.8423633003234863
- 1.7771456670761108
- 1.7238827443122864
- 1.6782290983200072
- 1.6802011775970458
- 1.751073133945465
- 1.6316763329505921
- 1.6254457283020018
- 1.5713209581375123
- 1.5332818126678467
- 1.5469417405128478
- 1.5695449376106263
- 1.658880672454834
- 1.559979190826416
- 1.5286554956436158
- 1.6393775010108949
- 1.4516052842140197
- 1.4815523099899293
- 1.5050951528549195
- 1.461623330116272
- 1.473930661678314
- 1.4786621260643005
- 1.5803129076957703
- 1.5268064904212952
- 1.5869089078903198
- 1.4916273474693298
- 1.5899855518341064
- 1.483652105331421
- 1.4961617517471313
- 1.449907159805298
- 1.5735259604454042
- 1.4934727668762207
- 1.594837646484375
- 1.39211843252182
- 1.5337091445922852
- 1.426021842956543
- 1.387993586063385
- 1.5067049217224122
- 1.4383180594444276
- 1.4149309134483337
- 1.330736346244812
- 1.3506600689888
- 1.495697078704834
- 1.3457573652267456
- 1.481050090789795
- 1.3430274653434753
- 1.346586949825287
- 1.476836953163147
- 1.529852044582367
- 1.5631616520881653
- 1.447594611644745
- 1.4589355683326721
- 1.3958366084098817
- 1.427610285282135
- 1.4034739232063294
- 1.4401821279525757
- 1.530556390285492
- 1.4381811237335205
- 1.4699339938163758
- 1.4757826709747315
- 1.4748852443695069
- 1.4140617084503173
- 1.4396644616127015
- 1.41434104681015
- 1.3360232019424438
- 1.3245998954772948
- 1.357691032886505
- 1.3582803535461425
- 1.472924919128418
- 1.3672333526611329
- 1.2925005459785461
- 1.4401736116409303
- 1.500489695072174
- 1.5219325923919678
- 1.3200500512123108
- 1.4754624462127686
- 1.407399413585663
- 1.5042807459831238
- 1.3970855617523192
- 1.5168023562431336
- 1.3677521657943725
- 1.3904170680046082
- 1.3418817019462586
- 1.3697609686851502
- 1.472031512260437
- 1.3682146167755127
- 1.3545132398605346
- 1.2892120695114135
- 1.4219920015335084
- 1.3504471564292908
- 1.3611405110359192
- 1.4060070204734803
- 1.372665774822235
- 1.4478928971290588
- 1.343923053741455
- 1.3345571875572204
- 1.3463228631019593
- 1.3628476905822753
- 1.4486929988861084
train_accuracy:
- 0.0
- 0.159
- 0.15
- 0.0
- 0.0
- 0.0
- 0.237
- 0.0
- 0.0
- 0.272
- 0.0
- 0.236
- 0.201
- 0.26
- 0.0
- 0.261
- 0.289
- 0.0
- 0.247
- 0.0
- 0.285
- 0.0
- 0.192
- 0.0
- 0.329
- 0.294
- 0.324
- 0.28
- 0.361
- 0.293
- 0.291
- 0.336
- 0.353
- 0.357
- 0.0
- 0.342
- 0.0
- 0.0
- 0.378
- 0.342
- 0.326
- 0.294
- 0.345
- 0.344
- 0.0
- 0.366
- 0.304
- 0.0
- 0.354
- 0.338
- 0.372
- 0.0
- 0.345
- 0.0
- 0.362
- 0.0
- 0.361
- 0.352
- 0.0
- 0.0
- 0.338
- 0.324
- 0.0
- 0.368
- 0.391
- 0.386
- 0.0
- 0.354
- 0.382
- 0.39
- 0.0
- 0.0
- 0.383
- 0.382
- 0.353
- 0.352
- 0.399
- 0.384
- 0.371
- 0.0
- 0.411
- 0.377
- 0.0
- 0.0
- 0.358
- 0.401
- 0.373
- 0.372
- 0.323
- 0.388
- 0.379
- 0.0
- 0.0
- 0.0
- 0.398
- 0.392
- 0.39
- 0.0
- 0.0
- 0.397
train_loss:
- 3.349
- 3.549
- 2.724
- 2.13
- 2.489
- 2.352
- 2.82
- 2.497
- 2.186
- 2.295
- 1.668
- 2.097
- 2.003
- 2.353
- 2.001
- 1.917
- 2.198
- 1.513
- 1.638
- 1.707
- 1.767
- 1.561
- 1.207
- 0.865
- 1.991
- 1.872
- 1.462
- 1.722
- 1.518
- 1.278
- 1.378
- 1.658
- 1.27
- 1.577
- 1.222
- 1.516
- 1.184
- 0.977
- 1.39
- 1.263
- 1.05
- 0.961
- 1.069
- 1.282
- 0.939
- 1.251
- 0.788
- 0.998
- 1.145
- 1.179
- 1.048
- 0.878
- 0.835
- 0.894
- 0.922
- 0.841
- 0.764
- 0.856
- 0.715
- 0.698
- 0.7
- 0.752
- 0.81
- 0.699
- 0.799
- 0.746
- 0.543
- 0.592
- 0.611
- 0.636
- 0.765
- 0.48
- 0.63
- 0.759
- 0.582
- 0.5
- 0.631
- 0.483
- 0.727
- 0.613
- 0.557
- 0.604
- 0.446
- 0.531
- 0.518
- 0.544
- 0.447
- 0.426
- 0.437
- 0.505
- 0.428
- 0.336
- 0.272
- 0.32
- 0.434
- 0.438
- 0.378
- 0.307
- 0.3
- 0.394
unequal: 0
verbose: 1
