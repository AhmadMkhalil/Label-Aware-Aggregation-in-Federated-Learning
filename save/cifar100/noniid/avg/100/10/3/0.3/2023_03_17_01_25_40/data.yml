avg_train_accuracy: 0.372
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0378
- 0.0868
- 0.1083
- 0.1289
- 0.1363
- 0.1418
- 0.15
- 0.1627
- 0.1718
- 0.1626
- 0.175
- 0.1806
- 0.1884
- 0.1789
- 0.1998
- 0.1892
- 0.1985
- 0.2057
- 0.2118
- 0.2038
- 0.2063
- 0.2121
- 0.2105
- 0.2209
- 0.2412
- 0.2383
- 0.2174
- 0.2391
- 0.2496
- 0.2299
- 0.234
- 0.2411
- 0.234
- 0.2471
- 0.2542
- 0.2469
- 0.2462
- 0.2608
- 0.2506
- 0.2587
- 0.2597
- 0.2653
- 0.2567
- 0.2091
- 0.2614
- 0.2469
- 0.2514
- 0.2636
- 0.2586
- 0.2558
- 0.2623
- 0.2545
- 0.2846
- 0.2691
- 0.2644
- 0.279
- 0.2782
- 0.2674
- 0.2836
- 0.2606
- 0.2757
- 0.2773
- 0.283
- 0.2812
- 0.2685
- 0.2662
- 0.2654
- 0.2848
- 0.2953
- 0.2696
- 0.2731
- 0.2775
- 0.2793
- 0.2729
- 0.2781
- 0.296
- 0.2801
- 0.2753
- 0.2901
- 0.2792
- 0.2966
- 0.2756
- 0.2994
- 0.278
- 0.2941
- 0.2772
- 0.294
- 0.2903
- 0.293
- 0.2879
- 0.3006
- 0.3021
- 0.2967
- 0.2923
- 0.2846
- 0.2923
- 0.2809
- 0.2796
- 0.2802
- 0.2782
test_loss_list:
- 1.857894868850708
- 1.7591582107543946
- 1.814787473678589
- 1.7432007217407226
- 1.6820951437950133
- 1.6271237707138062
- 1.726745719909668
- 1.6380873227119446
- 1.5173263001441955
- 1.656867754459381
- 1.5982543873786925
- 1.6145375275611877
- 1.5579111719131469
- 1.5737711143493653
- 1.5533564758300782
- 1.459731559753418
- 1.5004100584983826
- 1.490080623626709
- 1.4744194412231446
- 1.5948546290397645
- 1.6484266066551208
- 1.6705516004562377
- 1.6986251330375672
- 1.554242525100708
- 1.372336711883545
- 1.4398339319229125
- 1.5631555891036988
- 1.4651817464828492
- 1.3674074816703796
- 1.5136234521865846
- 1.5734070920944214
- 1.4761836290359498
- 1.5772291207313538
- 1.4599805998802184
- 1.4833365440368653
- 1.417828242778778
- 1.44592542886734
- 1.415306134223938
- 1.4316455578804017
- 1.4297805762290954
- 1.4549198055267334
- 1.4679857635498046
- 1.3880810856819152
- 1.449742386341095
- 1.3429166889190673
- 1.4812739658355714
- 1.5187855052947998
- 1.432436261177063
- 1.4516175818443298
- 1.5446060848236085
- 1.424483458995819
- 1.524938530921936
- 1.320378212928772
- 1.3753765869140624
- 1.4079437136650086
- 1.372886643409729
- 1.3062877130508423
- 1.3548165488243102
- 1.3416010642051697
- 1.4741669154167176
- 1.3744960117340088
- 1.3148872447013855
- 1.3450208711624145
- 1.343184266090393
- 1.393091344833374
- 1.4723408579826356
- 1.5207257676124573
- 1.3335402131080627
- 1.3150731778144837
- 1.4570871496200561
- 1.498952169418335
- 1.4041602087020875
- 1.3632140135765076
- 1.4791427636146546
- 1.4058955764770509
- 1.3696989107131958
- 1.4038059616088867
- 1.3424960350990296
- 1.3161092162132264
- 1.4417698049545289
- 1.3623210167884827
- 1.4735824370384216
- 1.3222346472740174
- 1.4463056254386901
- 1.3854927158355712
- 1.4820168828964233
- 1.417576789855957
- 1.4312731766700744
- 1.3424126505851746
- 1.3723695135116578
- 1.3679393577575683
- 1.3154137682914735
- 1.345760793685913
- 1.3830889582633972
- 1.4606118369102479
- 1.3559640908241273
- 1.470585629940033
- 1.5073986554145813
- 1.528468017578125
- 1.5550605583190917
train_accuracy:
- 0.0
- 0.117
- 0.174
- 0.0
- 0.183
- 0.0
- 0.205
- 0.0
- 0.0
- 0.227
- 0.199
- 0.238
- 0.248
- 0.0
- 0.258
- 0.193
- 0.241
- 0.0
- 0.241
- 0.291
- 0.284
- 0.315
- 0.263
- 0.325
- 0.0
- 0.278
- 0.308
- 0.286
- 0.0
- 0.279
- 0.311
- 0.336
- 0.311
- 0.387
- 0.0
- 0.342
- 0.0
- 0.0
- 0.39
- 0.318
- 0.0
- 0.3
- 0.366
- 0.0
- 0.336
- 0.369
- 0.36
- 0.0
- 0.341
- 0.351
- 0.346
- 0.349
- 0.0
- 0.358
- 0.338
- 0.0
- 0.0
- 0.0
- 0.341
- 0.356
- 0.368
- 0.292
- 0.334
- 0.339
- 0.0
- 0.363
- 0.381
- 0.0
- 0.0
- 0.357
- 0.356
- 0.0
- 0.368
- 0.378
- 0.438
- 0.338
- 0.421
- 0.0
- 0.348
- 0.375
- 0.378
- 0.369
- 0.0
- 0.373
- 0.354
- 0.458
- 0.434
- 0.0
- 0.0
- 0.335
- 0.0
- 0.368
- 0.329
- 0.331
- 0.367
- 0.0
- 0.384
- 0.468
- 0.382
- 0.372
train_loss:
- 3.225
- 3.006
- 3.328
- 2.561
- 2.565
- 2.589
- 2.797
- 2.276
- 1.89
- 2.602
- 2.134
- 2.051
- 2.034
- 1.497
- 1.814
- 1.619
- 1.852
- 1.796
- 1.723
- 2.151
- 1.934
- 2.045
- 1.83
- 1.694
- 1.329
- 1.404
- 1.752
- 1.435
- 1.111
- 1.714
- 1.671
- 1.287
- 1.505
- 1.312
- 1.116
- 1.242
- 1.116
- 1.227
- 1.125
- 1.043
- 1.008
- 1.127
- 1.246
- 0.616
- 1.054
- 1.233
- 1.152
- 0.965
- 0.905
- 1.07
- 0.899
- 1.177
- 0.812
- 0.842
- 0.808
- 0.877
- 0.726
- 0.765
- 0.811
- 0.876
- 0.793
- 0.523
- 0.657
- 0.723
- 0.714
- 0.852
- 0.8
- 0.654
- 0.713
- 0.727
- 0.712
- 0.693
- 0.612
- 0.725
- 0.53
- 0.667
- 0.525
- 0.43
- 0.541
- 0.673
- 0.509
- 0.583
- 0.451
- 0.549
- 0.547
- 0.495
- 0.429
- 0.432
- 0.538
- 0.434
- 0.434
- 0.439
- 0.401
- 0.383
- 0.467
- 0.46
- 0.402
- 0.394
- 0.366
- 0.349
unequal: 0
verbose: 1
