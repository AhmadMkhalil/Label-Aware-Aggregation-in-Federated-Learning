avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0291
- 0.0462
- 0.0911
- 0.0846
- 0.1176
- 0.1366
- 0.1535
- 0.1607
- 0.1655
- 0.1679
- 0.1692
- 0.1778
- 0.1873
- 0.1866
- 0.1878
- 0.1911
- 0.1995
- 0.2021
- 0.2028
- 0.21
- 0.2077
- 0.2175
- 0.1997
- 0.2124
- 0.224
- 0.2183
- 0.2182
- 0.2256
- 0.2243
- 0.2296
- 0.2343
- 0.2363
- 0.2409
- 0.2374
- 0.2461
- 0.2474
- 0.248
- 0.2549
- 0.249
- 0.2457
- 0.2521
- 0.235
- 0.2434
- 0.2355
- 0.2637
- 0.2566
- 0.246
- 0.2464
- 0.2603
- 0.2611
- 0.2635
- 0.2684
- 0.2675
- 0.254
- 0.2552
- 0.2521
- 0.2662
- 0.248
- 0.2636
- 0.266
- 0.2543
- 0.2693
- 0.2605
- 0.2608
- 0.273
- 0.2682
- 0.2762
- 0.2749
- 0.2798
- 0.2628
- 0.2776
- 0.2631
- 0.2638
- 0.2606
- 0.2785
- 0.2742
- 0.2818
- 0.2731
- 0.273
- 0.271
- 0.2763
- 0.2688
- 0.2853
- 0.2738
- 0.2854
- 0.2677
- 0.2738
- 0.2691
- 0.2958
- 0.2836
- 0.2881
- 0.2824
- 0.2907
- 0.2717
- 0.2697
- 0.2842
- 0.2974
- 0.2845
- 0.2795
- 0.2928
test_loss_list:
- 1.8658730936050416
- 1.8128626441955566
- 1.7527517366409302
- 1.7570994043350219
- 1.7782363176345826
- 1.8109398794174194
- 1.8295911788940429
- 1.7239817190170288
- 1.731601128578186
- 1.804899525642395
- 1.6516748785972595
- 1.738121747970581
- 1.6436248564720153
- 1.7334938955307007
- 1.6036467504501344
- 1.6879941940307617
- 1.5804587078094483
- 1.6763664412498473
- 1.585507526397705
- 1.5510152554512024
- 1.6492783880233766
- 1.463915641307831
- 1.5208012986183166
- 1.4550435256958008
- 1.4626557397842408
- 1.5784018898010255
- 1.5191175985336303
- 1.601760687828064
- 1.6372171497344972
- 1.5214803624153137
- 1.46879802942276
- 1.420110764503479
- 1.4079068946838378
- 1.5281390118598939
- 1.4112478852272035
- 1.3881600499153137
- 1.4054518413543702
- 1.4190747356414795
- 1.4258064770698546
- 1.4571306681632996
- 1.4697786998748779
- 1.4538407301902772
- 1.3711363863945008
- 1.4002957367897033
- 1.3688309478759766
- 1.4191210794448852
- 1.4109403252601624
- 1.4925613594055176
- 1.4365042114257813
- 1.465604419708252
- 1.4117961645126342
- 1.4222375655174255
- 1.4398967266082763
- 1.548081657886505
- 1.4111043214797974
- 1.5335816860198974
- 1.4485095405578614
- 1.5642852473258972
- 1.4474261093139649
- 1.4637725353240967
- 1.55794291973114
- 1.4875669765472412
- 1.5756044244766236
- 1.4434893584251405
- 1.4243846654891967
- 1.3697887253761292
- 1.3408152675628662
- 1.352272880077362
- 1.3546883153915406
- 1.4923057270050049
- 1.3935354089736938
- 1.5243726348876954
- 1.5436108565330506
- 1.5828580522537232
- 1.4458018827438355
- 1.4657540106773377
- 1.3996186661720276
- 1.3563545274734496
- 1.372809202671051
- 1.3654619288444518
- 1.3651409077644348
- 1.4639943623542786
- 1.3816798090934754
- 1.3830876445770264
- 1.3448801589012147
- 1.4803946495056153
- 1.4129441237449647
- 1.4942124724388122
- 1.317042999267578
- 1.3752759957313538
- 1.3849612164497376
- 1.4167247414588928
- 1.3643662166595458
- 1.4761382508277894
- 1.5226290130615234
- 1.4245679211616515
- 1.3116807770729064
- 1.3640455079078675
- 1.397175018787384
- 1.3557355070114137
train_accuracy:
- 0.019
- 0.015
- 0.091
- 0.047
- 0.166
- 0.158
- 0.178
- 0.0
- 0.176
- 0.233
- 0.244
- 0.245
- 0.0
- 0.223
- 0.227
- 0.271
- 0.252
- 0.259
- 0.297
- 0.273
- 0.246
- 0.0
- 0.0
- 0.0
- 0.276
- 0.267
- 0.0
- 0.27
- 0.266
- 0.267
- 0.323
- 0.235
- 0.255
- 0.303
- 0.0
- 0.289
- 0.282
- 0.297
- 0.27
- 0.288
- 0.0
- 0.0
- 0.0
- 0.0
- 0.283
- 0.0
- 0.0
- 0.344
- 0.294
- 0.0
- 0.0
- 0.299
- 0.0
- 0.311
- 0.32
- 0.332
- 0.34
- 0.341
- 0.332
- 0.341
- 0.346
- 0.0
- 0.334
- 0.342
- 0.317
- 0.0
- 0.0
- 0.0
- 0.323
- 0.319
- 0.0
- 0.348
- 0.337
- 0.38
- 0.332
- 0.32
- 0.343
- 0.0
- 0.272
- 0.253
- 0.0
- 0.378
- 0.359
- 0.311
- 0.366
- 0.352
- 0.0
- 0.374
- 0.323
- 0.0
- 0.323
- 0.322
- 0.362
- 0.361
- 0.398
- 0.36
- 0.0
- 0.329
- 0.296
- 0.0
train_loss:
- 3.267
- 2.325
- 2.76
- 2.063
- 3.21
- 2.95
- 2.858
- 2.299
- 2.085
- 2.59
- 2.263
- 2.459
- 1.978
- 2.307
- 2.119
- 2.223
- 1.769
- 2.062
- 1.774
- 1.708
- 2.016
- 1.511
- 1.171
- 1.647
- 1.6
- 1.722
- 1.398
- 1.808
- 1.639
- 1.433
- 1.308
- 1.152
- 1.31
- 1.638
- 1.13
- 1.193
- 1.171
- 1.137
- 1.032
- 0.968
- 0.988
- 0.79
- 1.044
- 0.821
- 1.073
- 1.15
- 0.856
- 1.311
- 0.981
- 0.931
- 1.075
- 0.838
- 0.836
- 1.057
- 0.851
- 1.007
- 0.747
- 0.807
- 0.661
- 0.864
- 0.805
- 0.73
- 0.922
- 0.736
- 0.536
- 0.739
- 0.603
- 0.673
- 0.734
- 0.811
- 0.667
- 0.732
- 0.692
- 0.672
- 0.569
- 0.449
- 0.537
- 0.633
- 0.489
- 0.462
- 0.496
- 0.572
- 0.533
- 0.516
- 0.454
- 0.567
- 0.42
- 0.444
- 0.37
- 0.468
- 0.413
- 0.319
- 0.405
- 0.419
- 0.474
- 0.377
- 0.471
- 0.366
- 0.354
- 0.539
unequal: 0
verbose: 1
