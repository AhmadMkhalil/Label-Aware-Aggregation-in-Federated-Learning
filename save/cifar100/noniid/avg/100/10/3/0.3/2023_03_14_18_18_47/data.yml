avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0269
- 0.0676
- 0.1023
- 0.1268
- 0.1352
- 0.1452
- 0.1585
- 0.1632
- 0.172
- 0.1775
- 0.1788
- 0.1757
- 0.1908
- 0.1916
- 0.1939
- 0.2052
- 0.1981
- 0.2158
- 0.2141
- 0.2103
- 0.2198
- 0.2177
- 0.219
- 0.2209
- 0.2197
- 0.2372
- 0.2307
- 0.2264
- 0.239
- 0.2208
- 0.2418
- 0.2383
- 0.2309
- 0.2497
- 0.2262
- 0.2472
- 0.2408
- 0.2503
- 0.2392
- 0.2504
- 0.2446
- 0.2613
- 0.2578
- 0.2614
- 0.2664
- 0.2501
- 0.2396
- 0.2695
- 0.2667
- 0.2516
- 0.2543
- 0.25
- 0.269
- 0.2625
- 0.2535
- 0.2736
- 0.2752
- 0.2727
- 0.258
- 0.2892
- 0.2771
- 0.2711
- 0.2623
- 0.28
- 0.2639
- 0.2753
- 0.2628
- 0.2626
- 0.2638
- 0.2944
- 0.2677
- 0.2932
- 0.2677
- 0.3019
- 0.2876
- 0.2933
- 0.2866
- 0.2893
- 0.2883
- 0.2722
- 0.2689
- 0.2718
- 0.2897
- 0.2738
- 0.2768
- 0.2869
- 0.2709
- 0.2814
- 0.3013
- 0.2957
- 0.2926
- 0.2921
- 0.2791
- 0.2748
- 0.2747
- 0.2937
- 0.2931
- 0.291
- 0.2689
- 0.2964
test_loss_list:
- 1.885836787223816
- 1.7443765258789063
- 1.7946312522888184
- 1.8222880840301514
- 1.7238723373413085
- 1.7930544137954711
- 1.8256006860733032
- 1.694017720222473
- 1.6800404906272888
- 1.689480493068695
- 1.5848013830184937
- 1.5062615919113158
- 1.5353938794136048
- 1.5375312066078186
- 1.5005627727508546
- 1.4942936635017394
- 1.6185992312431337
- 1.4708553910255433
- 1.4985609030723572
- 1.4590813326835632
- 1.4758470177650451
- 1.4674981260299682
- 1.4700843787193298
- 1.4437051796913147
- 1.5761449694633485
- 1.427406928539276
- 1.466177272796631
- 1.4923732113838195
- 1.4561430048942565
- 1.4801775074005128
- 1.4649643421173095
- 1.3996377992630005
- 1.5364622640609742
- 1.3830222415924072
- 1.4444894862174988
- 1.375693871974945
- 1.4015354561805724
- 1.4062395739555358
- 1.517272961139679
- 1.4370335125923157
- 1.5396349763870238
- 1.4428385448455812
- 1.3867042136192322
- 1.3732995414733886
- 1.3738896179199218
- 1.393233425617218
- 1.4332417583465575
- 1.3975452589988708
- 1.4028261137008666
- 1.5139389991760255
- 1.5479061198234558
- 1.5826972103118897
- 1.463778772354126
- 1.380546543598175
- 1.5088557839393615
- 1.4126858496665955
- 1.3578137707710267
- 1.3541918969154358
- 1.4870520234107971
- 1.31830637216568
- 1.3394575238227844
- 1.3616766285896302
- 1.446735954284668
- 1.3929606103897094
- 1.4878671813011168
- 1.4006520819664001
- 1.505580234527588
- 1.5493689346313477
- 1.5764655184745788
- 1.3540631532669067
- 1.5025326251983642
- 1.3106101369857788
- 1.459030225276947
- 1.297670395374298
- 1.3181882572174073
- 1.331820387840271
- 1.3695385670661926
- 1.3424717473983765
- 1.3691877126693726
- 1.4650627422332763
- 1.508857033252716
- 1.5391570138931274
- 1.405837233066559
- 1.5228949427604674
- 1.3845710039138794
- 1.4072420144081115
- 1.5115304112434387
- 1.3904134654998779
- 1.292334406375885
- 1.335274143218994
- 1.3433068466186524
- 1.3539433121681212
- 1.4583421397209166
- 1.5004833078384399
- 1.5317179322242738
- 1.4104876947402953
- 1.433246874809265
- 1.4502367687225342
- 1.3720045638084413
- 1.337330424785614
train_accuracy:
- 0.0
- 0.05
- 0.127
- 0.167
- 0.145
- 0.174
- 0.181
- 0.203
- 0.227
- 0.212
- 0.195
- 0.0
- 0.208
- 0.23
- 0.0
- 0.285
- 0.255
- 0.0
- 0.24
- 0.261
- 0.245
- 0.273
- 0.241
- 0.0
- 0.282
- 0.224
- 0.293
- 0.0
- 0.0
- 0.0
- 0.273
- 0.3
- 0.33
- 0.285
- 0.0
- 0.0
- 0.0
- 0.289
- 0.338
- 0.301
- 0.305
- 0.341
- 0.0
- 0.281
- 0.331
- 0.0
- 0.203
- 0.326
- 0.332
- 0.316
- 0.36
- 0.345
- 0.346
- 0.238
- 0.347
- 0.326
- 0.355
- 0.0
- 0.379
- 0.31
- 0.353
- 0.0
- 0.382
- 0.297
- 0.378
- 0.286
- 0.345
- 0.351
- 0.371
- 0.0
- 0.352
- 0.322
- 0.304
- 0.323
- 0.0
- 0.29
- 0.0
- 0.0
- 0.356
- 0.378
- 0.362
- 0.326
- 0.0
- 0.367
- 0.0
- 0.386
- 0.356
- 0.0
- 0.323
- 0.388
- 0.285
- 0.0
- 0.388
- 0.39
- 0.389
- 0.0
- 0.302
- 0.327
- 0.0
- 0.0
train_loss:
- 2.544
- 3.062
- 3.474
- 3.128
- 2.511
- 3.006
- 2.688
- 2.355
- 2.267
- 2.104
- 2.21
- 1.687
- 1.993
- 1.96
- 2.01
- 1.906
- 2.234
- 1.476
- 1.708
- 1.818
- 1.557
- 1.526
- 1.517
- 1.676
- 1.891
- 1.291
- 1.411
- 1.459
- 1.407
- 1.003
- 1.336
- 1.46
- 1.587
- 1.006
- 0.931
- 1.419
- 0.908
- 1.107
- 1.521
- 1.209
- 1.443
- 1.061
- 1.009
- 1.116
- 1.098
- 0.861
- 0.755
- 0.922
- 0.91
- 1.263
- 1.089
- 1.14
- 0.927
- 0.702
- 1.035
- 0.868
- 0.909
- 0.767
- 0.869
- 0.668
- 0.805
- 0.502
- 0.887
- 0.767
- 0.74
- 0.832
- 0.864
- 0.776
- 0.733
- 0.547
- 0.806
- 0.555
- 0.736
- 0.497
- 0.433
- 0.599
- 0.477
- 0.6
- 0.523
- 0.553
- 0.618
- 0.661
- 0.521
- 0.571
- 0.492
- 0.414
- 0.558
- 0.46
- 0.418
- 0.417
- 0.383
- 0.411
- 0.427
- 0.452
- 0.43
- 0.467
- 0.327
- 0.308
- 0.339
- 0.39
unequal: 0
verbose: 1
