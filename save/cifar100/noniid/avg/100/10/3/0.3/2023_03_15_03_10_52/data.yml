avg_train_accuracy: 0.367
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0206
- 0.0692
- 0.1014
- 0.1224
- 0.1366
- 0.1133
- 0.1422
- 0.1613
- 0.1565
- 0.1617
- 0.1747
- 0.1573
- 0.1884
- 0.1785
- 0.1876
- 0.1938
- 0.202
- 0.1962
- 0.1957
- 0.2019
- 0.2073
- 0.2217
- 0.2206
- 0.2261
- 0.2143
- 0.2189
- 0.23
- 0.2242
- 0.2262
- 0.2305
- 0.2323
- 0.2308
- 0.23
- 0.2499
- 0.2374
- 0.2394
- 0.2523
- 0.2535
- 0.2436
- 0.2634
- 0.2464
- 0.2752
- 0.2483
- 0.2449
- 0.2502
- 0.2717
- 0.2554
- 0.2538
- 0.2694
- 0.2652
- 0.2613
- 0.254
- 0.2767
- 0.2587
- 0.2805
- 0.2705
- 0.2635
- 0.2705
- 0.2667
- 0.2744
- 0.2938
- 0.2817
- 0.2843
- 0.2728
- 0.2698
- 0.2633
- 0.2783
- 0.2676
- 0.2628
- 0.2871
- 0.2881
- 0.2914
- 0.2845
- 0.2865
- 0.2838
- 0.2741
- 0.2862
- 0.2714
- 0.2899
- 0.2856
- 0.2734
- 0.2869
- 0.2705
- 0.2699
- 0.2974
- 0.2959
- 0.2901
- 0.2797
- 0.2914
- 0.2901
- 0.2863
- 0.2939
- 0.2903
- 0.2834
- 0.2906
- 0.2732
- 0.2866
- 0.2733
- 0.2877
- 0.2899
test_loss_list:
- 1.893320417404175
- 1.793801703453064
- 1.8202384424209594
- 1.850932879447937
- 1.6721612524986267
- 1.6310086035728455
- 1.6198742413520812
- 1.60933025598526
- 1.5554824566841126
- 1.6677503442764283
- 1.5613198709487914
- 1.5349351072311401
- 1.5320080876350404
- 1.6406385493278504
- 1.5701927590370177
- 1.5301994633674623
- 1.4977039313316345
- 1.612323911190033
- 1.670948202610016
- 1.6930880236625672
- 1.7111310696601867
- 1.4721257877349854
- 1.516940188407898
- 1.5052152061462403
- 1.6150605916976928
- 1.6589717173576355
- 1.546284990310669
- 1.6430166006088256
- 1.673428566455841
- 1.5526382684707642
- 1.6514744019508363
- 1.6880256891250611
- 1.70821546792984
- 1.4256099653244019
- 1.5781597685813904
- 1.61669100522995
- 1.5174406242370606
- 1.4552176690101624
- 1.3957238054275514
- 1.4070320868492125
- 1.5287995672225951
- 1.379165608882904
- 1.5174415230751037
- 1.572378821372986
- 1.5982072401046752
- 1.3724299097061157
- 1.5126912903785705
- 1.570288200378418
- 1.4631374168395996
- 1.4271624517440795
- 1.441554398536682
- 1.3814647722244262
- 1.3523159074783324
- 1.485478253364563
- 1.3658258748054504
- 1.3981570744514464
- 1.4990739989280701
- 1.3922672247886658
- 1.5099460673332215
- 1.425128583908081
- 1.3029557299613952
- 1.3631981086730958
- 1.3646291732788085
- 1.359954173564911
- 1.4071310997009276
- 1.5037661337852477
- 1.3729437136650084
- 1.4763026452064514
- 1.534462251663208
- 1.3666469550132752
- 1.329482865333557
- 1.3722588896751404
- 1.3947262239456177
- 1.4155636096000672
- 1.3752220225334169
- 1.4115457606315613
- 1.3850923991203308
- 1.4788459396362306
- 1.3416883850097656
- 1.3364067840576173
- 1.437140371799469
- 1.3857899498939514
- 1.4877176260948182
- 1.5162108874320983
- 1.322817680835724
- 1.3284981989860534
- 1.3537846064567567
- 1.4452682256698608
- 1.376001980304718
- 1.3653112745285034
- 1.3503486847877502
- 1.3590145373344422
- 1.3657743215560914
- 1.4010577869415284
- 1.377579572200775
- 1.4853912925720214
- 1.4181617212295532
- 1.5199023485183716
- 1.4127544641494751
- 1.41003568649292
train_accuracy:
- 0.0
- 0.045
- 0.17
- 0.17
- 0.0
- 0.077
- 0.0
- 0.0
- 0.135
- 0.213
- 0.2
- 0.114
- 0.0
- 0.239
- 0.212
- 0.228
- 0.283
- 0.305
- 0.244
- 0.278
- 0.304
- 0.272
- 0.29
- 0.271
- 0.312
- 0.29
- 0.308
- 0.333
- 0.318
- 0.282
- 0.306
- 0.319
- 0.326
- 0.315
- 0.301
- 0.338
- 0.344
- 0.344
- 0.0
- 0.34
- 0.301
- 0.0
- 0.352
- 0.384
- 0.352
- 0.0
- 0.295
- 0.299
- 0.0
- 0.0
- 0.33
- 0.287
- 0.301
- 0.329
- 0.302
- 0.34
- 0.372
- 0.319
- 0.38
- 0.0
- 0.353
- 0.332
- 0.0
- 0.311
- 0.337
- 0.316
- 0.0
- 0.371
- 0.364
- 0.327
- 0.346
- 0.332
- 0.0
- 0.362
- 0.0
- 0.247
- 0.312
- 0.361
- 0.0
- 0.0
- 0.339
- 0.355
- 0.356
- 0.377
- 0.0
- 0.0
- 0.327
- 0.348
- 0.359
- 0.355
- 0.317
- 0.339
- 0.0
- 0.378
- 0.365
- 0.379
- 0.0
- 0.352
- 0.354
- 0.367
train_loss:
- 2.552
- 3.065
- 3.482
- 3.112
- 2.078
- 1.9
- 2.307
- 2.289
- 1.893
- 2.744
- 1.724
- 1.649
- 2.001
- 2.446
- 2.046
- 1.972
- 1.867
- 2.195
- 1.989
- 2.129
- 2.043
- 1.596
- 1.666
- 1.557
- 1.853
- 1.709
- 1.695
- 1.775
- 1.636
- 1.383
- 1.594
- 1.438
- 1.477
- 1.181
- 1.41
- 1.296
- 1.268
- 1.178
- 1.022
- 1.171
- 1.307
- 0.835
- 1.324
- 1.127
- 1.154
- 0.944
- 1.114
- 1.025
- 1.102
- 0.849
- 0.931
- 0.816
- 0.858
- 0.918
- 0.722
- 0.883
- 0.864
- 0.872
- 0.91
- 0.715
- 0.7
- 0.747
- 0.625
- 0.75
- 0.668
- 0.781
- 0.624
- 0.723
- 0.738
- 0.635
- 0.609
- 0.479
- 0.579
- 0.507
- 0.429
- 0.414
- 0.547
- 0.535
- 0.448
- 0.445
- 0.615
- 0.456
- 0.563
- 0.544
- 0.512
- 0.337
- 0.428
- 0.516
- 0.494
- 0.466
- 0.544
- 0.416
- 0.435
- 0.416
- 0.445
- 0.451
- 0.414
- 0.429
- 0.348
- 0.359
unequal: 0
verbose: 1
