avg_train_accuracy: 0.316
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0481
- 0.0952
- 0.1031
- 0.067
- 0.1165
- 0.1288
- 0.1396
- 0.1585
- 0.1559
- 0.1545
- 0.1681
- 0.1683
- 0.1763
- 0.1784
- 0.1879
- 0.1868
- 0.1968
- 0.1898
- 0.2043
- 0.2118
- 0.1998
- 0.2015
- 0.2064
- 0.2067
- 0.2209
- 0.2099
- 0.2293
- 0.2311
- 0.2197
- 0.2079
- 0.2406
- 0.238
- 0.2262
- 0.2479
- 0.2231
- 0.2428
- 0.2324
- 0.2332
- 0.2333
- 0.2467
- 0.2485
- 0.2382
- 0.2545
- 0.2404
- 0.2704
- 0.2414
- 0.2661
- 0.2612
- 0.2489
- 0.2466
- 0.2546
- 0.2562
- 0.2551
- 0.2595
- 0.2672
- 0.27
- 0.2547
- 0.2569
- 0.2647
- 0.2762
- 0.2565
- 0.2536
- 0.2824
- 0.2651
- 0.2597
- 0.273
- 0.2603
- 0.2818
- 0.2701
- 0.2742
- 0.291
- 0.2682
- 0.2702
- 0.2734
- 0.2694
- 0.2706
- 0.2696
- 0.2686
- 0.2782
- 0.2685
- 0.2735
- 0.2775
- 0.29
- 0.294
- 0.2872
- 0.2818
- 0.2841
- 0.2723
- 0.2763
- 0.2775
- 0.2734
- 0.2897
- 0.2793
- 0.2752
- 0.3082
- 0.2833
- 0.2876
- 0.2786
- 0.2924
- 0.2966
test_loss_list:
- 1.873297986984253
- 1.80265230178833
- 1.7376439428329469
- 1.7483833122253418
- 1.6458078241348266
- 1.6587894678115844
- 1.7389404582977295
- 1.6507556891441346
- 1.538456871509552
- 1.5775091218948365
- 1.5730800533294678
- 1.5181596684455871
- 1.5435685634613037
- 1.5392800855636597
- 1.4839012789726258
- 1.5213583397865296
- 1.5136632466316222
- 1.6148276495933533
- 1.481882472038269
- 1.462932357788086
- 1.4793067216873168
- 1.5087023878097534
- 1.6015912628173827
- 1.6410764837265015
- 1.5359303498268126
- 1.4766410756111146
- 1.490144076347351
- 1.476493511199951
- 1.4298414039611815
- 1.4561160826683044
- 1.408652970790863
- 1.421834843158722
- 1.538141233921051
- 1.4203736090660095
- 1.4035242891311646
- 1.4082349276542663
- 1.4184014463424683
- 1.5186633324623109
- 1.5640507006645203
- 1.46448673248291
- 1.4202216720581056
- 1.5445613217353822
- 1.4318596005439759
- 1.5467179346084594
- 1.3780141758918762
- 1.5044370651245118
- 1.3516781163215636
- 1.3609555315971376
- 1.4985933518409729
- 1.5387230324745178
- 1.5623964524269105
- 1.4417282271385192
- 1.394114077091217
- 1.4990571308135987
- 1.3938363480567932
- 1.386741955280304
- 1.4941761302947998
- 1.5321580862998962
- 1.4378899574279784
- 1.3910273170471192
- 1.4954305076599121
- 1.5447615361213685
- 1.3417451930046083
- 1.3409848189353943
- 1.4468933534622193
- 1.3483605647087098
- 1.4636800265312195
- 1.3883126068115235
- 1.3666399884223939
- 1.3735844278335572
- 1.3101954865455627
- 1.3740403318405152
- 1.4390234375
- 1.3781799697875976
- 1.4747191309928893
- 1.420156445503235
- 1.50649986743927
- 1.5433937215805054
- 1.4449249553680419
- 1.5431717920303345
- 1.3899233055114746
- 1.343023760318756
- 1.3507886934280395
- 1.3324554872512817
- 1.3607996058464051
- 1.3403093934059143
- 1.3381861853599548
- 1.3858773684501648
- 1.4404002499580384
- 1.3870947718620301
- 1.4173284125328065
- 1.3511053466796874
- 1.3855514430999756
- 1.4768037843704223
- 1.3095374274253846
- 1.340273811817169
- 1.3454137015342713
- 1.4442283177375794
- 1.3934451007843018
- 1.3634553480148315
train_accuracy:
- 0.071
- 0.118
- 0.159
- 0.0
- 0.109
- 0.171
- 0.193
- 0.204
- 0.0
- 0.148
- 0.237
- 0.0
- 0.0
- 0.203
- 0.0
- 0.237
- 0.0
- 0.256
- 0.0
- 0.0
- 0.257
- 0.0
- 0.322
- 0.323
- 0.221
- 0.0
- 0.0
- 0.245
- 0.338
- 0.174
- 0.241
- 0.0
- 0.321
- 0.29
- 0.0
- 0.0
- 0.0
- 0.32
- 0.342
- 0.0
- 0.304
- 0.327
- 0.0
- 0.322
- 0.246
- 0.364
- 0.317
- 0.0
- 0.33
- 0.348
- 0.343
- 0.315
- 0.305
- 0.324
- 0.345
- 0.334
- 0.339
- 0.372
- 0.291
- 0.0
- 0.342
- 0.331
- 0.0
- 0.0
- 0.325
- 0.0
- 0.336
- 0.0
- 0.0
- 0.0
- 0.34
- 0.207
- 0.372
- 0.381
- 0.316
- 0.361
- 0.398
- 0.352
- 0.353
- 0.309
- 0.0
- 0.314
- 0.0
- 0.353
- 0.0
- 0.252
- 0.334
- 0.0
- 0.332
- 0.296
- 0.316
- 0.0
- 0.365
- 0.35
- 0.0
- 0.0
- 0.309
- 0.382
- 0.304
- 0.316
train_loss:
- 4.006
- 2.838
- 2.806
- 1.66
- 2.675
- 2.576
- 2.895
- 2.397
- 1.945
- 2.264
- 2.19
- 1.716
- 2.07
- 2.132
- 1.564
- 1.864
- 2.011
- 2.259
- 1.519
- 1.781
- 1.8
- 1.755
- 2.048
- 1.967
- 1.666
- 1.272
- 1.452
- 1.532
- 1.508
- 1.09
- 1.467
- 1.36
- 1.721
- 0.932
- 1.056
- 1.298
- 1.261
- 1.609
- 1.454
- 1.159
- 1.36
- 1.477
- 1.142
- 1.353
- 0.855
- 1.344
- 0.885
- 0.991
- 1.258
- 1.165
- 1.153
- 1.0
- 0.719
- 1.158
- 0.83
- 0.793
- 0.956
- 0.923
- 0.684
- 0.682
- 0.895
- 0.852
- 0.751
- 0.552
- 0.892
- 0.562
- 0.875
- 0.664
- 0.53
- 0.79
- 0.484
- 0.523
- 0.854
- 0.696
- 0.698
- 0.601
- 0.644
- 0.605
- 0.485
- 0.585
- 0.444
- 0.479
- 0.475
- 0.46
- 0.402
- 0.413
- 0.533
- 0.279
- 0.653
- 0.569
- 0.457
- 0.482
- 0.371
- 0.489
- 0.423
- 0.361
- 0.35
- 0.504
- 0.399
- 0.329
unequal: 0
verbose: 1
