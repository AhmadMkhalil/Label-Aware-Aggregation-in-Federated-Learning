avg_train_accuracy: 0.454
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0176
- 0.0686
- 0.0976
- 0.1177
- 0.1291
- 0.1446
- 0.1491
- 0.1553
- 0.1657
- 0.171
- 0.1793
- 0.1789
- 0.1832
- 0.1911
- 0.2032
- 0.205
- 0.202
- 0.2055
- 0.183
- 0.207
- 0.2191
- 0.219
- 0.2164
- 0.2206
- 0.215
- 0.2213
- 0.2355
- 0.2319
- 0.2243
- 0.2304
- 0.2578
- 0.2434
- 0.2353
- 0.2475
- 0.236
- 0.2216
- 0.2537
- 0.2516
- 0.2442
- 0.2559
- 0.2485
- 0.2431
- 0.2558
- 0.2514
- 0.2455
- 0.2482
- 0.2457
- 0.2465
- 0.2606
- 0.2634
- 0.252
- 0.2755
- 0.259
- 0.2566
- 0.2665
- 0.2715
- 0.262
- 0.2728
- 0.2592
- 0.2827
- 0.2597
- 0.2796
- 0.2754
- 0.2658
- 0.283
- 0.2676
- 0.284
- 0.2761
- 0.2843
- 0.2707
- 0.2873
- 0.2682
- 0.2703
- 0.283
- 0.2884
- 0.2935
- 0.2735
- 0.2851
- 0.2825
- 0.2843
- 0.2874
- 0.2906
- 0.2762
- 0.3
- 0.2965
- 0.2757
- 0.2893
- 0.2763
- 0.2889
- 0.3118
- 0.2961
- 0.2946
- 0.3021
- 0.2964
- 0.2849
- 0.295
- 0.3003
- 0.2785
- 0.2907
- 0.2788
test_loss_list:
- 1.890274739265442
- 1.7721671772003174
- 1.7288098955154418
- 1.7275850105285644
- 1.7835316133499146
- 1.8121580362319947
- 1.8374601745605468
- 1.7315923404693603
- 1.6433059310913085
- 1.5662319874763488
- 1.5207774710655213
- 1.5504311919212341
- 1.6604387044906617
- 1.693562445640564
- 1.5910670232772828
- 1.5485765743255615
- 1.490786507129669
- 1.4532469725608825
- 1.4836654710769652
- 1.4730197453498841
- 1.49961266040802
- 1.5206117033958435
- 1.6106753087043761
- 1.504306812286377
- 1.610125699043274
- 1.6544886779785157
- 1.5269396591186524
- 1.4585457348823547
- 1.5823133635520934
- 1.6179741215705872
- 1.4237346076965331
- 1.38925710439682
- 1.5348685193061828
- 1.450142056941986
- 1.4317144083976745
- 1.4749313879013062
- 1.4335987329483033
- 1.4580559611320496
- 1.5514284348487855
- 1.4852242851257325
- 1.4044626927375794
- 1.5222152614593505
- 1.4627193880081177
- 1.5618309950828553
- 1.5997774529457092
- 1.6287914061546325
- 1.643880627155304
- 1.4888448929786682
- 1.4400251007080078
- 1.358389482498169
- 1.5006746315956117
- 1.4282417488098145
- 1.5379342317581177
- 1.5769913840293883
- 1.4326673364639282
- 1.3800209045410157
- 1.5082430028915406
- 1.4162215638160705
- 1.5430565142631532
- 1.3569916152954102
- 1.4934205651283263
- 1.4166639041900635
- 1.443475821018219
- 1.5361096096038818
- 1.4659489631652831
- 1.559513771533966
- 1.4228531670570375
- 1.3512042593955993
- 1.3287183141708374
- 1.4475512027740478
- 1.3804566693305969
- 1.4954866528511048
- 1.5305019474029542
- 1.4448854041099548
- 1.3840833568572999
- 1.305668556690216
- 1.446949532032013
- 1.3595666289329529
- 1.383914086818695
- 1.4025301146507263
- 1.3543417167663574
- 1.3392672419548035
- 1.4629410815238952
- 1.316602566242218
- 1.3285931205749513
- 1.4500953769683838
- 1.3579362511634827
- 1.4487393069267274
- 1.3925026392936706
- 1.288156473636627
- 1.3526747488975526
- 1.3204704308509827
- 1.3398720383644105
- 1.3443448948860168
- 1.3590861916542054
- 1.3548188376426697
- 1.3490121674537658
- 1.455289809703827
- 1.3995489406585693
- 1.4987238645553589
train_accuracy:
- 0.0
- 0.0
- 0.104
- 0.0
- 0.233
- 0.172
- 0.217
- 0.0
- 0.224
- 0.218
- 0.185
- 0.182
- 0.22
- 0.243
- 0.237
- 0.317
- 0.277
- 0.164
- 0.0
- 0.299
- 0.29
- 0.243
- 0.264
- 0.0
- 0.338
- 0.273
- 0.307
- 0.309
- 0.285
- 0.356
- 0.263
- 0.311
- 0.292
- 0.0
- 0.0
- 0.0
- 0.32
- 0.0
- 0.346
- 0.0
- 0.0
- 0.316
- 0.315
- 0.346
- 0.311
- 0.342
- 0.33
- 0.0
- 0.315
- 0.0
- 0.297
- 0.0
- 0.354
- 0.335
- 0.322
- 0.306
- 0.347
- 0.347
- 0.334
- 0.0
- 0.383
- 0.338
- 0.322
- 0.323
- 0.0
- 0.33
- 0.382
- 0.0
- 0.0
- 0.312
- 0.0
- 0.359
- 0.432
- 0.395
- 0.323
- 0.0
- 0.418
- 0.333
- 0.0
- 0.0
- 0.352
- 0.311
- 0.439
- 0.292
- 0.343
- 0.338
- 0.0
- 0.412
- 0.318
- 0.0
- 0.368
- 0.301
- 0.336
- 0.0
- 0.0
- 0.344
- 0.325
- 0.386
- 0.0
- 0.454
train_loss:
- 2.567
- 2.961
- 2.818
- 2.662
- 3.124
- 2.875
- 2.762
- 2.264
- 2.195
- 2.294
- 1.612
- 2.001
- 2.369
- 2.328
- 1.908
- 1.962
- 1.875
- 1.482
- 1.354
- 1.761
- 1.629
- 1.541
- 2.001
- 1.595
- 1.796
- 1.79
- 1.519
- 1.488
- 1.618
- 1.557
- 1.112
- 1.453
- 1.528
- 1.281
- 0.958
- 0.821
- 1.081
- 1.094
- 1.27
- 1.125
- 0.846
- 1.285
- 0.971
- 1.157
- 1.007
- 1.144
- 1.001
- 0.977
- 1.018
- 0.858
- 1.055
- 0.93
- 1.038
- 1.072
- 0.913
- 0.874
- 0.897
- 0.815
- 0.886
- 0.697
- 0.809
- 0.649
- 0.585
- 0.841
- 0.647
- 0.691
- 0.672
- 0.677
- 0.518
- 0.673
- 0.583
- 0.642
- 0.564
- 0.537
- 0.662
- 0.509
- 0.544
- 0.446
- 0.394
- 0.432
- 0.511
- 0.55
- 0.58
- 0.473
- 0.541
- 0.545
- 0.427
- 0.463
- 0.479
- 0.42
- 0.457
- 0.378
- 0.436
- 0.407
- 0.327
- 0.33
- 0.385
- 0.395
- 0.362
- 0.378
unequal: 0
verbose: 1
