avg_train_accuracy: 0.367
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0194
- 0.0992
- 0.112
- 0.1259
- 0.1358
- 0.1445
- 0.1502
- 0.1589
- 0.1609
- 0.1704
- 0.1811
- 0.1835
- 0.1905
- 0.1918
- 0.1952
- 0.2006
- 0.21
- 0.2181
- 0.2104
- 0.2127
- 0.2191
- 0.2172
- 0.2197
- 0.2272
- 0.2336
- 0.2265
- 0.232
- 0.236
- 0.2339
- 0.2475
- 0.2384
- 0.2437
- 0.2524
- 0.2601
- 0.249
- 0.2531
- 0.2538
- 0.2515
- 0.2616
- 0.2706
- 0.2627
- 0.2617
- 0.2626
- 0.2573
- 0.2585
- 0.271
- 0.2615
- 0.2651
- 0.2642
- 0.2651
- 0.2756
- 0.2833
- 0.2893
- 0.2782
- 0.2711
- 0.2745
- 0.2726
- 0.2867
- 0.2912
- 0.2851
- 0.285
- 0.2916
- 0.2867
- 0.285
- 0.2931
- 0.2878
- 0.2905
- 0.298
- 0.3048
- 0.3059
- 0.2945
- 0.2942
- 0.2832
- 0.2906
- 0.2915
- 0.2931
- 0.293
- 0.2947
- 0.2871
- 0.2839
- 0.301
- 0.3088
- 0.3019
- 0.3055
- 0.3114
- 0.3135
- 0.3012
- 0.3133
- 0.3014
- 0.3115
- 0.3149
- 0.3074
- 0.3042
- 0.3049
- 0.3031
- 0.3157
- 0.3067
- 0.3062
- 0.3065
- 0.2948
test_loss_list:
- 1.823398609161377
- 1.752678894996643
- 1.660320806503296
- 1.643711314201355
- 1.6220956778526305
- 1.598636450767517
- 1.5398852348327636
- 1.5117548727989196
- 1.5338230967521667
- 1.5393475341796874
- 1.4833184599876403
- 1.4999226999282838
- 1.4547587895393372
- 1.4764541649818421
- 1.4782549452781677
- 1.4297454166412353
- 1.409227831363678
- 1.3987654638290405
- 1.4319679498672486
- 1.437552227973938
- 1.4417737698554993
- 1.4315634655952454
- 1.4886022090911866
- 1.4500669407844544
- 1.3814963650703431
- 1.5239013409614564
- 1.4465345382690429
- 1.4194126987457276
- 1.4064120984077453
- 1.3509726667404174
- 1.4397665452957153
- 1.407586510181427
- 1.3436284899711608
- 1.324917323589325
- 1.416860113143921
- 1.387394163608551
- 1.3749609041213988
- 1.4311540627479553
- 1.335897204875946
- 1.30872230052948
- 1.3465973472595214
- 1.3517872452735902
- 1.3517673087120057
- 1.4093630528450012
- 1.4351167917251586
- 1.3256390714645385
- 1.401966164112091
- 1.3604908275604248
- 1.4112197828292847
- 1.41948828458786
- 1.3141118240356446
- 1.2870627665519714
- 1.2779771375656128
- 1.3212269234657288
- 1.3901065325736999
- 1.342310025691986
- 1.396876699924469
- 1.297960753440857
- 1.2815189862251282
- 1.313088023662567
- 1.3285321927070617
- 1.2846572709083557
- 1.3162492156028747
- 1.3202801418304444
- 1.2785216188430786
- 1.3140308237075806
- 1.3218996119499207
- 1.2741510200500488
- 1.265437319278717
- 1.2609098076820373
- 1.3035643339157104
- 1.3177052402496339
- 1.3644001078605652
- 1.3292695379257202
- 1.3326595044136047
- 1.3186369299888612
- 1.323760483264923
- 1.3152718400955201
- 1.374764428138733
- 1.3954133081436157
- 1.2892654681205749
- 1.2670142340660095
- 1.306276330947876
- 1.2716665220260621
- 1.2664891743659974
- 1.2631911444664001
- 1.3035397958755492
- 1.26966290473938
- 1.302761902809143
- 1.2683680176734924
- 1.2640729570388793
- 1.299414701461792
- 1.3137875509262085
- 1.3086052083969115
- 1.3153365755081177
- 1.2713077187538147
- 1.3026800179481506
- 1.3082925724983214
- 1.314753770828247
- 1.3584724974632263
train_accuracy:
- 0.0
- 0.134
- 0.159
- 0.2
- 0.177
- 0.181
- 0.195
- 0.0
- 0.276
- 0.264
- 0.212
- 0.217
- 0.288
- 0.0
- 0.218
- 0.0
- 0.265
- 0.0
- 0.0
- 0.0
- 0.243
- 0.273
- 0.269
- 0.278
- 0.293
- 0.288
- 0.271
- 0.0
- 0.29
- 0.284
- 0.0
- 0.284
- 0.0
- 0.295
- 0.38
- 0.297
- 0.297
- 0.342
- 0.0
- 0.0
- 0.0
- 0.0
- 0.323
- 0.0
- 0.328
- 0.32
- 0.378
- 0.345
- 0.341
- 0.0
- 0.0
- 0.326
- 0.0
- 0.0
- 0.352
- 0.345
- 0.349
- 0.39
- 0.308
- 0.332
- 0.393
- 0.0
- 0.38
- 0.328
- 0.331
- 0.0
- 0.385
- 0.387
- 0.349
- 0.351
- 0.309
- 0.394
- 0.388
- 0.396
- 0.353
- 0.357
- 0.361
- 0.0
- 0.369
- 0.0
- 0.0
- 0.0
- 0.39
- 0.369
- 0.399
- 0.0
- 0.0
- 0.392
- 0.399
- 0.354
- 0.0
- 0.422
- 0.397
- 0.362
- 0.347
- 0.0
- 0.345
- 0.405
- 0.326
- 0.367
train_loss:
- 3.105
- 3.344
- 2.581
- 2.704
- 2.597
- 2.479
- 2.198
- 2.159
- 2.263
- 2.216
- 1.981
- 2.101
- 1.852
- 1.985
- 1.952
- 1.744
- 1.67
- 1.625
- 1.784
- 1.758
- 1.697
- 1.664
- 1.768
- 1.594
- 1.412
- 1.807
- 1.485
- 1.453
- 1.405
- 1.275
- 1.476
- 1.313
- 1.19
- 1.126
- 1.371
- 1.21
- 1.206
- 1.252
- 1.054
- 0.995
- 1.073
- 1.056
- 1.043
- 1.113
- 1.055
- 0.898
- 1.01
- 0.948
- 0.978
- 0.942
- 0.806
- 0.808
- 0.75
- 0.818
- 0.859
- 0.802
- 0.807
- 0.683
- 0.66
- 0.715
- 0.716
- 0.631
- 0.677
- 0.647
- 0.596
- 0.643
- 0.604
- 0.557
- 0.548
- 0.548
- 0.57
- 0.545
- 0.607
- 0.529
- 0.51
- 0.511
- 0.499
- 0.498
- 0.525
- 0.498
- 0.446
- 0.421
- 0.441
- 0.397
- 0.402
- 0.38
- 0.414
- 0.364
- 0.38
- 0.387
- 0.358
- 0.386
- 0.363
- 0.356
- 0.378
- 0.347
- 0.352
- 0.345
- 0.319
- 0.375
unequal: 0
verbose: 1
