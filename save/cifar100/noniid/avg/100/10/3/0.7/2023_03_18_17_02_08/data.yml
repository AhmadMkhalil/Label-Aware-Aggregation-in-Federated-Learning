avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0331
- 0.0777
- 0.1103
- 0.1258
- 0.1314
- 0.1438
- 0.1515
- 0.1604
- 0.1639
- 0.1726
- 0.1805
- 0.1818
- 0.1896
- 0.1928
- 0.1948
- 0.2035
- 0.2034
- 0.2088
- 0.2117
- 0.2164
- 0.2171
- 0.2181
- 0.2236
- 0.2274
- 0.2235
- 0.2286
- 0.2354
- 0.2396
- 0.237
- 0.2446
- 0.2426
- 0.242
- 0.2464
- 0.2408
- 0.2537
- 0.2505
- 0.2498
- 0.255
- 0.2639
- 0.2557
- 0.2604
- 0.2646
- 0.2624
- 0.2647
- 0.2732
- 0.2799
- 0.2788
- 0.2792
- 0.2823
- 0.2743
- 0.2676
- 0.2649
- 0.2725
- 0.2727
- 0.2758
- 0.2834
- 0.2789
- 0.282
- 0.2762
- 0.2757
- 0.2866
- 0.2909
- 0.2967
- 0.2964
- 0.2792
- 0.2803
- 0.2848
- 0.276
- 0.2904
- 0.2862
- 0.2948
- 0.2892
- 0.2869
- 0.2921
- 0.2892
- 0.2802
- 0.2972
- 0.2899
- 0.2868
- 0.2895
- 0.2891
- 0.2935
- 0.2956
- 0.2924
- 0.2943
- 0.2824
- 0.2894
- 0.2828
- 0.2979
- 0.3046
- 0.2968
- 0.2951
- 0.3035
- 0.3093
- 0.3129
- 0.2911
- 0.2972
- 0.2958
- 0.2993
- 0.2982
test_loss_list:
- 1.8279861068725587
- 1.7191714525222779
- 1.6898626708984374
- 1.668484606742859
- 1.6520608496665954
- 1.6213992071151733
- 1.5593485736846924
- 1.530623049736023
- 1.5501359581947327
- 1.505747320652008
- 1.48308602809906
- 1.50939551115036
- 1.5135756206512452
- 1.5167542862892152
- 1.5052987003326417
- 1.4485598993301392
- 1.472744767665863
- 1.5210610675811767
- 1.4872272634506225
- 1.4684913420677186
- 1.5153246092796326
- 1.525744879245758
- 1.4789398837089538
- 1.451561415195465
- 1.5008196997642518
- 1.4604975605010986
- 1.3905101346969604
- 1.3653993153572082
- 1.4538545560836793
- 1.373106598854065
- 1.4017704486846925
- 1.4059595608711242
- 1.4031156206130981
- 1.4552026343345643
- 1.3610547971725464
- 1.3894770312309266
- 1.3884237027168274
- 1.3826610565185546
- 1.3329973411560059
- 1.36660386800766
- 1.3805628299713135
- 1.3316893100738525
- 1.351567153930664
- 1.3651589155197144
- 1.3198170065879822
- 1.3031711411476135
- 1.3027779269218445
- 1.2987799906730653
- 1.2949941682815551
- 1.3339569926261903
- 1.3516067957878113
- 1.41246417760849
- 1.3792297148704529
- 1.3787953877449035
- 1.3567656207084655
- 1.3039441967010499
- 1.3455251717567445
- 1.3415764594078063
- 1.3471836853027344
- 1.3429108786582946
- 1.2942192697525023
- 1.2848127603530883
- 1.2820500040054321
- 1.2809305381774903
- 1.367287938594818
- 1.3996108150482178
- 1.3653956866264343
- 1.3998596811294555
- 1.3018883728981019
- 1.3303977203369142
- 1.2930636072158814
- 1.326915798187256
- 1.3284426522254944
- 1.3287321257591247
- 1.3322531652450562
- 1.398046202659607
- 1.3045962786674499
- 1.3312431216239928
- 1.3343564558029175
- 1.3312389063835144
- 1.33550785779953
- 1.3326187491416932
- 1.3357274770736693
- 1.3303244018554687
- 1.3287441611289978
- 1.3789376378059388
- 1.343431739807129
- 1.3898867964744568
- 1.2976642656326294
- 1.280733494758606
- 1.3189453506469726
- 1.3382108569145204
- 1.2877067399024964
- 1.2792708039283753
- 1.2769235253334046
- 1.3612416648864747
- 1.338290934562683
- 1.330513734817505
- 1.3311073470115662
- 1.3242165875434875
train_accuracy:
- 0.042
- 0.126
- 0.134
- 0.157
- 0.0
- 0.228
- 0.0
- 0.0
- 0.219
- 0.224
- 0.0
- 0.0
- 0.299
- 0.248
- 0.0
- 0.276
- 0.0
- 0.337
- 0.0
- 0.272
- 0.27
- 0.35
- 0.249
- 0.319
- 0.32
- 0.295
- 0.0
- 0.0
- 0.357
- 0.322
- 0.33
- 0.0
- 0.339
- 0.0
- 0.288
- 0.318
- 0.344
- 0.394
- 0.0
- 0.351
- 0.333
- 0.0
- 0.0
- 0.348
- 0.0
- 0.0
- 0.336
- 0.351
- 0.0
- 0.324
- 0.0
- 0.368
- 0.0
- 0.354
- 0.427
- 0.0
- 0.363
- 0.335
- 0.416
- 0.315
- 0.0
- 0.345
- 0.0
- 0.406
- 0.356
- 0.428
- 0.348
- 0.426
- 0.428
- 0.0
- 0.407
- 0.321
- 0.0
- 0.392
- 0.418
- 0.451
- 0.0
- 0.365
- 0.392
- 0.36
- 0.0
- 0.365
- 0.401
- 0.355
- 0.366
- 0.412
- 0.322
- 0.395
- 0.326
- 0.0
- 0.365
- 0.0
- 0.0
- 0.0
- 0.0
- 0.438
- 0.0
- 0.0
- 0.345
- 0.0
train_loss:
- 3.065
- 2.756
- 2.882
- 2.703
- 2.57
- 2.492
- 2.187
- 2.132
- 2.275
- 1.978
- 1.965
- 2.066
- 2.057
- 1.965
- 1.94
- 1.713
- 1.82
- 1.987
- 1.759
- 1.718
- 1.836
- 1.793
- 1.606
- 1.539
- 1.642
- 1.492
- 1.352
- 1.273
- 1.528
- 1.252
- 1.307
- 1.276
- 1.286
- 1.383
- 1.151
- 1.162
- 1.172
- 1.161
- 1.016
- 1.088
- 1.056
- 0.971
- 1.031
- 0.958
- 0.922
- 0.88
- 0.864
- 0.837
- 0.825
- 0.907
- 0.862
- 0.921
- 0.847
- 0.785
- 0.822
- 0.744
- 0.741
- 0.775
- 0.738
- 0.715
- 0.639
- 0.626
- 0.624
- 0.617
- 0.72
- 0.672
- 0.61
- 0.664
- 0.563
- 0.57
- 0.528
- 0.565
- 0.548
- 0.535
- 0.522
- 0.538
- 0.471
- 0.483
- 0.496
- 0.477
- 0.468
- 0.442
- 0.452
- 0.417
- 0.403
- 0.461
- 0.429
- 0.439
- 0.373
- 0.375
- 0.394
- 0.37
- 0.348
- 0.338
- 0.331
- 0.391
- 0.336
- 0.333
- 0.34
- 0.338
unequal: 0
verbose: 1
