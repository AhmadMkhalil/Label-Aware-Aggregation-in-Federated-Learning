avg_train_accuracy: 0.39
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0308
- 0.0918
- 0.1107
- 0.1204
- 0.1342
- 0.1402
- 0.1535
- 0.1615
- 0.1666
- 0.172
- 0.1793
- 0.183
- 0.1867
- 0.1894
- 0.1957
- 0.202
- 0.207
- 0.2051
- 0.2099
- 0.2133
- 0.2125
- 0.2198
- 0.22
- 0.2186
- 0.223
- 0.232
- 0.231
- 0.2306
- 0.2308
- 0.237
- 0.2377
- 0.2411
- 0.2428
- 0.2467
- 0.2434
- 0.2501
- 0.2467
- 0.2486
- 0.2442
- 0.2473
- 0.2528
- 0.2526
- 0.2652
- 0.2622
- 0.2595
- 0.2572
- 0.2696
- 0.2638
- 0.2697
- 0.2651
- 0.2758
- 0.2702
- 0.2626
- 0.2667
- 0.2734
- 0.2792
- 0.2715
- 0.271
- 0.2732
- 0.273
- 0.2848
- 0.2877
- 0.2691
- 0.2823
- 0.2899
- 0.2824
- 0.2884
- 0.2802
- 0.2724
- 0.2857
- 0.2919
- 0.2843
- 0.281
- 0.2777
- 0.2827
- 0.2836
- 0.2849
- 0.2924
- 0.2799
- 0.2933
- 0.287
- 0.2878
- 0.2848
- 0.2984
- 0.3017
- 0.2884
- 0.2885
- 0.302
- 0.2939
- 0.2896
- 0.2906
- 0.2907
- 0.3038
- 0.295
- 0.2826
- 0.2855
- 0.2921
- 0.2992
- 0.285
- 0.2928
test_loss_list:
- 1.829282398223877
- 1.7300086688995362
- 1.6618427848815918
- 1.6175522446632384
- 1.6225819325447082
- 1.571837410926819
- 1.5856764030456543
- 1.6327326893806458
- 1.5403685283660888
- 1.544298644065857
- 1.491052906513214
- 1.5665969061851501
- 1.4812331509590149
- 1.5001520705223084
- 1.4522605562210082
- 1.4357736921310424
- 1.4214800095558167
- 1.4558999490737916
- 1.4181611156463623
- 1.4038095712661742
- 1.4373213481903075
- 1.3980233931541444
- 1.43165691614151
- 1.4354126286506652
- 1.4308386325836182
- 1.3812928867340089
- 1.4092140626907348
- 1.4167559337615967
- 1.4158220958709717
- 1.4176290464401244
- 1.4227389335632323
- 1.4260020971298217
- 1.430142433643341
- 1.4319771838188171
- 1.4149382734298706
- 1.3564300870895385
- 1.3864233779907227
- 1.3859246301651
- 1.513395082950592
- 1.4254682874679565
- 1.3944966554641725
- 1.3842758631706238
- 1.330414433479309
- 1.3678750872612
- 1.3815624904632569
- 1.3750249361991882
- 1.324109811782837
- 1.3583795523643494
- 1.3174123072624206
- 1.3584286618232726
- 1.3152468800544739
- 1.353295087814331
- 1.4204718732833863
- 1.388742949962616
- 1.3266327238082887
- 1.3105602645874024
- 1.3437435340881347
- 1.3459860277175903
- 1.3527102422714234
- 1.3523496913909911
- 1.306563572883606
- 1.2992253160476686
- 1.3946920204162598
- 1.3157102608680724
- 1.2979105639457702
- 1.3398146080970763
- 1.3041546249389648
- 1.3379473614692687
- 1.4034407544136047
- 1.3128858590126038
- 1.2991779565811157
- 1.3356060075759888
- 1.3498979449272155
- 1.4090416216850281
- 1.376407001018524
- 1.372642686367035
- 1.3587998700141908
- 1.302447602748871
- 1.3988553404808044
- 1.3078812384605407
- 1.337991328239441
- 1.3462599635124206
- 1.3448537278175354
- 1.302296998500824
- 1.2946401929855347
- 1.3329574608802794
- 1.3370097064971924
- 1.2982444834709168
- 1.3342588806152345
- 1.342409884929657
- 1.3424277234077453
- 1.3365937447547913
- 1.2968802094459533
- 1.332500033378601
- 1.3945119619369506
- 1.3575252676010132
- 1.3550543236732482
- 1.309282627105713
- 1.3914311599731446
- 1.3477186703681945
train_accuracy:
- 0.041
- 0.103
- 0.13
- 0.132
- 0.169
- 0.0
- 0.174
- 0.225
- 0.0
- 0.232
- 0.213
- 0.229
- 0.244
- 0.251
- 0.221
- 0.0
- 0.282
- 0.239
- 0.253
- 0.274
- 0.254
- 0.298
- 0.0
- 0.279
- 0.283
- 0.0
- 0.0
- 0.316
- 0.311
- 0.304
- 0.276
- 0.283
- 0.306
- 0.323
- 0.0
- 0.332
- 0.293
- 0.285
- 0.368
- 0.0
- 0.306
- 0.357
- 0.0
- 0.299
- 0.0
- 0.374
- 0.338
- 0.0
- 0.314
- 0.317
- 0.311
- 0.387
- 0.323
- 0.381
- 0.387
- 0.388
- 0.372
- 0.379
- 0.302
- 0.0
- 0.35
- 0.0
- 0.398
- 0.391
- 0.366
- 0.394
- 0.0
- 0.0
- 0.391
- 0.416
- 0.0
- 0.318
- 0.0
- 0.329
- 0.329
- 0.377
- 0.432
- 0.329
- 0.0
- 0.338
- 0.0
- 0.366
- 0.0
- 0.0
- 0.384
- 0.0
- 0.345
- 0.386
- 0.0
- 0.347
- 0.348
- 0.362
- 0.327
- 0.322
- 0.403
- 0.344
- 0.318
- 0.336
- 0.336
- 0.39
train_loss:
- 3.084
- 3.048
- 2.581
- 2.471
- 2.6
- 2.268
- 2.402
- 2.513
- 2.059
- 2.165
- 1.938
- 2.278
- 1.85
- 1.948
- 1.761
- 1.692
- 1.67
- 1.805
- 1.574
- 1.544
- 1.658
- 1.527
- 1.612
- 1.616
- 1.518
- 1.385
- 1.475
- 1.481
- 1.44
- 1.396
- 1.338
- 1.351
- 1.292
- 1.263
- 1.255
- 1.108
- 1.169
- 1.192
- 1.335
- 1.112
- 1.087
- 1.078
- 0.961
- 1.011
- 0.984
- 0.982
- 0.884
- 0.933
- 0.848
- 0.881
- 0.81
- 0.85
- 0.905
- 0.817
- 0.775
- 0.735
- 0.793
- 0.762
- 0.738
- 0.74
- 0.667
- 0.642
- 0.745
- 0.616
- 0.595
- 0.636
- 0.571
- 0.628
- 0.661
- 0.572
- 0.531
- 0.588
- 0.578
- 0.59
- 0.513
- 0.507
- 0.539
- 0.477
- 0.533
- 0.448
- 0.501
- 0.473
- 0.47
- 0.44
- 0.409
- 0.444
- 0.452
- 0.375
- 0.433
- 0.411
- 0.407
- 0.416
- 0.367
- 0.37
- 0.393
- 0.349
- 0.364
- 0.341
- 0.363
- 0.343
unequal: 0
verbose: 1
