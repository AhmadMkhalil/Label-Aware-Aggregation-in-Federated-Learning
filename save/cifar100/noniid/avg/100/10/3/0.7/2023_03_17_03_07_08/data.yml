avg_train_accuracy: 0.387
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0315
- 0.0974
- 0.1122
- 0.1226
- 0.1324
- 0.1485
- 0.1522
- 0.1629
- 0.1707
- 0.1732
- 0.1761
- 0.1848
- 0.1893
- 0.1943
- 0.1975
- 0.2039
- 0.208
- 0.2151
- 0.2194
- 0.2145
- 0.2177
- 0.2223
- 0.2229
- 0.232
- 0.227
- 0.2294
- 0.2282
- 0.229
- 0.2343
- 0.2325
- 0.2371
- 0.2387
- 0.2381
- 0.2422
- 0.2419
- 0.2471
- 0.2551
- 0.2621
- 0.2535
- 0.2623
- 0.255
- 0.2563
- 0.2519
- 0.253
- 0.2607
- 0.2608
- 0.2579
- 0.2619
- 0.2629
- 0.2602
- 0.2608
- 0.2666
- 0.274
- 0.2697
- 0.2697
- 0.2791
- 0.2773
- 0.2734
- 0.2835
- 0.29
- 0.27
- 0.2706
- 0.273
- 0.2702
- 0.2709
- 0.2771
- 0.2704
- 0.2729
- 0.2745
- 0.2791
- 0.2823
- 0.2752
- 0.2744
- 0.2785
- 0.2791
- 0.2934
- 0.2868
- 0.287
- 0.2855
- 0.2987
- 0.2903
- 0.2896
- 0.2833
- 0.2843
- 0.2967
- 0.3011
- 0.3066
- 0.2923
- 0.2852
- 0.3008
- 0.2942
- 0.2906
- 0.295
- 0.2852
- 0.2889
- 0.2839
- 0.3019
- 0.2993
- 0.2971
- 0.296
test_loss_list:
- 1.8239129018783569
- 1.7691815519332885
- 1.6684137773513794
- 1.6513979649543762
- 1.5931644201278687
- 1.5961321997642517
- 1.551069152355194
- 1.6122914528846741
- 1.5825841236114502
- 1.5591896271705628
- 1.6048487734794616
- 1.5518479943275452
- 1.5290994954109192
- 1.4714944076538086
- 1.4908290791511536
- 1.4456626224517821
- 1.4296886348724365
- 1.4177005791664123
- 1.411846830844879
- 1.4482440066337585
- 1.4558425092697143
- 1.4076344275474548
- 1.4382609248161315
- 1.396628019809723
- 1.4271561527252197
- 1.4376064944267273
- 1.4985752272605897
- 1.5788682985305786
- 1.4241459107398986
- 1.4897325348854065
- 1.451036262512207
- 1.4251784014701843
- 1.478720018863678
- 1.4365528202056885
- 1.4756967043876648
- 1.3730147194862365
- 1.347304003238678
- 1.3337749123573304
- 1.3755236840248108
- 1.336564266681671
- 1.3726009631156921
- 1.3790283584594727
- 1.437432210445404
- 1.4572135138511657
- 1.3524468111991883
- 1.3726450419425964
- 1.4276009559631349
- 1.3906311202049255
- 1.3788808393478393
- 1.441410117149353
- 1.3830845475196838
- 1.375443787574768
- 1.3242947006225585
- 1.352453317642212
- 1.3628982734680175
- 1.3189625239372254
- 1.351616439819336
- 1.353590314388275
- 1.3127770686149598
- 1.3058295798301698
- 1.398557620048523
- 1.4259219121932984
- 1.380970585346222
- 1.4280713248252868
- 1.375246045589447
- 1.3613142943382264
- 1.417712619304657
- 1.4339727926254273
- 1.3760640549659728
- 1.366680817604065
- 1.3727849769592284
- 1.4269950771331787
- 1.430987091064453
- 1.3778575348854065
- 1.36282368183136
- 1.312294406890869
- 1.341547861099243
- 1.353422029018402
- 1.3529385662078857
- 1.308633372783661
- 1.3418528985977174
- 1.3454359006881713
- 1.400718219280243
- 1.3582972002029419
- 1.3080375623703002
- 1.2992443370819091
- 1.302030725479126
- 1.3325479698181153
- 1.3942007637023925
- 1.3140926742553711
- 1.3420026516914367
- 1.3424566173553467
- 1.344535574913025
- 1.4012508583068848
- 1.3660661363601685
- 1.4011194896697998
- 1.315300087928772
- 1.3412399578094483
- 1.3452267956733703
- 1.3528019523620605
train_accuracy:
- 0.033
- 0.0
- 0.174
- 0.0
- 0.0
- 0.0
- 0.219
- 0.207
- 0.197
- 0.243
- 0.281
- 0.232
- 0.252
- 0.0
- 0.264
- 0.26
- 0.0
- 0.233
- 0.0
- 0.276
- 0.311
- 0.0
- 0.322
- 0.0
- 0.294
- 0.283
- 0.282
- 0.304
- 0.301
- 0.344
- 0.328
- 0.0
- 0.313
- 0.295
- 0.0
- 0.312
- 0.307
- 0.305
- 0.351
- 0.3
- 0.0
- 0.306
- 0.362
- 0.353
- 0.332
- 0.303
- 0.324
- 0.326
- 0.323
- 0.333
- 0.327
- 0.31
- 0.335
- 0.334
- 0.38
- 0.0
- 0.0
- 0.344
- 0.0
- 0.328
- 0.35
- 0.334
- 0.357
- 0.346
- 0.339
- 0.0
- 0.0
- 0.336
- 0.346
- 0.358
- 0.339
- 0.401
- 0.349
- 0.0
- 0.0
- 0.348
- 0.0
- 0.0
- 0.34
- 0.335
- 0.363
- 0.356
- 0.365
- 0.0
- 0.359
- 0.361
- 0.0
- 0.357
- 0.0
- 0.338
- 0.355
- 0.0
- 0.354
- 0.368
- 0.355
- 0.359
- 0.0
- 0.364
- 0.0
- 0.387
train_loss:
- 3.396
- 3.264
- 2.597
- 2.682
- 2.356
- 2.487
- 2.207
- 2.561
- 2.258
- 2.212
- 2.329
- 2.103
- 2.031
- 1.823
- 1.935
- 1.721
- 1.705
- 1.645
- 1.596
- 1.742
- 1.702
- 1.519
- 1.61
- 1.421
- 1.578
- 1.508
- 1.61
- 1.696
- 1.347
- 1.493
- 1.345
- 1.337
- 1.392
- 1.276
- 1.355
- 1.123
- 1.059
- 1.099
- 1.119
- 1.039
- 1.087
- 1.072
- 1.166
- 1.101
- 0.934
- 0.987
- 1.063
- 0.915
- 0.905
- 0.931
- 0.908
- 0.881
- 0.78
- 0.822
- 0.8
- 0.714
- 0.781
- 0.773
- 0.709
- 0.668
- 0.802
- 0.744
- 0.691
- 0.713
- 0.66
- 0.663
- 0.665
- 0.641
- 0.606
- 0.591
- 0.56
- 0.58
- 0.601
- 0.548
- 0.539
- 0.5
- 0.511
- 0.504
- 0.502
- 0.457
- 0.466
- 0.459
- 0.47
- 0.473
- 0.413
- 0.401
- 0.408
- 0.412
- 0.429
- 0.38
- 0.399
- 0.389
- 0.383
- 0.392
- 0.373
- 0.379
- 0.352
- 0.342
- 0.335
- 0.328
unequal: 0
verbose: 1
