avg_train_accuracy: 0.384
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0298
- 0.0793
- 0.1025
- 0.1196
- 0.1315
- 0.1429
- 0.1522
- 0.1582
- 0.1663
- 0.1667
- 0.1746
- 0.1792
- 0.1866
- 0.1883
- 0.1924
- 0.1974
- 0.2029
- 0.2066
- 0.2058
- 0.2123
- 0.2124
- 0.2134
- 0.2169
- 0.2211
- 0.2259
- 0.2285
- 0.2334
- 0.2332
- 0.2324
- 0.2335
- 0.2366
- 0.2403
- 0.2403
- 0.244
- 0.2438
- 0.2457
- 0.2539
- 0.2462
- 0.2536
- 0.2593
- 0.2529
- 0.2603
- 0.2559
- 0.2608
- 0.2672
- 0.2745
- 0.2612
- 0.2592
- 0.2752
- 0.2612
- 0.2639
- 0.2754
- 0.2723
- 0.2633
- 0.2646
- 0.2636
- 0.2736
- 0.2778
- 0.2844
- 0.2765
- 0.2741
- 0.2875
- 0.2812
- 0.2794
- 0.2725
- 0.2767
- 0.2809
- 0.2797
- 0.2964
- 0.288
- 0.2901
- 0.3011
- 0.3011
- 0.2862
- 0.2883
- 0.2869
- 0.2897
- 0.2866
- 0.2918
- 0.2845
- 0.2952
- 0.3033
- 0.3098
- 0.3109
- 0.3132
- 0.2985
- 0.299
- 0.3093
- 0.2996
- 0.3105
- 0.2929
- 0.2863
- 0.2937
- 0.2969
- 0.2964
- 0.298
- 0.2925
- 0.2975
- 0.2937
- 0.2966
test_loss_list:
- 1.830133113861084
- 1.7186231756210326
- 1.6925681638717651
- 1.6659648823738098
- 1.6044685435295105
- 1.6094174218177795
- 1.5962304520606994
- 1.5881709837913514
- 1.5727341389656067
- 1.557778878211975
- 1.5427919149398803
- 1.4911031174659728
- 1.5623379492759704
- 1.5836806988716126
- 1.5334554433822631
- 1.5099780774116516
- 1.4461883234977722
- 1.466662437915802
- 1.5274981355667114
- 1.4367815804481507
- 1.5056660985946655
- 1.477379972934723
- 1.454065546989441
- 1.451379554271698
- 1.4513036298751831
- 1.437150890827179
- 1.382808518409729
- 1.405911042690277
- 1.465416476726532
- 1.482576036453247
- 1.4282623553276061
- 1.4087823581695558
- 1.4668911433219909
- 1.419923017024994
- 1.4692429852485658
- 1.4913058876991272
- 1.3747762417793274
- 1.4406641793251038
- 1.3944318079948426
- 1.3295746731758118
- 1.412512891292572
- 1.331339373588562
- 1.356045401096344
- 1.3655555629730225
- 1.3131936836242675
- 1.3022631573677064
- 1.3883250880241393
- 1.3616615891456605
- 1.307060043811798
- 1.3931794118881227
- 1.415221276283264
- 1.3138843774795532
- 1.332140052318573
- 1.459721007347107
- 1.4425404095649719
- 1.4361636543273926
- 1.3797700142860412
- 1.3693018460273743
- 1.305761866569519
- 1.3305091261863708
- 1.3396795034408568
- 1.2909841179847716
- 1.3212050580978394
- 1.3238943481445313
- 1.3848952770233154
- 1.3453586935997008
- 1.3314943885803223
- 1.332839081287384
- 1.279753246307373
- 1.3179759645462037
- 1.3177239227294921
- 1.2790084671974182
- 1.2720565366744996
- 1.356173129081726
- 1.3205781078338623
- 1.3264503765106201
- 1.3304036831855774
- 1.3203193354606628
- 1.3174150061607361
- 1.3718192076683045
- 1.3365704464912413
- 1.2836233830451966
- 1.2697257161140443
- 1.2668072986602783
- 1.2654846477508546
- 1.3030086302757262
- 1.3148371911048888
- 1.272279245853424
- 1.30517076253891
- 1.274607892036438
- 1.3521718859672547
- 1.3753545308113098
- 1.3298243045806886
- 1.3278494191169739
- 1.3224780702590941
- 1.310411651134491
- 1.3664478731155396
- 1.3322955083847046
- 1.3808670592308045
- 1.3441591906547545
train_accuracy:
- 0.034
- 0.089
- 0.121
- 0.137
- 0.0
- 0.208
- 0.172
- 0.204
- 0.212
- 0.189
- 0.211
- 0.0
- 0.241
- 0.232
- 0.246
- 0.246
- 0.0
- 0.27
- 0.255
- 0.0
- 0.241
- 0.297
- 0.267
- 0.312
- 0.26
- 0.293
- 0.0
- 0.289
- 0.307
- 0.272
- 0.314
- 0.0
- 0.295
- 0.318
- 0.322
- 0.326
- 0.327
- 0.303
- 0.321
- 0.0
- 0.336
- 0.0
- 0.315
- 0.301
- 0.343
- 0.0
- 0.341
- 0.324
- 0.334
- 0.0
- 0.0
- 0.345
- 0.0
- 0.353
- 0.356
- 0.305
- 0.345
- 0.355
- 0.0
- 0.0
- 0.33
- 0.356
- 0.0
- 0.0
- 0.368
- 0.36
- 0.0
- 0.341
- 0.323
- 0.324
- 0.364
- 0.322
- 0.344
- 0.337
- 0.37
- 0.352
- 0.0
- 0.366
- 0.368
- 0.344
- 0.366
- 0.0
- 0.371
- 0.0
- 0.347
- 0.371
- 0.0
- 0.373
- 0.39
- 0.0
- 0.384
- 0.35
- 0.0
- 0.0
- 0.36
- 0.379
- 0.372
- 0.372
- 0.0
- 0.384
train_loss:
- 3.096
- 2.778
- 2.855
- 2.71
- 2.373
- 2.507
- 2.406
- 2.326
- 2.262
- 2.213
- 2.147
- 1.887
- 2.203
- 2.157
- 1.954
- 1.881
- 1.679
- 1.796
- 1.921
- 1.562
- 1.846
- 1.64
- 1.587
- 1.532
- 1.513
- 1.517
- 1.346
- 1.442
- 1.53
- 1.495
- 1.333
- 1.333
- 1.385
- 1.224
- 1.313
- 1.266
- 1.091
- 1.255
- 1.109
- 0.992
- 1.157
- 0.958
- 1.029
- 0.998
- 0.9
- 0.876
- 1.037
- 0.921
- 0.854
- 0.974
- 0.931
- 0.771
- 0.857
- 0.94
- 0.851
- 0.835
- 0.753
- 0.732
- 0.675
- 0.723
- 0.693
- 0.625
- 0.649
- 0.664
- 0.672
- 0.636
- 0.626
- 0.594
- 0.576
- 0.579
- 0.581
- 0.509
- 0.488
- 0.591
- 0.529
- 0.494
- 0.501
- 0.504
- 0.483
- 0.505
- 0.461
- 0.431
- 0.42
- 0.416
- 0.403
- 0.411
- 0.389
- 0.364
- 0.392
- 0.365
- 0.415
- 0.406
- 0.392
- 0.373
- 0.365
- 0.352
- 0.37
- 0.322
- 0.347
- 0.318
unequal: 0
verbose: 1
