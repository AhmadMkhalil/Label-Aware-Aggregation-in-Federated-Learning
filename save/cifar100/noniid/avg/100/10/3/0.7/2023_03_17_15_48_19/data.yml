avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0389
- 0.0865
- 0.1112
- 0.1263
- 0.1369
- 0.1451
- 0.1541
- 0.1633
- 0.1715
- 0.1739
- 0.1792
- 0.1853
- 0.1886
- 0.1938
- 0.1946
- 0.1966
- 0.2017
- 0.2038
- 0.2065
- 0.2119
- 0.2092
- 0.2135
- 0.218
- 0.225
- 0.2263
- 0.2328
- 0.2289
- 0.2292
- 0.2337
- 0.2394
- 0.2381
- 0.2435
- 0.2365
- 0.2394
- 0.2474
- 0.2452
- 0.2411
- 0.2411
- 0.246
- 0.2497
- 0.2576
- 0.2528
- 0.2529
- 0.2561
- 0.2515
- 0.2546
- 0.256
- 0.2594
- 0.2573
- 0.2591
- 0.2664
- 0.2734
- 0.2672
- 0.2681
- 0.2605
- 0.2629
- 0.275
- 0.2778
- 0.2716
- 0.2696
- 0.2738
- 0.2733
- 0.2691
- 0.2827
- 0.274
- 0.2798
- 0.2688
- 0.2782
- 0.2705
- 0.2823
- 0.2899
- 0.2775
- 0.2814
- 0.2923
- 0.2832
- 0.2915
- 0.2928
- 0.2863
- 0.286
- 0.2863
- 0.2777
- 0.2794
- 0.2829
- 0.2958
- 0.2889
- 0.2926
- 0.2801
- 0.2934
- 0.3003
- 0.2899
- 0.278
- 0.2781
- 0.2766
- 0.2792
- 0.2856
- 0.2945
- 0.2936
- 0.2893
- 0.2903
- 0.3006
test_loss_list:
- 1.8459226179122925
- 1.7298974370956421
- 1.698166937828064
- 1.6684421849250795
- 1.6496951079368591
- 1.6279209899902343
- 1.612281858921051
- 1.5868195796012878
- 1.5281900596618652
- 1.502624373435974
- 1.5247320556640624
- 1.5231493377685548
- 1.5281755208969117
- 1.4720880842208863
- 1.4902290773391724
- 1.493760690689087
- 1.4437657475471497
- 1.5152243709564208
- 1.4347749733924866
- 1.4569204211235047
- 1.4553902888298034
- 1.5061426162719727
- 1.4717499709129334
- 1.4050956225395204
- 1.3837913584709167
- 1.3722417974472045
- 1.4133070635795593
- 1.4141072511672974
- 1.3733511066436768
- 1.3559751558303832
- 1.3930976510047912
- 1.3569113731384277
- 1.3888310170173646
- 1.3995119667053222
- 1.3513264560699463
- 1.3864231729507446
- 1.388862509727478
- 1.4407350635528564
- 1.4072514009475707
- 1.3484973788261414
- 1.3309033036231994
- 1.3611208128929138
- 1.366624207496643
- 1.3699924516677857
- 1.3683766436576843
- 1.3621457362174987
- 1.3662313961982726
- 1.3660119223594664
- 1.3580833649635315
- 1.363744170665741
- 1.3182542514801026
- 1.3047333550453186
- 1.3406952595710755
- 1.3561788082122803
- 1.4159584045410156
- 1.371139440536499
- 1.312540144920349
- 1.2982763576507568
- 1.3293644905090332
- 1.3381084966659547
- 1.3527157711982727
- 1.3426412653923034
- 1.340101888179779
- 1.296780800819397
- 1.3283482956886292
- 1.3389998149871827
- 1.399310417175293
- 1.3122726130485534
- 1.3859983110427856
- 1.3020814967155456
- 1.288247468471527
- 1.3241627097129822
- 1.3309373831748963
- 1.2881558990478517
- 1.323481433391571
- 1.2871736645698548
- 1.2842138504981995
- 1.31550719499588
- 1.3290300893783569
- 1.3295851564407348
- 1.3887469291687011
- 1.341804347038269
- 1.3361973357200623
- 1.2900683903694152
- 1.3174930095672608
- 1.2904018664360046
- 1.3718556356430054
- 1.292813766002655
- 1.2827240633964538
- 1.3150443243980408
- 1.374508831501007
- 1.3870490288734436
- 1.399390332698822
- 1.4078204822540283
- 1.3579022407531738
- 1.3001039576530458
- 1.3274686193466188
- 1.3253170037269593
- 1.325031452178955
- 1.2898256754875184
train_accuracy:
- 0.059
- 0.144
- 0.184
- 0.186
- 0.178
- 0.215
- 0.0
- 0.229
- 0.204
- 0.0
- 0.219
- 0.207
- 0.246
- 0.0
- 0.228
- 0.225
- 0.231
- 0.24
- 0.28
- 0.275
- 0.278
- 0.0
- 0.0
- 0.0
- 0.3
- 0.28
- 0.314
- 0.0
- 0.299
- 0.311
- 0.332
- 0.315
- 0.279
- 0.317
- 0.279
- 0.288
- 0.316
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.34
- 0.295
- 0.324
- 0.336
- 0.0
- 0.314
- 0.363
- 0.315
- 0.342
- 0.323
- 0.0
- 0.0
- 0.35
- 0.348
- 0.299
- 0.355
- 0.328
- 0.347
- 0.316
- 0.304
- 0.318
- 0.34
- 0.345
- 0.0
- 0.338
- 0.361
- 0.333
- 0.312
- 0.318
- 0.355
- 0.352
- 0.0
- 0.367
- 0.327
- 0.0
- 0.0
- 0.331
- 0.0
- 0.0
- 0.354
- 0.0
- 0.0
- 0.37
- 0.0
- 0.376
- 0.376
- 0.0
- 0.0
- 0.392
- 0.397
- 0.0
- 0.348
- 0.377
- 0.354
- 0.33
- 0.387
- 0.0
- 0.0
train_loss:
- 3.381
- 2.764
- 2.875
- 2.709
- 2.566
- 2.505
- 2.399
- 2.366
- 2.083
- 1.989
- 2.147
- 2.1
- 2.026
- 1.817
- 1.959
- 1.909
- 1.697
- 1.99
- 1.632
- 1.721
- 1.683
- 1.814
- 1.609
- 1.46
- 1.395
- 1.38
- 1.479
- 1.494
- 1.276
- 1.263
- 1.363
- 1.202
- 1.303
- 1.267
- 1.106
- 1.224
- 1.223
- 1.26
- 1.167
- 1.034
- 0.997
- 1.077
- 1.06
- 1.058
- 1.0
- 1.014
- 0.976
- 0.981
- 0.932
- 0.887
- 0.796
- 0.781
- 0.877
- 0.833
- 0.882
- 0.828
- 0.736
- 0.689
- 0.762
- 0.744
- 0.717
- 0.73
- 0.722
- 0.632
- 0.666
- 0.65
- 0.691
- 0.576
- 0.677
- 0.55
- 0.558
- 0.572
- 0.567
- 0.523
- 0.558
- 0.492
- 0.478
- 0.514
- 0.501
- 0.493
- 0.521
- 0.5
- 0.465
- 0.428
- 0.448
- 0.409
- 0.467
- 0.405
- 0.388
- 0.428
- 0.435
- 0.429
- 0.399
- 0.409
- 0.373
- 0.358
- 0.355
- 0.365
- 0.36
- 0.321
unequal: 0
verbose: 1
