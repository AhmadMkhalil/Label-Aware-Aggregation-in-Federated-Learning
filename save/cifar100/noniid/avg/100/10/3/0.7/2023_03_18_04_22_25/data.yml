avg_train_accuracy: 0.42
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0331
- 0.0969
- 0.1112
- 0.1299
- 0.1352
- 0.1459
- 0.1549
- 0.1622
- 0.1692
- 0.1755
- 0.18
- 0.1857
- 0.1889
- 0.1954
- 0.1969
- 0.2013
- 0.2079
- 0.2118
- 0.2158
- 0.2143
- 0.2189
- 0.2195
- 0.2226
- 0.2233
- 0.2204
- 0.2261
- 0.231
- 0.2319
- 0.2366
- 0.2362
- 0.2415
- 0.2422
- 0.243
- 0.2412
- 0.2456
- 0.2435
- 0.2573
- 0.2505
- 0.2515
- 0.2533
- 0.2568
- 0.2547
- 0.2637
- 0.2548
- 0.2607
- 0.2588
- 0.2614
- 0.2595
- 0.2683
- 0.2674
- 0.2597
- 0.2587
- 0.2686
- 0.2644
- 0.2727
- 0.2675
- 0.2768
- 0.2724
- 0.2704
- 0.2741
- 0.2813
- 0.2782
- 0.2715
- 0.2767
- 0.2743
- 0.2736
- 0.2845
- 0.2723
- 0.2785
- 0.2784
- 0.286
- 0.2799
- 0.28
- 0.291
- 0.28
- 0.291
- 0.2847
- 0.2929
- 0.28
- 0.2816
- 0.2904
- 0.2853
- 0.2858
- 0.2856
- 0.2861
- 0.2802
- 0.2847
- 0.2843
- 0.2857
- 0.2964
- 0.2927
- 0.2806
- 0.288
- 0.2888
- 0.2897
- 0.2905
- 0.2831
- 0.287
- 0.3017
- 0.3016
test_loss_list:
- 1.8243546438217164
- 1.733716049194336
- 1.6611284446716308
- 1.6510212516784668
- 1.593000864982605
- 1.5991500091552735
- 1.6393867349624633
- 1.5923670983314515
- 1.5270042634010315
- 1.5930728507041931
- 1.562393877506256
- 1.4918443965911865
- 1.5079213762283326
- 1.5136571288108827
- 1.5555005717277526
- 1.459923677444458
- 1.4319764041900636
- 1.4188442492485047
- 1.4091523098945617
- 1.4474456357955932
- 1.4075221300125123
- 1.4357970428466797
- 1.4429696440696715
- 1.447600347995758
- 1.5685062551498412
- 1.4768040013313293
- 1.454569206237793
- 1.5041335391998292
- 1.4566626381874084
- 1.4387077713012695
- 1.3758280396461486
- 1.4062439751625062
- 1.4087948155403138
- 1.4604117751121521
- 1.4241136646270751
- 1.4060976243019103
- 1.3496456575393676
- 1.3834016251564025
- 1.4396727728843688
- 1.4020600605010987
- 1.394231436252594
- 1.3935721397399903
- 1.3320809483528138
- 1.4225018405914307
- 1.3924964666366577
- 1.446542444229126
- 1.3922448301315307
- 1.3748843717575072
- 1.32346928358078
- 1.3578681921958924
- 1.423729944229126
- 1.3738118267059327
- 1.3693152809143065
- 1.4308429956436157
- 1.3285816764831544
- 1.3578394079208373
- 1.3132698941230774
- 1.3510323548316956
- 1.3527739000320436
- 1.3597919201850892
- 1.3073509645462036
- 1.3434792900085448
- 1.406418628692627
- 1.3560557055473328
- 1.3561848616600036
- 1.3454196071624756
- 1.3003055548667908
- 1.3934526753425598
- 1.3640227603912354
- 1.3619450783729554
- 1.3015792965888977
- 1.3322528672218323
- 1.3377709293365478
- 1.2919739031791686
- 1.3311964392662048
- 1.2932304382324218
- 1.3252660155296325
- 1.2852054691314698
- 1.3795386838912964
- 1.341389970779419
- 1.2941771864891052
- 1.3272554278373718
- 1.3312403964996338
- 1.3316199493408203
- 1.337051293849945
- 1.4010919284820558
- 1.3634036684036255
- 1.3451334762573242
- 1.332435131072998
- 1.2881740069389342
- 1.3219309401512147
- 1.3869458174705505
- 1.350314702987671
- 1.3371567273139953
- 1.3323406195640564
- 1.3376318383216859
- 1.3823233532905579
- 1.3449238133430481
- 1.291760983467102
- 1.2879752206802368
train_accuracy:
- 0.038
- 0.113
- 0.0
- 0.168
- 0.182
- 0.0
- 0.237
- 0.257
- 0.259
- 0.237
- 0.254
- 0.0
- 0.296
- 0.303
- 0.241
- 0.258
- 0.31
- 0.0
- 0.0
- 0.271
- 0.336
- 0.274
- 0.275
- 0.276
- 0.296
- 0.344
- 0.355
- 0.372
- 0.304
- 0.0
- 0.0
- 0.303
- 0.313
- 0.381
- 0.305
- 0.314
- 0.376
- 0.34
- 0.325
- 0.0
- 0.0
- 0.317
- 0.0
- 0.312
- 0.0
- 0.319
- 0.402
- 0.0
- 0.0
- 0.311
- 0.409
- 0.328
- 0.0
- 0.399
- 0.316
- 0.335
- 0.405
- 0.0
- 0.328
- 0.4
- 0.409
- 0.37
- 0.37
- 0.376
- 0.0
- 0.0
- 0.327
- 0.337
- 0.0
- 0.36
- 0.422
- 0.0
- 0.346
- 0.0
- 0.0
- 0.325
- 0.0
- 0.327
- 0.428
- 0.436
- 0.408
- 0.419
- 0.0
- 0.0
- 0.0
- 0.348
- 0.0
- 0.372
- 0.346
- 0.425
- 0.0
- 0.341
- 0.427
- 0.348
- 0.374
- 0.351
- 0.428
- 0.379
- 0.408
- 0.42
train_loss:
- 3.366
- 3.056
- 2.591
- 2.695
- 2.385
- 2.499
- 2.63
- 2.351
- 2.079
- 2.387
- 2.133
- 1.918
- 2.021
- 1.97
- 2.137
- 1.748
- 1.671
- 1.631
- 1.613
- 1.705
- 1.538
- 1.637
- 1.6
- 1.556
- 1.835
- 1.523
- 1.445
- 1.55
- 1.369
- 1.387
- 1.236
- 1.328
- 1.298
- 1.386
- 1.215
- 1.227
- 1.079
- 1.168
- 1.234
- 1.128
- 1.076
- 1.053
- 0.979
- 1.084
- 0.974
- 1.078
- 0.954
- 0.951
- 0.842
- 0.878
- 0.946
- 0.89
- 0.849
- 0.882
- 0.735
- 0.782
- 0.685
- 0.732
- 0.71
- 0.708
- 0.689
- 0.686
- 0.774
- 0.722
- 0.653
- 0.677
- 0.604
- 0.66
- 0.575
- 0.578
- 0.553
- 0.587
- 0.562
- 0.505
- 0.525
- 0.501
- 0.537
- 0.473
- 0.539
- 0.483
- 0.462
- 0.472
- 0.464
- 0.45
- 0.434
- 0.459
- 0.416
- 0.415
- 0.418
- 0.396
- 0.396
- 0.412
- 0.378
- 0.37
- 0.386
- 0.373
- 0.364
- 0.358
- 0.332
- 0.324
unequal: 0
verbose: 1
