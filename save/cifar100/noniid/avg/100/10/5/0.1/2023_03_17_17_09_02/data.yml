avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0311
- 0.0409
- 0.0459
- 0.0505
- 0.0464
- 0.0754
- 0.0997
- 0.1117
- 0.0481
- 0.1195
- 0.1314
- 0.0503
- 0.043
- 0.0558
- 0.0502
- 0.0567
- 0.0576
- 0.1295
- 0.1409
- 0.149
- 0.1524
- 0.1593
- 0.0507
- 0.1624
- 0.1661
- 0.0533
- 0.0532
- 0.1734
- 0.0562
- 0.0538
- 0.0542
- 0.0501
- 0.1679
- 0.0562
- 0.1775
- 0.0557
- 0.1789
- 0.1745
- 0.1824
- 0.1888
- 0.1804
- 0.1817
- 0.1888
- 0.1899
- 0.059
- 0.0571
- 0.0585
- 0.1946
- 0.0635
- 0.195
- 0.1876
- 0.0618
- 0.0622
- 0.0588
- 0.0573
- 0.06
- 0.2042
- 0.0688
- 0.063
- 0.0611
- 0.0585
- 0.0593
- 0.198
- 0.2074
- 0.2021
- 0.0679
- 0.1988
- 0.0655
- 0.2054
- 0.0657
- 0.0592
- 0.2116
- 0.0696
- 0.2123
- 0.0671
- 0.0651
- 0.2081
- 0.0748
- 0.2131
- 0.0689
- 0.2135
- 0.0756
- 0.0678
- 0.0702
- 0.2164
- 0.0709
- 0.0654
- 0.2173
- 0.2184
- 0.0772
- 0.0697
- 0.0653
- 0.0691
- 0.224
- 0.2213
- 0.2191
- 0.0865
- 0.0769
- 0.0717
- 0.0721
test_loss_list:
- 2.764650402069092
- 3.3989634799957273
- 3.7173171710968016
- 3.5081917095184325
- 3.563515377044678
- 1.991368374824524
- 2.1127238607406618
- 2.1774395418167116
- 3.336877965927124
- 2.129301390647888
- 2.1843023443222047
- 3.425379128456116
- 3.325519723892212
- 3.21394229888916
- 3.332824697494507
- 3.3483001232147216
- 3.533374137878418
- 1.9735896158218384
- 2.060847463607788
- 2.11660897731781
- 2.1536497020721437
- 2.202518162727356
- 3.347118492126465
- 2.104652214050293
- 2.165241732597351
- 3.2703834104537965
- 3.2203593826293946
- 1.9654979848861693
- 3.1711798810958864
- 3.4492314720153807
- 3.178324990272522
- 3.053274221420288
- 1.85991464138031
- 3.1126990842819215
- 1.89471538066864
- 3.0455416011810303
- 1.9197703886032105
- 2.0347957468032836
- 2.0934271574020387
- 2.071070976257324
- 2.1431702852249144
- 2.204282970428467
- 2.2148176860809325
- 2.2251189947128296
- 3.2721038627624512
- 3.0980154132843016
- 2.99254478931427
- 1.8945917320251464
- 2.8923563146591187
- 1.8693662214279174
- 1.953577799797058
- 3.023226113319397
- 3.015750322341919
- 2.91099823474884
- 2.993390636444092
- 3.0441131448745726
- 1.7832994556427002
- 2.9206105184555056
- 3.129823155403137
- 3.283446397781372
- 2.9786833143234253
- 2.830843324661255
- 1.779056088924408
- 1.850159728527069
- 1.9331956005096436
- 2.912199912071228
- 1.8714284706115722
- 2.8531686592102052
- 1.8392750692367554
- 2.8646859312057495
- 2.8182605409622195
- 1.7595528912544252
- 2.813901038169861
- 1.80548522233963
- 2.896116771697998
- 2.8126673698425293
- 1.8139332842826843
- 2.784095215797424
- 1.8408140778541564
- 2.9113019418716433
- 1.8716345095634461
- 2.7399750757217407
- 2.7744768333435057
- 2.8979443502426148
- 1.7988502097129822
- 2.7786878824234007
- 2.9799069452285765
- 1.7963931894302367
- 1.8437786817550659
- 2.772386646270752
- 2.785482325553894
- 2.762188377380371
- 2.7093002891540525
- 1.689830276966095
- 1.8035893964767455
- 1.8480071926116943
- 2.7224547338485716
- 2.750201606750488
- 2.609815158843994
- 2.7036277770996096
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.119
- 0.205
- 0.159
- 0.0
- 0.222
- 0.261
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.259
- 0.276
- 0.298
- 0.35
- 0.311
- 0.0
- 0.303
- 0.36
- 0.0
- 0.0
- 0.346
- 0.0
- 0.0
- 0.0
- 0.0
- 0.35
- 0.0
- 0.361
- 0.0
- 0.289
- 0.299
- 0.347
- 0.394
- 0.38
- 0.291
- 0.378
- 0.399
- 0.0
- 0.0
- 0.0
- 0.376
- 0.0
- 0.367
- 0.359
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.371
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.32
- 0.419
- 0.397
- 0.0
- 0.387
- 0.0
- 0.407
- 0.0
- 0.0
- 0.373
- 0.0
- 0.38
- 0.0
- 0.0
- 0.349
- 0.0
- 0.343
- 0.0
- 0.386
- 0.0
- 0.0
- 0.0
- 0.398
- 0.0
- 0.0
- 0.418
- 0.407
- 0.0
- 0.0
- 0.0
- 0.0
- 0.344
- 0.424
- 0.349
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 1.746
- 1.984
- 1.054
- 1.884
- 1.714
- 3.898
- 2.945
- 2.475
- 1.619
- 2.771
- 2.523
- 1.268
- 2.073
- 1.601
- 1.317
- 1.008
- 0.564
- 3.091
- 2.201
- 2.18
- 2.32
- 1.846
- 1.242
- 2.264
- 1.959
- 1.263
- 1.611
- 2.011
- 0.996
- 0.513
- 1.09
- 1.639
- 2.093
- 1.053
- 2.175
- 1.033
- 2.074
- 1.395
- 1.74
- 1.52
- 1.109
- 1.332
- 1.379
- 1.451
- 1.052
- 1.118
- 1.1
- 1.456
- 1.052
- 1.448
- 1.02
- 0.737
- 0.945
- 0.897
- 0.602
- 0.649
- 1.386
- 0.513
- 0.226
- 0.171
- 0.673
- 1.129
- 1.516
- 1.148
- 0.886
- 0.81
- 1.706
- 0.755
- 1.174
- 0.775
- 0.701
- 1.02
- 0.388
- 0.742
- 0.588
- 0.745
- 1.247
- 0.441
- 0.884
- 0.573
- 1.451
- 0.655
- 0.515
- 0.39
- 1.17
- 0.747
- 0.234
- 1.245
- 0.755
- 0.457
- 0.55
- 0.674
- 0.526
- 0.953
- 0.79
- 0.536
- 0.378
- 0.518
- 0.696
- 0.315
unequal: 0
verbose: 1
