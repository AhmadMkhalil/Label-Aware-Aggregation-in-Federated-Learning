avg_train_accuracy: 0.346
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0572
- 0.0815
- 0.0423
- 0.1029
- 0.0495
- 0.048
- 0.1213
- 0.124
- 0.1403
- 0.1478
- 0.1565
- 0.1634
- 0.1651
- 0.0527
- 0.1659
- 0.1766
- 0.1803
- 0.1951
- 0.2011
- 0.2013
- 0.2003
- 0.1981
- 0.2118
- 0.2154
- 0.2091
- 0.2197
- 0.2283
- 0.2182
- 0.0561
- 0.2275
- 0.2263
- 0.2275
- 0.2293
- 0.2349
- 0.2408
- 0.2447
- 0.2435
- 0.0583
- 0.2478
- 0.2551
- 0.2552
- 0.2611
- 0.2555
- 0.2613
- 0.2601
- 0.2565
- 0.2688
- 0.263
- 0.2673
- 0.2674
- 0.2674
- 0.2726
- 0.268
- 0.2694
- 0.2656
- 0.2707
- 0.2689
- 0.2713
- 0.2664
- 0.2739
- 0.2795
- 0.2757
- 0.2814
- 0.2806
- 0.2797
- 0.2781
- 0.2857
- 0.2828
- 0.2841
- 0.2822
- 0.2785
- 0.2748
- 0.2798
- 0.2862
- 0.2819
- 0.282
- 0.065
- 0.2894
- 0.2837
- 0.2755
- 0.2944
- 0.2873
- 0.2774
- 0.2912
- 0.2942
- 0.284
- 0.2842
- 0.2947
- 0.2972
- 0.3013
- 0.0805
- 0.3029
- 0.296
- 0.3064
- 0.2934
- 0.2938
- 0.3026
- 0.0847
- 0.3126
- 0.3131
test_loss_list:
- 1.7951471662521363
- 1.7382929039001465
- 3.1482088375091553
- 1.6566720581054688
- 3.1296520757675172
- 3.383406858444214
- 1.5946038103103637
- 1.601162736415863
- 1.5729451775550842
- 1.577034146785736
- 1.5818972611427307
- 1.5535674953460694
- 1.5447985482215882
- 2.915288419723511
- 1.4770088076591492
- 1.4702631521224976
- 1.475939781665802
- 1.4711314678192138
- 1.4750846576690675
- 1.473497085571289
- 1.4731956696510315
- 1.4893793272972107
- 1.46514404296875
- 1.4711826586723327
- 1.488828330039978
- 1.479369294643402
- 1.4629430890083313
- 1.4586621665954589
- 2.8067797517776487
- 1.3605901503562927
- 1.3837331938743591
- 1.405965087413788
- 1.3957150101661682
- 1.412036747932434
- 1.3905920553207398
- 1.3813567328453065
- 1.3964587020874024
- 2.7473504638671873
- 1.3240779280662536
- 1.3339483523368836
- 1.3413299345970153
- 1.3516730642318726
- 1.3583906388282776
- 1.3544538307189942
- 1.3547848296165466
- 1.3650472521781922
- 1.354842059612274
- 1.3880573344230651
- 1.3694004678726197
- 1.368927550315857
- 1.3872519326210022
- 1.3729608750343323
- 1.401010389328003
- 1.3851525592803955
- 1.3813405275344848
- 1.3740481567382812
- 1.3855664587020875
- 1.3990035653114319
- 1.401534810066223
- 1.3979937243461609
- 1.3866590404510497
- 1.3920245122909547
- 1.380809874534607
- 1.3940727472305299
- 1.3913754296302796
- 1.4087700247764587
- 1.3949369597434997
- 1.40903466463089
- 1.4173013615608214
- 1.4311543202400208
- 1.4073981380462646
- 1.4197309803962708
- 1.4227180671691895
- 1.4094724941253662
- 1.4259271502494812
- 1.4308292937278748
- 2.6689400720596312
- 1.2729753637313843
- 1.3128309273719787
- 1.3414622402191163
- 1.306352458000183
- 1.3462064480781555
- 1.380181429386139
- 1.3305898356437682
- 1.3310286211967468
- 1.3540474104881286
- 1.3752630209922792
- 1.3614806318283081
- 1.3491035056114198
- 1.3508654713630677
- 2.5149473476409914
- 1.2592138504981996
- 1.2751740670204164
- 1.2774982643127442
- 1.3088460087776184
- 1.3248505091667175
- 1.3222314763069152
- 2.5185405111312864
- 1.247952525615692
- 1.2563135051727294
train_accuracy:
- 0.057
- 0.102
- 0.0
- 0.121
- 0.0
- 0.0
- 0.091
- 0.113
- 0.14
- 0.169
- 0.168
- 0.13
- 0.206
- 0.0
- 0.139
- 0.187
- 0.178
- 0.172
- 0.215
- 0.189
- 0.209
- 0.198
- 0.213
- 0.231
- 0.23
- 0.204
- 0.231
- 0.215
- 0.0
- 0.249
- 0.222
- 0.222
- 0.264
- 0.207
- 0.224
- 0.276
- 0.286
- 0.0
- 0.266
- 0.259
- 0.264
- 0.273
- 0.267
- 0.233
- 0.283
- 0.253
- 0.259
- 0.288
- 0.27
- 0.287
- 0.284
- 0.308
- 0.3
- 0.266
- 0.285
- 0.277
- 0.27
- 0.292
- 0.274
- 0.287
- 0.267
- 0.298
- 0.294
- 0.26
- 0.269
- 0.281
- 0.318
- 0.335
- 0.331
- 0.316
- 0.294
- 0.253
- 0.311
- 0.303
- 0.317
- 0.311
- 0.0
- 0.303
- 0.249
- 0.255
- 0.284
- 0.271
- 0.248
- 0.304
- 0.293
- 0.263
- 0.265
- 0.313
- 0.312
- 0.327
- 0.0
- 0.3
- 0.3
- 0.353
- 0.308
- 0.264
- 0.332
- 0.0
- 0.328
- 0.346
train_loss:
- 4.274
- 3.777
- 1.884
- 3.626
- 1.381
- 0.806
- 3.787
- 2.942
- 3.283
- 3.232
- 2.755
- 3.146
- 3.015
- 1.262
- 2.986
- 2.785
- 2.582
- 2.836
- 2.574
- 2.683
- 2.612
- 2.753
- 2.252
- 2.208
- 1.785
- 2.328
- 2.229
- 2.356
- 1.176
- 2.025
- 1.978
- 2.009
- 2.296
- 2.322
- 2.247
- 2.294
- 1.947
- 0.986
- 2.178
- 1.914
- 1.612
- 1.766
- 1.66
- 1.591
- 1.967
- 1.915
- 1.8
- 1.452
- 1.612
- 1.469
- 1.195
- 1.472
- 0.951
- 1.362
- 1.623
- 1.673
- 1.241
- 0.945
- 1.009
- 1.325
- 1.391
- 0.965
- 1.374
- 1.074
- 1.18
- 0.816
- 1.276
- 0.88
- 0.569
- 0.419
- 1.038
- 1.752
- 0.515
- 0.818
- 0.383
- 0.29
- 1.069
- 1.42
- 1.416
- 0.9
- 1.524
- 0.773
- 0.538
- 1.182
- 1.103
- 0.616
- 0.383
- 1.1
- 1.105
- 1.039
- 0.786
- 0.989
- 1.013
- 0.509
- 0.605
- 0.405
- 0.823
- 0.632
- 1.163
- 0.42
unequal: 0
verbose: 1
