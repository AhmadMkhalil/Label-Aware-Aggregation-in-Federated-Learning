avg_train_accuracy: 0.295
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0549
- 0.0889
- 0.1002
- 0.1148
- 0.1268
- 0.1399
- 0.1503
- 0.1517
- 0.168
- 0.1634
- 0.1632
- 0.1749
- 0.1755
- 0.1813
- 0.1861
- 0.1923
- 0.1914
- 0.1925
- 0.2008
- 0.1996
- 0.2133
- 0.2003
- 0.218
- 0.2112
- 0.2194
- 0.2144
- 0.2156
- 0.2227
- 0.2286
- 0.2236
- 0.2256
- 0.2369
- 0.2327
- 0.2431
- 0.2443
- 0.2421
- 0.0551
- 0.2422
- 0.2351
- 0.2474
- 0.2507
- 0.2452
- 0.2465
- 0.2557
- 0.2525
- 0.2562
- 0.2574
- 0.2536
- 0.2611
- 0.2743
- 0.2554
- 0.2677
- 0.2645
- 0.2723
- 0.0626
- 0.2748
- 0.2658
- 0.2695
- 0.269
- 0.2658
- 0.263
- 0.2758
- 0.2663
- 0.2594
- 0.2681
- 0.2755
- 0.2723
- 0.2787
- 0.2857
- 0.2898
- 0.2855
- 0.07
- 0.2859
- 0.275
- 0.2835
- 0.2844
- 0.2913
- 0.2892
- 0.2836
- 0.2882
- 0.285
- 0.2902
- 0.299
- 0.301
- 0.2942
- 0.2944
- 0.2971
- 0.2921
- 0.2909
- 0.2912
- 0.2913
- 0.2923
- 0.2945
- 0.3001
- 0.2958
- 0.3062
- 0.2976
- 0.3002
- 0.3028
- 0.3052
test_loss_list:
- 1.8042725801467896
- 1.7368383073806763
- 1.7035167336463928
- 1.6751138401031493
- 1.6493311786651612
- 1.6431098008155822
- 1.6358048796653748
- 1.6254653167724609
- 1.6016686511039735
- 1.597107331752777
- 1.6150053763389587
- 1.5909356236457826
- 1.6026355981826783
- 1.5777915120124817
- 1.5828089261054992
- 1.5620737266540528
- 1.573659360408783
- 1.5663555216789247
- 1.555922088623047
- 1.575052936077118
- 1.5479382348060609
- 1.5724432396888732
- 1.5343771409988403
- 1.5477015256881714
- 1.5459409904479982
- 1.546556189060211
- 1.549833209514618
- 1.5473015594482422
- 1.5214756584167481
- 1.5375697922706604
- 1.5380331420898437
- 1.5317521595954895
- 1.5186496591567993
- 1.5118474793434142
- 1.5019239592552185
- 1.5099332928657532
- 2.8905211067199708
- 1.3349393010139465
- 1.3713471817970275
- 1.396526951789856
- 1.3859498929977416
- 1.3932004833221436
- 1.3848784708976745
- 1.4086438179016114
- 1.3895274376869202
- 1.4054004311561585
- 1.3957083630561828
- 1.4072341227531433
- 1.3954342651367186
- 1.3903858327865601
- 1.4176118969917297
- 1.414921612739563
- 1.4118494486808777
- 1.420921218395233
- 2.748694448471069
- 1.2847266221046447
- 1.3320315265655518
- 1.3311159205436707
- 1.3584892678260803
- 1.3639232039451599
- 1.3802526426315307
- 1.3482434272766113
- 1.3826725316047668
- 1.39563583612442
- 1.407436239719391
- 1.3709001994132997
- 1.3820097184181213
- 1.401632707118988
- 1.3644189500808717
- 1.3546212482452393
- 1.3645053243637084
- 2.6470357990264892
- 1.2619767689704895
- 1.3163072872161865
- 1.3075852465629578
- 1.3234009313583375
- 1.3159516668319702
- 1.3184300136566163
- 1.3379127335548402
- 1.3333466243743897
- 1.3585826873779296
- 1.351319556236267
- 1.3203450298309327
- 1.3309806752204896
- 1.3429706716537475
- 1.3691468477249145
- 1.3467668032646178
- 1.3608490824699402
- 1.3802158284187316
- 1.37768034696579
- 1.4002248668670654
- 1.3721865177154542
- 1.3797733354568482
- 1.3732877278327942
- 1.3883919978141785
- 1.3564515805244446
- 1.3853606986999512
- 1.367325644493103
- 1.3645904874801635
- 1.38257253408432
train_accuracy:
- 0.084
- 0.083
- 0.142
- 0.106
- 0.152
- 0.135
- 0.156
- 0.123
- 0.186
- 0.191
- 0.189
- 0.178
- 0.182
- 0.206
- 0.204
- 0.183
- 0.19
- 0.178
- 0.227
- 0.2
- 0.181
- 0.203
- 0.206
- 0.246
- 0.173
- 0.19
- 0.205
- 0.22
- 0.275
- 0.231
- 0.198
- 0.206
- 0.277
- 0.319
- 0.296
- 0.277
- 0.0
- 0.247
- 0.238
- 0.235
- 0.345
- 0.222
- 0.308
- 0.276
- 0.327
- 0.252
- 0.268
- 0.291
- 0.355
- 0.258
- 0.336
- 0.283
- 0.316
- 0.258
- 0.0
- 0.277
- 0.338
- 0.331
- 0.34
- 0.356
- 0.371
- 0.334
- 0.363
- 0.33
- 0.286
- 0.262
- 0.253
- 0.288
- 0.288
- 0.289
- 0.385
- 0.0
- 0.292
- 0.326
- 0.274
- 0.376
- 0.281
- 0.359
- 0.276
- 0.382
- 0.354
- 0.297
- 0.386
- 0.3
- 0.4
- 0.312
- 0.397
- 0.373
- 0.38
- 0.273
- 0.315
- 0.314
- 0.271
- 0.368
- 0.293
- 0.299
- 0.297
- 0.41
- 0.335
- 0.295
train_loss:
- 4.266
- 3.733
- 3.602
- 3.494
- 3.242
- 3.068
- 2.871
- 3.258
- 3.132
- 3.086
- 2.616
- 2.762
- 2.323
- 2.601
- 2.813
- 2.726
- 2.396
- 2.355
- 2.421
- 2.132
- 2.466
- 1.858
- 2.566
- 2.52
- 2.154
- 2.151
- 1.677
- 2.144
- 2.174
- 1.723
- 1.939
- 1.822
- 2.096
- 2.432
- 1.891
- 2.02
- 1.815
- 2.072
- 1.332
- 1.63
- 2.104
- 1.715
- 1.77
- 1.523
- 1.572
- 1.381
- 1.952
- 1.528
- 1.731
- 1.425
- 1.315
- 1.301
- 1.313
- 1.127
- 1.319
- 1.633
- 1.084
- 0.759
- 0.571
- 1.302
- 0.798
- 1.688
- 0.773
- 1.22
- 1.309
- 1.173
- 0.913
- 1.146
- 1.038
- 1.568
- 0.833
- 1.069
- 1.165
- 1.284
- 0.673
- 0.693
- 0.563
- 1.129
- 0.887
- 0.839
- 0.488
- 1.311
- 0.893
- 0.603
- 0.591
- 0.898
- 0.468
- 0.558
- 0.312
- 0.487
- 0.681
- 1.057
- 0.767
- 0.759
- 0.895
- 0.465
- 0.554
- 0.473
- 0.777
- 0.653
unequal: 0
verbose: 1
