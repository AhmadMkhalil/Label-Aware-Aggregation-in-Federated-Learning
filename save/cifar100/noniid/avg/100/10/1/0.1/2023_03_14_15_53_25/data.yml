avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0322
- 0.0842
- 0.1076
- 0.1238
- 0.0433
- 0.0505
- 0.1272
- 0.1408
- 0.1532
- 0.1548
- 0.1556
- 0.1676
- 0.1706
- 0.1787
- 0.1834
- 0.1725
- 0.1816
- 0.1912
- 0.2047
- 0.0533
- 0.2
- 0.207
- 0.2109
- 0.208
- 0.2205
- 0.2164
- 0.2176
- 0.2221
- 0.2293
- 0.2201
- 0.2101
- 0.2274
- 0.2174
- 0.2371
- 0.2343
- 0.2368
- 0.2385
- 0.2366
- 0.2449
- 0.2376
- 0.238
- 0.2491
- 0.2438
- 0.2495
- 0.2526
- 0.2587
- 0.2441
- 0.2606
- 0.0611
- 0.2628
- 0.2573
- 0.25
- 0.2621
- 0.2595
- 0.2632
- 0.0637
- 0.0629
- 0.2516
- 0.2618
- 0.2644
- 0.2637
- 0.0686
- 0.2623
- 0.2711
- 0.2493
- 0.268
- 0.2768
- 0.2729
- 0.0746
- 0.2737
- 0.264
- 0.2709
- 0.2712
- 0.2798
- 0.2762
- 0.2711
- 0.2735
- 0.2802
- 0.2865
- 0.2828
- 0.2893
- 0.2792
- 0.2842
- 0.2824
- 0.2841
- 0.277
- 0.2868
- 0.0805
- 0.2918
- 0.2923
- 0.2873
- 0.0865
- 0.2979
- 0.2973
- 0.2911
- 0.2886
- 0.0969
- 0.3011
- 0.2908
- 0.091
test_loss_list:
- 1.8386996698379516
- 1.7335656309127807
- 1.7120868921279908
- 1.6820924592018127
- 3.1519430446624757
- 3.475842933654785
- 1.5734078669548035
- 1.57596764087677
- 1.5631913948059082
- 1.5608823537826537
- 1.5613020873069763
- 1.5572112584114075
- 1.5709580993652343
- 1.5422885942459106
- 1.540684928894043
- 1.5764671063423157
- 1.5633922743797302
- 1.533044285774231
- 1.510820288658142
- 2.930327787399292
- 1.4203742909431458
- 1.4270836925506591
- 1.432667112350464
- 1.4454201102256774
- 1.4395127820968627
- 1.4413998460769653
- 1.462171950340271
- 1.4608543419837952
- 1.4408572173118592
- 1.458260142803192
- 1.483905291557312
- 1.472337167263031
- 1.4933648943901061
- 1.4444187450408936
- 1.4511137747764586
- 1.4587033319473266
- 1.4485243821144105
- 1.463819501399994
- 1.4604914855957032
- 1.4602815771102906
- 1.4680209827423096
- 1.4711368680000305
- 1.4712479209899902
- 1.477223632335663
- 1.442652976512909
- 1.433040668964386
- 1.467096745967865
- 1.4589022827148437
- 2.7481356048583985
- 1.304845371246338
- 1.3498021960258484
- 1.3804801154136657
- 1.3490675234794616
- 1.3688324618339538
- 1.3575580358505248
- 2.6948477935791018
- 2.872927746772766
- 1.3386705493927002
- 1.3235602712631225
- 1.3521764516830443
- 1.3596706533432006
- 2.613430895805359
- 1.2843698477745056
- 1.3145449590682983
- 1.3760742807388306
- 1.3383466839790343
- 1.3418316984176635
- 1.341675465106964
- 2.5655390787124634
- 1.2874125123023987
- 1.3137026381492616
- 1.321056821346283
- 1.322362141609192
- 1.3191118836402893
- 1.3472169494628907
- 1.346575710773468
- 1.3526522278785706
- 1.3388591599464417
- 1.3424772000312806
- 1.35103586435318
- 1.3587778902053833
- 1.3684493970870972
- 1.36576313495636
- 1.360518319606781
- 1.367774920463562
- 1.3871487092971801
- 1.3634436011314393
- 2.5003855657577514
- 1.2662565064430238
- 1.2861912393569945
- 1.3047741103172301
- 2.478401050567627
- 1.2585733366012573
- 1.2732510876655578
- 1.2980181717872619
- 1.3106842160224914
- 2.408892331123352
- 1.2578671169281006
- 1.271431941986084
- 2.430977506637573
train_accuracy:
- 0.036
- 0.065
- 0.133
- 0.128
- 0.0
- 0.0
- 0.138
- 0.131
- 0.147
- 0.126
- 0.163
- 0.229
- 0.218
- 0.176
- 0.176
- 0.175
- 0.193
- 0.161
- 0.139
- 0.0
- 0.231
- 0.244
- 0.198
- 0.255
- 0.191
- 0.205
- 0.185
- 0.288
- 0.163
- 0.16
- 0.164
- 0.199
- 0.186
- 0.258
- 0.201
- 0.281
- 0.216
- 0.205
- 0.222
- 0.231
- 0.207
- 0.246
- 0.251
- 0.277
- 0.217
- 0.275
- 0.318
- 0.238
- 0.0
- 0.271
- 0.243
- 0.244
- 0.245
- 0.233
- 0.272
- 0.0
- 0.0
- 0.23
- 0.324
- 0.314
- 0.281
- 0.0
- 0.301
- 0.312
- 0.312
- 0.301
- 0.273
- 0.237
- 0.0
- 0.293
- 0.311
- 0.278
- 0.316
- 0.282
- 0.307
- 0.328
- 0.311
- 0.32
- 0.261
- 0.331
- 0.288
- 0.269
- 0.29
- 0.328
- 0.288
- 0.332
- 0.366
- 0.0
- 0.279
- 0.294
- 0.273
- 0.0
- 0.26
- 0.306
- 0.305
- 0.257
- 0.0
- 0.343
- 0.346
- 0.0
train_loss:
- 4.33
- 3.787
- 3.614
- 3.315
- 1.975
- 0.99
- 3.76
- 3.342
- 2.909
- 3.143
- 3.116
- 3.084
- 2.546
- 2.864
- 2.854
- 2.379
- 2.049
- 2.668
- 2.647
- 1.396
- 3.027
- 2.72
- 2.065
- 2.36
- 2.433
- 2.257
- 1.819
- 2.055
- 2.206
- 1.733
- 1.415
- 1.758
- 1.336
- 2.257
- 1.846
- 2.273
- 1.473
- 1.336
- 2.053
- 1.113
- 0.805
- 1.659
- 1.386
- 2.217
- 1.602
- 1.88
- 1.772
- 1.2
- 1.271
- 1.736
- 0.944
- 1.499
- 1.001
- 1.281
- 1.322
- 0.908
- 0.366
- 1.523
- 1.514
- 0.987
- 1.117
- 0.668
- 2.227
- 1.0
- 1.513
- 0.811
- 1.786
- 1.185
- 0.645
- 1.48
- 1.386
- 1.208
- 1.787
- 0.883
- 0.847
- 1.338
- 0.867
- 0.706
- 0.993
- 0.465
- 0.989
- 0.798
- 0.481
- 0.471
- 0.429
- 0.359
- 1.196
- 0.695
- 1.189
- 0.823
- 0.632
- 0.47
- 0.98
- 0.611
- 0.352
- 0.53
- 0.42
- 0.59
- 1.001
- 0.346
unequal: 0
verbose: 1
