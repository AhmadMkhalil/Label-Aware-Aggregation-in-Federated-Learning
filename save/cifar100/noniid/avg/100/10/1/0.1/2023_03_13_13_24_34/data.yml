avg_train_accuracy: 0.289
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0388
- 0.0867
- 0.1099
- 0.105
- 0.128
- 0.1335
- 0.1427
- 0.1544
- 0.1534
- 0.1591
- 0.1643
- 0.1736
- 0.1779
- 0.1777
- 0.0425
- 0.1796
- 0.1787
- 0.1867
- 0.2052
- 0.1997
- 0.1951
- 0.2071
- 0.2079
- 0.2048
- 0.2181
- 0.2165
- 0.0551
- 0.2212
- 0.223
- 0.2295
- 0.2304
- 0.0566
- 0.2388
- 0.2352
- 0.2388
- 0.2363
- 0.0584
- 0.2437
- 0.2442
- 0.061
- 0.2411
- 0.2478
- 0.0669
- 0.2474
- 0.2528
- 0.2506
- 0.2556
- 0.2528
- 0.0655
- 0.2626
- 0.2502
- 0.2598
- 0.2576
- 0.2665
- 0.2646
- 0.2625
- 0.0687
- 0.0651
- 0.2677
- 0.0742
- 0.2682
- 0.2753
- 0.2743
- 0.275
- 0.2762
- 0.2738
- 0.2803
- 0.2778
- 0.2715
- 0.279
- 0.2731
- 0.0772
- 0.2855
- 0.2879
- 0.2765
- 0.2562
- 0.2844
- 0.2829
- 0.283
- 0.2868
- 0.2874
- 0.2867
- 0.2857
- 0.2871
- 0.2954
- 0.2885
- 0.2911
- 0.2879
- 0.2923
- 0.2933
- 0.2964
- 0.2913
- 0.0854
- 0.2936
- 0.3055
- 0.2914
- 0.304
- 0.3015
- 0.3005
- 0.2958
test_loss_list:
- 1.8273989248275757
- 1.7451849746704102
- 1.713952898979187
- 1.7006133604049682
- 1.674956467151642
- 1.6546141052246093
- 1.656988160610199
- 1.634375603199005
- 1.6420293736457825
- 1.633363823890686
- 1.6351932287216187
- 1.6166871571540833
- 1.6187236666679383
- 1.6094020771980286
- 3.1235957193374633
- 1.4765159940719605
- 1.4991778492927552
- 1.501243908405304
- 1.4912314128875732
- 1.4975166654586791
- 1.5029485893249512
- 1.5054969668388367
- 1.4973507142066955
- 1.5053739905357362
- 1.4950066590309143
- 1.505242817401886
- 2.9655337810516356
- 1.3797605323791504
- 1.402662034034729
- 1.410692913532257
- 1.4260852193832398
- 2.889005823135376
- 1.3529928064346313
- 1.3736568021774291
- 1.3727201557159423
- 1.3910746669769287
- 2.8081377601623534
- 1.3266205954551697
- 1.3593161392211914
- 2.7526466178894045
- 1.3368130612373352
- 1.3320179629325866
- 2.6663970851898195
- 1.308392164707184
- 1.3266916489601135
- 1.345068507194519
- 1.3496092820167542
- 1.354039306640625
- 2.61683434009552
- 1.3006937336921691
- 1.3313266587257386
- 1.3275846099853517
- 1.3479687666893005
- 1.3377892208099365
- 1.3356550002098084
- 1.3519611167907715
- 2.5802460861206056
- 2.786269245147705
- 1.287831494808197
- 2.5573419761657714
- 1.28348464012146
- 1.2907813000679016
- 1.2923017978668212
- 1.3167587995529175
- 1.3046278524398804
- 1.3185139727592468
- 1.3153997993469237
- 1.333368992805481
- 1.3478497910499572
- 1.3479586362838745
- 1.3520837330818176
- 2.4617816972732545
- 1.2636183857917787
- 1.2564470672607422
- 1.3090374159812928
- 1.4072549986839293
- 1.3152900528907776
- 1.3295350503921508
- 1.340116937160492
- 1.3263886022567748
- 1.3281856179237366
- 1.3298886919021606
- 1.3469767928123475
- 1.332157506942749
- 1.339161949157715
- 1.3386989498138429
- 1.3455427861213685
- 1.3646611857414246
- 1.345249445438385
- 1.3485819220542907
- 1.3573551154136658
- 1.3370836544036866
- 2.4178146600723265
- 1.265195927619934
- 1.258017611503601
- 1.294877395629883
- 1.2789967846870423
- 1.2931807398796082
- 1.3094886541366577
- 1.3056855034828185
train_accuracy:
- 0.053
- 0.08
- 0.088
- 0.144
- 0.112
- 0.137
- 0.168
- 0.176
- 0.191
- 0.171
- 0.176
- 0.18
- 0.188
- 0.161
- 0.0
- 0.198
- 0.209
- 0.174
- 0.213
- 0.227
- 0.218
- 0.207
- 0.22
- 0.189
- 0.223
- 0.234
- 0.0
- 0.233
- 0.257
- 0.216
- 0.276
- 0.0
- 0.253
- 0.281
- 0.267
- 0.225
- 0.0
- 0.234
- 0.231
- 0.0
- 0.278
- 0.259
- 0.0
- 0.239
- 0.269
- 0.225
- 0.269
- 0.226
- 0.0
- 0.29
- 0.239
- 0.271
- 0.251
- 0.282
- 0.292
- 0.28
- 0.0
- 0.0
- 0.257
- 0.0
- 0.241
- 0.279
- 0.241
- 0.273
- 0.295
- 0.307
- 0.312
- 0.266
- 0.292
- 0.313
- 0.298
- 0.0
- 0.292
- 0.32
- 0.315
- 0.287
- 0.304
- 0.319
- 0.313
- 0.275
- 0.301
- 0.307
- 0.322
- 0.324
- 0.327
- 0.273
- 0.319
- 0.331
- 0.275
- 0.328
- 0.316
- 0.336
- 0.0
- 0.329
- 0.314
- 0.31
- 0.336
- 0.33
- 0.313
- 0.289
train_loss:
- 4.239
- 3.833
- 3.382
- 3.5
- 3.436
- 3.315
- 3.032
- 3.18
- 2.686
- 2.673
- 3.051
- 2.956
- 2.631
- 2.937
- 1.88
- 2.767
- 1.999
- 2.778
- 2.59
- 2.423
- 2.359
- 2.169
- 2.548
- 2.744
- 2.354
- 1.888
- 1.437
- 2.753
- 2.177
- 2.112
- 1.779
- 1.055
- 2.408
- 1.936
- 2.061
- 1.788
- 0.924
- 2.557
- 2.003
- 0.759
- 1.83
- 1.822
- 0.666
- 1.766
- 1.645
- 1.985
- 1.321
- 1.323
- 0.681
- 1.951
- 1.091
- 2.068
- 1.716
- 1.584
- 1.715
- 1.673
- 0.662
- 0.247
- 1.583
- 0.415
- 1.867
- 1.297
- 1.045
- 0.912
- 1.49
- 1.433
- 0.817
- 0.865
- 1.124
- 1.437
- 0.874
- 0.583
- 1.372
- 1.449
- 0.921
- 1.383
- 0.849
- 0.51
- 0.391
- 0.978
- 1.037
- 1.269
- 0.972
- 0.619
- 0.865
- 1.405
- 1.208
- 0.703
- 0.994
- 1.036
- 0.62
- 0.956
- 0.596
- 1.098
- 0.47
- 0.653
- 0.675
- 0.372
- 0.814
- 0.926
unequal: 0
verbose: 1
