avg_train_accuracy: 0.331
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0435
- 0.0876
- 0.0973
- 0.1112
- 0.1258
- 0.0444
- 0.1355
- 0.1425
- 0.1518
- 0.149
- 0.1601
- 0.1627
- 0.1713
- 0.1708
- 0.1861
- 0.1825
- 0.1918
- 0.0522
- 0.1856
- 0.1979
- 0.199
- 0.1982
- 0.2011
- 0.2049
- 0.194
- 0.1996
- 0.1921
- 0.2054
- 0.2258
- 0.224
- 0.2308
- 0.0578
- 0.2285
- 0.2279
- 0.2232
- 0.2376
- 0.234
- 0.2373
- 0.2427
- 0.2468
- 0.2404
- 0.2342
- 0.2306
- 0.2282
- 0.2444
- 0.2444
- 0.2431
- 0.25
- 0.2405
- 0.0644
- 0.2474
- 0.2526
- 0.2501
- 0.2568
- 0.2583
- 0.2529
- 0.2617
- 0.2548
- 0.2626
- 0.2577
- 0.2575
- 0.2551
- 0.2738
- 0.2741
- 0.266
- 0.2763
- 0.2752
- 0.2727
- 0.2765
- 0.2753
- 0.2752
- 0.2744
- 0.0762
- 0.279
- 0.2826
- 0.2779
- 0.2863
- 0.2772
- 0.0736
- 0.2815
- 0.2826
- 0.2975
- 0.2796
- 0.295
- 0.2934
- 0.2889
- 0.2918
- 0.0869
- 0.2918
- 0.2941
- 0.2913
- 0.2967
- 0.2849
- 0.297
- 0.2919
- 0.2908
- 0.2873
- 0.3008
- 0.3026
- 0.2992
test_loss_list:
- 1.835696392059326
- 1.770321431159973
- 1.7226874685287477
- 1.6886095261573792
- 1.682476246356964
- 3.1406009340286256
- 1.58445467710495
- 1.5814864134788513
- 1.5668595623970032
- 1.5875204634666442
- 1.5753398394584657
- 1.5601613330841064
- 1.5676254296302796
- 1.5625725173950196
- 1.5503406739234924
- 1.549841995239258
- 1.5345272326469421
- 2.9522952795028687
- 1.4519480443000794
- 1.4524245929718018
- 1.4828354454040527
- 1.4744967722892761
- 1.492084891796112
- 1.4798636579513549
- 1.5098520517349243
- 1.5238398003578186
- 1.549526376724243
- 1.5021830606460571
- 1.4880635690689088
- 1.4702452111244202
- 1.4720685052871705
- 2.875031476020813
- 1.3667040824890138
- 1.3798972725868226
- 1.4207873249053955
- 1.4072426986694335
- 1.419491446018219
- 1.4227131032943725
- 1.4206717205047608
- 1.4094488024711609
- 1.4290748095512391
- 1.450637218952179
- 1.4710793375968934
- 1.4826023268699646
- 1.4530044555664063
- 1.4289229798316956
- 1.4399459552764893
- 1.4341243124008178
- 1.4641294431686402
- 2.7545658111572267
- 1.3547178030014038
- 1.370659372806549
- 1.3471151494979858
- 1.364433500766754
- 1.364385130405426
- 1.372619104385376
- 1.3865709328651428
- 1.3828835773468018
- 1.3881642055511474
- 1.3973221611976623
- 1.4072439026832582
- 1.4027806210517884
- 1.3879400563240052
- 1.368220524787903
- 1.400537600517273
- 1.377180392742157
- 1.3842505097389222
- 1.3941827893257142
- 1.3881875324249267
- 1.4029232883453369
- 1.3989307761192322
- 1.3987145662307738
- 2.6168646240234374
- 1.2815095615386962
- 1.3071535778045655
- 1.313141531944275
- 1.3262859606742858
- 1.3220610952377319
- 2.5916648054122926
- 1.281387174129486
- 1.3009480118751526
- 1.2865334057807922
- 1.3139676284790038
- 1.302927658557892
- 1.3065665102005004
- 1.3126138949394226
- 1.315627634525299
- 2.5224704360961914
- 1.2504933524131774
- 1.2632035040855407
- 1.2997547197341919
- 1.2939041447639466
- 1.3270847964286805
- 1.3018482637405395
- 1.3223893785476684
- 1.3449757194519043
- 1.3488935589790345
- 1.318752338886261
- 1.3309286952018737
- 1.345046753883362
train_accuracy:
- 0.05
- 0.103
- 0.087
- 0.132
- 0.146
- 0.0
- 0.131
- 0.166
- 0.154
- 0.155
- 0.153
- 0.188
- 0.184
- 0.174
- 0.232
- 0.191
- 0.21
- 0.0
- 0.231
- 0.195
- 0.186
- 0.227
- 0.243
- 0.214
- 0.182
- 0.194
- 0.178
- 0.224
- 0.236
- 0.273
- 0.272
- 0.0
- 0.235
- 0.221
- 0.214
- 0.267
- 0.202
- 0.269
- 0.279
- 0.269
- 0.288
- 0.285
- 0.265
- 0.275
- 0.258
- 0.253
- 0.285
- 0.3
- 0.295
- 0.0
- 0.289
- 0.26
- 0.259
- 0.284
- 0.295
- 0.271
- 0.303
- 0.267
- 0.31
- 0.233
- 0.244
- 0.283
- 0.316
- 0.306
- 0.292
- 0.312
- 0.279
- 0.324
- 0.314
- 0.286
- 0.333
- 0.266
- 0.0
- 0.304
- 0.332
- 0.284
- 0.333
- 0.301
- 0.0
- 0.301
- 0.305
- 0.344
- 0.247
- 0.298
- 0.332
- 0.295
- 0.336
- 0.0
- 0.335
- 0.326
- 0.333
- 0.281
- 0.306
- 0.347
- 0.299
- 0.276
- 0.302
- 0.286
- 0.332
- 0.331
train_loss:
- 4.259
- 3.527
- 3.661
- 3.423
- 3.04
- 1.944
- 3.717
- 3.301
- 3.293
- 2.769
- 2.996
- 3.071
- 2.707
- 2.869
- 2.665
- 2.729
- 2.595
- 1.562
- 2.654
- 2.57
- 2.074
- 2.113
- 1.718
- 2.388
- 1.888
- 1.525
- 1.295
- 2.457
- 2.303
- 1.808
- 2.581
- 1.354
- 2.337
- 2.093
- 1.534
- 2.2
- 1.397
- 1.568
- 1.135
- 2.199
- 1.041
- 0.798
- 0.649
- 0.543
- 1.917
- 1.841
- 1.825
- 0.689
- 0.48
- 1.11
- 0.624
- 1.573
- 2.37
- 1.216
- 1.588
- 1.83
- 0.632
- 1.375
- 1.225
- 1.443
- 0.905
- 1.562
- 1.161
- 1.304
- 2.027
- 0.705
- 1.218
- 1.136
- 1.742
- 1.05
- 1.258
- 1.035
- 1.03
- 1.181
- 0.845
- 0.81
- 0.579
- 1.207
- 0.739
- 1.63
- 1.027
- 0.991
- 1.048
- 0.758
- 0.926
- 1.597
- 0.682
- 0.699
- 0.95
- 0.733
- 0.723
- 0.845
- 1.098
- 0.53
- 0.575
- 0.337
- 1.27
- 0.858
- 0.693
- 0.874
unequal: 0
verbose: 1
