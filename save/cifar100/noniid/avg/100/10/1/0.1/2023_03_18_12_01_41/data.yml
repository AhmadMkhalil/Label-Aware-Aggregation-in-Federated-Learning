avg_train_accuracy: 0.364
avg_train_loss: 0.009
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.038
- 0.0892
- 0.0968
- 0.1229
- 0.1245
- 0.0445
- 0.14
- 0.1396
- 0.1657
- 0.0509
- 0.1615
- 0.1687
- 0.1698
- 0.1811
- 0.1871
- 0.1898
- 0.1909
- 0.183
- 0.1933
- 0.1971
- 0.1954
- 0.2097
- 0.2113
- 0.216
- 0.214
- 0.2198
- 0.2194
- 0.222
- 0.2265
- 0.2284
- 0.2384
- 0.2377
- 0.2362
- 0.2389
- 0.2471
- 0.2372
- 0.2426
- 0.2471
- 0.2475
- 0.2505
- 0.2575
- 0.0638
- 0.257
- 0.2639
- 0.2545
- 0.2639
- 0.2597
- 0.2648
- 0.2684
- 0.265
- 0.2583
- 0.272
- 0.2677
- 0.2709
- 0.2668
- 0.2821
- 0.2756
- 0.2738
- 0.2737
- 0.2689
- 0.2865
- 0.2829
- 0.2756
- 0.0695
- 0.2797
- 0.2809
- 0.2846
- 0.2812
- 0.283
- 0.2899
- 0.2841
- 0.0737
- 0.2898
- 0.0719
- 0.2895
- 0.2971
- 0.2907
- 0.2973
- 0.2921
- 0.0769
- 0.3027
- 0.3017
- 0.2938
- 0.3036
- 0.3052
- 0.3063
- 0.3017
- 0.0846
- 0.3125
- 0.3042
- 0.3077
- 0.3032
- 0.3037
- 0.3104
- 0.3085
- 0.3094
- 0.089
- 0.0863
- 0.3152
- 0.3062
test_loss_list:
- 1.8119529390335083
- 1.7297947645187377
- 1.710560073852539
- 1.6824602222442626
- 1.6715009784698487
- 3.092693271636963
- 1.5563170576095582
- 1.5797231268882752
- 1.5544696140289307
- 2.983659658432007
- 1.5084724521636963
- 1.500385401248932
- 1.5152672958374023
- 1.5045934700965882
- 1.5133600878715514
- 1.517049834728241
- 1.5241105723381043
- 1.5497915291786193
- 1.521041033267975
- 1.5044757151603698
- 1.5067958593368531
- 1.4875833153724671
- 1.4888755702972412
- 1.4894560861587525
- 1.4844876837730407
- 1.4839682221412658
- 1.4767946076393128
- 1.4789686226844787
- 1.484200406074524
- 1.4836220860481262
- 1.4553949737548828
- 1.4588390183448792
- 1.4500571131706237
- 1.4706819534301758
- 1.4561007165908812
- 1.4904049921035767
- 1.4605510544776916
- 1.4533497142791747
- 1.4528075575828552
- 1.4632813096046449
- 1.4411617159843444
- 2.7831077909469606
- 1.3072728681564332
- 1.3230661344528198
- 1.3667404890060424
- 1.349174942970276
- 1.3561203956604004
- 1.354355227947235
- 1.352058141231537
- 1.3731136584281922
- 1.3848671293258668
- 1.3571605491638183
- 1.3722043490409852
- 1.3725430655479431
- 1.3872265577316285
- 1.3669186568260192
- 1.375081696510315
- 1.3801872277259826
- 1.3837805604934692
- 1.3946300482749938
- 1.367264950275421
- 1.3871683430671693
- 1.401259799003601
- 2.674995770454407
- 1.2609289979934692
- 1.2862913513183594
- 1.2959753441810609
- 1.3078937172889709
- 1.3188957166671753
- 1.3094368147850037
- 1.3377302026748656
- 2.583695454597473
- 1.2523069596290588
- 2.61461980342865
- 1.2452527022361755
- 1.2513143420219421
- 1.2626124548912048
- 1.2762680172920227
- 1.2818507623672486
- 2.515371150970459
- 1.2232365107536316
- 1.2508988642692567
- 1.2766106986999513
- 1.2636449670791625
- 1.2691004943847657
- 1.2817221689224243
- 1.3117285013198852
- 2.468693661689758
- 1.2150547194480896
- 1.2442719638347626
- 1.2551624274253845
- 1.2733387494087218
- 1.2644921624660492
- 1.27099280834198
- 1.2770376467704774
- 1.2862153363227844
- 2.4401382970809937
- 2.5709810400009157
- 1.2034316873550415
- 1.2365083277225495
train_accuracy:
- 0.024
- 0.111
- 0.095
- 0.116
- 0.182
- 0.0
- 0.141
- 0.145
- 0.146
- 0.0
- 0.157
- 0.205
- 0.204
- 0.218
- 0.192
- 0.236
- 0.239
- 0.218
- 0.193
- 0.196
- 0.246
- 0.255
- 0.184
- 0.265
- 0.206
- 0.231
- 0.235
- 0.255
- 0.209
- 0.269
- 0.238
- 0.221
- 0.236
- 0.244
- 0.259
- 0.269
- 0.292
- 0.244
- 0.284
- 0.24
- 0.321
- 0.0
- 0.287
- 0.258
- 0.256
- 0.318
- 0.352
- 0.281
- 0.278
- 0.316
- 0.317
- 0.314
- 0.257
- 0.328
- 0.273
- 0.308
- 0.333
- 0.263
- 0.285
- 0.27
- 0.328
- 0.343
- 0.336
- 0.0
- 0.289
- 0.313
- 0.287
- 0.324
- 0.241
- 0.302
- 0.335
- 0.0
- 0.333
- 0.0
- 0.292
- 0.335
- 0.276
- 0.302
- 0.277
- 0.0
- 0.328
- 0.338
- 0.332
- 0.263
- 0.329
- 0.282
- 0.31
- 0.0
- 0.322
- 0.333
- 0.301
- 0.314
- 0.306
- 0.291
- 0.351
- 0.302
- 0.0
- 0.0
- 0.31
- 0.364
train_loss:
- 4.337
- 3.833
- 3.589
- 3.542
- 3.455
- 1.908
- 3.617
- 2.847
- 3.08
- 1.428
- 3.365
- 3.009
- 3.082
- 2.61
- 2.813
- 2.318
- 1.904
- 1.66
- 2.606
- 2.623
- 2.562
- 2.66
- 2.262
- 2.197
- 2.403
- 1.872
- 2.586
- 2.001
- 1.728
- 1.812
- 2.19
- 2.201
- 1.93
- 1.809
- 2.128
- 1.615
- 1.813
- 1.58
- 1.422
- 1.649
- 2.177
- 1.413
- 1.949
- 1.435
- 0.977
- 1.555
- 1.335
- 1.825
- 1.436
- 1.227
- 1.139
- 1.81
- 1.096
- 1.025
- 1.39
- 1.514
- 0.85
- 1.201
- 1.082
- 1.183
- 1.542
- 0.777
- 0.502
- 1.148
- 1.251
- 1.032
- 0.989
- 1.54
- 1.94
- 0.89
- 0.622
- 0.834
- 1.415
- 0.569
- 0.909
- 1.279
- 0.898
- 0.86
- 1.59
- 0.629
- 0.825
- 0.983
- 1.097
- 1.216
- 1.072
- 0.873
- 0.603
- 0.59
- 0.924
- 0.775
- 0.714
- 0.406
- 0.57
- 0.868
- 1.062
- 0.471
- 0.539
- 0.166
- 0.664
- 0.859
unequal: 0
verbose: 1
