avg_train_accuracy: 0.277
avg_train_loss: 0.007
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0389
- 0.0727
- 0.0986
- 0.1175
- 0.1317
- 0.0438
- 0.1321
- 0.1379
- 0.1475
- 0.051
- 0.1496
- 0.1616
- 0.1687
- 0.1728
- 0.1741
- 0.1863
- 0.0535
- 0.1863
- 0.1972
- 0.1982
- 0.2046
- 0.206
- 0.0574
- 0.2022
- 0.214
- 0.2139
- 0.2164
- 0.2194
- 0.2224
- 0.2231
- 0.2288
- 0.2307
- 0.2281
- 0.2325
- 0.2402
- 0.2329
- 0.2396
- 0.2381
- 0.2502
- 0.2437
- 0.2433
- 0.2463
- 0.2474
- 0.2586
- 0.2538
- 0.2546
- 0.2444
- 0.2572
- 0.2544
- 0.2552
- 0.255
- 0.2648
- 0.2655
- 0.2616
- 0.2627
- 0.2739
- 0.2652
- 0.2672
- 0.2539
- 0.2653
- 0.2682
- 0.2697
- 0.2803
- 0.2744
- 0.2819
- 0.2726
- 0.2769
- 0.2761
- 0.0684
- 0.2767
- 0.2672
- 0.2843
- 0.2833
- 0.285
- 0.2846
- 0.287
- 0.0764
- 0.2885
- 0.293
- 0.2909
- 0.2874
- 0.2903
- 0.2953
- 0.0796
- 0.2883
- 0.2862
- 0.293
- 0.2905
- 0.0861
- 0.0713
- 0.2997
- 0.093
- 0.2963
- 0.0896
- 0.0773
- 0.2913
- 0.3
- 0.0964
- 0.0849
- 0.3049
test_loss_list:
- 1.823388433456421
- 1.7535667133331299
- 1.707017455101013
- 1.6739039182662965
- 1.6584344720840454
- 3.1215472650527953
- 1.5765130591392518
- 1.573393919467926
- 1.5645701837539674
- 3.0448081588745115
- 1.5232585835456849
- 1.5260359787940978
- 1.5388300132751465
- 1.5182290172576904
- 1.510279598236084
- 1.5085064268112183
- 2.930564432144165
- 1.4400178098678589
- 1.4495584750175476
- 1.4556015753746032
- 1.462304072380066
- 1.4630948758125306
- 2.81289381980896
- 1.4060586428642272
- 1.4080393981933594
- 1.4200621008872987
- 1.4208340907096864
- 1.420091178417206
- 1.4177560091018677
- 1.4385724639892579
- 1.417945420742035
- 1.4267289161682128
- 1.4516369199752808
- 1.4336314582824707
- 1.4340423607826234
- 1.4534048867225646
- 1.4396352028846742
- 1.4342879629135132
- 1.4266426324844361
- 1.4380984807014465
- 1.4447782135009766
- 1.4234819650650024
- 1.4220594143867493
- 1.4330165839195252
- 1.427849245071411
- 1.4314742255210877
- 1.4737367987632752
- 1.4289810061454773
- 1.4322130799293518
- 1.4406172847747802
- 1.4513292980194092
- 1.4266418433189392
- 1.4361624717712402
- 1.457556529045105
- 1.4477055621147157
- 1.4231407618522645
- 1.4263296031951904
- 1.433401575088501
- 1.4580416560173035
- 1.4540242314338685
- 1.426461899280548
- 1.430190420150757
- 1.4202667045593262
- 1.4399792265892029
- 1.441701855659485
- 1.4502413964271545
- 1.4338776659965515
- 1.4466714286804199
- 2.6334784412384034
- 1.2906874799728394
- 1.3349930596351625
- 1.2986905336380006
- 1.3085061311721802
- 1.318606526851654
- 1.3386918878555298
- 1.3313450717926025
- 2.5758853340148926
- 1.2563083791732788
- 1.2737473440170288
- 1.2865986919403076
- 1.3082446765899658
- 1.3127874422073365
- 1.2975282454490662
- 2.5270197105407717
- 1.266062388420105
- 1.2836596298217773
- 1.3142065715789795
- 1.293343529701233
- 2.483212399482727
- 2.7593828296661376
- 1.2752203702926637
- 2.445550169944763
- 1.2549531888961791
- 2.393926544189453
- 2.6651358556747438
- 1.288503258228302
- 1.2656800770759582
- 2.3787068128585815
- 2.5503393840789794
- 1.2413765096664429
train_accuracy:
- 0.036
- 0.067
- 0.106
- 0.104
- 0.093
- 0.0
- 0.134
- 0.163
- 0.137
- 0.0
- 0.175
- 0.157
- 0.157
- 0.191
- 0.185
- 0.162
- 0.0
- 0.193
- 0.169
- 0.2
- 0.213
- 0.177
- 0.0
- 0.234
- 0.236
- 0.22
- 0.233
- 0.218
- 0.191
- 0.232
- 0.181
- 0.253
- 0.226
- 0.204
- 0.225
- 0.233
- 0.273
- 0.27
- 0.234
- 0.221
- 0.253
- 0.241
- 0.231
- 0.243
- 0.254
- 0.257
- 0.259
- 0.29
- 0.253
- 0.248
- 0.264
- 0.246
- 0.285
- 0.25
- 0.271
- 0.246
- 0.275
- 0.296
- 0.275
- 0.273
- 0.261
- 0.308
- 0.282
- 0.258
- 0.291
- 0.262
- 0.284
- 0.307
- 0.0
- 0.268
- 0.257
- 0.307
- 0.289
- 0.293
- 0.319
- 0.306
- 0.0
- 0.311
- 0.262
- 0.287
- 0.281
- 0.304
- 0.293
- 0.0
- 0.32
- 0.332
- 0.278
- 0.275
- 0.0
- 0.0
- 0.264
- 0.0
- 0.327
- 0.0
- 0.0
- 0.254
- 0.324
- 0.0
- 0.0
- 0.277
train_loss:
- 4.256
- 3.885
- 3.711
- 3.487
- 3.371
- 1.927
- 3.671
- 3.149
- 3.185
- 1.423
- 3.038
- 3.026
- 2.545
- 2.8
- 2.926
- 2.784
- 1.281
- 2.775
- 2.951
- 2.442
- 2.787
- 2.662
- 1.136
- 2.348
- 2.609
- 2.388
- 2.261
- 2.257
- 2.466
- 1.916
- 2.31
- 2.111
- 2.24
- 2.146
- 1.716
- 1.853
- 1.87
- 1.921
- 2.269
- 1.675
- 2.137
- 1.945
- 1.936
- 1.432
- 1.543
- 1.819
- 1.327
- 1.691
- 1.342
- 0.952
- 1.311
- 1.88
- 1.393
- 1.032
- 1.482
- 1.702
- 1.065
- 1.423
- 1.22
- 0.789
- 1.352
- 1.584
- 1.171
- 1.449
- 0.884
- 0.964
- 1.338
- 1.256
- 1.263
- 2.061
- 1.191
- 1.061
- 1.211
- 1.097
- 1.04
- 0.892
- 0.814
- 0.734
- 1.179
- 0.489
- 0.317
- 0.818
- 1.021
- 0.671
- 1.083
- 0.545
- 1.069
- 0.751
- 0.575
- 0.213
- 0.946
- 0.384
- 0.76
- 0.304
- 0.132
- 0.754
- 0.725
- 0.306
- 0.1
- 0.67
unequal: 0
verbose: 1
