avg_train_accuracy: 0.297
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0414
- 0.0817
- 0.0997
- 0.1288
- 0.0481
- 0.1157
- 0.1416
- 0.1457
- 0.1614
- 0.0495
- 0.1599
- 0.1615
- 0.0518
- 0.1661
- 0.1752
- 0.1857
- 0.1813
- 0.1745
- 0.1905
- 0.2013
- 0.1966
- 0.2142
- 0.0564
- 0.2134
- 0.2101
- 0.2183
- 0.2163
- 0.2071
- 0.2154
- 0.2164
- 0.2272
- 0.2246
- 0.2206
- 0.0583
- 0.2369
- 0.2262
- 0.2234
- 0.2285
- 0.238
- 0.2333
- 0.2332
- 0.2445
- 0.2548
- 0.2446
- 0.2471
- 0.2393
- 0.2408
- 0.2359
- 0.2381
- 0.2346
- 0.2525
- 0.2569
- 0.2535
- 0.2524
- 0.2661
- 0.2693
- 0.2596
- 0.2553
- 0.27
- 0.266
- 0.2693
- 0.2615
- 0.2691
- 0.2766
- 0.2777
- 0.2744
- 0.279
- 0.2734
- 0.2782
- 0.2826
- 0.276
- 0.2877
- 0.2883
- 0.2934
- 0.2909
- 0.2844
- 0.2834
- 0.2897
- 0.2918
- 0.2919
- 0.2984
- 0.2884
- 0.0741
- 0.0707
- 0.2963
- 0.2986
- 0.0825
- 0.0755
- 0.2999
- 0.2961
- 0.2934
- 0.2911
- 0.2949
- 0.2996
- 0.2911
- 0.2953
- 0.2919
- 0.3037
- 0.302
- 0.2996
test_loss_list:
- 1.8345849323272705
- 1.7507199621200562
- 1.7332359457015991
- 1.680393795967102
- 3.113761420249939
- 1.601135609149933
- 1.5886692023277282
- 1.5827140355110167
- 1.5871195220947265
- 3.0381840467453003
- 1.5123645520210267
- 1.5394957256317139
- 2.9622837352752684
- 1.4898330187797546
- 1.5028357052803039
- 1.5040045833587647
- 1.4925468945503235
- 1.5100067639350891
- 1.5043308019638062
- 1.4813902401924133
- 1.4979396915435792
- 1.4723216271400452
- 2.8429317569732664
- 1.3925899076461792
- 1.4283551478385925
- 1.419091181755066
- 1.430010061264038
- 1.4485982036590577
- 1.4541349601745606
- 1.4576807641983032
- 1.4424546957015991
- 1.4632827401161195
- 1.4456350350379943
- 2.7798922491073608
- 1.3506474447250367
- 1.384675347805023
- 1.412482533454895
- 1.3917581939697266
- 1.4011910986900329
- 1.428212857246399
- 1.4431727313995362
- 1.403747878074646
- 1.3810686469078064
- 1.3840656447410584
- 1.4064693975448608
- 1.4215908908843995
- 1.4459574484825135
- 1.4689859199523925
- 1.467872965335846
- 1.4858052158355712
- 1.4278206062316894
- 1.4146600651741028
- 1.418644940853119
- 1.428398506641388
- 1.4104733729362489
- 1.3899061822891234
- 1.4134438014030457
- 1.4544203543663026
- 1.415233747959137
- 1.440498948097229
- 1.421258008480072
- 1.4169887733459472
- 1.4172507476806642
- 1.4159300923347473
- 1.3976925539970397
- 1.396374316215515
- 1.4101026058197021
- 1.427409200668335
- 1.4212533187866212
- 1.415955469608307
- 1.4144502592086792
- 1.3988851928710937
- 1.4022474837303163
- 1.3975957489013673
- 1.4116397380828858
- 1.4233038568496703
- 1.4264437937736512
- 1.4179746222496032
- 1.4153949046134948
- 1.4221339464187621
- 1.4083232188224792
- 1.4261106967926025
- 2.613363528251648
- 2.824824252128601
- 1.2396898889541625
- 1.2691843247413634
- 2.5289370584487916
- 2.716692900657654
- 1.2441161155700684
- 1.2623703575134277
- 1.2905297112464904
- 1.3065027809143066
- 1.310305769443512
- 1.2921737432479858
- 1.3241015768051148
- 1.332129292488098
- 1.3361559557914733
- 1.3188424229621887
- 1.3094183158874513
- 1.3374296259880065
train_accuracy:
- 0.061
- 0.072
- 0.106
- 0.133
- 0.0
- 0.102
- 0.108
- 0.136
- 0.139
- 0.0
- 0.184
- 0.17
- 0.0
- 0.163
- 0.162
- 0.17
- 0.199
- 0.18
- 0.18
- 0.195
- 0.216
- 0.188
- 0.0
- 0.193
- 0.209
- 0.217
- 0.206
- 0.218
- 0.242
- 0.227
- 0.192
- 0.204
- 0.221
- 0.0
- 0.187
- 0.215
- 0.24
- 0.236
- 0.25
- 0.255
- 0.235
- 0.214
- 0.26
- 0.279
- 0.25
- 0.278
- 0.247
- 0.244
- 0.241
- 0.233
- 0.201
- 0.266
- 0.253
- 0.255
- 0.248
- 0.259
- 0.245
- 0.269
- 0.271
- 0.273
- 0.252
- 0.273
- 0.286
- 0.271
- 0.303
- 0.294
- 0.267
- 0.295
- 0.287
- 0.306
- 0.3
- 0.255
- 0.319
- 0.297
- 0.314
- 0.279
- 0.336
- 0.264
- 0.311
- 0.312
- 0.256
- 0.322
- 0.0
- 0.0
- 0.326
- 0.311
- 0.0
- 0.0
- 0.3
- 0.338
- 0.316
- 0.294
- 0.265
- 0.311
- 0.266
- 0.295
- 0.328
- 0.297
- 0.274
- 0.297
train_loss:
- 4.268
- 3.832
- 3.421
- 3.512
- 1.881
- 3.513
- 3.326
- 2.792
- 2.919
- 1.461
- 3.444
- 2.659
- 1.188
- 2.807
- 2.621
- 2.811
- 2.532
- 2.934
- 2.907
- 2.742
- 2.479
- 2.705
- 1.182
- 2.474
- 2.456
- 2.378
- 1.919
- 1.535
- 2.24
- 2.154
- 2.489
- 1.964
- 1.612
- 1.04
- 2.408
- 1.905
- 1.425
- 1.356
- 2.218
- 1.653
- 1.312
- 1.963
- 2.048
- 1.885
- 1.494
- 1.474
- 1.175
- 0.856
- 0.686
- 0.578
- 1.631
- 1.505
- 1.964
- 1.31
- 1.897
- 2.037
- 1.436
- 0.95
- 1.25
- 0.647
- 1.44
- 1.254
- 0.991
- 1.181
- 1.366
- 1.637
- 0.996
- 1.162
- 1.111
- 0.936
- 1.393
- 1.351
- 0.986
- 0.728
- 0.742
- 0.733
- 0.589
- 1.047
- 0.978
- 0.658
- 1.366
- 0.726
- 1.149
- 0.349
- 0.93
- 0.987
- 0.53
- 0.209
- 0.781
- 0.548
- 0.408
- 0.652
- 0.912
- 0.696
- 0.6
- 0.5
- 1.135
- 0.806
- 0.545
- 0.444
unequal: 0
verbose: 1
