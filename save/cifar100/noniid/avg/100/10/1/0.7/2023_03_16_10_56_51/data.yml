avg_train_accuracy: 0.31
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0481
- 0.0997
- 0.1195
- 0.135
- 0.1522
- 0.1603
- 0.1725
- 0.177
- 0.1901
- 0.1922
- 0.2017
- 0.205
- 0.2112
- 0.2208
- 0.2244
- 0.2267
- 0.2306
- 0.2365
- 0.2379
- 0.2393
- 0.2428
- 0.2474
- 0.2507
- 0.2541
- 0.2548
- 0.262
- 0.2653
- 0.262
- 0.2644
- 0.2683
- 0.2712
- 0.2715
- 0.2741
- 0.2763
- 0.2764
- 0.2799
- 0.2816
- 0.2844
- 0.2854
- 0.2884
- 0.2886
- 0.2832
- 0.2894
- 0.2899
- 0.291
- 0.2923
- 0.2949
- 0.2979
- 0.2956
- 0.2955
- 0.2976
- 0.2994
- 0.3004
- 0.2973
- 0.3019
- 0.2999
- 0.3001
- 0.3025
- 0.3024
- 0.3082
- 0.3089
- 0.3114
- 0.3044
- 0.3039
- 0.3053
- 0.3076
- 0.3084
- 0.3052
- 0.3109
- 0.3144
- 0.3141
- 0.3164
- 0.3185
- 0.3174
- 0.3164
- 0.317
- 0.3191
- 0.3121
- 0.3194
- 0.3148
- 0.3199
- 0.3218
- 0.3227
- 0.3216
- 0.3196
- 0.3185
- 0.3208
- 0.3185
- 0.3217
- 0.3196
- 0.3163
- 0.3229
- 0.3252
- 0.3239
- 0.3203
- 0.3204
- 0.3151
- 0.3241
- 0.324
- 0.3202
test_loss_list:
- 1.7943839311599732
- 1.657750985622406
- 1.6004902362823485
- 1.5534304404258727
- 1.5189462971687318
- 1.5210757446289063
- 1.4783338069915772
- 1.452311291694641
- 1.4648675417900086
- 1.426362519264221
- 1.440922772884369
- 1.4010955357551576
- 1.4163584971427918
- 1.4181773972511291
- 1.3762007403373717
- 1.349171154499054
- 1.3389633440971374
- 1.3261860513687134
- 1.35332528591156
- 1.3223723697662353
- 1.3462842202186585
- 1.309789125919342
- 1.2942746591567993
- 1.2880634331703187
- 1.2793145656585694
- 1.2744124388694764
- 1.2677504920959473
- 1.300837631225586
- 1.2689016938209534
- 1.298764922618866
- 1.3075903296470641
- 1.267309970855713
- 1.2516912388801575
- 1.2834384632110596
- 1.297150855064392
- 1.3033588361740112
- 1.2593749833106995
- 1.238980975151062
- 1.2281685376167297
- 1.2227066493034362
- 1.2198978924751283
- 1.2594165658950807
- 1.223239507675171
- 1.2148509192466737
- 1.2107141923904419
- 1.2118303751945496
- 1.2067792868614198
- 1.202264003753662
- 1.237811803817749
- 1.211142475605011
- 1.2407351803779603
- 1.210829677581787
- 1.201472351551056
- 1.2349606680870056
- 1.2035973787307739
- 1.2383312678337097
- 1.2046513080596923
- 1.1953846430778503
- 1.1930679416656493
- 1.1873916745185853
- 1.186867160797119
- 1.1854376673698426
- 1.2220896244049073
- 1.2364464473724366
- 1.2456388401985168
- 1.202327904701233
- 1.232374885082245
- 1.2466698002815246
- 1.2003105640411378
- 1.1889904737472534
- 1.1875097584724426
- 1.1827564072608947
- 1.1799652647972108
- 1.1802764868736266
- 1.181181139945984
- 1.1804977297782897
- 1.180742356777191
- 1.2173284697532654
- 1.1891896772384642
- 1.2197622966766357
- 1.1900578594207765
- 1.180631263256073
- 1.1795998859405517
- 1.1774749779701232
- 1.21257390499115
- 1.1879928779602051
- 1.183546280860901
- 1.2194770216941833
- 1.1864735531806945
- 1.2206835556030273
- 1.2344046092033387
- 1.193313422203064
- 1.186297504901886
- 1.1870976901054382
- 1.214679501056671
- 1.192797658443451
- 1.2234540796279907
- 1.1947624611854553
- 1.1848887634277343
- 1.2221832656860352
train_accuracy:
- 0.058
- 0.127
- 0.0
- 0.177
- 0.0
- 0.167
- 0.0
- 0.215
- 0.231
- 0.0
- 0.162
- 0.205
- 0.21
- 0.203
- 0.182
- 0.0
- 0.222
- 0.279
- 0.259
- 0.0
- 0.213
- 0.0
- 0.265
- 0.284
- 0.217
- 0.233
- 0.243
- 0.243
- 0.0
- 0.233
- 0.253
- 0.267
- 0.325
- 0.259
- 0.296
- 0.327
- 0.0
- 0.269
- 0.277
- 0.275
- 0.273
- 0.286
- 0.278
- 0.322
- 0.335
- 0.324
- 0.309
- 0.0
- 0.279
- 0.315
- 0.378
- 0.339
- 0.287
- 0.314
- 0.281
- 0.284
- 0.316
- 0.277
- 0.295
- 0.0
- 0.343
- 0.0
- 0.304
- 0.335
- 0.299
- 0.284
- 0.322
- 0.284
- 0.298
- 0.302
- 0.306
- 0.293
- 0.0
- 0.311
- 0.305
- 0.299
- 0.0
- 0.351
- 0.309
- 0.289
- 0.362
- 0.352
- 0.393
- 0.0
- 0.355
- 0.32
- 0.317
- 0.286
- 0.315
- 0.342
- 0.298
- 0.32
- 0.306
- 0.382
- 0.369
- 0.346
- 0.383
- 0.0
- 0.295
- 0.31
train_loss:
- 4.205
- 3.472
- 3.268
- 3.119
- 2.981
- 3.119
- 2.781
- 2.691
- 2.861
- 2.548
- 2.689
- 2.448
- 2.566
- 2.489
- 2.243
- 2.2
- 2.141
- 2.126
- 2.23
- 2.009
- 2.117
- 1.911
- 1.88
- 1.812
- 1.807
- 1.74
- 1.714
- 1.846
- 1.648
- 1.732
- 1.693
- 1.54
- 1.534
- 1.597
- 1.542
- 1.493
- 1.365
- 1.315
- 1.339
- 1.276
- 1.26
- 1.322
- 1.209
- 1.189
- 1.135
- 1.11
- 1.067
- 1.094
- 1.133
- 1.04
- 1.102
- 1.017
- 0.978
- 1.029
- 0.986
- 0.979
- 0.888
- 0.885
- 0.844
- 0.855
- 0.817
- 0.802
- 0.837
- 0.813
- 0.785
- 0.732
- 0.754
- 0.743
- 0.698
- 0.666
- 0.656
- 0.631
- 0.616
- 0.58
- 0.591
- 0.587
- 0.586
- 0.607
- 0.55
- 0.552
- 0.554
- 0.504
- 0.489
- 0.491
- 0.528
- 0.482
- 0.452
- 0.479
- 0.449
- 0.445
- 0.463
- 0.44
- 0.406
- 0.386
- 0.428
- 0.392
- 0.41
- 0.373
- 0.379
- 0.367
unequal: 0
verbose: 1
