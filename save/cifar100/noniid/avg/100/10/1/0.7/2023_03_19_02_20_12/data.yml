avg_train_accuracy: 0.36
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0415
- 0.0928
- 0.1131
- 0.1271
- 0.1466
- 0.1615
- 0.1666
- 0.1753
- 0.1828
- 0.1911
- 0.1992
- 0.2068
- 0.21
- 0.212
- 0.2177
- 0.2259
- 0.2286
- 0.2308
- 0.2361
- 0.2412
- 0.2437
- 0.246
- 0.2514
- 0.2548
- 0.2578
- 0.2616
- 0.2658
- 0.2628
- 0.2661
- 0.2709
- 0.2709
- 0.2778
- 0.2762
- 0.2792
- 0.2836
- 0.2829
- 0.2839
- 0.2842
- 0.2876
- 0.2859
- 0.2895
- 0.2874
- 0.2906
- 0.2949
- 0.2988
- 0.2937
- 0.3006
- 0.2989
- 0.3048
- 0.3048
- 0.3051
- 0.3039
- 0.3016
- 0.3032
- 0.3063
- 0.3088
- 0.3049
- 0.3082
- 0.311
- 0.3138
- 0.3099
- 0.3141
- 0.3178
- 0.3152
- 0.3136
- 0.315
- 0.3096
- 0.3169
- 0.3199
- 0.3181
- 0.3189
- 0.3207
- 0.323
- 0.3249
- 0.3258
- 0.325
- 0.3163
- 0.315
- 0.3254
- 0.3223
- 0.3287
- 0.3269
- 0.326
- 0.3253
- 0.3251
- 0.3267
- 0.3287
- 0.3281
- 0.3227
- 0.3216
- 0.3249
- 0.3219
- 0.328
- 0.3314
- 0.3358
- 0.3262
- 0.3322
- 0.3272
- 0.3317
- 0.3247
test_loss_list:
- 1.7936261892318726
- 1.6628061294555665
- 1.6050280785560609
- 1.5636493730545045
- 1.527664852142334
- 1.4964317750930787
- 1.473653619289398
- 1.4555674409866333
- 1.4335445356369019
- 1.417172303199768
- 1.4032549691200256
- 1.3872872138023375
- 1.3747106957435609
- 1.4004976630210877
- 1.3646593332290649
- 1.3438270235061645
- 1.3688189196586609
- 1.337774634361267
- 1.358670244216919
- 1.3204125618934632
- 1.303972659111023
- 1.3335104775428772
- 1.2964227676391602
- 1.2822304034233094
- 1.2722006964683532
- 1.2688602590560913
- 1.2577564358711242
- 1.2951629734039307
- 1.257703137397766
- 1.2445652770996094
- 1.2393578553199769
- 1.2339030313491821
- 1.230094792842865
- 1.2293076777458192
- 1.2227588367462159
- 1.2200451922416686
- 1.2143875885009765
- 1.2136744856834412
- 1.2445449781417848
- 1.2599840998649596
- 1.2194328832626342
- 1.248691222667694
- 1.2592917418479919
- 1.213837947845459
- 1.198247311115265
- 1.2331724095344543
- 1.1961387372016907
- 1.2291395258903504
- 1.1970496892929077
- 1.1903210425376891
- 1.1826333355903627
- 1.1829483699798584
- 1.2201641011238098
- 1.23014582157135
- 1.190531063079834
- 1.181701624393463
- 1.2161831068992615
- 1.2279612517356873
- 1.1869725179672241
- 1.176048400402069
- 1.2154139947891236
- 1.1785433101654053
- 1.1702109241485597
- 1.1707067036628722
- 1.2026787400245667
- 1.2166856575012206
- 1.2307164406776427
- 1.184278757572174
- 1.1675513434410094
- 1.170554931163788
- 1.1651386189460755
- 1.1653611040115357
- 1.1595169019699096
- 1.161292350292206
- 1.158786325454712
- 1.156775677204132
- 1.1961254692077636
- 1.2111825037002564
- 1.1685191941261293
- 1.163668007850647
- 1.158957188129425
- 1.1568987774848938
- 1.1604043793678285
- 1.1611301445960998
- 1.1595156502723694
- 1.159888083934784
- 1.1593192505836487
- 1.158306097984314
- 1.193230140209198
- 1.2046934723854066
- 1.1740592312812805
- 1.206548237800598
- 1.1675941228866578
- 1.1603389501571655
- 1.1596831583976746
- 1.1954793810844422
- 1.1633157229423523
- 1.1998427486419678
- 1.1690732097625733
- 1.2038981962203978
train_accuracy:
- 0.034
- 0.104
- 0.122
- 0.127
- 0.169
- 0.167
- 0.188
- 0.189
- 0.2
- 0.213
- 0.175
- 0.23
- 0.245
- 0.243
- 0.221
- 0.254
- 0.261
- 0.247
- 0.221
- 0.272
- 0.279
- 0.272
- 0.276
- 0.299
- 0.271
- 0.271
- 0.273
- 0.311
- 0.337
- 0.306
- 0.295
- 0.281
- 0.304
- 0.0
- 0.0
- 0.323
- 0.329
- 0.324
- 0.323
- 0.327
- 0.319
- 0.335
- 0.307
- 0.313
- 0.364
- 0.358
- 0.3
- 0.379
- 0.302
- 0.338
- 0.306
- 0.335
- 0.305
- 0.327
- 0.3
- 0.287
- 0.331
- 0.315
- 0.393
- 0.305
- 0.335
- 0.349
- 0.0
- 0.0
- 0.35
- 0.326
- 0.366
- 0.323
- 0.359
- 0.305
- 0.365
- 0.376
- 0.346
- 0.344
- 0.314
- 0.394
- 0.319
- 0.365
- 0.324
- 0.399
- 0.371
- 0.315
- 0.367
- 0.403
- 0.0
- 0.375
- 0.363
- 0.373
- 0.402
- 0.356
- 0.351
- 0.326
- 0.332
- 0.334
- 0.373
- 0.355
- 0.371
- 0.363
- 0.332
- 0.36
train_loss:
- 3.952
- 3.519
- 3.315
- 3.132
- 3.008
- 2.902
- 2.827
- 2.715
- 2.664
- 2.565
- 2.497
- 2.441
- 2.407
- 2.569
- 2.281
- 2.237
- 2.374
- 2.12
- 2.246
- 2.029
- 1.999
- 2.131
- 1.899
- 1.887
- 1.806
- 1.771
- 1.762
- 1.852
- 1.7
- 1.631
- 1.598
- 1.585
- 1.495
- 1.491
- 1.489
- 1.421
- 1.426
- 1.374
- 1.477
- 1.435
- 1.312
- 1.37
- 1.335
- 1.208
- 1.185
- 1.283
- 1.14
- 1.193
- 1.115
- 1.047
- 1.018
- 0.972
- 1.051
- 1.036
- 0.948
- 0.916
- 0.968
- 0.98
- 0.891
- 0.858
- 0.914
- 0.819
- 0.763
- 0.784
- 0.816
- 0.816
- 0.766
- 0.72
- 0.728
- 0.682
- 0.663
- 0.677
- 0.643
- 0.63
- 0.616
- 0.635
- 0.632
- 0.618
- 0.595
- 0.548
- 0.529
- 0.536
- 0.521
- 0.498
- 0.482
- 0.478
- 0.473
- 0.477
- 0.531
- 0.488
- 0.435
- 0.472
- 0.442
- 0.418
- 0.401
- 0.433
- 0.4
- 0.432
- 0.377
- 0.388
unequal: 0
verbose: 1
