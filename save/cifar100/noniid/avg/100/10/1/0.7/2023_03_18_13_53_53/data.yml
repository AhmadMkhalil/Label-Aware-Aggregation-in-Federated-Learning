avg_train_accuracy: 0.393
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0301
- 0.0956
- 0.1177
- 0.1331
- 0.1459
- 0.1571
- 0.1646
- 0.1707
- 0.1804
- 0.1875
- 0.1979
- 0.203
- 0.2052
- 0.2131
- 0.218
- 0.2188
- 0.2213
- 0.2336
- 0.2345
- 0.2375
- 0.2442
- 0.248
- 0.2464
- 0.2503
- 0.2595
- 0.2581
- 0.2656
- 0.2667
- 0.2714
- 0.2698
- 0.2744
- 0.2732
- 0.2746
- 0.2807
- 0.2823
- 0.2859
- 0.2867
- 0.2925
- 0.2914
- 0.2918
- 0.2979
- 0.2963
- 0.2898
- 0.3
- 0.3027
- 0.3067
- 0.3071
- 0.306
- 0.3075
- 0.3091
- 0.307
- 0.3097
- 0.3016
- 0.3047
- 0.3081
- 0.3037
- 0.3132
- 0.3108
- 0.316
- 0.3139
- 0.3174
- 0.3169
- 0.3178
- 0.3172
- 0.3179
- 0.3215
- 0.32
- 0.3115
- 0.3116
- 0.3204
- 0.3227
- 0.3163
- 0.3219
- 0.3141
- 0.3148
- 0.3127
- 0.3207
- 0.3177
- 0.3202
- 0.3272
- 0.3275
- 0.3292
- 0.329
- 0.3294
- 0.3321
- 0.3314
- 0.3281
- 0.3306
- 0.3301
- 0.3286
- 0.323
- 0.3275
- 0.3299
- 0.3309
- 0.3223
- 0.323
- 0.3299
- 0.3334
- 0.336
- 0.3332
test_loss_list:
- 1.8017547941207885
- 1.6534165954589843
- 1.5952184987068176
- 1.5512054920196534
- 1.5192643642425536
- 1.4900930905342102
- 1.4687393474578858
- 1.4801601123809816
- 1.4413077330589295
- 1.4170753145217896
- 1.3972417831420898
- 1.3840526604652406
- 1.4054786825180055
- 1.367880597114563
- 1.3494662237167359
- 1.3774644255638122
- 1.3413805389404296
- 1.3191084623336793
- 1.3501589846611024
- 1.3153227400779723
- 1.2981645369529724
- 1.329323925971985
- 1.3392819619178773
- 1.3417325139045715
- 1.2927148342132568
- 1.314720094203949
- 1.273202245235443
- 1.257054991722107
- 1.2481453537940979
- 1.283311004638672
- 1.2484800148010253
- 1.278809688091278
- 1.288374879360199
- 1.2449270606040954
- 1.2692852759361266
- 1.231299319267273
- 1.2171708536148071
- 1.211729474067688
- 1.2036253023147583
- 1.2021323585510253
- 1.1983563685417176
- 1.1972749257087707
- 1.2357447576522826
- 1.2000629687309265
- 1.1926855039596558
- 1.1911607027053832
- 1.186188395023346
- 1.1816087365150452
- 1.1796606254577637
- 1.1777998256683349
- 1.1761437010765077
- 1.1758698177337648
- 1.2131680679321288
- 1.2267280340194702
- 1.190156054496765
- 1.2229527115821839
- 1.1834896779060364
- 1.1760593008995057
- 1.1695118951797485
- 1.1681155133247376
- 1.1679655075073243
- 1.1667058801651
- 1.1672364830970765
- 1.1676330494880676
- 1.1662407565116881
- 1.1620121645927428
- 1.165287630558014
- 1.203391489982605
- 1.215729296207428
- 1.172806122303009
- 1.1612956047058105
- 1.2032455062866212
- 1.1684567046165466
- 1.206362144947052
- 1.217858316898346
- 1.225729959011078
- 1.1857756757736206
- 1.2138343405723573
- 1.1796819734573365
- 1.1694683599472047
- 1.1653684520721435
- 1.1636843085289001
- 1.1634026551246643
- 1.1623661971092225
- 1.1605295586585997
- 1.1632818150520325
- 1.1643731331825256
- 1.1649969410896301
- 1.1619521117210387
- 1.1640177536010743
- 1.1983591556549071
- 1.1712895226478577
- 1.1676462054252625
- 1.1669825983047486
- 1.1997543811798095
- 1.2131379866600036
- 1.177323350906372
- 1.1659074449539184
- 1.165026683807373
- 1.1657279086112977
train_accuracy:
- 0.0
- 0.0
- 0.128
- 0.132
- 0.153
- 0.204
- 0.206
- 0.172
- 0.167
- 0.219
- 0.232
- 0.247
- 0.249
- 0.0
- 0.277
- 0.221
- 0.23
- 0.236
- 0.287
- 0.221
- 0.0
- 0.274
- 0.288
- 0.262
- 0.282
- 0.304
- 0.22
- 0.223
- 0.216
- 0.304
- 0.344
- 0.27
- 0.271
- 0.326
- 0.338
- 0.295
- 0.359
- 0.279
- 0.337
- 0.332
- 0.285
- 0.295
- 0.373
- 0.289
- 0.341
- 0.3
- 0.305
- 0.0
- 0.306
- 0.382
- 0.342
- 0.36
- 0.326
- 0.344
- 0.38
- 0.344
- 0.0
- 0.36
- 0.348
- 0.0
- 0.0
- 0.318
- 0.402
- 0.389
- 0.276
- 0.341
- 0.0
- 0.402
- 0.332
- 0.385
- 0.349
- 0.346
- 0.363
- 0.376
- 0.3
- 0.366
- 0.404
- 0.371
- 0.0
- 0.0
- 0.379
- 0.344
- 0.345
- 0.37
- 0.0
- 0.408
- 0.358
- 0.321
- 0.405
- 0.341
- 0.312
- 0.0
- 0.0
- 0.418
- 0.384
- 0.351
- 0.41
- 0.303
- 0.379
- 0.393
train_loss:
- 3.935
- 3.492
- 3.272
- 3.111
- 2.985
- 2.852
- 2.75
- 2.973
- 2.638
- 2.574
- 2.503
- 2.433
- 2.581
- 2.332
- 2.233
- 2.404
- 2.151
- 2.107
- 2.249
- 1.995
- 1.955
- 2.066
- 2.02
- 1.967
- 1.824
- 1.892
- 1.69
- 1.667
- 1.613
- 1.716
- 1.568
- 1.631
- 1.603
- 1.474
- 1.519
- 1.4
- 1.36
- 1.338
- 1.298
- 1.259
- 1.217
- 1.18
- 1.259
- 1.196
- 1.12
- 1.084
- 1.096
- 1.085
- 1.066
- 1.011
- 1.006
- 0.945
- 1.028
- 1.001
- 0.901
- 0.933
- 0.898
- 0.838
- 0.866
- 0.81
- 0.816
- 0.771
- 0.777
- 0.754
- 0.743
- 0.739
- 0.687
- 0.733
- 0.719
- 0.671
- 0.655
- 0.66
- 0.623
- 0.649
- 0.613
- 0.619
- 0.56
- 0.582
- 0.535
- 0.509
- 0.502
- 0.514
- 0.488
- 0.495
- 0.481
- 0.468
- 0.469
- 0.434
- 0.453
- 0.45
- 0.448
- 0.407
- 0.408
- 0.397
- 0.441
- 0.41
- 0.388
- 0.367
- 0.371
- 0.362
unequal: 0
verbose: 1
