avg_train_accuracy: 0.314
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04
- 0.0932
- 0.1137
- 0.1371
- 0.1521
- 0.1651
- 0.1762
- 0.181
- 0.1864
- 0.1953
- 0.2015
- 0.2084
- 0.2141
- 0.219
- 0.2257
- 0.228
- 0.2341
- 0.2335
- 0.2428
- 0.2443
- 0.2481
- 0.2481
- 0.2493
- 0.2522
- 0.2565
- 0.2599
- 0.266
- 0.2657
- 0.2648
- 0.2643
- 0.2721
- 0.2774
- 0.2745
- 0.2764
- 0.2783
- 0.2791
- 0.2815
- 0.2839
- 0.2896
- 0.2886
- 0.2903
- 0.2892
- 0.2891
- 0.2917
- 0.2951
- 0.296
- 0.2978
- 0.2982
- 0.3021
- 0.3002
- 0.2999
- 0.2987
- 0.301
- 0.2992
- 0.3036
- 0.3062
- 0.306
- 0.306
- 0.307
- 0.3123
- 0.3128
- 0.3126
- 0.3099
- 0.311
- 0.3162
- 0.3131
- 0.3132
- 0.3174
- 0.3131
- 0.3135
- 0.3198
- 0.3199
- 0.319
- 0.3182
- 0.3182
- 0.3184
- 0.3193
- 0.3142
- 0.3138
- 0.3188
- 0.3232
- 0.325
- 0.3276
- 0.3246
- 0.326
- 0.3231
- 0.3203
- 0.3198
- 0.322
- 0.3261
- 0.3258
- 0.3265
- 0.3275
- 0.32
- 0.3189
- 0.3261
- 0.3286
- 0.3289
- 0.3234
- 0.3201
test_loss_list:
- 1.7957477378845215
- 1.661369242668152
- 1.6051208138465882
- 1.5859631943702697
- 1.5333540201187135
- 1.4996223282814025
- 1.502926642894745
- 1.460639042854309
- 1.4698841261863709
- 1.4286137700080872
- 1.4425129175186158
- 1.4022160768508911
- 1.376419849395752
- 1.3622358870506286
- 1.3518371057510377
- 1.3400592994689942
- 1.3313954663276673
- 1.324881899356842
- 1.31367333650589
- 1.3071618628501893
- 1.3015617847442627
- 1.3297523713111878
- 1.3008969473838805
- 1.3231380319595336
- 1.2858730053901672
- 1.2735260510444641
- 1.2658778095245362
- 1.2977756667137146
- 1.2682169914245605
- 1.2972432136535645
- 1.2607866787910462
- 1.2451586103439332
- 1.281378390789032
- 1.2910698008537294
- 1.252073392868042
- 1.2790614795684814
- 1.2413603520393373
- 1.2308244252204894
- 1.2193344640731811
- 1.2177802443504333
- 1.2174229049682617
- 1.249129445552826
- 1.263300986289978
- 1.2225302052497864
- 1.2121021938323975
- 1.206748423576355
- 1.201399438381195
- 1.1982033920288087
- 1.1952538228034972
- 1.2341690230369569
- 1.2016616725921632
- 1.2345311546325684
- 1.2464368081092834
- 1.2523565626144408
- 1.2097283983230591
- 1.193830897808075
- 1.1850086808204652
- 1.2202773809432983
- 1.1876268315315246
- 1.184340705871582
- 1.1764599609375
- 1.1782550096511841
- 1.21325040102005
- 1.1876517224311829
- 1.1805317664146424
- 1.2096660542488098
- 1.183241286277771
- 1.1786084914207458
- 1.2141847681999207
- 1.1825861120224
- 1.1759553694725036
- 1.1734430599212646
- 1.168039906024933
- 1.1689279770851135
- 1.1684914994239808
- 1.2035391020774842
- 1.173573076725006
- 1.2153221106529235
- 1.2222724962234497
- 1.1842269730567931
- 1.1708960247039795
- 1.1710822343826295
- 1.170309066772461
- 1.1679627561569215
- 1.166682677268982
- 1.1689141035079955
- 1.1995055150985718
- 1.2149882435798645
- 1.1804257440567016
- 1.1714751935005188
- 1.1700140500068665
- 1.169802188873291
- 1.1721661257743836
- 1.2043516421318055
- 1.2158615255355836
- 1.1801466035842896
- 1.173375403881073
- 1.1755550336837768
- 1.2064802527427674
- 1.2187548756599427
train_accuracy:
- 0.038
- 0.09
- 0.108
- 0.156
- 0.155
- 0.15
- 0.19
- 0.194
- 0.206
- 0.216
- 0.208
- 0.179
- 0.239
- 0.233
- 0.237
- 0.229
- 0.263
- 0.259
- 0.263
- 0.275
- 0.265
- 0.287
- 0.274
- 0.28
- 0.277
- 0.287
- 0.252
- 0.307
- 0.295
- 0.29
- 0.289
- 0.308
- 0.306
- 0.286
- 0.303
- 0.306
- 0.286
- 0.24
- 0.27
- 0.281
- 0.296
- 0.324
- 0.289
- 0.291
- 0.292
- 0.263
- 0.0
- 0.316
- 0.265
- 0.331
- 0.3
- 0.292
- 0.346
- 0.285
- 0.279
- 0.0
- 0.356
- 0.332
- 0.343
- 0.343
- 0.285
- 0.303
- 0.351
- 0.0
- 0.328
- 0.293
- 0.371
- 0.339
- 0.33
- 0.359
- 0.324
- 0.0
- 0.34
- 0.368
- 0.314
- 0.336
- 0.318
- 0.384
- 0.32
- 0.358
- 0.325
- 0.338
- 0.29
- 0.348
- 0.33
- 0.291
- 0.355
- 0.318
- 0.316
- 0.306
- 0.338
- 0.352
- 0.322
- 0.35
- 0.332
- 0.389
- 0.328
- 0.306
- 0.302
- 0.314
train_loss:
- 3.948
- 3.525
- 3.308
- 3.43
- 3.013
- 2.905
- 3.053
- 2.733
- 2.864
- 2.586
- 2.712
- 2.452
- 2.41
- 2.33
- 2.248
- 2.225
- 2.141
- 2.084
- 2.05
- 2.021
- 1.974
- 2.133
- 1.904
- 2.037
- 1.799
- 1.787
- 1.721
- 1.891
- 1.656
- 1.778
- 1.584
- 1.568
- 1.645
- 1.612
- 1.464
- 1.547
- 1.438
- 1.34
- 1.34
- 1.313
- 1.249
- 1.414
- 1.29
- 1.222
- 1.153
- 1.134
- 1.096
- 1.127
- 1.073
- 1.134
- 1.026
- 1.101
- 1.048
- 1.044
- 0.965
- 0.931
- 0.919
- 0.95
- 0.873
- 0.841
- 0.833
- 0.817
- 0.848
- 0.759
- 0.739
- 0.785
- 0.71
- 0.692
- 0.72
- 0.668
- 0.67
- 0.638
- 0.639
- 0.63
- 0.626
- 0.642
- 0.614
- 0.595
- 0.588
- 0.543
- 0.547
- 0.505
- 0.527
- 0.499
- 0.502
- 0.482
- 0.503
- 0.482
- 0.46
- 0.458
- 0.431
- 0.431
- 0.419
- 0.423
- 0.425
- 0.399
- 0.393
- 0.384
- 0.408
- 0.38
unequal: 0
verbose: 1
