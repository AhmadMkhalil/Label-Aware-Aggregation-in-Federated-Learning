avg_train_accuracy: 0.423
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0406
- 0.0982
- 0.1167
- 0.1339
- 0.1476
- 0.1644
- 0.167
- 0.1792
- 0.185
- 0.194
- 0.2003
- 0.2064
- 0.2129
- 0.2192
- 0.2256
- 0.2267
- 0.2318
- 0.2364
- 0.2425
- 0.2425
- 0.2488
- 0.252
- 0.2545
- 0.2574
- 0.2577
- 0.2632
- 0.2661
- 0.2695
- 0.2749
- 0.2695
- 0.2711
- 0.2801
- 0.2849
- 0.2865
- 0.2827
- 0.2825
- 0.2874
- 0.2892
- 0.2902
- 0.2912
- 0.2945
- 0.2919
- 0.2945
- 0.3027
- 0.3019
- 0.3035
- 0.3
- 0.308
- 0.3014
- 0.3056
- 0.3059
- 0.3061
- 0.3035
- 0.3101
- 0.3099
- 0.3124
- 0.3107
- 0.311
- 0.3173
- 0.3141
- 0.3129
- 0.3156
- 0.3168
- 0.3178
- 0.3167
- 0.3173
- 0.3213
- 0.3171
- 0.3147
- 0.3197
- 0.3204
- 0.32
- 0.3234
- 0.323
- 0.3237
- 0.3235
- 0.3243
- 0.3242
- 0.3178
- 0.3201
- 0.3234
- 0.3245
- 0.3183
- 0.3214
- 0.3234
- 0.3255
- 0.3281
- 0.3206
- 0.327
- 0.3292
- 0.3298
- 0.3318
- 0.3312
- 0.3266
- 0.3293
- 0.3319
- 0.3325
- 0.3279
- 0.3298
- 0.3313
test_loss_list:
- 1.804853205680847
- 1.704052734375
- 1.6264804482460022
- 1.5699162769317627
- 1.5277488398551942
- 1.5277853035926818
- 1.5232925033569336
- 1.4692164134979249
- 1.4379145216941833
- 1.4540364050865173
- 1.4152623844146728
- 1.393081030845642
- 1.3747711563110352
- 1.3614015412330627
- 1.3485327887535095
- 1.37594708442688
- 1.3818213438987732
- 1.3365981483459473
- 1.3154411602020264
- 1.34201012134552
- 1.3513184714317321
- 1.3074310612678528
- 1.2853737258911133
- 1.3154990243911744
- 1.2806438827514648
- 1.2666044902801514
- 1.2557176804542542
- 1.2514113402366638
- 1.2457700324058534
- 1.2794071698188783
- 1.247365987300873
- 1.2335688638687134
- 1.2266164636611938
- 1.2224537444114685
- 1.2575030946731567
- 1.2282904267311097
- 1.2142455720901488
- 1.249031913280487
- 1.2197186613082887
- 1.2477292585372926
- 1.2148218727111817
- 1.2423657369613648
- 1.2106817221641542
- 1.1963641834259033
- 1.1933956551551819
- 1.1917702388763427
- 1.2256057977676391
- 1.1904376816749573
- 1.2262031936645508
- 1.1892166972160338
- 1.1803230547904968
- 1.2145578837394715
- 1.1853292679786682
- 1.175745575428009
- 1.2098022818565368
- 1.1819963335990906
- 1.1760859322547912
- 1.1703140497207642
- 1.167312936782837
- 1.2031588578224182
- 1.1768281722068787
- 1.1676475167274476
- 1.201898136138916
- 1.170580997467041
- 1.1671697807312011
- 1.1647593641281129
- 1.1587915849685668
- 1.1952662920951844
- 1.2091082239151
- 1.1701256227493286
- 1.1627910447120666
- 1.1616166400909425
- 1.1570346879959106
- 1.1563774824142456
- 1.1562398386001587
- 1.1509444904327393
- 1.1553822016716004
- 1.154212327003479
- 1.1894534635543823
- 1.1635065650939942
- 1.1565844559669494
- 1.1538257193565369
- 1.1919718742370606
- 1.2039074802398682
- 1.1687958455085754
- 1.1635921752452851
- 1.154851723909378
- 1.1902297449111938
- 1.1637037003040314
- 1.1599184656143189
- 1.1570085418224334
- 1.156029462814331
- 1.1556981313228607
- 1.1890674364566802
- 1.160722448825836
- 1.1545558214187621
- 1.157358272075653
- 1.191619348526001
- 1.1654378950595856
- 1.1569191718101501
train_accuracy:
- 0.058
- 0.115
- 0.118
- 0.135
- 0.181
- 0.159
- 0.186
- 0.173
- 0.159
- 0.17
- 0.203
- 0.178
- 0.228
- 0.264
- 0.0
- 0.234
- 0.269
- 0.262
- 0.0
- 0.311
- 0.23
- 0.237
- 0.269
- 0.274
- 0.0
- 0.0
- 0.289
- 0.288
- 0.299
- 0.293
- 0.308
- 0.265
- 0.323
- 0.337
- 0.289
- 0.338
- 0.294
- 0.357
- 0.327
- 0.32
- 0.343
- 0.366
- 0.283
- 0.371
- 0.346
- 0.291
- 0.3
- 0.335
- 0.37
- 0.0
- 0.296
- 0.374
- 0.359
- 0.333
- 0.396
- 0.321
- 0.315
- 0.35
- 0.314
- 0.371
- 0.356
- 0.378
- 0.362
- 0.342
- 0.372
- 0.0
- 0.378
- 0.396
- 0.348
- 0.315
- 0.317
- 0.321
- 0.317
- 0.4
- 0.323
- 0.38
- 0.365
- 0.376
- 0.332
- 0.397
- 0.401
- 0.391
- 0.398
- 0.379
- 0.367
- 0.4
- 0.387
- 0.359
- 0.0
- 0.378
- 0.366
- 0.402
- 0.396
- 0.41
- 0.0
- 0.0
- 0.396
- 0.363
- 0.388
- 0.423
train_loss:
- 4.299
- 3.827
- 3.35
- 3.174
- 3.032
- 3.173
- 3.051
- 2.726
- 2.659
- 2.782
- 2.476
- 2.448
- 2.428
- 2.325
- 2.275
- 2.43
- 2.362
- 2.092
- 2.112
- 2.182
- 2.126
- 1.936
- 1.869
- 2.024
- 1.796
- 1.743
- 1.723
- 1.657
- 1.695
- 1.738
- 1.585
- 1.555
- 1.53
- 1.477
- 1.57
- 1.449
- 1.39
- 1.491
- 1.348
- 1.418
- 1.267
- 1.344
- 1.218
- 1.179
- 1.164
- 1.117
- 1.227
- 1.07
- 1.185
- 1.069
- 1.028
- 1.081
- 0.971
- 0.966
- 1.016
- 0.912
- 0.867
- 0.89
- 0.877
- 0.915
- 0.842
- 0.801
- 0.857
- 0.764
- 0.745
- 0.73
- 0.726
- 0.756
- 0.738
- 0.67
- 0.649
- 0.66
- 0.628
- 0.602
- 0.614
- 0.608
- 0.575
- 0.574
- 0.605
- 0.544
- 0.538
- 0.516
- 0.543
- 0.537
- 0.492
- 0.488
- 0.48
- 0.493
- 0.459
- 0.449
- 0.435
- 0.421
- 0.413
- 0.425
- 0.415
- 0.399
- 0.387
- 0.405
- 0.384
- 0.376
unequal: 0
verbose: 1
