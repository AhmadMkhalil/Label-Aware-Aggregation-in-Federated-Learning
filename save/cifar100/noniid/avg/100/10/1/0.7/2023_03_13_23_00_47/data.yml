avg_train_accuracy: 0.305
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0956
- 0.1226
- 0.1328
- 0.1546
- 0.1616
- 0.1696
- 0.1779
- 0.1847
- 0.1949
- 0.2007
- 0.2057
- 0.2097
- 0.2134
- 0.2194
- 0.2273
- 0.2275
- 0.2341
- 0.2371
- 0.2394
- 0.2445
- 0.2475
- 0.2473
- 0.2524
- 0.2548
- 0.2615
- 0.2597
- 0.2577
- 0.2673
- 0.2718
- 0.2729
- 0.2758
- 0.2775
- 0.2814
- 0.2794
- 0.2784
- 0.2822
- 0.2843
- 0.2888
- 0.2909
- 0.2886
- 0.2905
- 0.2917
- 0.295
- 0.2975
- 0.2947
- 0.2988
- 0.2961
- 0.2973
- 0.2996
- 0.3023
- 0.2984
- 0.3035
- 0.3032
- 0.3092
- 0.3014
- 0.3063
- 0.3049
- 0.3059
- 0.3101
- 0.3121
- 0.3117
- 0.3085
- 0.3139
- 0.3111
- 0.3102
- 0.3147
- 0.3151
- 0.3173
- 0.3179
- 0.314
- 0.3165
- 0.315
- 0.3114
- 0.316
- 0.3146
- 0.3179
- 0.3187
- 0.3219
- 0.3198
- 0.3215
- 0.3276
- 0.3251
- 0.3246
- 0.3254
- 0.3217
- 0.3223
- 0.3242
- 0.3262
- 0.325
- 0.3272
- 0.3262
- 0.3228
- 0.3234
- 0.3261
- 0.3298
- 0.3312
- 0.3309
- 0.3256
- 0.3282
test_loss_list:
- 1.7946755266189576
- 1.6623886394500733
- 1.6272287797927856
- 1.5665019297599792
- 1.5563047456741332
- 1.5092018389701842
- 1.4777471113204956
- 1.4531392788887023
- 1.4696503376960754
- 1.4266972970962524
- 1.4050173091888427
- 1.3887464594841004
- 1.373512601852417
- 1.3979651379585265
- 1.40192049741745
- 1.4033237838745116
- 1.3523653483390807
- 1.3276973628997804
- 1.3146383309364318
- 1.306420819759369
- 1.2983304166793823
- 1.290772614479065
- 1.2847563338279724
- 1.2758617568016053
- 1.2721483063697816
- 1.2657161045074463
- 1.2588510608673096
- 1.2922576689720153
- 1.259628839492798
- 1.2479043793678284
- 1.2415595483779907
- 1.2751598525047303
- 1.24196679353714
- 1.2300025391578675
- 1.2678024053573609
- 1.2773216342926026
- 1.2386060881614684
- 1.2208556818962097
- 1.214268503189087
- 1.2089099645614625
- 1.2429179382324218
- 1.211505823135376
- 1.2416514873504638
- 1.2100862646102906
- 1.1983212995529176
- 1.2333821535110474
- 1.2009056878089905
- 1.2324927639961243
- 1.2446308302879334
- 1.2048829340934752
- 1.1912072920799255
- 1.224501099586487
- 1.1946423959732055
- 1.1841374278068542
- 1.1799960041046142
- 1.2149388885498047
- 1.186626546382904
- 1.2231358909606933
- 1.185551609992981
- 1.176626114845276
- 1.1690842032432556
- 1.1679227781295776
- 1.2081194448471069
- 1.1770948457717896
- 1.167768921852112
- 1.2079603457450867
- 1.1757658219337463
- 1.1701389002799987
- 1.1628713083267213
- 1.1621773767471313
- 1.2051433181762696
- 1.1714789128303529
- 1.2059534525871276
- 1.2259611225128173
- 1.2287632536888122
- 1.231811273097992
- 1.1876615333557128
- 1.1759273219108581
- 1.1667941188812256
- 1.167999768257141
- 1.1644704008102418
- 1.1634965538978577
- 1.1630226469039917
- 1.1622681832313537
- 1.1615282249450685
- 1.2000652050971985
- 1.210394902229309
- 1.1774608945846559
- 1.1631308746337892
- 1.2005549693107604
- 1.1712500548362732
- 1.2038305187225342
- 1.2142566108703614
- 1.2285157465934753
- 1.1822435927391053
- 1.1711717414855958
- 1.1637581491470337
- 1.1698133540153504
- 1.2046826314926147
- 1.1756880474090576
train_accuracy:
- 0.042
- 0.085
- 0.107
- 0.0
- 0.157
- 0.0
- 0.142
- 0.186
- 0.222
- 0.0
- 0.174
- 0.166
- 0.192
- 0.213
- 0.229
- 0.268
- 0.0
- 0.236
- 0.308
- 0.242
- 0.287
- 0.288
- 0.231
- 0.308
- 0.314
- 0.241
- 0.236
- 0.333
- 0.223
- 0.31
- 0.32
- 0.252
- 0.26
- 0.0
- 0.279
- 0.297
- 0.262
- 0.323
- 0.276
- 0.306
- 0.324
- 0.334
- 0.315
- 0.29
- 0.286
- 0.341
- 0.333
- 0.322
- 0.308
- 0.263
- 0.271
- 0.342
- 0.359
- 0.303
- 0.312
- 0.318
- 0.293
- 0.278
- 0.352
- 0.34
- 0.313
- 0.317
- 0.35
- 0.405
- 0.0
- 0.346
- 0.287
- 0.401
- 0.379
- 0.386
- 0.326
- 0.289
- 0.37
- 0.278
- 0.337
- 0.359
- 0.293
- 0.347
- 0.402
- 0.345
- 0.293
- 0.29
- 0.356
- 0.0
- 0.346
- 0.307
- 0.291
- 0.362
- 0.299
- 0.382
- 0.0
- 0.313
- 0.348
- 0.355
- 0.354
- 0.295
- 0.295
- 0.42
- 0.381
- 0.305
train_loss:
- 3.909
- 3.502
- 3.592
- 3.127
- 3.251
- 2.891
- 2.779
- 2.7
- 2.885
- 2.554
- 2.467
- 2.408
- 2.342
- 2.501
- 2.416
- 2.364
- 2.171
- 2.06
- 2.003
- 1.975
- 1.914
- 1.874
- 1.873
- 1.808
- 1.745
- 1.76
- 1.709
- 1.794
- 1.644
- 1.596
- 1.547
- 1.64
- 1.509
- 1.47
- 1.537
- 1.494
- 1.344
- 1.343
- 1.274
- 1.255
- 1.356
- 1.22
- 1.294
- 1.161
- 1.116
- 1.208
- 1.091
- 1.151
- 1.104
- 1.02
- 0.995
- 1.043
- 0.92
- 0.935
- 0.913
- 0.966
- 0.887
- 0.91
- 0.812
- 0.803
- 0.795
- 0.78
- 0.787
- 0.762
- 0.743
- 0.747
- 0.693
- 0.684
- 0.66
- 0.649
- 0.677
- 0.607
- 0.644
- 0.644
- 0.614
- 0.601
- 0.57
- 0.55
- 0.533
- 0.514
- 0.502
- 0.506
- 0.48
- 0.492
- 0.461
- 0.464
- 0.481
- 0.438
- 0.437
- 0.449
- 0.42
- 0.425
- 0.424
- 0.405
- 0.375
- 0.363
- 0.378
- 0.363
- 0.376
- 0.356
unequal: 0
verbose: 1
