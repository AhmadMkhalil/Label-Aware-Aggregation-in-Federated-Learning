avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0404
- 0.0988
- 0.1195
- 0.1327
- 0.15
- 0.1584
- 0.1697
- 0.1792
- 0.1878
- 0.1975
- 0.2005
- 0.2065
- 0.2125
- 0.2179
- 0.2235
- 0.2261
- 0.2306
- 0.2385
- 0.241
- 0.2427
- 0.245
- 0.2492
- 0.2546
- 0.2524
- 0.2572
- 0.2596
- 0.2639
- 0.2675
- 0.2728
- 0.2739
- 0.2699
- 0.2749
- 0.2772
- 0.2736
- 0.2799
- 0.2829
- 0.2792
- 0.2867
- 0.284
- 0.2879
- 0.2904
- 0.2908
- 0.2948
- 0.2997
- 0.2954
- 0.2957
- 0.2978
- 0.2937
- 0.2984
- 0.3039
- 0.3011
- 0.3047
- 0.301
- 0.3005
- 0.3024
- 0.3039
- 0.3057
- 0.3025
- 0.3038
- 0.3054
- 0.3074
- 0.3116
- 0.304
- 0.3133
- 0.3107
- 0.309
- 0.3118
- 0.3155
- 0.3189
- 0.3176
- 0.3197
- 0.3143
- 0.3169
- 0.3186
- 0.3207
- 0.3158
- 0.3165
- 0.3229
- 0.3238
- 0.3225
- 0.3198
- 0.323
- 0.3188
- 0.3225
- 0.3252
- 0.3178
- 0.3265
- 0.3266
- 0.3279
- 0.3227
- 0.3284
- 0.3281
- 0.3323
- 0.3293
- 0.324
- 0.3312
- 0.3335
- 0.3338
- 0.3251
- 0.329
test_loss_list:
- 1.795841941833496
- 1.6639948987960815
- 1.628964259624481
- 1.6037478494644164
- 1.5432159900665283
- 1.5016852307319641
- 1.5079732632637024
- 1.4641993379592895
- 1.4385166239738465
- 1.4200514698028563
- 1.4032549309730529
- 1.3863792037963867
- 1.406826181411743
- 1.4123813724517822
- 1.3678595399856568
- 1.3500130987167358
- 1.3336080503463745
- 1.3573654198646545
- 1.323401005268097
- 1.3104179048538207
- 1.3382621574401856
- 1.3038339304924011
- 1.290515341758728
- 1.3210072493553162
- 1.3290949392318725
- 1.2900730490684509
- 1.2716150736808778
- 1.2627855157852172
- 1.2549838638305664
- 1.2492095565795898
- 1.2818631362915038
- 1.2501905512809754
- 1.2414938402175903
- 1.2720656323432922
- 1.2385866284370421
- 1.2267766571044922
- 1.2617128562927247
- 1.228587248325348
- 1.2573964142799376
- 1.2254793095588683
- 1.2132988572120667
- 1.2071058464050293
- 1.2048630952835082
- 1.2028567719459533
- 1.2008319878578186
- 1.1995068979263306
- 1.2316416788101197
- 1.2422183966636657
- 1.2062234091758728
- 1.1948407316207885
- 1.1888081169128417
- 1.1859693646430969
- 1.2198575568199157
- 1.236128957271576
- 1.1982586765289307
- 1.1862902736663818
- 1.1819032883644105
- 1.2202314019203186
- 1.2303684496879577
- 1.191393325328827
- 1.1812916922569274
- 1.1771948051452636
- 1.2147767210006715
- 1.1838522481918334
- 1.2130605101585388
- 1.2290281105041503
- 1.1942169976234436
- 1.1820577573776245
- 1.1739887166023255
- 1.175832211971283
- 1.1711858463287355
- 1.2078419375419616
- 1.181169457435608
- 1.175884974002838
- 1.1737429213523864
- 1.2060645008087159
- 1.1827295732498169
- 1.1712012195587158
- 1.1674244093894959
- 1.1710894179344178
- 1.206370186805725
- 1.1760216903686525
- 1.2112836980819701
- 1.1782863068580627
- 1.1734158658981324
- 1.2112209606170654
- 1.1771101999282836
- 1.1719703555107117
- 1.1722699546813964
- 1.2097806429862976
- 1.180354313850403
- 1.1747115850448608
- 1.17123295545578
- 1.1740594577789307
- 1.204789571762085
- 1.1766452860832215
- 1.174825050830841
- 1.1740529179573058
- 1.206259353160858
- 1.1805031943321227
train_accuracy:
- 0.0
- 0.0
- 0.123
- 0.146
- 0.158
- 0.192
- 0.208
- 0.179
- 0.175
- 0.181
- 0.184
- 0.217
- 0.196
- 0.206
- 0.22
- 0.24
- 0.23
- 0.23
- 0.0
- 0.0
- 0.279
- 0.241
- 0.246
- 0.292
- 0.256
- 0.0
- 0.252
- 0.0
- 0.246
- 0.238
- 0.286
- 0.281
- 0.307
- 0.276
- 0.278
- 0.286
- 0.289
- 0.29
- 0.329
- 0.291
- 0.275
- 0.28
- 0.311
- 0.273
- 0.311
- 0.0
- 0.309
- 0.324
- 0.307
- 0.287
- 0.306
- 0.0
- 0.283
- 0.299
- 0.276
- 0.298
- 0.283
- 0.305
- 0.325
- 0.316
- 0.314
- 0.316
- 0.332
- 0.318
- 0.328
- 0.319
- 0.319
- 0.33
- 0.316
- 0.0
- 0.314
- 0.349
- 0.35
- 0.329
- 0.338
- 0.286
- 0.33
- 0.329
- 0.0
- 0.332
- 0.311
- 0.0
- 0.346
- 0.344
- 0.303
- 0.328
- 0.328
- 0.327
- 0.343
- 0.344
- 0.33
- 0.334
- 0.33
- 0.344
- 0.339
- 0.301
- 0.371
- 0.353
- 0.364
- 0.0
train_loss:
- 3.905
- 3.509
- 3.605
- 3.389
- 3.033
- 2.916
- 3.057
- 2.717
- 2.644
- 2.584
- 2.516
- 2.455
- 2.598
- 2.521
- 2.272
- 2.179
- 2.151
- 2.269
- 2.049
- 2.004
- 2.153
- 1.922
- 1.89
- 1.981
- 1.961
- 1.74
- 1.676
- 1.693
- 1.633
- 1.575
- 1.729
- 1.545
- 1.483
- 1.614
- 1.438
- 1.444
- 1.485
- 1.382
- 1.415
- 1.286
- 1.252
- 1.222
- 1.172
- 1.179
- 1.126
- 1.117
- 1.165
- 1.154
- 1.052
- 1.037
- 1.018
- 0.942
- 1.073
- 0.983
- 0.929
- 0.91
- 0.869
- 0.933
- 0.882
- 0.821
- 0.778
- 0.788
- 0.814
- 0.761
- 0.761
- 0.758
- 0.674
- 0.662
- 0.66
- 0.664
- 0.627
- 0.652
- 0.613
- 0.582
- 0.557
- 0.625
- 0.554
- 0.565
- 0.543
- 0.52
- 0.554
- 0.507
- 0.502
- 0.479
- 0.48
- 0.49
- 0.467
- 0.439
- 0.43
- 0.454
- 0.425
- 0.411
- 0.403
- 0.389
- 0.391
- 0.388
- 0.373
- 0.361
- 0.372
- 0.348
unequal: 0
verbose: 1
