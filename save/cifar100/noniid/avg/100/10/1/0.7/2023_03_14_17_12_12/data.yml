avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0414
- 0.0882
- 0.1083
- 0.1257
- 0.1396
- 0.1561
- 0.1647
- 0.1754
- 0.1828
- 0.1895
- 0.2022
- 0.2071
- 0.2109
- 0.2157
- 0.2227
- 0.2274
- 0.2277
- 0.2336
- 0.2413
- 0.2417
- 0.2505
- 0.2506
- 0.2531
- 0.2518
- 0.2577
- 0.2621
- 0.2642
- 0.2688
- 0.2688
- 0.2661
- 0.2707
- 0.2739
- 0.2778
- 0.2836
- 0.2784
- 0.2808
- 0.2889
- 0.2791
- 0.2872
- 0.2928
- 0.2917
- 0.2908
- 0.2918
- 0.294
- 0.2974
- 0.2957
- 0.2983
- 0.3043
- 0.3061
- 0.3078
- 0.3086
- 0.3067
- 0.2994
- 0.3087
- 0.3063
- 0.3089
- 0.3119
- 0.3148
- 0.3074
- 0.3117
- 0.3157
- 0.3135
- 0.3203
- 0.3202
- 0.3203
- 0.325
- 0.3147
- 0.321
- 0.3236
- 0.3178
- 0.3207
- 0.3248
- 0.3206
- 0.3209
- 0.321
- 0.3241
- 0.3256
- 0.3278
- 0.3287
- 0.3221
- 0.3261
- 0.3272
- 0.3283
- 0.3248
- 0.3316
- 0.3319
- 0.3276
- 0.3289
- 0.3328
- 0.3324
- 0.3326
- 0.3238
- 0.3343
- 0.333
- 0.3364
- 0.3351
- 0.3381
- 0.3354
- 0.3383
- 0.3363
test_loss_list:
- 1.8040520668029785
- 1.673192071914673
- 1.6175359535217284
- 1.5741069984436036
- 1.5364683628082276
- 1.5017112755775452
- 1.4782681035995484
- 1.4859670209884643
- 1.4444541788101197
- 1.4198336839675902
- 1.4001201438903808
- 1.3875743651390076
- 1.3739486622810364
- 1.3612083530426025
- 1.3514550232887268
- 1.340399479866028
- 1.3666775298118592
- 1.3322572636604308
- 1.3160006260871888
- 1.3052664709091186
- 1.2977514863014221
- 1.2887051701545715
- 1.2829308104515076
- 1.3125516033172608
- 1.2809842777252198
- 1.2689297008514404
- 1.2619385933876037
- 1.2564406991004944
- 1.2504454255104065
- 1.2835411977767945
- 1.252514533996582
- 1.2401108932495117
- 1.2345420908927918
- 1.2236364936828614
- 1.2574299716949462
- 1.2302970695495605
- 1.2154078269004822
- 1.2539382839202882
- 1.2592432808876037
- 1.219117856025696
- 1.2063620567321778
- 1.242518014907837
- 1.2499797463417053
- 1.2085591864585876
- 1.1940644431114196
- 1.2296999931335448
- 1.1953594946861268
- 1.185042757987976
- 1.1814043354988097
- 1.1779222941398622
- 1.1753482031822204
- 1.176443519592285
- 1.2131043815612792
- 1.1806735873222352
- 1.2113606977462767
- 1.1797999882698058
- 1.169608612060547
- 1.165521047115326
- 1.2047774600982666
- 1.1738434553146362
- 1.1644073295593262
- 1.1615690231323241
- 1.160537428855896
- 1.1573443961143495
- 1.1583763289451598
- 1.1567175269126893
- 1.1948219656944274
- 1.1674117517471314
- 1.1620340991020202
- 1.1976976084709168
- 1.1680280590057373
- 1.1565717005729674
- 1.190894832611084
- 1.16570148229599
- 1.1942013382911683
- 1.164110734462738
- 1.1564252853393555
- 1.1527453804016112
- 1.1495616388320924
- 1.18709823846817
- 1.1564777159690858
- 1.1570053696632385
- 1.150858952999115
- 1.1890030360221864
- 1.159184579849243
- 1.151824893951416
- 1.1526660799980164
- 1.1537159204483032
- 1.1517815470695496
- 1.1538307094573974
- 1.151993842124939
- 1.1893802881240845
- 1.1563020157814026
- 1.1530126976966857
- 1.1560840678215027
- 1.1524711656570434
- 1.151689338684082
- 1.1531892156600951
- 1.1546379923820496
- 1.1547095990180969
train_accuracy:
- 0.049
- 0.0
- 0.098
- 0.154
- 0.139
- 0.171
- 0.176
- 0.119
- 0.178
- 0.193
- 0.247
- 0.214
- 0.201
- 0.0
- 0.218
- 0.277
- 0.219
- 0.239
- 0.228
- 0.218
- 0.224
- 0.182
- 0.213
- 0.196
- 0.218
- 0.292
- 0.302
- 0.289
- 0.25
- 0.29
- 0.0
- 0.261
- 0.302
- 0.326
- 0.325
- 0.0
- 0.239
- 0.3
- 0.275
- 0.321
- 0.304
- 0.272
- 0.307
- 0.334
- 0.345
- 0.276
- 0.0
- 0.336
- 0.289
- 0.3
- 0.273
- 0.0
- 0.285
- 0.355
- 0.257
- 0.287
- 0.263
- 0.318
- 0.292
- 0.293
- 0.302
- 0.308
- 0.0
- 0.356
- 0.303
- 0.359
- 0.307
- 0.334
- 0.312
- 0.321
- 0.362
- 0.318
- 0.327
- 0.301
- 0.319
- 0.32
- 0.383
- 0.287
- 0.368
- 0.338
- 0.363
- 0.368
- 0.344
- 0.314
- 0.379
- 0.0
- 0.299
- 0.329
- 0.332
- 0.39
- 0.35
- 0.372
- 0.344
- 0.377
- 0.315
- 0.318
- 0.33
- 0.34
- 0.344
- 0.0
train_loss:
- 3.926
- 3.55
- 3.336
- 3.193
- 3.082
- 2.963
- 2.861
- 3.023
- 2.7
- 2.606
- 2.538
- 2.449
- 2.439
- 2.35
- 2.289
- 2.263
- 2.421
- 2.138
- 2.1
- 2.099
- 2.029
- 1.954
- 1.938
- 2.065
- 1.861
- 1.802
- 1.728
- 1.737
- 1.69
- 1.835
- 1.596
- 1.608
- 1.556
- 1.573
- 1.668
- 1.443
- 1.462
- 1.566
- 1.513
- 1.372
- 1.32
- 1.413
- 1.375
- 1.255
- 1.177
- 1.302
- 1.137
- 1.149
- 1.066
- 1.103
- 1.063
- 1.033
- 1.107
- 0.979
- 1.083
- 0.949
- 0.932
- 0.925
- 0.959
- 0.876
- 0.861
- 0.839
- 0.819
- 0.805
- 0.784
- 0.754
- 0.827
- 0.717
- 0.724
- 0.783
- 0.689
- 0.685
- 0.717
- 0.638
- 0.681
- 0.612
- 0.603
- 0.569
- 0.578
- 0.607
- 0.568
- 0.529
- 0.544
- 0.568
- 0.51
- 0.514
- 0.484
- 0.486
- 0.471
- 0.474
- 0.464
- 0.473
- 0.427
- 0.425
- 0.411
- 0.423
- 0.397
- 0.383
- 0.376
- 0.398
unequal: 0
verbose: 1
