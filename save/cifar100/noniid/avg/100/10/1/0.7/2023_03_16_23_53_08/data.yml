avg_train_accuracy: 0.339
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0329
- 0.0972
- 0.1244
- 0.1416
- 0.1488
- 0.1632
- 0.1711
- 0.1783
- 0.1877
- 0.1959
- 0.2024
- 0.2072
- 0.2141
- 0.2205
- 0.2268
- 0.231
- 0.2352
- 0.238
- 0.2413
- 0.2446
- 0.2498
- 0.2481
- 0.2548
- 0.2615
- 0.2597
- 0.2672
- 0.2648
- 0.2684
- 0.2722
- 0.2781
- 0.2744
- 0.2771
- 0.2805
- 0.2771
- 0.2847
- 0.2802
- 0.287
- 0.2883
- 0.2914
- 0.292
- 0.294
- 0.2938
- 0.2961
- 0.2968
- 0.2995
- 0.2995
- 0.2981
- 0.2977
- 0.3026
- 0.3038
- 0.3061
- 0.3068
- 0.3072
- 0.3092
- 0.3137
- 0.3101
- 0.3072
- 0.3136
- 0.3145
- 0.3152
- 0.3175
- 0.3133
- 0.3127
- 0.3176
- 0.3148
- 0.3169
- 0.3188
- 0.3157
- 0.3196
- 0.321
- 0.322
- 0.32
- 0.3176
- 0.3198
- 0.3246
- 0.3253
- 0.3303
- 0.3223
- 0.3292
- 0.333
- 0.3306
- 0.3309
- 0.3312
- 0.33
- 0.3303
- 0.3313
- 0.3338
- 0.3358
- 0.3321
- 0.3308
- 0.3353
- 0.3385
- 0.3293
- 0.3352
- 0.3325
- 0.3338
- 0.3366
- 0.3394
- 0.34
- 0.3313
test_loss_list:
- 1.812793607711792
- 1.6660459089279174
- 1.5980716776847839
- 1.5795283937454223
- 1.530139663219452
- 1.492564194202423
- 1.468572142124176
- 1.4492986083030701
- 1.4271082091331482
- 1.410379581451416
- 1.3960947251319886
- 1.415785813331604
- 1.422396035194397
- 1.3761777591705322
- 1.3516227555274964
- 1.3362470746040345
- 1.360693347454071
- 1.328142364025116
- 1.3136651086807252
- 1.3050822854042052
- 1.297327332496643
- 1.322937617301941
- 1.3313843631744384
- 1.2886726593971252
- 1.2703992056846618
- 1.2607165002822875
- 1.2575358605384828
- 1.2517070746421814
- 1.2434542870521545
- 1.2359244632720947
- 1.271586902141571
- 1.2803617548942565
- 1.2435132551193238
- 1.2680821323394775
- 1.2310524773597717
- 1.261277458667755
- 1.2674317741394043
- 1.2253187847137452
- 1.2496561670303346
- 1.262663631439209
- 1.2687023210525512
- 1.2240175652503966
- 1.200060167312622
- 1.2307296347618104
- 1.196577682495117
- 1.1884500432014464
- 1.2258506941795348
- 1.237389566898346
- 1.1905662274360658
- 1.1775168991088867
- 1.1760226464271546
- 1.172185444831848
- 1.2073988556861877
- 1.172451593875885
- 1.1641090059280395
- 1.2001910996437073
- 1.2136825180053712
- 1.1717542672157288
- 1.1624662160873414
- 1.1579530453681945
- 1.1551012229919433
- 1.1954456162452698
- 1.1658024883270264
- 1.1521067690849305
- 1.1967285990715026
- 1.2048606967926025
- 1.1673852968215943
- 1.1966336941719056
- 1.2085185551643371
- 1.1695374250411987
- 1.2003410744667053
- 1.1633725380897522
- 1.1972390794754029
- 1.1612117767333985
- 1.1491563391685486
- 1.1480774092674255
- 1.1466434597969055
- 1.1817160892486571
- 1.151267602443695
- 1.1466799116134643
- 1.14467289686203
- 1.1426464200019837
- 1.1441594457626343
- 1.1463595151901245
- 1.1431259751319884
- 1.147554051876068
- 1.1438238739967346
- 1.1461095571517945
- 1.1480086827278138
- 1.177213408946991
- 1.1507955193519592
- 1.1482677364349365
- 1.1824335050582886
- 1.1577828645706176
- 1.1845851612091065
- 1.1544491934776306
- 1.1443160343170167
- 1.1456027007102967
- 1.1463168382644653
- 1.178749659061432
train_accuracy:
- 0.031
- 0.1
- 0.0
- 0.152
- 0.15
- 0.157
- 0.169
- 0.192
- 0.164
- 0.178
- 0.213
- 0.18
- 0.209
- 0.214
- 0.227
- 0.225
- 0.237
- 0.0
- 0.243
- 0.0
- 0.255
- 0.226
- 0.262
- 0.251
- 0.237
- 0.244
- 0.282
- 0.239
- 0.265
- 0.274
- 0.249
- 0.276
- 0.0
- 0.285
- 0.287
- 0.291
- 0.288
- 0.267
- 0.271
- 0.296
- 0.323
- 0.273
- 0.288
- 0.342
- 0.273
- 0.287
- 0.293
- 0.275
- 0.3
- 0.291
- 0.308
- 0.283
- 0.297
- 0.367
- 0.348
- 0.362
- 0.298
- 0.293
- 0.31
- 0.36
- 0.297
- 0.316
- 0.298
- 0.363
- 0.296
- 0.354
- 0.32
- 0.31
- 0.318
- 0.323
- 0.314
- 0.364
- 0.342
- 0.0
- 0.362
- 0.0
- 0.306
- 0.338
- 0.395
- 0.402
- 0.409
- 0.312
- 0.322
- 0.34
- 0.322
- 0.396
- 0.309
- 0.3
- 0.392
- 0.364
- 0.0
- 0.331
- 0.309
- 0.351
- 0.334
- 0.334
- 0.334
- 0.334
- 0.38
- 0.339
train_loss:
- 4.31
- 3.546
- 3.31
- 3.428
- 3.024
- 2.896
- 2.813
- 2.737
- 2.671
- 2.6
- 2.533
- 2.695
- 2.613
- 2.365
- 2.287
- 2.231
- 2.385
- 2.129
- 2.066
- 2.017
- 1.988
- 2.155
- 2.087
- 1.876
- 1.834
- 1.799
- 1.727
- 1.69
- 1.695
- 1.623
- 1.753
- 1.714
- 1.52
- 1.619
- 1.448
- 1.527
- 1.523
- 1.39
- 1.425
- 1.406
- 1.377
- 1.258
- 1.195
- 1.336
- 1.14
- 1.13
- 1.183
- 1.168
- 1.087
- 1.035
- 1.026
- 0.966
- 1.045
- 1.013
- 0.935
- 0.966
- 0.968
- 0.873
- 0.877
- 0.84
- 0.82
- 0.849
- 0.772
- 0.789
- 0.823
- 0.774
- 0.728
- 0.766
- 0.711
- 0.654
- 0.703
- 0.636
- 0.659
- 0.605
- 0.606
- 0.602
- 0.574
- 0.607
- 0.56
- 0.55
- 0.533
- 0.531
- 0.504
- 0.502
- 0.485
- 0.475
- 0.473
- 0.482
- 0.454
- 0.475
- 0.428
- 0.432
- 0.441
- 0.415
- 0.433
- 0.395
- 0.39
- 0.383
- 0.364
- 0.38
unequal: 0
verbose: 1
