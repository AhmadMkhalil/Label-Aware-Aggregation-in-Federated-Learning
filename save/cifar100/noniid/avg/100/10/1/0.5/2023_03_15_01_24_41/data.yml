avg_train_accuracy: 0.345
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0462
- 0.1034
- 0.1228
- 0.1374
- 0.1544
- 0.1619
- 0.1716
- 0.1756
- 0.1843
- 0.1901
- 0.1961
- 0.2015
- 0.2072
- 0.2183
- 0.2154
- 0.2208
- 0.2262
- 0.225
- 0.2343
- 0.2414
- 0.2398
- 0.2422
- 0.2443
- 0.2472
- 0.2467
- 0.2518
- 0.2587
- 0.2569
- 0.2619
- 0.2648
- 0.2658
- 0.2651
- 0.2714
- 0.2708
- 0.2697
- 0.2698
- 0.2801
- 0.2826
- 0.285
- 0.2912
- 0.279
- 0.2921
- 0.2887
- 0.2841
- 0.2916
- 0.2864
- 0.2977
- 0.3018
- 0.3001
- 0.3046
- 0.3069
- 0.2941
- 0.2947
- 0.3013
- 0.3045
- 0.3022
- 0.3063
- 0.3003
- 0.3108
- 0.3124
- 0.3124
- 0.3089
- 0.3037
- 0.3038
- 0.2997
- 0.3111
- 0.3165
- 0.318
- 0.3087
- 0.3064
- 0.307
- 0.3122
- 0.3078
- 0.3174
- 0.3206
- 0.3117
- 0.3237
- 0.3159
- 0.315
- 0.3214
- 0.3151
- 0.3191
- 0.3239
- 0.3164
- 0.3255
- 0.3271
- 0.3254
- 0.3262
- 0.3274
- 0.3199
- 0.3249
- 0.323
- 0.3306
- 0.3246
- 0.3328
- 0.3219
- 0.3191
- 0.3205
- 0.3162
- 0.3204
test_loss_list:
- 1.7892066717147828
- 1.6446762371063233
- 1.583806688785553
- 1.5745975351333619
- 1.5104713249206543
- 1.4804464483261108
- 1.4591309499740601
- 1.4778736853599548
- 1.4785083246231079
- 1.4197564578056336
- 1.3986372208595277
- 1.420730984210968
- 1.3738374829292297
- 1.3543745851516724
- 1.384406406879425
- 1.3921283626556396
- 1.3398587799072266
- 1.3660031533241273
- 1.3144824528694152
- 1.2981935834884644
- 1.3304849863052368
- 1.3438056373596192
- 1.3496274590492248
- 1.288073284626007
- 1.3238188815116883
- 1.3334871125221253
- 1.2716663932800294
- 1.3031877303123474
- 1.2529103302955626
- 1.2402101182937622
- 1.2762408399581908
- 1.2928367733955384
- 1.2393480658531189
- 1.2717624020576477
- 1.287335216999054
- 1.2938779401779175
- 1.228946921825409
- 1.215579183101654
- 1.208625886440277
- 1.2026722431182861
- 1.2489323353767394
- 1.2036330342292785
- 1.1946750974655151
- 1.23949054479599
- 1.1928841614723205
- 1.2363217997550964
- 1.1906229424476624
- 1.1804442358016969
- 1.1793156862258911
- 1.1781768012046814
- 1.1740253567695618
- 1.2190306067466736
- 1.230774462223053
- 1.1818861436843873
- 1.1707850360870362
- 1.2121109914779664
- 1.174150252342224
- 1.2152035093307496
- 1.1694113326072693
- 1.1671544432640075
- 1.1666871237754821
- 1.2030221009254456
- 1.2192577052116393
- 1.2295181965827942
- 1.2440335583686828
- 1.1709019112586976
- 1.1603610444068908
- 1.1619241380691527
- 1.2009777641296386
- 1.2207673454284669
- 1.2295543456077576
- 1.1752310371398926
- 1.2134865856170653
- 1.1635171127319337
- 1.1607689785957336
- 1.1965143394470215
- 1.1555695271492004
- 1.198327248096466
- 1.214329650402069
- 1.1602179789543152
- 1.2032436561584472
- 1.1589663195610047
- 1.1558409667015075
- 1.1939185237884522
- 1.1618731260299682
- 1.1517582654953002
- 1.153445246219635
- 1.1538397192955017
- 1.1534305691719056
- 1.191017746925354
- 1.1573669934272766
- 1.1938256621360779
- 1.1571602845191955
- 1.1959800624847412
- 1.1583326411247254
- 1.1997932410240173
- 1.2132280921936036
- 1.2233699727058411
- 1.2313131022453307
- 1.2319704461097718
train_accuracy:
- 0.045
- 0.125
- 0.169
- 0.185
- 0.147
- 0.207
- 0.0
- 0.207
- 0.239
- 0.0
- 0.192
- 0.202
- 0.197
- 0.221
- 0.185
- 0.266
- 0.224
- 0.216
- 0.0
- 0.0
- 0.254
- 0.234
- 0.288
- 0.285
- 0.251
- 0.283
- 0.26
- 0.28
- 0.259
- 0.263
- 0.302
- 0.258
- 0.28
- 0.297
- 0.273
- 0.235
- 0.278
- 0.314
- 0.295
- 0.0
- 0.28
- 0.274
- 0.257
- 0.286
- 0.301
- 0.296
- 0.34
- 0.293
- 0.0
- 0.317
- 0.318
- 0.335
- 0.327
- 0.309
- 0.293
- 0.331
- 0.0
- 0.324
- 0.312
- 0.322
- 0.31
- 0.339
- 0.342
- 0.307
- 0.324
- 0.333
- 0.327
- 0.313
- 0.309
- 0.325
- 0.333
- 0.334
- 0.336
- 0.0
- 0.371
- 0.325
- 0.306
- 0.347
- 0.342
- 0.349
- 0.354
- 0.33
- 0.317
- 0.301
- 0.0
- 0.307
- 0.362
- 0.33
- 0.344
- 0.318
- 0.34
- 0.359
- 0.0
- 0.362
- 0.317
- 0.347
- 0.322
- 0.32
- 0.369
- 0.345
train_loss:
- 4.218
- 3.369
- 3.205
- 3.402
- 2.923
- 2.781
- 2.72
- 3.002
- 2.887
- 2.521
- 2.378
- 2.738
- 2.342
- 2.335
- 2.527
- 2.456
- 2.105
- 2.367
- 2.04
- 1.985
- 2.231
- 2.17
- 2.136
- 1.827
- 1.984
- 1.923
- 1.691
- 1.843
- 1.65
- 1.614
- 1.737
- 1.702
- 1.53
- 1.59
- 1.582
- 1.538
- 1.377
- 1.3
- 1.281
- 1.239
- 1.38
- 1.216
- 1.147
- 1.282
- 1.186
- 1.217
- 1.128
- 1.122
- 1.028
- 1.028
- 1.081
- 1.108
- 1.06
- 0.971
- 0.918
- 1.034
- 0.871
- 0.987
- 0.891
- 0.819
- 0.8
- 0.933
- 0.823
- 0.828
- 0.835
- 0.755
- 0.664
- 0.666
- 0.726
- 0.665
- 0.694
- 0.594
- 0.704
- 0.562
- 0.563
- 0.717
- 0.531
- 0.59
- 0.631
- 0.583
- 0.58
- 0.491
- 0.557
- 0.594
- 0.465
- 0.503
- 0.438
- 0.474
- 0.41
- 0.507
- 0.427
- 0.506
- 0.41
- 0.411
- 0.423
- 0.494
- 0.451
- 0.432
- 0.412
- 0.386
unequal: 0
verbose: 1
