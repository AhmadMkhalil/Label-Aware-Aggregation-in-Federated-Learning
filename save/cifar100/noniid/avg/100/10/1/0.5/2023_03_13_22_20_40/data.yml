avg_train_accuracy: 0.354
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0348
- 0.1026
- 0.1257
- 0.1414
- 0.1558
- 0.1657
- 0.1668
- 0.1814
- 0.1845
- 0.1933
- 0.1989
- 0.2085
- 0.2126
- 0.221
- 0.224
- 0.2267
- 0.2328
- 0.2338
- 0.2388
- 0.2392
- 0.2444
- 0.25
- 0.251
- 0.2524
- 0.256
- 0.261
- 0.2634
- 0.2667
- 0.269
- 0.2641
- 0.2734
- 0.2792
- 0.2762
- 0.283
- 0.2765
- 0.2875
- 0.2814
- 0.2831
- 0.2854
- 0.291
- 0.2895
- 0.2975
- 0.2983
- 0.3008
- 0.2952
- 0.2952
- 0.2977
- 0.3018
- 0.3074
- 0.3018
- 0.303
- 0.3072
- 0.3015
- 0.3133
- 0.3121
- 0.3191
- 0.3202
- 0.3153
- 0.3064
- 0.3176
- 0.3113
- 0.3171
- 0.313
- 0.3115
- 0.3096
- 0.321
- 0.3144
- 0.319
- 0.3285
- 0.3306
- 0.3305
- 0.3296
- 0.3182
- 0.3216
- 0.3275
- 0.3202
- 0.3232
- 0.3293
- 0.3231
- 0.3217
- 0.329
- 0.3266
- 0.3314
- 0.3269
- 0.3325
- 0.3399
- 0.3274
- 0.3366
- 0.3357
- 0.3369
- 0.3378
- 0.3245
- 0.3266
- 0.3357
- 0.3383
- 0.3299
- 0.3385
- 0.3302
- 0.3274
- 0.3367
test_loss_list:
- 1.7969223403930663
- 1.6696548891067504
- 1.6332796978950501
- 1.6054344272613525
- 1.583007950782776
- 1.565548939704895
- 1.4899776363372803
- 1.4445200514793397
- 1.4639920115470886
- 1.4117524909973145
- 1.3902387356758117
- 1.3730560564994811
- 1.3653920030593871
- 1.3514006543159485
- 1.3798542594909669
- 1.3372580695152283
- 1.3227044200897218
- 1.3551009392738342
- 1.3653398442268372
- 1.3701969695091247
- 1.306185712814331
- 1.2843001413345336
- 1.3192918825149536
- 1.3341825199127197
- 1.334598922729492
- 1.341325316429138
- 1.2695432257652284
- 1.2991116857528686
- 1.248479447364807
- 1.2913660144805907
- 1.2378092336654662
- 1.2260922551155091
- 1.264340980052948
- 1.2230381965637207
- 1.2606821322441102
- 1.2168388032913209
- 1.255950539112091
- 1.2671800780296325
- 1.2738008284568787
- 1.2132552695274352
- 1.2500058841705322
- 1.199687123298645
- 1.1871016478538514
- 1.181367166042328
- 1.2282464241981506
- 1.2437146878242493
- 1.2492546081542968
- 1.1944449520111085
- 1.1773406648635865
- 1.218173155784607
- 1.2316959643363952
- 1.1804302501678468
- 1.2258566164970397
- 1.178515305519104
- 1.16509929895401
- 1.1582982778549193
- 1.1615200686454772
- 1.1616143584251404
- 1.2064647603034973
- 1.16516930103302
- 1.204125199317932
- 1.161871738433838
- 1.2051451516151428
- 1.2246399593353272
- 1.2265182876586913
- 1.1720712518692016
- 1.2067342376708985
- 1.1673565006256104
- 1.1549910497665405
- 1.157401580810547
- 1.1536357736587524
- 1.1559506845474243
- 1.2014407420158386
- 1.215564420223236
- 1.1648147797584534
- 1.203813943862915
- 1.2171594738960265
- 1.1595675206184388
- 1.203411545753479
- 1.2150086879730224
- 1.1627321028709412
- 1.199125587940216
- 1.1571456980705261
- 1.1964025115966797
- 1.1586554431915284
- 1.1549412941932677
- 1.1940434384346008
- 1.1554778385162354
- 1.1565967392921448
- 1.1539601612091064
- 1.149514036178589
- 1.1972110509872436
- 1.2034114241600036
- 1.159966495037079
- 1.151327440738678
- 1.1961727738380432
- 1.158429832458496
- 1.1967217803001404
- 1.2110436034202576
- 1.1633136773109436
train_accuracy:
- 0.044
- 0.101
- 0.133
- 0.154
- 0.144
- 0.176
- 0.0
- 0.191
- 0.176
- 0.0
- 0.187
- 0.0
- 0.22
- 0.272
- 0.212
- 0.256
- 0.281
- 0.275
- 0.269
- 0.286
- 0.265
- 0.0
- 0.25
- 0.279
- 0.257
- 0.306
- 0.0
- 0.304
- 0.0
- 0.313
- 0.316
- 0.256
- 0.286
- 0.0
- 0.31
- 0.324
- 0.335
- 0.295
- 0.312
- 0.292
- 0.313
- 0.312
- 0.321
- 0.316
- 0.295
- 0.323
- 0.288
- 0.284
- 0.0
- 0.32
- 0.33
- 0.315
- 0.326
- 0.0
- 0.333
- 0.331
- 0.324
- 0.0
- 0.341
- 0.337
- 0.293
- 0.0
- 0.342
- 0.344
- 0.326
- 0.0
- 0.326
- 0.33
- 0.0
- 0.34
- 0.336
- 0.33
- 0.338
- 0.338
- 0.341
- 0.329
- 0.328
- 0.0
- 0.371
- 0.365
- 0.341
- 0.371
- 0.348
- 0.372
- 0.0
- 0.342
- 0.312
- 0.362
- 0.349
- 0.344
- 0.365
- 0.367
- 0.343
- 0.344
- 0.36
- 0.365
- 0.356
- 0.368
- 0.354
- 0.354
train_loss:
- 3.759
- 3.794
- 3.549
- 3.35
- 3.209
- 3.126
- 2.746
- 2.642
- 2.865
- 2.454
- 2.397
- 2.371
- 2.336
- 2.238
- 2.505
- 2.118
- 2.047
- 2.349
- 2.237
- 2.152
- 1.93
- 1.824
- 2.103
- 1.967
- 1.999
- 1.89
- 1.734
- 1.866
- 1.553
- 1.679
- 1.544
- 1.46
- 1.749
- 1.379
- 1.658
- 1.354
- 1.51
- 1.53
- 1.411
- 1.35
- 1.361
- 1.248
- 1.211
- 1.109
- 1.354
- 1.189
- 1.168
- 1.03
- 1.097
- 1.151
- 1.124
- 1.007
- 1.046
- 0.946
- 0.888
- 0.894
- 0.875
- 0.788
- 0.944
- 0.807
- 0.915
- 0.765
- 0.869
- 0.822
- 0.802
- 0.751
- 0.784
- 0.65
- 0.661
- 0.617
- 0.623
- 0.601
- 0.625
- 0.631
- 0.579
- 0.632
- 0.591
- 0.554
- 0.605
- 0.62
- 0.536
- 0.552
- 0.542
- 0.501
- 0.51
- 0.464
- 0.564
- 0.465
- 0.453
- 0.444
- 0.44
- 0.465
- 0.456
- 0.414
- 0.389
- 0.44
- 0.357
- 0.443
- 0.379
- 0.352
unequal: 0
verbose: 1
