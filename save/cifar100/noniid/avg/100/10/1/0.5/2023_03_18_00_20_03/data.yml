avg_train_accuracy: 0.364
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0324
- 0.0934
- 0.1156
- 0.1262
- 0.1461
- 0.1536
- 0.1618
- 0.1717
- 0.1801
- 0.186
- 0.1926
- 0.2006
- 0.2061
- 0.2132
- 0.2146
- 0.2215
- 0.2244
- 0.2273
- 0.2376
- 0.2353
- 0.2411
- 0.2452
- 0.2451
- 0.2527
- 0.2544
- 0.2582
- 0.2575
- 0.2612
- 0.2642
- 0.2705
- 0.2743
- 0.2769
- 0.2839
- 0.2755
- 0.2819
- 0.2857
- 0.2813
- 0.2887
- 0.287
- 0.2899
- 0.2973
- 0.2993
- 0.2968
- 0.2959
- 0.2918
- 0.2891
- 0.2946
- 0.3006
- 0.2917
- 0.3023
- 0.2991
- 0.3086
- 0.3095
- 0.3016
- 0.304
- 0.3124
- 0.3149
- 0.3145
- 0.3054
- 0.3039
- 0.3149
- 0.3215
- 0.3206
- 0.3186
- 0.3173
- 0.3181
- 0.3085
- 0.3097
- 0.3186
- 0.3236
- 0.3235
- 0.3161
- 0.3156
- 0.3198
- 0.3072
- 0.324
- 0.3258
- 0.3268
- 0.3191
- 0.3159
- 0.316
- 0.317
- 0.3233
- 0.3178
- 0.3302
- 0.3314
- 0.3332
- 0.3207
- 0.3203
- 0.3195
- 0.3287
- 0.3306
- 0.3319
- 0.3245
- 0.3339
- 0.3378
- 0.3365
- 0.3277
- 0.3358
- 0.3271
test_loss_list:
- 1.7987899303436279
- 1.6813829469680786
- 1.6474330759048461
- 1.62669278383255
- 1.5434536504745484
- 1.4974179673194885
- 1.5173559069633484
- 1.513034267425537
- 1.5124762296676635
- 1.4399720573425292
- 1.4059616565704345
- 1.389618525505066
- 1.3788994097709655
- 1.3664367270469666
- 1.3968910479545593
- 1.3481712675094604
- 1.382164514064789
- 1.3919747924804688
- 1.3305703830718993
- 1.3629087543487548
- 1.314432852268219
- 1.3442121458053589
- 1.3499860215187072
- 1.2882653832435609
- 1.2760624504089355
- 1.266633358001709
- 1.308291063308716
- 1.3171710324287416
- 1.325933792591095
- 1.259125201702118
- 1.238358166217804
- 1.233656232357025
- 1.225347831249237
- 1.2717125129699707
- 1.224348804950714
- 1.2164049458503723
- 1.2584076452255248
- 1.213335473537445
- 1.2524826145172119
- 1.2054350924491883
- 1.1974448442459107
- 1.1945409846305848
- 1.1979012656211854
- 1.1919677257537842
- 1.236307713985443
- 1.2481255006790162
- 1.2591210985183716
- 1.1909466218948364
- 1.2367722129821777
- 1.189349319934845
- 1.2305394625663757
- 1.182033519744873
- 1.173807578086853
- 1.2226929187774658
- 1.2343529772758484
- 1.1811559367179871
- 1.1707539820671082
- 1.170978558063507
- 1.21876935005188
- 1.2298749709129333
- 1.1701427245140075
- 1.1609986233711242
- 1.1588508653640748
- 1.158942573070526
- 1.158764863014221
- 1.1591174459457398
- 1.203978316783905
- 1.2186159086227417
- 1.1688999152183532
- 1.1564819765090943
- 1.1549886798858642
- 1.2035416603088378
- 1.2166928958892822
- 1.1702981758117676
- 1.217282612323761
- 1.1584815359115601
- 1.163177182674408
- 1.1545504927635193
- 1.1945930624008179
- 1.2165990686416626
- 1.224642083644867
- 1.2310397028923035
- 1.1676673483848572
- 1.212999267578125
- 1.160604441165924
- 1.159056007862091
- 1.1543264341354371
- 1.194595296382904
- 1.2138960480690002
- 1.2262714505195618
- 1.1689108657836913
- 1.1588523316383361
- 1.157244246006012
- 1.19880934715271
- 1.1579009175300599
- 1.157179958820343
- 1.1556790828704835
- 1.1967502665519714
- 1.1607630729675293
- 1.1997308802604676
train_accuracy:
- 0.033
- 0.102
- 0.144
- 0.104
- 0.128
- 0.18
- 0.13
- 0.216
- 0.173
- 0.182
- 0.175
- 0.0
- 0.199
- 0.181
- 0.183
- 0.222
- 0.212
- 0.247
- 0.0
- 0.249
- 0.217
- 0.228
- 0.239
- 0.0
- 0.288
- 0.264
- 0.266
- 0.293
- 0.258
- 0.268
- 0.317
- 0.262
- 0.285
- 0.287
- 0.0
- 0.272
- 0.29
- 0.307
- 0.264
- 0.324
- 0.308
- 0.0
- 0.273
- 0.336
- 0.312
- 0.297
- 0.327
- 0.315
- 0.288
- 0.0
- 0.312
- 0.261
- 0.285
- 0.28
- 0.291
- 0.274
- 0.333
- 0.325
- 0.291
- 0.289
- 0.279
- 0.338
- 0.325
- 0.33
- 0.0
- 0.329
- 0.344
- 0.331
- 0.325
- 0.309
- 0.0
- 0.32
- 0.325
- 0.323
- 0.319
- 0.344
- 0.3
- 0.325
- 0.342
- 0.283
- 0.329
- 0.312
- 0.29
- 0.297
- 0.0
- 0.326
- 0.311
- 0.337
- 0.349
- 0.333
- 0.349
- 0.329
- 0.34
- 0.353
- 0.0
- 0.294
- 0.361
- 0.33
- 0.349
- 0.364
train_loss:
- 3.82
- 3.881
- 3.63
- 3.405
- 2.979
- 2.857
- 3.073
- 3.027
- 2.897
- 2.542
- 2.497
- 2.404
- 2.34
- 2.258
- 2.595
- 2.173
- 2.419
- 2.377
- 2.004
- 2.215
- 1.879
- 2.242
- 2.144
- 1.859
- 1.745
- 1.737
- 1.883
- 2.005
- 1.905
- 1.677
- 1.574
- 1.516
- 1.532
- 1.69
- 1.437
- 1.448
- 1.584
- 1.359
- 1.554
- 1.33
- 1.27
- 1.209
- 1.209
- 1.206
- 1.356
- 1.307
- 1.247
- 1.157
- 1.216
- 1.065
- 1.113
- 0.948
- 1.019
- 1.064
- 1.055
- 0.894
- 0.983
- 0.82
- 0.927
- 0.954
- 0.862
- 0.843
- 0.775
- 0.829
- 0.797
- 0.743
- 0.877
- 0.817
- 0.677
- 0.758
- 0.654
- 0.731
- 0.735
- 0.593
- 0.713
- 0.66
- 0.596
- 0.535
- 0.706
- 0.631
- 0.612
- 0.616
- 0.557
- 0.562
- 0.525
- 0.449
- 0.5
- 0.565
- 0.488
- 0.468
- 0.446
- 0.446
- 0.401
- 0.495
- 0.431
- 0.397
- 0.413
- 0.444
- 0.386
- 0.451
unequal: 0
verbose: 1
