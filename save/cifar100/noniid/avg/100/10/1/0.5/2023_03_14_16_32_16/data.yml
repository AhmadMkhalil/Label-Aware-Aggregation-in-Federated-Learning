avg_train_accuracy: 0.398
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0455
- 0.0986
- 0.1133
- 0.1345
- 0.1471
- 0.1605
- 0.1698
- 0.1794
- 0.1818
- 0.1912
- 0.2026
- 0.2071
- 0.2093
- 0.2148
- 0.2222
- 0.2233
- 0.2252
- 0.2298
- 0.2338
- 0.2339
- 0.2398
- 0.2478
- 0.246
- 0.2477
- 0.2548
- 0.2542
- 0.2582
- 0.2579
- 0.2605
- 0.2666
- 0.2671
- 0.2684
- 0.2725
- 0.2751
- 0.2771
- 0.2767
- 0.2775
- 0.2843
- 0.2879
- 0.2893
- 0.2922
- 0.2953
- 0.2873
- 0.2859
- 0.29
- 0.2908
- 0.2911
- 0.3015
- 0.3037
- 0.2976
- 0.3008
- 0.3064
- 0.3088
- 0.2961
- 0.3079
- 0.3029
- 0.3103
- 0.3059
- 0.3089
- 0.3084
- 0.3081
- 0.3088
- 0.3125
- 0.3178
- 0.3184
- 0.3189
- 0.3205
- 0.3204
- 0.312
- 0.3103
- 0.3238
- 0.3258
- 0.3165
- 0.3201
- 0.322
- 0.3188
- 0.3146
- 0.3156
- 0.3184
- 0.3184
- 0.3229
- 0.3204
- 0.3225
- 0.3306
- 0.3295
- 0.3199
- 0.3202
- 0.3254
- 0.3201
- 0.328
- 0.3315
- 0.3325
- 0.3237
- 0.3233
- 0.3278
- 0.3243
- 0.3322
- 0.3359
- 0.3268
- 0.3233
test_loss_list:
- 1.7835253477096558
- 1.6739235424995422
- 1.6387040162086486
- 1.6115211582183837
- 1.5889989352226257
- 1.5767248606681823
- 1.563899075984955
- 1.552032699584961
- 1.5431496429443359
- 1.536432569026947
- 1.5210452318191527
- 1.4410190320014953
- 1.393903570175171
- 1.3662831711769103
- 1.3541333818435668
- 1.343527340888977
- 1.3371315741539
- 1.3735717177391051
- 1.3763231778144835
- 1.3863496661186219
- 1.3855679893493653
- 1.3130959868431091
- 1.340785653591156
- 1.3546011924743653
- 1.3555540919303894
- 1.2954374647140503
- 1.3206236934661866
- 1.3380205178260802
- 1.340079643726349
- 1.3385542488098146
- 1.3426794052124023
- 1.349009988307953
- 1.347572433948517
- 1.3483041548728942
- 1.2710618662834168
- 1.3005201363563537
- 1.2478005862236023
- 1.226553556919098
- 1.222861897945404
- 1.218547351360321
- 1.2157343626022339
- 1.21207923412323
- 1.255377507209778
- 1.2727296710014344
- 1.2769189119338988
- 1.2873698329925538
- 1.221027524471283
- 1.200443615913391
- 1.1982414960861205
- 1.2382720136642456
- 1.19886474609375
- 1.1911310815811158
- 1.1876532697677613
- 1.2349433064460755
- 1.1921232485771178
- 1.2346415615081787
- 1.1907732605934143
- 1.2316937375068664
- 1.190234248638153
- 1.2276204633712768
- 1.2417143893241882
- 1.2465203094482422
- 1.1895178079605102
- 1.1810323476791382
- 1.1742501115798951
- 1.175230107307434
- 1.1746828389167785
- 1.1764200949668884
- 1.216583411693573
- 1.2366870427131653
- 1.1851121830940246
- 1.173517382144928
- 1.2181603813171387
- 1.179036660194397
- 1.1726616358757018
- 1.214836401939392
- 1.2273187160491943
- 1.2420985412597656
- 1.2472804284095764
- 1.254697802066803
- 1.192435336112976
- 1.2305698680877686
- 1.188157069683075
- 1.1750817823410034
- 1.1738115429878235
- 1.213186411857605
- 1.228429856300354
- 1.1801202654838563
- 1.2233389496803284
- 1.1880115175247192
- 1.1745617842674256
- 1.179154598712921
- 1.2135710263252257
- 1.2290164828300476
- 1.1868220090866088
- 1.2199732756614685
- 1.1826380443573
- 1.1793118977546693
- 1.2156029272079467
- 1.2322572517395018
train_accuracy:
- 0.042
- 0.089
- 0.142
- 0.14
- 0.162
- 0.172
- 0.165
- 0.216
- 0.206
- 0.197
- 0.194
- 0.233
- 0.186
- 0.0
- 0.256
- 0.231
- 0.229
- 0.236
- 0.262
- 0.265
- 0.257
- 0.245
- 0.222
- 0.254
- 0.251
- 0.291
- 0.264
- 0.317
- 0.285
- 0.276
- 0.263
- 0.308
- 0.285
- 0.311
- 0.275
- 0.312
- 0.301
- 0.258
- 0.298
- 0.278
- 0.31
- 0.338
- 0.299
- 0.323
- 0.31
- 0.289
- 0.299
- 0.301
- 0.312
- 0.316
- 0.334
- 0.313
- 0.303
- 0.332
- 0.307
- 0.321
- 0.306
- 0.369
- 0.369
- 0.342
- 0.347
- 0.321
- 0.342
- 0.317
- 0.357
- 0.372
- 0.37
- 0.328
- 0.329
- 0.323
- 0.34
- 0.362
- 0.356
- 0.0
- 0.0
- 0.366
- 0.347
- 0.318
- 0.351
- 0.352
- 0.369
- 0.368
- 0.382
- 0.0
- 0.376
- 0.352
- 0.363
- 0.388
- 0.349
- 0.324
- 0.0
- 0.354
- 0.287
- 0.353
- 0.288
- 0.336
- 0.341
- 0.0
- 0.391
- 0.398
train_loss:
- 3.761
- 3.831
- 3.544
- 3.36
- 3.233
- 3.113
- 2.966
- 2.918
- 2.837
- 2.703
- 2.776
- 2.441
- 2.363
- 2.323
- 2.196
- 2.181
- 2.103
- 2.327
- 2.309
- 2.213
- 2.17
- 1.981
- 2.101
- 2.0
- 1.977
- 1.763
- 1.862
- 1.887
- 1.814
- 1.76
- 1.76
- 1.663
- 1.656
- 1.559
- 1.434
- 1.517
- 1.327
- 1.331
- 1.259
- 1.27
- 1.275
- 1.273
- 1.305
- 1.266
- 1.29
- 1.252
- 1.078
- 1.151
- 1.006
- 1.115
- 1.036
- 0.948
- 0.92
- 0.972
- 0.959
- 1.025
- 0.949
- 0.973
- 0.888
- 0.922
- 0.92
- 0.854
- 0.761
- 0.732
- 0.804
- 0.716
- 0.682
- 0.634
- 0.749
- 0.703
- 0.571
- 0.601
- 0.731
- 0.601
- 0.637
- 0.67
- 0.663
- 0.596
- 0.566
- 0.597
- 0.604
- 0.539
- 0.569
- 0.513
- 0.508
- 0.514
- 0.521
- 0.443
- 0.493
- 0.407
- 0.415
- 0.383
- 0.433
- 0.403
- 0.4
- 0.446
- 0.357
- 0.387
- 0.446
- 0.367
unequal: 0
verbose: 1
