avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.043
- 0.0996
- 0.1224
- 0.1359
- 0.1502
- 0.157
- 0.167
- 0.1765
- 0.188
- 0.1897
- 0.1967
- 0.2045
- 0.2086
- 0.2181
- 0.2197
- 0.2237
- 0.228
- 0.2307
- 0.2352
- 0.243
- 0.2436
- 0.2458
- 0.2503
- 0.2502
- 0.2541
- 0.2536
- 0.2604
- 0.2641
- 0.2665
- 0.2625
- 0.2659
- 0.2729
- 0.2725
- 0.274
- 0.2783
- 0.277
- 0.2776
- 0.2807
- 0.283
- 0.2825
- 0.2823
- 0.2847
- 0.2872
- 0.2923
- 0.2922
- 0.2918
- 0.3005
- 0.2911
- 0.2953
- 0.2917
- 0.2952
- 0.2983
- 0.2922
- 0.3008
- 0.3019
- 0.3046
- 0.311
- 0.3077
- 0.3099
- 0.3111
- 0.309
- 0.3052
- 0.3093
- 0.3046
- 0.3111
- 0.3158
- 0.3131
- 0.3206
- 0.3208
- 0.3135
- 0.3181
- 0.3193
- 0.3137
- 0.3202
- 0.3155
- 0.3194
- 0.3146
- 0.3132
- 0.3207
- 0.3237
- 0.3163
- 0.3204
- 0.3266
- 0.3288
- 0.3176
- 0.3223
- 0.3261
- 0.3171
- 0.3168
- 0.3184
- 0.3175
- 0.3228
- 0.3193
- 0.321
- 0.3212
- 0.3192
- 0.326
- 0.3251
- 0.3217
- 0.3277
test_loss_list:
- 1.8052890634536742
- 1.6998119831085206
- 1.6577267599105836
- 1.6300411796569825
- 1.5431616616249084
- 1.4998994064331055
- 1.5103968858718873
- 1.4540594434738159
- 1.4739125108718871
- 1.4224911117553711
- 1.4432944631576539
- 1.4510409045219421
- 1.4464264059066771
- 1.4445560550689698
- 1.375557882785797
- 1.396441102027893
- 1.3406123256683349
- 1.370820701122284
- 1.31902747631073
- 1.3024865674972534
- 1.3388272070884704
- 1.349934458732605
- 1.2931900596618653
- 1.3268180942535401
- 1.3357722187042236
- 1.3443027091026307
- 1.279779543876648
- 1.303934898376465
- 1.2551989364624023
- 1.2903388261795044
- 1.300416808128357
- 1.3084960746765137
- 1.312569601535797
- 1.2466242384910584
- 1.2236531043052674
- 1.2650671792030335
- 1.2801649355888367
- 1.2903133153915405
- 1.2217838978767395
- 1.2566139793395996
- 1.2711717534065246
- 1.2813648319244384
- 1.2158027124404907
- 1.1947643113136293
- 1.2342117977142335
- 1.1924892449378968
- 1.190242190361023
- 1.2248000073432923
- 1.1917121195793152
- 1.2278794312477113
- 1.243842782974243
- 1.1859272742271423
- 1.2356185817718506
- 1.2353370356559754
- 1.1847374153137207
- 1.1710816287994386
- 1.165526728630066
- 1.1692049837112426
- 1.1673519968986512
- 1.167307074069977
- 1.170402250289917
- 1.2063740468025208
- 1.2147089076042175
- 1.2289453840255737
- 1.171230387687683
- 1.161642277240753
- 1.1608700704574586
- 1.158745107650757
- 1.150731017589569
- 1.1907906937599182
- 1.155288815498352
- 1.1534292960166932
- 1.1953626918792724
- 1.1572805333137512
- 1.1965777373313904
- 1.156417260169983
- 1.200623507499695
- 1.21601567029953
- 1.1634877157211303
- 1.1493711256980896
- 1.188873655796051
- 1.206424961090088
- 1.1556097507476806
- 1.1562258887290955
- 1.190465395450592
- 1.1616424965858458
- 1.1524711751937866
- 1.1983212876319884
- 1.2110427927970886
- 1.2166399908065797
- 1.2253852319717407
- 1.167647018432617
- 1.21054749250412
- 1.21503338098526
- 1.227207350730896
- 1.232939670085907
- 1.1659535884857177
- 1.2052812385559082
- 1.2205446577072143
- 1.1671990728378296
train_accuracy:
- 0.048
- 0.127
- 0.139
- 0.146
- 0.158
- 0.169
- 0.162
- 0.187
- 0.181
- 0.219
- 0.222
- 0.212
- 0.228
- 0.236
- 0.254
- 0.226
- 0.0
- 0.23
- 0.244
- 0.235
- 0.233
- 0.276
- 0.247
- 0.254
- 0.262
- 0.268
- 0.237
- 0.275
- 0.292
- 0.279
- 0.274
- 0.257
- 0.293
- 0.266
- 0.265
- 0.295
- 0.285
- 0.286
- 0.298
- 0.304
- 0.295
- 0.289
- 0.328
- 0.29
- 0.299
- 0.31
- 0.315
- 0.293
- 0.0
- 0.311
- 0.329
- 0.0
- 0.277
- 0.299
- 0.0
- 0.335
- 0.29
- 0.324
- 0.305
- 0.307
- 0.317
- 0.325
- 0.327
- 0.309
- 0.32
- 0.306
- 0.306
- 0.333
- 0.344
- 0.339
- 0.311
- 0.328
- 0.32
- 0.33
- 0.338
- 0.305
- 0.303
- 0.315
- 0.351
- 0.35
- 0.346
- 0.342
- 0.352
- 0.309
- 0.349
- 0.352
- 0.334
- 0.325
- 0.36
- 0.36
- 0.343
- 0.0
- 0.358
- 0.352
- 0.328
- 0.314
- 0.328
- 0.35
- 0.355
- 0.0
train_loss:
- 4.268
- 3.791
- 3.555
- 3.356
- 2.976
- 2.836
- 3.045
- 2.717
- 2.932
- 2.521
- 2.779
- 2.678
- 2.624
- 2.547
- 2.259
- 2.421
- 2.138
- 2.363
- 2.083
- 1.994
- 2.216
- 2.115
- 1.901
- 2.058
- 1.939
- 1.874
- 1.772
- 1.948
- 1.643
- 1.794
- 1.73
- 1.773
- 1.684
- 1.497
- 1.433
- 1.581
- 1.518
- 1.48
- 1.363
- 1.447
- 1.349
- 1.36
- 1.209
- 1.145
- 1.284
- 1.13
- 1.039
- 1.262
- 1.041
- 1.086
- 1.174
- 0.938
- 1.148
- 1.041
- 1.026
- 0.963
- 0.895
- 0.886
- 0.867
- 0.815
- 0.838
- 0.897
- 0.932
- 0.83
- 0.755
- 0.764
- 0.677
- 0.706
- 0.732
- 0.749
- 0.71
- 0.67
- 0.692
- 0.622
- 0.729
- 0.574
- 0.646
- 0.682
- 0.572
- 0.533
- 0.594
- 0.596
- 0.548
- 0.538
- 0.578
- 0.536
- 0.502
- 0.544
- 0.507
- 0.475
- 0.437
- 0.462
- 0.492
- 0.461
- 0.443
- 0.437
- 0.398
- 0.429
- 0.427
- 0.392
unequal: 0
verbose: 1
