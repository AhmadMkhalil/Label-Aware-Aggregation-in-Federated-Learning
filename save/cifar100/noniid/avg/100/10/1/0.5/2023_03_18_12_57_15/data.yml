avg_train_accuracy: 0.307
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0432
- 0.0954
- 0.1129
- 0.126
- 0.1429
- 0.1508
- 0.1636
- 0.176
- 0.1783
- 0.1877
- 0.196
- 0.2044
- 0.2096
- 0.2163
- 0.2195
- 0.227
- 0.2222
- 0.2302
- 0.2439
- 0.2337
- 0.2445
- 0.2428
- 0.2504
- 0.2448
- 0.2576
- 0.2639
- 0.265
- 0.2586
- 0.2656
- 0.2646
- 0.2642
- 0.2736
- 0.278
- 0.2811
- 0.2858
- 0.2862
- 0.2885
- 0.2785
- 0.285
- 0.2845
- 0.2899
- 0.287
- 0.2851
- 0.2907
- 0.2952
- 0.2975
- 0.3017
- 0.3054
- 0.2976
- 0.3085
- 0.2951
- 0.2978
- 0.3038
- 0.3043
- 0.3134
- 0.3046
- 0.31
- 0.31
- 0.3174
- 0.318
- 0.3084
- 0.3176
- 0.3182
- 0.3173
- 0.3173
- 0.3243
- 0.3295
- 0.3167
- 0.3162
- 0.3224
- 0.3279
- 0.3222
- 0.3269
- 0.3222
- 0.3282
- 0.3249
- 0.3322
- 0.324
- 0.3303
- 0.3267
- 0.3339
- 0.3233
- 0.3252
- 0.335
- 0.3378
- 0.3251
- 0.3259
- 0.3284
- 0.3338
- 0.338
- 0.337
- 0.3399
- 0.3416
- 0.3328
- 0.3373
- 0.3291
- 0.3349
- 0.3304
- 0.3336
- 0.3307
test_loss_list:
- 1.789641489982605
- 1.678496994972229
- 1.6016528058052062
- 1.593042597770691
- 1.5780616521835327
- 1.5101779127120971
- 1.51582768201828
- 1.5115054035186768
- 1.4493471336364747
- 1.4185146117210388
- 1.4399609136581422
- 1.4422299909591674
- 1.3836882352828979
- 1.366136155128479
- 1.3532313704490662
- 1.3405373215675354
- 1.3781612420082092
- 1.3311663913726806
- 1.3125169634819032
- 1.3525130128860474
- 1.3072774076461793
- 1.3411143279075624
- 1.2933360767364501
- 1.3307627940177917
- 1.2761673998832703
- 1.2658227467536927
- 1.2582850170135498
- 1.2939551711082458
- 1.2520340299606323
- 1.2881047964096068
- 1.3026007390022278
- 1.240523693561554
- 1.226083836555481
- 1.2188154220581056
- 1.215640938282013
- 1.2144027662277221
- 1.209109332561493
- 1.2523772501945496
- 1.2071437597274781
- 1.2522537755966185
- 1.2035520315170287
- 1.2425472927093506
- 1.2579363918304443
- 1.2584085249900818
- 1.2027897572517394
- 1.237202651500702
- 1.183078589439392
- 1.1772858786582947
- 1.2139906692504883
- 1.1747468256950377
- 1.2228097915649414
- 1.2360093259811402
- 1.1830175161361693
- 1.2185683202743531
- 1.1725587272644042
- 1.2153892827033996
- 1.170734896659851
- 1.211495292186737
- 1.1657447552680968
- 1.1601964020729065
- 1.2008043599128724
- 1.1623681116104125
- 1.1611201429367066
- 1.1604655241966249
- 1.1643353533744811
- 1.1521956729888916
- 1.1543635177612304
- 1.1942635011672973
- 1.2045713329315186
- 1.156157088279724
- 1.1511137390136719
- 1.18797945022583
- 1.1534870123863221
- 1.194952974319458
- 1.1496193432807922
- 1.1910724258422851
- 1.1530263829231262
- 1.1940961265563965
- 1.1512643432617187
- 1.1909837603569031
- 1.1500471615791321
- 1.1990282583236693
- 1.204751968383789
- 1.1509002923965455
- 1.1416587018966675
- 1.1891444444656372
- 1.1990248346328736
- 1.2076078677177429
- 1.153780858516693
- 1.1473107481002807
- 1.1454728269577026
- 1.144740138053894
- 1.1449665331840515
- 1.179208538532257
- 1.1525639510154724
- 1.1853709721565246
- 1.1520015406608581
- 1.186902482509613
- 1.1967091107368468
- 1.210722770690918
train_accuracy:
- 0.037
- 0.083
- 0.135
- 0.152
- 0.15
- 0.0
- 0.183
- 0.186
- 0.0
- 0.197
- 0.19
- 0.208
- 0.2
- 0.0
- 0.202
- 0.265
- 0.235
- 0.0
- 0.0
- 0.206
- 0.199
- 0.257
- 0.228
- 0.293
- 0.292
- 0.218
- 0.291
- 0.247
- 0.0
- 0.325
- 0.319
- 0.0
- 0.263
- 0.281
- 0.243
- 0.278
- 0.31
- 0.288
- 0.299
- 0.318
- 0.318
- 0.321
- 0.3
- 0.261
- 0.276
- 0.332
- 0.313
- 0.306
- 0.281
- 0.27
- 0.272
- 0.276
- 0.315
- 0.282
- 0.28
- 0.306
- 0.322
- 0.315
- 0.293
- 0.271
- 0.295
- 0.324
- 0.282
- 0.318
- 0.316
- 0.304
- 0.0
- 0.298
- 0.302
- 0.321
- 0.295
- 0.326
- 0.291
- 0.324
- 0.0
- 0.303
- 0.355
- 0.338
- 0.349
- 0.375
- 0.0
- 0.348
- 0.344
- 0.305
- 0.377
- 0.304
- 0.311
- 0.373
- 0.0
- 0.309
- 0.272
- 0.315
- 0.366
- 0.338
- 0.343
- 0.321
- 0.0
- 0.301
- 0.332
- 0.307
train_loss:
- 3.752
- 3.834
- 3.17
- 3.433
- 3.275
- 2.85
- 3.054
- 2.979
- 2.619
- 2.527
- 2.772
- 2.714
- 2.335
- 2.229
- 2.195
- 2.153
- 2.428
- 2.129
- 1.986
- 2.259
- 1.9
- 2.177
- 1.829
- 2.077
- 1.845
- 1.752
- 1.765
- 1.859
- 1.577
- 1.961
- 1.789
- 1.587
- 1.473
- 1.534
- 1.44
- 1.396
- 1.346
- 1.64
- 1.329
- 1.484
- 1.333
- 1.452
- 1.392
- 1.349
- 1.191
- 1.338
- 1.101
- 1.091
- 1.24
- 1.095
- 1.164
- 1.101
- 0.994
- 1.08
- 0.981
- 1.027
- 0.893
- 0.949
- 0.862
- 0.86
- 0.907
- 0.784
- 0.726
- 0.723
- 0.741
- 0.802
- 0.72
- 0.857
- 0.845
- 0.685
- 0.658
- 0.702
- 0.609
- 0.718
- 0.698
- 0.643
- 0.607
- 0.637
- 0.577
- 0.635
- 0.523
- 0.598
- 0.536
- 0.568
- 0.541
- 0.571
- 0.528
- 0.521
- 0.465
- 0.426
- 0.454
- 0.437
- 0.434
- 0.478
- 0.411
- 0.454
- 0.368
- 0.448
- 0.382
- 0.407
unequal: 0
verbose: 1
