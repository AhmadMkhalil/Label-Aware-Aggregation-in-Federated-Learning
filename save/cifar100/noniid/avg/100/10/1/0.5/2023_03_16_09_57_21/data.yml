avg_train_accuracy: 0.32
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033
- 0.0958
- 0.1156
- 0.1295
- 0.1448
- 0.1604
- 0.166
- 0.1771
- 0.1867
- 0.1935
- 0.1966
- 0.205
- 0.2153
- 0.2168
- 0.2226
- 0.2272
- 0.2348
- 0.238
- 0.2403
- 0.2472
- 0.2465
- 0.2478
- 0.254
- 0.256
- 0.2615
- 0.2669
- 0.2626
- 0.2633
- 0.2678
- 0.2742
- 0.271
- 0.2729
- 0.2719
- 0.2788
- 0.2782
- 0.2777
- 0.2788
- 0.2838
- 0.2857
- 0.2876
- 0.2891
- 0.289
- 0.2922
- 0.2934
- 0.2899
- 0.2936
- 0.2973
- 0.2984
- 0.2973
- 0.3049
- 0.3025
- 0.3043
- 0.3
- 0.304
- 0.3103
- 0.3059
- 0.3113
- 0.3041
- 0.309
- 0.3145
- 0.317
- 0.3102
- 0.3172
- 0.3185
- 0.314
- 0.3087
- 0.3136
- 0.3155
- 0.3164
- 0.3161
- 0.3189
- 0.3278
- 0.3231
- 0.3151
- 0.3237
- 0.3139
- 0.3233
- 0.3263
- 0.3215
- 0.3283
- 0.3295
- 0.3222
- 0.3251
- 0.3254
- 0.3302
- 0.3303
- 0.3221
- 0.3247
- 0.3316
- 0.3236
- 0.3198
- 0.3284
- 0.3337
- 0.332
- 0.3283
- 0.3283
- 0.3317
- 0.3286
- 0.3333
- 0.3286
test_loss_list:
- 1.8040357685089112
- 1.6842716217041016
- 1.6024915051460267
- 1.589000277519226
- 1.5690475916862487
- 1.5583930778503419
- 1.5443374228477478
- 1.5328450989723206
- 1.5222891449928284
- 1.4399916768074035
- 1.4528579425811767
- 1.4495718002319335
- 1.4471936893463135
- 1.372914934158325
- 1.394815936088562
- 1.4022992300987243
- 1.4015940809249878
- 1.401191749572754
- 1.3262632584571838
- 1.348955442905426
- 1.3650869560241699
- 1.2951430344581605
- 1.3230021786689758
- 1.3361840558052063
- 1.2715250205993653
- 1.2528696179389953
- 1.296764521598816
- 1.2470836019515992
- 1.2375154972076416
- 1.2312233567237854
- 1.2301236248016358
- 1.2662811040878297
- 1.282292833328247
- 1.2264492344856261
- 1.2657773995399475
- 1.2159336686134339
- 1.2549984073638916
- 1.2064941263198852
- 1.2404183483123778
- 1.2599801373481752
- 1.2650323915481567
- 1.2691927218437196
- 1.2715921664237977
- 1.2072453427314758
- 1.2447930479049683
- 1.1903339195251466
- 1.1766457176208496
- 1.1770532202720643
- 1.2161007964611052
- 1.1739274168014526
- 1.1731372678279877
- 1.1700628256797792
- 1.2094273006916045
- 1.174866601228714
- 1.1616789746284484
- 1.2032456231117248
- 1.1626273548603059
- 1.2141753268241882
- 1.1672567081451417
- 1.1537533700466156
- 1.150234431028366
- 1.1914843571186067
- 1.1540064370632173
- 1.1530435657501221
- 1.190487892627716
- 1.209456775188446
- 1.2129244816303253
- 1.159111771583557
- 1.1962618815898896
- 1.209820817708969
- 1.1591532182693483
- 1.1440315961837768
- 1.146722776889801
- 1.1953658699989318
- 1.1460533714294434
- 1.190600081682205
- 1.1488584864139557
- 1.1437609922885894
- 1.184170504808426
- 1.1438552832603455
- 1.1376056671142578
- 1.1862184071540833
- 1.145164338350296
- 1.1420042181015015
- 1.1433579576015473
- 1.1409032690525054
- 1.1778457164764404
- 1.190788859128952
- 1.1422211301326752
- 1.1876170468330383
- 1.2046504545211791
- 1.150345094203949
- 1.1431032729148864
- 1.141553943157196
- 1.179998710155487
- 1.1909534335136414
- 1.1519643115997313
- 1.184080332517624
- 1.1461243855953216
- 1.1821669054031372
train_accuracy:
- 0.038
- 0.104
- 0.0
- 0.141
- 0.12
- 0.16
- 0.178
- 0.172
- 0.2
- 0.205
- 0.22
- 0.232
- 0.249
- 0.2
- 0.228
- 0.23
- 0.219
- 0.258
- 0.0
- 0.231
- 0.239
- 0.218
- 0.225
- 0.253
- 0.228
- 0.281
- 0.278
- 0.0
- 0.263
- 0.282
- 0.245
- 0.292
- 0.247
- 0.29
- 0.245
- 0.0
- 0.292
- 0.241
- 0.286
- 0.303
- 0.28
- 0.253
- 0.324
- 0.326
- 0.326
- 0.303
- 0.293
- 0.261
- 0.308
- 0.319
- 0.297
- 0.0
- 0.322
- 0.0
- 0.29
- 0.336
- 0.0
- 0.298
- 0.319
- 0.334
- 0.302
- 0.345
- 0.0
- 0.0
- 0.362
- 0.319
- 0.366
- 0.311
- 0.321
- 0.31
- 0.0
- 0.297
- 0.308
- 0.28
- 0.35
- 0.324
- 0.303
- 0.37
- 0.338
- 0.378
- 0.357
- 0.348
- 0.0
- 0.274
- 0.293
- 0.0
- 0.305
- 0.294
- 0.342
- 0.293
- 0.357
- 0.327
- 0.327
- 0.313
- 0.32
- 0.303
- 0.308
- 0.305
- 0.361
- 0.32
train_loss:
- 3.782
- 3.83
- 3.192
- 3.438
- 3.27
- 3.148
- 3.018
- 2.946
- 2.842
- 2.519
- 2.746
- 2.65
- 2.606
- 2.288
- 2.463
- 2.368
- 2.298
- 2.192
- 2.017
- 2.17
- 2.09
- 1.945
- 2.028
- 1.959
- 1.726
- 1.637
- 1.861
- 1.648
- 1.537
- 1.52
- 1.487
- 1.734
- 1.66
- 1.494
- 1.507
- 1.406
- 1.47
- 1.371
- 1.446
- 1.38
- 1.316
- 1.325
- 1.296
- 1.124
- 1.25
- 1.118
- 1.081
- 1.061
- 1.119
- 0.974
- 0.895
- 0.932
- 1.042
- 0.9
- 0.835
- 0.96
- 0.875
- 0.877
- 0.851
- 0.875
- 0.753
- 0.88
- 0.804
- 0.78
- 0.8
- 0.805
- 0.789
- 0.672
- 0.76
- 0.7
- 0.646
- 0.59
- 0.589
- 0.68
- 0.601
- 0.693
- 0.578
- 0.575
- 0.593
- 0.566
- 0.54
- 0.596
- 0.485
- 0.454
- 0.462
- 0.456
- 0.499
- 0.504
- 0.47
- 0.479
- 0.47
- 0.456
- 0.399
- 0.409
- 0.439
- 0.403
- 0.364
- 0.366
- 0.347
- 0.36
unequal: 0
verbose: 1
