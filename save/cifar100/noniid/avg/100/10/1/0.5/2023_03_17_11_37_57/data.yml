avg_train_accuracy: 0.348
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0472
- 0.1043
- 0.121
- 0.1303
- 0.1481
- 0.1574
- 0.1676
- 0.1727
- 0.1863
- 0.1876
- 0.1955
- 0.1994
- 0.2098
- 0.2148
- 0.2175
- 0.2239
- 0.2276
- 0.2321
- 0.2363
- 0.2407
- 0.2351
- 0.2463
- 0.2547
- 0.2479
- 0.2514
- 0.2526
- 0.2574
- 0.2616
- 0.2635
- 0.2619
- 0.2617
- 0.2605
- 0.264
- 0.2651
- 0.2676
- 0.2707
- 0.2707
- 0.2746
- 0.2736
- 0.2754
- 0.2775
- 0.2799
- 0.2828
- 0.2879
- 0.2827
- 0.2854
- 0.2904
- 0.2871
- 0.2945
- 0.2919
- 0.2975
- 0.3
- 0.2902
- 0.2948
- 0.3022
- 0.2928
- 0.3062
- 0.2961
- 0.306
- 0.3118
- 0.3084
- 0.3094
- 0.3091
- 0.312
- 0.3023
- 0.3122
- 0.305
- 0.3129
- 0.3088
- 0.3025
- 0.3156
- 0.3185
- 0.3207
- 0.3196
- 0.307
- 0.3078
- 0.3193
- 0.3241
- 0.3134
- 0.3219
- 0.3253
- 0.3146
- 0.3118
- 0.3126
- 0.3152
- 0.3189
- 0.3133
- 0.3141
- 0.3191
- 0.3281
- 0.3183
- 0.3153
- 0.3271
- 0.3183
- 0.3282
- 0.3314
- 0.3207
- 0.3197
- 0.3215
- 0.3299
test_loss_list:
- 1.7873804378509521
- 1.6455838584899902
- 1.5870034074783326
- 1.5460931992530822
- 1.5101032042503357
- 1.5173761892318725
- 1.4664038276672364
- 1.4833139491081238
- 1.4258393120765687
- 1.4488227891921996
- 1.401290147304535
- 1.4234789466857911
- 1.4270793724060058
- 1.3685793733596803
- 1.389716215133667
- 1.3961407947540283
- 1.4011985278129577
- 1.3976294255256654
- 1.3292498421669006
- 1.3064748406410218
- 1.3437529611587524
- 1.2936599159240723
- 1.2778230500221253
- 1.3174040246009826
- 1.2744921255111694
- 1.3076251697540284
- 1.262763924598694
- 1.2524778580665588
- 1.2480434823036193
- 1.2465590357780456
- 1.2801039505004883
- 1.296343207359314
- 1.3026672911643982
- 1.3103691864013671
- 1.3144515776634216
- 1.3158665323257446
- 1.315074279308319
- 1.3217362642288208
- 1.3232205700874329
- 1.3262875080108643
- 1.3202745985984803
- 1.2403903317451477
- 1.2704005980491637
- 1.2756429505348206
- 1.284975209236145
- 1.2089666247367858
- 1.190326645374298
- 1.233750274181366
- 1.185226502418518
- 1.2273602652549744
- 1.1859843635559082
- 1.1767612767219544
- 1.2244986271858216
- 1.231857008934021
- 1.1814345026016235
- 1.2250256896018983
- 1.1765825653076172
- 1.2209283804893494
- 1.176828899383545
- 1.1679337787628175
- 1.167278506755829
- 1.1692671084403992
- 1.1672642207145691
- 1.1658144354820252
- 1.2060972476005554
- 1.1638992381095887
- 1.2012989926338196
- 1.1623688769340514
- 1.2006891369819641
- 1.2220715546607972
- 1.1675827741622924
- 1.1585504484176636
- 1.1594603300094604
- 1.1560111165046691
- 1.2011029505729676
- 1.2193526101112366
- 1.1629219770431518
- 1.15636634349823
- 1.2014691710472107
- 1.1648681163787842
- 1.1555503511428833
- 1.1953298783302306
- 1.2148891973495484
- 1.2253661966323852
- 1.2350501918792725
- 1.1730806469917296
- 1.2145263957977295
- 1.218524887561798
- 1.1725880980491639
- 1.1600858187675476
- 1.2024729609489442
- 1.216646478176117
- 1.1677282547950745
- 1.2037106323242188
- 1.1642860412597655
- 1.1613416266441345
- 1.2021831846237183
- 1.2174651694297791
- 1.2240028858184815
- 1.1675429296493531
train_accuracy:
- 0.055
- 0.0
- 0.0
- 0.164
- 0.163
- 0.149
- 0.0
- 0.213
- 0.189
- 0.191
- 0.208
- 0.21
- 0.203
- 0.226
- 0.171
- 0.242
- 0.231
- 0.258
- 0.0
- 0.286
- 0.249
- 0.251
- 0.28
- 0.315
- 0.265
- 0.267
- 0.284
- 0.259
- 0.0
- 0.251
- 0.276
- 0.27
- 0.317
- 0.277
- 0.264
- 0.307
- 0.29
- 0.289
- 0.301
- 0.295
- 0.305
- 0.298
- 0.346
- 0.354
- 0.285
- 0.0
- 0.324
- 0.286
- 0.31
- 0.292
- 0.0
- 0.0
- 0.247
- 0.361
- 0.0
- 0.375
- 0.36
- 0.327
- 0.317
- 0.329
- 0.0
- 0.0
- 0.0
- 0.342
- 0.322
- 0.262
- 0.335
- 0.316
- 0.301
- 0.333
- 0.376
- 0.0
- 0.365
- 0.346
- 0.376
- 0.299
- 0.366
- 0.321
- 0.318
- 0.307
- 0.337
- 0.358
- 0.264
- 0.298
- 0.367
- 0.358
- 0.309
- 0.35
- 0.332
- 0.352
- 0.357
- 0.351
- 0.341
- 0.338
- 0.355
- 0.36
- 0.369
- 0.363
- 0.345
- 0.348
train_loss:
- 4.295
- 3.392
- 3.181
- 3.01
- 2.916
- 3.226
- 2.712
- 2.972
- 2.642
- 2.829
- 2.413
- 2.751
- 2.611
- 2.288
- 2.506
- 2.42
- 2.389
- 2.311
- 2.006
- 1.949
- 2.193
- 1.903
- 1.873
- 2.086
- 1.821
- 1.972
- 1.693
- 1.687
- 1.609
- 1.612
- 1.79
- 1.736
- 1.69
- 1.592
- 1.565
- 1.588
- 1.534
- 1.421
- 1.463
- 1.409
- 1.423
- 1.305
- 1.337
- 1.335
- 1.232
- 1.177
- 1.077
- 1.244
- 1.074
- 1.148
- 0.998
- 1.037
- 1.034
- 1.04
- 0.921
- 1.04
- 0.886
- 0.956
- 0.88
- 0.799
- 0.854
- 0.773
- 0.75
- 0.808
- 0.86
- 0.807
- 0.778
- 0.769
- 0.752
- 0.744
- 0.659
- 0.653
- 0.673
- 0.615
- 0.655
- 0.672
- 0.599
- 0.552
- 0.654
- 0.55
- 0.518
- 0.573
- 0.542
- 0.548
- 0.581
- 0.491
- 0.531
- 0.494
- 0.433
- 0.454
- 0.552
- 0.451
- 0.42
- 0.434
- 0.435
- 0.419
- 0.433
- 0.425
- 0.417
- 0.389
unequal: 0
verbose: 1
