avg_train_accuracy: 0.306
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0378
- 0.0975
- 0.111
- 0.125
- 0.14
- 0.1469
- 0.1542
- 0.1724
- 0.1801
- 0.1861
- 0.1988
- 0.2068
- 0.2107
- 0.2124
- 0.2232
- 0.2211
- 0.2245
- 0.2221
- 0.2399
- 0.2322
- 0.2392
- 0.2401
- 0.2446
- 0.2468
- 0.2466
- 0.2503
- 0.2527
- 0.2628
- 0.2602
- 0.2676
- 0.2662
- 0.2647
- 0.2775
- 0.2668
- 0.2764
- 0.2693
- 0.2676
- 0.2665
- 0.2843
- 0.2781
- 0.2792
- 0.2738
- 0.2727
- 0.2785
- 0.2772
- 0.2858
- 0.2911
- 0.2927
- 0.284
- 0.2879
- 0.2876
- 0.2918
- 0.2875
- 0.2873
- 0.2971
- 0.2983
- 0.3058
- 0.2993
- 0.2904
- 0.2945
- 0.2957
- 0.3108
- 0.3062
- 0.3017
- 0.3084
- 0.3084
- 0.3047
- 0.3004
- 0.3019
- 0.304
- 0.3169
- 0.306
- 0.3034
- 0.3066
- 0.3082
- 0.3087
- 0.304
- 0.3091
- 0.3181
- 0.3083
- 0.3015
- 0.3067
- 0.3164
- 0.3072
- 0.3084
- 0.3129
- 0.3102
- 0.3132
- 0.3178
- 0.3245
- 0.3152
- 0.3143
- 0.3075
- 0.313
- 0.3107
- 0.3099
- 0.3116
- 0.3236
- 0.3239
- 0.3194
test_loss_list:
- 1.8096834468841552
- 1.705580506324768
- 1.6700571155548096
- 1.6466721510887146
- 1.5265791630744934
- 1.515396773815155
- 1.4947640872001648
- 1.4644681072235108
- 1.4720168828964233
- 1.484129354953766
- 1.4749915814399719
- 1.473116056919098
- 1.4671597099304199
- 1.4660564017295838
- 1.357871310710907
- 1.3560700082778931
- 1.3543290519714355
- 1.3762912464141845
- 1.3216752552986144
- 1.3593982219696046
- 1.3714613318443298
- 1.3838254165649415
- 1.3728871536254883
- 1.3777742242813111
- 1.3787107801437377
- 1.3800004529953003
- 1.3775161290168763
- 1.2649683713912965
- 1.3083579683303832
- 1.2589279341697692
- 1.2635228776931762
- 1.2897857570648192
- 1.2420357251167298
- 1.2875053262710572
- 1.237617495059967
- 1.277417311668396
- 1.2955450630187988
- 1.3163534927368163
- 1.218695740699768
- 1.260473051071167
- 1.2841237616539
- 1.2951593041419982
- 1.3082555842399597
- 1.3077492332458496
- 1.3178576469421386
- 1.3063948154449463
- 1.209296290874481
- 1.2104561352729797
- 1.2521617126464843
- 1.2571853685379029
- 1.2739524412155152
- 1.2768517279624938
- 1.2842585802078248
- 1.2940098142623901
- 1.2896930146217347
- 1.1929402232170105
- 1.192554681301117
- 1.230425910949707
- 1.2548661589622498
- 1.264696054458618
- 1.2668054986000061
- 1.178230950832367
- 1.1955650782585143
- 1.2263836145401001
- 1.18804105758667
- 1.1927039432525635
- 1.2211479759216308
- 1.241328308582306
- 1.2489112520217895
- 1.257161340713501
- 1.1804509329795838
- 1.220512011051178
- 1.2452041792869568
- 1.2488872241973876
- 1.2548090767860414
- 1.2607593607902527
- 1.2753484344482422
- 1.2787137722969055
- 1.1737640380859375
- 1.2360611748695374
- 1.2467243242263795
- 1.2519444370269774
- 1.1794829869270325
- 1.2340271615982055
- 1.2453499984741212
- 1.2428077721595765
- 1.2494479322433472
- 1.2584027719497681
- 1.1854902815818786
- 1.1811346077919007
- 1.2140619134902955
- 1.2334301662445069
- 1.2524977469444274
- 1.2571270179748535
- 1.263237545490265
- 1.2710558915138244
- 1.2722608542442322
- 1.1795617651939392
- 1.1919512724876404
- 1.2233408975601197
train_accuracy:
- 0.039
- 0.087
- 0.104
- 0.138
- 0.154
- 0.0
- 0.123
- 0.199
- 0.239
- 0.155
- 0.267
- 0.206
- 0.208
- 0.217
- 0.221
- 0.184
- 0.195
- 0.232
- 0.202
- 0.252
- 0.258
- 0.244
- 0.238
- 0.212
- 0.24
- 0.268
- 0.209
- 0.0
- 0.261
- 0.264
- 0.231
- 0.241
- 0.0
- 0.279
- 0.247
- 0.304
- 0.294
- 0.249
- 0.298
- 0.299
- 0.291
- 0.265
- 0.303
- 0.299
- 0.31
- 0.301
- 0.29
- 0.0
- 0.273
- 0.264
- 0.275
- 0.328
- 0.377
- 0.265
- 0.371
- 0.0
- 0.312
- 0.318
- 0.366
- 0.273
- 0.307
- 0.271
- 0.276
- 0.272
- 0.0
- 0.0
- 0.32
- 0.302
- 0.349
- 0.352
- 0.302
- 0.324
- 0.327
- 0.294
- 0.327
- 0.27
- 0.271
- 0.326
- 0.3
- 0.297
- 0.362
- 0.357
- 0.0
- 0.338
- 0.287
- 0.362
- 0.295
- 0.297
- 0.375
- 0.278
- 0.302
- 0.395
- 0.361
- 0.315
- 0.348
- 0.361
- 0.296
- 0.0
- 0.303
- 0.306
train_loss:
- 4.256
- 3.804
- 3.539
- 3.383
- 2.799
- 2.593
- 2.46
- 2.422
- 3.008
- 2.871
- 2.805
- 2.681
- 2.594
- 2.566
- 2.142
- 1.934
- 1.82
- 2.394
- 2.028
- 2.23
- 2.274
- 2.046
- 2.298
- 2.113
- 2.118
- 1.875
- 2.091
- 1.589
- 1.92
- 1.428
- 1.384
- 1.896
- 1.372
- 1.715
- 1.299
- 1.819
- 1.736
- 1.569
- 1.243
- 1.604
- 1.351
- 1.358
- 1.446
- 1.249
- 1.304
- 1.497
- 1.143
- 0.963
- 1.164
- 1.192
- 1.335
- 1.1
- 1.217
- 1.107
- 1.138
- 0.842
- 0.799
- 0.963
- 0.977
- 0.911
- 0.923
- 0.856
- 0.644
- 0.877
- 0.838
- 0.74
- 0.85
- 0.656
- 0.763
- 0.763
- 0.79
- 0.716
- 0.801
- 0.805
- 0.732
- 0.749
- 0.646
- 0.639
- 0.51
- 0.656
- 0.65
- 0.656
- 0.538
- 0.534
- 0.616
- 0.552
- 0.671
- 0.52
- 0.54
- 0.483
- 0.48
- 0.536
- 0.439
- 0.499
- 0.51
- 0.389
- 0.405
- 0.404
- 0.408
- 0.377
unequal: 0
verbose: 1
