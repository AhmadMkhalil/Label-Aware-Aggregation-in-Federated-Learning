avg_train_accuracy: 0.314
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0482
- 0.0993
- 0.1258
- 0.1399
- 0.1475
- 0.1608
- 0.172
- 0.1689
- 0.1816
- 0.1827
- 0.2004
- 0.1968
- 0.2062
- 0.2081
- 0.2168
- 0.2202
- 0.2228
- 0.2289
- 0.2315
- 0.233
- 0.2373
- 0.2389
- 0.2355
- 0.2447
- 0.2435
- 0.2498
- 0.2554
- 0.2557
- 0.2559
- 0.2588
- 0.2647
- 0.2636
- 0.2715
- 0.2713
- 0.2666
- 0.2682
- 0.2662
- 0.268
- 0.2699
- 0.2689
- 0.2764
- 0.2786
- 0.2822
- 0.2763
- 0.2784
- 0.2819
- 0.2793
- 0.2835
- 0.285
- 0.2856
- 0.2877
- 0.2863
- 0.2914
- 0.2936
- 0.2934
- 0.3009
- 0.2958
- 0.2931
- 0.2994
- 0.3047
- 0.2991
- 0.2985
- 0.3115
- 0.301
- 0.3123
- 0.3114
- 0.3074
- 0.3074
- 0.3165
- 0.311
- 0.3113
- 0.3109
- 0.311
- 0.3188
- 0.3162
- 0.3102
- 0.3059
- 0.3061
- 0.3056
- 0.3177
- 0.3115
- 0.3227
- 0.315
- 0.3132
- 0.31
- 0.3095
- 0.3136
- 0.3229
- 0.3206
- 0.3146
- 0.3114
- 0.3166
- 0.3117
- 0.3292
- 0.3156
- 0.3288
- 0.3226
- 0.3164
- 0.3152
- 0.3145
test_loss_list:
- 1.7894473218917846
- 1.6924533557891845
- 1.65141042470932
- 1.6273522186279297
- 1.6090370941162109
- 1.4963481950759887
- 1.5102774548530578
- 1.5143282675743104
- 1.4360603666305543
- 1.460676031112671
- 1.4066399025917053
- 1.4346476197242737
- 1.4410271120071412
- 1.445681471824646
- 1.3591970109939575
- 1.3906446647644044
- 1.4063916039466857
- 1.406331124305725
- 1.4058772468566894
- 1.4109835863113402
- 1.4156452322006225
- 1.4101958060264588
- 1.413693528175354
- 1.2948827171325683
- 1.3427645397186279
- 1.3466467618942262
- 1.3509779620170592
- 1.268512132167816
- 1.310692045688629
- 1.3331480383872987
- 1.2626282739639283
- 1.298285505771637
- 1.2472377729415893
- 1.254446198940277
- 1.2623785519599915
- 1.255277726650238
- 1.256393427848816
- 1.274599986076355
- 1.29187584400177
- 1.301855776309967
- 1.3062849140167236
- 1.3020719361305237
- 1.219397897720337
- 1.2384847211837768
- 1.257483241558075
- 1.2797185945510865
- 1.2946659469604491
- 1.2980836415290833
- 1.2916522407531739
- 1.3097502064704896
- 1.313156831264496
- 1.3159287929534913
- 1.3095646214485168
- 1.3088307285308838
- 1.3103530097007752
- 1.306460418701172
- 1.2042633414268493
- 1.2515932321548462
- 1.2524311757087707
- 1.2711386132240294
- 1.2780232286453248
- 1.284685685634613
- 1.1803691053390504
- 1.2367587685585022
- 1.1899318170547486
- 1.1859554243087769
- 1.1976378631591797
- 1.219927225112915
- 1.1794783234596253
- 1.1908377242088317
- 1.1901732087135315
- 1.2155043506622314
- 1.2224118304252625
- 1.1699316859245301
- 1.18383798122406
- 1.2143328189849854
- 1.2389016795158385
- 1.2519268441200255
- 1.25678316116333
- 1.1770065021514893
- 1.211863148212433
- 1.1723079013824462
- 1.2109365820884705
- 1.2293902158737182
- 1.2458784151077271
- 1.2518999695777893
- 1.2603885412216187
- 1.1754999995231628
- 1.2099657773971557
- 1.2325252056121827
- 1.24742915391922
- 1.2494255781173706
- 1.2645860123634338
- 1.1714905524253845
- 1.220203549861908
- 1.1682046270370483
- 1.2114526259899139
- 1.228861311674118
- 1.2424511528015136
- 1.2535508799552917
train_accuracy:
- 0.066
- 0.141
- 0.141
- 0.163
- 0.13
- 0.169
- 0.207
- 0.171
- 0.0
- 0.177
- 0.0
- 0.183
- 0.208
- 0.253
- 0.0
- 0.235
- 0.227
- 0.267
- 0.253
- 0.257
- 0.208
- 0.257
- 0.245
- 0.278
- 0.292
- 0.306
- 0.263
- 0.0
- 0.282
- 0.278
- 0.0
- 0.275
- 0.0
- 0.22
- 0.0
- 0.292
- 0.265
- 0.26
- 0.318
- 0.242
- 0.312
- 0.291
- 0.0
- 0.327
- 0.289
- 0.301
- 0.289
- 0.283
- 0.332
- 0.322
- 0.346
- 0.329
- 0.336
- 0.259
- 0.368
- 0.293
- 0.33
- 0.317
- 0.356
- 0.303
- 0.368
- 0.281
- 0.276
- 0.328
- 0.277
- 0.328
- 0.0
- 0.361
- 0.0
- 0.338
- 0.249
- 0.367
- 0.33
- 0.335
- 0.294
- 0.292
- 0.289
- 0.3
- 0.395
- 0.327
- 0.364
- 0.29
- 0.32
- 0.354
- 0.302
- 0.344
- 0.312
- 0.35
- 0.382
- 0.376
- 0.305
- 0.351
- 0.384
- 0.0
- 0.305
- 0.386
- 0.323
- 0.325
- 0.387
- 0.314
train_loss:
- 4.191
- 3.712
- 3.549
- 3.368
- 3.193
- 2.719
- 3.098
- 2.9
- 2.435
- 2.757
- 2.284
- 2.74
- 2.676
- 2.549
- 2.053
- 2.587
- 2.346
- 2.389
- 2.348
- 2.24
- 2.136
- 2.099
- 2.034
- 1.73
- 2.041
- 2.01
- 1.884
- 1.604
- 1.74
- 1.841
- 1.418
- 1.779
- 1.56
- 1.311
- 1.194
- 1.289
- 1.119
- 1.682
- 1.47
- 1.528
- 1.424
- 1.525
- 1.15
- 0.985
- 1.48
- 1.276
- 1.155
- 1.179
- 1.391
- 1.084
- 1.139
- 1.045
- 1.362
- 1.104
- 1.192
- 1.04
- 0.825
- 1.16
- 1.004
- 0.934
- 0.89
- 0.904
- 1.006
- 0.816
- 0.706
- 0.863
- 0.663
- 0.954
- 0.749
- 0.694
- 0.608
- 0.7
- 0.823
- 0.621
- 0.549
- 0.73
- 0.731
- 0.649
- 0.608
- 0.584
- 0.798
- 0.498
- 0.586
- 0.609
- 0.47
- 0.525
- 0.591
- 0.512
- 0.61
- 0.596
- 0.506
- 0.555
- 0.477
- 0.485
- 0.503
- 0.456
- 0.427
- 0.394
- 0.54
- 0.472
unequal: 0
verbose: 1
