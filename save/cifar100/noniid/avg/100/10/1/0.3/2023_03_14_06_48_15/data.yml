avg_train_accuracy: 0.366
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0544
- 0.093
- 0.1156
- 0.1323
- 0.1457
- 0.1547
- 0.1686
- 0.1697
- 0.1828
- 0.1815
- 0.1952
- 0.2014
- 0.2017
- 0.2094
- 0.2158
- 0.2151
- 0.2199
- 0.2196
- 0.2254
- 0.2302
- 0.231
- 0.2353
- 0.244
- 0.2422
- 0.24
- 0.2474
- 0.2533
- 0.2566
- 0.2585
- 0.2551
- 0.2592
- 0.2597
- 0.2614
- 0.2659
- 0.2719
- 0.2691
- 0.2768
- 0.2756
- 0.2873
- 0.2765
- 0.2758
- 0.2785
- 0.2819
- 0.2935
- 0.2859
- 0.2831
- 0.2833
- 0.2966
- 0.2862
- 0.286
- 0.3057
- 0.2912
- 0.2916
- 0.3062
- 0.3046
- 0.3001
- 0.3004
- 0.3001
- 0.2935
- 0.3138
- 0.2981
- 0.3152
- 0.303
- 0.2999
- 0.3173
- 0.3088
- 0.3004
- 0.3031
- 0.3045
- 0.3047
- 0.3135
- 0.3112
- 0.3081
- 0.3118
- 0.3113
- 0.3084
- 0.3063
- 0.3081
- 0.3082
- 0.3075
- 0.3111
- 0.3147
- 0.3115
- 0.3098
- 0.3231
- 0.3185
- 0.3298
- 0.3173
- 0.3152
- 0.3144
- 0.3142
- 0.3172
- 0.3169
- 0.3307
- 0.317
- 0.3145
- 0.3154
- 0.3213
- 0.3173
- 0.3189
test_loss_list:
- 1.7947475814819336
- 1.657621808052063
- 1.6294938564300536
- 1.610835223197937
- 1.5884633684158325
- 1.581806092262268
- 1.565720763206482
- 1.5554371070861817
- 1.5461147236824035
- 1.43513498544693
- 1.4568321323394775
- 1.4650523829460145
- 1.4656438875198363
- 1.467728488445282
- 1.3583329892158509
- 1.3998391032218933
- 1.4164942574501038
- 1.4180037689208984
- 1.3324941039085387
- 1.3720899176597596
- 1.3805160331726074
- 1.3914698433876038
- 1.3847960925102234
- 1.391508150100708
- 1.3966530799865722
- 1.3941235899925233
- 1.3914060235023498
- 1.3896325707435608
- 1.3940313172340393
- 1.3984013652801515
- 1.3897067666053773
- 1.4000072050094605
- 1.2693884468078613
- 1.3151954340934753
- 1.251679401397705
- 1.2890341353416443
- 1.2384089827537537
- 1.2748872780799865
- 1.225741307735443
- 1.2717364501953126
- 1.2908705759048462
- 1.292202010154724
- 1.3050658106803894
- 1.205494840145111
- 1.2541718935966493
- 1.282796275615692
- 1.2897198510169983
- 1.1998468565940856
- 1.2498612785339356
- 1.2670348262786866
- 1.1924792218208313
- 1.2453417325019835
- 1.2547898340225219
- 1.1920746994018554
- 1.19327565908432
- 1.1952899765968323
- 1.199823477268219
- 1.222141146659851
- 1.2444785261154174
- 1.1754347038269044
- 1.222593276500702
- 1.1738526558876037
- 1.2161886930465697
- 1.2340738940238953
- 1.1717177486419679
- 1.1921946024894714
- 1.225033278465271
- 1.2353271532058716
- 1.239450809955597
- 1.2492061471939087
- 1.1689015460014343
- 1.2146030282974243
- 1.2365144276618958
- 1.2346182441711426
- 1.2498342037200927
- 1.2574304842948913
- 1.2628942346572876
- 1.2587132382392883
- 1.272608470916748
- 1.2720454144477844
- 1.2777377724647523
- 1.286386489868164
- 1.2788557267189027
- 1.2943807864189147
- 1.1608301818370819
- 1.2163811254501342
- 1.161238830089569
- 1.2078333592414856
- 1.2209698677062988
- 1.2351305317878722
- 1.247061276435852
- 1.2559592080116273
- 1.2645260381698609
- 1.1641953468322754
- 1.2150083327293395
- 1.228733835220337
- 1.2442683923244475
- 1.250654900074005
- 1.245907883644104
- 1.2615953803062439
train_accuracy:
- 0.053
- 0.058
- 0.164
- 0.173
- 0.131
- 0.145
- 0.151
- 0.168
- 0.182
- 0.0
- 0.177
- 0.215
- 0.23
- 0.224
- 0.212
- 0.217
- 0.208
- 0.243
- 0.0
- 0.226
- 0.186
- 0.273
- 0.246
- 0.26
- 0.239
- 0.255
- 0.266
- 0.244
- 0.274
- 0.286
- 0.261
- 0.266
- 0.271
- 0.29
- 0.0
- 0.246
- 0.0
- 0.247
- 0.0
- 0.296
- 0.272
- 0.288
- 0.281
- 0.279
- 0.264
- 0.296
- 0.286
- 0.0
- 0.284
- 0.308
- 0.284
- 0.315
- 0.318
- 0.3
- 0.285
- 0.275
- 0.274
- 0.326
- 0.298
- 0.299
- 0.356
- 0.0
- 0.323
- 0.301
- 0.0
- 0.29
- 0.329
- 0.337
- 0.324
- 0.315
- 0.324
- 0.312
- 0.363
- 0.315
- 0.317
- 0.29
- 0.346
- 0.302
- 0.344
- 0.336
- 0.317
- 0.318
- 0.292
- 0.35
- 0.0
- 0.316
- 0.343
- 0.342
- 0.301
- 0.307
- 0.356
- 0.328
- 0.358
- 0.335
- 0.328
- 0.361
- 0.338
- 0.344
- 0.335
- 0.366
train_loss:
- 4.242
- 3.169
- 3.59
- 3.332
- 3.284
- 3.123
- 3.058
- 2.926
- 2.83
- 2.419
- 2.924
- 2.699
- 2.572
- 2.592
- 2.179
- 2.564
- 2.297
- 2.358
- 1.909
- 2.302
- 2.219
- 2.051
- 2.279
- 1.953
- 1.942
- 1.864
- 1.891
- 1.906
- 1.792
- 1.568
- 1.836
- 1.697
- 1.474
- 1.655
- 1.215
- 1.566
- 1.446
- 1.747
- 1.346
- 1.353
- 1.374
- 1.416
- 1.343
- 1.312
- 1.4
- 1.259
- 1.101
- 1.028
- 1.378
- 1.164
- 0.984
- 1.189
- 1.204
- 0.855
- 0.926
- 0.908
- 0.926
- 1.044
- 0.978
- 0.811
- 0.968
- 0.786
- 0.903
- 0.997
- 0.774
- 0.67
- 0.931
- 0.822
- 0.758
- 0.793
- 0.621
- 0.828
- 0.72
- 0.831
- 0.678
- 0.723
- 0.672
- 0.657
- 0.643
- 0.694
- 0.572
- 0.519
- 0.621
- 0.546
- 0.603
- 0.593
- 0.445
- 0.483
- 0.527
- 0.498
- 0.525
- 0.456
- 0.399
- 0.5
- 0.419
- 0.546
- 0.407
- 0.37
- 0.52
- 0.375
unequal: 0
verbose: 1
