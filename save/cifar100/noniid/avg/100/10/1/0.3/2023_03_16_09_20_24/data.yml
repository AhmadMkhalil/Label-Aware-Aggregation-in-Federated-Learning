avg_train_accuracy: 0.34
avg_train_loss: 0.005
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0381
- 0.0895
- 0.1072
- 0.1238
- 0.1417
- 0.1483
- 0.1556
- 0.1662
- 0.1809
- 0.1861
- 0.1881
- 0.1925
- 0.1961
- 0.1988
- 0.2018
- 0.2056
- 0.2124
- 0.2137
- 0.2211
- 0.2247
- 0.2436
- 0.2312
- 0.2474
- 0.2376
- 0.2526
- 0.2472
- 0.2477
- 0.2494
- 0.2558
- 0.2577
- 0.2619
- 0.2784
- 0.2674
- 0.2686
- 0.2696
- 0.273
- 0.2805
- 0.2755
- 0.2874
- 0.2865
- 0.2838
- 0.2908
- 0.2902
- 0.2867
- 0.2881
- 0.3039
- 0.2861
- 0.2891
- 0.3033
- 0.3017
- 0.2915
- 0.3001
- 0.2978
- 0.2941
- 0.2993
- 0.3022
- 0.3029
- 0.3018
- 0.3193
- 0.3047
- 0.3246
- 0.3199
- 0.3179
- 0.3101
- 0.3113
- 0.32
- 0.3154
- 0.318
- 0.3135
- 0.314
- 0.3203
- 0.3119
- 0.3108
- 0.3142
- 0.3269
- 0.3282
- 0.3168
- 0.3171
- 0.3321
- 0.3263
- 0.3226
- 0.3197
- 0.3154
- 0.3191
- 0.3373
- 0.329
- 0.3289
- 0.3212
- 0.3249
- 0.323
- 0.3259
- 0.3249
- 0.3264
- 0.3274
- 0.3405
- 0.3261
- 0.3363
- 0.3275
- 0.3351
- 0.3337
test_loss_list:
- 1.8181643676757813
- 1.6656088972091674
- 1.622180392742157
- 1.5933275055885314
- 1.5331240367889405
- 1.5395506930351257
- 1.5339084601402282
- 1.528531663417816
- 1.4408422112464905
- 1.4304692482948302
- 1.4237252426147462
- 1.4115966153144837
- 1.397786283493042
- 1.391471700668335
- 1.4002848696708678
- 1.405364580154419
- 1.4110208797454833
- 1.4054472136497498
- 1.4052388787269592
- 1.4048692965507508
- 1.3023688626289367
- 1.3424260449409484
- 1.289781847000122
- 1.3325108337402343
- 1.2809570527076721
- 1.2909121203422547
- 1.3087820816040039
- 1.3252130270004272
- 1.3233781599998473
- 1.3346717190742492
- 1.3255804204940795
- 1.2334922170639038
- 1.2779851841926575
- 1.2881653428077697
- 1.3069300603866578
- 1.304382312297821
- 1.213789186477661
- 1.2571785187721252
- 1.2167998576164245
- 1.2153206944465638
- 1.241644904613495
- 1.204670250415802
- 1.2174977207183837
- 1.2302622175216675
- 1.2466788840293885
- 1.1846541142463685
- 1.2363065576553345
- 1.2439806938171387
- 1.1823261570930481
- 1.1947638273239136
- 1.2225352597236634
- 1.2271266508102416
- 1.2378283953666687
- 1.2580303144454956
- 1.2547517800331116
- 1.2581972765922547
- 1.2614994859695434
- 1.2568004274368285
- 1.1559822511672975
- 1.2127017188072204
- 1.1548252987861634
- 1.1678074812889099
- 1.1709957766532897
- 1.192752697467804
- 1.2053464007377626
- 1.1651119804382324
- 1.1733324217796326
- 1.1707628655433655
- 1.1904095768928529
- 1.2102382230758666
- 1.157778992652893
- 1.1894451189041138
- 1.213766140937805
- 1.2202217984199524
- 1.1541769647598266
- 1.1585886597633361
- 1.1876281261444093
- 1.2002667808532714
- 1.1426322388648986
- 1.1575835490226745
- 1.1781461668014526
- 1.1979026699066162
- 1.2094692420959472
- 1.2183302593231202
- 1.1370327115058898
- 1.1606594467163085
- 1.1622122859954833
- 1.1880249667167664
- 1.2036678314208984
- 1.2082375955581666
- 1.2102012014389039
- 1.2200871229171752
- 1.226004867553711
- 1.2312606525421144
- 1.1386967265605927
- 1.1928903698921203
- 1.1461979734897614
- 1.1807971239089965
- 1.1572288990020752
- 1.1757394969463348
train_accuracy:
- 0.063
- 0.0
- 0.098
- 0.141
- 0.103
- 0.15
- 0.135
- 0.176
- 0.155
- 0.0
- 0.163
- 0.161
- 0.102
- 0.169
- 0.212
- 0.21
- 0.201
- 0.251
- 0.231
- 0.181
- 0.165
- 0.2
- 0.0
- 0.217
- 0.268
- 0.233
- 0.275
- 0.27
- 0.272
- 0.281
- 0.293
- 0.198
- 0.29
- 0.249
- 0.293
- 0.244
- 0.292
- 0.306
- 0.0
- 0.28
- 0.267
- 0.287
- 0.289
- 0.246
- 0.274
- 0.0
- 0.28
- 0.319
- 0.303
- 0.281
- 0.336
- 0.286
- 0.274
- 0.331
- 0.268
- 0.335
- 0.325
- 0.292
- 0.0
- 0.34
- 0.303
- 0.249
- 0.272
- 0.282
- 0.314
- 0.0
- 0.265
- 0.0
- 0.33
- 0.346
- 0.282
- 0.322
- 0.292
- 0.334
- 0.345
- 0.0
- 0.307
- 0.344
- 0.0
- 0.322
- 0.31
- 0.395
- 0.342
- 0.342
- 0.312
- 0.0
- 0.279
- 0.305
- 0.335
- 0.33
- 0.344
- 0.343
- 0.385
- 0.36
- 0.0
- 0.305
- 0.295
- 0.34
- 0.291
- 0.34
train_loss:
- 4.33
- 3.162
- 2.93
- 3.508
- 2.714
- 3.226
- 3.138
- 2.959
- 2.401
- 2.315
- 2.203
- 2.137
- 2.149
- 2.098
- 2.697
- 2.667
- 2.534
- 2.476
- 2.386
- 2.321
- 1.832
- 2.242
- 1.718
- 2.073
- 1.715
- 1.477
- 2.014
- 1.982
- 2.013
- 1.862
- 1.821
- 1.551
- 1.793
- 1.724
- 1.681
- 1.621
- 1.433
- 1.625
- 1.156
- 1.189
- 1.553
- 1.148
- 1.078
- 1.606
- 1.274
- 1.115
- 1.25
- 1.31
- 0.977
- 0.915
- 1.206
- 1.374
- 1.241
- 1.175
- 1.118
- 1.096
- 1.058
- 1.082
- 0.864
- 1.041
- 0.793
- 0.679
- 0.721
- 0.923
- 1.017
- 0.693
- 0.661
- 0.695
- 0.823
- 0.81
- 0.581
- 0.962
- 0.773
- 0.71
- 0.6
- 0.567
- 0.707
- 0.735
- 0.528
- 0.527
- 0.77
- 0.624
- 0.616
- 0.634
- 0.555
- 0.393
- 0.489
- 0.529
- 0.581
- 0.574
- 0.555
- 0.591
- 0.502
- 0.48
- 0.486
- 0.449
- 0.421
- 0.478
- 0.455
- 0.451
unequal: 0
verbose: 1
