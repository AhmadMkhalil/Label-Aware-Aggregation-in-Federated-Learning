avg_train_accuracy: 0.291
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0471
- 0.0904
- 0.1206
- 0.13
- 0.1492
- 0.1561
- 0.1661
- 0.1773
- 0.1819
- 0.1952
- 0.1929
- 0.2078
- 0.1998
- 0.2088
- 0.213
- 0.2159
- 0.2165
- 0.2254
- 0.2175
- 0.2372
- 0.2322
- 0.2336
- 0.24
- 0.2424
- 0.2562
- 0.246
- 0.2446
- 0.2512
- 0.2563
- 0.2654
- 0.2533
- 0.26
- 0.2614
- 0.2611
- 0.2734
- 0.2692
- 0.2719
- 0.2771
- 0.2738
- 0.2863
- 0.2799
- 0.2772
- 0.2778
- 0.2998
- 0.2839
- 0.2954
- 0.289
- 0.2911
- 0.3037
- 0.2952
- 0.2878
- 0.2881
- 0.2865
- 0.2873
- 0.2925
- 0.3086
- 0.2949
- 0.2956
- 0.2981
- 0.3147
- 0.2968
- 0.3038
- 0.2973
- 0.3017
- 0.3043
- 0.3076
- 0.3057
- 0.3189
- 0.3117
- 0.3204
- 0.3174
- 0.3138
- 0.3015
- 0.3118
- 0.3161
- 0.3144
- 0.3125
- 0.315
- 0.3147
- 0.3102
- 0.323
- 0.3267
- 0.3283
- 0.322
- 0.3286
- 0.328
- 0.3218
- 0.329
- 0.3217
- 0.3243
- 0.3194
- 0.3121
- 0.3204
- 0.318
- 0.3331
- 0.3317
- 0.3285
- 0.3323
- 0.3317
- 0.3242
test_loss_list:
- 1.800226845741272
- 1.7088925886154174
- 1.663418354988098
- 1.6402623319625855
- 1.6186913228034974
- 1.502659363746643
- 1.519996054172516
- 1.4587156987190246
- 1.4814374208450318
- 1.4193702030181885
- 1.4439889359474183
- 1.3920654702186583
- 1.4250923895835876
- 1.4261525750160218
- 1.4314474964141846
- 1.3519883012771607
- 1.3880557608604431
- 1.3345677995681762
- 1.3761747407913207
- 1.3177346730232238
- 1.3556638407707213
- 1.3659568953514098
- 1.3719149613380432
- 1.3717306423187257
- 1.2832735562324524
- 1.3289355611801148
- 1.3423592472076415
- 1.3418670535087585
- 1.345308814048767
- 1.2547461557388306
- 1.298752498626709
- 1.3138932180404663
- 1.3265220522880554
- 1.335382022857666
- 1.238424038887024
- 1.2426789355278016
- 1.2687234354019166
- 1.2884472274780274
- 1.2915225386619569
- 1.216161298751831
- 1.2514041948318482
- 1.2817972207069397
- 1.2842943930625916
- 1.1940367650985717
- 1.2464286756515504
- 1.1997477722167968
- 1.2071201777458191
- 1.2319415807724
- 1.186780445575714
- 1.2032667255401612
- 1.223278534412384
- 1.252135488986969
- 1.2578549551963807
- 1.272311758995056
- 1.2727342391014098
- 1.1715095591545106
- 1.234338982105255
- 1.2482717370986938
- 1.2477635550498962
- 1.1701758813858032
- 1.2196478462219238
- 1.2321441769599915
- 1.2617876505851746
- 1.2561786580085754
- 1.2608624053001405
- 1.2555261278152465
- 1.2606425285339355
- 1.1662908220291137
- 1.2098720383644104
- 1.1589728641510009
- 1.1745929980278016
- 1.20104887008667
- 1.2364505887031556
- 1.2248530530929564
- 1.2261335349082947
- 1.2440210962295533
- 1.2486637616157532
- 1.240281858444214
- 1.255172574520111
- 1.2697267246246338
- 1.1595810747146607
- 1.168216712474823
- 1.1676412773132325
- 1.197943000793457
- 1.1605940198898315
- 1.1643120956420898
- 1.1885591101646424
- 1.1605751419067383
- 1.1994918942451478
- 1.2010167288780211
- 1.2111523318290711
- 1.2396871376037597
- 1.2382650589942932
- 1.243758614063263
- 1.1526609301567077
- 1.1567743444442748
- 1.1868468070030211
- 1.1628978419303895
- 1.1714984631538392
- 1.1844070053100586
train_accuracy:
- 0.051
- 0.114
- 0.141
- 0.12
- 0.164
- 0.166
- 0.155
- 0.17
- 0.179
- 0.202
- 0.206
- 0.174
- 0.192
- 0.175
- 0.205
- 0.184
- 0.238
- 0.197
- 0.194
- 0.0
- 0.22
- 0.244
- 0.284
- 0.225
- 0.0
- 0.259
- 0.233
- 0.29
- 0.225
- 0.242
- 0.246
- 0.248
- 0.241
- 0.306
- 0.326
- 0.0
- 0.275
- 0.245
- 0.277
- 0.259
- 0.299
- 0.285
- 0.272
- 0.256
- 0.243
- 0.297
- 0.0
- 0.283
- 0.0
- 0.0
- 0.293
- 0.31
- 0.34
- 0.3
- 0.278
- 0.279
- 0.329
- 0.274
- 0.34
- 0.307
- 0.269
- 0.301
- 0.314
- 0.311
- 0.311
- 0.334
- 0.271
- 0.342
- 0.301
- 0.0
- 0.276
- 0.357
- 0.342
- 0.305
- 0.307
- 0.286
- 0.33
- 0.311
- 0.316
- 0.34
- 0.338
- 0.29
- 0.296
- 0.309
- 0.281
- 0.0
- 0.32
- 0.272
- 0.286
- 0.303
- 0.367
- 0.311
- 0.318
- 0.326
- 0.0
- 0.0
- 0.321
- 0.273
- 0.283
- 0.291
train_loss:
- 4.267
- 3.765
- 3.611
- 3.376
- 3.293
- 2.672
- 3.129
- 2.481
- 2.954
- 2.368
- 2.881
- 2.282
- 2.697
- 2.634
- 2.574
- 1.985
- 2.444
- 1.924
- 2.306
- 1.837
- 2.319
- 2.241
- 2.222
- 2.178
- 1.773
- 1.956
- 1.965
- 2.004
- 1.989
- 1.621
- 1.897
- 1.723
- 1.696
- 1.571
- 1.432
- 1.364
- 1.797
- 1.56
- 1.542
- 1.119
- 1.657
- 1.374
- 1.309
- 1.262
- 1.496
- 1.114
- 1.016
- 1.334
- 1.042
- 0.843
- 1.291
- 1.093
- 1.12
- 0.915
- 1.08
- 1.117
- 1.044
- 0.916
- 0.957
- 1.008
- 1.035
- 0.919
- 0.997
- 1.099
- 0.921
- 0.944
- 0.875
- 0.791
- 0.892
- 0.676
- 0.705
- 0.783
- 0.72
- 0.761
- 0.683
- 0.747
- 0.679
- 0.681
- 0.633
- 0.514
- 0.625
- 0.586
- 0.536
- 0.561
- 0.502
- 0.481
- 0.616
- 0.536
- 0.581
- 0.517
- 0.501
- 0.431
- 0.564
- 0.43
- 0.416
- 0.465
- 0.426
- 0.394
- 0.434
- 0.401
unequal: 0
verbose: 1
