avg_train_accuracy: 0.276
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0321
- 0.092
- 0.1179
- 0.1385
- 0.1433
- 0.158
- 0.1627
- 0.1766
- 0.1831
- 0.191
- 0.1953
- 0.1962
- 0.2105
- 0.2055
- 0.2191
- 0.2178
- 0.2208
- 0.2216
- 0.2259
- 0.2428
- 0.2277
- 0.2358
- 0.2358
- 0.2446
- 0.2467
- 0.2461
- 0.2534
- 0.2609
- 0.2682
- 0.263
- 0.2624
- 0.266
- 0.2819
- 0.2726
- 0.2894
- 0.277
- 0.2782
- 0.283
- 0.2843
- 0.2953
- 0.2843
- 0.2858
- 0.287
- 0.2862
- 0.2887
- 0.3082
- 0.306
- 0.3039
- 0.2967
- 0.3006
- 0.2945
- 0.2983
- 0.2992
- 0.2985
- 0.3032
- 0.3038
- 0.3069
- 0.3091
- 0.3082
- 0.3095
- 0.3126
- 0.3102
- 0.3088
- 0.3126
- 0.3216
- 0.3176
- 0.3099
- 0.3246
- 0.3129
- 0.316
- 0.3142
- 0.3128
- 0.324
- 0.3124
- 0.3115
- 0.3309
- 0.3296
- 0.3214
- 0.3158
- 0.3288
- 0.3148
- 0.3215
- 0.3363
- 0.3307
- 0.323
- 0.3208
- 0.3175
- 0.3201
- 0.3183
- 0.3208
- 0.3182
- 0.3219
- 0.3223
- 0.3231
- 0.3318
- 0.3255
- 0.3215
- 0.3229
- 0.322
- 0.3372
test_loss_list:
- 1.8110660266876222
- 1.6805333042144774
- 1.6481799912452697
- 1.5535496544837952
- 1.5530780363082886
- 1.5522783303260803
- 1.5367070817947388
- 1.5255856132507324
- 1.5216273021698
- 1.4180990409851075
- 1.4122552371025086
- 1.4287987852096558
- 1.3800419306755065
- 1.4085808634757995
- 1.361722548007965
- 1.351724464893341
- 1.369017369747162
- 1.3903183078765868
- 1.3919006180763245
- 1.305794677734375
- 1.3504714560508728
- 1.3597894406318665
- 1.3772126936912537
- 1.3682928586006164
- 1.3696636605262755
- 1.385590534210205
- 1.3658369994163513
- 1.3647601771354676
- 1.2498679041862488
- 1.2958066701889037
- 1.3139903497695924
- 1.3150623989105226
- 1.2275276136398316
- 1.2713237261772157
- 1.2169395303726196
- 1.2558256721496581
- 1.267924952507019
- 1.2874887108802795
- 1.2952256846427916
- 1.2002669095993042
- 1.248936414718628
- 1.2624320888519287
- 1.2714383578300477
- 1.2841688656806947
- 1.292937424182892
- 1.1774776625633239
- 1.18017249584198
- 1.188711678981781
- 1.2262535190582275
- 1.2300457644462586
- 1.2562637495994569
- 1.2611264395713806
- 1.261724066734314
- 1.2841286516189576
- 1.2694992923736572
- 1.2764757800102233
- 1.2768560528755188
- 1.278789222240448
- 1.2791930150985718
- 1.2843371224403382
- 1.1635643601417542
- 1.2242753171920777
- 1.243329198360443
- 1.2364506220817566
- 1.157327492237091
- 1.170185260772705
- 1.205005350112915
- 1.1606180000305175
- 1.2005254650115966
- 1.2128646421432494
- 1.2366906785964966
- 1.2422717142105102
- 1.1562381148338319
- 1.2084132409095765
- 1.226984405517578
- 1.1504382658004761
- 1.1663948440551757
- 1.1924398303031922
- 1.212832041978836
- 1.1511280071735381
- 1.2092531275749208
- 1.202510381937027
- 1.1465715384483337
- 1.1612526607513427
- 1.191405519247055
- 1.2183200418949127
- 1.2253861486911775
- 1.2196354007720946
- 1.2388535130023957
- 1.2408101952075958
- 1.247425091266632
- 1.2448013174533843
- 1.2542974495887755
- 1.2592843389511108
- 1.152392407655716
- 1.2005689334869385
- 1.217904396057129
- 1.240059585571289
- 1.2266666722297668
- 1.152060992717743
train_accuracy:
- 0.0
- 0.121
- 0.113
- 0.0
- 0.134
- 0.167
- 0.174
- 0.163
- 0.2
- 0.0
- 0.0
- 0.159
- 0.192
- 0.212
- 0.207
- 0.0
- 0.194
- 0.204
- 0.224
- 0.0
- 0.241
- 0.239
- 0.244
- 0.215
- 0.248
- 0.236
- 0.264
- 0.261
- 0.0
- 0.264
- 0.273
- 0.27
- 0.234
- 0.262
- 0.0
- 0.311
- 0.297
- 0.262
- 0.316
- 0.298
- 0.304
- 0.306
- 0.296
- 0.266
- 0.273
- 0.293
- 0.289
- 0.251
- 0.278
- 0.32
- 0.265
- 0.279
- 0.302
- 0.279
- 0.32
- 0.326
- 0.289
- 0.271
- 0.283
- 0.322
- 0.318
- 0.34
- 0.332
- 0.276
- 0.0
- 0.297
- 0.294
- 0.281
- 0.3
- 0.291
- 0.294
- 0.328
- 0.0
- 0.324
- 0.345
- 0.258
- 0.289
- 0.335
- 0.358
- 0.323
- 0.322
- 0.338
- 0.291
- 0.258
- 0.338
- 0.338
- 0.274
- 0.361
- 0.301
- 0.339
- 0.295
- 0.331
- 0.334
- 0.344
- 0.0
- 0.287
- 0.346
- 0.332
- 0.361
- 0.276
train_loss:
- 3.448
- 3.916
- 3.548
- 2.838
- 3.363
- 3.129
- 3.128
- 2.993
- 2.865
- 2.388
- 2.261
- 2.777
- 2.09
- 2.543
- 1.94
- 2.025
- 2.531
- 2.285
- 2.305
- 1.899
- 2.065
- 2.022
- 1.966
- 2.104
- 1.965
- 1.79
- 1.916
- 1.951
- 1.731
- 1.838
- 1.583
- 1.857
- 1.485
- 1.639
- 1.45
- 1.621
- 1.565
- 1.534
- 1.395
- 1.154
- 1.493
- 1.458
- 1.349
- 1.288
- 1.242
- 1.202
- 1.0
- 0.979
- 1.313
- 1.248
- 1.134
- 1.091
- 1.037
- 1.022
- 1.092
- 1.063
- 1.059
- 0.922
- 0.943
- 0.86
- 0.85
- 0.84
- 0.765
- 0.955
- 0.681
- 0.747
- 0.837
- 0.662
- 0.717
- 0.856
- 0.642
- 0.706
- 0.626
- 0.698
- 0.764
- 0.639
- 0.527
- 0.596
- 0.791
- 0.534
- 0.531
- 0.648
- 0.502
- 0.497
- 0.5
- 0.475
- 0.575
- 0.598
- 0.497
- 0.448
- 0.482
- 0.477
- 0.453
- 0.397
- 0.429
- 0.485
- 0.339
- 0.4
- 0.5
- 0.381
unequal: 0
verbose: 1
