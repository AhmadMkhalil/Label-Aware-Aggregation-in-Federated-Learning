avg_train_accuracy: 0.297
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0432
- 0.0976
- 0.1173
- 0.1335
- 0.1489
- 0.1652
- 0.1666
- 0.1781
- 0.1796
- 0.1921
- 0.1984
- 0.1967
- 0.2051
- 0.2084
- 0.214
- 0.2196
- 0.2189
- 0.2236
- 0.2301
- 0.2344
- 0.2432
- 0.2385
- 0.2344
- 0.2442
- 0.246
- 0.2486
- 0.2525
- 0.2607
- 0.2577
- 0.2612
- 0.2616
- 0.2716
- 0.2635
- 0.2809
- 0.2766
- 0.2695
- 0.2738
- 0.2719
- 0.2756
- 0.2784
- 0.2887
- 0.2795
- 0.28
- 0.2845
- 0.2877
- 0.2878
- 0.2902
- 0.2933
- 0.29
- 0.2953
- 0.3018
- 0.294
- 0.2945
- 0.2924
- 0.3068
- 0.3085
- 0.2983
- 0.2967
- 0.2986
- 0.3017
- 0.2992
- 0.3035
- 0.309
- 0.3172
- 0.3051
- 0.3017
- 0.3111
- 0.3042
- 0.311
- 0.3083
- 0.3103
- 0.3081
- 0.3087
- 0.3108
- 0.3099
- 0.3097
- 0.3118
- 0.3081
- 0.3147
- 0.3172
- 0.311
- 0.3247
- 0.3216
- 0.3193
- 0.3173
- 0.3338
- 0.32
- 0.3274
- 0.321
- 0.3217
- 0.3201
- 0.3326
- 0.3215
- 0.3329
- 0.3287
- 0.3319
- 0.329
- 0.3228
- 0.3358
- 0.3298
test_loss_list:
- 1.805188202857971
- 1.6929896116256713
- 1.6566388154029845
- 1.6386103582382203
- 1.6194224596023559
- 1.6003046345710754
- 1.5860587310791017
- 1.5797122120857239
- 1.4523314571380614
- 1.4204477787017822
- 1.4090861678123474
- 1.4319354104995727
- 1.4407420659065246
- 1.449214415550232
- 1.441541292667389
- 1.3449062848091125
- 1.3787602090835571
- 1.3912352657318114
- 1.3977378726005554
- 1.40090660572052
- 1.3043014812469482
- 1.3086362504959106
- 1.3425486302375793
- 1.345513768196106
- 1.355101571083069
- 1.3562084078788756
- 1.3584126710891724
- 1.2564073300361633
- 1.3064152336120605
- 1.3229218244552612
- 1.3242497801780702
- 1.239275803565979
- 1.2960874915122986
- 1.232130777835846
- 1.2472155356407166
- 1.2774208641052247
- 1.2859598517417907
- 1.2922765469551087
- 1.2991956186294555
- 1.3076834535598756
- 1.2091145920753479
- 1.2620897674560547
- 1.2798379230499268
- 1.2790337157249452
- 1.283674683570862
- 1.2964324164390564
- 1.304314250946045
- 1.2950943875312806
- 1.3074736094474793
- 1.307643096446991
- 1.1863380289077758
- 1.2378758025169372
- 1.2573877811431884
- 1.2705046606063843
- 1.1772892355918885
- 1.1893279886245727
- 1.223467197418213
- 1.2463767528533936
- 1.24983633518219
- 1.2621567678451537
- 1.278788628578186
- 1.266832275390625
- 1.1788023209571838
- 1.1732385110855104
- 1.2137775802612305
- 1.2432611215114593
- 1.2425160241127013
- 1.2523552036285401
- 1.2596468234062195
- 1.2684263801574707
- 1.2695168900489806
- 1.2694314241409301
- 1.2912078595161438
- 1.2835487246513366
- 1.2920358562469483
- 1.2893220925331115
- 1.2940492749214172
- 1.2956576538085938
- 1.2903071331977845
- 1.165509147644043
- 1.2258422100543975
- 1.1728829264640808
- 1.1792917990684508
- 1.208219153881073
- 1.2211524868011474
- 1.1644210362434386
- 1.210880777835846
- 1.176761667728424
- 1.2058146023750305
- 1.2183563685417176
- 1.2303242874145508
- 1.1587755918502807
- 1.2065672087669372
- 1.162583498954773
- 1.1848541164398194
- 1.174127037525177
- 1.1884136247634887
- 1.1966700303554534
- 1.1677730298042297
- 1.1773193764686585
train_accuracy:
- 0.042
- 0.106
- 0.121
- 0.141
- 0.137
- 0.14
- 0.182
- 0.19
- 0.202
- 0.154
- 0.176
- 0.215
- 0.272
- 0.26
- 0.23
- 0.0
- 0.223
- 0.214
- 0.205
- 0.23
- 0.246
- 0.0
- 0.206
- 0.271
- 0.235
- 0.275
- 0.267
- 0.259
- 0.239
- 0.248
- 0.283
- 0.0
- 0.288
- 0.266
- 0.241
- 0.299
- 0.334
- 0.262
- 0.285
- 0.281
- 0.0
- 0.262
- 0.29
- 0.301
- 0.327
- 0.308
- 0.35
- 0.285
- 0.301
- 0.311
- 0.0
- 0.291
- 0.371
- 0.321
- 0.318
- 0.281
- 0.297
- 0.265
- 0.323
- 0.314
- 0.29
- 0.331
- 0.0
- 0.314
- 0.322
- 0.362
- 0.299
- 0.298
- 0.347
- 0.344
- 0.385
- 0.346
- 0.333
- 0.36
- 0.319
- 0.343
- 0.338
- 0.315
- 0.345
- 0.0
- 0.327
- 0.0
- 0.297
- 0.309
- 0.326
- 0.0
- 0.317
- 0.0
- 0.324
- 0.324
- 0.329
- 0.0
- 0.361
- 0.0
- 0.332
- 0.0
- 0.267
- 0.34
- 0.324
- 0.297
train_loss:
- 4.26
- 3.773
- 3.467
- 3.245
- 3.13
- 3.088
- 2.974
- 2.755
- 2.474
- 2.35
- 2.279
- 2.708
- 2.643
- 2.429
- 2.589
- 2.073
- 2.433
- 2.395
- 2.25
- 2.203
- 1.841
- 1.741
- 2.035
- 2.033
- 2.084
- 2.03
- 1.857
- 1.653
- 1.884
- 1.687
- 1.874
- 1.397
- 1.718
- 1.362
- 1.179
- 1.604
- 1.564
- 1.602
- 1.599
- 1.504
- 1.182
- 1.452
- 1.315
- 1.349
- 1.229
- 1.12
- 1.314
- 1.254
- 1.183
- 1.248
- 1.092
- 0.998
- 1.091
- 1.051
- 0.954
- 0.79
- 0.952
- 1.003
- 0.783
- 1.004
- 0.905
- 0.753
- 0.653
- 0.888
- 0.879
- 0.893
- 0.894
- 0.837
- 0.82
- 0.661
- 0.715
- 0.675
- 0.584
- 0.818
- 0.575
- 0.558
- 0.632
- 0.648
- 0.633
- 0.656
- 0.54
- 0.601
- 0.517
- 0.624
- 0.618
- 0.562
- 0.486
- 0.482
- 0.538
- 0.48
- 0.512
- 0.51
- 0.514
- 0.436
- 0.392
- 0.443
- 0.388
- 0.492
- 0.37
- 0.352
unequal: 0
verbose: 1
