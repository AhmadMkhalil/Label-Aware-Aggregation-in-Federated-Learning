avg_train_accuracy: 0.333
avg_train_loss: 0.004
avg_type: avg
dataset: cifar100
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.001
max_pool: 'True'
model: cnn
momentum: 0.9
norm: batch_norm
num_channels: 3
num_classes: 100
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 10
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0316
- 0.0844
- 0.1094
- 0.124
- 0.139
- 0.154
- 0.1646
- 0.1713
- 0.1854
- 0.1882
- 0.1921
- 0.1965
- 0.205
- 0.2147
- 0.2159
- 0.2159
- 0.2296
- 0.2335
- 0.2395
- 0.2384
- 0.2417
- 0.2495
- 0.2473
- 0.2546
- 0.2497
- 0.2485
- 0.2657
- 0.2579
- 0.2565
- 0.2686
- 0.2642
- 0.2749
- 0.2673
- 0.2702
- 0.2718
- 0.2729
- 0.2777
- 0.2748
- 0.2822
- 0.2815
- 0.2847
- 0.2977
- 0.2867
- 0.2872
- 0.2887
- 0.2879
- 0.2927
- 0.2956
- 0.2922
- 0.2987
- 0.2973
- 0.2983
- 0.3
- 0.2972
- 0.2985
- 0.3016
- 0.2971
- 0.2969
- 0.2979
- 0.3048
- 0.3055
- 0.3089
- 0.3028
- 0.3032
- 0.3133
- 0.3072
- 0.305
- 0.3195
- 0.3134
- 0.3073
- 0.3243
- 0.3123
- 0.3061
- 0.3057
- 0.3112
- 0.3085
- 0.327
- 0.3224
- 0.3146
- 0.3155
- 0.3158
- 0.3245
- 0.3202
- 0.3115
- 0.3173
- 0.3285
- 0.3249
- 0.3189
- 0.3111
- 0.3157
- 0.3164
- 0.3259
- 0.3245
- 0.3261
- 0.3153
- 0.3233
- 0.3224
- 0.3312
- 0.3329
- 0.3215
test_loss_list:
- 1.807457971572876
- 1.685894865989685
- 1.6053897476196288
- 1.5899980545043946
- 1.570618929862976
- 1.4964995932579042
- 1.510444371700287
- 1.513113739490509
- 1.507023766040802
- 1.4974325919151306
- 1.4961715650558471
- 1.4894344210624695
- 1.4886706137657166
- 1.3668712043762208
- 1.400261709690094
- 1.4142377328872682
- 1.4080901098251344
- 1.402076907157898
- 1.313035521507263
- 1.3534722328186035
- 1.3644804072380066
- 1.2955868792533876
- 1.3285358357429504
- 1.2812521696090697
- 1.2862755942344666
- 1.3143423986434937
- 1.2644326639175416
- 1.2940398859977722
- 1.3131393766403199
- 1.3176234149932862
- 1.3303341460227966
- 1.2433794045448303
- 1.2896255588531493
- 1.3001878547668457
- 1.3120160102844238
- 1.3048452234268189
- 1.3158762741088867
- 1.3268655014038087
- 1.317652361392975
- 1.3114377236366273
- 1.3207797765731812
- 1.2042376232147216
- 1.259910204410553
- 1.267909677028656
- 1.2873077297210693
- 1.2849059200286865
- 1.2864165139198303
- 1.2967107915878295
- 1.307353081703186
- 1.1950013828277588
- 1.1986662006378175
- 1.2263468837738036
- 1.2458170533180237
- 1.2600062108039856
- 1.2671794128417968
- 1.185442442893982
- 1.2235282278060913
- 1.2505464744567871
- 1.2664051270484924
- 1.257573308944702
- 1.2666711521148681
- 1.1739960718154907
- 1.2245843720436096
- 1.2421916818618775
- 1.174780695438385
- 1.2176131677627564
- 1.2351413249969483
- 1.1670156478881837
- 1.1852453231811524
- 1.2144726634025573
- 1.1761014890670776
- 1.2151581025123597
- 1.2355635118484498
- 1.23836523771286
- 1.2463330721855164
- 1.2515754437446593
- 1.1569738912582397
- 1.173006546497345
- 1.2096393179893494
- 1.218122262954712
- 1.2325169682502746
- 1.1687129616737366
- 1.2081630396842957
- 1.2339397597312927
- 1.237634003162384
- 1.166204195022583
- 1.1805986833572388
- 1.1939658665657042
- 1.2167672801017761
- 1.221823227405548
- 1.2298947954177857
- 1.171836061477661
- 1.1809964108467101
- 1.1988811779022217
- 1.223627152442932
- 1.2235880851745606
- 1.2356876945495605
- 1.1662712645530702
- 1.1759049415588378
- 1.2084733629226685
train_accuracy:
- 0.014
- 0.074
- 0.0
- 0.103
- 0.128
- 0.0
- 0.18
- 0.175
- 0.158
- 0.189
- 0.192
- 0.214
- 0.237
- 0.225
- 0.227
- 0.175
- 0.237
- 0.249
- 0.22
- 0.228
- 0.255
- 0.239
- 0.275
- 0.242
- 0.221
- 0.2
- 0.272
- 0.265
- 0.264
- 0.27
- 0.272
- 0.279
- 0.26
- 0.222
- 0.291
- 0.277
- 0.283
- 0.311
- 0.303
- 0.303
- 0.311
- 0.237
- 0.291
- 0.28
- 0.294
- 0.318
- 0.341
- 0.334
- 0.307
- 0.312
- 0.279
- 0.29
- 0.321
- 0.326
- 0.252
- 0.312
- 0.244
- 0.344
- 0.337
- 0.305
- 0.346
- 0.304
- 0.301
- 0.258
- 0.312
- 0.299
- 0.342
- 0.257
- 0.324
- 0.317
- 0.239
- 0.353
- 0.307
- 0.293
- 0.316
- 0.311
- 0.312
- 0.297
- 0.296
- 0.314
- 0.319
- 0.307
- 0.256
- 0.323
- 0.335
- 0.34
- 0.293
- 0.294
- 0.32
- 0.314
- 0.357
- 0.0
- 0.307
- 0.352
- 0.311
- 0.261
- 0.328
- 0.312
- 0.3
- 0.333
train_loss:
- 3.456
- 3.906
- 2.922
- 3.505
- 3.354
- 2.571
- 3.151
- 2.888
- 2.905
- 2.767
- 2.776
- 2.533
- 2.588
- 2.221
- 2.562
- 2.405
- 2.443
- 2.522
- 1.914
- 2.352
- 2.217
- 1.757
- 2.302
- 1.678
- 1.602
- 2.076
- 1.594
- 2.07
- 1.981
- 1.826
- 1.747
- 1.399
- 1.611
- 1.74
- 1.62
- 1.558
- 1.591
- 1.596
- 1.621
- 1.549
- 1.425
- 1.195
- 1.255
- 1.407
- 1.21
- 1.352
- 1.182
- 1.132
- 1.116
- 0.967
- 0.99
- 1.14
- 1.205
- 0.998
- 1.031
- 0.89
- 1.144
- 0.889
- 0.987
- 1.002
- 0.834
- 0.821
- 0.769
- 0.738
- 0.841
- 0.865
- 0.653
- 0.807
- 0.644
- 0.738
- 0.63
- 0.73
- 0.585
- 0.594
- 0.901
- 0.788
- 0.623
- 0.458
- 0.518
- 0.724
- 0.634
- 0.638
- 0.586
- 0.558
- 0.574
- 0.43
- 0.375
- 0.374
- 0.511
- 0.538
- 0.498
- 0.473
- 0.44
- 0.58
- 0.53
- 0.616
- 0.374
- 0.396
- 0.447
- 0.428
unequal: 0
verbose: 1
