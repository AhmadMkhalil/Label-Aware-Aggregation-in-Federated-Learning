avg_train_accuracy: 0.088
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04398936170212766
- 0.11904255319148936
- 0.16787234042553192
- 0.19680851063829788
- 0.2323404255319149
- 0.2597340425531915
- 0.22659574468085106
- 0.28154255319148935
- 0.26382978723404255
- 0.2680851063829787
- 0.29
- 0.28414893617021275
- 0.30861702127659574
- 0.32654255319148934
- 0.3071808510638298
- 0.3013297872340426
- 0.31053191489361703
- 0.34585106382978725
- 0.34122340425531916
- 0.33420212765957447
- 0.3229787234042553
- 0.354468085106383
- 0.33893617021276595
- 0.351968085106383
- 0.3400531914893617
- 0.3397872340425532
- 0.38409574468085106
- 0.35382978723404257
- 0.3607446808510638
- 0.4095744680851064
- 0.4308510638297872
- 0.3174468085106383
- 0.37888297872340426
- 0.3447872340425532
- 0.3878191489361702
- 0.3723936170212766
- 0.37877659574468087
- 0.36851063829787234
- 0.4122872340425532
- 0.37946808510638297
- 0.34808510638297874
- 0.37893617021276593
- 0.4373404255319149
- 0.38313829787234044
- 0.40377659574468083
- 0.39691489361702126
- 0.42404255319148937
- 0.4072340425531915
- 0.40861702127659577
- 0.46287234042553194
- 0.44111702127659574
- 0.4076063829787234
- 0.381063829787234
- 0.4452127659574468
- 0.38632978723404254
- 0.42781914893617023
- 0.4333510638297872
- 0.4588829787234043
- 0.3980851063829787
- 0.42329787234042554
- 0.39776595744680854
- 0.4160106382978723
- 0.4673404255319149
- 0.4321808510638298
- 0.45835106382978724
- 0.4491489361702128
- 0.4446276595744681
- 0.3903191489361702
- 0.4898936170212766
- 0.4469148936170213
- 0.3979255319148936
- 0.4254787234042553
- 0.49627659574468086
- 0.3500531914893617
- 0.4238297872340426
- 0.36154255319148937
- 0.39989361702127657
- 0.47372340425531917
- 0.3926595744680851
- 0.43175531914893617
- 0.4734042553191489
- 0.39351063829787236
- 0.4275
- 0.4695744680851064
- 0.46297872340425533
- 0.4803191489361702
- 0.468031914893617
- 0.4684042553191489
- 0.4843085106382979
- 0.42377659574468085
- 0.43053191489361703
- 0.4353723404255319
- 0.42223404255319147
- 0.47329787234042553
- 0.5199468085106383
- 0.4975531914893617
- 0.3988829787234043
- 0.43164893617021277
- 0.41606382978723405
- 0.47585106382978726
test_loss_list:
- 4.072863012949625
- 4.224505583445231
- 4.319169311523438
- 3.743287928899129
- 4.176941951115926
- 3.8963505458831786
- 3.631321334838867
- 3.1193595536549887
- 3.8213902727762856
- 3.393730560938517
- 3.200718011856079
- 4.8478651682535805
- 3.4869874795277913
- 3.3010134887695313
- 3.0285271835327148
- 3.6346919123331705
- 3.753417409261068
- 3.070669476191203
- 3.108529189427694
- 2.9963409964243573
- 3.7465668455759684
- 3.371553694407145
- 3.271846049626668
- 2.9506022993723553
- 3.4754422251383463
- 2.915199556350708
- 3.1493123817443847
- 3.2248270225524904
- 3.451859213511149
- 2.8792437648773195
- 2.7809169578552244
- 4.540250968933106
- 2.754121650060018
- 3.5361447938283286
- 3.5505074310302733
- 3.6605440743764244
- 3.8327377732594807
- 3.301912053426107
- 2.9796239503224693
- 2.897872804005941
- 3.1875085926055906
- 3.1305610656738283
- 2.615977716445923
- 2.8171821149190266
- 2.704178212483724
- 3.541119070053101
- 2.5839772097269695
- 2.877217572530111
- 3.546389169692993
- 2.633083413441976
- 2.582384843826294
- 3.3778076426188153
- 3.0745654169718426
- 2.7768080552419026
- 3.6435671774546305
- 2.6227502663930258
- 2.9929131285349526
- 2.8279788812001545
- 3.4634458510080974
- 2.642056608200073
- 3.384132588704427
- 3.22561448097229
- 2.8723514080047607
- 2.6425412336985272
- 2.921633062362671
- 2.6674868551890056
- 2.773880370457967
- 3.5766008726755776
- 2.7370481236775714
- 2.6464608891805015
- 3.120754041671753
- 3.2074350865681964
- 2.4318292919794717
- 4.5473273054758705
- 2.832125266393026
- 4.323128773371379
- 2.893482869466146
- 2.580499833424886
- 3.1494128863016764
- 3.0918141841888427
- 2.662156286239624
- 3.495280574162801
- 2.78247363726298
- 2.6674978923797608
- 2.7198661390940346
- 2.6368849341074627
- 2.5924665927886963
- 2.717463986078898
- 2.6783928553263348
- 3.100103810628255
- 3.109201707839966
- 3.1311274083455403
- 3.105792096455892
- 2.7248782030741374
- 2.5648046112060547
- 2.524628299077352
- 3.190772647857666
- 2.9451615905761717
- 3.1704806900024414
- 2.80057746887207
train_accuracy:
- 0.077
- 0.337
- 0.0
- 0.55
- 0.598
- 0.0
- 0.642
- 0.006
- 0.713
- 0.008
- 0.698
- 0.0
- 0.65
- 0.054
- 0.017
- 0.004
- 0.004
- 0.006
- 0.006
- 0.044
- 0.769
- 0.754
- 0.756
- 0.758
- 0.065
- 0.681
- 0.04
- 0.779
- 0.8
- 0.021
- 0.733
- 0.835
- 0.027
- 0.0
- 0.042
- 0.808
- 0.048
- 0.815
- 0.077
- 0.033
- 0.821
- 0.806
- 0.058
- 0.808
- 0.048
- 0.065
- 0.058
- 0.067
- 0.838
- 0.06
- 0.798
- 0.844
- 0.833
- 0.802
- 0.819
- 0.056
- 0.842
- 0.831
- 0.092
- 0.794
- 0.035
- 0.869
- 0.8
- 0.0
- 0.823
- 0.008
- 0.052
- 0.06
- 0.767
- 0.831
- 0.817
- 0.094
- 0.102
- 0.854
- 0.046
- 0.846
- 0.842
- 0.137
- 0.825
- 0.85
- 0.0
- 0.86
- 0.86
- 0.002
- 0.838
- 0.802
- 0.088
- 0.002
- 0.812
- 0.84
- 0.806
- 0.871
- 0.827
- 0.071
- 0.056
- 0.006
- 0.835
- 0.062
- 0.833
- 0.088
train_loss:
- 2.568
- 2.391
- 1.861
- 1.434
- 1.415
- 1.362
- 1.342
- 0.979
- 1.244
- 1.201
- 1.039
- 1.195
- 1.069
- 0.925
- 0.937
- 1.07
- 1.026
- 0.879
- 0.843
- 0.858
- 0.923
- 0.891
- 0.931
- 0.798
- 0.896
- 0.82
- 0.745
- 0.884
- 0.822
- 0.732
- 0.616
- 0.907
- 0.744
- 0.821
- 0.76
- 0.764
- 0.727
- 0.788
- 0.695
- 0.687
- 0.762
- 0.784
- 0.58
- 0.706
- 0.687
- 0.699
- 0.715
- 0.637
- 0.68
- 0.649
- 0.568
- 0.672
- 0.706
- 0.647
- 0.668
- 0.675
- 0.606
- 0.602
- 0.686
- 0.64
- 0.687
- 0.654
- 0.599
- 0.628
- 0.593
- 0.623
- 0.581
- 0.63
- 0.573
- 0.609
- 0.68
- 0.642
- 0.522
- 0.687
- 0.688
- 0.692
- 0.655
- 0.485
- 0.656
- 0.623
- 0.549
- 0.609
- 0.679
- 0.568
- 0.529
- 0.53
- 0.581
- 0.517
- 0.515
- 0.587
- 0.613
- 0.612
- 0.625
- 0.557
- 0.463
- 0.482
- 0.588
- 0.589
- 0.573
- 0.506
unequal: 0
verbose: 1
