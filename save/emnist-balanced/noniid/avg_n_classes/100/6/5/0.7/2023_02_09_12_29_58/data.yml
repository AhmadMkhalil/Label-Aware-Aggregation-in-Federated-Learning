avg_train_accuracy: 0.021
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.01946808510638298
- 0.09404255319148937
- 0.16388297872340427
- 0.17835106382978724
- 0.24143617021276595
- 0.24186170212765956
- 0.25590425531914895
- 0.27824468085106385
- 0.2961170212765957
- 0.2743617021276596
- 0.32638297872340427
- 0.3159574468085106
- 0.3421276595744681
- 0.31292553191489364
- 0.349468085106383
- 0.36957446808510636
- 0.39617021276595743
- 0.33808510638297873
- 0.4014893617021277
- 0.3598404255319149
- 0.3698404255319149
- 0.36829787234042555
- 0.37372340425531914
- 0.43898936170212766
- 0.42223404255319147
- 0.43659574468085105
- 0.3989893617021277
- 0.39941489361702126
- 0.43851063829787235
- 0.43840425531914895
- 0.4118085106382979
- 0.4527127659574468
- 0.37601063829787235
- 0.478031914893617
- 0.35079787234042553
- 0.4847872340425532
- 0.4427127659574468
- 0.47819148936170214
- 0.4692021276595745
- 0.3792553191489362
- 0.4397340425531915
- 0.46632978723404256
- 0.443563829787234
- 0.4938297872340425
- 0.3822340425531915
- 0.46664893617021275
- 0.48734042553191487
- 0.3989893617021277
- 0.4653191489361702
- 0.5191489361702127
- 0.474468085106383
- 0.4643617021276596
- 0.49920212765957445
- 0.49351063829787234
- 0.4654255319148936
- 0.4677127659574468
- 0.4503723404255319
- 0.46893617021276596
- 0.4626063829787234
- 0.5427127659574468
- 0.4677127659574468
- 0.5154255319148936
- 0.5219148936170213
- 0.47345744680851065
- 0.4257446808510638
- 0.46856382978723404
- 0.470531914893617
- 0.4971276595744681
- 0.5402127659574468
- 0.4747872340425532
- 0.5324468085106383
- 0.5684574468085106
- 0.46356382978723404
- 0.5047872340425532
- 0.4811170212765957
- 0.48654255319148937
- 0.5427659574468086
- 0.5013829787234042
- 0.5437765957446808
- 0.48734042553191487
- 0.5507978723404255
- 0.5038297872340426
- 0.44335106382978723
- 0.5086170212765957
- 0.5460106382978723
- 0.49601063829787234
- 0.5057446808510638
- 0.5502127659574468
- 0.5546808510638298
- 0.5054787234042554
- 0.5233510638297872
- 0.556063829787234
- 0.5331382978723405
- 0.5019148936170212
- 0.5226595744680851
- 0.4993085106382979
- 0.5151063829787234
- 0.5603191489361702
- 0.535372340425532
- 0.5838297872340426
test_loss_list:
- 3.913994353612264
- 3.9840804513295494
- 3.7286704444885252
- 3.5527159468332927
- 3.5797126356760662
- 3.1643290615081785
- 3.5144196573893227
- 3.052956059773763
- 3.0946940485636394
- 3.036134386062622
- 2.98029047648112
- 3.3267232354482017
- 2.7118815930684406
- 3.064845136006673
- 2.7657301235198974
- 2.8210852845509846
- 2.572611468633016
- 2.975479078292847
- 2.657176218032837
- 3.0074052747090656
- 2.8977268505096436
- 2.6993352794647216
- 2.9350361506144207
- 2.4142201296488444
- 2.462435566584269
- 2.5709528064727785
- 2.6252355639139813
- 2.5992388502756754
- 2.4855733172098797
- 2.5002081203460693
- 2.704746446609497
- 2.4438402048746743
- 3.0916250546773276
- 2.4696717103322348
- 3.4572901248931887
- 2.2652702871958414
- 2.5094584147135417
- 2.460533997217814
- 2.4130508518218994
- 3.22479767481486
- 2.652245972951253
- 2.4328965187072753
- 2.555079256693522
- 2.427753318150838
- 3.230902010599772
- 2.60190092086792
- 2.323969513575236
- 3.1525807094573977
- 2.5019870090484617
- 2.2549366601308187
- 2.6278068987528482
- 2.4791651503245036
- 2.359337798754374
- 2.443301954269409
- 2.5970507621765138
- 2.770829331080119
- 2.6974654229482016
- 2.716177151997884
- 2.7889169438680015
- 2.1748837741216023
- 2.6299315865834556
- 2.304868286450704
- 2.3753833834330242
- 2.7434255186716716
- 2.774947827657064
- 2.4231575393676756
- 2.6347327709197996
- 2.451289313634237
- 2.2380893802642823
- 2.6863361676534017
- 2.273206969896952
- 2.1587223784128824
- 2.636992400487264
- 2.459530544281006
- 2.4712098757425944
- 2.6714902114868164
- 2.266352710723877
- 2.557530396779378
- 2.3453642241160075
- 2.4717835855484007
- 2.2854820696512856
- 2.4857144673665363
- 3.021371873219808
- 2.470293925603231
- 2.3859940846761067
- 2.6646236673990886
- 2.5751539929707845
- 2.2422767957051595
- 2.288541522026062
- 2.5446507263183595
- 2.2852524089813233
- 2.311574551264445
- 2.493062254587809
- 2.39848260084788
- 2.397856136957804
- 2.6251814365386963
- 2.3322740443547567
- 2.2360698620478314
- 2.4817805099487305
- 2.1701692056655886
train_accuracy:
- 0.037
- 0.275
- 0.0
- 0.002
- 0.025
- 0.002
- 0.006
- 0.0
- 0.623
- 0.008
- 0.625
- 0.744
- 0.008
- 0.033
- 0.01
- 0.048
- 0.638
- 0.769
- 0.029
- 0.737
- 0.756
- 0.767
- 0.0
- 0.725
- 0.083
- 0.052
- 0.004
- 0.054
- 0.069
- 0.804
- 0.744
- 0.044
- 0.058
- 0.744
- 0.004
- 0.752
- 0.817
- 0.769
- 0.004
- 0.819
- 0.065
- 0.829
- 0.806
- 0.052
- 0.825
- 0.037
- 0.025
- 0.823
- 0.781
- 0.785
- 0.108
- 0.823
- 0.046
- 0.821
- 0.794
- 0.767
- 0.873
- 0.815
- 0.84
- 0.119
- 0.796
- 0.829
- 0.098
- 0.844
- 0.006
- 0.873
- 0.854
- 0.012
- 0.079
- 0.067
- 0.071
- 0.008
- 0.89
- 0.846
- 0.879
- 0.852
- 0.085
- 0.833
- 0.152
- 0.004
- 0.838
- 0.102
- 0.842
- 0.094
- 0.108
- 0.898
- 0.125
- 0.042
- 0.073
- 0.852
- 0.077
- 0.135
- 0.838
- 0.069
- 0.825
- 0.833
- 0.056
- 0.875
- 0.863
- 0.021
train_loss:
- 2.514
- 2.148
- 1.576
- 1.432
- 1.438
- 1.072
- 1.26
- 1.089
- 1.079
- 1.137
- 0.984
- 1.078
- 0.922
- 1.024
- 0.9
- 0.865
- 0.744
- 0.953
- 0.832
- 0.911
- 0.893
- 0.873
- 0.878
- 0.677
- 0.738
- 0.744
- 0.817
- 0.817
- 0.722
- 0.715
- 0.793
- 0.71
- 0.85
- 0.672
- 0.849
- 0.677
- 0.679
- 0.65
- 0.654
- 0.805
- 0.737
- 0.644
- 0.699
- 0.62
- 0.77
- 0.691
- 0.609
- 0.754
- 0.671
- 0.531
- 0.665
- 0.653
- 0.587
- 0.581
- 0.637
- 0.646
- 0.663
- 0.647
- 0.636
- 0.508
- 0.638
- 0.567
- 0.552
- 0.627
- 0.692
- 0.606
- 0.611
- 0.604
- 0.521
- 0.604
- 0.539
- 0.455
- 0.597
- 0.596
- 0.583
- 0.594
- 0.515
- 0.577
- 0.512
- 0.575
- 0.508
- 0.583
- 0.626
- 0.584
- 0.497
- 0.557
- 0.561
- 0.496
- 0.49
- 0.548
- 0.559
- 0.487
- 0.542
- 0.548
- 0.549
- 0.532
- 0.545
- 0.481
- 0.522
- 0.458
unequal: 0
verbose: 1
