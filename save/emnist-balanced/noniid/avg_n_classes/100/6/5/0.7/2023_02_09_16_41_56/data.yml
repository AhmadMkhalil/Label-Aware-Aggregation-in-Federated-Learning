avg_train_accuracy: 0.848
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04845744680851064
- 0.08388297872340425
- 0.17340425531914894
- 0.20558510638297872
- 0.25351063829787235
- 0.27430851063829786
- 0.2544148936170213
- 0.30095744680851066
- 0.3097340425531915
- 0.2817021276595745
- 0.29781914893617023
- 0.3275531914893617
- 0.3275531914893617
- 0.34143617021276595
- 0.31824468085106383
- 0.3840425531914894
- 0.3076063829787234
- 0.3774468085106383
- 0.3793617021276596
- 0.3468617021276596
- 0.384468085106383
- 0.38632978723404254
- 0.36484042553191487
- 0.42340425531914894
- 0.3852659574468085
- 0.44090425531914895
- 0.3772340425531915
- 0.3930851063829787
- 0.3594148936170213
- 0.4747340425531915
- 0.40882978723404256
- 0.38632978723404254
- 0.4913297872340426
- 0.4060106382978723
- 0.43882978723404253
- 0.46611702127659577
- 0.4187234042553192
- 0.5133510638297872
- 0.42877659574468086
- 0.44659574468085106
- 0.5226063829787234
- 0.47547872340425534
- 0.4465425531914894
- 0.441063829787234
- 0.49611702127659574
- 0.5034574468085107
- 0.5419148936170213
- 0.46441489361702126
- 0.47138297872340423
- 0.5103723404255319
- 0.4782446808510638
- 0.47654255319148936
- 0.4597872340425532
- 0.47138297872340423
- 0.5289893617021276
- 0.5199468085106383
- 0.5290957446808511
- 0.4702127659574468
- 0.4852659574468085
- 0.5345212765957447
- 0.5313829787234042
- 0.5295744680851063
- 0.5703723404255319
- 0.4781382978723404
- 0.4873936170212766
- 0.48329787234042554
- 0.5320212765957447
- 0.5712765957446808
- 0.5496808510638298
- 0.5073936170212766
- 0.5379787234042553
- 0.5801595744680851
- 0.5528723404255319
- 0.5481382978723405
- 0.5509042553191489
- 0.49861702127659574
- 0.5128191489361702
- 0.4996808510638298
- 0.5026063829787234
- 0.4981914893617021
- 0.43361702127659574
- 0.5073936170212766
- 0.5337234042553192
- 0.5500531914893617
- 0.5032446808510638
- 0.5598404255319149
- 0.5034574468085107
- 0.5690425531914893
- 0.5548404255319149
- 0.44585106382978723
- 0.5672340425531915
- 0.6039893617021277
- 0.5556382978723404
- 0.6006382978723405
- 0.5287765957446808
- 0.5685106382978723
- 0.6115425531914893
- 0.5207446808510638
- 0.5795744680851064
- 0.5336170212765957
test_loss_list:
- 3.9522240861256916
- 3.8547158177693683
- 3.7703131675720214
- 3.7055351161956787
- 3.263903586069743
- 3.0516010761260985
- 3.3384004338582356
- 3.0126003360748292
- 3.0416567770640057
- 3.097885592778524
- 3.0529474957784015
- 2.838315254847209
- 2.833689438501994
- 3.0697013823191326
- 2.960969918568929
- 2.6823211892445884
- 3.5905209445953368
- 2.854618142445882
- 2.690784823099772
- 2.9838953971862794
- 2.8723303286234536
- 2.6034251276652016
- 2.879245023727417
- 2.553727382024129
- 2.8594960753122964
- 2.516158234278361
- 2.9028982734680175
- 2.7540438270568846
- 3.3443086369832358
- 2.374447224934896
- 2.8297655550638834
- 3.3321194966634113
- 2.247606822649638
- 2.90778902053833
- 2.7456946245829266
- 2.3462803236643475
- 2.8280950164794922
- 2.217312383651733
- 2.8641287740071615
- 2.517264340718587
- 2.2207566483815513
- 2.467728207906087
- 2.620763619740804
- 2.7059887981414796
- 2.3378243494033812
- 2.3962444639205933
- 2.202889013290405
- 2.6449196974436444
- 2.4676374626159667
- 2.3769747098286946
- 2.6111531607309977
- 2.56638703028361
- 2.60877410252889
- 2.535705842971802
- 2.3061296558380127
- 2.374907643000285
- 2.334326300621033
- 2.535216490427653
- 2.5152394421895345
- 2.289340991973877
- 2.3590331093470254
- 2.3315762344996136
- 2.1854021819432576
- 2.567441733678182
- 2.6285172589619954
- 2.4697437381744383
- 2.3444150908788046
- 2.1775428835550943
- 2.320892392794291
- 2.565697736740112
- 2.3158761787414552
- 2.1885287523269654
- 2.3035175037384032
- 2.266126348177592
- 2.3136475833257037
- 2.581540454228719
- 2.549114112854004
- 2.486625148455302
- 2.516792098681132
- 2.6399387327829995
- 3.2084545358022054
- 2.623667532602946
- 2.34957866191864
- 2.318205343882243
- 2.517855246861776
- 2.336120505332947
- 2.5418261273701988
- 2.2215525499979654
- 2.346376503308614
- 3.023645855585734
- 2.2722990783055623
- 2.1660675875345867
- 2.3466913302739463
- 2.1788423252105713
- 2.5796403551101683
- 2.2833068625132245
- 2.1624517552057902
- 2.542177349726359
- 2.2906917015711468
- 2.442667277654012
train_accuracy:
- 0.0
- 0.0
- 0.415
- 0.51
- 0.006
- 0.04
- 0.0
- 0.006
- 0.696
- 0.638
- 0.012
- 0.66
- 0.025
- 0.004
- 0.729
- 0.01
- 0.0
- 0.05
- 0.727
- 0.006
- 0.717
- 0.017
- 0.775
- 0.715
- 0.037
- 0.698
- 0.021
- 0.779
- 0.812
- 0.75
- 0.794
- 0.81
- 0.75
- 0.021
- 0.802
- 0.785
- 0.802
- 0.054
- 0.779
- 0.783
- 0.035
- 0.008
- 0.015
- 0.06
- 0.783
- 0.085
- 0.056
- 0.819
- 0.79
- 0.023
- 0.069
- 0.831
- 0.819
- 0.785
- 0.065
- 0.004
- 0.794
- 0.817
- 0.781
- 0.083
- 0.058
- 0.825
- 0.773
- 0.808
- 0.054
- 0.819
- 0.756
- 0.081
- 0.815
- 0.119
- 0.796
- 0.04
- 0.06
- 0.81
- 0.069
- 0.835
- 0.823
- 0.129
- 0.819
- 0.817
- 0.85
- 0.115
- 0.806
- 0.069
- 0.09
- 0.079
- 0.825
- 0.131
- 0.042
- 0.846
- 0.802
- 0.054
- 0.008
- 0.137
- 0.848
- 0.779
- 0.767
- 0.835
- 0.804
- 0.848
train_loss:
- 2.581
- 1.873
- 1.676
- 1.498
- 1.247
- 0.998
- 1.217
- 1.046
- 0.973
- 1.061
- 1.025
- 0.88
- 0.868
- 0.951
- 0.946
- 0.822
- 0.979
- 0.89
- 0.764
- 0.82
- 0.82
- 0.729
- 0.831
- 0.708
- 0.793
- 0.689
- 0.741
- 0.781
- 0.829
- 0.672
- 0.734
- 0.802
- 0.575
- 0.71
- 0.702
- 0.624
- 0.685
- 0.539
- 0.678
- 0.672
- 0.521
- 0.582
- 0.656
- 0.649
- 0.56
- 0.58
- 0.491
- 0.65
- 0.628
- 0.565
- 0.628
- 0.627
- 0.623
- 0.603
- 0.553
- 0.536
- 0.54
- 0.597
- 0.591
- 0.536
- 0.52
- 0.528
- 0.449
- 0.575
- 0.579
- 0.577
- 0.508
- 0.446
- 0.511
- 0.575
- 0.504
- 0.432
- 0.498
- 0.489
- 0.503
- 0.563
- 0.566
- 0.548
- 0.554
- 0.546
- 0.598
- 0.539
- 0.481
- 0.464
- 0.54
- 0.477
- 0.545
- 0.466
- 0.468
- 0.585
- 0.487
- 0.406
- 0.471
- 0.403
- 0.532
- 0.466
- 0.397
- 0.508
- 0.462
- 0.528
unequal: 0
verbose: 1
