avg_train_accuracy: 0.073
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05595744680851064
- 0.1474468085106383
- 0.2022340425531915
- 0.21946808510638297
- 0.2277127659574468
- 0.2397340425531915
- 0.24712765957446808
- 0.2495744680851064
- 0.2618617021276596
- 0.28452127659574467
- 0.2657978723404255
- 0.1398936170212766
- 0.28111702127659577
- 0.27430851063829786
- 0.29143617021276597
- 0.3053723404255319
- 0.28925531914893615
- 0.1746808510638298
- 0.3071276595744681
- 0.30388297872340425
- 0.2944148936170213
- 0.2904255319148936
- 0.3252127659574468
- 0.31122340425531914
- 0.31957446808510637
- 0.24659574468085108
- 0.3292553191489362
- 0.3025531914893617
- 0.3090425531914894
- 0.3049468085106383
- 0.32968085106382977
- 0.31872340425531914
- 0.3069148936170213
- 0.27632978723404256
- 0.3671808510638298
- 0.38813829787234044
- 0.3171276595744681
- 0.3649468085106383
- 0.35143617021276596
- 0.2901595744680851
- 0.3282978723404255
- 0.3370744680851064
- 0.33920212765957447
- 0.3407978723404255
- 0.3825
- 0.3644148936170213
- 0.36627659574468086
- 0.39085106382978724
- 0.31398936170212766
- 0.3552659574468085
- 0.3771276595744681
- 0.3596276595744681
- 0.32776595744680853
- 0.3152659574468085
- 0.3783510638297872
- 0.38904255319148934
- 0.38643617021276594
- 0.3493085106382979
- 0.3573404255319149
- 0.35138297872340424
- 0.384468085106383
- 0.4003191489361702
- 0.39824468085106385
- 0.3561170212765957
- 0.36398936170212765
- 0.39617021276595743
- 0.39148936170212767
- 0.3293617021276596
- 0.4026595744680851
- 0.35877659574468085
- 0.36159574468085104
- 0.36856382978723407
- 0.3628723404255319
- 0.43106382978723407
- 0.34638297872340423
- 0.4194148936170213
- 0.3558510638297872
- 0.42569148936170215
- 0.36617021276595746
- 0.41372340425531917
- 0.37
- 0.4426063829787234
- 0.4404787234042553
- 0.3207978723404255
- 0.3518085106382979
- 0.3683510638297872
- 0.3627127659574468
- 0.37367021276595747
- 0.4194148936170213
- 0.35851063829787233
- 0.4262234042553191
- 0.42436170212765956
- 0.37382978723404253
- 0.4571276595744681
- 0.44553191489361704
- 0.414468085106383
- 0.3625531914893617
- 0.3698936170212766
- 0.4482978723404255
- 0.37361702127659574
test_loss_list:
- 3.9441612084706623
- 5.1330094782511395
- 5.585698420206706
- 5.697720578511556
- 4.233188368479411
- 4.870383599599203
- 5.2521458435058594
- 3.9148973083496093
- 4.740555515289307
- 4.627819582621257
- 5.001667194366455
- 4.673641007741292
- 5.380683148701985
- 4.2820814482371015
- 3.6269065284729005
- 4.912491919199626
- 4.462472321192424
- 3.520408433278402
- 3.9227089881896973
- 3.8643453725179038
- 6.029006862640381
- 4.4072810077667235
- 3.9789110978444415
- 4.026608718236288
- 4.383385299046834
- 3.3772518984476725
- 3.444311812718709
- 5.877411638895671
- 4.734805291493734
- 6.169784965515137
- 3.511026366551717
- 3.7711102231343587
- 6.089590034484863
- 3.594242499669393
- 3.5835528341929117
- 3.614429823557536
- 4.2464920552571614
- 3.668051424026489
- 4.6709040228525796
- 3.6814892450968424
- 3.972787691752116
- 4.245032110214233
- 4.514810371398926
- 3.2799876244862873
- 3.619344189961751
- 3.5902459621429443
- 3.2554865169525145
- 3.6134097671508787
- 5.94728406270345
- 4.507081629435222
- 3.453979428609212
- 3.4408421007792156
- 4.339042663574219
- 6.289892876942952
- 2.958994528452555
- 3.3882680066426594
- 3.3145050112406413
- 4.338600050608317
- 4.467291005452474
- 4.029784803390503
- 3.4172562917073566
- 3.7429871209462484
- 3.2632978693644206
- 4.294049968719483
- 4.239277941385905
- 3.353220459620158
- 3.4534340286254883
- 3.5277741146087647
- 3.484575694402059
- 4.095694630940756
- 4.067205120722453
- 4.418842217127482
- 4.485805269877116
- 3.8319221909840904
- 4.089570976893107
- 3.602390200297038
- 3.945827449162801
- 3.263738997777303
- 4.405173749923706
- 3.3146231015523275
- 4.328941103617351
- 3.676411828994751
- 3.8557769139607747
- 6.454373105367025
- 3.3825120067596437
- 3.2649725405375163
- 3.84418381690979
- 3.836454086303711
- 3.4803286870320638
- 4.622260487874349
- 3.7265286445617676
- 3.3794322363535563
- 4.2259524631500245
- 3.4826994196573895
- 3.7488955942789715
- 3.3153547064463296
- 3.4755515480041503
- 4.4521782525380456
- 3.2231107171376547
- 4.225766703287761
train_accuracy:
- 0.0
- 0.396
- 0.0
- 0.0
- 0.0
- 0.0
- 0.688
- 0.627
- 0.75
- 0.735
- 0.004
- 0.015
- 0.775
- 0.008
- 0.0
- 0.765
- 0.744
- 0.033
- 0.0
- 0.035
- 0.831
- 0.01
- 0.029
- 0.798
- 0.006
- 0.11
- 0.052
- 0.846
- 0.833
- 0.858
- 0.035
- 0.008
- 0.865
- 0.065
- 0.015
- 0.048
- 0.831
- 0.012
- 0.021
- 0.129
- 0.848
- 0.85
- 0.021
- 0.858
- 0.042
- 0.856
- 0.017
- 0.015
- 0.875
- 0.865
- 0.037
- 0.85
- 0.852
- 0.873
- 0.096
- 0.069
- 0.035
- 0.877
- 0.029
- 0.873
- 0.025
- 0.075
- 0.015
- 0.852
- 0.077
- 0.085
- 0.86
- 0.071
- 0.865
- 0.875
- 0.879
- 0.073
- 0.873
- 0.035
- 0.867
- 0.033
- 0.89
- 0.083
- 0.869
- 0.867
- 0.892
- 0.877
- 0.865
- 0.894
- 0.085
- 0.119
- 0.904
- 0.858
- 0.856
- 0.042
- 0.081
- 0.89
- 0.071
- 0.012
- 0.077
- 0.883
- 0.031
- 0.896
- 0.029
- 0.073
train_loss:
- 3.11
- 2.473
- 1.84
- 1.551
- 1.28
- 1.526
- 1.291
- 1.33
- 1.289
- 1.193
- 1.147
- 1.012
- 1.481
- 1.246
- 1.034
- 1.08
- 1.066
- 1.026
- 1.08
- 0.972
- 1.133
- 1.013
- 0.898
- 0.934
- 0.881
- 0.865
- 0.798
- 1.043
- 0.946
- 0.981
- 0.826
- 0.732
- 0.962
- 0.706
- 0.792
- 0.657
- 0.849
- 0.652
- 0.76
- 0.575
- 0.96
- 0.787
- 0.754
- 0.716
- 0.622
- 0.628
- 0.72
- 0.672
- 0.844
- 0.727
- 0.698
- 0.617
- 0.713
- 0.814
- 0.662
- 0.674
- 0.617
- 0.688
- 0.731
- 0.701
- 0.625
- 0.596
- 0.595
- 0.667
- 0.662
- 0.562
- 0.637
- 0.477
- 0.548
- 0.693
- 0.665
- 0.624
- 0.627
- 0.518
- 0.679
- 0.604
- 0.655
- 0.55
- 0.635
- 0.525
- 0.638
- 0.495
- 0.471
- 0.718
- 0.572
- 0.426
- 0.676
- 0.637
- 0.563
- 0.639
- 0.537
- 0.531
- 0.593
- 0.541
- 0.501
- 0.496
- 0.433
- 0.666
- 0.527
- 0.585
unequal: 0
verbose: 1
