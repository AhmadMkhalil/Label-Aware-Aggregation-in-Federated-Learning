avg_train_accuracy: 0.883
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0598404255319149
- 0.1696276595744681
- 0.1952127659574468
- 0.19180851063829787
- 0.23143617021276597
- 0.1474468085106383
- 0.24265957446808512
- 0.2545212765957447
- 0.25372340425531914
- 0.2767553191489362
- 0.278031914893617
- 0.26601063829787236
- 0.2928191489361702
- 0.27547872340425533
- 0.3051063829787234
- 0.294468085106383
- 0.2853191489361702
- 0.295531914893617
- 0.30909574468085105
- 0.33861702127659576
- 0.30058510638297875
- 0.3373404255319149
- 0.2951595744680851
- 0.32904255319148934
- 0.3122872340425532
- 0.3337765957446808
- 0.32132978723404254
- 0.30484042553191487
- 0.3204787234042553
- 0.32632978723404255
- 0.3395744680851064
- 0.34085106382978725
- 0.31898936170212766
- 0.33872340425531916
- 0.3166489361702128
- 0.34452127659574466
- 0.3184574468085106
- 0.38111702127659575
- 0.3402659574468085
- 0.3448936170212766
- 0.3650531914893617
- 0.32132978723404254
- 0.2574468085106383
- 0.2867021276595745
- 0.27904255319148935
- 0.27691489361702126
- 0.38351063829787235
- 0.40680851063829787
- 0.34872340425531917
- 0.40404255319148935
- 0.398031914893617
- 0.42154255319148937
- 0.34287234042553194
- 0.3642021276595745
- 0.34367021276595744
- 0.41335106382978726
- 0.3671276595744681
- 0.38127659574468087
- 0.39420212765957446
- 0.3381914893617021
- 0.4232446808510638
- 0.3006382978723404
- 0.3707446808510638
- 0.42627659574468085
- 0.42154255319148937
- 0.4503191489361702
- 0.35829787234042554
- 0.43281914893617024
- 0.4128723404255319
- 0.35867021276595745
- 0.3623936170212766
- 0.4026063829787234
- 0.41925531914893616
- 0.4035106382978723
- 0.4046276595744681
- 0.3198936170212766
- 0.35829787234042554
- 0.37303191489361703
- 0.3652659574468085
- 0.4301063829787234
- 0.40808510638297874
- 0.3459042553191489
- 0.36079787234042554
- 0.35345744680851066
- 0.4248936170212766
- 0.39132978723404255
- 0.4109042553191489
- 0.4326063829787234
- 0.3567021276595745
- 0.35117021276595745
- 0.35601063829787233
- 0.4095744680851064
- 0.37031914893617024
- 0.4319148936170213
- 0.4574468085106383
- 0.32351063829787235
- 0.4269148936170213
- 0.35202127659574467
- 0.4352127659574468
- 0.36223404255319147
test_loss_list:
- 3.9146884568532307
- 4.522383778889974
- 4.402259387969971
- 3.778481829961141
- 4.363307072321574
- 4.167313219706218
- 4.130587848027547
- 4.1929903380076095
- 3.5653753662109375
- 3.481120236714681
- 4.418822523752849
- 3.6208768622080485
- 3.3692052459716795
- 3.5973766644795737
- 3.275620215733846
- 3.3951801300048827
- 4.364278411865234
- 6.830536924997966
- 4.364737555185954
- 3.4447248204549155
- 6.619460461934407
- 3.428293514251709
- 4.312488590876262
- 4.6854148228963215
- 4.244561112721761
- 4.737931067148844
- 3.198619451522827
- 4.237807521820068
- 3.130546525319417
- 3.0671565024058025
- 4.182701409657796
- 2.8480954424540204
- 3.967232405344645
- 4.142779690424601
- 3.8730386861165367
- 4.210364828109741
- 4.123966290156047
- 3.350943682988485
- 4.412004906336467
- 2.936438849767049
- 3.1802740319569907
- 4.126801993052164
- 3.4742024898529054
- 3.515092674891154
- 3.995430212020874
- 4.257599722544352
- 2.8869731362660724
- 2.940423059463501
- 3.3464185587565103
- 2.713471762339274
- 2.663130734761556
- 3.0514779186248777
- 3.6159555943806967
- 3.8878327496846516
- 3.7540243434906007
- 2.942041997909546
- 4.090837888717651
- 4.254813381830851
- 2.5797682984670005
- 3.4321484915415446
- 3.0082502714792887
- 3.340202932357788
- 3.6201953983306883
- 2.986924091974894
- 2.553674087524414
- 2.9120268122355144
- 3.4001227188110352
- 2.9215926837921145
- 2.5960551643371583
- 3.624156141281128
- 3.9469001706441245
- 2.6803719997406006
- 3.0200060431162514
- 2.9184331862131754
- 2.8662024275461833
- 5.6794377772013345
- 3.7755962085723875
- 4.088398640950521
- 2.9638983249664306
- 3.0218051211039225
- 2.8697247664133707
- 3.9196426995595295
- 3.707679230372111
- 3.69296355565389
- 3.0508117421468097
- 2.8597397645314535
- 2.899982191721598
- 2.949279416402181
- 3.613246971766154
- 3.492540527979533
- 3.751536693572998
- 2.7985662905375164
- 3.8693009916941326
- 2.8410351435343424
- 2.607511841456095
- 5.249236971537272
- 3.004971262613932
- 3.8184616470336916
- 3.110707934697469
- 3.709539353052775
train_accuracy:
- 0.169
- 0.448
- 0.0
- 0.0
- 0.642
- 0.085
- 0.675
- 0.008
- 0.713
- 0.021
- 0.0
- 0.0
- 0.056
- 0.0
- 0.702
- 0.01
- 0.0
- 0.821
- 0.102
- 0.062
- 0.823
- 0.0
- 0.796
- 0.827
- 0.829
- 0.073
- 0.765
- 0.835
- 0.802
- 0.125
- 0.831
- 0.802
- 0.846
- 0.867
- 0.833
- 0.062
- 0.831
- 0.094
- 0.092
- 0.835
- 0.86
- 0.858
- 0.083
- 0.104
- 0.125
- 0.137
- 0.008
- 0.098
- 0.069
- 0.017
- 0.004
- 0.852
- 0.06
- 0.115
- 0.062
- 0.004
- 0.879
- 0.873
- 0.037
- 0.852
- 0.077
- 0.065
- 0.077
- 0.008
- 0.09
- 0.081
- 0.875
- 0.058
- 0.079
- 0.048
- 0.883
- 0.863
- 0.094
- 0.854
- 0.102
- 0.879
- 0.883
- 0.081
- 0.119
- 0.852
- 0.869
- 0.873
- 0.875
- 0.046
- 0.881
- 0.0
- 0.867
- 0.098
- 0.0
- 0.05
- 0.871
- 0.873
- 0.885
- 0.092
- 0.135
- 0.902
- 0.881
- 0.0
- 0.085
- 0.883
train_loss:
- 2.431
- 2.248
- 1.808
- 1.637
- 1.498
- 1.121
- 1.644
- 1.39
- 1.17
- 1.061
- 1.126
- 1.064
- 1.147
- 1.01
- 1.037
- 0.948
- 1.041
- 1.09
- 0.952
- 0.831
- 1.054
- 0.871
- 0.985
- 0.868
- 0.895
- 0.81
- 0.865
- 0.901
- 0.786
- 0.683
- 0.851
- 0.836
- 0.852
- 0.792
- 0.811
- 0.753
- 0.755
- 0.679
- 0.708
- 0.773
- 0.674
- 0.77
- 0.683
- 0.553
- 0.476
- 0.442
- 0.69
- 0.58
- 0.463
- 0.666
- 0.658
- 0.592
- 0.672
- 0.698
- 0.659
- 0.627
- 0.642
- 0.61
- 0.628
- 0.752
- 0.548
- 0.495
- 0.696
- 0.591
- 0.541
- 0.553
- 0.627
- 0.581
- 0.578
- 0.628
- 0.607
- 0.592
- 0.538
- 0.579
- 0.524
- 0.676
- 0.647
- 0.592
- 0.523
- 0.533
- 0.532
- 0.612
- 0.602
- 0.581
- 0.529
- 0.586
- 0.526
- 0.536
- 0.603
- 0.589
- 0.613
- 0.522
- 0.574
- 0.556
- 0.48
- 0.722
- 0.558
- 0.581
- 0.536
- 0.568
unequal: 0
verbose: 1
