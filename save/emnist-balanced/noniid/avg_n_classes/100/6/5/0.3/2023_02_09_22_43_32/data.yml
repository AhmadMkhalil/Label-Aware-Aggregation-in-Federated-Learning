avg_train_accuracy: 0.002
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02526595744680851
- 0.05909574468085106
- 0.15595744680851065
- 0.1876063829787234
- 0.24345744680851064
- 0.20037234042553193
- 0.22787234042553192
- 0.22531914893617022
- 0.2322872340425532
- 0.2578191489361702
- 0.25840425531914896
- 0.2574468085106383
- 0.2825531914893617
- 0.28335106382978725
- 0.27356382978723404
- 0.26361702127659575
- 0.28356382978723405
- 0.2843085106382979
- 0.28095744680851065
- 0.2892021276595745
- 0.2983510638297872
- 0.29984042553191487
- 0.3228191489361702
- 0.20686170212765959
- 0.3196276595744681
- 0.34367021276595744
- 0.2995744680851064
- 0.30164893617021277
- 0.3022872340425532
- 0.32574468085106384
- 0.32074468085106383
- 0.33893617021276595
- 0.3069148936170213
- 0.3535106382978723
- 0.30367021276595746
- 0.31718085106382976
- 0.32898936170212767
- 0.3231914893617021
- 0.3527127659574468
- 0.33489361702127657
- 0.34643617021276596
- 0.3725531914893617
- 0.32680851063829786
- 0.3874468085106383
- 0.38585106382978723
- 0.2826063829787234
- 0.3523936170212766
- 0.33297872340425533
- 0.3172340425531915
- 0.34085106382978725
- 0.3598936170212766
- 0.32601063829787236
- 0.35122340425531917
- 0.38090425531914895
- 0.3510106382978723
- 0.39478723404255317
- 0.38409574468085106
- 0.389468085106383
- 0.3146808510638298
- 0.3496808510638298
- 0.40180851063829787
- 0.3448404255319149
- 0.3428191489361702
- 0.3727127659574468
- 0.3872872340425532
- 0.3347872340425532
- 0.3442021276595745
- 0.3537234042553192
- 0.3796276595744681
- 0.3652659574468085
- 0.3396276595744681
- 0.35436170212765955
- 0.40547872340425534
- 0.2982446808510638
- 0.3503723404255319
- 0.31696808510638297
- 0.3620212765957447
- 0.35340425531914893
- 0.3861702127659574
- 0.39547872340425533
- 0.3970744680851064
- 0.3854787234042553
- 0.3191489361702128
- 0.4010106382978723
- 0.38632978723404254
- 0.40297872340425533
- 0.3677659574468085
- 0.36117021276595745
- 0.42329787234042554
- 0.321968085106383
- 0.3907978723404255
- 0.3203723404255319
- 0.3825531914893617
- 0.35164893617021276
- 0.32053191489361704
- 0.36675531914893617
- 0.40335106382978725
- 0.376063829787234
- 0.3207978723404255
- 0.3478191489361702
test_loss_list:
- 3.9587349764506023
- 4.462621587117513
- 4.205781882603963
- 4.580507589975993
- 6.769822820027669
- 3.528901284535726
- 3.8525543467203778
- 4.108915475209554
- 3.6236549282073973
- 4.491517480214437
- 3.8577928225199383
- 3.492184591293335
- 7.253549868265788
- 3.3061719608306883
- 4.862784900665283
- 4.200375121434529
- 3.4719340006510415
- 3.4600336360931396
- 3.400221338272095
- 4.537414766947428
- 3.1217521031697593
- 3.3725893751780194
- 3.4764081764221193
- 3.7913621425628663
- 3.3301192855834962
- 3.2789489968617755
- 4.35304882367452
- 7.057566184997558
- 4.1319914786020915
- 3.352557487487793
- 4.52364624341329
- 4.274065453211467
- 6.893488394419352
- 4.088692452112833
- 3.9465694014231363
- 4.380991633733114
- 3.134674580891927
- 4.250743242899577
- 3.292026154200236
- 3.367666063308716
- 3.196631212234497
- 3.387645082473755
- 4.165618848800659
- 3.30950982093811
- 3.546725180943807
- 3.1215774059295653
- 3.977435064315796
- 3.959625981648763
- 3.8019337113698324
- 4.246411428451538
- 2.8885776233673095
- 3.1525744247436522
- 3.98456249554952
- 3.1726050694783527
- 4.434534804026286
- 3.3148450883229574
- 3.070825080871582
- 3.133568588892619
- 3.3615164693196613
- 3.979994764328003
- 3.116490618387858
- 4.172629928588867
- 3.7875763893127443
- 2.8770325215657553
- 3.0525014050801595
- 3.4873073228200275
- 4.065906918843587
- 3.4376225153605144
- 3.0800383853912354
- 2.9524633439381915
- 3.9446216106414793
- 3.4183392238616945
- 2.7775549634297687
- 3.452058951059977
- 3.6820945294698078
- 5.835976161956787
- 3.844135669072469
- 4.120747464497884
- 2.963494866689046
- 3.4205686823527017
- 2.7386254278818765
- 3.1214329465230306
- 5.9712530008951825
- 2.722165444691976
- 3.357331822713216
- 2.8109285322825115
- 3.01090384165446
- 3.4138811683654784
- 2.9555946254730223
- 5.863603115081787
- 2.923218183517456
- 5.77673729578654
- 2.9369276014963788
- 3.8899039204915367
- 5.919149290720622
- 3.15372376759847
- 2.7926920223236085
- 2.9822638352711994
- 5.209381891886394
- 3.8201801681518557
train_accuracy:
- 0.0
- 0.163
- 0.0
- 0.556
- 0.662
- 0.012
- 0.0
- 0.008
- 0.606
- 0.733
- 0.696
- 0.019
- 0.752
- 0.633
- 0.796
- 0.733
- 0.031
- 0.054
- 0.002
- 0.006
- 0.731
- 0.79
- 0.017
- 0.137
- 0.0
- 0.002
- 0.84
- 0.838
- 0.802
- 0.81
- 0.829
- 0.86
- 0.84
- 0.85
- 0.004
- 0.829
- 0.846
- 0.875
- 0.015
- 0.002
- 0.85
- 0.062
- 0.015
- 0.062
- 0.042
- 0.11
- 0.865
- 0.006
- 0.002
- 0.025
- 0.052
- 0.123
- 0.885
- 0.071
- 0.058
- 0.004
- 0.008
- 0.002
- 0.14
- 0.865
- 0.042
- 0.833
- 0.881
- 0.833
- 0.048
- 0.842
- 0.019
- 0.019
- 0.0
- 0.142
- 0.84
- 0.844
- 0.088
- 0.156
- 0.019
- 0.906
- 0.835
- 0.025
- 0.06
- 0.04
- 0.85
- 0.883
- 0.896
- 0.04
- 0.883
- 0.035
- 0.108
- 0.879
- 0.048
- 0.9
- 0.025
- 0.883
- 0.883
- 0.012
- 0.887
- 0.133
- 0.871
- 0.856
- 0.883
- 0.002
train_loss:
- 2.553
- 1.93
- 1.687
- 1.741
- 1.862
- 1.372
- 1.127
- 1.459
- 1.1
- 1.276
- 1.286
- 1.146
- 1.336
- 1.029
- 1.106
- 1.101
- 1.029
- 0.914
- 0.889
- 0.981
- 0.956
- 0.828
- 0.895
- 0.668
- 0.762
- 0.725
- 0.875
- 1.025
- 0.917
- 0.774
- 0.86
- 0.832
- 0.935
- 0.841
- 0.899
- 0.876
- 0.743
- 0.828
- 0.718
- 0.619
- 0.648
- 0.693
- 0.758
- 0.633
- 0.611
- 0.578
- 0.786
- 0.789
- 0.733
- 0.702
- 0.718
- 0.484
- 0.742
- 0.613
- 0.693
- 0.564
- 0.653
- 0.57
- 0.46
- 0.71
- 0.638
- 0.684
- 0.664
- 0.685
- 0.57
- 0.717
- 0.674
- 0.687
- 0.552
- 0.457
- 0.664
- 0.675
- 0.548
- 0.415
- 0.69
- 0.756
- 0.652
- 0.637
- 0.569
- 0.511
- 0.573
- 0.585
- 0.71
- 0.641
- 0.541
- 0.581
- 0.462
- 0.698
- 0.536
- 0.709
- 0.593
- 0.696
- 0.555
- 0.621
- 0.663
- 0.531
- 0.6
- 0.522
- 0.715
- 0.593
unequal: 0
verbose: 1
