avg_train_accuracy: 0.154
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.09191489361702128
- 0.08398936170212766
- 0.08824468085106384
- 0.09808510638297872
- 0.10579787234042554
- 0.09648936170212766
- 0.09345744680851063
- 0.07893617021276596
- 0.10904255319148937
- 0.08728723404255319
- 0.09835106382978723
- 0.10074468085106383
- 0.09388297872340426
- 0.09914893617021277
- 0.09297872340425532
- 0.09313829787234043
- 0.09079787234042554
- 0.09436170212765957
- 0.1025
- 0.10079787234042553
- 0.10308510638297873
- 0.09909574468085107
- 0.09308510638297872
- 0.09813829787234042
- 0.10893617021276596
- 0.11037234042553191
- 0.1052127659574468
- 0.11223404255319148
- 0.10074468085106383
- 0.09170212765957447
- 0.10462765957446808
- 0.11808510638297873
- 0.10436170212765958
- 0.09962765957446809
- 0.10835106382978724
- 0.10813829787234043
- 0.11808510638297873
- 0.12920212765957448
- 0.13170212765957448
- 0.11803191489361702
- 0.12186170212765958
- 0.11127659574468085
- 0.10430851063829787
- 0.09867021276595744
- 0.12340425531914893
- 0.13893617021276597
- 0.10632978723404256
- 0.1247872340425532
- 0.11718085106382979
- 0.14829787234042552
- 0.16707446808510637
- 0.14303191489361702
- 0.15973404255319149
- 0.13420212765957445
- 0.13797872340425532
- 0.1452659574468085
- 0.18728723404255318
- 0.18611702127659574
- 0.14882978723404255
- 0.17872340425531916
- 0.19388297872340426
- 0.1848936170212766
- 0.1920744680851064
- 0.17946808510638299
- 0.12351063829787234
- 0.1074468085106383
- 0.11686170212765958
- 0.105
- 0.10228723404255319
- 0.10191489361702127
- 0.13893617021276597
- 0.12367021276595745
- 0.11265957446808511
- 0.13446808510638297
- 0.14765957446808511
- 0.13297872340425532
- 0.18675531914893617
- 0.16537234042553192
- 0.18829787234042553
- 0.18319148936170213
- 0.16888297872340424
- 0.19531914893617022
- 0.1950531914893617
- 0.1523936170212766
- 0.1428723404255319
- 0.22063829787234043
- 0.1898936170212766
- 0.19893617021276597
- 0.17303191489361702
- 0.15271276595744682
- 0.18478723404255318
- 0.1351063829787234
- 0.14845744680851064
- 0.22031914893617022
- 0.18563829787234043
- 0.2128191489361702
- 0.14877659574468086
- 0.2047872340425532
- 0.19861702127659575
- 0.20138297872340424
test_loss_list:
- 11.784630991617838
- 13.228044522603353
- 12.561399523417155
- 11.798938369750976
- 14.195420583089193
- 10.726814753214517
- 11.009886830647787
- 11.878918889363607
- 8.59914841969808
- 11.406575253804524
- 9.81652411142985
- 13.793530337015788
- 10.972817904154459
- 9.219595781962077
- 10.114235293070475
- 11.662154184977213
- 9.349225273132324
- 8.335475959777831
- 9.26814754486084
- 11.72791306813558
- 8.372946236928303
- 9.327363713582356
- 13.06776217142741
- 15.26651575724284
- 7.387784105936686
- 7.126179517110189
- 9.052151540120443
- 9.174313062032065
- 9.704765803019205
- 9.306865717569988
- 7.9579366683959964
- 6.91829740524292
- 8.984797426859538
- 9.548053499857584
- 7.712715333302816
- 7.690133304595947
- 8.448241653442382
- 7.274348735809326
- 6.672729701995849
- 6.973651638031006
- 8.123037096659342
- 7.526565004984538
- 7.27906504313151
- 9.249897219340006
- 7.259739462534586
- 6.756706816355387
- 8.409928652445474
- 7.007997760772705
- 8.595504315694173
- 6.542093410491943
- 7.597464008331299
- 7.8921812121073405
- 7.019678796132405
- 6.974244550069173
- 7.11052962621053
- 6.661532096862793
- 6.412346776326498
- 6.266333967844645
- 6.356184495290121
- 6.022772909800212
- 6.631502704620361
- 6.275307184855143
- 7.109472217559815
- 7.758482557932536
- 7.767119770050049
- 7.320724118550618
- 6.837708485921224
- 8.327803300221762
- 8.849901262919108
- 9.650804901123047
- 6.414291547139485
- 7.775250301361084
- 8.496495253245035
- 8.239124984741212
- 6.208666261037191
- 7.749378019968669
- 6.389735215504964
- 6.273352184295654
- 5.638600705464681
- 6.01484141031901
- 6.75712158203125
- 6.058941650390625
- 5.790444081624349
- 6.680036958058675
- 8.200790246327719
- 6.25920872370402
- 6.258597253163655
- 5.680983047485352
- 6.801045640309652
- 8.17870564142863
- 6.035412724812826
- 6.9967023340861
- 6.4575627899169925
- 6.0287015342712404
- 6.017884089152019
- 5.6993439356486
- 6.303520056406657
- 5.474700711568197
- 6.001420809427898
- 5.323759981791178
train_accuracy:
- 0.244
- 0.798
- 0.142
- 0.429
- 0.562
- 0.133
- 0.148
- 0.069
- 0.631
- 0.842
- 0.154
- 0.163
- 0.852
- 0.125
- 0.867
- 0.881
- 0.119
- 0.879
- 0.148
- 0.154
- 0.908
- 0.908
- 0.144
- 0.144
- 0.615
- 0.167
- 0.167
- 0.131
- 0.148
- 0.146
- 0.142
- 0.704
- 0.158
- 0.135
- 0.152
- 0.158
- 0.154
- 0.737
- 0.163
- 0.156
- 0.156
- 0.152
- 0.902
- 0.923
- 0.167
- 0.152
- 0.154
- 0.14
- 0.146
- 0.165
- 0.152
- 0.921
- 0.167
- 0.158
- 0.927
- 0.152
- 0.152
- 0.167
- 0.708
- 0.167
- 0.154
- 0.167
- 0.154
- 0.154
- 0.154
- 0.148
- 0.933
- 0.938
- 0.946
- 0.94
- 0.154
- 0.154
- 0.156
- 0.158
- 0.156
- 0.156
- 0.154
- 0.156
- 0.167
- 0.154
- 0.948
- 0.167
- 0.154
- 0.742
- 0.821
- 0.154
- 0.938
- 0.156
- 0.812
- 0.863
- 0.95
- 0.156
- 0.963
- 0.154
- 0.963
- 0.167
- 0.154
- 0.167
- 0.942
- 0.154
train_loss:
- 1.975
- 1.933
- 2.117
- 1.28
- 0.564
- 2.112
- 2.415
- 2.178
- 1.227
- 1.449
- 2.396
- 0.719
- 1.17
- 1.708
- 1.065
- 0.668
- 2.453
- 0.972
- 1.644
- 0.667
- 0.873
- 0.548
- 1.919
- 0.822
- 1.555
- 1.179
- 0.47
- 1.483
- 1.202
- 2.34
- 1.115
- 1.156
- 1.333
- 1.636
- 1.439
- 1.102
- 1.098
- 0.884
- 0.937
- 0.988
- 0.918
- 0.964
- 1.388
- 0.596
- 0.733
- 0.804
- 1.243
- 1.214
- 0.466
- 0.649
- 0.555
- 1.038
- 0.484
- 1.184
- 0.842
- 0.828
- 0.782
- 0.539
- 1.219
- 0.446
- 0.627
- 0.357
- 0.445
- 0.305
- 1.303
- 1.177
- 1.084
- 0.484
- 0.429
- 0.387
- 0.911
- 0.357
- 0.813
- 0.915
- 0.587
- 0.617
- 0.801
- 0.544
- 0.73
- 0.429
- 0.833
- 0.447
- 0.46
- 1.188
- 0.385
- 0.811
- 0.79
- 0.486
- 0.657
- 0.318
- 0.757
- 0.901
- 0.609
- 0.728
- 0.532
- 0.64
- 1.181
- 0.432
- 0.595
- 0.63
unequal: 0
verbose: 1
