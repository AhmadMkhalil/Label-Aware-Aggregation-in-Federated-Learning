avg_train_accuracy: 0.165
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.07893617021276596
- 0.08090425531914894
- 0.07101063829787234
- 0.07718085106382978
- 0.08941489361702128
- 0.08430851063829788
- 0.08553191489361703
- 0.08531914893617021
- 0.0925
- 0.0678191489361702
- 0.0828191489361702
- 0.08664893617021277
- 0.08324468085106383
- 0.09393617021276596
- 0.07888297872340426
- 0.09031914893617021
- 0.08569148936170212
- 0.0947872340425532
- 0.09058510638297872
- 0.09648936170212766
- 0.09521276595744681
- 0.09744680851063829
- 0.09569148936170213
- 0.0972872340425532
- 0.09792553191489362
- 0.10984042553191489
- 0.10031914893617021
- 0.09106382978723404
- 0.09797872340425531
- 0.09473404255319148
- 0.10122340425531914
- 0.09941489361702127
- 0.09877659574468085
- 0.10404255319148936
- 0.09835106382978723
- 0.10553191489361702
- 0.10920212765957447
- 0.11335106382978724
- 0.10888297872340426
- 0.10324468085106384
- 0.11941489361702128
- 0.13845744680851063
- 0.11446808510638298
- 0.12063829787234043
- 0.12462765957446809
- 0.10840425531914893
- 0.12601063829787235
- 0.11409574468085107
- 0.12824468085106383
- 0.13414893617021276
- 0.14675531914893616
- 0.11095744680851063
- 0.1301063829787234
- 0.13175531914893618
- 0.13845744680851063
- 0.13537234042553192
- 0.1149468085106383
- 0.10590425531914893
- 0.1596808510638298
- 0.13579787234042554
- 0.10760638297872341
- 0.11377659574468085
- 0.13303191489361701
- 0.15361702127659574
- 0.12053191489361702
- 0.14436170212765959
- 0.13436170212765958
- 0.11563829787234042
- 0.1376063829787234
- 0.13234042553191488
- 0.15478723404255318
- 0.15563829787234043
- 0.11781914893617021
- 0.10851063829787234
- 0.14638297872340425
- 0.16877659574468085
- 0.13904255319148937
- 0.16281914893617022
- 0.09234042553191489
- 0.14148936170212767
- 0.12058510638297873
- 0.11
- 0.15186170212765956
- 0.17175531914893616
- 0.1497872340425532
- 0.154468085106383
- 0.14111702127659576
- 0.19101063829787235
- 0.16898936170212767
- 0.10484042553191489
- 0.13638297872340427
- 0.1302127659574468
- 0.16680851063829788
- 0.12164893617021276
- 0.14920212765957447
- 0.18728723404255318
- 0.11340425531914894
- 0.12638297872340426
- 0.18223404255319148
- 0.1504255319148936
test_loss_list:
- 13.447651112874349
- 14.220521596272787
- 13.145342343648275
- 13.202498550415038
- 12.35520523071289
- 12.039503415425619
- 12.18520736694336
- 9.515050493876139
- 11.026445808410644
- 12.970249188741048
- 14.815561230977377
- 15.76755443572998
- 12.33858762105306
- 14.289678014119467
- 12.65192320505778
- 12.399458592732747
- 10.793413683573405
- 10.2054749806722
- 9.706184374491373
- 13.429246915181478
- 9.293861033121745
- 12.011535542805989
- 8.588650805155437
- 11.182862930297851
- 8.825290082295735
- 9.995086110432943
- 8.707845293680826
- 10.062004890441894
- 12.625655517578124
- 10.964147822062175
- 8.53008010228475
- 9.686371409098307
- 10.514433911641438
- 10.866070124308267
- 9.798287315368652
- 8.549413681030273
- 9.580234921773275
- 7.484027957916259
- 7.314179204305013
- 8.498494110107423
- 8.190967025756835
- 7.645492979685465
- 8.205410302480061
- 6.984269275665283
- 7.83628942489624
- 8.471415506998698
- 8.13405704498291
- 9.44845167795817
- 7.269799728393554
- 6.810954004923502
- 7.964634742736816
- 8.35719170888265
- 7.521468938191732
- 7.00313783009847
- 7.103261184692383
- 6.504864018758138
- 7.595210577646891
- 8.067251110076905
- 7.44222370783488
- 8.838828671773275
- 8.010155811309815
- 7.740106512705485
- 7.113679307301839
- 7.247396761576335
- 8.445082619984944
- 7.37589345296224
- 8.145022010803222
- 7.923810234069824
- 7.506163272857666
- 7.591006412506103
- 6.7101045481363935
- 7.590648746490478
- 7.824413528442383
- 9.1734609858195
- 6.729218044281006
- 6.836202971140543
- 7.824187056223551
- 6.631889133453369
- 11.528754475911459
- 6.066697260538737
- 7.081296463012695
- 8.383299789428712
- 6.643962364196778
- 5.832927913665771
- 6.268901036580403
- 7.23815336227417
- 8.192655537923176
- 5.4968285051981605
- 5.985250790913899
- 8.892777137756347
- 5.753327337900798
- 6.329992612202962
- 6.673741518656413
- 7.87421994527181
- 6.388592421213786
- 6.210387757619222
- 6.257067527770996
- 7.0189639155069985
- 5.278553613026937
- 6.270343691507975
train_accuracy:
- 0.121
- 0.81
- 0.165
- 0.158
- 0.156
- 0.812
- 0.137
- 0.819
- 0.137
- 0.062
- 0.142
- 0.142
- 0.135
- 0.144
- 0.073
- 0.117
- 0.838
- 0.135
- 0.875
- 0.135
- 0.148
- 0.146
- 0.146
- 0.156
- 0.154
- 0.152
- 0.871
- 0.106
- 0.15
- 0.144
- 0.896
- 0.923
- 0.944
- 0.154
- 0.137
- 0.158
- 0.154
- 0.148
- 0.938
- 0.931
- 0.154
- 0.158
- 0.144
- 0.923
- 0.158
- 0.146
- 0.158
- 0.163
- 0.154
- 0.919
- 0.16
- 0.156
- 0.156
- 0.16
- 0.142
- 0.927
- 0.929
- 0.952
- 0.156
- 0.158
- 0.148
- 0.156
- 0.948
- 0.16
- 0.156
- 0.952
- 0.965
- 0.154
- 0.933
- 0.163
- 0.971
- 0.156
- 0.156
- 0.156
- 0.95
- 0.148
- 0.16
- 0.956
- 0.142
- 0.156
- 0.163
- 0.163
- 0.158
- 0.152
- 0.948
- 0.165
- 0.16
- 0.158
- 0.95
- 0.152
- 0.969
- 0.965
- 0.167
- 0.148
- 0.954
- 0.158
- 0.163
- 0.152
- 0.156
- 0.165
train_loss:
- 1.957
- 2.031
- 2.132
- 2.132
- 1.527
- 1.361
- 2.216
- 1.293
- 2.166
- 2.123
- 1.076
- 0.862
- 2.641
- 1.075
- 2.148
- 2.11
- 1.521
- 1.261
- 1.029
- 1.366
- 1.648
- 0.644
- 1.206
- 1.773
- 0.888
- 0.896
- 1.294
- 1.991
- 0.873
- 1.763
- 1.043
- 0.618
- 0.541
- 1.054
- 1.469
- 1.302
- 0.972
- 1.044
- 0.981
- 0.518
- 1.08
- 0.711
- 1.413
- 0.814
- 0.996
- 1.219
- 0.609
- 0.303
- 0.801
- 0.856
- 0.481
- 1.247
- 0.509
- 1.035
- 1.245
- 0.809
- 0.435
- 0.418
- 0.581
- 0.247
- 1.087
- 1.038
- 0.744
- 0.524
- 0.73
- 0.638
- 0.396
- 0.807
- 0.564
- 0.923
- 0.508
- 0.8
- 0.683
- 0.283
- 0.642
- 1.288
- 0.777
- 0.57
- 2.066
- 1.067
- 0.706
- 0.268
- 0.649
- 1.049
- 0.697
- 0.706
- 1.088
- 0.811
- 0.624
- 1.426
- 0.611
- 0.342
- 0.737
- 0.975
- 0.55
- 1.009
- 0.838
- 1.012
- 0.969
- 0.521
unequal: 0
verbose: 1
