avg_train_accuracy: 0.115
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.023882978723404256
- 0.10345744680851064
- 0.13117021276595744
- 0.13324468085106383
- 0.15664893617021278
- 0.12069148936170213
- 0.15372340425531916
- 0.1974468085106383
- 0.17356382978723403
- 0.21856382978723404
- 0.21085106382978724
- 0.23537234042553193
- 0.2226063829787234
- 0.20829787234042554
- 0.2348936170212766
- 0.25622340425531914
- 0.25718085106382976
- 0.2792021276595745
- 0.26670212765957446
- 0.28356382978723405
- 0.26335106382978724
- 0.26218085106382977
- 0.2605851063829787
- 0.27893617021276595
- 0.2495744680851064
- 0.2752659574468085
- 0.29425531914893616
- 0.246968085106383
- 0.25579787234042556
- 0.27617021276595743
- 0.2856382978723404
- 0.34808510638297874
- 0.2826595744680851
- 0.2917021276595745
- 0.3250531914893617
- 0.35781914893617023
- 0.36861702127659574
- 0.3802127659574468
- 0.36601063829787234
- 0.36675531914893617
- 0.3204255319148936
- 0.3956914893617021
- 0.31803191489361704
- 0.3773404255319149
- 0.4001595744680851
- 0.4048936170212766
- 0.39276595744680853
- 0.38851063829787236
- 0.4120744680851064
- 0.3375
- 0.3452127659574468
- 0.40547872340425534
- 0.4151595744680851
- 0.4078723404255319
- 0.3575
- 0.3553191489361702
- 0.42734042553191487
- 0.4498936170212766
- 0.35643617021276597
- 0.37292553191489364
- 0.3489893617021277
- 0.38611702127659575
- 0.35973404255319147
- 0.443563829787234
- 0.37367021276595747
- 0.43170212765957444
- 0.41558510638297874
- 0.38654255319148934
- 0.4332446808510638
- 0.4443617021276596
- 0.44122340425531914
- 0.415
- 0.38632978723404254
- 0.44872340425531915
- 0.4272340425531915
- 0.30531914893617024
- 0.4076595744680851
- 0.3556382978723404
- 0.3623936170212766
- 0.451968085106383
- 0.39101063829787236
- 0.41632978723404257
- 0.47452127659574467
- 0.46861702127659577
- 0.38632978723404254
- 0.46
- 0.3702127659574468
- 0.4951595744680851
- 0.47122340425531917
- 0.4168085106382979
- 0.3126595744680851
- 0.39856382978723404
- 0.41404255319148936
- 0.32851063829787236
- 0.42590425531914894
- 0.3809574468085106
- 0.33143617021276595
- 0.3282978723404255
- 0.3026595744680851
- 0.41585106382978726
test_loss_list:
- 4.253658809661865
- 4.6343123118082685
- 3.986357952753703
- 3.6528141180674236
- 3.8254380861918134
- 4.001704009373983
- 4.027982311248779
- 3.4528702131907143
- 4.0061582088470455
- 3.43239281018575
- 3.375049730936686
- 3.18782821337382
- 3.462818152109782
- 3.645723107655843
- 3.2749380461374917
- 3.4048889891306557
- 3.675384216308594
- 3.765658149719238
- 3.5980164114634197
- 3.1838672796885175
- 3.6153766949971518
- 3.9172581799825035
- 3.331803140640259
- 3.4466124057769774
- 3.6577767181396483
- 3.376009327570597
- 3.6605017058054607
- 3.358151839574178
- 3.500331853230794
- 3.3782554244995118
- 3.3701810010274253
- 3.086457783381144
- 3.591841007868449
- 3.5040782737731933
- 3.255080420176188
- 3.04627942721049
- 2.9050215911865234
- 3.1206480757395427
- 3.0688947518666585
- 3.0801491578420004
- 3.4309266312917073
- 3.082955592473348
- 3.861553576787313
- 3.430120735168457
- 2.993635705312093
- 2.889500093460083
- 3.0486259333292645
- 3.2623286215464273
- 2.9465672906239826
- 3.416495027542114
- 3.313633120854696
- 3.0358046595255535
- 3.0595110289255776
- 3.0215131791432697
- 3.2845253149668374
- 3.2443929227193196
- 2.8414967568715412
- 2.946196533838908
- 3.5232185618082683
- 3.459134028752645
- 3.9134963162740073
- 3.208926115036011
- 3.490903609593709
- 3.140638262430827
- 3.3668848037719727
- 3.1168406009674072
- 3.0226351833343506
- 3.3197446346282957
- 3.2575305239359538
- 3.094898109436035
- 2.8777098782857258
- 3.0723696168263754
- 3.330819705327352
- 2.8867484378814696
- 3.305081605911255
- 3.867387663523356
- 3.1013669459025066
- 3.5839702479044595
- 3.5507444826761883
- 2.898148202896118
- 3.5609222221374512
- 3.116145435969035
- 2.9340342903137206
- 2.970681355794271
- 3.536711263656616
- 2.960824499130249
- 3.5011661370595295
- 2.8617048613230387
- 2.936993678410848
- 3.4370491250356037
- 4.213501316706339
- 3.2352380847930906
- 3.417950267791748
- 4.07322782198588
- 3.213150053024292
- 3.6657141208648683
- 4.105461330413818
- 3.680214068094889
- 4.285562540690104
- 3.465659189224243
train_accuracy:
- 0.0
- 0.017
- 0.09
- 0.025
- 0.163
- 0.352
- 0.146
- 0.008
- 0.004
- 0.085
- 0.088
- 0.579
- 0.002
- 0.098
- 0.142
- 0.458
- 0.075
- 0.006
- 0.604
- 0.498
- 0.121
- 0.475
- 0.029
- 0.352
- 0.135
- 0.575
- 0.577
- 0.033
- 0.41
- 0.108
- 0.025
- 0.131
- 0.021
- 0.744
- 0.473
- 0.129
- 0.01
- 0.052
- 0.113
- 0.121
- 0.635
- 0.085
- 0.135
- 0.125
- 0.129
- 0.058
- 0.119
- 0.646
- 0.123
- 0.098
- 0.683
- 0.071
- 0.098
- 0.01
- 0.098
- 0.715
- 0.11
- 0.081
- 0.098
- 0.727
- 0.737
- 0.533
- 0.115
- 0.723
- 0.133
- 0.081
- 0.717
- 0.748
- 0.683
- 0.012
- 0.129
- 0.148
- 0.775
- 0.604
- 0.0
- 0.14
- 0.737
- 0.619
- 0.002
- 0.133
- 0.085
- 0.735
- 0.117
- 0.752
- 0.123
- 0.671
- 0.102
- 0.129
- 0.127
- 0.135
- 0.748
- 0.135
- 0.092
- 0.146
- 0.14
- 0.781
- 0.673
- 0.154
- 0.748
- 0.115
train_loss:
- 1.902
- 1.129
- 0.921
- 0.809
- 0.835
- 0.877
- 0.75
- 0.773
- 0.72
- 0.685
- 0.7
- 0.664
- 0.559
- 0.629
- 0.654
- 0.564
- 0.534
- 0.509
- 0.572
- 0.572
- 0.474
- 0.519
- 0.556
- 0.455
- 0.503
- 0.513
- 0.462
- 0.557
- 0.528
- 0.502
- 0.46
- 0.438
- 0.446
- 0.463
- 0.439
- 0.444
- 0.457
- 0.372
- 0.406
- 0.351
- 0.452
- 0.379
- 0.372
- 0.365
- 0.407
- 0.387
- 0.376
- 0.351
- 0.391
- 0.395
- 0.387
- 0.362
- 0.344
- 0.38
- 0.422
- 0.391
- 0.361
- 0.369
- 0.347
- 0.345
- 0.346
- 0.406
- 0.344
- 0.346
- 0.376
- 0.305
- 0.317
- 0.35
- 0.318
- 0.318
- 0.313
- 0.359
- 0.336
- 0.342
- 0.283
- 0.359
- 0.372
- 0.342
- 0.321
- 0.308
- 0.309
- 0.348
- 0.298
- 0.299
- 0.292
- 0.311
- 0.318
- 0.322
- 0.301
- 0.298
- 0.318
- 0.313
- 0.301
- 0.302
- 0.329
- 0.284
- 0.317
- 0.333
- 0.325
- 0.302
unequal: 0
verbose: 1
