avg_train_accuracy: 0.144
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03590425531914894
- 0.06037234042553191
- 0.09670212765957446
- 0.09744680851063829
- 0.13436170212765958
- 0.15638297872340426
- 0.16
- 0.14840425531914894
- 0.1724468085106383
- 0.1753723404255319
- 0.1701595744680851
- 0.19441489361702127
- 0.2119148936170213
- 0.22345744680851065
- 0.2048936170212766
- 0.20638297872340425
- 0.22845744680851063
- 0.2753191489361702
- 0.25643617021276593
- 0.23409574468085106
- 0.25340425531914895
- 0.2713829787234043
- 0.25648936170212766
- 0.2832978723404255
- 0.2476063829787234
- 0.2713829787234043
- 0.28319148936170213
- 0.27367021276595743
- 0.30617021276595746
- 0.3223404255319149
- 0.3347872340425532
- 0.3165425531914894
- 0.2870744680851064
- 0.3302127659574468
- 0.32180851063829785
- 0.3045744680851064
- 0.33547872340425533
- 0.30164893617021277
- 0.28877659574468084
- 0.321968085106383
- 0.22739361702127658
- 0.3595212765957447
- 0.34095744680851064
- 0.37388297872340426
- 0.32904255319148934
- 0.3697872340425532
- 0.3063297872340425
- 0.3728191489361702
- 0.36638297872340425
- 0.31627659574468087
- 0.39702127659574465
- 0.35382978723404257
- 0.3846276595744681
- 0.39861702127659576
- 0.33111702127659576
- 0.4129255319148936
- 0.4
- 0.35010638297872343
- 0.41132978723404257
- 0.41675531914893615
- 0.4097340425531915
- 0.34297872340425534
- 0.41308510638297874
- 0.39313829787234045
- 0.3670744680851064
- 0.37148936170212765
- 0.36175531914893616
- 0.42143617021276597
- 0.40547872340425534
- 0.38941489361702125
- 0.36803191489361703
- 0.45909574468085107
- 0.426436170212766
- 0.43696808510638296
- 0.3805851063829787
- 0.4498936170212766
- 0.4251595744680851
- 0.46154255319148935
- 0.46117021276595743
- 0.3950531914893617
- 0.38888297872340427
- 0.36414893617021277
- 0.4672340425531915
- 0.39595744680851064
- 0.45340425531914896
- 0.4748936170212766
- 0.4072340425531915
- 0.47127659574468084
- 0.4048404255319149
- 0.38835106382978724
- 0.481968085106383
- 0.44388297872340426
- 0.32643617021276594
- 0.39739361702127657
- 0.3881914893617021
- 0.3612234042553191
- 0.4031914893617021
- 0.37446808510638296
- 0.45643617021276595
- 0.4520212765957447
test_loss_list:
- 4.366560198465983
- 4.568613758087158
- 4.458398494720459
- 3.926463966369629
- 3.775961996714274
- 3.844597781499227
- 3.4518558915456135
- 4.104244387944539
- 3.5674964809417724
- 3.9112752310434975
- 3.580374771753947
- 3.4746178245544432
- 3.2196291478474937
- 3.3709298769632974
- 3.647077398300171
- 3.778186610539754
- 3.7161966705322267
- 3.0712783749898276
- 3.273614829381307
- 3.7867626984914144
- 3.3860188357035317
- 3.5697781976064045
- 3.434651959737142
- 3.177945750554403
- 3.6753033129374186
- 3.84450626373291
- 3.319097464879354
- 3.2377966435750327
- 3.126486775080363
- 3.0101663208007814
- 2.9355694993336994
- 3.3288115660349527
- 3.4425343831380206
- 3.089527339935303
- 3.4658169809977215
- 3.4786603609720865
- 3.425166571935018
- 3.6573242568969726
- 3.7740277290344237
- 3.282887862523397
- 4.204817867279052
- 3.036233657201131
- 3.3636286385854084
- 3.057540356318156
- 3.5822545687357583
- 2.8264672056833904
- 3.403476390838623
- 3.174492082595825
- 2.986221227645874
- 3.627882785797119
- 2.894449920654297
- 3.152026669184367
- 2.968832391103109
- 2.9550673071543376
- 3.373152484893799
- 2.865037581125895
- 3.014855759938558
- 3.077488578160604
- 2.8291874599456786
- 2.992252629597982
- 3.0233477942148843
- 3.551619167327881
- 2.847859296798706
- 3.036562878290812
- 3.281058168411255
- 3.053261629740397
- 3.253334554036458
- 2.904375286102295
- 3.1192222849527993
- 3.058162364959717
- 3.5187346522013345
- 2.9049216492970786
- 2.9830342388153075
- 3.069317216873169
- 3.2670622952779134
- 2.860392230351766
- 3.0910663318634035
- 2.870561269124349
- 2.818550335566203
- 3.1970880285898846
- 3.3257434304555256
- 3.2913939253489177
- 2.8234247589111328
- 3.2840922419230143
- 2.953191493352254
- 2.8209887536366782
- 3.1051953252156577
- 2.8563886006673176
- 3.226735582351685
- 3.2735342947642008
- 2.852625322341919
- 3.0140547307332355
- 3.8507018820444743
- 3.2255543804168703
- 3.3749672158559165
- 3.491062313715617
- 3.2823832511901854
- 3.5105418014526366
- 3.0541338189442953
- 3.0319187959035236
train_accuracy:
- 0.0
- 0.0
- 0.179
- 0.258
- 0.042
- 0.029
- 0.121
- 0.069
- 0.342
- 0.294
- 0.452
- 0.033
- 0.073
- 0.494
- 0.008
- 0.373
- 0.106
- 0.61
- 0.102
- 0.035
- 0.052
- 0.096
- 0.092
- 0.0
- 0.096
- 0.417
- 0.096
- 0.065
- 0.648
- 0.025
- 0.094
- 0.071
- 0.012
- 0.131
- 0.104
- 0.787
- 0.496
- 0.15
- 0.644
- 0.027
- 0.581
- 0.075
- 0.098
- 0.115
- 0.123
- 0.123
- 0.137
- 0.117
- 0.702
- 0.062
- 0.056
- 0.092
- 0.1
- 0.081
- 0.115
- 0.115
- 0.121
- 0.729
- 0.638
- 0.123
- 0.119
- 0.135
- 0.7
- 0.133
- 0.102
- 0.1
- 0.769
- 0.135
- 0.156
- 0.121
- 0.75
- 0.142
- 0.067
- 0.121
- 0.083
- 0.119
- 0.133
- 0.144
- 0.117
- 0.673
- 0.654
- 0.117
- 0.125
- 0.148
- 0.154
- 0.017
- 0.152
- 0.119
- 0.781
- 0.129
- 0.115
- 0.092
- 0.796
- 0.69
- 0.746
- 0.123
- 0.088
- 0.137
- 0.071
- 0.144
train_loss:
- 2.02
- 1.299
- 1.063
- 1.079
- 0.898
- 0.9
- 0.862
- 0.831
- 0.785
- 0.755
- 0.746
- 0.712
- 0.666
- 0.695
- 0.698
- 0.655
- 0.687
- 0.659
- 0.626
- 0.649
- 0.581
- 0.615
- 0.565
- 0.626
- 0.596
- 0.557
- 0.626
- 0.586
- 0.569
- 0.541
- 0.515
- 0.552
- 0.493
- 0.57
- 0.519
- 0.503
- 0.486
- 0.549
- 0.499
- 0.483
- 0.502
- 0.447
- 0.479
- 0.452
- 0.45
- 0.517
- 0.474
- 0.461
- 0.501
- 0.47
- 0.44
- 0.518
- 0.462
- 0.413
- 0.469
- 0.45
- 0.477
- 0.47
- 0.446
- 0.452
- 0.418
- 0.471
- 0.445
- 0.42
- 0.397
- 0.404
- 0.41
- 0.44
- 0.409
- 0.392
- 0.425
- 0.402
- 0.397
- 0.38
- 0.386
- 0.419
- 0.372
- 0.383
- 0.355
- 0.368
- 0.393
- 0.4
- 0.362
- 0.401
- 0.372
- 0.37
- 0.396
- 0.398
- 0.344
- 0.388
- 0.339
- 0.353
- 0.399
- 0.381
- 0.363
- 0.352
- 0.33
- 0.315
- 0.32
- 0.374
unequal: 0
verbose: 1
