avg_train_accuracy: 0.677
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02595744680851064
- 0.0651063829787234
- 0.09563829787234042
- 0.1173404255319149
- 0.13127659574468084
- 0.20829787234042554
- 0.1348404255319149
- 0.1804255319148936
- 0.16792553191489362
- 0.21638297872340426
- 0.16361702127659575
- 0.20585106382978724
- 0.25372340425531914
- 0.18329787234042552
- 0.27170212765957447
- 0.188031914893617
- 0.20861702127659573
- 0.21015957446808511
- 0.2721276595744681
- 0.23537234042553193
- 0.26930851063829786
- 0.2799468085106383
- 0.2200531914893617
- 0.21414893617021277
- 0.2577659574468085
- 0.32904255319148934
- 0.21367021276595743
- 0.3195212765957447
- 0.3047872340425532
- 0.34585106382978725
- 0.3422872340425532
- 0.34106382978723404
- 0.3542021276595745
- 0.30882978723404253
- 0.32335106382978723
- 0.31446808510638297
- 0.31696808510638297
- 0.23835106382978724
- 0.3378191489361702
- 0.363936170212766
- 0.30542553191489363
- 0.3606382978723404
- 0.3955851063829787
- 0.37957446808510636
- 0.3326595744680851
- 0.3130851063829787
- 0.26388297872340427
- 0.3601595744680851
- 0.3972872340425532
- 0.4004255319148936
- 0.3752659574468085
- 0.39643617021276595
- 0.34574468085106386
- 0.34691489361702127
- 0.3471808510638298
- 0.40622340425531916
- 0.42696808510638296
- 0.35414893617021276
- 0.38718085106382977
- 0.38430851063829785
- 0.3422872340425532
- 0.35122340425531917
- 0.43186170212765956
- 0.44079787234042556
- 0.45622340425531915
- 0.41888297872340424
- 0.4201063829787234
- 0.3932978723404255
- 0.4454255319148936
- 0.4425
- 0.3026595744680851
- 0.45643617021276595
- 0.4302127659574468
- 0.48888297872340425
- 0.4448936170212766
- 0.45606382978723403
- 0.4082978723404255
- 0.48425531914893616
- 0.45
- 0.4470212765957447
- 0.39398936170212767
- 0.4703723404255319
- 0.4374468085106383
- 0.3798404255319149
- 0.311436170212766
- 0.4430851063829787
- 0.4251063829787234
- 0.4932446808510638
- 0.4197872340425532
- 0.4173936170212766
- 0.41393617021276596
- 0.3801595744680851
- 0.43627659574468086
- 0.451968085106383
- 0.41590425531914893
- 0.30882978723404253
- 0.4998404255319149
- 0.48069148936170214
- 0.488936170212766
- 0.4178191489361702
test_loss_list:
- 4.912446047465006
- 4.391512692769369
- 4.079620418548584
- 3.763660643895467
- 4.019772291183472
- 3.5646859200795493
- 4.6521903355916345
- 3.606063861846924
- 4.265791893005371
- 4.086627887090047
- 3.6233507855733236
- 3.4559158929189047
- 3.2448459529876708
- 3.6025127760569253
- 3.2205702304840087
- 4.207435522079468
- 3.6538495635986328
- 3.9487682374318442
- 3.322309268315633
- 3.559743585586548
- 3.1918760426839192
- 3.3172194131215416
- 3.4105932553609213
- 4.139793748855591
- 3.2923692925771078
- 3.016866823832194
- 4.276117518742879
- 3.150080238978068
- 3.1327047697703043
- 3.113233149846395
- 2.9859927908579507
- 3.4148661931355795
- 3.1277483050028483
- 3.8253789488474528
- 2.8883506457010903
- 3.0069536368052163
- 3.304107354482015
- 4.7633491770426435
- 2.7814328543345135
- 2.970453020731608
- 3.2736636543273927
- 3.1192796198527017
- 2.8801037565867107
- 2.99756241162618
- 2.9937225914001466
- 3.598601811726888
- 4.146055676142375
- 2.9015240065256753
- 2.789498427708944
- 3.1007627995808917
- 2.928131872812907
- 2.7634309005737303
- 3.2560591316223144
- 3.289705114364624
- 3.3141460768381754
- 3.030484727223714
- 2.603411931991577
- 3.1936037953694663
- 2.9738929271698
- 2.878957141240438
- 3.447467877070109
- 2.976516205469767
- 2.664395513534546
- 2.6904482491811117
- 2.6372871367136637
- 2.772678887049357
- 2.893159669240316
- 2.954612210591634
- 2.5869169425964356
- 2.740572605133057
- 4.080380681355794
- 2.6541278743743897
- 2.8895756308237712
- 2.5211359945933025
- 2.8408645153045655
- 2.6227451451619466
- 2.929800148010254
- 2.5397830899556477
- 2.796754684448242
- 2.9386237716674803
- 2.868750940958659
- 2.5800380738576254
- 2.681800047556559
- 3.203680013020833
- 3.4385658423105876
- 2.722681608200073
- 2.9172482013702394
- 2.5524967320760092
- 2.814823668797811
- 2.9007972431182862
- 2.9780447546641033
- 3.2563803418477377
- 2.9026402982076007
- 2.7640421104431154
- 3.1876201025644937
- 4.234305324554444
- 2.6676750628153485
- 2.808377482096354
- 2.564081958134969
- 3.006362984975179
train_accuracy:
- 0.0
- 0.0
- 0.062
- 0.31
- 0.217
- 0.052
- 0.235
- 0.454
- 0.01
- 0.073
- 0.727
- 0.079
- 0.46
- 0.669
- 0.137
- 0.15
- 0.09
- 0.025
- 0.079
- 0.092
- 0.442
- 0.594
- 0.006
- 0.11
- 0.06
- 0.065
- 0.14
- 0.652
- 0.108
- 0.1
- 0.081
- 0.056
- 0.062
- 0.554
- 0.127
- 0.26
- 0.583
- 0.131
- 0.033
- 0.119
- 0.012
- 0.242
- 0.071
- 0.183
- 0.025
- 0.065
- 0.66
- 0.19
- 0.088
- 0.127
- 0.033
- 0.146
- 0.117
- 0.14
- 0.058
- 0.337
- 0.317
- 0.742
- 0.096
- 0.094
- 0.094
- 0.713
- 0.1
- 0.048
- 0.125
- 0.119
- 0.421
- 0.725
- 0.754
- 0.096
- 0.81
- 0.142
- 0.05
- 0.154
- 0.677
- 0.077
- 0.569
- 0.113
- 0.773
- 0.094
- 0.685
- 0.058
- 0.319
- 0.767
- 0.652
- 0.062
- 0.115
- 0.677
- 0.154
- 0.142
- 0.158
- 0.156
- 0.108
- 0.808
- 0.113
- 0.817
- 0.731
- 0.052
- 0.102
- 0.677
train_loss:
- 1.869
- 1.268
- 1.126
- 0.997
- 0.821
- 0.822
- 0.795
- 0.708
- 0.694
- 0.632
- 0.76
- 0.672
- 0.728
- 0.679
- 0.66
- 0.617
- 0.607
- 0.534
- 0.631
- 0.578
- 0.608
- 0.553
- 0.583
- 0.576
- 0.545
- 0.606
- 0.554
- 0.495
- 0.53
- 0.507
- 0.475
- 0.458
- 0.473
- 0.433
- 0.515
- 0.494
- 0.469
- 0.455
- 0.507
- 0.475
- 0.495
- 0.455
- 0.441
- 0.434
- 0.455
- 0.434
- 0.441
- 0.449
- 0.403
- 0.384
- 0.422
- 0.429
- 0.41
- 0.404
- 0.394
- 0.397
- 0.427
- 0.382
- 0.363
- 0.381
- 0.375
- 0.43
- 0.386
- 0.366
- 0.38
- 0.387
- 0.372
- 0.371
- 0.357
- 0.362
- 0.377
- 0.35
- 0.336
- 0.371
- 0.338
- 0.325
- 0.386
- 0.346
- 0.323
- 0.303
- 0.396
- 0.346
- 0.369
- 0.342
- 0.386
- 0.333
- 0.353
- 0.354
- 0.324
- 0.362
- 0.346
- 0.331
- 0.299
- 0.316
- 0.309
- 0.318
- 0.346
- 0.306
- 0.32
- 0.344
unequal: 0
verbose: 1
