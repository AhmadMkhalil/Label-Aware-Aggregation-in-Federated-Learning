avg_train_accuracy: 0.119
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02893617021276596
- 0.09468085106382979
- 0.1226595744680851
- 0.1427127659574468
- 0.1423404255319149
- 0.15361702127659574
- 0.19595744680851063
- 0.16686170212765958
- 0.19797872340425532
- 0.1772872340425532
- 0.19537234042553192
- 0.19361702127659575
- 0.2274468085106383
- 0.23755319148936171
- 0.21148936170212765
- 0.1626595744680851
- 0.26776595744680853
- 0.2693617021276596
- 0.3079787234042553
- 0.2749468085106383
- 0.28111702127659577
- 0.2902127659574468
- 0.2929787234042553
- 0.3084574468085106
- 0.29329787234042554
- 0.3228191489361702
- 0.31601063829787235
- 0.3130851063829787
- 0.26941489361702126
- 0.2673936170212766
- 0.3051063829787234
- 0.3029787234042553
- 0.3579787234042553
- 0.2968085106382979
- 0.33117021276595743
- 0.2679787234042553
- 0.33101063829787236
- 0.324468085106383
- 0.30781914893617024
- 0.37617021276595747
- 0.3204787234042553
- 0.33287234042553193
- 0.3843617021276596
- 0.31803191489361704
- 0.33691489361702126
- 0.32680851063829786
- 0.3948936170212766
- 0.4076063829787234
- 0.3852659574468085
- 0.3199468085106383
- 0.3473936170212766
- 0.333031914893617
- 0.41260638297872343
- 0.3772340425531915
- 0.4026595744680851
- 0.4381914893617021
- 0.42351063829787233
- 0.3951063829787234
- 0.3607446808510638
- 0.41425531914893615
- 0.410531914893617
- 0.4383510638297872
- 0.4425
- 0.2774468085106383
- 0.3423404255319149
- 0.4245744680851064
- 0.35914893617021276
- 0.3981914893617021
- 0.4277127659574468
- 0.3331914893617021
- 0.44409574468085106
- 0.3903723404255319
- 0.41329787234042553
- 0.4525531914893617
- 0.4231382978723404
- 0.4131382978723404
- 0.39335106382978724
- 0.4640957446808511
- 0.4015957446808511
- 0.45680851063829786
- 0.3871276595744681
- 0.4800531914893617
- 0.3740425531914894
- 0.3698404255319149
- 0.35377659574468084
- 0.5315425531914894
- 0.4580851063829787
- 0.47952127659574467
- 0.41904255319148936
- 0.3895744680851064
- 0.47702127659574467
- 0.39143617021276594
- 0.42409574468085104
- 0.48734042553191487
- 0.4352127659574468
- 0.45835106382978724
- 0.47867021276595745
- 0.47914893617021276
- 0.43659574468085105
- 0.4997872340425532
test_loss_list:
- 4.217895113627116
- 4.710077641805013
- 5.215010051727295
- 3.9902572377522785
- 3.6208811823527016
- 4.129127238591512
- 3.395582701365153
- 3.479579334259033
- 3.4815931193033856
- 3.9612098121643067
- 3.521225086847941
- 3.7983988539377846
- 3.3082884820302327
- 3.289090690612793
- 3.599867598215739
- 4.775557613372802
- 3.1351932938893636
- 3.2301009464263917
- 3.0976847648620605
- 3.292475214004517
- 3.2236521530151365
- 3.0660122458140053
- 3.3213023948669433
- 2.905710430145264
- 3.2601317310333253
- 3.0673531119028725
- 3.4432578881581626
- 3.288536911010742
- 3.6412482515970868
- 3.6446117528279625
- 3.716901305516561
- 4.051681559880574
- 3.0159226067860923
- 3.31243483543396
- 3.2046076456705728
- 3.6046091747283935
- 3.043505973815918
- 3.163610308965047
- 3.185714651743571
- 2.8536441993713377
- 3.3087728659311932
- 3.088001375198364
- 2.943400681813558
- 3.280719690322876
- 3.264745445251465
- 3.4876404921213786
- 2.8661838658650716
- 2.797209005355835
- 3.00320738474528
- 3.5798498821258544
- 3.21756937344869
- 3.321851641337077
- 2.822351229985555
- 3.054145510991414
- 2.886081069310506
- 2.7190606880187986
- 2.7896747461954754
- 3.0959704081217447
- 3.2693122482299803
- 2.910576423009237
- 2.9038329251607258
- 2.8318129634857176
- 2.926484162012736
- 3.9803303877512612
- 3.380245901743571
- 2.950177141825358
- 3.675337308247884
- 3.042672030131022
- 2.947105731964111
- 3.64927375793457
- 2.9687907600402834
- 2.8855424753824868
- 3.0533214378356934
- 2.834260896046956
- 2.998711522420247
- 2.977927252451579
- 3.053949515024821
- 2.767301292419434
- 3.168282318115234
- 2.8324349308013916
- 3.1679999828338623
- 2.7291341463724774
- 3.250729007720947
- 3.407339865366618
- 3.614059772491455
- 2.4891169611612955
- 2.847123295466105
- 2.7747603829701744
- 3.2336581643422444
- 3.457526699701945
- 2.711424706776937
- 3.288997999827067
- 3.178405965169271
- 2.7230025164286293
- 2.949961608250936
- 2.8027851676940916
- 2.8542385419209797
- 2.7255167547861734
- 2.937476034164429
- 2.8045668824513754
train_accuracy:
- 0.002
- 0.146
- 0.173
- 0.048
- 0.046
- 0.025
- 0.0
- 0.06
- 0.523
- 0.033
- 0.088
- 0.056
- 0.073
- 0.0
- 0.442
- 0.137
- 0.008
- 0.088
- 0.06
- 0.517
- 0.077
- 0.448
- 0.083
- 0.035
- 0.529
- 0.102
- 0.094
- 0.031
- 0.598
- 0.085
- 0.094
- 0.125
- 0.104
- 0.646
- 0.037
- 0.098
- 0.09
- 0.717
- 0.117
- 0.031
- 0.083
- 0.09
- 0.096
- 0.104
- 0.135
- 0.088
- 0.121
- 0.067
- 0.019
- 0.108
- 0.594
- 0.646
- 0.783
- 0.058
- 0.096
- 0.073
- 0.075
- 0.1
- 0.09
- 0.083
- 0.633
- 0.81
- 0.037
- 0.677
- 0.123
- 0.117
- 0.123
- 0.827
- 0.098
- 0.098
- 0.073
- 0.121
- 0.104
- 0.113
- 0.131
- 0.804
- 0.819
- 0.104
- 0.777
- 0.1
- 0.848
- 0.758
- 0.65
- 0.617
- 0.123
- 0.1
- 0.106
- 0.1
- 0.729
- 0.135
- 0.11
- 0.142
- 0.135
- 0.125
- 0.144
- 0.875
- 0.083
- 0.123
- 0.135
- 0.119
train_loss:
- 2.026
- 1.198
- 0.981
- 0.894
- 0.954
- 0.808
- 0.816
- 0.867
- 0.767
- 0.707
- 0.733
- 0.71
- 0.683
- 0.722
- 0.687
- 0.658
- 0.68
- 0.635
- 0.637
- 0.65
- 0.576
- 0.629
- 0.579
- 0.572
- 0.543
- 0.526
- 0.498
- 0.497
- 0.508
- 0.497
- 0.488
- 0.455
- 0.502
- 0.534
- 0.478
- 0.534
- 0.478
- 0.503
- 0.464
- 0.488
- 0.434
- 0.476
- 0.436
- 0.418
- 0.421
- 0.388
- 0.463
- 0.44
- 0.397
- 0.385
- 0.421
- 0.426
- 0.394
- 0.392
- 0.418
- 0.41
- 0.381
- 0.371
- 0.363
- 0.349
- 0.393
- 0.354
- 0.387
- 0.361
- 0.38
- 0.36
- 0.344
- 0.373
- 0.348
- 0.352
- 0.36
- 0.401
- 0.324
- 0.327
- 0.38
- 0.338
- 0.366
- 0.387
- 0.334
- 0.346
- 0.325
- 0.333
- 0.348
- 0.313
- 0.299
- 0.375
- 0.329
- 0.332
- 0.331
- 0.316
- 0.341
- 0.314
- 0.306
- 0.345
- 0.313
- 0.317
- 0.3
- 0.34
- 0.308
- 0.333
unequal: 0
verbose: 1
