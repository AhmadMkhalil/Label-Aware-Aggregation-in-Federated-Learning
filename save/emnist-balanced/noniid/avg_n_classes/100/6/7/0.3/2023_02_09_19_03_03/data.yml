avg_train_accuracy: 0.798
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02303191489361702
- 0.09069148936170213
- 0.1295744680851064
- 0.10138297872340425
- 0.1325531914893617
- 0.13787234042553193
- 0.18563829787234043
- 0.13159574468085106
- 0.1479255319148936
- 0.2204787234042553
- 0.15335106382978722
- 0.17617021276595746
- 0.21840425531914895
- 0.14712765957446808
- 0.19569148936170214
- 0.20202127659574468
- 0.19840425531914893
- 0.20414893617021276
- 0.22090425531914892
- 0.23925531914893616
- 0.22351063829787235
- 0.22882978723404254
- 0.23835106382978724
- 0.2323404255319149
- 0.17367021276595745
- 0.2676063829787234
- 0.2542553191489362
- 0.2229787234042553
- 0.2646276595744681
- 0.16553191489361702
- 0.17164893617021276
- 0.30361702127659573
- 0.19117021276595744
- 0.2328191489361702
- 0.25574468085106383
- 0.30877659574468086
- 0.2971808510638298
- 0.3072872340425532
- 0.265
- 0.25718085106382976
- 0.26218085106382977
- 0.3276595744680851
- 0.29648936170212764
- 0.27170212765957447
- 0.2843085106382979
- 0.3121808510638298
- 0.216968085106383
- 0.36792553191489363
- 0.31696808510638297
- 0.2718617021276596
- 0.31680851063829785
- 0.30090425531914894
- 0.29127659574468084
- 0.23335106382978724
- 0.2772340425531915
- 0.3205851063829787
- 0.28882978723404257
- 0.31968085106382976
- 0.2963297872340426
- 0.2931382978723404
- 0.3101063829787234
- 0.3631382978723404
- 0.2829255319148936
- 0.2714893617021277
- 0.2530851063829787
- 0.3152659574468085
- 0.28212765957446806
- 0.3243617021276596
- 0.34319148936170213
- 0.33345744680851064
- 0.30079787234042554
- 0.3230851063829787
- 0.30851063829787234
- 0.3389893617021277
- 0.35569148936170214
- 0.3326595744680851
- 0.32345744680851063
- 0.36351063829787233
- 0.34675531914893615
- 0.34180851063829787
- 0.21361702127659574
- 0.3951595744680851
- 0.3694148936170213
- 0.3246276595744681
- 0.37377659574468086
- 0.4200531914893617
- 0.21180851063829786
- 0.3592021276595745
- 0.3684574468085106
- 0.3400531914893617
- 0.34595744680851065
- 0.3476595744680851
- 0.35723404255319147
- 0.3955851063829787
- 0.3543085106382979
- 0.3996276595744681
- 0.3749468085106383
- 0.3567021276595745
- 0.23202127659574467
- 0.31877659574468087
test_loss_list:
- 5.255278523763021
- 5.923937867482503
- 5.3970183690389
- 4.127046480178833
- 3.9076493326822916
- 4.5371096865336105
- 4.698050066630046
- 6.207408332824707
- 7.244208170572917
- 4.997772274017334
- 6.07877685546875
- 3.83309196472168
- 5.0625613530476885
- 3.440868536631266
- 3.639564530054728
- 4.039260473251343
- 3.825804303487142
- 3.954651870727539
- 3.255169293085734
- 3.853043584823608
- 4.262310578028361
- 4.88195109685262
- 4.004986146291097
- 4.426666132609049
- 6.640130818684896
- 4.458814080556234
- 3.2937478542327883
- 4.3407475344340005
- 4.346909370422363
- 6.71317107518514
- 7.408336671193441
- 3.38899800936381
- 5.560671310424805
- 4.04462121963501
- 3.5510368824005125
- 3.665500609079997
- 3.591590623855591
- 3.2650719610850016
- 4.265650221506754
- 4.939670435587565
- 4.7560239601135255
- 3.3823388481140135
- 3.6344501399993896
- 4.5833593877156575
- 4.739953645070394
- 4.334995457331339
- 5.800924415588379
- 2.931103531519572
- 3.5489415295918785
- 4.646582597096761
- 3.463859068552653
- 4.166034514109294
- 4.074934736887614
- 4.216617393493652
- 4.344102722803751
- 3.683114744822184
- 4.135927454630534
- 3.7592127323150635
- 3.9907755184173586
- 4.705973161061605
- 4.314127763112386
- 3.7539531135559083
- 4.938022816975911
- 5.408163153330485
- 4.042990636825562
- 3.8018373362223308
- 4.109097487131755
- 3.4437584177652996
- 3.679645388921102
- 3.6919302845001223
- 4.171472806930542
- 3.9361147340138753
- 4.267184438705445
- 3.9002579498291015
- 3.9601990795135498
- 3.7800492318471273
- 3.845342887242635
- 3.4506660238901774
- 4.04437206586202
- 4.007087227503459
- 5.31097697575887
- 3.5506205781300864
- 4.113613306681315
- 3.844405263264974
- 3.502104711532593
- 3.321176986694336
- 5.274389419555664
- 3.856227267583211
- 3.6451391728719074
- 3.9370834159851076
- 3.7758622328440348
- 3.970380891164144
- 4.141149495442709
- 3.5988318888346353
- 4.138947642644246
- 3.3965072377522785
- 3.8198920822143556
- 3.8902255948384603
- 5.191795806884766
- 4.530700715382894
train_accuracy:
- 0.0
- 0.0
- 0.148
- 0.044
- 0.0
- 0.077
- 0.15
- 0.508
- 0.579
- 0.137
- 0.548
- 0.585
- 0.113
- 0.05
- 0.123
- 0.088
- 0.123
- 0.673
- 0.119
- 0.6
- 0.14
- 0.137
- 0.075
- 0.669
- 0.708
- 0.158
- 0.023
- 0.11
- 0.773
- 0.146
- 0.121
- 0.131
- 0.156
- 0.137
- 0.769
- 0.115
- 0.688
- 0.142
- 0.704
- 0.156
- 0.673
- 0.146
- 0.104
- 0.142
- 0.102
- 0.123
- 0.16
- 0.09
- 0.058
- 0.783
- 0.142
- 0.123
- 0.077
- 0.108
- 0.135
- 0.148
- 0.783
- 0.1
- 0.117
- 0.137
- 0.137
- 0.131
- 0.154
- 0.123
- 0.76
- 0.127
- 0.142
- 0.137
- 0.76
- 0.152
- 0.106
- 0.135
- 0.144
- 0.152
- 0.11
- 0.142
- 0.746
- 0.154
- 0.758
- 0.16
- 0.852
- 0.106
- 0.15
- 0.754
- 0.131
- 0.108
- 0.792
- 0.148
- 0.106
- 0.152
- 0.094
- 0.137
- 0.123
- 0.129
- 0.165
- 0.152
- 0.856
- 0.106
- 0.767
- 0.798
train_loss:
- 2.047
- 1.253
- 1.055
- 1.258
- 1.042
- 0.81
- 0.763
- 0.768
- 0.624
- 0.667
- 0.658
- 0.812
- 0.564
- 0.89
- 0.736
- 0.657
- 0.76
- 0.686
- 0.672
- 0.609
- 0.546
- 0.462
- 0.653
- 0.541
- 0.519
- 0.552
- 0.642
- 0.594
- 0.477
- 0.455
- 0.417
- 0.535
- 0.553
- 0.557
- 0.564
- 0.471
- 0.522
- 0.511
- 0.472
- 0.412
- 0.384
- 0.52
- 0.46
- 0.416
- 0.382
- 0.352
- 0.431
- 0.537
- 0.438
- 0.368
- 0.526
- 0.4
- 0.432
- 0.514
- 0.383
- 0.398
- 0.385
- 0.423
- 0.387
- 0.321
- 0.286
- 0.436
- 0.304
- 0.296
- 0.45
- 0.354
- 0.366
- 0.42
- 0.428
- 0.422
- 0.37
- 0.337
- 0.34
- 0.389
- 0.281
- 0.445
- 0.364
- 0.363
- 0.35
- 0.321
- 0.379
- 0.336
- 0.272
- 0.398
- 0.385
- 0.371
- 0.354
- 0.42
- 0.328
- 0.381
- 0.366
- 0.322
- 0.346
- 0.313
- 0.322
- 0.393
- 0.336
- 0.306
- 0.335
- 0.308
unequal: 0
verbose: 1
