avg_train_accuracy: 0.144
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06664893617021277
- 0.08861702127659575
- 0.11978723404255319
- 0.12771276595744682
- 0.12723404255319148
- 0.13787234042553193
- 0.08882978723404256
- 0.14648936170212765
- 0.15319148936170213
- 0.16585106382978723
- 0.1898936170212766
- 0.1901063829787234
- 0.17803191489361703
- 0.12585106382978722
- 0.13957446808510637
- 0.1523404255319149
- 0.18632978723404256
- 0.18186170212765956
- 0.22180851063829787
- 0.1772340425531915
- 0.09675531914893618
- 0.09744680851063829
- 0.1321276595744681
- 0.22063829787234043
- 0.20420212765957446
- 0.15882978723404256
- 0.23106382978723405
- 0.15175531914893617
- 0.21819148936170213
- 0.20755319148936172
- 0.2376595744680851
- 0.2272872340425532
- 0.17340425531914894
- 0.2509574468085106
- 0.17824468085106382
- 0.24319148936170212
- 0.2534574468085106
- 0.1804255319148936
- 0.17207446808510637
- 0.2571276595744681
- 0.2670744680851064
- 0.2726595744680851
- 0.17803191489361703
- 0.17893617021276595
- 0.1920212765957447
- 0.26361702127659575
- 0.26691489361702125
- 0.26648936170212767
- 0.2553191489361702
- 0.32170212765957445
- 0.24063829787234042
- 0.28377659574468084
- 0.33382978723404255
- 0.3053723404255319
- 0.2810106382978723
- 0.27074468085106385
- 0.2591489361702128
- 0.19329787234042553
- 0.2860106382978723
- 0.29984042553191487
- 0.33367021276595743
- 0.2857446808510638
- 0.1874468085106383
- 0.36851063829787234
- 0.26526595744680853
- 0.3295212765957447
- 0.2877659574468085
- 0.281968085106383
- 0.2900531914893617
- 0.2746276595744681
- 0.2125531914893617
- 0.26835106382978724
- 0.2777659574468085
- 0.2850531914893617
- 0.35138297872340424
- 0.25680851063829785
- 0.3477659574468085
- 0.28819148936170214
- 0.36148936170212764
- 0.3226063829787234
- 0.3192553191489362
- 0.29148936170212764
- 0.21904255319148935
- 0.2968085106382979
- 0.29909574468085104
- 0.3104787234042553
- 0.3154787234042553
- 0.19170212765957448
- 0.33739361702127657
- 0.20361702127659576
- 0.3267553191489362
- 0.3002659574468085
- 0.32335106382978723
- 0.35223404255319146
- 0.3604787234042553
- 0.3171276595744681
- 0.35069148936170214
- 0.30436170212765956
- 0.3625
- 0.33877659574468083
test_loss_list:
- 4.443966496785482
- 4.656455713907878
- 4.76070499420166
- 3.8188928031921385
- 4.299952373504639
- 4.668519846598307
- 5.709427674611409
- 3.656909392674764
- 4.623981393178304
- 4.299157784779866
- 4.432789551417033
- 3.9138694032033285
- 4.325614016850789
- 4.902735373179118
- 5.629406305948893
- 6.8298643112182615
- 4.395965830485026
- 4.6869867897033695
- 3.8434818267822264
- 3.5531313832600913
- 13.004678738911947
- 13.373524780273437
- 6.011232452392578
- 3.385255339940389
- 4.12331122080485
- 7.333814849853516
- 3.724636198679606
- 5.506035664876302
- 3.929286298751831
- 4.5374098428090415
- 3.7306432088216144
- 4.4842891629536945
- 6.06905974706014
- 3.833076718648275
- 6.339223410288493
- 3.765555798212687
- 3.881179857254028
- 5.245565872192383
- 6.02775619506836
- 3.656879606246948
- 4.257576920191447
- 3.7259441947937013
- 5.75060853322347
- 6.972113463083903
- 5.944472910563151
- 3.844808899561564
- 4.029350582758585
- 3.9450731722513837
- 3.8157214546203613
- 3.2739842319488526
- 4.554981749852498
- 3.728425614039103
- 3.1446995385487875
- 3.446493460337321
- 3.6768379561106364
- 4.207017040252685
- 4.29365935643514
- 5.456391023000081
- 4.200227966308594
- 3.5830321089426675
- 3.3769298362731934
- 3.635992342631022
- 5.218578923543294
- 3.08763303120931
- 4.288413273493449
- 3.57577862739563
- 4.0931125736236575
- 4.193962739308675
- 4.101020412445068
- 4.071839281717936
- 5.787862415313721
- 3.9986890284220378
- 4.507781712214152
- 3.7696886920928954
- 3.25588339805603
- 4.611082019805909
- 3.446754051844279
- 4.042226025263468
- 3.2961855220794676
- 3.688526668548584
- 3.8727215480804444
- 3.9410243701934813
- 5.203174215952555
- 4.1429315948486325
- 4.071788864135742
- 4.034485136667888
- 3.90791615486145
- 6.273940575917562
- 3.350413885116577
- 5.594660263061524
- 3.757573839823405
- 4.46855744043986
- 3.93105219523112
- 3.8338690280914305
- 3.3545474116007488
- 3.955623064041138
- 3.734112269083659
- 4.234086818695069
- 3.5267360464731854
- 3.6179004859924317
train_accuracy:
- 0.0
- 0.006
- 0.044
- 0.054
- 0.0
- 0.075
- 0.117
- 0.044
- 0.088
- 0.031
- 0.029
- 0.085
- 0.204
- 0.171
- 0.59
- 0.625
- 0.558
- 0.09
- 0.146
- 0.104
- 0.919
- 0.917
- 0.315
- 0.129
- 0.048
- 0.604
- 0.065
- 0.515
- 0.079
- 0.61
- 0.023
- 0.077
- 0.733
- 0.117
- 0.123
- 0.05
- 0.79
- 0.142
- 0.683
- 0.06
- 0.137
- 0.74
- 0.669
- 0.146
- 0.733
- 0.131
- 0.702
- 0.098
- 0.035
- 0.044
- 0.7
- 0.148
- 0.135
- 0.133
- 0.11
- 0.117
- 0.117
- 0.787
- 0.804
- 0.065
- 0.075
- 0.142
- 0.798
- 0.104
- 0.121
- 0.148
- 0.767
- 0.148
- 0.09
- 0.146
- 0.156
- 0.11
- 0.148
- 0.794
- 0.804
- 0.758
- 0.081
- 0.106
- 0.135
- 0.148
- 0.088
- 0.137
- 0.148
- 0.121
- 0.131
- 0.135
- 0.144
- 0.815
- 0.842
- 0.154
- 0.725
- 0.133
- 0.131
- 0.152
- 0.15
- 0.158
- 0.133
- 0.102
- 0.144
- 0.144
train_loss:
- 1.745
- 1.297
- 0.924
- 1.043
- 1.021
- 0.939
- 0.944
- 1.008
- 0.853
- 0.86
- 0.685
- 0.821
- 0.705
- 0.785
- 0.744
- 0.611
- 0.644
- 0.619
- 0.73
- 0.838
- 0.625
- 0.491
- 0.614
- 0.754
- 0.694
- 0.576
- 0.683
- 0.569
- 0.588
- 0.537
- 0.587
- 0.566
- 0.538
- 0.571
- 0.488
- 0.686
- 0.545
- 0.537
- 0.477
- 0.55
- 0.523
- 0.538
- 0.475
- 0.393
- 0.481
- 0.51
- 0.441
- 0.5
- 0.53
- 0.474
- 0.463
- 0.432
- 0.53
- 0.53
- 0.46
- 0.422
- 0.403
- 0.404
- 0.428
- 0.499
- 0.467
- 0.46
- 0.43
- 0.492
- 0.388
- 0.455
- 0.414
- 0.405
- 0.387
- 0.426
- 0.398
- 0.399
- 0.348
- 0.446
- 0.45
- 0.357
- 0.44
- 0.382
- 0.419
- 0.366
- 0.35
- 0.393
- 0.446
- 0.364
- 0.382
- 0.344
- 0.339
- 0.314
- 0.455
- 0.332
- 0.406
- 0.345
- 0.357
- 0.341
- 0.438
- 0.357
- 0.344
- 0.328
- 0.383
- 0.368
unequal: 0
verbose: 1
