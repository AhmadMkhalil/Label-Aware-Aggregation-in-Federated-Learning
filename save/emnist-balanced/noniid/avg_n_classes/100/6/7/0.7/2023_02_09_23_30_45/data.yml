avg_train_accuracy: 0.119
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037127659574468085
- 0.05313829787234042
- 0.13638297872340427
- 0.1721808510638298
- 0.12941489361702127
- 0.15664893617021278
- 0.1548936170212766
- 0.22478723404255319
- 0.18521276595744682
- 0.2248936170212766
- 0.21404255319148935
- 0.23303191489361702
- 0.23537234042553193
- 0.2397872340425532
- 0.2870744680851064
- 0.26595744680851063
- 0.2894148936170213
- 0.2561702127659575
- 0.2653191489361702
- 0.31313829787234043
- 0.30707446808510636
- 0.2628191489361702
- 0.28952127659574467
- 0.3202127659574468
- 0.3206914893617021
- 0.3145212765957447
- 0.30851063829787234
- 0.3385106382978723
- 0.36659574468085104
- 0.34941489361702127
- 0.34372340425531916
- 0.3902127659574468
- 0.3547872340425532
- 0.3775
- 0.3017021276595745
- 0.3439893617021277
- 0.38053191489361704
- 0.3920744680851064
- 0.33452127659574465
- 0.3510106382978723
- 0.38840425531914896
- 0.37898936170212766
- 0.4272340425531915
- 0.37117021276595746
- 0.3720212765957447
- 0.38335106382978723
- 0.40654255319148935
- 0.44840425531914896
- 0.45074468085106384
- 0.41664893617021276
- 0.3746808510638298
- 0.4153723404255319
- 0.421968085106383
- 0.39143617021276594
- 0.4487765957446809
- 0.43670212765957445
- 0.39920212765957447
- 0.4722340425531915
- 0.4473404255319149
- 0.40558510638297873
- 0.4677659574468085
- 0.4913297872340426
- 0.4135106382978723
- 0.4014893617021277
- 0.4520212765957447
- 0.4576595744680851
- 0.4379787234042553
- 0.4896808510638298
- 0.44372340425531914
- 0.5007978723404255
- 0.4343085106382979
- 0.49303191489361703
- 0.4697340425531915
- 0.47893617021276597
- 0.4721808510638298
- 0.47154255319148936
- 0.4652659574468085
- 0.48851063829787233
- 0.48148936170212764
- 0.4801063829787234
- 0.5122340425531915
- 0.45797872340425533
- 0.4221808510638298
- 0.5008510638297873
- 0.44117021276595747
- 0.4831382978723404
- 0.5042021276595745
- 0.5290425531914894
- 0.445
- 0.43670212765957445
- 0.4696808510638298
- 0.47643617021276596
- 0.526595744680851
- 0.47590425531914893
- 0.46170212765957447
- 0.43351063829787234
- 0.46367021276595743
- 0.43356382978723407
- 0.43851063829787235
- 0.5039361702127659
test_loss_list:
- 4.1330706469217935
- 4.239757645924886
- 3.6955593744913737
- 3.7557239945729575
- 3.5291799831390382
- 3.6018248144785563
- 3.4862310473124185
- 3.2855580329895018
- 3.445791343053182
- 3.396581506729126
- 3.33508513768514
- 3.400243771870931
- 3.2286019770304364
- 3.419767599105835
- 3.064652665456136
- 3.283192030588786
- 3.1287413883209227
- 3.511144822438558
- 3.199468631744385
- 3.0998541577657064
- 3.209525893529256
- 3.3266806570688883
- 3.168611634572347
- 3.209390411376953
- 3.171801013946533
- 3.033482370376587
- 3.096037368774414
- 3.1398116620381673
- 3.0585790157318113
- 3.135689544677734
- 2.875820903778076
- 2.9620601240793865
- 3.0001494216918947
- 3.0547468090057373
- 3.2429151852925617
- 2.9630974388122557
- 2.8648250261942545
- 2.885572322209676
- 3.136341848373413
- 3.1685445245107013
- 2.8936794662475585
- 3.0335607051849367
- 2.7952733198801676
- 3.063727773030599
- 3.2060435231526694
- 2.981227149963379
- 3.025518283843994
- 2.884361120859782
- 2.94946133295695
- 2.859600435892741
- 3.3339224497477216
- 2.8586771551767987
- 2.8694303957621257
- 3.0398560619354247
- 2.8855996036529543
- 2.8487937672932944
- 2.9692863051096596
- 2.806979948679606
- 3.047769832611084
- 2.900512374242147
- 2.7652697499593097
- 2.713442811965942
- 3.1482224877675375
- 3.172143405278524
- 2.998757902781169
- 3.0237516848246258
- 2.8362212149302164
- 2.702545919418335
- 3.053782981236776
- 2.671203149159749
- 2.9604858589172363
- 2.791172358194987
- 2.955037597020467
- 2.883971061706543
- 2.9765640767415364
- 2.7252320194244386
- 2.950749635696411
- 2.785786460240682
- 2.763434886932373
- 2.877396831512451
- 2.8380600516001384
- 2.885426772435506
- 3.1377248191833496
- 2.7700286865234376
- 2.943262720108032
- 2.854114526112874
- 2.7890627733866373
- 2.7860453446706135
- 3.064112113316854
- 3.0212336349487305
- 3.002790390650431
- 2.9013622633616127
- 2.678912320137024
- 2.9594332504272463
- 2.877362756729126
- 3.152415370941162
- 2.9182703177134197
- 3.1956991449991863
- 3.2258976554870604
- 2.890759811401367
train_accuracy:
- 0.0
- 0.065
- 0.077
- 0.185
- 0.01
- 0.096
- 0.131
- 0.104
- 0.002
- 0.037
- 0.077
- 0.065
- 0.004
- 0.396
- 0.113
- 0.01
- 0.044
- 0.263
- 0.079
- 0.019
- 0.115
- 0.388
- 0.056
- 0.127
- 0.296
- 0.125
- 0.402
- 0.085
- 0.123
- 0.073
- 0.348
- 0.04
- 0.085
- 0.55
- 0.137
- 0.585
- 0.377
- 0.044
- 0.117
- 0.079
- 0.485
- 0.142
- 0.079
- 0.106
- 0.054
- 0.325
- 0.102
- 0.073
- 0.106
- 0.496
- 0.106
- 0.535
- 0.029
- 0.569
- 0.456
- 0.558
- 0.144
- 0.056
- 0.525
- 0.031
- 0.131
- 0.454
- 0.144
- 0.544
- 0.131
- 0.083
- 0.092
- 0.083
- 0.077
- 0.058
- 0.71
- 0.14
- 0.067
- 0.119
- 0.121
- 0.569
- 0.142
- 0.098
- 0.081
- 0.146
- 0.562
- 0.135
- 0.098
- 0.135
- 0.127
- 0.671
- 0.625
- 0.123
- 0.11
- 0.652
- 0.054
- 0.59
- 0.092
- 0.108
- 0.683
- 0.083
- 0.583
- 0.719
- 0.665
- 0.119
train_loss:
- 2.096
- 1.253
- 1.052
- 0.89
- 0.944
- 0.816
- 0.853
- 0.781
- 0.76
- 0.729
- 0.728
- 0.7
- 0.675
- 0.692
- 0.61
- 0.626
- 0.601
- 0.593
- 0.623
- 0.567
- 0.539
- 0.62
- 0.562
- 0.542
- 0.543
- 0.542
- 0.564
- 0.526
- 0.516
- 0.517
- 0.515
- 0.478
- 0.506
- 0.5
- 0.512
- 0.489
- 0.486
- 0.452
- 0.486
- 0.47
- 0.44
- 0.468
- 0.408
- 0.489
- 0.459
- 0.463
- 0.446
- 0.413
- 0.404
- 0.44
- 0.446
- 0.426
- 0.438
- 0.449
- 0.411
- 0.416
- 0.429
- 0.396
- 0.384
- 0.44
- 0.426
- 0.386
- 0.432
- 0.399
- 0.403
- 0.398
- 0.398
- 0.375
- 0.387
- 0.38
- 0.382
- 0.338
- 0.362
- 0.383
- 0.388
- 0.381
- 0.358
- 0.379
- 0.369
- 0.379
- 0.342
- 0.397
- 0.35
- 0.381
- 0.381
- 0.366
- 0.342
- 0.319
- 0.381
- 0.348
- 0.314
- 0.361
- 0.326
- 0.357
- 0.373
- 0.341
- 0.38
- 0.339
- 0.364
- 0.34
unequal: 0
verbose: 1
