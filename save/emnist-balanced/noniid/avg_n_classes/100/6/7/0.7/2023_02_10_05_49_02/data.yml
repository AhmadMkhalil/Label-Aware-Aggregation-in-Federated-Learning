avg_train_accuracy: 0.677
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03973404255319149
- 0.07914893617021276
- 0.11324468085106383
- 0.1524468085106383
- 0.14718085106382978
- 0.1798936170212766
- 0.19377659574468084
- 0.25813829787234044
- 0.23095744680851063
- 0.24691489361702126
- 0.24941489361702127
- 0.2324468085106383
- 0.29393617021276597
- 0.2625531914893617
- 0.26218085106382977
- 0.2701063829787234
- 0.3273404255319149
- 0.31851063829787235
- 0.27611702127659576
- 0.30154255319148937
- 0.3374468085106383
- 0.33180851063829786
- 0.30590425531914894
- 0.31170212765957445
- 0.3144148936170213
- 0.32441489361702125
- 0.3301063829787234
- 0.3313829787234043
- 0.35329787234042553
- 0.3506382978723404
- 0.37893617021276593
- 0.3147872340425532
- 0.36361702127659573
- 0.3747872340425532
- 0.38398936170212766
- 0.40085106382978725
- 0.4220212765957447
- 0.34867021276595744
- 0.389468085106383
- 0.42154255319148937
- 0.436436170212766
- 0.3848404255319149
- 0.42404255319148937
- 0.3671276595744681
- 0.4502127659574468
- 0.41058510638297874
- 0.4477127659574468
- 0.4178723404255319
- 0.4678191489361702
- 0.37824468085106383
- 0.36622340425531913
- 0.43611702127659574
- 0.3847340425531915
- 0.43127659574468086
- 0.46808510638297873
- 0.4525
- 0.4872872340425532
- 0.4334574468085106
- 0.4517553191489362
- 0.43622340425531914
- 0.4213297872340426
- 0.3873404255319149
- 0.44563829787234044
- 0.3882978723404255
- 0.43893617021276593
- 0.49803191489361703
- 0.464468085106383
- 0.4892021276595745
- 0.43340425531914895
- 0.44920212765957446
- 0.4908510638297872
- 0.5171808510638298
- 0.45398936170212767
- 0.43707446808510636
- 0.47845744680851066
- 0.4420212765957447
- 0.48904255319148937
- 0.4856382978723404
- 0.42095744680851066
- 0.48696808510638295
- 0.516436170212766
- 0.48861702127659573
- 0.47936170212765955
- 0.4951063829787234
- 0.4190957446808511
- 0.5234042553191489
- 0.514468085106383
- 0.4905851063829787
- 0.44659574468085106
- 0.49813829787234043
- 0.5128191489361702
- 0.5457446808510639
- 0.5051063829787235
- 0.5402659574468085
- 0.4436702127659575
- 0.4972340425531915
- 0.5371808510638297
- 0.48143617021276597
- 0.5240957446808511
- 0.48143617021276597
test_loss_list:
- 4.257940196990967
- 3.82247220993042
- 3.545648603439331
- 3.7431764888763426
- 3.398394314448039
- 3.4961636606852213
- 3.4561835861206056
- 3.1146894772847493
- 3.1891613642374677
- 3.0895099449157715
- 3.308333568572998
- 3.2913043117523193
- 3.0472461477915447
- 3.11238161722819
- 3.127635294596354
- 3.4181039714813233
- 2.821584046681722
- 3.012624209721883
- 3.0194691626230874
- 3.1265721130371094
- 2.8234514490763347
- 3.0112939453125
- 2.9934776973724366
- 3.0504701773325604
- 3.0615608565012615
- 2.957185344696045
- 3.0188216876983645
- 3.0106316725413005
- 3.0249368127187095
- 2.881931562423706
- 2.768103329340617
- 3.077590004603068
- 2.833031717936198
- 2.870389617284139
- 2.776819626490275
- 2.780219300587972
- 2.7152758185068766
- 3.2161886151631673
- 2.853604561487834
- 2.6313879617055256
- 2.6082772159576417
- 2.937310167948405
- 2.723580757776896
- 3.1545633856455484
- 2.6368894799550375
- 2.7983423201243083
- 2.651789665222168
- 2.7156940428415934
- 2.622934039433797
- 2.981008768081665
- 3.06895783106486
- 2.803710511525472
- 3.1129657491048177
- 2.7251899369557697
- 2.631088202794393
- 2.676512540181478
- 2.5987351894378663
- 2.7733487764994305
- 2.7113350009918213
- 2.768529020945231
- 2.8844939422607423
- 3.1412912019093833
- 2.761685361862183
- 3.09061510403951
- 2.7422774537404377
- 2.5957027689615884
- 2.7264319896697997
- 2.698897202809652
- 2.8184856383005776
- 2.8591128094991047
- 2.716275192896525
- 2.6052120876312257
- 2.862831169764201
- 2.915746720631917
- 2.7145361042022706
- 2.807017278671265
- 2.672182003657023
- 2.6737104638417564
- 2.971216630935669
- 2.751523602803548
- 2.5777951113382973
- 2.686617905298869
- 2.7023582649230957
- 2.648783025741577
- 3.042185926437378
- 2.5671263217926024
- 2.633719342549642
- 2.7291224638621014
- 2.9174987061818443
- 2.70073011080424
- 2.6666653537750244
- 2.591759567260742
- 2.781775805155436
- 2.5584463818868
- 3.051074641545614
- 2.8465903695424397
- 2.5917277844746907
- 2.8360730457305907
- 2.7036569213867185
- 2.9235466957092284
train_accuracy:
- 0.154
- 0.0
- 0.208
- 0.225
- 0.108
- 0.046
- 0.033
- 0.335
- 0.023
- 0.048
- 0.0
- 0.335
- 0.483
- 0.544
- 0.058
- 0.396
- 0.106
- 0.421
- 0.002
- 0.071
- 0.544
- 0.019
- 0.069
- 0.083
- 0.373
- 0.444
- 0.054
- 0.075
- 0.46
- 0.094
- 0.035
- 0.01
- 0.088
- 0.117
- 0.065
- 0.017
- 0.075
- 0.546
- 0.092
- 0.056
- 0.035
- 0.115
- 0.042
- 0.123
- 0.062
- 0.625
- 0.085
- 0.698
- 0.504
- 0.104
- 0.631
- 0.104
- 0.562
- 0.052
- 0.052
- 0.096
- 0.075
- 0.646
- 0.492
- 0.027
- 0.477
- 0.585
- 0.098
- 0.61
- 0.756
- 0.062
- 0.067
- 0.11
- 0.058
- 0.121
- 0.088
- 0.046
- 0.117
- 0.66
- 0.125
- 0.106
- 0.119
- 0.033
- 0.0
- 0.642
- 0.119
- 0.671
- 0.625
- 0.121
- 0.085
- 0.077
- 0.04
- 0.05
- 0.081
- 0.69
- 0.117
- 0.027
- 0.123
- 0.656
- 0.106
- 0.623
- 0.079
- 0.794
- 0.133
- 0.677
train_loss:
- 1.818
- 1.164
- 1.017
- 0.897
- 0.887
- 0.816
- 0.761
- 0.728
- 0.736
- 0.716
- 0.679
- 0.701
- 0.64
- 0.645
- 0.649
- 0.597
- 0.601
- 0.574
- 0.592
- 0.585
- 0.56
- 0.551
- 0.57
- 0.566
- 0.55
- 0.522
- 0.525
- 0.535
- 0.503
- 0.544
- 0.507
- 0.495
- 0.519
- 0.507
- 0.476
- 0.464
- 0.463
- 0.486
- 0.495
- 0.443
- 0.427
- 0.459
- 0.433
- 0.441
- 0.434
- 0.458
- 0.458
- 0.46
- 0.411
- 0.45
- 0.432
- 0.441
- 0.42
- 0.429
- 0.41
- 0.431
- 0.395
- 0.416
- 0.391
- 0.414
- 0.392
- 0.392
- 0.372
- 0.402
- 0.446
- 0.388
- 0.36
- 0.358
- 0.384
- 0.413
- 0.392
- 0.369
- 0.381
- 0.403
- 0.402
- 0.412
- 0.376
- 0.356
- 0.381
- 0.377
- 0.362
- 0.366
- 0.374
- 0.353
- 0.384
- 0.368
- 0.339
- 0.374
- 0.348
- 0.36
- 0.368
- 0.348
- 0.332
- 0.351
- 0.353
- 0.331
- 0.328
- 0.374
- 0.333
- 0.361
unequal: 0
verbose: 1
