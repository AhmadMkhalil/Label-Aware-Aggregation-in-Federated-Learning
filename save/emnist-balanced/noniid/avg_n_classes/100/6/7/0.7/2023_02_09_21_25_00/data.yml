avg_train_accuracy: 0.125
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026329787234042553
- 0.0876063829787234
- 0.11106382978723404
- 0.13537234042553192
- 0.14882978723404255
- 0.16452127659574467
- 0.20159574468085106
- 0.21680851063829787
- 0.23696808510638298
- 0.18563829787234043
- 0.22920212765957446
- 0.28106382978723404
- 0.2376595744680851
- 0.28414893617021275
- 0.24654255319148935
- 0.27680851063829787
- 0.2817021276595745
- 0.3051063829787234
- 0.2804255319148936
- 0.29010638297872343
- 0.2923936170212766
- 0.3280851063829787
- 0.26345744680851063
- 0.3389893617021277
- 0.3397872340425532
- 0.32101063829787235
- 0.34867021276595744
- 0.2933510638297872
- 0.3853191489361702
- 0.3826063829787234
- 0.32138297872340427
- 0.386968085106383
- 0.3105851063829787
- 0.3913829787234043
- 0.3952127659574468
- 0.39882978723404255
- 0.3832978723404255
- 0.4276595744680851
- 0.4052659574468085
- 0.3604255319148936
- 0.4101595744680851
- 0.3972872340425532
- 0.4394148936170213
- 0.4006914893617021
- 0.41595744680851066
- 0.4545212765957447
- 0.41882978723404257
- 0.3872340425531915
- 0.4653191489361702
- 0.3857978723404255
- 0.4424468085106383
- 0.4529787234042553
- 0.44335106382978723
- 0.43553191489361703
- 0.3872872340425532
- 0.48186170212765955
- 0.4732446808510638
- 0.45659574468085107
- 0.41319148936170214
- 0.4577127659574468
- 0.43175531914893617
- 0.4198404255319149
- 0.4478723404255319
- 0.4451063829787234
- 0.4375
- 0.44446808510638297
- 0.45313829787234045
- 0.46180851063829786
- 0.46819148936170213
- 0.5197872340425532
- 0.4257446808510638
- 0.4696808510638298
- 0.4881382978723404
- 0.410531914893617
- 0.5206914893617022
- 0.48404255319148937
- 0.4603191489361702
- 0.49601063829787234
- 0.49627659574468086
- 0.4921276595744681
- 0.4922872340425532
- 0.5221808510638298
- 0.43372340425531913
- 0.5414361702127659
- 0.5276595744680851
- 0.4797872340425532
- 0.42148936170212764
- 0.4430851063829787
- 0.4902659574468085
- 0.4676595744680851
- 0.4752659574468085
- 0.5401063829787234
- 0.47382978723404257
- 0.5056914893617022
- 0.5073404255319149
- 0.5202127659574468
- 0.4340425531914894
- 0.5
- 0.4792021276595745
- 0.46356382978723404
test_loss_list:
- 4.13847972869873
- 3.8683109601338703
- 3.691561765670776
- 3.7314912446339927
- 3.4801230589548746
- 3.6861662260691324
- 3.3742676957448325
- 3.3105399131774904
- 3.3805521297454835
- 3.6698396396636963
- 3.2993961079915364
- 3.2602143891652426
- 3.3318299452463784
- 3.1776067924499514
- 3.456960668563843
- 3.040099067687988
- 3.2126617654164633
- 3.1538041973114015
- 3.1867435868581135
- 3.385273183186849
- 3.0690633074442544
- 3.06636526743571
- 3.2809312184651693
- 3.081015698115031
- 3.078854735692342
- 3.2908318614959717
- 3.12896333694458
- 3.4926852862040203
- 2.874369436899821
- 3.0931383196512856
- 3.245754839579264
- 3.0769678433736165
- 3.3288028240203857
- 2.9586282920837403
- 3.0346626059214272
- 2.944695930480957
- 3.0103230381011965
- 2.926599086125692
- 2.84523780186971
- 3.3634768168131512
- 2.91662278175354
- 3.0931437079111737
- 2.87320855140686
- 3.108081407546997
- 3.0295420424143473
- 2.7730431842803953
- 3.1173701349894207
- 3.2189648818969725
- 2.751672430038452
- 3.1956200949350992
- 2.898827823003133
- 2.892130260467529
- 3.030908807118734
- 2.9178691260019938
- 3.4812405172983807
- 2.8234998671213787
- 2.915802024205526
- 2.975020186106364
- 3.2671715513865154
- 2.9973412926991783
- 3.0330010732014974
- 3.1675548426310223
- 3.0881166489919027
- 3.2038783899943035
- 3.0256441243489585
- 3.0311943817138673
- 3.128627395629883
- 2.886823870340983
- 2.987674045562744
- 2.7150393199920653
- 3.340406634012858
- 3.101572593053182
- 2.83498192469279
- 3.4090459219614666
- 2.777367448806763
- 2.968430112202962
- 3.067139759063721
- 2.995689525604248
- 2.871015895207723
- 3.006743189493815
- 2.9116198507944744
- 2.853767630259196
- 3.33621776898702
- 2.731446994145711
- 2.8369319502512615
- 3.0499277750651044
- 3.391657133102417
- 3.1411483160654705
- 2.9607247511545816
- 3.1219211991628013
- 2.928161522547404
- 2.7685503482818605
- 3.171120958328247
- 2.921332349777222
- 3.0225282224019367
- 2.877528870900472
- 3.342212823232015
- 2.9970546849568684
- 3.1033707014719645
- 3.161256586710612
train_accuracy:
- 0.0
- 0.0
- 0.019
- 0.002
- 0.227
- 0.119
- 0.046
- 0.085
- 0.225
- 0.369
- 0.321
- 0.09
- 0.09
- 0.052
- 0.004
- 0.0
- 0.125
- 0.042
- 0.406
- 0.531
- 0.073
- 0.071
- 0.083
- 0.098
- 0.108
- 0.137
- 0.115
- 0.181
- 0.11
- 0.144
- 0.065
- 0.115
- 0.108
- 0.046
- 0.133
- 0.037
- 0.017
- 0.117
- 0.015
- 0.06
- 0.117
- 0.069
- 0.029
- 0.135
- 0.098
- 0.037
- 0.077
- 0.442
- 0.556
- 0.081
- 0.121
- 0.094
- 0.135
- 0.048
- 0.554
- 0.079
- 0.05
- 0.121
- 0.596
- 0.102
- 0.14
- 0.552
- 0.108
- 0.067
- 0.615
- 0.096
- 0.606
- 0.142
- 0.562
- 0.133
- 0.058
- 0.054
- 0.746
- 0.125
- 0.577
- 0.642
- 0.056
- 0.152
- 0.592
- 0.129
- 0.638
- 0.075
- 0.606
- 0.004
- 0.135
- 0.608
- 0.137
- 0.156
- 0.702
- 0.121
- 0.567
- 0.137
- 0.567
- 0.131
- 0.083
- 0.085
- 0.675
- 0.146
- 0.01
- 0.125
train_loss:
- 2.095
- 1.218
- 1.015
- 0.937
- 0.871
- 0.822
- 0.765
- 0.739
- 0.694
- 0.719
- 0.709
- 0.649
- 0.646
- 0.629
- 0.661
- 0.611
- 0.628
- 0.585
- 0.574
- 0.579
- 0.556
- 0.562
- 0.593
- 0.54
- 0.549
- 0.54
- 0.494
- 0.539
- 0.494
- 0.484
- 0.525
- 0.48
- 0.503
- 0.497
- 0.461
- 0.456
- 0.449
- 0.43
- 0.443
- 0.448
- 0.44
- 0.422
- 0.413
- 0.444
- 0.427
- 0.406
- 0.408
- 0.426
- 0.408
- 0.442
- 0.411
- 0.409
- 0.401
- 0.419
- 0.421
- 0.38
- 0.358
- 0.374
- 0.402
- 0.38
- 0.414
- 0.398
- 0.384
- 0.373
- 0.372
- 0.375
- 0.398
- 0.379
- 0.38
- 0.343
- 0.376
- 0.36
- 0.364
- 0.368
- 0.347
- 0.339
- 0.334
- 0.345
- 0.341
- 0.329
- 0.335
- 0.328
- 0.335
- 0.327
- 0.308
- 0.313
- 0.341
- 0.368
- 0.334
- 0.334
- 0.342
- 0.317
- 0.341
- 0.338
- 0.326
- 0.313
- 0.323
- 0.313
- 0.331
- 0.331
unequal: 0
verbose: 1
