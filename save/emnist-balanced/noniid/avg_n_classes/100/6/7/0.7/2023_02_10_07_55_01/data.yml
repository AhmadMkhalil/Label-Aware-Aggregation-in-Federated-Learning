avg_train_accuracy: 0.031
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04297872340425532
- 0.06606382978723405
- 0.1026063829787234
- 0.13085106382978723
- 0.16430851063829788
- 0.19781914893617022
- 0.16638297872340427
- 0.19872340425531915
- 0.1971276595744681
- 0.15888297872340426
- 0.21829787234042553
- 0.25930851063829785
- 0.23686170212765958
- 0.2647340425531915
- 0.20872340425531916
- 0.22952127659574467
- 0.26159574468085106
- 0.29340425531914893
- 0.2973404255319149
- 0.24840425531914895
- 0.29664893617021276
- 0.3266489361702128
- 0.28047872340425534
- 0.32053191489361704
- 0.30398936170212765
- 0.3323936170212766
- 0.3043085106382979
- 0.33085106382978724
- 0.315
- 0.3519148936170213
- 0.35058510638297874
- 0.3484042553191489
- 0.32595744680851063
- 0.37148936170212765
- 0.3998404255319149
- 0.32643617021276594
- 0.3579255319148936
- 0.36659574468085104
- 0.39872340425531916
- 0.3716489361702128
- 0.40595744680851065
- 0.4059042553191489
- 0.33930851063829787
- 0.35606382978723405
- 0.4001595744680851
- 0.42936170212765956
- 0.41143617021276596
- 0.4148936170212766
- 0.4448936170212766
- 0.4103723404255319
- 0.3432978723404255
- 0.4378191489361702
- 0.3951063829787234
- 0.37069148936170215
- 0.41648936170212764
- 0.45218085106382977
- 0.4602127659574468
- 0.4332446808510638
- 0.4262234042553191
- 0.4369148936170213
- 0.39404255319148934
- 0.4232446808510638
- 0.4325531914893617
- 0.47840425531914893
- 0.46797872340425534
- 0.4023936170212766
- 0.4470212765957447
- 0.45478723404255317
- 0.49042553191489363
- 0.4701063829787234
- 0.46382978723404256
- 0.45648936170212767
- 0.46574468085106385
- 0.4226063829787234
- 0.4602127659574468
- 0.45382978723404255
- 0.47723404255319146
- 0.4497340425531915
- 0.45074468085106384
- 0.49127659574468086
- 0.5126595744680851
- 0.4625531914893617
- 0.4653191489361702
- 0.43851063829787235
- 0.47856382978723405
- 0.4072340425531915
- 0.43867021276595747
- 0.5024468085106383
- 0.5345212765957447
- 0.40893617021276596
- 0.476968085106383
- 0.5017021276595744
- 0.47127659574468084
- 0.4844148936170213
- 0.5273404255319148
- 0.4592553191489362
- 0.5448936170212766
- 0.5050531914893617
- 0.42686170212765956
- 0.4429787234042553
test_loss_list:
- 4.125657348632813
- 3.8983641147613524
- 3.785398775736491
- 3.6778578662872317
- 3.572535654703776
- 3.5135358587900796
- 3.5197029399871824
- 3.3560043557484946
- 3.5207109546661375
- 3.45456537882487
- 3.3544036229451497
- 3.2248185729980468
- 3.3706267070770264
- 3.1232957394917804
- 3.425142078399658
- 3.659037014643351
- 3.3224815559387206
- 3.0862108866373696
- 3.179775044123332
- 3.620433276494344
- 3.158028939565023
- 2.9875721899668375
- 3.154221471150716
- 3.121807657877604
- 3.00087197303772
- 3.0197577412923176
- 3.0849765968322753
- 3.085838473637899
- 3.2780881690979005
- 2.8901312065124514
- 2.9994144439697266
- 3.11667805035909
- 3.0707862599690756
- 2.884965705871582
- 2.8093431917826335
- 3.0696895917256675
- 3.006073579788208
- 3.081782464981079
- 2.9329669125874838
- 2.8413693936665854
- 2.928587792714437
- 3.0076101620992026
- 3.073924894332886
- 2.9677885564168296
- 2.8445229434967043
- 2.7486047108968097
- 2.748167349497477
- 2.9397681935628257
- 2.782758232752482
- 2.793654152552287
- 3.0760067462921143
- 2.7252784156799317
- 2.946779670715332
- 3.0501947530110676
- 2.783848314285278
- 2.7290562184651694
- 2.7243033250172934
- 2.8193149280548098
- 2.778405160903931
- 2.8432732582092286
- 3.051422503789266
- 2.818901777267456
- 2.872992115020752
- 2.7053940137227377
- 2.6775260734558106
- 3.0377915287017823
- 2.7812934589385985
- 2.7983936309814452
- 2.6704209073384604
- 2.7560181331634523
- 2.835167169570923
- 2.867746108373006
- 2.783236214319865
- 2.9086175632476805
- 2.7774752521514894
- 2.8737098153432212
- 2.7748597272237143
- 2.7898792616526285
- 2.8157634290059406
- 2.7395298353830975
- 2.6079011567433676
- 2.8634017213185627
- 2.795545736948649
- 2.965742349624634
- 2.8073080666859944
- 3.1368087482452394
- 2.8993201637268067
- 2.655365940729777
- 2.6162681134541828
- 3.209567918777466
- 2.8683813349405924
- 2.760736831029256
- 2.9034806950887044
- 2.8181842740376792
- 2.6830242093404135
- 2.927938944498698
- 2.635668382644653
- 2.772437890370687
- 3.1362620544433595
- 3.1016378593444824
train_accuracy:
- 0.0
- 0.0
- 0.048
- 0.002
- 0.06
- 0.0
- 0.065
- 0.004
- 0.029
- 0.227
- 0.015
- 0.01
- 0.004
- 0.042
- 0.01
- 0.021
- 0.458
- 0.406
- 0.127
- 0.058
- 0.05
- 0.519
- 0.467
- 0.458
- 0.446
- 0.012
- 0.535
- 0.0
- 0.475
- 0.565
- 0.077
- 0.429
- 0.01
- 0.033
- 0.537
- 0.467
- 0.617
- 0.485
- 0.104
- 0.065
- 0.496
- 0.55
- 0.0
- 0.065
- 0.073
- 0.002
- 0.6
- 0.135
- 0.533
- 0.125
- 0.113
- 0.562
- 0.533
- 0.677
- 0.144
- 0.619
- 0.146
- 0.069
- 0.523
- 0.521
- 0.069
- 0.61
- 0.1
- 0.067
- 0.083
- 0.581
- 0.148
- 0.088
- 0.0
- 0.077
- 0.525
- 0.606
- 0.081
- 0.113
- 0.088
- 0.042
- 0.094
- 0.01
- 0.056
- 0.133
- 0.108
- 0.029
- 0.602
- 0.129
- 0.033
- 0.025
- 0.61
- 0.121
- 0.104
- 0.127
- 0.144
- 0.033
- 0.085
- 0.023
- 0.148
- 0.125
- 0.094
- 0.1
- 0.031
- 0.031
train_loss:
- 1.766
- 1.167
- 1.052
- 0.928
- 0.903
- 0.838
- 0.862
- 0.795
- 0.756
- 0.799
- 0.743
- 0.663
- 0.679
- 0.659
- 0.686
- 0.648
- 0.63
- 0.614
- 0.614
- 0.613
- 0.62
- 0.571
- 0.613
- 0.574
- 0.604
- 0.555
- 0.592
- 0.54
- 0.53
- 0.561
- 0.542
- 0.516
- 0.564
- 0.522
- 0.501
- 0.535
- 0.531
- 0.492
- 0.484
- 0.524
- 0.474
- 0.455
- 0.518
- 0.503
- 0.468
- 0.463
- 0.502
- 0.45
- 0.429
- 0.484
- 0.49
- 0.446
- 0.448
- 0.461
- 0.483
- 0.423
- 0.416
- 0.45
- 0.427
- 0.429
- 0.446
- 0.442
- 0.421
- 0.429
- 0.413
- 0.433
- 0.427
- 0.432
- 0.418
- 0.397
- 0.391
- 0.369
- 0.408
- 0.417
- 0.423
- 0.395
- 0.388
- 0.425
- 0.399
- 0.409
- 0.393
- 0.397
- 0.407
- 0.423
- 0.389
- 0.415
- 0.387
- 0.378
- 0.378
- 0.393
- 0.382
- 0.392
- 0.364
- 0.371
- 0.373
- 0.347
- 0.388
- 0.353
- 0.368
- 0.363
unequal: 0
verbose: 1
