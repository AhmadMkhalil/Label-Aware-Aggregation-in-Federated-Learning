avg_train_accuracy: 0.119
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041223404255319146
- 0.09521276595744681
- 0.1297340425531915
- 0.13553191489361702
- 0.17148936170212767
- 0.17632978723404255
- 0.22877659574468084
- 0.2298936170212766
- 0.2323404255319149
- 0.2575531914893617
- 0.2521276595744681
- 0.20441489361702128
- 0.24196808510638299
- 0.23186170212765958
- 0.2500531914893617
- 0.2629787234042553
- 0.2809042553191489
- 0.2979255319148936
- 0.31861702127659575
- 0.3230851063829787
- 0.31329787234042555
- 0.29345744680851066
- 0.33106382978723403
- 0.29627659574468085
- 0.3374468085106383
- 0.3342553191489362
- 0.35148936170212763
- 0.3236702127659574
- 0.3729787234042553
- 0.28877659574468084
- 0.35223404255319146
- 0.4224468085106383
- 0.34404255319148935
- 0.4359574468085106
- 0.39632978723404255
- 0.4428191489361702
- 0.39680851063829786
- 0.4018617021276596
- 0.40382978723404256
- 0.42069148936170214
- 0.4127127659574468
- 0.3743085106382979
- 0.39893617021276595
- 0.4392553191489362
- 0.42909574468085104
- 0.42388297872340425
- 0.4077659574468085
- 0.4405851063829787
- 0.383563829787234
- 0.44446808510638297
- 0.46537234042553194
- 0.37340425531914895
- 0.4318085106382979
- 0.45095744680851063
- 0.38563829787234044
- 0.44563829787234044
- 0.4922872340425532
- 0.45372340425531915
- 0.44398936170212766
- 0.45420212765957446
- 0.39420212765957446
- 0.45382978723404255
- 0.4746808510638298
- 0.4302659574468085
- 0.4785106382978723
- 0.45393617021276594
- 0.3928191489361702
- 0.43367021276595746
- 0.46191489361702126
- 0.47627659574468084
- 0.5000531914893617
- 0.4486702127659574
- 0.49622340425531913
- 0.4043617021276596
- 0.48132978723404257
- 0.4200531914893617
- 0.45904255319148934
- 0.4703723404255319
- 0.4271808510638298
- 0.4537765957446809
- 0.4973404255319149
- 0.45585106382978724
- 0.4870212765957447
- 0.47840425531914893
- 0.46414893617021274
- 0.48638297872340425
- 0.4701063829787234
- 0.4826595744680851
- 0.4747340425531915
- 0.48664893617021276
- 0.4375531914893617
- 0.42223404255319147
- 0.4276595744680851
- 0.4794148936170213
- 0.5102127659574468
- 0.5285106382978724
- 0.5152659574468085
- 0.49920212765957445
- 0.4877659574468085
- 0.43617021276595747
test_loss_list:
- 4.088459771474202
- 3.9145712248484292
- 3.815755402247111
- 3.435904347101847
- 3.3426294390360516
- 3.513221581776937
- 3.138793923060099
- 3.3069995276133217
- 3.2518998114267985
- 3.196306708653768
- 3.0130697854359947
- 3.4222294743855795
- 3.337938454945882
- 3.4744006252288817
- 3.0868983936309813
- 3.1417729663848877
- 3.094142853418986
- 3.073734693527222
- 2.964912503560384
- 2.844166491826375
- 3.1430063088734945
- 3.1279554017384847
- 3.1273369948069254
- 3.0742211055755617
- 3.1618610445658364
- 3.0069374942779543
- 2.9023236560821535
- 2.8873633925120035
- 2.808629341125488
- 3.1803380076090493
- 2.9512628523508706
- 2.7400399907430013
- 2.973200537363688
- 2.710669094721476
- 2.9031378841400146
- 2.714001375834147
- 2.9428327751159666
- 2.9641365337371828
- 2.979417839050293
- 2.9131087557474773
- 2.765738639831543
- 2.961357418696086
- 2.8986787509918215
- 2.674930143356323
- 2.886965986887614
- 2.8359265327453613
- 2.8296482117970783
- 2.784807192484538
- 3.060532519022624
- 2.855586992899577
- 2.6786315059661865
- 3.1759721660614013
- 3.007257118225098
- 2.721041266123454
- 2.9964321581522624
- 2.7785527896881104
- 2.7764121119181313
- 2.8986279074350993
- 2.8170407072703045
- 2.866129000981649
- 3.1292118994394937
- 2.768012472788493
- 2.8514095560709634
- 3.1147332604726157
- 2.7353948465983073
- 2.8889453411102295
- 3.229264039993286
- 3.048845373789469
- 2.952930065790812
- 2.9245683479309084
- 2.8515928904215495
- 3.0868447081247967
- 2.7175496419270835
- 3.1518914477030435
- 2.89736722946167
- 3.231802085240682
- 3.041780627568563
- 2.9738420327504476
- 3.0217981783548993
- 3.0303790092468263
- 2.7971842288970947
- 3.0198959159851073
- 2.9167953523000083
- 2.8816411304473877
- 2.9709221680959064
- 2.82892352104187
- 2.9877099577585855
- 2.994094432195028
- 3.004683443705241
- 2.869806760152181
- 3.249433224995931
- 3.2816454569498696
- 3.1145971838633217
- 2.7801293913523355
- 2.9890209738413493
- 2.7391231791178385
- 2.8253256479899087
- 2.934461177190145
- 2.888532832463582
- 3.1372484906514484
train_accuracy:
- 0.012
- 0.0
- 0.012
- 0.0
- 0.062
- 0.021
- 0.021
- 0.019
- 0.304
- 0.058
- 0.198
- 0.075
- 0.237
- 0.09
- 0.09
- 0.096
- 0.06
- 0.083
- 0.425
- 0.027
- 0.102
- 0.417
- 0.05
- 0.506
- 0.083
- 0.071
- 0.44
- 0.037
- 0.065
- 0.067
- 0.085
- 0.081
- 0.096
- 0.071
- 0.548
- 0.056
- 0.131
- 0.094
- 0.119
- 0.115
- 0.088
- 0.098
- 0.1
- 0.079
- 0.129
- 0.113
- 0.59
- 0.073
- 0.569
- 0.604
- 0.096
- 0.088
- 0.083
- 0.604
- 0.65
- 0.071
- 0.581
- 0.642
- 0.1
- 0.108
- 0.625
- 0.125
- 0.652
- 0.14
- 0.115
- 0.094
- 0.096
- 0.11
- 0.113
- 0.115
- 0.135
- 0.1
- 0.092
- 0.612
- 0.131
- 0.121
- 0.113
- 0.117
- 0.61
- 0.104
- 0.104
- 0.121
- 0.125
- 0.133
- 0.077
- 0.121
- 0.585
- 0.1
- 0.588
- 0.638
- 0.102
- 0.133
- 0.094
- 0.117
- 0.688
- 0.135
- 0.665
- 0.131
- 0.096
- 0.119
train_loss:
- 1.879
- 1.162
- 1.047
- 0.928
- 0.849
- 0.835
- 0.755
- 0.764
- 0.69
- 0.672
- 0.68
- 0.697
- 0.679
- 0.649
- 0.657
- 0.656
- 0.614
- 0.624
- 0.57
- 0.617
- 0.569
- 0.578
- 0.529
- 0.603
- 0.536
- 0.551
- 0.551
- 0.572
- 0.513
- 0.538
- 0.542
- 0.467
- 0.502
- 0.455
- 0.476
- 0.467
- 0.466
- 0.452
- 0.44
- 0.439
- 0.453
- 0.459
- 0.474
- 0.451
- 0.435
- 0.426
- 0.445
- 0.425
- 0.464
- 0.443
- 0.422
- 0.443
- 0.416
- 0.448
- 0.452
- 0.435
- 0.376
- 0.395
- 0.417
- 0.412
- 0.436
- 0.418
- 0.372
- 0.392
- 0.385
- 0.399
- 0.414
- 0.387
- 0.373
- 0.368
- 0.348
- 0.363
- 0.378
- 0.407
- 0.382
- 0.392
- 0.378
- 0.351
- 0.396
- 0.359
- 0.357
- 0.367
- 0.366
- 0.37
- 0.359
- 0.379
- 0.354
- 0.354
- 0.365
- 0.366
- 0.341
- 0.343
- 0.377
- 0.371
- 0.323
- 0.344
- 0.334
- 0.356
- 0.348
- 0.37
unequal: 0
verbose: 1
