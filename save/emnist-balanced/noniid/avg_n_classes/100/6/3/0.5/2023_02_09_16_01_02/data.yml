avg_train_accuracy: 0.844
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04526595744680851
- 0.1494148936170213
- 0.2673936170212766
- 0.3548404255319149
- 0.33920212765957447
- 0.34319148936170213
- 0.3917553191489362
- 0.4040957446808511
- 0.39218085106382977
- 0.4072872340425532
- 0.4217021276595745
- 0.42601063829787233
- 0.4348936170212766
- 0.4477659574468085
- 0.4492553191489362
- 0.4397872340425532
- 0.4573404255319149
- 0.451063829787234
- 0.4625531914893617
- 0.46537234042553194
- 0.4643617021276596
- 0.4723936170212766
- 0.4777659574468085
- 0.473031914893617
- 0.48271276595744683
- 0.47845744680851066
- 0.48617021276595745
- 0.4921276595744681
- 0.4849468085106383
- 0.4922340425531915
- 0.49851063829787234
- 0.4955851063829787
- 0.4973936170212766
- 0.5036170212765958
- 0.5131914893617021
- 0.5102127659574468
- 0.5048936170212766
- 0.5067553191489361
- 0.5139893617021276
- 0.5221808510638298
- 0.5379787234042553
- 0.5124468085106383
- 0.5089361702127659
- 0.506968085106383
- 0.5071808510638298
- 0.515
- 0.5152659574468085
- 0.5218085106382979
- 0.521436170212766
- 0.5471808510638297
- 0.5303723404255319
- 0.533031914893617
- 0.5159574468085106
- 0.5241489361702127
- 0.5472340425531915
- 0.5173404255319148
- 0.5463297872340426
- 0.549468085106383
- 0.5199468085106383
- 0.5356382978723404
- 0.5298936170212766
- 0.5401063829787234
- 0.5652127659574468
- 0.5190957446808511
- 0.5534042553191489
- 0.5533510638297873
- 0.5391489361702128
- 0.5251595744680851
- 0.543563829787234
- 0.5598404255319149
- 0.5269148936170213
- 0.5304255319148936
- 0.5412234042553191
- 0.5453191489361702
- 0.5361702127659574
- 0.5297340425531915
- 0.5318617021276596
- 0.5350531914893617
- 0.5390957446808511
- 0.5290425531914894
- 0.5275531914893618
- 0.5551595744680851
- 0.5607446808510639
- 0.546968085106383
- 0.5782446808510638
- 0.5916489361702127
- 0.555531914893617
- 0.5348404255319149
- 0.5579255319148936
- 0.5907446808510638
- 0.5774468085106383
- 0.5798404255319148
- 0.5791489361702128
- 0.5288829787234043
- 0.5802659574468085
- 0.5562765957446808
- 0.556968085106383
- 0.5528191489361702
- 0.5540957446808511
- 0.5447872340425531
test_loss_list:
- 3.8200283908843993
- 3.6676385021209716
- 3.4723753197987874
- 3.652813145319621
- 3.1477052783966064
- 2.9435414282480874
- 3.2110100269317625
- 3.1967911593119305
- 2.8500026003519694
- 2.8139555009206134
- 3.34020689646403
- 2.8052995427449545
- 2.841921704610189
- 3.278484334945679
- 3.051998872756958
- 2.6418117554982503
- 3.139169257481893
- 2.5908929951985677
- 3.262383998235067
- 3.0891465028127034
- 2.597085568110148
- 2.665620845158895
- 2.685492534637451
- 2.50563193321228
- 3.1402158832550047
- 2.991031125386556
- 3.0055301284790037
- 2.581835397084554
- 2.6119434801737467
- 2.4495322863260904
- 2.468160104751587
- 2.5305584081014
- 3.7682194995880125
- 2.5115941270192463
- 2.2602732594807944
- 2.5485780239105225
- 2.9936576652526856
- 2.403739964167277
- 2.515742743810018
- 2.5181593958536785
- 2.158282543818156
- 2.9344136619567873
- 3.8096111011505127
- 3.054634526570638
- 2.9190368620554605
- 2.4872630882263183
- 3.079903065363566
- 2.3368043184280394
- 2.474368896484375
- 2.0944327529271445
- 2.4084311135609946
- 2.401555576324463
- 2.8102460384368895
- 2.848373072942098
- 2.360819608370463
- 2.9367107009887694
- 2.4228747685750327
- 2.3487660201390583
- 3.694693930943807
- 2.8720562585194904
- 3.0999504470825197
- 3.0421042156219484
- 2.196836689313253
- 3.7115016841888426
- 2.425596615473429
- 2.436455046335856
- 3.006063919067383
- 2.8433050886789957
- 2.8866479937235514
- 2.458309914271037
- 2.812074998219808
- 2.88096204439799
- 2.354448602994283
- 2.3824665609995526
- 2.783175080617269
- 2.762515303293864
- 2.8224120998382567
- 2.92899972597758
- 2.7511529127756753
- 2.804989827473958
- 3.7278410720825197
- 2.3921046829223633
- 2.3632904958724974
- 2.8861570262908938
- 2.3480377689997356
- 2.1009068504969277
- 2.809331839879354
- 2.750304053624471
- 2.784148734410604
- 2.0728941408793133
- 2.37840341091156
- 2.351034723917643
- 2.3167180029551186
- 3.5434738286336263
- 2.2778527816136678
- 2.8165800189971923
- 2.909375187555949
- 2.2988408915201823
- 2.35113481203715
- 2.7419971879323324
train_accuracy:
- 0.085
- 0.263
- 0.479
- 0.608
- 0.548
- 0.598
- 0.642
- 0.646
- 0.0
- 0.642
- 0.0
- 0.0
- 0.66
- 0.708
- 0.723
- 0.694
- 0.0
- 0.0
- 0.721
- 0.79
- 0.0
- 0.735
- 0.721
- 0.0
- 0.763
- 0.779
- 0.0
- 0.798
- 0.0
- 0.0
- 0.808
- 0.008
- 0.856
- 0.017
- 0.0
- 0.806
- 0.804
- 0.787
- 0.798
- 0.025
- 0.0
- 0.023
- 0.829
- 0.0
- 0.84
- 0.81
- 0.844
- 0.808
- 0.817
- 0.0
- 0.0
- 0.806
- 0.858
- 0.831
- 0.829
- 0.842
- 0.0
- 0.806
- 0.846
- 0.883
- 0.027
- 0.846
- 0.0
- 0.835
- 0.835
- 0.819
- 0.042
- 0.829
- 0.892
- 0.846
- 0.858
- 0.852
- 0.84
- 0.852
- 0.85
- 0.0
- 0.852
- 0.852
- 0.854
- 0.858
- 0.896
- 0.0
- 0.052
- 0.037
- 0.85
- 0.848
- 0.852
- 0.858
- 0.058
- 0.85
- 0.854
- 0.858
- 0.0
- 0.863
- 0.056
- 0.044
- 0.844
- 0.85
- 0.842
- 0.844
train_loss:
- 3.335
- 2.655
- 2.636
- 2.575
- 1.795
- 1.496
- 1.775
- 1.656
- 1.482
- 1.409
- 1.584
- 1.286
- 1.237
- 1.408
- 1.365
- 1.242
- 1.285
- 1.182
- 1.299
- 1.235
- 1.105
- 1.063
- 1.029
- 1.063
- 1.185
- 1.2
- 1.11
- 0.965
- 1.023
- 0.961
- 0.965
- 0.983
- 1.196
- 0.985
- 0.809
- 0.934
- 1.035
- 0.899
- 0.916
- 0.889
- 0.76
- 0.997
- 1.094
- 0.981
- 0.968
- 0.844
- 0.954
- 0.869
- 0.812
- 0.719
- 0.801
- 0.788
- 0.959
- 0.933
- 0.816
- 0.917
- 0.819
- 0.805
- 1.007
- 0.913
- 0.887
- 0.886
- 0.708
- 0.982
- 0.801
- 0.779
- 0.877
- 0.858
- 0.881
- 0.784
- 0.859
- 0.836
- 0.742
- 0.726
- 0.858
- 0.847
- 0.826
- 0.807
- 0.848
- 0.842
- 0.922
- 0.775
- 0.737
- 0.845
- 0.733
- 0.63
- 0.833
- 0.826
- 0.819
- 0.639
- 0.722
- 0.727
- 0.716
- 0.91
- 0.726
- 0.8
- 0.8
- 0.72
- 0.695
- 0.772
unequal: 0
verbose: 1
