avg_train_accuracy: 0.829
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03148936170212766
- 0.07792553191489361
- 0.2655851063829787
- 0.3042021276595745
- 0.3326063829787234
- 0.36819148936170215
- 0.4032978723404255
- 0.37574468085106383
- 0.39228723404255317
- 0.4027127659574468
- 0.4142021276595745
- 0.42648936170212765
- 0.42569148936170215
- 0.4374468085106383
- 0.44329787234042556
- 0.44898936170212767
- 0.443563829787234
- 0.4566489361702128
- 0.4706382978723404
- 0.47382978723404257
- 0.47723404255319146
- 0.4702659574468085
- 0.4727127659574468
- 0.47632978723404257
- 0.47462765957446806
- 0.4721808510638298
- 0.4807446808510638
- 0.4856382978723404
- 0.4946808510638298
- 0.48914893617021277
- 0.48936170212765956
- 0.4925
- 0.4957446808510638
- 0.49792553191489364
- 0.502127659574468
- 0.5027659574468085
- 0.5046276595744681
- 0.5038829787234043
- 0.5009574468085106
- 0.5067021276595745
- 0.5053191489361702
- 0.516436170212766
- 0.5061702127659574
- 0.5231914893617021
- 0.5125531914893617
- 0.5350531914893617
- 0.5072340425531915
- 0.5151595744680851
- 0.5076063829787234
- 0.5089361702127659
- 0.5348936170212766
- 0.5415425531914894
- 0.518031914893617
- 0.5586170212765957
- 0.5554255319148936
- 0.5207978723404255
- 0.5495212765957447
- 0.5348936170212766
- 0.5131382978723404
- 0.5297340425531915
- 0.5178723404255319
- 0.5313829787234042
- 0.523936170212766
- 0.549468085106383
- 0.5381914893617021
- 0.5692553191489361
- 0.5266489361702128
- 0.5548404255319149
- 0.5731382978723404
- 0.5464893617021277
- 0.5476063829787234
- 0.5525531914893617
- 0.545
- 0.555531914893617
- 0.5823404255319149
- 0.5344148936170213
- 0.5324468085106383
- 0.522127659574468
- 0.5350531914893617
- 0.5608510638297872
- 0.5417553191489362
- 0.5213829787234042
- 0.5517553191489362
- 0.5230851063829787
- 0.5287234042553192
- 0.5252659574468085
- 0.5382446808510638
- 0.5293617021276595
- 0.5293085106382979
- 0.5362765957446809
- 0.5692021276595745
- 0.5378723404255319
- 0.5759042553191489
- 0.5743085106382979
- 0.5575531914893617
- 0.5729255319148936
- 0.5583510638297873
- 0.5307446808510639
- 0.5317021276595745
- 0.5345744680851063
test_loss_list:
- 3.821100050608317
- 3.761077340443929
- 3.7205473709106447
- 3.4965318775177003
- 3.1727069282531737
- 3.3312348747253417
- 3.895620781580607
- 2.999359334309896
- 2.7134478092193604
- 2.9038146209716795
- 2.557015415827433
- 2.707212972640991
- 2.694591433207194
- 2.6585089683532717
- 3.03401437441508
- 2.542907781600952
- 2.6231190172831216
- 3.078267567952474
- 3.9677335325876872
- 4.048660570780436
- 4.135692370732626
- 3.197872444788615
- 3.1843878809611
- 3.1398069794972736
- 2.60760503133138
- 2.617908175786336
- 3.0248628997802736
- 2.994029343922933
- 2.5486471780141193
- 2.958533935546875
- 3.065088653564453
- 3.014377867380778
- 3.0613029925028483
- 3.1579757277170817
- 4.124705231984456
- 2.5668118031819662
- 4.0057275644938155
- 3.189801575342814
- 3.00123259862264
- 3.020875898996989
- 2.4998856671651204
- 2.4239260387420654
- 2.500723021825155
- 2.4593145497639974
- 2.9676562627156575
- 2.455817715326945
- 2.901239995956421
- 2.9525248114267986
- 2.933061615626017
- 3.030295454661051
- 2.088002716700236
- 2.0888356304168703
- 2.9842557843526203
- 1.9868384822209677
- 2.0172477436065672
- 2.956679360071818
- 2.3363343890508017
- 2.2944043334325155
- 2.8670950730641684
- 2.2994111585617065
- 2.80893580754598
- 2.3091156593958537
- 3.0071656322479248
- 2.36041933854421
- 2.2902491521835326
- 2.0051895221074423
- 2.869561580022176
- 2.3425750398635863
- 1.99910578250885
- 2.245787885983785
- 2.268969496091207
- 2.3017052014668784
- 2.2497168970108032
- 2.1905906565984092
- 1.9427380084991455
- 2.771079028447469
- 2.804048328399658
- 3.7843405914306643
- 2.913442290623983
- 2.373893982569377
- 2.378352263768514
- 2.8561074352264404
- 2.264119963645935
- 3.7687573623657227
- 2.752407735188802
- 2.906552740732829
- 2.356964863141378
- 2.759295701980591
- 2.8975889174143474
- 2.902654504776001
- 2.3084533055623373
- 2.8310125414530436
- 2.313159770965576
- 2.408924198150635
- 2.2255016390482583
- 2.3136181020736695
- 2.2595761887232464
- 2.8376823075612387
- 2.853128360112508
- 2.8013250414530435
train_accuracy:
- 0.062
- 0.129
- 0.373
- 0.467
- 0.569
- 0.581
- 0.671
- 0.0
- 0.652
- 0.665
- 0.0
- 0.692
- 0.681
- 0.688
- 0.708
- 0.723
- 0.71
- 0.725
- 0.76
- 0.767
- 0.781
- 0.769
- 0.0
- 0.773
- 0.002
- 0.0
- 0.815
- 0.0
- 0.781
- 0.779
- 0.794
- 0.833
- 0.798
- 0.808
- 0.825
- 0.0
- 0.823
- 0.004
- 0.804
- 0.0
- 0.81
- 0.804
- 0.817
- 0.0
- 0.0
- 0.0
- 0.85
- 0.798
- 0.808
- 0.0
- 0.008
- 0.008
- 0.81
- 0.021
- 0.0
- 0.844
- 0.831
- 0.81
- 0.0
- 0.817
- 0.825
- 0.0
- 0.827
- 0.0
- 0.0
- 0.842
- 0.829
- 0.01
- 0.856
- 0.0
- 0.842
- 0.829
- 0.825
- 0.006
- 0.015
- 0.85
- 0.838
- 0.844
- 0.842
- 0.812
- 0.0
- 0.865
- 0.0
- 0.85
- 0.854
- 0.848
- 0.0
- 0.0
- 0.833
- 0.867
- 0.838
- 0.829
- 0.0
- 0.0
- 0.854
- 0.812
- 0.854
- 0.835
- 0.831
- 0.829
train_loss:
- 3.416
- 2.807
- 3.18
- 2.351
- 1.844
- 1.958
- 1.99
- 1.496
- 1.226
- 1.329
- 1.122
- 1.266
- 1.24
- 1.183
- 1.344
- 1.147
- 1.133
- 1.26
- 1.398
- 1.352
- 1.323
- 1.168
- 1.155
- 1.16
- 0.99
- 0.967
- 1.094
- 1.056
- 0.94
- 1.078
- 1.052
- 1.061
- 1.016
- 0.993
- 1.107
- 0.887
- 1.105
- 0.973
- 0.975
- 0.966
- 0.88
- 0.858
- 0.834
- 0.824
- 0.935
- 0.801
- 0.953
- 0.915
- 0.924
- 0.917
- 0.7
- 0.67
- 0.873
- 0.669
- 0.651
- 0.864
- 0.755
- 0.773
- 0.883
- 0.758
- 0.878
- 0.755
- 0.833
- 0.734
- 0.773
- 0.622
- 0.839
- 0.718
- 0.617
- 0.741
- 0.724
- 0.723
- 0.722
- 0.722
- 0.611
- 0.827
- 0.802
- 0.923
- 0.812
- 0.705
- 0.708
- 0.817
- 0.708
- 0.913
- 0.801
- 0.802
- 0.699
- 0.8
- 0.774
- 0.766
- 0.689
- 0.769
- 0.674
- 0.657
- 0.705
- 0.659
- 0.682
- 0.784
- 0.78
- 0.768
unequal: 0
verbose: 1
