avg_train_accuracy: 0.008
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03276595744680851
- 0.12728723404255318
- 0.19914893617021276
- 0.2527659574468085
- 0.31457446808510636
- 0.3511170212765957
- 0.36021276595744683
- 0.3898936170212766
- 0.39920212765957447
- 0.4072340425531915
- 0.4142021276595745
- 0.42654255319148937
- 0.43670212765957445
- 0.4470212765957447
- 0.4429787234042553
- 0.4526595744680851
- 0.4596276595744681
- 0.47335106382978726
- 0.45952127659574465
- 0.46702127659574466
- 0.4696808510638298
- 0.49606382978723407
- 0.4826595744680851
- 0.4782446808510638
- 0.5103191489361703
- 0.48877659574468085
- 0.5101063829787233
- 0.4869148936170213
- 0.5162765957446809
- 0.5231382978723405
- 0.5322872340425532
- 0.5233510638297872
- 0.5416489361702128
- 0.5404255319148936
- 0.5100531914893617
- 0.5531914893617021
- 0.5051595744680851
- 0.5360106382978723
- 0.5511702127659575
- 0.5136702127659575
- 0.5564893617021277
- 0.5352127659574468
- 0.5651595744680851
- 0.5369680851063829
- 0.5302127659574468
- 0.5420744680851064
- 0.511968085106383
- 0.5445744680851063
- 0.5709574468085107
- 0.546595744680851
- 0.5127127659574469
- 0.5297340425531915
- 0.5447872340425531
- 0.5475
- 0.5626595744680851
- 0.5174468085106383
- 0.5180851063829788
- 0.5307978723404255
- 0.5255851063829787
- 0.5842021276595745
- 0.5170212765957447
- 0.5344148936170213
- 0.5301063829787234
- 0.5615425531914894
- 0.585531914893617
- 0.5687234042553192
- 0.573031914893617
- 0.5740425531914893
- 0.5429787234042553
- 0.5401063829787234
- 0.5873936170212766
- 0.5928723404255319
- 0.6
- 0.5204255319148936
- 0.546063829787234
- 0.5672872340425532
- 0.5542021276595744
- 0.5974468085106382
- 0.5778191489361703
- 0.5821808510638298
- 0.5742553191489361
- 0.606968085106383
- 0.5795212765957447
- 0.5574468085106383
- 0.5512234042553191
- 0.529468085106383
- 0.5962765957446808
- 0.5725
- 0.6068085106382979
- 0.579627659574468
- 0.5868085106382979
- 0.5604255319148936
- 0.5318085106382979
- 0.5763297872340426
- 0.5816489361702127
- 0.6091489361702128
- 0.58
- 0.561968085106383
- 0.5660106382978723
- 0.5536170212765957
test_loss_list:
- 3.7912317434946696
- 3.703391669591268
- 3.436749054590861
- 3.075144430796305
- 2.9763054529825848
- 2.913737392425537
- 2.684305985768636
- 2.7995032501220702
- 2.5327408854166666
- 2.6788218530019123
- 2.6049789015452065
- 2.638389368057251
- 2.3441019821166993
- 2.3295152028401693
- 2.9879018433888755
- 2.430864423116048
- 2.5601934878031414
- 2.207724610964457
- 2.4906262365976968
- 2.383031489054362
- 2.9147345193227134
- 2.1143249384562175
- 2.532746108373006
- 2.9623858165740966
- 2.0794484599431358
- 2.979702803293864
- 2.4199582449595134
- 2.3763461128870644
- 2.1068598969777423
- 2.0874408435821534
- 2.062485065460205
- 2.382765677769979
- 2.0178486013412478
- 2.0633804337183634
- 2.9302343845367433
- 1.9869781827926636
- 2.337196470896403
- 2.3074637985229494
- 2.013167463938395
- 2.2734536790847777
- 1.9496681102116902
- 2.3602765385309854
- 1.9574369684855144
- 2.3871596336364744
- 2.14755185286204
- 2.312652676900228
- 2.7088973331451416
- 2.295779816309611
- 1.9566139268875122
- 2.3822317123413086
- 2.7283810710906984
- 2.1799492820103965
- 2.341302049954732
- 2.2895492919286093
- 2.2879579957326253
- 2.7217890548706056
- 2.675482177734375
- 2.241216786702474
- 2.8765741284688313
- 1.9239958953857421
- 3.6601989142100018
- 2.203940415382385
- 2.867648649215698
- 2.310546908378601
- 1.9936405086517335
- 2.28920095761617
- 2.266026366551717
- 2.359385544459025
- 2.2161892541249593
- 2.2054271856943766
- 1.9298746315638224
- 1.9578285646438598
- 1.9174843295415243
- 3.5799323908487954
- 2.839758145014445
- 2.3637996085484825
- 2.9152070554097493
- 1.9986101611455283
- 2.3423247448603313
- 2.3069985326131186
- 2.307992738087972
- 1.9473796876271565
- 2.3273594268163045
- 2.163083612124125
- 2.196319662729899
- 2.764663667678833
- 1.8690744813283284
- 2.2822022024790445
- 1.942846204439799
- 2.3100958824157716
- 2.2448639742533367
- 2.171005506515503
- 2.656989501317342
- 2.2367713769276936
- 2.3162695201237997
- 1.91924121538798
- 2.300052348772685
- 2.851923122406006
- 2.1275261576970417
- 2.2236305856704712
train_accuracy:
- 0.004
- 0.0
- 0.325
- 0.0
- 0.487
- 0.548
- 0.54
- 0.633
- 0.642
- 0.677
- 0.0
- 0.729
- 0.71
- 0.723
- 0.721
- 0.725
- 0.713
- 0.725
- 0.0
- 0.754
- 0.74
- 0.037
- 0.779
- 0.735
- 0.729
- 0.808
- 0.79
- 0.771
- 0.777
- 0.744
- 0.048
- 0.802
- 0.744
- 0.0
- 0.838
- 0.806
- 0.796
- 0.829
- 0.01
- 0.835
- 0.777
- 0.8
- 0.781
- 0.796
- 0.0
- 0.817
- 0.84
- 0.835
- 0.0
- 0.785
- 0.821
- 0.002
- 0.808
- 0.81
- 0.831
- 0.829
- 0.808
- 0.835
- 0.021
- 0.827
- 0.848
- 0.827
- 0.815
- 0.0
- 0.838
- 0.848
- 0.848
- 0.848
- 0.012
- 0.817
- 0.0
- 0.021
- 0.058
- 0.85
- 0.854
- 0.823
- 0.831
- 0.0
- 0.004
- 0.844
- 0.854
- 0.012
- 0.842
- 0.867
- 0.846
- 0.821
- 0.052
- 0.865
- 0.856
- 0.844
- 0.838
- 0.844
- 0.838
- 0.835
- 0.846
- 0.062
- 0.854
- 0.865
- 0.833
- 0.008
train_loss:
- 3.239
- 3.06
- 2.671
- 2.022
- 2.031
- 1.868
- 1.523
- 1.635
- 1.379
- 1.494
- 1.437
- 1.417
- 1.209
- 1.174
- 1.444
- 1.269
- 1.231
- 1.084
- 1.191
- 1.169
- 1.289
- 1.03
- 1.125
- 1.221
- 0.984
- 1.192
- 1.068
- 1.049
- 0.917
- 0.9
- 0.885
- 1.001
- 0.886
- 0.861
- 1.075
- 0.874
- 0.948
- 0.947
- 0.844
- 0.929
- 0.825
- 0.918
- 0.812
- 0.915
- 0.901
- 0.896
- 0.993
- 0.887
- 0.779
- 0.861
- 0.962
- 0.853
- 0.857
- 0.86
- 0.843
- 0.936
- 0.922
- 0.822
- 0.919
- 0.738
- 0.999
- 0.824
- 0.897
- 0.808
- 0.727
- 0.8
- 0.799
- 0.782
- 0.792
- 0.786
- 0.701
- 0.697
- 0.691
- 0.96
- 0.861
- 0.783
- 0.843
- 0.689
- 0.755
- 0.764
- 0.769
- 0.668
- 0.749
- 0.76
- 0.747
- 0.822
- 0.68
- 0.739
- 0.664
- 0.735
- 0.75
- 0.737
- 0.819
- 0.734
- 0.718
- 0.658
- 0.729
- 0.798
- 0.735
- 0.725
unequal: 0
verbose: 1
