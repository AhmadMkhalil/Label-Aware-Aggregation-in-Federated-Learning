avg_train_accuracy: 0.825
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03803191489361702
- 0.10792553191489361
- 0.22797872340425532
- 0.28579787234042553
- 0.35132978723404257
- 0.3410106382978723
- 0.37792553191489364
- 0.3980851063829787
- 0.38776595744680853
- 0.400531914893617
- 0.4009042553191489
- 0.41829787234042554
- 0.4297872340425532
- 0.4217021276595745
- 0.4403723404255319
- 0.4323404255319149
- 0.4368085106382979
- 0.44409574468085106
- 0.4487765957446809
- 0.4551063829787234
- 0.4645744680851064
- 0.46627659574468083
- 0.4625
- 0.4638829787234043
- 0.4833510638297872
- 0.48367021276595745
- 0.4825531914893617
- 0.4846276595744681
- 0.4845212765957447
- 0.4858510638297872
- 0.5038829787234043
- 0.49319148936170215
- 0.5011702127659574
- 0.5184042553191489
- 0.5053723404255319
- 0.5311170212765958
- 0.48558510638297875
- 0.5082978723404256
- 0.5117553191489361
- 0.5025531914893617
- 0.5179255319148937
- 0.5108510638297873
- 0.5113297872340425
- 0.5217553191489361
- 0.5491489361702128
- 0.4972340425531915
- 0.5038297872340426
- 0.5413829787234042
- 0.5258510638297872
- 0.5259574468085106
- 0.5606914893617021
- 0.503031914893617
- 0.5325
- 0.5263829787234042
- 0.5047872340425532
- 0.5313829787234042
- 0.5389893617021276
- 0.5706382978723404
- 0.5719148936170213
- 0.5429787234042553
- 0.5378191489361702
- 0.5372872340425532
- 0.5122872340425532
- 0.5348936170212766
- 0.543936170212766
- 0.576968085106383
- 0.5464893617021277
- 0.5930319148936171
- 0.5246808510638298
- 0.5496808510638298
- 0.5212234042553191
- 0.5525
- 0.5863297872340425
- 0.5536170212765957
- 0.5523404255319149
- 0.5127659574468085
- 0.5462234042553191
- 0.5482978723404255
- 0.5454787234042553
- 0.5515425531914894
- 0.551595744680851
- 0.5550531914893617
- 0.5548404255319149
- 0.5555851063829788
- 0.5631382978723404
- 0.5359574468085107
- 0.5303723404255319
- 0.564468085106383
- 0.5357978723404255
- 0.5645212765957447
- 0.5866489361702127
- 0.5676063829787235
- 0.5980851063829787
- 0.5998936170212766
- 0.5287765957446808
- 0.5670212765957446
- 0.5678191489361702
- 0.5578723404255319
- 0.5736702127659574
- 0.5735106382978723
test_loss_list:
- 3.768343130747477
- 3.607857577006022
- 3.3254334195454915
- 3.0156317647298176
- 3.2426267147064207
- 2.7902455075581867
- 2.896397294998169
- 3.0682302633921306
- 2.7182781092325845
- 2.7787768014272056
- 2.5426295948028566
- 2.714762388865153
- 3.117232780456543
- 2.659271796544393
- 3.232591962814331
- 2.6379804452260336
- 2.4915756861368816
- 2.642048708597819
- 2.620962521235148
- 2.379263604482015
- 2.330383752187093
- 2.306774133046468
- 2.4720770104726157
- 2.5541683292388915
- 2.1926466449101767
- 2.2232159121831256
- 2.5104115041097006
- 2.544910996754964
- 2.325297425587972
- 2.4186181831359863
- 2.1516724157333376
- 2.503840847015381
- 2.3235509745279948
- 2.0860335652033486
- 2.447216453552246
- 2.0306212202707927
- 2.778390464782715
- 2.340554140408834
- 2.311572477022807
- 2.2868252070744832
- 2.326574575106303
- 2.279066465695699
- 2.295866823196411
- 2.327329004605611
- 1.9586456966400148
- 3.5848545392354327
- 2.9029973538716636
- 1.983563675880432
- 2.3860779190063477
- 2.1902612686157226
- 1.9226085011164347
- 2.7063741493225097
- 2.245368088086446
- 2.244552640914917
- 2.7225677490234377
- 2.2492089001337687
- 2.3283043066660563
- 1.9195210568110148
- 1.9501305373509725
- 2.223740839958191
- 2.155695843696594
- 2.209263946215312
- 2.726616512934367
- 2.2682328621546426
- 2.2380705229441324
- 1.9178951644897462
- 2.27590873559316
- 1.837191047668457
- 2.7683725992838544
- 2.157149675687154
- 2.76569793065389
- 2.1795593388875325
- 1.8859779294331869
- 2.267516352335612
- 2.121896177927653
- 3.5648641109466555
- 2.2502838134765626
- 2.2033306964238486
- 2.211802067756653
- 2.211891776720683
- 2.2432283131281534
- 2.278139853477478
- 2.176368091901143
- 2.2385928440093994
- 2.2287909825642904
- 2.7421046670277915
- 2.7952994378407796
- 2.322712370554606
- 2.833875986735026
- 2.3538948011398317
- 1.9349513022104898
- 2.3336366828282675
- 1.8749588886896769
- 1.9092856311798097
- 2.6308508936564126
- 2.1589354912439984
- 2.223909029960632
- 2.185607802073161
- 2.1399401092529295
- 2.2237738386789956
train_accuracy:
- 0.062
- 0.171
- 0.35
- 0.0
- 0.55
- 0.569
- 0.625
- 0.656
- 0.625
- 0.638
- 0.646
- 0.0
- 0.721
- 0.7
- 0.731
- 0.683
- 0.0
- 0.717
- 0.0
- 0.719
- 0.721
- 0.74
- 0.725
- 0.721
- 0.0
- 0.002
- 0.75
- 0.0
- 0.0
- 0.0
- 0.75
- 0.775
- 0.756
- 0.0
- 0.0
- 0.019
- 0.785
- 0.0
- 0.79
- 0.0
- 0.783
- 0.792
- 0.781
- 0.79
- 0.756
- 0.842
- 0.808
- 0.783
- 0.794
- 0.796
- 0.781
- 0.79
- 0.0
- 0.0
- 0.8
- 0.781
- 0.806
- 0.027
- 0.775
- 0.796
- 0.794
- 0.792
- 0.827
- 0.802
- 0.0
- 0.008
- 0.802
- 0.775
- 0.815
- 0.792
- 0.821
- 0.802
- 0.771
- 0.81
- 0.0
- 0.842
- 0.017
- 0.0
- 0.808
- 0.019
- 0.012
- 0.812
- 0.823
- 0.802
- 0.0
- 0.848
- 0.842
- 0.831
- 0.0
- 0.027
- 0.781
- 0.0
- 0.808
- 0.002
- 0.831
- 0.815
- 0.006
- 0.812
- 0.81
- 0.825
train_loss:
- 3.243
- 2.935
- 2.546
- 2.004
- 2.221
- 1.668
- 1.735
- 1.825
- 1.593
- 1.521
- 1.326
- 1.422
- 1.544
- 1.366
- 1.469
- 1.32
- 1.178
- 1.262
- 1.236
- 1.107
- 1.088
- 1.072
- 1.183
- 1.166
- 1.036
- 1.009
- 1.109
- 1.089
- 1.118
- 1.084
- 0.966
- 1.042
- 1.052
- 0.925
- 1.017
- 0.93
- 1.148
- 1.004
- 0.993
- 0.997
- 0.982
- 0.987
- 0.976
- 0.954
- 0.863
- 1.151
- 1.034
- 0.855
- 0.914
- 0.934
- 0.812
- 1.028
- 0.901
- 0.911
- 0.992
- 0.903
- 0.873
- 0.788
- 0.783
- 0.873
- 0.893
- 0.87
- 0.959
- 0.876
- 0.859
- 0.762
- 0.857
- 0.765
- 0.932
- 0.84
- 0.926
- 0.835
- 0.757
- 0.827
- 0.848
- 0.993
- 0.823
- 0.827
- 0.819
- 0.821
- 0.81
- 0.804
- 0.811
- 0.792
- 0.797
- 0.865
- 0.869
- 0.779
- 0.855
- 0.775
- 0.703
- 0.762
- 0.708
- 0.698
- 0.877
- 0.788
- 0.766
- 0.791
- 0.774
- 0.761
unequal: 0
verbose: 1
