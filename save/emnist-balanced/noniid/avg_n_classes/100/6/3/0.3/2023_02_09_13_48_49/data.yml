avg_train_accuracy: 0.856
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033829787234042556
- 0.11542553191489362
- 0.2775531914893617
- 0.2979787234042553
- 0.3670744680851064
- 0.3898404255319149
- 0.4059042553191489
- 0.39356382978723403
- 0.4073936170212766
- 0.4151595744680851
- 0.4252127659574468
- 0.4402127659574468
- 0.451063829787234
- 0.4405851063829787
- 0.446968085106383
- 0.44132978723404254
- 0.4638829787234043
- 0.46893617021276596
- 0.4523404255319149
- 0.4782446808510638
- 0.4808510638297872
- 0.47372340425531917
- 0.4618617021276596
- 0.4820212765957447
- 0.48212765957446807
- 0.47452127659574467
- 0.493936170212766
- 0.4846808510638298
- 0.4851595744680851
- 0.4894148936170213
- 0.4875531914893617
- 0.5009574468085106
- 0.49398936170212765
- 0.49398936170212765
- 0.4971808510638298
- 0.5047340425531915
- 0.5006914893617022
- 0.5006914893617022
- 0.5027127659574468
- 0.5078723404255319
- 0.51
- 0.5056382978723404
- 0.5088297872340426
- 0.5136702127659575
- 0.5123936170212766
- 0.5147872340425532
- 0.5140425531914894
- 0.510904255319149
- 0.5148936170212766
- 0.5195744680851064
- 0.5173936170212766
- 0.5292553191489362
- 0.5281914893617021
- 0.525904255319149
- 0.5137234042553191
- 0.5292021276595744
- 0.5373936170212766
- 0.5236702127659575
- 0.52
- 0.5211702127659574
- 0.52
- 0.5224468085106383
- 0.5220212765957447
- 0.522127659574468
- 0.5203723404255319
- 0.5234574468085106
- 0.5203191489361703
- 0.5237765957446808
- 0.5273936170212766
- 0.5264893617021277
- 0.5320744680851064
- 0.5256382978723404
- 0.5268617021276596
- 0.5269148936170213
- 0.5223404255319148
- 0.5260106382978723
- 0.5251063829787234
- 0.5227127659574468
- 0.5259574468085106
- 0.528563829787234
- 0.5331382978723405
- 0.5361702127659574
- 0.5423404255319149
- 0.5320212765957447
- 0.5337234042553192
- 0.5270212765957447
- 0.5251063829787234
- 0.5356382978723404
- 0.5323936170212766
- 0.5265425531914893
- 0.5405851063829787
- 0.5357978723404255
- 0.5683510638297873
- 0.5289893617021276
- 0.5423936170212766
- 0.5606914893617021
- 0.5298404255319149
- 0.5327659574468085
- 0.5404255319148936
- 0.5442553191489362
test_loss_list:
- 3.805768461227417
- 3.763427931467692
- 3.6928386147816976
- 3.3939630794525146
- 3.7837238025665285
- 3.9488916969299317
- 4.055270150502523
- 3.386384916305542
- 3.535963455835978
- 3.407190138498942
- 3.3687154547373455
- 4.277317727406819
- 4.414055941899617
- 3.6003130785624187
- 3.5230528831481935
- 2.933336629867554
- 4.424154822031657
- 4.480807889302572
- 2.873703540166219
- 4.368923260370891
- 4.544725634256999
- 3.5055708440144855
- 2.900245574315389
- 3.5397260189056396
- 3.3301228682200112
- 2.7378032366434732
- 4.307754615147909
- 3.3133127466837564
- 2.711816002527873
- 2.7894242064158123
- 2.7485215632120767
- 4.221629110972087
- 3.2867854245503745
- 2.6456252924601236
- 3.2425044059753416
- 4.158305466969808
- 3.2738550249735514
- 2.8218434047698975
- 3.019031349817912
- 4.13491423924764
- 4.29462731997172
- 3.174408213297526
- 3.240341412226359
- 2.625922743479411
- 4.175689551035563
- 3.1987540022532146
- 4.23162589708964
- 3.286079184214274
- 3.2219866847991945
- 2.7200773111979166
- 4.176753177642822
- 2.635060249964396
- 2.636408150990804
- 3.0944501908620197
- 3.0823792171478273
- 2.9975573348999025
- 2.5600376669565836
- 3.0988566207885744
- 4.021190605163574
- 4.203506205876669
- 3.205792856216431
- 4.122184247970581
- 4.321049216588338
- 4.448812735875448
- 3.2886270968119304
- 4.265001792907714
- 3.2657845306396482
- 3.2590928490956625
- 2.571759974161784
- 3.0780790265401206
- 3.132215846379598
- 4.046402006149292
- 4.1827157179514565
- 4.235573298136393
- 3.2625831349690757
- 4.250983823140462
- 3.22222536722819
- 2.705440003077189
- 3.1294033559163412
- 3.2002631600697837
- 3.094606211980184
- 3.1628358141581217
- 3.1140044339497885
- 2.977726761500041
- 3.0370768292744956
- 3.985194746653239
- 3.0478097756703693
- 3.0394591108957925
- 3.0265440464019777
- 3.0736886819203693
- 2.9907343578338623
- 2.9771408716837566
- 2.451817715962728
- 3.0146909046173094
- 2.9691118399302163
- 2.341565562884013
- 3.7765517457326254
- 2.974231271743774
- 2.939221595128377
- 3.045133295059204
train_accuracy:
- 0.035
- 0.158
- 0.477
- 0.0
- 0.617
- 0.644
- 0.648
- 0.642
- 0.0
- 0.0
- 0.688
- 0.723
- 0.737
- 0.0
- 0.725
- 0.727
- 0.763
- 0.773
- 0.731
- 0.783
- 0.785
- 0.779
- 0.0
- 0.794
- 0.798
- 0.002
- 0.815
- 0.8
- 0.767
- 0.81
- 0.806
- 0.806
- 0.004
- 0.833
- 0.823
- 0.821
- 0.81
- 0.812
- 0.821
- 0.838
- 0.838
- 0.838
- 0.829
- 0.829
- 0.831
- 0.829
- 0.842
- 0.827
- 0.85
- 0.0
- 0.838
- 0.004
- 0.027
- 0.021
- 0.004
- 0.852
- 0.035
- 0.848
- 0.842
- 0.846
- 0.85
- 0.844
- 0.84
- 0.85
- 0.867
- 0.85
- 0.86
- 0.846
- 0.004
- 0.01
- 0.831
- 0.867
- 0.85
- 0.852
- 0.854
- 0.871
- 0.844
- 0.0
- 0.871
- 0.863
- 0.846
- 0.0
- 0.856
- 0.01
- 0.869
- 0.863
- 0.0
- 0.846
- 0.0
- 0.856
- 0.0
- 0.871
- 0.856
- 0.85
- 0.854
- 0.012
- 0.879
- 0.863
- 0.873
- 0.856
train_loss:
- 3.232
- 2.837
- 3.091
- 2.296
- 2.332
- 2.105
- 1.954
- 1.712
- 1.624
- 1.618
- 1.476
- 1.616
- 1.561
- 1.431
- 1.372
- 1.205
- 1.427
- 1.373
- 1.151
- 1.364
- 1.321
- 1.174
- 1.018
- 1.151
- 1.137
- 0.909
- 1.236
- 1.042
- 0.86
- 0.805
- 0.891
- 1.159
- 0.955
- 0.932
- 0.923
- 1.129
- 1.018
- 0.812
- 0.984
- 1.087
- 1.061
- 0.961
- 0.898
- 0.809
- 1.062
- 0.913
- 1.04
- 0.918
- 0.871
- 0.788
- 1.019
- 0.736
- 0.755
- 0.825
- 0.843
- 0.822
- 0.727
- 0.882
- 0.972
- 0.948
- 0.906
- 0.955
- 0.948
- 0.923
- 0.859
- 0.934
- 0.827
- 0.86
- 0.738
- 0.811
- 0.821
- 0.925
- 0.909
- 0.909
- 0.816
- 0.906
- 0.809
- 0.737
- 0.749
- 0.735
- 0.829
- 0.793
- 0.786
- 0.796
- 0.748
- 0.874
- 0.777
- 0.76
- 0.809
- 0.736
- 0.784
- 0.756
- 0.643
- 0.744
- 0.764
- 0.607
- 0.893
- 0.732
- 0.783
- 0.733
unequal: 0
verbose: 1
