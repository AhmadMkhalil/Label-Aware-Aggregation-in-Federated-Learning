avg_train_accuracy: 0.875
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0575
- 0.08074468085106383
- 0.07787234042553191
- 0.2325531914893617
- 0.2531914893617021
- 0.3312765957446808
- 0.3382978723404255
- 0.39159574468085107
- 0.4029255319148936
- 0.41590425531914893
- 0.42388297872340425
- 0.4168085106382979
- 0.4401063829787234
- 0.4403723404255319
- 0.4473936170212766
- 0.42117021276595745
- 0.44893617021276594
- 0.4243085106382979
- 0.4516489361702128
- 0.465
- 0.4541489361702128
- 0.4452659574468085
- 0.46675531914893614
- 0.4769148936170213
- 0.4703723404255319
- 0.4685106382978723
- 0.48
- 0.478031914893617
- 0.47840425531914893
- 0.48356382978723406
- 0.4808510638297872
- 0.48808510638297875
- 0.4870744680851064
- 0.4904787234042553
- 0.4924468085106383
- 0.5012234042553192
- 0.5025531914893617
- 0.4923936170212766
- 0.5028723404255319
- 0.4975531914893617
- 0.503031914893617
- 0.5023404255319149
- 0.5042021276595745
- 0.5086170212765957
- 0.5107446808510638
- 0.5076595744680851
- 0.5114893617021277
- 0.506436170212766
- 0.5111170212765958
- 0.5092553191489362
- 0.513563829787234
- 0.513563829787234
- 0.5145212765957446
- 0.5112234042553192
- 0.510904255319149
- 0.5118085106382979
- 0.5142553191489362
- 0.5164893617021277
- 0.5193085106382979
- 0.5157978723404255
- 0.5326063829787234
- 0.5188297872340426
- 0.5203191489361703
- 0.5174468085106383
- 0.5215425531914893
- 0.5217553191489361
- 0.5320744680851064
- 0.5210106382978723
- 0.5266489361702128
- 0.5274468085106383
- 0.5205851063829787
- 0.5269148936170213
- 0.5227127659574468
- 0.5290425531914894
- 0.5239893617021276
- 0.5251063829787234
- 0.523936170212766
- 0.5281382978723405
- 0.5319148936170213
- 0.5424468085106383
- 0.5369680851063829
- 0.5263297872340426
- 0.5249468085106384
- 0.5267021276595745
- 0.5328191489361702
- 0.5246808510638298
- 0.5273936170212766
- 0.5382978723404256
- 0.5261702127659574
- 0.5264893617021277
- 0.5305851063829787
- 0.5295212765957447
- 0.5312765957446809
- 0.5454255319148936
- 0.5377659574468086
- 0.5282446808510638
- 0.528031914893617
- 0.5331914893617021
- 0.5355319148936171
- 0.5286170212765957
test_loss_list:
- 3.791257759730021
- 3.6683527787526446
- 5.156736386617025
- 3.3722488848368326
- 3.0789297072092694
- 3.330274861653646
- 2.990891326268514
- 3.801457773844401
- 3.979846305847168
- 4.147102610270182
- 4.244766228993734
- 3.4869408321380617
- 4.274436985651652
- 4.336790974934896
- 4.496790955861409
- 2.8146132946014406
- 3.4428824838002523
- 3.0076668485005698
- 3.5356239954630535
- 4.332077137629191
- 3.3522790622711183
- 2.894085594813029
- 3.4160162512461345
- 4.412174682617188
- 3.0725228118896486
- 2.7276529534657796
- 3.2685879039764405
- 2.624974234898885
- 3.2605090077718097
- 2.5399655024210612
- 3.289652674992879
- 3.2522261810302733
- 3.2995055675506593
- 3.0877510515848794
- 3.0035835138956704
- 4.269725058873495
- 4.315317916870117
- 3.3701471583048503
- 4.312484391530355
- 3.267590821584066
- 3.1379962889353434
- 2.6328429222106933
- 2.987867593765259
- 4.184946050643921
- 2.454733959833781
- 3.214645547866821
- 3.154054594039917
- 3.159726759592692
- 4.213370396296184
- 3.0198060035705567
- 4.2480911445617675
- 4.2136834303538
- 4.397357540130615
- 3.3886549186706545
- 3.432485926946004
- 3.3873657099405925
- 3.1890617911020915
- 4.295666405359904
- 3.313767665227254
- 3.025892219543457
- 2.5832730197906493
- 3.2365503406524656
- 3.17469900449117
- 2.9099918111165364
- 3.0644561672210693
- 3.14972469329834
- 2.404363651275635
- 3.0106892013549804
- 3.0689196586608887
- 3.1948350302378334
- 4.201430931091308
- 3.1885367743174235
- 4.25387233098348
- 3.238271198272705
- 4.159711631139119
- 4.369633334477743
- 2.9694777393341063
- 3.254109182357788
- 3.413620497385661
- 2.727220993041992
- 3.3165687338511147
- 4.243056898117065
- 4.322593743006388
- 4.527938604354858
- 3.417677714029948
- 4.469376087188721
- 4.5647854900360105
- 2.780858669281006
- 4.366712255477905
- 3.2170638529459636
- 4.419989153544108
- 4.49640364964803
- 3.471072794596354
- 2.871927401224772
- 2.475961988766988
- 4.263021109898885
- 4.389759699503581
- 3.2721259371439615
- 3.340092124938965
- 4.546623398462931
train_accuracy:
- 0.094
- 0.0
- 0.0
- 0.388
- 0.396
- 0.529
- 0.0
- 0.619
- 0.66
- 0.665
- 0.685
- 0.0
- 0.735
- 0.696
- 0.752
- 0.0
- 0.733
- 0.0
- 0.0
- 0.777
- 0.76
- 0.0
- 0.0
- 0.777
- 0.792
- 0.748
- 0.0
- 0.752
- 0.773
- 0.006
- 0.0
- 0.0
- 0.773
- 0.79
- 0.819
- 0.819
- 0.838
- 0.0
- 0.825
- 0.002
- 0.0
- 0.794
- 0.842
- 0.819
- 0.025
- 0.815
- 0.035
- 0.848
- 0.842
- 0.0
- 0.856
- 0.833
- 0.835
- 0.846
- 0.835
- 0.0
- 0.821
- 0.84
- 0.029
- 0.827
- 0.0
- 0.0
- 0.846
- 0.835
- 0.848
- 0.848
- 0.0
- 0.846
- 0.844
- 0.0
- 0.846
- 0.852
- 0.854
- 0.852
- 0.871
- 0.86
- 0.844
- 0.0
- 0.0
- 0.027
- 0.856
- 0.867
- 0.86
- 0.875
- 0.0
- 0.848
- 0.844
- 0.025
- 0.863
- 0.019
- 0.877
- 0.863
- 0.867
- 0.854
- 0.05
- 0.865
- 0.865
- 0.86
- 0.035
- 0.875
train_loss:
- 2.52
- 2.292
- 1.223
- 2.415
- 1.528
- 1.878
- 1.312
- 2.117
- 1.948
- 1.864
- 1.799
- 1.437
- 1.682
- 1.615
- 1.582
- 1.323
- 1.387
- 1.059
- 1.192
- 1.462
- 1.244
- 0.931
- 1.151
- 1.344
- 1.265
- 0.979
- 1.173
- 0.931
- 1.07
- 0.879
- 1.013
- 0.998
- 0.965
- 1.076
- 1.086
- 1.172
- 1.167
- 0.954
- 1.125
- 1.001
- 1.032
- 0.798
- 1.012
- 1.094
- 0.878
- 0.919
- 0.899
- 0.897
- 1.05
- 0.97
- 1.032
- 1.001
- 1.007
- 0.887
- 0.852
- 0.833
- 0.874
- 1.011
- 0.857
- 0.961
- 0.711
- 0.811
- 0.792
- 0.932
- 0.866
- 0.804
- 0.73
- 0.838
- 0.8
- 0.757
- 0.938
- 0.756
- 0.917
- 0.761
- 0.956
- 0.917
- 0.921
- 0.765
- 0.742
- 0.645
- 0.745
- 0.876
- 0.896
- 0.866
- 0.769
- 0.862
- 0.878
- 0.705
- 0.891
- 0.814
- 0.878
- 0.865
- 0.748
- 0.63
- 0.779
- 0.865
- 0.847
- 0.762
- 0.729
- 0.849
unequal: 0
verbose: 1
