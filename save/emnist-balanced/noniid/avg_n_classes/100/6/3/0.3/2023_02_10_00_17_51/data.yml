avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05425531914893617
- 0.1051063829787234
- 0.21271276595744681
- 0.2666489361702128
- 0.2961170212765957
- 0.3206914893617021
- 0.3477127659574468
- 0.3448936170212766
- 0.39606382978723403
- 0.3587234042553191
- 0.41632978723404257
- 0.4001595744680851
- 0.4109042553191489
- 0.4099468085106383
- 0.4219148936170213
- 0.4277127659574468
- 0.4450531914893617
- 0.45159574468085106
- 0.4559042553191489
- 0.4276063829787234
- 0.4481914893617021
- 0.4530851063829787
- 0.4447340425531915
- 0.45468085106382977
- 0.46622340425531916
- 0.4613829787234043
- 0.46691489361702126
- 0.469468085106383
- 0.47356382978723405
- 0.47441489361702127
- 0.47808510638297874
- 0.48569148936170214
- 0.47664893617021276
- 0.4901063829787234
- 0.4847872340425532
- 0.48851063829787233
- 0.48909574468085104
- 0.49
- 0.4934574468085106
- 0.4968085106382979
- 0.4996808510638298
- 0.49744680851063827
- 0.4969148936170213
- 0.49457446808510636
- 0.5047872340425532
- 0.4926063829787234
- 0.5015957446808511
- 0.5065425531914893
- 0.5012765957446809
- 0.31638297872340426
- 0.5085106382978724
- 0.5073936170212766
- 0.5071808510638298
- 0.5102659574468085
- 0.5039893617021277
- 0.5045212765957446
- 0.5093617021276595
- 0.5085106382978724
- 0.5156382978723404
- 0.5210638297872341
- 0.5122872340425532
- 0.5266489361702128
- 0.5110638297872341
- 0.5176595744680851
- 0.5122340425531915
- 0.515531914893617
- 0.5193617021276595
- 0.3673936170212766
- 0.5300531914893617
- 0.5170212765957447
- 0.5160106382978723
- 0.5179787234042553
- 0.5220744680851064
- 0.5192021276595745
- 0.5241489361702127
- 0.5196276595744681
- 0.5334042553191489
- 0.5379255319148936
- 0.5158510638297872
- 0.5234574468085106
- 0.5195744680851064
- 0.5201595744680851
- 0.5260106382978723
- 0.5312234042553191
- 0.5220744680851064
- 0.5368085106382978
- 0.5197872340425532
- 0.5203723404255319
- 0.5279787234042553
- 0.5212765957446809
- 0.5223404255319148
- 0.5292553191489362
- 0.5387234042553192
- 0.5232978723404256
- 0.5207978723404255
- 0.5225
- 0.5223936170212766
- 0.5287765957446808
- 0.5219148936170213
- 0.538563829787234
test_loss_list:
- 3.7892234834035237
- 3.752803602218628
- 3.6309475326538085
- 3.62113707224528
- 3.457172393798828
- 3.4447029495239256
- 3.4309913063049318
- 3.0576875432332358
- 4.212286771138509
- 2.948562431335449
- 4.285590244928996
- 3.3894811789194743
- 3.346231969197591
- 3.305741554896037
- 3.296527640024821
- 3.347448771794637
- 4.346006536483765
- 4.4076913007100424
- 4.494093290964762
- 2.734844175974528
- 3.3871281973520913
- 3.275863847732544
- 2.6744365374247234
- 2.734604625701904
- 3.183289162317912
- 3.0704849338531495
- 3.1863220723470054
- 3.1799429988861085
- 3.1429877789815266
- 3.1311212380727134
- 3.09218342145284
- 4.210478808085123
- 3.042451690038045
- 4.277661034266154
- 3.1948968156178794
- 3.2989747111002603
- 3.1326486015319825
- 3.2261231740315757
- 3.242609354654948
- 3.3790962092081704
- 4.310395024617513
- 3.2337783018747968
- 3.257244151433309
- 2.6125954564412437
- 4.010132449467977
- 2.593121083577474
- 2.5930090236663816
- 4.01100227355957
- 3.0950375684102376
- 3.079979934692383
- 2.8743787892659505
- 3.8401817576090496
- 3.0257968934377035
- 3.9985863081614177
- 2.490736977259318
- 3.008775208791097
- 3.9868951638539634
- 3.083958864212036
- 3.1060152880350747
- 3.0994140179951986
- 3.0864598401387533
- 2.4735817178090413
- 3.068128032684326
- 3.019556252161662
- 2.9868683211008706
- 3.1679573504130047
- 3.11071395556132
- 2.806531874338786
- 2.7499628480275473
- 2.8692531871795652
- 2.959025634129842
- 3.794738852183024
- 2.417074435551961
- 3.016079037984212
- 3.03186027208964
- 3.9739915180206298
- 2.424728167851766
- 2.5407461643218996
- 2.962629632949829
- 2.923964074452718
- 3.775827770233154
- 3.941105473836263
- 3.0550523789723716
- 3.1186140092213948
- 4.00081264813741
- 3.154860003789266
- 4.155291881561279
- 3.022593959172567
- 3.1429177379608153
- 3.9960573641459147
- 4.109000797271729
- 3.235893834431966
- 2.6870725440979
- 3.958869031270345
- 3.105048735936483
- 4.019623835881551
- 4.11166410446167
- 3.199329624176025
- 3.0552830346425375
- 2.605983050664266
train_accuracy:
- 0.071
- 0.0
- 0.0
- 0.0
- 0.0
- 0.5
- 0.588
- 0.002
- 0.633
- 0.6
- 0.677
- 0.665
- 0.667
- 0.0
- 0.698
- 0.692
- 0.737
- 0.75
- 0.787
- 0.002
- 0.0
- 0.704
- 0.708
- 0.0
- 0.779
- 0.0
- 0.767
- 0.74
- 0.754
- 0.0
- 0.0
- 0.785
- 0.0
- 0.8
- 0.783
- 0.0
- 0.817
- 0.817
- 0.771
- 0.796
- 0.798
- 0.0
- 0.0
- 0.806
- 0.852
- 0.767
- 0.0
- 0.81
- 0.806
- 0.106
- 0.0
- 0.808
- 0.0
- 0.821
- 0.0
- 0.8
- 0.823
- 0.81
- 0.0
- 0.0
- 0.835
- 0.0
- 0.0
- 0.0
- 0.831
- 0.796
- 0.848
- 0.104
- 0.0
- 0.831
- 0.829
- 0.856
- 0.0
- 0.0
- 0.0
- 0.856
- 0.844
- 0.0
- 0.0
- 0.85
- 0.856
- 0.856
- 0.867
- 0.842
- 0.825
- 0.0
- 0.858
- 0.829
- 0.838
- 0.85
- 0.835
- 0.0
- 0.804
- 0.831
- 0.0
- 0.856
- 0.84
- 0.867
- 0.0
- 0.0
train_loss:
- 3.168
- 2.229
- 2.719
- 2.305
- 2.044
- 1.86
- 1.728
- 1.314
- 2.004
- 1.503
- 1.866
- 1.495
- 1.423
- 1.584
- 1.469
- 1.413
- 1.568
- 1.537
- 1.497
- 1.107
- 1.329
- 1.258
- 1.012
- 0.893
- 1.109
- 1.226
- 1.16
- 1.145
- 1.072
- 1.091
- 1.032
- 1.228
- 1.132
- 1.193
- 1.098
- 1.035
- 1.003
- 1.015
- 1.028
- 0.988
- 1.12
- 0.996
- 1.019
- 0.769
- 1.131
- 0.875
- 0.728
- 1.094
- 0.974
- 0.626
- 0.958
- 1.06
- 0.915
- 1.064
- 0.818
- 0.886
- 1.031
- 0.858
- 0.827
- 0.817
- 0.947
- 0.693
- 0.915
- 0.817
- 0.902
- 0.872
- 0.892
- 0.566
- 0.88
- 0.832
- 0.813
- 0.977
- 0.732
- 0.832
- 0.826
- 0.958
- 0.718
- 0.65
- 0.816
- 0.791
- 0.96
- 0.945
- 0.801
- 0.755
- 0.931
- 0.761
- 0.915
- 0.861
- 0.758
- 0.906
- 0.918
- 0.753
- 0.628
- 0.897
- 0.797
- 0.913
- 0.91
- 0.756
- 0.865
- 0.654
unequal: 0
verbose: 1
