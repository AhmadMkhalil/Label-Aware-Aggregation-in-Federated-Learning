avg_train_accuracy: 0.904
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06313829787234043
- 0.16861702127659575
- 0.2594148936170213
- 0.3222872340425532
- 0.3552659574468085
- 0.36957446808510636
- 0.3850531914893617
- 0.4174468085106383
- 0.42659574468085104
- 0.41095744680851065
- 0.4243085106382979
- 0.4302127659574468
- 0.4359574468085106
- 0.441063829787234
- 0.44638297872340427
- 0.45728723404255317
- 0.4504787234042553
- 0.45356382978723403
- 0.46882978723404256
- 0.46297872340425533
- 0.47627659574468084
- 0.4776595744680851
- 0.47973404255319146
- 0.4697872340425532
- 0.47074468085106386
- 0.48686170212765956
- 0.48856382978723406
- 0.49042553191489363
- 0.4725531914893617
- 0.47622340425531917
- 0.4925
- 0.49579787234042555
- 0.48914893617021277
- 0.4846808510638298
- 0.5002127659574468
- 0.5011170212765957
- 0.49888297872340426
- 0.49696808510638296
- 0.5039893617021277
- 0.5028191489361702
- 0.5030851063829788
- 0.5037765957446808
- 0.49622340425531913
- 0.506968085106383
- 0.5071808510638298
- 0.5123936170212766
- 0.5125531914893617
- 0.5215425531914893
- 0.5162234042553191
- 0.5085106382978724
- 0.5120212765957447
- 0.5137765957446808
- 0.5114893617021277
- 0.5147872340425532
- 0.5110106382978723
- 0.5118617021276596
- 0.5130851063829788
- 0.5124468085106383
- 0.5161170212765958
- 0.5174468085106383
- 0.5109574468085106
- 0.513031914893617
- 0.5176595744680851
- 0.5174468085106383
- 0.5181382978723404
- 0.516436170212766
- 0.5164893617021277
- 0.5201063829787234
- 0.5205851063829787
- 0.519468085106383
- 0.5202659574468085
- 0.5246276595744681
- 0.5264893617021277
- 0.5270744680851064
- 0.5356914893617021
- 0.5455851063829787
- 0.5325
- 0.5211170212765958
- 0.5238297872340425
- 0.5168617021276596
- 0.5261170212765958
- 0.5228191489361702
- 0.5346808510638298
- 0.5193617021276595
- 0.5290425531914894
- 0.5353191489361702
- 0.540904255319149
- 0.5452659574468085
- 0.5283510638297872
- 0.5334574468085106
- 0.5344148936170213
- 0.5245744680851064
- 0.5244148936170213
- 0.5286170212765957
- 0.5347340425531915
- 0.5329787234042553
- 0.5257978723404255
- 0.5504787234042553
- 0.5259574468085106
- 0.5250531914893617
test_loss_list:
- 3.87007576306661
- 3.8411547342936196
- 3.5769648265838625
- 3.4610335540771486
- 3.5038336531321206
- 3.3639915498097737
- 3.3400546805063884
- 4.116291898091634
- 4.162168509165446
- 3.063509254455566
- 3.3580661010742188
- 3.4478525797526043
- 3.496018149058024
- 3.3588541158040366
- 3.4243362808227538
- 4.285110734303792
- 3.534338935216268
- 2.948825124104818
- 4.35637007077535
- 3.5783146731058757
- 4.407344538370769
- 4.557516962687174
- 4.568194583257039
- 3.040896339416504
- 3.4095037587483725
- 4.389753904342651
- 4.537644783655803
- 4.574906851450602
- 3.046245361963908
- 3.0317554092407226
- 4.42549067179362
- 4.570687640508016
- 3.365931924184163
- 2.924747536977132
- 3.5694192441304526
- 3.5444881693522134
- 3.1875951131184896
- 3.2000284576416016
- 4.269630737304688
- 3.163025426864624
- 3.215817035039266
- 2.7449532636006673
- 2.6258831373850504
- 4.068820454279582
- 3.078147217432658
- 2.69409899075826
- 3.148635346094767
- 3.1326971213022867
- 3.228442913691203
- 3.1334172185262044
- 4.095906146367391
- 4.103355261484782
- 2.5168218485514324
- 4.105585088729859
- 4.159413639704386
- 3.0504197756449383
- 3.3405105209350587
- 3.1916222540537516
- 4.048935766220093
- 4.155580196380615
- 3.0834280586242677
- 2.686442470550537
- 4.011033681233724
- 2.963463611602783
- 4.032215840021769
- 3.277295217514038
- 3.145198408762614
- 3.1353451442718505
- 3.0612727959950763
- 3.994133733113607
- 4.103356215159098
- 2.650380646387736
- 3.1843447144826253
- 3.193547372817993
- 2.6780989837646483
- 2.6463014793396
- 3.0501127370198566
- 3.8864894771575926
- 4.031441507339477
- 2.9191824054718016
- 3.202617514928182
- 4.013522958755493
- 2.6328594303131103
- 2.9167974853515624
- 3.004543504714966
- 3.100602127710978
- 3.0851735401153566
- 2.437683375676473
- 3.031189187367757
- 2.9961075592041015
- 2.9879566478729247
- 2.7849237791697186
- 3.7274530696868897
- 2.995098574956258
- 2.365280887285868
- 3.0875582281748453
- 3.8745700391133626
- 2.5527525043487547
- 2.746919495264689
- 3.7657292652130128
train_accuracy:
- 0.1
- 0.265
- 0.398
- 0.502
- 0.0
- 0.0
- 0.633
- 0.71
- 0.7
- 0.0
- 0.725
- 0.74
- 0.004
- 0.0
- 0.004
- 0.779
- 0.002
- 0.0
- 0.721
- 0.004
- 0.735
- 0.767
- 0.756
- 0.008
- 0.79
- 0.804
- 0.84
- 0.79
- 0.0
- 0.0
- 0.796
- 0.792
- 0.819
- 0.004
- 0.806
- 0.002
- 0.81
- 0.79
- 0.823
- 0.821
- 0.852
- 0.0
- 0.006
- 0.823
- 0.863
- 0.0
- 0.871
- 0.0
- 0.0
- 0.848
- 0.829
- 0.838
- 0.825
- 0.838
- 0.827
- 0.002
- 0.877
- 0.0
- 0.877
- 0.846
- 0.873
- 0.0
- 0.848
- 0.835
- 0.85
- 0.863
- 0.844
- 0.84
- 0.0
- 0.84
- 0.854
- 0.002
- 0.854
- 0.86
- 0.808
- 0.0
- 0.844
- 0.852
- 0.848
- 0.002
- 0.846
- 0.875
- 0.0
- 0.0
- 0.85
- 0.863
- 0.848
- 0.0
- 0.0
- 0.0
- 0.863
- 0.86
- 0.838
- 0.856
- 0.802
- 0.84
- 0.863
- 0.0
- 0.0
- 0.904
train_loss:
- 3.715
- 2.897
- 2.534
- 2.137
- 1.873
- 1.817
- 1.637
- 1.892
- 1.793
- 1.275
- 1.403
- 1.39
- 1.314
- 1.31
- 1.265
- 1.472
- 1.233
- 0.984
- 1.434
- 1.149
- 1.369
- 1.335
- 1.33
- 0.985
- 1.487
- 1.272
- 1.242
- 1.24
- 1.181
- 1.02
- 1.225
- 1.202
- 1.194
- 0.967
- 1.008
- 0.983
- 1.055
- 1.119
- 1.149
- 1.008
- 0.95
- 0.806
- 0.925
- 1.115
- 0.957
- 0.76
- 0.884
- 0.868
- 0.866
- 0.933
- 1.062
- 1.029
- 0.931
- 1.034
- 1.025
- 1.03
- 0.915
- 0.87
- 1.004
- 1.003
- 1.012
- 0.763
- 1.009
- 0.992
- 0.991
- 0.901
- 0.845
- 0.861
- 0.832
- 0.962
- 0.955
- 0.731
- 0.818
- 0.788
- 0.669
- 0.629
- 0.782
- 0.926
- 0.922
- 0.961
- 0.802
- 0.908
- 0.693
- 0.934
- 0.791
- 0.771
- 0.741
- 0.752
- 0.814
- 0.772
- 0.786
- 0.927
- 0.913
- 0.805
- 0.764
- 0.755
- 0.88
- 0.656
- 0.888
- 0.881
unequal: 0
verbose: 1
