avg_train_accuracy: 0.854
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03228723404255319
- 0.10925531914893617
- 0.24968085106382978
- 0.3373404255319149
- 0.3477659574468085
- 0.3850531914893617
- 0.37303191489361703
- 0.3976595744680851
- 0.4173404255319149
- 0.4256382978723404
- 0.4168085106382979
- 0.4283510638297872
- 0.4301595744680851
- 0.4372340425531915
- 0.42164893617021276
- 0.4553191489361702
- 0.4600531914893617
- 0.45180851063829786
- 0.45095744680851063
- 0.4506914893617021
- 0.4596276595744681
- 0.4681382978723404
- 0.4638829787234043
- 0.4710106382978723
- 0.4685106382978723
- 0.47702127659574467
- 0.4871808510638298
- 0.47297872340425534
- 0.49
- 0.4848404255319149
- 0.4956382978723404
- 0.4944148936170213
- 0.4972340425531915
- 0.48984042553191487
- 0.4876595744680851
- 0.4947340425531915
- 0.49675531914893617
- 0.49686170212765957
- 0.48851063829787233
- 0.5011170212765957
- 0.496436170212766
- 0.500531914893617
- 0.5063829787234042
- 0.5054787234042554
- 0.5090425531914894
- 0.503563829787234
- 0.5137234042553191
- 0.5120212765957447
- 0.5074468085106383
- 0.510531914893617
- 0.5149468085106383
- 0.5126063829787234
- 0.5125
- 0.521595744680851
- 0.5171808510638298
- 0.5212234042553191
- 0.5207446808510638
- 0.5182978723404256
- 0.5200531914893617
- 0.5185106382978724
- 0.5210106382978723
- 0.524468085106383
- 0.5153191489361703
- 0.5158510638297872
- 0.5193085106382979
- 0.5178191489361702
- 0.5219148936170213
- 0.5199468085106383
- 0.522127659574468
- 0.5220212765957447
- 0.5219680851063829
- 0.5177127659574469
- 0.5195744680851064
- 0.5237765957446808
- 0.5254255319148936
- 0.5297872340425532
- 0.5238297872340425
- 0.5338829787234043
- 0.5424468085106383
- 0.5256914893617022
- 0.5262234042553191
- 0.5284574468085106
- 0.5273404255319148
- 0.5292021276595744
- 0.5279787234042553
- 0.525904255319149
- 0.5283510638297872
- 0.5250531914893617
- 0.5276595744680851
- 0.5356914893617021
- 0.5297872340425532
- 0.5292553191489362
- 0.5381382978723405
- 0.5314893617021277
- 0.5274468085106383
- 0.5438829787234043
- 0.5318085106382979
- 0.5314893617021277
- 0.5371808510638297
- 0.5614361702127659
test_loss_list:
- 3.805205036799113
- 3.8475745868682862
- 3.8013510195414226
- 3.861160405476888
- 3.5098999055226643
- 3.99784369468689
- 3.1545535405476888
- 3.4911542479197184
- 4.179661181767782
- 4.352560297648112
- 3.501028429667155
- 3.668117119471232
- 3.3303772672017415
- 3.2892848173777263
- 2.9033254305521647
- 4.38630215326945
- 4.431537768046061
- 3.5005882771809897
- 3.4610266367594402
- 2.78166277885437
- 3.3224305947621664
- 3.434062194824219
- 2.7864451599121094
- 3.3589464060465493
- 2.7895236873626708
- 3.1118255837758384
- 4.236888761520386
- 2.4849744478861493
- 4.225454613367717
- 3.0447765572865806
- 4.407170813878377
- 4.390946550369263
- 4.484963623682658
- 3.3613239192962645
- 2.6847055435180662
- 3.302398478190104
- 3.3796032842000328
- 3.349460121790568
- 2.4682230981191
- 3.261301403045654
- 3.131972064971924
- 2.9994260946909588
- 4.268875675201416
- 3.199490661621094
- 3.4158622074127196
- 3.048520078659058
- 3.366657606760661
- 4.2195531876881915
- 3.2212617524464924
- 3.2285718154907226
- 4.3647754192352295
- 4.471509977976481
- 3.382050355275472
- 2.7460519727071127
- 3.178133878707886
- 3.2243343671162923
- 3.285706574122111
- 4.238296111424764
- 2.356602783203125
- 4.198075040181478
- 3.152782014211019
- 3.3144440778096516
- 2.94742927869161
- 3.0026442782084146
- 4.125205119450887
- 2.915509335199992
- 4.194284801483154
- 3.1031841055552163
- 4.210961653391521
- 4.386523170471191
- 4.379146286646525
- 3.197062880198161
- 3.224260721206665
- 4.367801268895467
- 3.1631068706512453
- 2.380625139872233
- 2.979847542444865
- 2.4374812253316245
- 2.4050870768229164
- 4.03607463200887
- 4.12297248840332
- 3.0204720242818195
- 4.053771082560221
- 3.1822918542226155
- 4.043653230667115
- 4.159452476501465
- 4.360260025660197
- 3.1301359144846597
- 4.311867074966431
- 2.475635153452555
- 3.0471120262145996
- 4.081340157190959
- 2.5201826032002765
- 3.0578514607747396
- 3.9781417560577395
- 2.362990223566691
- 2.9915651925404867
- 3.8919350210825603
- 3.082779280344645
- 2.4219856945673626
train_accuracy:
- 0.05
- 0.185
- 0.41
- 0.573
- 0.59
- 0.629
- 0.0
- 0.0
- 0.683
- 0.727
- 0.717
- 0.717
- 0.688
- 0.694
- 0.0
- 0.769
- 0.758
- 0.735
- 0.725
- 0.725
- 0.79
- 0.0
- 0.004
- 0.748
- 0.748
- 0.783
- 0.779
- 0.01
- 0.808
- 0.783
- 0.804
- 0.806
- 0.808
- 0.779
- 0.79
- 0.796
- 0.785
- 0.0
- 0.0
- 0.831
- 0.806
- 0.823
- 0.827
- 0.829
- 0.819
- 0.81
- 0.808
- 0.831
- 0.0
- 0.815
- 0.827
- 0.821
- 0.812
- 0.806
- 0.842
- 0.0
- 0.0
- 0.821
- 0.804
- 0.844
- 0.85
- 0.835
- 0.0
- 0.84
- 0.838
- 0.833
- 0.827
- 0.852
- 0.848
- 0.854
- 0.846
- 0.0
- 0.0
- 0.867
- 0.835
- 0.858
- 0.852
- 0.819
- 0.0
- 0.875
- 0.873
- 0.0
- 0.86
- 0.86
- 0.842
- 0.863
- 0.842
- 0.85
- 0.86
- 0.0
- 0.852
- 0.84
- 0.829
- 0.865
- 0.854
- 0.0
- 0.856
- 0.871
- 0.0
- 0.854
train_loss:
- 3.804
- 3.176
- 3.286
- 2.772
- 2.142
- 2.206
- 1.595
- 1.654
- 1.886
- 1.799
- 1.469
- 1.328
- 1.532
- 1.451
- 1.488
- 1.593
- 1.543
- 1.263
- 1.494
- 1.071
- 1.413
- 1.265
- 1.056
- 1.204
- 0.966
- 1.187
- 1.284
- 1.068
- 1.312
- 1.127
- 1.196
- 1.229
- 1.205
- 1.103
- 0.984
- 0.995
- 0.974
- 0.944
- 0.988
- 0.943
- 1.007
- 1.005
- 1.114
- 0.906
- 0.868
- 1.002
- 0.862
- 1.079
- 0.933
- 0.904
- 1.006
- 0.965
- 0.856
- 0.738
- 0.899
- 0.869
- 0.813
- 0.986
- 0.905
- 0.955
- 0.859
- 0.847
- 0.964
- 0.919
- 0.98
- 0.925
- 0.936
- 0.837
- 0.925
- 0.911
- 0.895
- 0.881
- 0.796
- 0.91
- 0.81
- 0.796
- 0.831
- 0.67
- 0.713
- 0.887
- 0.87
- 0.808
- 0.893
- 0.729
- 0.902
- 0.873
- 0.851
- 0.822
- 0.862
- 0.765
- 0.786
- 0.89
- 0.689
- 0.776
- 0.87
- 0.697
- 0.782
- 0.864
- 0.714
- 0.627
unequal: 0
verbose: 1
