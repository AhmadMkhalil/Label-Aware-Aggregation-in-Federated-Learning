avg_train_accuracy: 0.802
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03265957446808511
- 0.060904255319148934
- 0.1502659574468085
- 0.26
- 0.34664893617021275
- 0.43867021276595747
- 0.4423936170212766
- 0.4725531914893617
- 0.49388297872340425
- 0.5169148936170213
- 0.5298936170212766
- 0.5425531914893617
- 0.5634574468085106
- 0.5606382978723404
- 0.5727127659574468
- 0.5888829787234042
- 0.5857978723404256
- 0.5897340425531915
- 0.6073404255319149
- 0.6025531914893617
- 0.6063297872340425
- 0.6126063829787234
- 0.6179787234042553
- 0.6188829787234043
- 0.6196808510638298
- 0.638031914893617
- 0.6272340425531915
- 0.6322340425531915
- 0.6432446808510638
- 0.6388297872340426
- 0.651595744680851
- 0.6432978723404256
- 0.6462234042553191
- 0.6487234042553192
- 0.6590957446808511
- 0.6614893617021277
- 0.6646276595744681
- 0.6549468085106382
- 0.6601063829787234
- 0.660904255319149
- 0.6631914893617021
- 0.6723404255319149
- 0.6666489361702128
- 0.668936170212766
- 0.67
- 0.6715425531914894
- 0.6798936170212766
- 0.6738829787234043
- 0.6763297872340426
- 0.6831382978723404
- 0.6775
- 0.6793085106382979
- 0.6813829787234043
- 0.6820744680851064
- 0.6837234042553192
- 0.6834574468085106
- 0.6904255319148936
- 0.6846808510638298
- 0.6871276595744681
- 0.6884574468085106
- 0.6881914893617022
- 0.6900531914893617
- 0.6910106382978723
- 0.6915425531914894
- 0.6924468085106383
- 0.6963829787234043
- 0.6961702127659575
- 0.6999468085106383
- 0.6948936170212766
- 0.6971808510638298
- 0.6973404255319149
- 0.7011702127659575
- 0.7
- 0.7009042553191489
- 0.7014893617021276
- 0.7025531914893617
- 0.7022872340425532
- 0.7036170212765958
- 0.704627659574468
- 0.7049468085106383
- 0.7068617021276595
- 0.7060106382978724
- 0.706436170212766
- 0.7044148936170213
- 0.705
- 0.7073936170212766
- 0.7091489361702128
- 0.709627659574468
- 0.7067553191489362
- 0.7093617021276596
- 0.7072340425531914
- 0.7095212765957447
- 0.708404255319149
- 0.7117021276595744
- 0.7098936170212766
- 0.7093617021276596
- 0.711968085106383
- 0.7115425531914894
- 0.7152127659574468
- 0.7131914893617022
test_loss_list:
- 3.7790685749053954
- 3.7039230473836264
- 3.5361096064249673
- 3.125391200383504
- 2.78790504137675
- 2.6590094343821207
- 2.42653621673584
- 2.300404675801595
- 2.2114823404947916
- 2.13455393632253
- 2.0673280318578082
- 2.006680754025777
- 2.165435872077942
- 1.9588331031799315
- 1.913768695195516
- 2.0885296869277954
- 1.871721118291219
- 1.8434761428833009
- 2.0450737222035724
- 1.7992618942260743
- 1.7703840351104736
- 1.7449650478363037
- 1.730020128885905
- 1.7060739024480185
- 1.6887659168243407
- 1.9333261966705322
- 1.6836038621266682
- 1.6720552221934
- 1.9165476004282633
- 1.644521336555481
- 1.9234895054499308
- 1.6351457341512043
- 1.631737937927246
- 1.6094628651936849
- 1.8687371794382732
- 1.9094422340393067
- 1.9298405424753824
- 1.6462671597798666
- 1.599338126182556
- 1.583753015200297
- 1.5628703196843465
- 1.8373672946294148
- 1.5578244241078694
- 1.5410571511586506
- 1.5273013909657795
- 1.509822333653768
- 1.784133939743042
- 1.5185643657048544
- 1.5093327236175538
- 1.7711011584599812
- 1.4978982130686442
- 1.4812187894185385
- 1.4836145973205566
- 1.4711200873057046
- 1.4556896193822224
- 1.4611119985580445
- 1.7319816700617472
- 1.4771017106374105
- 1.46108589331309
- 1.4466258637110392
- 1.4440996678670248
- 1.4232388861974081
- 1.432810254096985
- 1.4326899019877115
- 1.4231390762329101
- 1.7074766333897908
- 1.4297073841094972
- 1.7297515106201171
- 1.4548209778467813
- 1.4450371313095092
- 1.4206190156936644
- 1.7035910177230835
- 1.4219214566548666
- 1.426959875424703
- 1.4139776341120402
- 1.4104698848724366
- 1.4026825348536174
- 1.3874770251909891
- 1.386137994925181
- 1.3983119249343872
- 1.3863322520256043
- 1.6714821910858155
- 1.7259018484751383
- 1.4183788728713989
- 1.4206101910273234
- 1.691347378094991
- 1.7163508319854737
- 1.7621128225326539
- 1.464144835472107
- 1.7210152737299602
- 1.4416625785827637
- 1.4218820349375407
- 1.4031437460581462
- 1.6680274248123168
- 1.4037706740697224
- 1.4044631656010946
- 1.3835616930325827
- 1.3742675320307414
- 1.360653744538625
- 1.3790386311213176
train_accuracy:
- 0.042
- 0.0
- 0.188
- 0.308
- 0.377
- 0.548
- 0.0
- 0.533
- 0.0
- 0.604
- 0.617
- 0.619
- 0.642
- 0.658
- 0.669
- 0.696
- 0.696
- 0.729
- 0.717
- 0.708
- 0.704
- 0.731
- 0.685
- 0.723
- 0.698
- 0.731
- 0.735
- 0.735
- 0.731
- 0.752
- 0.737
- 0.748
- 0.771
- 0.754
- 0.76
- 0.775
- 0.777
- 0.765
- 0.779
- 0.781
- 0.763
- 0.8
- 0.785
- 0.76
- 0.775
- 0.779
- 0.792
- 0.773
- 0.783
- 0.79
- 0.01
- 0.804
- 0.008
- 0.76
- 0.802
- 0.8
- 0.79
- 0.815
- 0.787
- 0.794
- 0.775
- 0.802
- 0.81
- 0.785
- 0.012
- 0.827
- 0.79
- 0.794
- 0.775
- 0.81
- 0.808
- 0.833
- 0.798
- 0.802
- 0.015
- 0.804
- 0.821
- 0.81
- 0.802
- 0.017
- 0.812
- 0.821
- 0.827
- 0.819
- 0.817
- 0.815
- 0.825
- 0.823
- 0.812
- 0.84
- 0.825
- 0.802
- 0.833
- 0.838
- 0.819
- 0.01
- 0.017
- 0.823
- 0.8
- 0.802
train_loss:
- 3.548
- 3.445
- 3.675
- 3.066
- 2.749
- 2.813
- 2.336
- 2.186
- 2.071
- 1.991
- 1.928
- 1.854
- 2.025
- 1.749
- 1.71
- 1.863
- 1.643
- 1.597
- 1.773
- 1.576
- 1.534
- 1.511
- 1.498
- 1.47
- 1.445
- 1.6
- 1.425
- 1.401
- 1.551
- 1.375
- 1.513
- 1.363
- 1.327
- 1.32
- 1.459
- 1.432
- 1.432
- 1.277
- 1.272
- 1.244
- 1.238
- 1.367
- 1.227
- 1.214
- 1.209
- 1.215
- 1.332
- 1.189
- 1.18
- 1.318
- 1.183
- 1.16
- 1.156
- 1.147
- 1.152
- 1.124
- 1.265
- 1.12
- 1.123
- 1.116
- 1.116
- 1.109
- 1.088
- 1.095
- 1.104
- 1.209
- 1.091
- 1.192
- 1.071
- 1.064
- 1.077
- 1.189
- 1.071
- 1.055
- 1.057
- 1.051
- 1.038
- 1.036
- 1.04
- 1.033
- 1.033
- 1.154
- 1.145
- 1.039
- 1.017
- 1.142
- 1.121
- 1.117
- 1.033
- 1.121
- 1.014
- 1.013
- 1.004
- 1.103
- 1.009
- 0.985
- 0.99
- 0.994
- 0.981
- 0.975
unequal: 0
verbose: 1
