avg_train_accuracy: 0.846
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03835106382978724
- 0.08946808510638297
- 0.1926063829787234
- 0.2877659574468085
- 0.31372340425531914
- 0.321968085106383
- 0.34547872340425534
- 0.34925531914893615
- 0.3528723404255319
- 0.386063829787234
- 0.3828191489361702
- 0.40117021276595743
- 0.3852659574468085
- 0.4001595744680851
- 0.4089893617021277
- 0.40808510638297874
- 0.39367021276595743
- 0.41340425531914893
- 0.4132446808510638
- 0.41654255319148936
- 0.4252659574468085
- 0.42872340425531913
- 0.42675531914893616
- 0.42425531914893616
- 0.42569148936170215
- 0.43106382978723407
- 0.4398936170212766
- 0.4324468085106383
- 0.4427127659574468
- 0.4402659574468085
- 0.448563829787234
- 0.44313829787234044
- 0.44468085106382976
- 0.45382978723404255
- 0.4566489361702128
- 0.4445212765957447
- 0.26382978723404255
- 0.4592553191489362
- 0.4598404255319149
- 0.3019148936170213
- 0.4671276595744681
- 0.46797872340425534
- 0.4676595744680851
- 0.46585106382978725
- 0.4692021276595745
- 0.4650531914893617
- 0.4623404255319149
- 0.2874468085106383
- 0.4727659574468085
- 0.46877659574468084
- 0.4753723404255319
- 0.3052659574468085
- 0.4823404255319149
- 0.48877659574468085
- 0.4778723404255319
- 0.4750531914893617
- 0.47175531914893615
- 0.48473404255319147
- 0.475
- 0.480531914893617
- 0.4811170212765957
- 0.48861702127659573
- 0.48648936170212764
- 0.48143617021276597
- 0.47622340425531917
- 0.47867021276595745
- 0.2995212765957447
- 0.48877659574468085
- 0.4862234042553191
- 0.36159574468085104
- 0.5027659574468085
- 0.4006914893617021
- 0.5259574468085106
- 0.49675531914893617
- 0.5061170212765957
- 0.49446808510638296
- 0.4955851063829787
- 0.4980851063829787
- 0.35909574468085104
- 0.5024468085106383
- 0.5088297872340426
- 0.5000531914893617
- 0.4997872340425532
- 0.48601063829787233
- 0.49138297872340425
- 0.48861702127659573
- 0.49840425531914895
- 0.5020744680851064
- 0.4881382978723404
- 0.49372340425531913
- 0.4972872340425532
- 0.4959574468085106
- 0.5023936170212766
- 0.5053191489361702
- 0.5006914893617022
- 0.40537234042553194
- 0.5138297872340426
- 0.49675531914893617
- 0.5080851063829788
- 0.5041489361702127
test_loss_list:
- 3.836106233596802
- 3.838139975865682
- 3.721932764053345
- 3.657142343521118
- 3.450852467219035
- 3.405376017888387
- 3.363091252644857
- 3.316243718465169
- 3.236342560450236
- 3.6380368423461915
- 3.533450584411621
- 3.4904915301005044
- 3.0974482981363933
- 3.408252280553182
- 3.31237722714742
- 3.323069149653117
- 2.9348921362559
- 3.1521842193603518
- 3.1380822785695393
- 3.0455505943298338
- 3.1317734654744465
- 3.2360035355885826
- 2.9086087958017983
- 3.071493174235026
- 2.9163631439208983
- 2.739956579208374
- 3.0576063283284505
- 2.77990153948466
- 3.178226458231608
- 2.876640256245931
- 3.0893204561869303
- 2.734602769215902
- 3.1413020515441894
- 3.4424745845794678
- 3.5545761426289877
- 2.6870516459147136
- 3.396292769114176
- 3.1884148693084717
- 2.5469972260793052
- 3.0323459688822427
- 2.7311945470174153
- 2.559925371805827
- 2.5260808277130127
- 3.0294635740915936
- 2.7688690058390297
- 2.5621418571472168
- 2.6048813343048094
- 2.984588572184245
- 2.4727884356180825
- 3.092578439712524
- 2.4976729202270507
- 2.993638178507487
- 2.4061832269032797
- 2.3082584063212077
- 2.374580914179484
- 2.3703873030344647
- 2.664002046585083
- 2.2779487943649293
- 2.7059160041809083
- 2.5577821763356527
- 2.4901457341512043
- 2.5026266225179037
- 2.4932466634114583
- 2.379976374308268
- 2.319535190264384
- 2.657721954981486
- 2.9592520078023274
- 2.5165666929880777
- 2.3563473224639893
- 2.17373567422231
- 2.236946113904317
- 2.2368872419993084
- 2.1085685761769613
- 2.430681126912435
- 2.129161589940389
- 2.1820748694737753
- 2.2623935890197755
- 2.2353732872009275
- 2.3873785877227784
- 2.2893529240290325
- 2.106349903742472
- 2.48512926419576
- 2.2441972653071085
- 2.4157042630513508
- 2.2006890249252318
- 2.4603254254659017
- 2.2125018628438315
- 2.2112248706817628
- 2.394594256083171
- 2.375970996220907
- 2.3460232067108153
- 2.4084569072723387
- 2.1660368124643963
- 2.136768879890442
- 2.174812534650167
- 2.221574778556824
- 2.2802655426661174
- 2.6391688855489095
- 2.4362221209208172
- 2.1398013750712077
train_accuracy:
- 0.0
- 0.0
- 0.35
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.642
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.727
- 0.74
- 0.0
- 0.0
- 0.0
- 0.0
- 0.754
- 0.0
- 0.746
- 0.0
- 0.773
- 0.0
- 0.0
- 0.0
- 0.79
- 0.002
- 0.0
- 0.0
- 0.0
- 0.002
- 0.81
- 0.0
- 0.246
- 0.0
- 0.004
- 0.377
- 0.804
- 0.008
- 0.806
- 0.808
- 0.0
- 0.0
- 0.798
- 0.727
- 0.0
- 0.833
- 0.0
- 0.942
- 0.0
- 0.008
- 0.0
- 0.0
- 0.0
- 0.008
- 0.0
- 0.821
- 0.812
- 0.002
- 0.01
- 0.0
- 0.0
- 0.006
- 0.365
- 0.829
- 0.002
- 0.215
- 0.829
- 0.627
- 0.0
- 0.006
- 0.177
- 0.004
- 0.0
- 0.004
- 0.41
- 0.025
- 0.006
- 0.002
- 0.835
- 0.002
- 0.0
- 0.846
- 0.01
- 0.0
- 0.033
- 0.0
- 0.002
- 0.0
- 0.0
- 0.002
- 0.817
- 0.556
- 0.858
- 0.833
- 0.004
- 0.846
train_loss:
- 1.736
- 1.429
- 1.223
- 1.455
- 1.004
- 0.893
- 0.876
- 0.826
- 0.809
- 1.254
- 1.028
- 0.983
- 0.725
- 0.884
- 0.861
- 0.817
- 0.659
- 0.619
- 0.776
- 0.651
- 0.794
- 0.766
- 0.657
- 0.615
- 0.574
- 0.538
- 0.698
- 0.553
- 0.767
- 0.609
- 0.693
- 0.568
- 0.69
- 0.826
- 0.799
- 0.556
- 0.364
- 0.812
- 0.538
- 0.36
- 0.647
- 0.506
- 0.491
- 0.741
- 0.592
- 0.517
- 0.494
- 0.349
- 0.429
- 0.742
- 0.455
- 0.31
- 0.456
- 0.418
- 0.457
- 0.44
- 0.611
- 0.454
- 0.564
- 0.546
- 0.455
- 0.41
- 0.446
- 0.427
- 0.456
- 0.555
- 0.298
- 0.56
- 0.462
- 0.303
- 0.408
- 0.267
- 0.372
- 0.515
- 0.411
- 0.412
- 0.386
- 0.387
- 0.275
- 0.506
- 0.406
- 0.484
- 0.422
- 0.531
- 0.413
- 0.526
- 0.378
- 0.383
- 0.516
- 0.514
- 0.394
- 0.507
- 0.385
- 0.375
- 0.381
- 0.259
- 0.5
- 0.606
- 0.479
- 0.392
unequal: 0
verbose: 1
