avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.025691489361702128
- 0.0901595744680851
- 0.22452127659574467
- 0.30042553191489363
- 0.3388829787234043
- 0.34558510638297874
- 0.35856382978723406
- 0.3748404255319149
- 0.39085106382978724
- 0.38920212765957446
- 0.4053191489361702
- 0.39739361702127657
- 0.41143617021276596
- 0.4128191489361702
- 0.41702127659574467
- 0.4245744680851064
- 0.4223936170212766
- 0.4245744680851064
- 0.4328723404255319
- 0.4305851063829787
- 0.4273936170212766
- 0.31042553191489364
- 0.4325531914893617
- 0.43909574468085105
- 0.4347872340425532
- 0.4365425531914894
- 0.4475
- 0.44601063829787235
- 0.4502127659574468
- 0.45276595744680853
- 0.4549468085106383
- 0.45643617021276595
- 0.4482978723404255
- 0.46117021276595743
- 0.461968085106383
- 0.46037234042553193
- 0.27324468085106385
- 0.4673936170212766
- 0.4635106382978723
- 0.46414893617021274
- 0.4623404255319149
- 0.4597872340425532
- 0.46414893617021274
- 0.4657978723404255
- 0.47106382978723405
- 0.4678191489361702
- 0.4676063829787234
- 0.4672340425531915
- 0.47143617021276596
- 0.47047872340425534
- 0.47569148936170214
- 0.31393617021276593
- 0.47760638297872343
- 0.47654255319148936
- 0.46941489361702127
- 0.47579787234042553
- 0.47441489361702127
- 0.47835106382978726
- 0.4787234042553192
- 0.37930851063829785
- 0.4894148936170213
- 0.48186170212765955
- 0.47808510638297874
- 0.47952127659574467
- 0.47648936170212763
- 0.47606382978723405
- 0.4753191489361702
- 0.48101063829787233
- 0.4747872340425532
- 0.35398936170212764
- 0.481968085106383
- 0.48867021276595746
- 0.4288297872340426
- 0.47973404255319146
- 0.48723404255319147
- 0.48819148936170215
- 0.48840425531914894
- 0.4838297872340426
- 0.4918085106382979
- 0.48606382978723406
- 0.4878723404255319
- 0.4848404255319149
- 0.4823936170212766
- 0.4848936170212766
- 0.4877659574468085
- 0.48069148936170214
- 0.4925
- 0.4881382978723404
- 0.4097872340425532
- 0.48781914893617023
- 0.4922872340425532
- 0.4946276595744681
- 0.48851063829787233
- 0.4848404255319149
- 0.40691489361702127
- 0.5061170212765957
- 0.4921276595744681
- 0.4922872340425532
- 0.4933510638297872
- 0.49925531914893617
test_loss_list:
- 3.7917400360107423
- 3.754431749979655
- 3.670843722025553
- 3.5954504426320395
- 3.5575077692667643
- 3.515049034754435
- 3.2857917086283366
- 3.2610129006703694
- 3.5341172377268473
- 3.6239196236928306
- 3.549363187154134
- 3.481422020594279
- 3.3337686252593994
- 3.440403823852539
- 3.3536430199941
- 3.452097625732422
- 3.505258118311564
- 3.428468853632609
- 3.8362200387318928
- 3.6210730266571045
- 3.2977861309051515
- 2.6915501817067464
- 2.889053382873535
- 2.905277134577433
- 3.137997430165609
- 2.9715249347686767
- 3.1149584611256915
- 2.9766288216908774
- 3.1460297044118244
- 3.581698818206787
- 3.0128830687204995
- 3.2249280993143716
- 2.9395152791341146
- 3.215375623703003
- 3.4311061541239423
- 2.956576414108276
- 2.697461544672648
- 2.6821703720092773
- 3.2297395769755046
- 3.1073440488179527
- 3.0923140462239584
- 3.015671084721883
- 2.9020066897074384
- 2.9515455945332847
- 2.792084560394287
- 2.708897164662679
- 2.805274550120036
- 3.123013763427734
- 3.022586259841919
- 3.0077079137166343
- 2.658164742787679
- 2.760786822636922
- 2.5339609591166177
- 3.186832113265991
- 2.7886993312835693
- 2.9162647755940756
- 2.880448455810547
- 2.6369691340128583
- 2.8187196254730225
- 2.40696590423584
- 2.364110059738159
- 2.7701812744140626
- 2.6034152348836264
- 2.5001125717163086
- 2.4263286113739015
- 2.6814302253723143
- 2.689766788482666
- 2.387170810699463
- 2.7224143759409585
- 2.4612604014078774
- 2.875145311355591
- 2.3943723583221437
- 1.9484324248631795
- 2.644577449162801
- 2.274078690210978
- 2.2953343788782754
- 2.2118109321594237
- 2.5977383359273274
- 2.329822092056274
- 2.2555538431803384
- 2.568654114405314
- 2.274393768310547
- 2.470447251001994
- 2.2870664978027344
- 2.2304844284057617
- 2.4786318810780843
- 2.162823011080424
- 2.271808633804321
- 2.043670902252197
- 2.2762198384602863
- 2.078276311556498
- 2.1537568680445354
- 2.129757726987203
- 2.3977539189656576
- 2.0356427907943724
- 1.9218587112426757
- 2.344027673403422
- 2.3578605047861734
- 2.299270315170288
- 2.1257263803482056
train_accuracy:
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.713
- 0.0
- 0.0
- 0.0
- 0.733
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.767
- 0.0
- 0.642
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.829
- 0.821
- 0.0
- 0.0
- 0.0
- 0.0
- 0.815
- 0.0
- 0.06
- 0.819
- 0.869
- 0.0
- 0.846
- 0.806
- 0.002
- 0.825
- 0.0
- 0.017
- 0.0
- 0.0
- 0.873
- 0.027
- 0.06
- 0.212
- 0.0
- 0.85
- 0.002
- 0.027
- 0.854
- 0.106
- 0.083
- 0.0
- 0.0
- 0.004
- 0.0
- 0.031
- 0.0
- 0.877
- 0.865
- 0.852
- 0.0
- 0.925
- 0.867
- 0.0
- 0.552
- 0.0
- 0.002
- 0.004
- 0.0
- 0.881
- 0.877
- 0.0
- 0.0
- 0.0
- 0.856
- 0.0
- 0.0
- 0.0
- 0.062
- 0.017
- 0.806
- 0.008
- 0.067
- 0.062
- 0.0
- 0.0
- 0.748
- 0.0
- 0.012
- 0.0
- 0.006
- 0.0
train_loss:
- 1.835
- 1.465
- 1.687
- 1.414
- 1.247
- 1.185
- 0.939
- 0.849
- 1.076
- 1.215
- 0.966
- 0.983
- 0.727
- 0.954
- 0.888
- 0.866
- 0.824
- 0.804
- 0.93
- 0.96
- 0.84
- 0.475
- 0.542
- 0.634
- 0.751
- 0.544
- 0.733
- 0.542
- 0.698
- 0.839
- 0.584
- 0.653
- 0.543
- 0.629
- 0.781
- 0.493
- 0.396
- 0.466
- 0.758
- 0.628
- 0.627
- 0.633
- 0.468
- 0.607
- 0.434
- 0.473
- 0.451
- 0.709
- 0.592
- 0.567
- 0.461
- 0.325
- 0.487
- 0.662
- 0.586
- 0.52
- 0.528
- 0.4
- 0.545
- 0.334
- 0.393
- 0.512
- 0.597
- 0.42
- 0.419
- 0.506
- 0.53
- 0.465
- 0.498
- 0.299
- 0.628
- 0.365
- 0.336
- 0.669
- 0.411
- 0.413
- 0.393
- 0.492
- 0.389
- 0.418
- 0.474
- 0.392
- 0.471
- 0.409
- 0.388
- 0.465
- 0.409
- 0.353
- 0.28
- 0.516
- 0.374
- 0.405
- 0.364
- 0.449
- 0.28
- 0.349
- 0.462
- 0.439
- 0.497
- 0.392
unequal: 0
verbose: 1
