avg_train_accuracy: 0.042
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04143617021276596
- 0.11829787234042553
- 0.23856382978723403
- 0.29462765957446807
- 0.32930851063829786
- 0.34393617021276596
- 0.36638297872340425
- 0.37101063829787234
- 0.3832978723404255
- 0.38680851063829785
- 0.38111702127659575
- 0.40372340425531916
- 0.4085106382978723
- 0.4043617021276596
- 0.4151595744680851
- 0.42154255319148937
- 0.4271276595744681
- 0.4302659574468085
- 0.42638297872340425
- 0.1901063829787234
- 0.42436170212765956
- 0.4331382978723404
- 0.43590425531914895
- 0.43867021276595747
- 0.2641489361702128
- 0.4447872340425532
- 0.4402659574468085
- 0.3056382978723404
- 0.44590425531914896
- 0.3220212765957447
- 0.45324468085106384
- 0.4504787234042553
- 0.45122340425531915
- 0.4520212765957447
- 0.4551595744680851
- 0.4600531914893617
- 0.31813829787234044
- 0.47904255319148936
- 0.4624468085106383
- 0.4624468085106383
- 0.46638297872340423
- 0.4673936170212766
- 0.4613829787234043
- 0.4626595744680851
- 0.34675531914893615
- 0.47760638297872343
- 0.46377659574468083
- 0.46824468085106385
- 0.46930851063829787
- 0.46414893617021274
- 0.4652127659574468
- 0.46622340425531916
- 0.4681382978723404
- 0.46797872340425534
- 0.47127659574468084
- 0.46845744680851065
- 0.47297872340425534
- 0.47622340425531917
- 0.47372340425531917
- 0.47627659574468084
- 0.47117021276595744
- 0.47622340425531917
- 0.48212765957446807
- 0.4697340425531915
- 0.47138297872340423
- 0.47686170212765955
- 0.4727659574468085
- 0.48696808510638295
- 0.48606382978723406
- 0.4752659574468085
- 0.4797872340425532
- 0.47952127659574467
- 0.4881382978723404
- 0.48590425531914894
- 0.49122340425531913
- 0.4832446808510638
- 0.48377659574468085
- 0.4776595744680851
- 0.49356382978723407
- 0.48186170212765955
- 0.4887234042553191
- 0.4820744680851064
- 0.4820744680851064
- 0.4896276595744681
- 0.48143617021276597
- 0.48569148936170214
- 0.4975531914893617
- 0.4868085106382979
- 0.490531914893617
- 0.485
- 0.4968085106382979
- 0.38361702127659575
- 0.5089361702127659
- 0.5125531914893617
- 0.4952127659574468
- 0.514468085106383
- 0.4921808510638298
- 0.5138297872340426
- 0.5051063829787235
- 0.5005851063829787
test_loss_list:
- 3.861444215774536
- 3.9567032782236735
- 3.7200799147288004
- 3.3644839922587075
- 3.3590335051218667
- 3.280495074590047
- 3.243671398162842
- 3.227312526702881
- 3.1624845536549886
- 3.1105823421478274
- 3.2096423880259195
- 3.3109401353200276
- 3.1022354443868
- 3.1269576676686603
- 3.0555291589101157
- 3.3815702692667644
- 3.7113318634033203
- 3.646076485315959
- 3.334231071472168
- 3.331350107192993
- 2.7300835863749184
- 3.1113654963175454
- 2.8851753934224447
- 3.0825891494750977
- 2.6992660554250083
- 3.1531982421875
- 3.2992474746704104
- 2.5894147682189943
- 2.701773420969645
- 2.4503934001922607
- 2.5073271083831785
- 2.584241008758545
- 2.7901017665863037
- 2.6177822144826255
- 2.585630671183268
- 2.653206049601237
- 2.575247424443563
- 2.426276912689209
- 2.502858521143595
- 2.7266857846577963
- 2.5452814610799153
- 2.5040224234263104
- 2.7999068291982017
- 2.530439163843791
- 2.4312905184427898
- 2.3754660574595134
- 2.5563957023620607
- 2.654207099278768
- 2.434579792022705
- 2.6397917048136392
- 2.960383243560791
- 2.646058225631714
- 2.7679262733459473
- 2.6539441108703614
- 2.541413396199544
- 2.9922143459320067
- 2.704145711263021
- 2.7193233585357666
- 2.4271644115448
- 2.396875956853231
- 2.6235241063435875
- 2.619359922409058
- 2.370734074910482
- 2.653289670944214
- 2.6374915599823
- 2.3182873153686523
- 2.6146523571014404
- 2.3512279637654623
- 2.33949906984965
- 2.854615748723348
- 2.259928599993388
- 2.3859790643056233
- 2.2076814206441244
- 2.5095453612009684
- 2.287353998819987
- 2.5701138178507485
- 2.6158527755737304
- 2.8316836325327555
- 2.266402891476949
- 2.333147045771281
- 2.4492340819040934
- 2.476991523106893
- 2.486288792292277
- 2.210407050450643
- 2.580569019317627
- 2.465498946507772
- 2.116106038093567
- 2.5439505132039386
- 2.3632830238342284
- 2.515846455891927
- 2.1733465147018434
- 2.2097740014394125
- 2.1580881023406984
- 2.1048727067311606
- 2.369881887435913
- 1.9407498502731324
- 2.3927446873982747
- 2.076255586942037
- 2.0797606166203817
- 2.1643592278162638
train_accuracy:
- 0.0
- 0.0
- 0.429
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.698
- 0.0
- 0.713
- 0.76
- 0.0
- 0.746
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.708
- 0.0
- 0.794
- 0.267
- 0.015
- 0.617
- 0.004
- 0.01
- 0.121
- 0.0
- 0.0
- 0.042
- 0.794
- 0.0
- 0.0
- 0.108
- 0.004
- 0.117
- 0.0
- 0.0
- 0.315
- 0.0
- 0.844
- 0.0
- 0.0
- 0.85
- 0.015
- 0.0
- 0.858
- 0.01
- 0.854
- 0.0
- 0.0
- 0.035
- 0.0
- 0.021
- 0.0
- 0.027
- 0.0
- 0.852
- 0.002
- 0.01
- 0.869
- 0.002
- 0.0
- 0.0
- 0.0
- 0.021
- 0.869
- 0.1
- 0.0
- 0.0
- 0.881
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.117
- 0.017
- 0.0
- 0.0
- 0.0
- 0.869
- 0.871
- 0.0
- 0.787
- 0.006
- 0.0
- 0.002
- 0.0
- 0.002
- 0.027
- 0.867
- 0.042
train_loss:
- 2.264
- 1.51
- 1.222
- 1.065
- 0.952
- 0.887
- 0.852
- 0.8
- 0.806
- 0.734
- 0.748
- 0.928
- 0.723
- 0.694
- 0.667
- 0.808
- 0.967
- 0.936
- 0.856
- 0.558
- 0.64
- 0.766
- 0.645
- 0.76
- 0.422
- 0.921
- 0.924
- 0.437
- 0.764
- 0.425
- 0.509
- 0.49
- 0.685
- 0.508
- 0.503
- 0.499
- 0.329
- 0.483
- 0.513
- 0.601
- 0.465
- 0.482
- 0.606
- 0.493
- 0.357
- 0.456
- 0.626
- 0.568
- 0.473
- 0.584
- 0.743
- 0.612
- 0.599
- 0.565
- 0.477
- 0.678
- 0.542
- 0.558
- 0.455
- 0.457
- 0.57
- 0.56
- 0.415
- 0.548
- 0.559
- 0.463
- 0.552
- 0.445
- 0.425
- 0.636
- 0.422
- 0.427
- 0.416
- 0.527
- 0.417
- 0.508
- 0.523
- 0.609
- 0.415
- 0.43
- 0.519
- 0.533
- 0.51
- 0.423
- 0.507
- 0.494
- 0.414
- 0.478
- 0.503
- 0.491
- 0.38
- 0.296
- 0.353
- 0.35
- 0.499
- 0.405
- 0.485
- 0.377
- 0.396
- 0.369
unequal: 0
verbose: 1
