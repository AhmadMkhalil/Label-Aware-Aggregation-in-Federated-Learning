avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029361702127659574
- 0.09627659574468085
- 0.19680851063829788
- 0.25803191489361704
- 0.30148936170212765
- 0.31361702127659574
- 0.33914893617021274
- 0.3447340425531915
- 0.35473404255319146
- 0.36579787234042555
- 0.37159574468085105
- 0.37648936170212766
- 0.39361702127659576
- 0.3904255319148936
- 0.3959042553191489
- 0.390531914893617
- 0.38872340425531915
- 0.3997340425531915
- 0.4034042553191489
- 0.40622340425531916
- 0.28654255319148936
- 0.26340425531914896
- 0.41345744680851065
- 0.41127659574468084
- 0.42409574468085104
- 0.41936170212765955
- 0.4204787234042553
- 0.43042553191489363
- 0.4271808510638298
- 0.43425531914893617
- 0.43303191489361703
- 0.44074468085106383
- 0.44005319148936173
- 0.4409574468085106
- 0.4422340425531915
- 0.4429787234042553
- 0.4452127659574468
- 0.4420212765957447
- 0.4497340425531915
- 0.4517553191489362
- 0.45813829787234045
- 0.45643617021276595
- 0.451968085106383
- 0.456968085106383
- 0.46
- 0.45398936170212767
- 0.4613829787234043
- 0.46372340425531916
- 0.4573936170212766
- 0.4580851063829787
- 0.45478723404255317
- 0.4631914893617021
- 0.46404255319148935
- 0.4642553191489362
- 0.4626063829787234
- 0.4652659574468085
- 0.46441489361702126
- 0.46867021276595744
- 0.46063829787234045
- 0.46606382978723404
- 0.46547872340425533
- 0.46835106382978725
- 0.469468085106383
- 0.46622340425531916
- 0.4692021276595745
- 0.46893617021276596
- 0.47111702127659577
- 0.4681382978723404
- 0.46702127659574466
- 0.4696808510638298
- 0.47095744680851065
- 0.47585106382978726
- 0.4723936170212766
- 0.4725531914893617
- 0.4722872340425532
- 0.4774468085106383
- 0.47622340425531917
- 0.47606382978723405
- 0.47962765957446807
- 0.44340425531914895
- 0.47898936170212764
- 0.4825531914893617
- 0.48569148936170214
- 0.4827659574468085
- 0.47904255319148936
- 0.4825
- 0.48138297872340424
- 0.4803723404255319
- 0.48090425531914893
- 0.48558510638297875
- 0.4876063829787234
- 0.48781914893617023
- 0.446063829787234
- 0.4956382978723404
- 0.4922872340425532
- 0.48877659574468085
- 0.49292553191489363
- 0.48696808510638295
- 0.4925531914893617
- 0.48909574468085104
test_loss_list:
- 3.884936777750651
- 4.002117067972819
- 4.157463436126709
- 4.053375358581543
- 4.048928057352702
- 3.6147550423940022
- 3.5395113023122153
- 3.2677446937561037
- 3.518736769358317
- 3.2504246934254963
- 3.2280830828348797
- 3.1257853571573895
- 3.5069706281026205
- 3.301201556523641
- 3.3465654118855794
- 3.190664790471395
- 3.1973617362976072
- 3.1945820077260336
- 3.1741821257273357
- 3.1178662395477295
- 2.782340507507324
- 2.959328721364339
- 3.0099567381540933
- 2.977859764099121
- 3.327581475575765
- 3.0001123015085858
- 3.1845643615722654
- 2.923261423110962
- 3.153353010813395
- 3.4348850695292157
- 3.0893572489420573
- 3.1839800516764325
- 3.2946334425608317
- 3.2156593004862466
- 3.3984315236409506
- 3.1462271372477213
- 3.1957574208577473
- 2.8878950945536297
- 2.8673056602478026
- 2.8550140635172525
- 3.082827237447103
- 3.1035384527842202
- 2.7782610193888346
- 3.1935905488332113
- 3.451387360890706
- 2.6676558526357015
- 2.7740645853678387
- 2.7184743595123293
- 2.9912826379140216
- 3.016166785558065
- 2.714246104558309
- 2.7555049069722495
- 3.266226790746053
- 2.693089812596639
- 2.9240520858764647
- 2.709052527745565
- 2.988164135615031
- 2.780137923558553
- 2.6178389263153075
- 3.2260506884257
- 2.6101532204945883
- 2.9752643394470213
- 3.239403435389201
- 2.9133888339996337
- 2.801692342758179
- 2.871448055903117
- 2.8465584977467855
- 2.8225649038950604
- 2.687945718765259
- 2.9083174387613933
- 2.4990294138590494
- 2.599847723642985
- 2.5393135833740232
- 2.822164128621419
- 2.6680482482910155
- 2.615547310511271
- 2.823755216598511
- 2.63080002784729
- 2.514108018875122
- 2.0280317227045694
- 2.504369862874349
- 2.657057539621989
- 2.4358551279703775
- 2.573966595331828
- 2.7151011784871417
- 2.629462327957153
- 2.426306095123291
- 2.396901235580444
- 2.418494249979655
- 2.380690371195475
- 2.323779033025106
- 2.374353971481323
- 1.842448239326477
- 2.106422282854716
- 2.1767953046162924
- 2.4400266456604003
- 2.2100591723124188
- 2.5081448618570965
- 2.351187000274658
- 2.5333444245656334
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.517
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.719
- 0.0
- 0.002
- 0.0
- 0.0
- 0.733
- 0.0
- 0.148
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.802
- 0.0
- 0.812
- 0.808
- 0.796
- 0.0
- 0.823
- 0.004
- 0.0
- 0.0
- 0.819
- 0.833
- 0.0
- 0.0
- 0.84
- 0.0
- 0.844
- 0.835
- 0.846
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.0
- 0.86
- 0.0
- 0.856
- 0.0
- 0.871
- 0.842
- 0.004
- 0.85
- 0.0
- 0.008
- 0.0
- 0.002
- 0.006
- 0.035
- 0.002
- 0.021
- 0.854
- 0.858
- 0.0
- 0.871
- 0.0
- 0.0
- 0.052
- 0.877
- 0.852
- 0.0
- 0.008
- 0.0
- 0.875
- 0.0
- 0.0
- 0.006
- 0.006
- 0.86
- 0.0
- 0.542
- 0.002
- 0.885
- 0.0
- 0.0
- 0.871
- 0.89
- 0.0
train_loss:
- 1.728
- 1.454
- 1.748
- 1.459
- 1.643
- 1.321
- 1.17
- 0.9
- 1.149
- 0.846
- 0.851
- 0.786
- 0.997
- 0.952
- 0.943
- 0.725
- 0.779
- 0.695
- 0.699
- 0.737
- 0.482
- 0.453
- 0.598
- 0.666
- 0.778
- 0.633
- 0.797
- 0.658
- 0.794
- 0.737
- 0.581
- 0.816
- 0.735
- 0.708
- 0.922
- 0.743
- 0.74
- 0.584
- 0.561
- 0.543
- 0.699
- 0.692
- 0.567
- 0.659
- 0.782
- 0.609
- 0.551
- 0.515
- 0.643
- 0.659
- 0.532
- 0.507
- 0.752
- 0.495
- 0.647
- 0.476
- 0.573
- 0.621
- 0.506
- 0.698
- 0.501
- 0.565
- 0.718
- 0.573
- 0.613
- 0.567
- 0.569
- 0.552
- 0.437
- 0.546
- 0.475
- 0.418
- 0.468
- 0.576
- 0.576
- 0.419
- 0.556
- 0.56
- 0.451
- 0.313
- 0.578
- 0.541
- 0.401
- 0.573
- 0.537
- 0.526
- 0.424
- 0.424
- 0.449
- 0.438
- 0.419
- 0.405
- 0.337
- 0.411
- 0.42
- 0.507
- 0.436
- 0.527
- 0.417
- 0.518
unequal: 0
verbose: 1
