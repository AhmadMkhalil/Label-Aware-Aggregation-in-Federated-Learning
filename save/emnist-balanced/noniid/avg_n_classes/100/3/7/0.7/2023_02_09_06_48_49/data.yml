avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.028351063829787235
- 0.09797872340425531
- 0.24111702127659573
- 0.2820744680851064
- 0.3222340425531915
- 0.33739361702127657
- 0.350531914893617
- 0.36569148936170215
- 0.3704787234042553
- 0.3825531914893617
- 0.383563829787234
- 0.3875
- 0.3981914893617021
- 0.4042021276595745
- 0.4100531914893617
- 0.4071808510638298
- 0.4097340425531915
- 0.41569148936170214
- 0.4128191489361702
- 0.41867021276595745
- 0.42446808510638295
- 0.425
- 0.4272340425531915
- 0.4272872340425532
- 0.43420212765957444
- 0.43627659574468086
- 0.43340425531914895
- 0.43638297872340426
- 0.43803191489361704
- 0.44292553191489364
- 0.4536702127659574
- 0.4521276595744681
- 0.4498936170212766
- 0.455
- 0.4592553191489362
- 0.4614893617021277
- 0.4559042553191489
- 0.46202127659574466
- 0.46361702127659576
- 0.46106382978723404
- 0.46154255319148935
- 0.46239361702127657
- 0.46595744680851064
- 0.46691489361702126
- 0.4702127659574468
- 0.46872340425531916
- 0.47095744680851065
- 0.47558510638297874
- 0.48356382978723406
- 0.4875531914893617
- 0.4930851063829787
- 0.4854255319148936
- 0.4874468085106383
- 0.48154255319148936
- 0.4843085106382979
- 0.49601063829787234
- 0.4899468085106383
- 0.48856382978723406
- 0.48095744680851066
- 0.4782446808510638
- 0.4946808510638298
- 0.5008510638297873
- 0.48579787234042554
- 0.503563829787234
- 0.4947872340425532
- 0.49042553191489363
- 0.4927127659574468
- 0.4826063829787234
- 0.4895212765957447
- 0.4996276595744681
- 0.4825531914893617
- 0.4952659574468085
- 0.49792553191489364
- 0.5029255319148936
- 0.481968085106383
- 0.5130851063829788
- 0.488031914893617
- 0.4995212765957447
- 0.49234042553191487
- 0.4926063829787234
- 0.5029255319148936
- 0.5029787234042553
- 0.5008510638297873
- 0.49388297872340425
- 0.4969148936170213
- 0.5082446808510638
- 0.5010638297872341
- 0.5065425531914893
- 0.49420212765957444
- 0.5032978723404256
- 0.5153723404255319
- 0.5256914893617022
- 0.5246808510638298
- 0.5063829787234042
- 0.5151595744680851
- 0.5306914893617021
- 0.519468085106383
- 0.528031914893617
- 0.5072872340425532
- 0.5151595744680851
test_loss_list:
- 3.811995840072632
- 3.6998091316223145
- 3.42740608215332
- 3.3075060335795086
- 3.1569166564941407
- 3.1889976501464843
- 3.0254345162709555
- 3.113730812072754
- 2.946557327906291
- 3.03933988571167
- 2.850530745188395
- 2.883943513234456
- 2.840747413635254
- 2.9722260443369546
- 2.967053000132243
- 2.671410977045695
- 2.596684939066569
- 2.665107838312785
- 2.517188278834025
- 2.844621483484904
- 2.675466022491455
- 2.5934894053141275
- 2.59024569829305
- 2.6577152474721273
- 2.4455518436431887
- 2.663697363535563
- 2.596044543584188
- 2.4650398381551106
- 2.3174211819966635
- 2.370064646402995
- 2.651215165456136
- 2.6074474557240803
- 2.611645933787028
- 2.417504081726074
- 2.439863125483195
- 2.3616486835479735
- 2.362679656346639
- 2.3426575024922687
- 2.3866250769297284
- 2.2682045618693034
- 2.2925469303131103
- 2.4677009709676105
- 2.1130729866027833
- 2.5661655616760255
- 2.0099689102172853
- 2.252870869636536
- 2.5078347396850584
- 2.253874306678772
- 2.0217674509684245
- 2.078509111404419
- 2.0705870532989503
- 2.140469853083293
- 2.204183677037557
- 2.1043636258443197
- 2.1284697977701823
- 1.9554288212458293
- 2.1425449657440185
- 1.998249618212382
- 2.400073912938436
- 2.3388261731465656
- 2.1046584606170655
- 1.9473332007726034
- 2.304732894897461
- 1.8880468638737997
- 2.0684106890360514
- 2.343971176147461
- 1.9565188805262248
- 2.2732134199142457
- 2.21947758992513
- 1.964585812886556
- 2.2012569522857666
- 1.986633685429891
- 2.044267772038778
- 2.005133752822876
- 2.1668710327148437
- 1.7514314699172973
- 2.2147322114308676
- 1.899500584602356
- 1.9737656831741333
- 2.214666152000427
- 1.9516986910502117
- 1.980057414372762
- 2.153687008221944
- 2.1566821177800497
- 2.1866121991475422
- 1.8181906954447429
- 1.8963007720311482
- 1.9187425724665323
- 2.0326598437627155
- 2.067148275375366
- 1.924727357228597
- 1.7970600255330405
- 1.7348102204004923
- 2.094845414161682
- 1.8403825934727986
- 1.6176684999465942
- 1.8929720417658489
- 1.8312884839375814
- 2.1435350688298542
- 2.039685344696045
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.537
- 0.579
- 0.0
- 0.0
- 0.64
- 0.669
- 0.0
- 0.696
- 0.004
- 0.748
- 0.0
- 0.758
- 0.0
- 0.006
- 0.004
- 0.0
- 0.79
- 0.006
- 0.01
- 0.002
- 0.002
- 0.0
- 0.0
- 0.804
- 0.79
- 0.01
- 0.002
- 0.029
- 0.046
- 0.052
- 0.004
- 0.81
- 0.842
- 0.002
- 0.0
- 0.808
- 0.004
- 0.0
- 0.838
- 0.117
- 0.0
- 0.0
- 0.0
- 0.84
- 0.84
- 0.0
- 0.192
- 0.0
- 0.812
- 0.017
- 0.819
- 0.017
- 0.019
- 0.821
- 0.006
- 0.865
- 0.835
- 0.002
- 0.21
- 0.854
- 0.065
- 0.015
- 0.867
- 0.004
- 0.846
- 0.854
- 0.867
- 0.871
- 0.106
- 0.142
- 0.002
- 0.0
- 0.179
- 0.854
- 0.0
- 0.873
- 0.892
- 0.198
- 0.217
- 0.863
- 0.004
- 0.89
- 0.002
- 0.008
- 0.865
- 0.023
- 0.873
- 0.887
- 0.002
- 0.11
- 0.887
- 0.071
- 0.067
- 0.004
- 0.019
- 0.24
- 0.0
train_loss:
- 1.493
- 1.581
- 1.337
- 1.18
- 1.07
- 1.233
- 0.916
- 1.129
- 0.872
- 0.989
- 0.816
- 0.77
- 0.756
- 0.895
- 0.881
- 0.722
- 0.562
- 0.669
- 0.538
- 0.806
- 0.757
- 0.656
- 0.632
- 0.718
- 0.508
- 0.71
- 0.708
- 0.591
- 0.478
- 0.584
- 0.685
- 0.671
- 0.691
- 0.577
- 0.555
- 0.538
- 0.543
- 0.522
- 0.541
- 0.51
- 0.517
- 0.602
- 0.426
- 0.604
- 0.407
- 0.48
- 0.595
- 0.497
- 0.41
- 0.382
- 0.384
- 0.465
- 0.475
- 0.472
- 0.47
- 0.382
- 0.468
- 0.449
- 0.548
- 0.539
- 0.449
- 0.37
- 0.532
- 0.359
- 0.43
- 0.528
- 0.445
- 0.513
- 0.531
- 0.442
- 0.507
- 0.434
- 0.432
- 0.439
- 0.494
- 0.362
- 0.495
- 0.414
- 0.42
- 0.491
- 0.41
- 0.412
- 0.495
- 0.493
- 0.479
- 0.338
- 0.42
- 0.409
- 0.479
- 0.491
- 0.418
- 0.324
- 0.323
- 0.479
- 0.412
- 0.322
- 0.4
- 0.406
- 0.465
- 0.473
unequal: 0
verbose: 1
