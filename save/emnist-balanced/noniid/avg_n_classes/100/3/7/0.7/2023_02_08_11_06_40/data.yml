avg_train_accuracy: 0.86
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04893617021276596
- 0.11063829787234042
- 0.19675531914893618
- 0.2728191489361702
- 0.29271276595744683
- 0.31148936170212765
- 0.33845744680851064
- 0.3527127659574468
- 0.365
- 0.3608510638297872
- 0.3750531914893617
- 0.38638297872340427
- 0.38361702127659575
- 0.38670212765957446
- 0.3854787234042553
- 0.40132978723404256
- 0.398031914893617
- 0.4071808510638298
- 0.41047872340425534
- 0.4146808510638298
- 0.4201595744680851
- 0.419468085106383
- 0.42361702127659573
- 0.42473404255319147
- 0.42664893617021277
- 0.428936170212766
- 0.4373404255319149
- 0.4408510638297872
- 0.4295744680851064
- 0.4379787234042553
- 0.4501063829787234
- 0.4467553191489362
- 0.446063829787234
- 0.4496276595744681
- 0.4402127659574468
- 0.45632978723404255
- 0.4471276595744681
- 0.4551595744680851
- 0.44659574468085106
- 0.45170212765957446
- 0.44851063829787235
- 0.45276595744680853
- 0.4696808510638298
- 0.45872340425531916
- 0.46787234042553194
- 0.4626595744680851
- 0.46702127659574466
- 0.4603191489361702
- 0.46925531914893615
- 0.47367021276595744
- 0.47441489361702127
- 0.46558510638297873
- 0.47069148936170213
- 0.4692021276595745
- 0.4844148936170213
- 0.4697340425531915
- 0.4803723404255319
- 0.4972872340425532
- 0.4896276595744681
- 0.4849468085106383
- 0.48877659574468085
- 0.4820212765957447
- 0.49659574468085105
- 0.4879787234042553
- 0.4832446808510638
- 0.4769148936170213
- 0.4929787234042553
- 0.48909574468085104
- 0.4892021276595745
- 0.4991489361702128
- 0.48101063829787233
- 0.49898936170212765
- 0.4799468085106383
- 0.5029787234042553
- 0.49159574468085104
- 0.49579787234042555
- 0.5206382978723404
- 0.4875
- 0.5022872340425532
- 0.4952659574468085
- 0.5062234042553192
- 0.5000531914893617
- 0.48781914893617023
- 0.5020212765957447
- 0.5047340425531915
- 0.4965425531914894
- 0.5270744680851064
- 0.5111702127659574
- 0.5222340425531915
- 0.5081914893617021
- 0.49920212765957445
- 0.518031914893617
- 0.49877659574468086
- 0.5169148936170213
- 0.5044148936170213
- 0.5122872340425532
- 0.5280851063829787
- 0.521595744680851
- 0.5099468085106383
- 0.5028723404255319
test_loss_list:
- 3.8501941680908205
- 3.802312072118123
- 3.600561803181966
- 3.339944076538086
- 3.261502777735392
- 3.095857025782267
- 3.12062180519104
- 3.06831916809082
- 3.1782040564219156
- 3.043527908325195
- 2.989805065790812
- 3.1656608740488688
- 2.8688353157043456
- 3.072828073501587
- 2.81386492729187
- 2.8322298685709635
- 2.672483263015747
- 2.810858370463053
- 2.9907171535491943
- 2.946472438176473
- 2.628785800933838
- 2.6723365942637125
- 2.887495133082072
- 2.632937707901001
- 2.78618852297465
- 2.362575133641561
- 2.831888567606608
- 2.279850910504659
- 2.465754648844401
- 2.40923926671346
- 2.274932870864868
- 2.536972115834554
- 2.3626305135091146
- 2.406147216161092
- 2.6256493600209554
- 2.1874294551213582
- 2.5861081059773765
- 2.2798320070902505
- 2.3136917527516685
- 2.2755942058563234
- 2.5044053586324058
- 2.569731124242147
- 2.09605441570282
- 2.0988945690790812
- 2.276580622990926
- 2.2118737284342447
- 2.170327835083008
- 2.412767302195231
- 2.244165061314901
- 1.9499001757303873
- 2.202101035118103
- 2.0370393244425458
- 2.1620600700378416
- 2.359739548365275
- 1.8683659394582113
- 2.0816099389394123
- 2.0740888484319053
- 1.8606342458724976
- 1.9523392089207967
- 2.04324990272522
- 1.9714538971583049
- 2.0608219448725382
- 1.865513784090678
- 2.061348559061686
- 1.9677618821461995
- 2.169422844250997
- 1.9812839635213215
- 1.9351163180669149
- 1.986040563583374
- 1.891788288752238
- 2.2208309253056844
- 1.8999416255950927
- 2.2092250140508014
- 1.8247949345906576
- 1.930947461128235
- 1.9865372037887574
- 1.7384465551376342
- 2.306208504041036
- 1.8274147717158
- 1.9655560811360677
- 1.8272577985127767
- 1.970716241200765
- 2.085972458521525
- 2.1104790623982748
- 1.8104354651769001
- 2.181537920633952
- 1.703245898882548
- 1.9308712069193523
- 1.6652218151092528
- 1.8587789964675903
- 2.131364781061808
- 1.7461753193537395
- 2.1013402938842773
- 1.7745927063624065
- 2.0106524801254273
- 1.8016572332382201
- 1.7926942952473959
- 1.8046823358535766
- 2.0233736769358317
- 2.048325702349345
train_accuracy:
- 0.083
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.658
- 0.0
- 0.0
- 0.0
- 0.0
- 0.021
- 0.004
- 0.698
- 0.729
- 0.071
- 0.0
- 0.748
- 0.0
- 0.0
- 0.0
- 0.76
- 0.0
- 0.777
- 0.027
- 0.0
- 0.133
- 0.002
- 0.002
- 0.002
- 0.006
- 0.0
- 0.0
- 0.0
- 0.781
- 0.785
- 0.096
- 0.0
- 0.781
- 0.004
- 0.819
- 0.037
- 0.004
- 0.779
- 0.002
- 0.017
- 0.01
- 0.8
- 0.185
- 0.01
- 0.0
- 0.829
- 0.0
- 0.058
- 0.827
- 0.015
- 0.31
- 0.006
- 0.088
- 0.787
- 0.04
- 0.062
- 0.037
- 0.0
- 0.0
- 0.808
- 0.046
- 0.0
- 0.819
- 0.017
- 0.065
- 0.833
- 0.006
- 0.815
- 0.023
- 0.069
- 0.842
- 0.846
- 0.019
- 0.825
- 0.0
- 0.021
- 0.021
- 0.846
- 0.0
- 0.219
- 0.0
- 0.01
- 0.202
- 0.0
- 0.829
- 0.835
- 0.0
- 0.852
- 0.825
- 0.042
- 0.856
- 0.071
- 0.86
train_loss:
- 2.247
- 1.217
- 1.347
- 1.214
- 1.043
- 0.757
- 0.892
- 0.859
- 1.056
- 0.808
- 0.783
- 0.961
- 0.803
- 0.915
- 0.761
- 0.705
- 0.589
- 0.71
- 0.842
- 0.822
- 0.711
- 0.646
- 0.78
- 0.639
- 0.776
- 0.506
- 0.766
- 0.494
- 0.575
- 0.601
- 0.464
- 0.581
- 0.579
- 0.572
- 0.69
- 0.459
- 0.689
- 0.569
- 0.535
- 0.558
- 0.646
- 0.666
- 0.436
- 0.416
- 0.527
- 0.527
- 0.528
- 0.631
- 0.543
- 0.418
- 0.518
- 0.5
- 0.496
- 0.614
- 0.403
- 0.48
- 0.494
- 0.386
- 0.394
- 0.485
- 0.484
- 0.489
- 0.381
- 0.486
- 0.479
- 0.569
- 0.473
- 0.467
- 0.455
- 0.455
- 0.545
- 0.472
- 0.544
- 0.465
- 0.448
- 0.447
- 0.381
- 0.541
- 0.452
- 0.454
- 0.443
- 0.452
- 0.513
- 0.528
- 0.443
- 0.523
- 0.363
- 0.443
- 0.341
- 0.42
- 0.524
- 0.435
- 0.518
- 0.427
- 0.502
- 0.43
- 0.423
- 0.412
- 0.491
- 0.493
unequal: 0
verbose: 1
