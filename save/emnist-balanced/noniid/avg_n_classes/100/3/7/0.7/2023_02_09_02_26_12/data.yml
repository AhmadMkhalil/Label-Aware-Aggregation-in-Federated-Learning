avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026436170212765956
- 0.12425531914893617
- 0.24851063829787234
- 0.3045744680851064
- 0.3320744680851064
- 0.3493617021276596
- 0.3525
- 0.3698404255319149
- 0.3759574468085106
- 0.3854255319148936
- 0.3925531914893617
- 0.3947340425531915
- 0.399468085106383
- 0.40393617021276595
- 0.41047872340425534
- 0.4123936170212766
- 0.41510638297872343
- 0.4182446808510638
- 0.4196808510638298
- 0.4237234042553191
- 0.42664893617021277
- 0.42856382978723406
- 0.43159574468085105
- 0.4294148936170213
- 0.43617021276595747
- 0.4352659574468085
- 0.4425
- 0.4452659574468085
- 0.4371276595744681
- 0.44813829787234044
- 0.45122340425531915
- 0.4476063829787234
- 0.4521276595744681
- 0.4554787234042553
- 0.4537765957446809
- 0.455531914893617
- 0.4532978723404255
- 0.4571276595744681
- 0.4566489361702128
- 0.46239361702127657
- 0.46335106382978725
- 0.4576063829787234
- 0.46537234042553194
- 0.46638297872340423
- 0.4703191489361702
- 0.32930851063829786
- 0.4740957446808511
- 0.46617021276595744
- 0.4653191489361702
- 0.4728723404255319
- 0.4671276595744681
- 0.47632978723404257
- 0.47414893617021275
- 0.4779255319148936
- 0.4823404255319149
- 0.48
- 0.4798936170212766
- 0.48138297872340424
- 0.47914893617021276
- 0.47962765957446807
- 0.4732446808510638
- 0.4731382978723404
- 0.4921808510638298
- 0.47558510638297874
- 0.48569148936170214
- 0.48845744680851066
- 0.48781914893617023
- 0.496436170212766
- 0.48909574468085104
- 0.4849468085106383
- 0.5007446808510638
- 0.4803723404255319
- 0.48377659574468085
- 0.49957446808510636
- 0.4871276595744681
- 0.4851063829787234
- 0.4819148936170213
- 0.49164893617021277
- 0.4949468085106383
- 0.49611702127659574
- 0.4854787234042553
- 0.4932446808510638
- 0.49281914893617024
- 0.5036702127659575
- 0.5086170212765957
- 0.5109574468085106
- 0.5125531914893617
- 0.49409574468085105
- 0.4957446808510638
- 0.5142553191489362
- 0.500531914893617
- 0.49372340425531913
- 0.4892021276595745
- 0.49127659574468086
- 0.5107446808510638
- 0.49367021276595746
- 0.49398936170212765
- 0.49409574468085105
- 0.5143085106382979
- 0.5082978723404256
test_loss_list:
- 3.8426113001505535
- 3.664520279566447
- 3.4220265928904214
- 3.19056502978007
- 3.150497220357259
- 3.1296722412109377
- 2.9658424536387127
- 3.155028533935547
- 2.8917326800028484
- 3.0900732453664146
- 2.91807102839152
- 2.8527966944376626
- 2.9302655824025474
- 2.893839063644409
- 2.9560346444447836
- 2.670622720718384
- 3.034357973734538
- 2.900002549489339
- 2.91440923055013
- 2.934272050857544
- 2.5948048559824626
- 2.7279483826955158
- 2.7199264907836915
- 2.8446348603566487
- 2.4356885019938153
- 2.8313157176971435
- 2.4041253662109376
- 2.5641386477152506
- 2.7224404939015705
- 2.6836112467447917
- 2.485421371459961
- 2.558764867782593
- 2.4050258858998617
- 2.423084805806478
- 2.2704540506998696
- 2.644487101236979
- 2.621312665939331
- 2.266395540237427
- 2.3822348499298096
- 2.3446064726511637
- 2.6062756792704262
- 2.4876642417907715
- 2.1874945656458538
- 2.262427635192871
- 2.2839885409673055
- 2.3005961545308433
- 2.1467121839523315
- 2.239135494232178
- 2.3866067695617676
- 2.1846197017033897
- 2.243799169858297
- 2.2009284925460815
- 2.3927764097849527
- 2.146704297065735
- 2.198023018836975
- 2.0538915618260702
- 2.202960801124573
- 2.311046390533447
- 2.2888543589909873
- 2.1342289543151853
- 2.188062070210775
- 2.303177653948466
- 1.9851493692398072
- 2.1657131814956667
- 2.0865966510772704
- 2.1086210266749066
- 2.1390808153152467
- 1.9099146763483683
- 2.300259132385254
- 1.990759275754293
- 1.8692831071217855
- 2.2571418476104737
- 2.0201739422480265
- 2.0237560335795086
- 2.1458799616495767
- 2.2209272066752117
- 2.22056435585022
- 2.011716823577881
- 2.034839005470276
- 1.992582418123881
- 2.189306877454122
- 2.1909344164530435
- 2.1262130085627238
- 1.8084050957361857
- 1.78956063747406
- 1.8698214070002237
- 1.8295356289545694
- 2.121022880872091
- 2.0734626897176107
- 1.7590559895833333
- 1.9041966931025187
- 2.02885266939799
- 2.064137454032898
- 2.089635887145996
- 1.7441667016347249
- 2.099055465062459
- 2.0752492205301922
- 1.9942554410298665
- 1.7076732158660888
- 1.8715071551005045
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.531
- 0.0
- 0.0
- 0.002
- 0.698
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.74
- 0.0
- 0.0
- 0.0
- 0.756
- 0.025
- 0.0
- 0.756
- 0.79
- 0.133
- 0.0
- 0.046
- 0.0
- 0.0
- 0.0
- 0.002
- 0.008
- 0.815
- 0.002
- 0.002
- 0.783
- 0.81
- 0.004
- 0.058
- 0.0
- 0.808
- 0.0
- 0.004
- 0.823
- 0.027
- 0.113
- 0.823
- 0.812
- 0.815
- 0.819
- 0.015
- 0.006
- 0.002
- 0.004
- 0.044
- 0.838
- 0.84
- 0.844
- 0.027
- 0.012
- 0.04
- 0.015
- 0.002
- 0.008
- 0.069
- 0.833
- 0.0
- 0.831
- 0.002
- 0.01
- 0.071
- 0.846
- 0.015
- 0.844
- 0.004
- 0.004
- 0.012
- 0.017
- 0.004
- 0.852
- 0.85
- 0.0
- 0.863
- 0.017
- 0.85
- 0.0
- 0.0
- 0.094
- 0.042
- 0.0
- 0.846
- 0.863
- 0.858
- 0.867
- 0.033
- 0.01
- 0.85
- 0.863
- 0.844
- 0.0
train_loss:
- 1.631
- 1.21
- 1.268
- 1.155
- 1.013
- 0.954
- 0.736
- 1.074
- 0.659
- 1.029
- 0.8
- 0.823
- 0.803
- 0.739
- 0.911
- 0.586
- 0.866
- 0.85
- 0.816
- 0.814
- 0.555
- 0.687
- 0.638
- 0.756
- 0.533
- 0.741
- 0.508
- 0.645
- 0.728
- 0.745
- 0.605
- 0.572
- 0.588
- 0.587
- 0.475
- 0.678
- 0.666
- 0.443
- 0.557
- 0.539
- 0.643
- 0.67
- 0.431
- 0.413
- 0.541
- 0.326
- 0.533
- 0.514
- 0.604
- 0.498
- 0.506
- 0.475
- 0.584
- 0.532
- 0.495
- 0.382
- 0.496
- 0.592
- 0.596
- 0.492
- 0.497
- 0.577
- 0.395
- 0.492
- 0.466
- 0.461
- 0.46
- 0.379
- 0.55
- 0.468
- 0.369
- 0.564
- 0.451
- 0.449
- 0.553
- 0.554
- 0.536
- 0.457
- 0.441
- 0.428
- 0.513
- 0.52
- 0.528
- 0.339
- 0.329
- 0.437
- 0.333
- 0.496
- 0.508
- 0.353
- 0.436
- 0.519
- 0.502
- 0.49
- 0.342
- 0.485
- 0.504
- 0.495
- 0.334
- 0.415
unequal: 0
verbose: 1
