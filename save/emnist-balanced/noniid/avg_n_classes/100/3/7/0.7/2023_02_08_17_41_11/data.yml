avg_train_accuracy: 0.183
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024946808510638296
- 0.10808510638297872
- 0.1975
- 0.27351063829787237
- 0.28058510638297873
- 0.31117021276595747
- 0.3470744680851064
- 0.34132978723404256
- 0.35829787234042554
- 0.37893617021276593
- 0.3702659574468085
- 0.3887765957446809
- 0.39154255319148934
- 0.39228723404255317
- 0.39861702127659576
- 0.40180851063829787
- 0.4110106382978723
- 0.41856382978723405
- 0.4129255319148936
- 0.42367021276595745
- 0.42819148936170215
- 0.4278723404255319
- 0.4292021276595745
- 0.4372872340425532
- 0.44409574468085106
- 0.4434574468085106
- 0.44872340425531915
- 0.4546276595744681
- 0.4476063829787234
- 0.4537765957446809
- 0.451063829787234
- 0.46154255319148935
- 0.4632978723404255
- 0.45845744680851064
- 0.4640957446808511
- 0.4646276595744681
- 0.46585106382978725
- 0.4652127659574468
- 0.46143617021276595
- 0.4648936170212766
- 0.47356382978723405
- 0.48154255319148936
- 0.4649468085106383
- 0.46872340425531916
- 0.47111702127659577
- 0.48888297872340425
- 0.4723936170212766
- 0.4903723404255319
- 0.47095744680851065
- 0.4833510638297872
- 0.48595744680851066
- 0.4853723404255319
- 0.4947872340425532
- 0.49840425531914895
- 0.47856382978723405
- 0.5080851063829788
- 0.48829787234042554
- 0.4922872340425532
- 0.501968085106383
- 0.48675531914893616
- 0.4903723404255319
- 0.4873936170212766
- 0.4867021276595745
- 0.5159574468085106
- 0.4994148936170213
- 0.49611702127659574
- 0.5048404255319149
- 0.49377659574468086
- 0.5103191489361703
- 0.5131914893617021
- 0.510531914893617
- 0.4945212765957447
- 0.5225531914893617
- 0.5113829787234042
- 0.5130851063829788
- 0.5227127659574468
- 0.4977127659574468
- 0.5249468085106384
- 0.5042021276595745
- 0.5284574468085106
- 0.5053723404255319
- 0.5472872340425532
- 0.49851063829787234
- 0.5217021276595745
- 0.5402127659574468
- 0.5179787234042553
- 0.5504787234042553
- 0.5019148936170212
- 0.558031914893617
- 0.5145212765957446
- 0.5119148936170212
- 0.5092553191489362
- 0.5436702127659574
- 0.5076595744680851
- 0.5343085106382979
- 0.5153723404255319
- 0.5372872340425532
- 0.5124468085106383
- 0.5169148936170213
- 0.5232978723404256
test_loss_list:
- 3.8361973985036215
- 3.8022170448303223
- 3.642022031148275
- 3.4808984088897703
- 3.377103026707967
- 3.310446637471517
- 3.1195605341593424
- 3.146397720972697
- 3.0189997164408364
- 3.1892371304829914
- 2.89002010345459
- 3.2328908602396647
- 3.021117795308431
- 2.9034565353393553
- 2.8365364996592204
- 2.851434202194214
- 2.702779188156128
- 2.8755482323964436
- 2.668520371119181
- 2.5562539863586426
- 2.857309039433797
- 2.4047812366485597
- 2.451864191691081
- 2.533503386179606
- 2.483460028966268
- 2.401910613377889
- 2.5228035926818846
- 2.300991161664327
- 2.403134578069051
- 2.5771056175231934
- 2.434541120529175
- 2.198818686803182
- 2.2432393074035644
- 2.1838442373275755
- 2.15122096379598
- 2.5787350591023763
- 2.275930519104004
- 2.2821620241800944
- 2.3733015124003094
- 2.379242057800293
- 2.099043978055318
- 2.0708991622924806
- 2.4168398507436115
- 2.3937806924184164
- 2.461380748748779
- 1.981320201555888
- 2.4303881104787193
- 1.9316210047403972
- 2.4088375123341876
- 2.275088062286377
- 2.1615143966674806
- 2.129437861442566
- 2.0224463510513306
- 2.0510517088572184
- 2.3329783566792806
- 1.9530067539215088
- 2.069166905085246
- 2.0733131408691405
- 2.0157029581069947
- 2.078329488436381
- 2.2349793974558514
- 2.2865385961532594
- 2.2128722524642943
- 1.8204587729771933
- 2.0195998430252073
- 2.2140478833516437
- 1.9587966871261597
- 2.240559999148051
- 1.942036477724711
- 1.9668927892049153
- 1.917521907488505
- 2.1172514581680297
- 1.6988285096486408
- 1.834911592801412
- 1.9311338233947755
- 1.8912329053878785
- 2.0938664229710895
- 1.8252292331059774
- 2.0386323245366413
- 1.7890028603871664
- 1.9392644866307576
- 1.6336560185750326
- 2.1791089900334675
- 1.8551611280441285
- 1.7007444508870442
- 1.9060258340835572
- 1.650618600845337
- 2.204694522221883
- 1.558716788291931
- 1.8830093161265056
- 1.978974733352661
- 1.9949986028671265
- 1.62947212378184
- 2.077397600809733
- 1.6856443548202515
- 1.84215935866038
- 1.714143303235372
- 2.0090473000208537
- 1.918237754503886
- 1.8033597469329834
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.575
- 0.0
- 0.0
- 0.0
- 0.692
- 0.0
- 0.0
- 0.0
- 0.0
- 0.706
- 0.0
- 0.004
- 0.0
- 0.0
- 0.0
- 0.765
- 0.004
- 0.0
- 0.01
- 0.79
- 0.75
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.006
- 0.015
- 0.004
- 0.827
- 0.0
- 0.842
- 0.096
- 0.808
- 0.0
- 0.004
- 0.031
- 0.0
- 0.0
- 0.002
- 0.0
- 0.052
- 0.044
- 0.0
- 0.0
- 0.0
- 0.84
- 0.158
- 0.0
- 0.844
- 0.104
- 0.008
- 0.0
- 0.137
- 0.838
- 0.856
- 0.0
- 0.127
- 0.129
- 0.0
- 0.85
- 0.0
- 0.846
- 0.002
- 0.044
- 0.856
- 0.002
- 0.844
- 0.0
- 0.852
- 0.0
- 0.0
- 0.173
- 0.263
- 0.006
- 0.0
- 0.0
- 0.0
- 0.194
- 0.867
- 0.002
- 0.863
- 0.023
- 0.0
- 0.865
- 0.0
- 0.017
- 0.0
- 0.873
- 0.01
- 0.869
- 0.135
- 0.102
- 0.183
train_loss:
- 1.924
- 1.705
- 1.357
- 1.448
- 1.347
- 1.242
- 0.95
- 1.122
- 0.918
- 0.989
- 0.818
- 0.988
- 0.97
- 0.795
- 0.689
- 0.719
- 0.727
- 0.871
- 0.635
- 0.513
- 0.752
- 0.544
- 0.455
- 0.57
- 0.605
- 0.622
- 0.606
- 0.466
- 0.589
- 0.688
- 0.615
- 0.458
- 0.461
- 0.454
- 0.437
- 0.659
- 0.544
- 0.528
- 0.611
- 0.586
- 0.427
- 0.408
- 0.593
- 0.637
- 0.592
- 0.377
- 0.611
- 0.378
- 0.6
- 0.55
- 0.502
- 0.451
- 0.479
- 0.471
- 0.563
- 0.447
- 0.486
- 0.484
- 0.466
- 0.49
- 0.561
- 0.576
- 0.574
- 0.343
- 0.462
- 0.56
- 0.475
- 0.509
- 0.408
- 0.407
- 0.47
- 0.501
- 0.383
- 0.363
- 0.446
- 0.444
- 0.493
- 0.437
- 0.52
- 0.401
- 0.448
- 0.319
- 0.488
- 0.515
- 0.341
- 0.425
- 0.308
- 0.515
- 0.352
- 0.394
- 0.504
- 0.485
- 0.345
- 0.511
- 0.432
- 0.417
- 0.374
- 0.456
- 0.49
- 0.421
unequal: 0
verbose: 1
