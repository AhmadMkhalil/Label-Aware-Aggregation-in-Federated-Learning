avg_train_accuracy: 0.25
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03664893617021277
- 0.13106382978723405
- 0.22287234042553192
- 0.2550531914893617
- 0.2895744680851064
- 0.3021276595744681
- 0.3242553191489362
- 0.3478191489361702
- 0.3453723404255319
- 0.3472872340425532
- 0.3702659574468085
- 0.3624468085106383
- 0.3759574468085106
- 0.38313829787234044
- 0.38148936170212766
- 0.3886702127659574
- 0.38563829787234044
- 0.3906914893617021
- 0.404468085106383
- 0.3943617021276596
- 0.4010106382978723
- 0.4125531914893617
- 0.4118617021276596
- 0.41654255319148936
- 0.4226595744680851
- 0.41829787234042554
- 0.4249468085106383
- 0.4179787234042553
- 0.425
- 0.43367021276595746
- 0.4333510638297872
- 0.4356914893617021
- 0.4350531914893617
- 0.42925531914893617
- 0.4391489361702128
- 0.4428723404255319
- 0.31617021276595747
- 0.44845744680851063
- 0.44388297872340426
- 0.4478723404255319
- 0.4498404255319149
- 0.45085106382978724
- 0.4446276595744681
- 0.4555851063829787
- 0.45632978723404255
- 0.46074468085106385
- 0.4604255319148936
- 0.46345744680851064
- 0.4621276595744681
- 0.46962765957446806
- 0.4673936170212766
- 0.4742021276595745
- 0.46335106382978725
- 0.4702659574468085
- 0.46893617021276596
- 0.4700531914893617
- 0.47510638297872343
- 0.4727659574468085
- 0.46808510638297873
- 0.46617021276595744
- 0.4790957446808511
- 0.4698936170212766
- 0.4718085106382979
- 0.48090425531914893
- 0.48186170212765955
- 0.47877659574468084
- 0.4786170212765957
- 0.4756382978723404
- 0.47898936170212764
- 0.4909574468085106
- 0.4748936170212766
- 0.48409574468085104
- 0.4803723404255319
- 0.48409574468085104
- 0.48521276595744683
- 0.48829787234042554
- 0.4903723404255319
- 0.4887234042553191
- 0.4925531914893617
- 0.49186170212765956
- 0.4922340425531915
- 0.5011170212765957
- 0.4845744680851064
- 0.49638297872340426
- 0.48601063829787233
- 0.48627659574468085
- 0.4971808510638298
- 0.5037765957446808
- 0.48473404255319147
- 0.48856382978723406
- 0.4905851063829787
- 0.5023404255319149
- 0.48792553191489363
- 0.5012765957446809
- 0.4874468085106383
- 0.4842021276595745
- 0.5004255319148936
- 0.49319148936170215
- 0.5003723404255319
- 0.5101595744680851
test_loss_list:
- 3.7930082575480144
- 3.647666047414144
- 3.5119496250152586
- 3.3970619742075603
- 3.416770353317261
- 3.269616664250692
- 3.1813356049855552
- 3.302744983037313
- 3.2393882846832276
- 3.03961612701416
- 3.0732615852355956
- 2.8853762849171956
- 3.237728157043457
- 2.9369910621643065
- 3.080218900044759
- 3.0004164187113442
- 2.8894847456614174
- 2.8088677088419596
- 2.826332861582438
- 2.683041426340739
- 2.69335854212443
- 2.905449638366699
- 2.667869965235392
- 2.6331289990743003
- 2.647673784891764
- 2.6511134338378906
- 2.8049069754282634
- 2.566034320195516
- 2.485736586252848
- 2.5763024202982585
- 2.5457437896728514
- 2.583507537841797
- 2.7873819224039713
- 2.4727346261342364
- 2.7595693842569986
- 2.6606055386861165
- 2.543119796117147
- 2.6465299638112385
- 2.3176311302185058
- 2.397950709660848
- 2.253068353335063
- 2.4725818888346356
- 2.332305720647176
- 2.362722520828247
- 2.33517840385437
- 2.3248255157470705
- 2.494054247538249
- 2.1660898876190187
- 2.250980599721273
- 2.2772853708267213
- 2.3620845222473146
- 2.0858053874969484
- 2.3745498561859133
- 2.303764580090841
- 2.2334481843312584
- 2.2510889355341592
- 2.219512114524841
- 2.4448501936594647
- 2.197479871114095
- 2.478552548090617
- 2.0804456345240276
- 2.511422074635824
- 2.436316270828247
- 2.068777135213216
- 2.1112299903233844
- 2.193425397872925
- 2.214186159769694
- 2.3520332781473794
- 2.239460689226786
- 2.004088748296102
- 2.3850389957427978
- 2.0682919073104857
- 2.3479878393809
- 2.1424270073572793
- 2.1524363931020103
- 2.114258058865865
- 2.2832678365707397
- 2.334101937611898
- 2.084351331392924
- 2.101936411857605
- 1.9466637563705445
- 1.891798038482666
- 2.265855023066203
- 2.047887102762858
- 2.247156095504761
- 2.252042088508606
- 2.032709250450134
- 1.9596848662694295
- 2.272775208155314
- 2.192072779337565
- 2.2505001497268675
- 1.9374440050125121
- 2.310197027524312
- 1.987833127975464
- 2.0413574155171714
- 2.2658581336339316
- 2.005806484222412
- 2.2836124086380005
- 2.129387315114339
- 1.8935081799825033
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.638
- 0.0
- 0.0
- 0.615
- 0.0
- 0.64
- 0.002
- 0.646
- 0.0
- 0.0
- 0.0
- 0.717
- 0.656
- 0.004
- 0.704
- 0.0
- 0.012
- 0.708
- 0.769
- 0.0
- 0.0
- 0.029
- 0.017
- 0.012
- 0.806
- 0.796
- 0.04
- 0.0
- 0.76
- 0.212
- 0.002
- 0.004
- 0.0
- 0.0
- 0.012
- 0.004
- 0.094
- 0.0
- 0.0
- 0.002
- 0.088
- 0.004
- 0.004
- 0.0
- 0.113
- 0.777
- 0.0
- 0.035
- 0.831
- 0.092
- 0.006
- 0.0
- 0.0
- 0.827
- 0.002
- 0.848
- 0.002
- 0.008
- 0.0
- 0.019
- 0.854
- 0.012
- 0.002
- 0.844
- 0.79
- 0.858
- 0.844
- 0.796
- 0.0
- 0.787
- 0.0
- 0.0
- 0.0
- 0.027
- 0.14
- 0.865
- 0.012
- 0.0
- 0.863
- 0.015
- 0.0
- 0.0
- 0.01
- 0.0
- 0.0
- 0.133
- 0.0
- 0.019
- 0.881
- 0.856
- 0.144
- 0.856
- 0.25
train_loss:
- 1.489
- 1.15
- 1.305
- 1.163
- 1.371
- 1.069
- 0.986
- 1.166
- 1.108
- 0.935
- 0.895
- 0.674
- 1.012
- 0.83
- 0.922
- 0.91
- 0.739
- 0.748
- 0.71
- 0.598
- 0.571
- 0.827
- 0.682
- 0.539
- 0.675
- 0.656
- 0.739
- 0.637
- 0.521
- 0.618
- 0.626
- 0.619
- 0.733
- 0.593
- 0.69
- 0.68
- 0.365
- 0.717
- 0.445
- 0.562
- 0.437
- 0.561
- 0.579
- 0.514
- 0.538
- 0.551
- 0.636
- 0.43
- 0.402
- 0.494
- 0.51
- 0.421
- 0.519
- 0.506
- 0.506
- 0.494
- 0.513
- 0.594
- 0.52
- 0.586
- 0.405
- 0.58
- 0.572
- 0.393
- 0.377
- 0.505
- 0.481
- 0.536
- 0.463
- 0.376
- 0.561
- 0.48
- 0.538
- 0.463
- 0.483
- 0.467
- 0.527
- 0.544
- 0.467
- 0.45
- 0.365
- 0.34
- 0.538
- 0.436
- 0.535
- 0.522
- 0.431
- 0.46
- 0.51
- 0.534
- 0.51
- 0.436
- 0.494
- 0.422
- 0.443
- 0.497
- 0.408
- 0.514
- 0.513
- 0.341
unequal: 0
verbose: 1
