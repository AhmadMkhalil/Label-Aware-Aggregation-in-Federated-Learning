avg_train_accuracy: 0.921
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05430851063829787
- 0.15462765957446808
- 0.05723404255319149
- 0.2667553191489362
- 0.0828191489361702
- 0.07292553191489362
- 0.3095212765957447
- 0.3451063829787234
- 0.3427659574468085
- 0.36888297872340425
- 0.08898936170212766
- 0.38361702127659575
- 0.385
- 0.3928191489361702
- 0.1474468085106383
- 0.39090425531914896
- 0.393031914893617
- 0.13414893617021276
- 0.40797872340425534
- 0.405531914893617
- 0.12829787234042553
- 0.40941489361702127
- 0.4096808510638298
- 0.42164893617021276
- 0.4268085106382979
- 0.2653191489361702
- 0.1400531914893617
- 0.41888297872340424
- 0.17936170212765956
- 0.428031914893617
- 0.42867021276595746
- 0.43388297872340426
- 0.43069148936170215
- 0.4358510638297872
- 0.2523936170212766
- 0.4353191489361702
- 0.44351063829787235
- 0.4418617021276596
- 0.443563829787234
- 0.19414893617021275
- 0.44590425531914896
- 0.4473936170212766
- 0.448563829787234
- 0.4472340425531915
- 0.4531914893617021
- 0.45074468085106384
- 0.45595744680851064
- 0.4557978723404255
- 0.45606382978723403
- 0.45622340425531915
- 0.4592553191489362
- 0.35212765957446807
- 0.25553191489361704
- 0.45526595744680853
- 0.461968085106383
- 0.46356382978723404
- 0.4625
- 0.46063829787234045
- 0.46675531914893614
- 0.4664893617021277
- 0.46239361702127657
- 0.4700531914893617
- 0.3506382978723404
- 0.4765957446808511
- 0.4648936170212766
- 0.46835106382978725
- 0.4725531914893617
- 0.24558510638297873
- 0.47904255319148936
- 0.473031914893617
- 0.4678191489361702
- 0.47372340425531917
- 0.47175531914893615
- 0.4722340425531915
- 0.33159574468085107
- 0.2078723404255319
- 0.48664893617021276
- 0.35904255319148937
- 0.4867021276595745
- 0.39287234042553193
- 0.4752659574468085
- 0.47877659574468084
- 0.4749468085106383
- 0.3655851063829787
- 0.2848936170212766
- 0.3607446808510638
- 0.4879787234042553
- 0.35127659574468084
- 0.49617021276595746
- 0.4871808510638298
- 0.4799468085106383
- 0.3499468085106383
- 0.49840425531914895
- 0.48069148936170214
- 0.48696808510638295
- 0.4820212765957447
- 0.4824468085106383
- 0.4786170212765957
- 0.4798404255319149
- 0.41973404255319147
test_loss_list:
- 3.861146920522054
- 3.9694650491078693
- 5.219205741882324
- 3.7308441162109376
- 4.808546320597331
- 5.495062096913656
- 3.4615560372670493
- 3.817439301808675
- 3.7111837609608966
- 3.6552723693847655
- 4.2046607494354244
- 3.8158589522043864
- 3.7136295795440675
- 3.9934470589955646
- 3.803320048650106
- 3.6215994644165037
- 3.598071190516154
- 4.094707101186117
- 3.6393571440378825
- 3.5062313079833984
- 4.028808701833089
- 3.3886539141337075
- 3.6206676133473716
- 3.9898147710164387
- 3.9628382873535157
- 2.855861784617106
- 4.889648717244466
- 3.345579163233439
- 3.4356232039133707
- 3.131582825978597
- 3.398602914810181
- 3.839603141148885
- 3.4645612398783365
- 3.325406529108683
- 3.243283828099569
- 3.1527661291758218
- 3.2845243136088054
- 3.427791649500529
- 3.450063145955404
- 3.764022839864095
- 3.0914291508992515
- 3.140336488087972
- 3.266016664505005
- 3.365013828277588
- 3.6747368303934733
- 3.230799522399902
- 3.260931873321533
- 3.382714042663574
- 3.2558308855692544
- 3.2529839356740315
- 3.6266161410013833
- 2.570871556599935
- 3.1963703060150146
- 2.9579141426086424
- 3.410081221262614
- 3.472414067586263
- 3.2017694822947185
- 3.110099795659383
- 3.1026860078175864
- 3.1672689660390216
- 3.201849603652954
- 3.128909250895182
- 2.7159856796264648
- 2.848214880625407
- 2.9418068440755207
- 3.216010338465373
- 3.376752627690633
- 3.3896613216400144
- 3.0089634704589843
- 3.2369442653656004
- 3.017911507288615
- 3.1449143060048423
- 3.4544465859731037
- 3.502390054066976
- 2.6821524906158447
- 3.745554110209147
- 2.639102223714193
- 2.3975177828470864
- 2.5287352784474693
- 2.2298477617899577
- 2.8374418926239016
- 2.8350706990559895
- 2.846553703943888
- 2.490553216934204
- 3.159059753417969
- 2.234688336054484
- 2.250747087796529
- 2.429909791946411
- 2.38024671236674
- 2.560862471262614
- 2.917453441619873
- 2.7421886126200357
- 2.642045342127482
- 2.544377021789551
- 2.730132598876953
- 2.748212292989095
- 2.76195951461792
- 2.827924108505249
- 2.705338077545166
- 2.1268657223383585
train_accuracy:
- 0.0
- 0.26
- 0.292
- 0.473
- 0.01
- 0.908
- 0.544
- 0.606
- 0.592
- 0.652
- 0.017
- 0.646
- 0.696
- 0.696
- 0.615
- 0.717
- 0.0
- 0.19
- 0.733
- 0.0
- 0.573
- 0.0
- 0.0
- 0.783
- 0.0
- 0.627
- 0.787
- 0.01
- 0.027
- 0.769
- 0.0
- 0.779
- 0.008
- 0.787
- 0.452
- 0.765
- 0.808
- 0.0
- 0.0
- 0.427
- 0.0
- 0.806
- 0.0
- 0.812
- 0.827
- 0.815
- 0.0
- 0.0
- 0.0
- 0.823
- 0.84
- 0.508
- 0.623
- 0.806
- 0.002
- 0.002
- 0.002
- 0.838
- 0.0
- 0.0
- 0.0
- 0.002
- 0.725
- 0.0
- 0.0
- 0.842
- 0.835
- 0.379
- 0.0
- 0.867
- 0.0
- 0.0
- 0.835
- 0.0
- 0.288
- 0.615
- 0.0
- 0.281
- 0.075
- 0.64
- 0.86
- 0.838
- 0.0
- 0.51
- 0.84
- 0.79
- 0.854
- 0.85
- 0.0
- 0.002
- 0.867
- 0.881
- 0.004
- 0.856
- 0.0
- 0.0
- 0.0
- 0.0
- 0.008
- 0.921
train_loss:
- 2.101
- 2.62
- 0.941
- 1.395
- 0.607
- 0.66
- 2.011
- 1.777
- 1.068
- 1.059
- 0.585
- 1.488
- 0.868
- 1.321
- 0.538
- 0.832
- 0.898
- 0.524
- 1.267
- 0.757
- 0.574
- 0.792
- 0.752
- 1.054
- 1.095
- 0.509
- 0.352
- 0.745
- 0.485
- 0.731
- 0.697
- 0.952
- 0.669
- 0.698
- 0.419
- 0.658
- 0.662
- 0.645
- 0.619
- 0.419
- 0.661
- 0.63
- 0.588
- 0.606
- 0.837
- 0.618
- 0.621
- 0.562
- 0.611
- 0.614
- 0.843
- 0.405
- 0.277
- 0.608
- 0.79
- 0.783
- 0.546
- 0.62
- 0.544
- 0.555
- 0.575
- 0.519
- 0.321
- 0.516
- 0.59
- 0.512
- 0.715
- 0.343
- 0.503
- 0.714
- 0.55
- 0.5
- 0.682
- 0.666
- 0.39
- 0.252
- 0.481
- 0.3
- 0.465
- 0.291
- 0.787
- 0.488
- 0.521
- 0.316
- 0.237
- 0.306
- 0.519
- 0.242
- 0.481
- 0.444
- 0.669
- 0.289
- 0.434
- 0.524
- 0.449
- 0.466
- 0.477
- 0.487
- 0.481
- 0.267
unequal: 0
verbose: 1
