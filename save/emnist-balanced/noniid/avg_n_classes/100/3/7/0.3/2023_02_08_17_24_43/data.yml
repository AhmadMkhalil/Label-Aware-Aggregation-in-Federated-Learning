avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02143617021276596
- 0.04058510638297872
- 0.13095744680851062
- 0.2543617021276596
- 0.29654255319148937
- 0.32898936170212767
- 0.09585106382978724
- 0.08893617021276595
- 0.1100531914893617
- 0.34808510638297874
- 0.07957446808510639
- 0.356968085106383
- 0.36840425531914894
- 0.15175531914893617
- 0.14962765957446808
- 0.15132978723404256
- 0.14829787234042552
- 0.3766489361702128
- 0.37643617021276593
- 0.16670212765957446
- 0.3926063829787234
- 0.39861702127659576
- 0.39914893617021274
- 0.40388297872340423
- 0.4110106382978723
- 0.41686170212765955
- 0.1305851063829787
- 0.41819148936170214
- 0.4238297872340426
- 0.20132978723404255
- 0.17202127659574468
- 0.4229255319148936
- 0.22026595744680852
- 0.43409574468085105
- 0.4315425531914894
- 0.4345212765957447
- 0.43
- 0.2696276595744681
- 0.4397872340425532
- 0.2722340425531915
- 0.4429787234042553
- 0.44468085106382976
- 0.4452127659574468
- 0.25590425531914895
- 0.45154255319148934
- 0.45
- 0.4522340425531915
- 0.4503723404255319
- 0.4526063829787234
- 0.45563829787234045
- 0.4578191489361702
- 0.2573404255319149
- 0.4582978723404255
- 0.4629255319148936
- 0.46377659574468083
- 0.3207978723404255
- 0.4625531914893617
- 0.46574468085106385
- 0.46691489361702126
- 0.46787234042553194
- 0.46617021276595744
- 0.4695744680851064
- 0.3797340425531915
- 0.2662765957446809
- 0.4703191489361702
- 0.35345744680851066
- 0.4720744680851064
- 0.4727127659574468
- 0.38196808510638297
- 0.4777127659574468
- 0.4753191489361702
- 0.4771808510638298
- 0.34962765957446806
- 0.3106914893617021
- 0.48686170212765956
- 0.48271276595744683
- 0.3447872340425532
- 0.47585106382978726
- 0.37436170212765957
- 0.2751063829787234
- 0.26388297872340427
- 0.3704787234042553
- 0.2857446808510638
- 0.26409574468085106
- 0.22675531914893618
- 0.29
- 0.48611702127659573
- 0.4804787234042553
- 0.47925531914893615
- 0.4027659574468085
- 0.3030851063829787
- 0.4920212765957447
- 0.49122340425531913
- 0.3252127659574468
- 0.4876595744680851
- 0.4773936170212766
- 0.47888297872340424
- 0.4786170212765957
- 0.47829787234042553
- 0.4770744680851064
test_loss_list:
- 3.836901823679606
- 6.261952381134034
- 3.7806327819824217
- 3.8582921473185223
- 3.7839335918426515
- 3.782934226989746
- 4.1328240013122555
- 4.733241596221924
- 4.1278825283050535
- 3.167121518452962
- 4.490621439615885
- 3.1080524063110353
- 3.1604209423065184
- 4.06438512802124
- 3.568546714782715
- 4.936050326029459
- 5.519867788950602
- 3.2342405637105305
- 3.1072014808654784
- 3.585608819325765
- 3.0859189383188883
- 3.084336436589559
- 3.183514877955119
- 3.20888342221578
- 3.116075096130371
- 3.2693116823832193
- 4.772691440582276
- 3.0976807689666748
- 3.5943456904093423
- 3.1156415144602456
- 4.587825552622477
- 3.0484228197733563
- 3.433754596710205
- 3.141059885025024
- 3.4572089036305744
- 3.549658104578654
- 3.2751767508188885
- 2.82980042775472
- 3.386741355260213
- 2.835312945048014
- 3.3894361368815105
- 3.497804807027181
- 3.1858406511942547
- 3.3581614748636883
- 2.9507017580668133
- 3.019379431406657
- 3.095501047770182
- 3.0414453252156575
- 3.2279708003997802
- 3.1039159011840822
- 3.018482526143392
- 3.2686336676279706
- 3.153476203282674
- 3.119578603108724
- 2.9948789660135904
- 2.5473140207926432
- 2.667085949579875
- 3.0575458017985024
- 3.0004346497853596
- 3.037901433308919
- 3.3262971369425456
- 3.177079963684082
- 2.3481715520222983
- 3.2002430375417075
- 2.9562461121877033
- 2.349336420694987
- 2.534531421661377
- 2.6817325019836424
- 2.294539581934611
- 2.5271924495697022
- 2.807817497253418
- 2.852036164601644
- 2.6086199220021564
- 2.7720414924621584
- 2.36812060991923
- 2.6374375120798748
- 2.5299693520863853
- 2.7725174140930178
- 2.566270345052083
- 3.651256497701009
- 3.7002918275197345
- 2.1302638991673786
- 3.032263406117757
- 3.416988207499186
- 4.493392486572265
- 2.9120729255676268
- 2.2400713109970094
- 2.2505098724365236
- 2.5129998906453452
- 2.000191844304403
- 2.8513634173075357
- 2.141542738278707
- 1.7774938726425171
- 2.6854894574483237
- 2.126573955217997
- 2.550133498509725
- 2.5064736874898275
- 2.807637761433919
- 2.9143795776367187
- 2.574836384455363
train_accuracy:
- 0.04
- 0.0
- 0.0
- 0.0
- 0.535
- 0.608
- 0.056
- 0.0
- 0.71
- 0.619
- 0.0
- 0.621
- 0.0
- 0.052
- 0.733
- 0.84
- 0.821
- 0.69
- 0.0
- 0.794
- 0.696
- 0.0
- 0.729
- 0.0
- 0.733
- 0.756
- 0.771
- 0.748
- 0.769
- 0.144
- 0.421
- 0.0
- 0.312
- 0.0
- 0.783
- 0.0
- 0.0
- 0.321
- 0.0
- 0.908
- 0.804
- 0.812
- 0.0
- 0.823
- 0.0
- 0.792
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.598
- 0.817
- 0.821
- 0.0
- 0.854
- 0.85
- 0.0
- 0.0
- 0.835
- 0.823
- 0.0
- 0.856
- 0.652
- 0.0
- 0.723
- 0.0
- 0.0
- 0.906
- 0.0
- 0.0
- 0.829
- 0.912
- 0.831
- 0.002
- 0.835
- 0.892
- 0.821
- 0.894
- 0.217
- 0.902
- 0.898
- 0.933
- 0.825
- 0.887
- 0.806
- 0.875
- 0.84
- 0.0
- 0.956
- 0.652
- 0.84
- 0.662
- 0.681
- 0.833
- 0.085
- 0.885
- 0.025
- 0.838
- 0.0
train_loss:
- 2.946
- 1.147
- 1.644
- 1.391
- 1.168
- 1.023
- 0.668
- 0.524
- 0.462
- 1.285
- 0.729
- 1.111
- 0.951
- 0.485
- 0.443
- 0.271
- 0.227
- 1.636
- 0.822
- 0.565
- 0.86
- 0.842
- 0.831
- 0.753
- 0.893
- 0.737
- 0.432
- 0.781
- 1.137
- 0.487
- 0.288
- 0.817
- 0.388
- 0.666
- 1.003
- 0.966
- 0.622
- 0.383
- 1.017
- 0.419
- 1.007
- 0.934
- 0.659
- 0.349
- 0.689
- 0.674
- 0.621
- 0.586
- 0.616
- 0.675
- 0.705
- 0.402
- 0.899
- 0.584
- 0.573
- 0.371
- 0.636
- 0.838
- 0.602
- 0.55
- 0.805
- 0.535
- 0.39
- 0.253
- 0.843
- 0.358
- 0.535
- 0.515
- 0.308
- 0.532
- 0.507
- 0.481
- 0.304
- 0.276
- 0.499
- 0.482
- 0.295
- 0.759
- 0.255
- 0.161
- 0.213
- 0.309
- 0.18
- 0.184
- 0.124
- 0.275
- 0.822
- 0.467
- 0.44
- 0.27
- 0.179
- 0.434
- 0.271
- 0.182
- 0.402
- 0.657
- 0.5
- 0.649
- 0.662
- 0.46
unequal: 0
verbose: 1
