avg_train_accuracy: 0.775
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03446808510638298
- 0.09914893617021277
- 0.244468085106383
- 0.30388297872340425
- 0.3388829787234043
- 0.3725
- 0.3728723404255319
- 0.37829787234042556
- 0.3844148936170213
- 0.09170212765957447
- 0.39909574468085107
- 0.4000531914893617
- 0.40925531914893615
- 0.41962765957446807
- 0.41345744680851065
- 0.42079787234042554
- 0.42117021276595745
- 0.21978723404255318
- 0.4231382978723404
- 0.43053191489361703
- 0.43388297872340426
- 0.14074468085106384
- 0.17441489361702128
- 0.15111702127659574
- 0.43111702127659574
- 0.2023936170212766
- 0.435
- 0.2322340425531915
- 0.4396276595744681
- 0.18122340425531916
- 0.4403723404255319
- 0.2675
- 0.4429787234042553
- 0.44638297872340427
- 0.20792553191489363
- 0.44840425531914896
- 0.4479255319148936
- 0.3395744680851064
- 0.4512765957446809
- 0.4536702127659574
- 0.32111702127659575
- 0.454468085106383
- 0.45601063829787236
- 0.45617021276595743
- 0.4563829787234043
- 0.4571808510638298
- 0.46063829787234045
- 0.46324468085106385
- 0.45824468085106385
- 0.29058510638297874
- 0.4627659574468085
- 0.45813829787234045
- 0.4657978723404255
- 0.4674468085106383
- 0.4621276595744681
- 0.4623404255319149
- 0.4657978723404255
- 0.4648404255319149
- 0.4545744680851064
- 0.4706382978723404
- 0.46287234042553194
- 0.46404255319148935
- 0.46787234042553194
- 0.4684042553191489
- 0.46882978723404256
- 0.4725531914893617
- 0.3063297872340425
- 0.20601063829787233
- 0.47345744680851065
- 0.47404255319148936
- 0.4728191489361702
- 0.4720744680851064
- 0.4752127659574468
- 0.4751595744680851
- 0.4752127659574468
- 0.4723404255319149
- 0.4718617021276596
- 0.4760106382978723
- 0.4651063829787234
- 0.4772872340425532
- 0.48
- 0.4849468085106383
- 0.479468085106383
- 0.4760106382978723
- 0.47585106382978726
- 0.3473404255319149
- 0.2793617021276596
- 0.4846808510638298
- 0.37069148936170215
- 0.2326595744680851
- 0.4824468085106383
- 0.48212765957446807
- 0.4778191489361702
- 0.48356382978723406
- 0.48
- 0.47973404255319146
- 0.47898936170212764
- 0.47712765957446807
- 0.4908510638297872
- 0.41154255319148936
test_loss_list:
- 3.816921672821045
- 3.9043989467620848
- 3.8709295399983725
- 3.825253521601359
- 3.804764970143636
- 3.8678534412384034
- 3.8710972468058267
- 3.7261652342478433
- 3.868297955195109
- 4.574131081899007
- 4.106379782358806
- 3.7995539824167888
- 3.7496440601348877
- 4.331311744054158
- 4.051944402058919
- 4.210868005752563
- 3.9315250396728514
- 3.5084915447235105
- 3.578823757171631
- 4.406241798400879
- 4.277616036732992
- 4.5534830665588375
- 3.5794821770985923
- 4.228132928212483
- 3.2617931302388508
- 3.5386089674631753
- 3.2551184558868407
- 3.278538506825765
- 3.3930245145161946
- 4.558485717773437
- 2.9863616021474204
- 3.1570787525177
- 2.906099665959676
- 3.129008992513021
- 3.2977812004089357
- 2.919656893412272
- 3.0219854418436687
- 2.709909048080444
- 2.8492259216308593
- 3.4450454266866046
- 2.692661196390788
- 3.4043988513946535
- 3.0844315846761066
- 3.1466109943389893
- 3.124371115366618
- 3.29865829149882
- 3.6301549275716147
- 3.6894660631815595
- 3.294378973642985
- 2.8028800455729166
- 3.4060406843821207
- 3.2604273637135823
- 3.2129484685262044
- 3.6723832766215008
- 3.257535057067871
- 3.2676460043589275
- 3.4037360191345214
- 3.3205128955841063
- 2.2802475452423097
- 3.0261756070454915
- 3.044738442103068
- 2.9585375022888183
- 3.3995292377471924
- 3.1422857411702476
- 3.350097351074219
- 3.1637720108032226
- 3.2317874908447264
- 4.36272180557251
- 3.035080916086833
- 2.9530966409047443
- 3.332865654627482
- 2.9942072995503746
- 3.0830355421702067
- 3.1405139795939125
- 3.109305559794108
- 3.000719347000122
- 2.024074274698893
- 3.1882740592956544
- 2.2131723388036093
- 3.4134204546610514
- 3.1837439250946047
- 2.1256625684102377
- 3.1775386714935303
- 3.4364423116048175
- 3.305903402964274
- 2.6427574316660563
- 3.042177454630534
- 2.4240354537963866
- 2.2544171953201295
- 4.256046597162882
- 2.4001841831207273
- 2.4646755409240724
- 2.9047038332621256
- 2.7991676139831543
- 2.86607107480367
- 3.0405857372283935
- 3.224847551981608
- 2.097144538561503
- 2.6760413646698
- 2.228278651237488
train_accuracy:
- 0.0
- 0.196
- 0.0
- 0.0
- 0.0
- 0.671
- 0.0
- 0.698
- 0.0
- 0.0
- 0.729
- 0.746
- 0.0
- 0.756
- 0.0
- 0.0
- 0.0
- 0.588
- 0.771
- 0.79
- 0.767
- 0.085
- 0.515
- 0.569
- 0.0
- 0.185
- 0.0
- 0.833
- 0.0
- 0.304
- 0.008
- 0.09
- 0.79
- 0.025
- 0.233
- 0.796
- 0.0
- 0.296
- 0.0
- 0.842
- 0.158
- 0.0
- 0.004
- 0.84
- 0.0
- 0.0
- 0.831
- 0.004
- 0.0
- 0.137
- 0.842
- 0.829
- 0.865
- 0.84
- 0.0
- 0.0
- 0.852
- 0.883
- 0.337
- 0.879
- 0.871
- 0.848
- 0.89
- 0.0
- 0.0
- 0.885
- 0.594
- 0.208
- 0.858
- 0.002
- 0.854
- 0.015
- 0.0
- 0.033
- 0.0
- 0.848
- 0.69
- 0.858
- 0.835
- 0.871
- 0.871
- 0.704
- 0.863
- 0.898
- 0.0
- 0.779
- 0.954
- 0.019
- 0.84
- 0.84
- 0.0
- 0.015
- 0.9
- 0.904
- 0.065
- 0.0
- 0.86
- 0.831
- 0.848
- 0.775
train_loss:
- 2.193
- 1.772
- 1.622
- 1.405
- 1.226
- 1.147
- 0.951
- 1.128
- 0.981
- 0.704
- 1.417
- 1.049
- 0.888
- 1.145
- 0.845
- 0.806
- 0.937
- 0.583
- 0.874
- 1.018
- 1.113
- 0.552
- 0.547
- 0.447
- 0.669
- 0.475
- 0.736
- 0.421
- 1.087
- 0.479
- 0.768
- 0.434
- 0.74
- 0.647
- 0.395
- 0.697
- 0.646
- 0.415
- 0.684
- 0.843
- 0.395
- 0.865
- 0.623
- 0.564
- 0.603
- 0.595
- 0.806
- 0.767
- 0.64
- 0.424
- 0.811
- 0.63
- 0.561
- 0.73
- 0.588
- 0.594
- 0.557
- 0.568
- 0.39
- 0.554
- 0.58
- 0.582
- 0.734
- 0.533
- 0.541
- 0.536
- 0.387
- 0.328
- 0.837
- 0.519
- 0.675
- 0.533
- 0.529
- 0.522
- 0.546
- 0.54
- 0.366
- 0.692
- 0.313
- 0.911
- 0.464
- 0.321
- 0.66
- 0.617
- 0.642
- 0.435
- 0.333
- 0.507
- 0.327
- 0.246
- 0.532
- 0.464
- 0.657
- 0.479
- 0.488
- 0.623
- 0.655
- 0.349
- 0.436
- 0.377
unequal: 0
verbose: 1
