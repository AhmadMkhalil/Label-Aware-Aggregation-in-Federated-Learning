avg_train_accuracy: 0.008
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0325531914893617
- 0.14590425531914894
- 0.0499468085106383
- 0.05686170212765958
- 0.24691489361702126
- 0.3255851063829787
- 0.33872340425531916
- 0.36936170212765956
- 0.37920212765957445
- 0.39159574468085107
- 0.39654255319148934
- 0.39659574468085107
- 0.40287234042553194
- 0.14563829787234042
- 0.14074468085106384
- 0.10462765957446808
- 0.41
- 0.4131382978723404
- 0.15265957446808512
- 0.14659574468085107
- 0.4171808510638298
- 0.4223936170212766
- 0.42367021276595745
- 0.42329787234042554
- 0.43803191489361704
- 0.4302659574468085
- 0.43563829787234043
- 0.43877659574468086
- 0.4383510638297872
- 0.4442553191489362
- 0.4440425531914894
- 0.44643617021276594
- 0.1724468085106383
- 0.4477659574468085
- 0.4492553191489362
- 0.45191489361702125
- 0.2843085106382979
- 0.4511702127659574
- 0.4567553191489362
- 0.45393617021276594
- 0.4506914893617021
- 0.45989361702127657
- 0.4571808510638298
- 0.22547872340425532
- 0.45920212765957447
- 0.46026595744680854
- 0.46239361702127657
- 0.3243617021276596
- 0.46164893617021274
- 0.4638829787234043
- 0.4673404255319149
- 0.4631382978723404
- 0.4681382978723404
- 0.4674468085106383
- 0.34414893617021275
- 0.4660106382978723
- 0.46914893617021275
- 0.4701063829787234
- 0.4701595744680851
- 0.46952127659574466
- 0.4725
- 0.4721808510638298
- 0.4743617021276596
- 0.4693617021276596
- 0.47143617021276596
- 0.33143617021276595
- 0.4748936170212766
- 0.4731382978723404
- 0.47712765957446807
- 0.4754255319148936
- 0.4773404255319149
- 0.4748936170212766
- 0.4748404255319149
- 0.47617021276595745
- 0.47840425531914893
- 0.478031914893617
- 0.479468085106383
- 0.47856382978723405
- 0.3672872340425532
- 0.2936170212765957
- 0.47835106382978726
- 0.3339893617021277
- 0.35223404255319146
- 0.4808510638297872
- 0.31377659574468086
- 0.4779255319148936
- 0.3432978723404255
- 0.4803723404255319
- 0.4812234042553192
- 0.48175531914893616
- 0.48101063829787233
- 0.48079787234042554
- 0.48154255319148936
- 0.4812234042553192
- 0.3557446808510638
- 0.4825
- 0.5041489361702127
- 0.48808510638297875
- 0.3354255319148936
- 0.4843085106382979
test_loss_list:
- 3.829156827926636
- 3.805205653508504
- 5.543194325764974
- 5.776860326131185
- 3.5309810574849445
- 3.745662171045939
- 3.5251592953999835
- 3.8508499813079835
- 3.611793845494588
- 4.028476384480794
- 4.128073110580444
- 3.7932652314503987
- 3.8241214593251547
- 4.8281631151835125
- 4.8105981699625655
- 5.000696875254313
- 3.1159608046213787
- 3.514650446573893
- 4.930777784983317
- 6.289095916748047
- 3.4510015455881753
- 3.8559282493591307
- 3.6338869285583497
- 3.537985884348551
- 4.6728846677144364
- 3.7433763472239177
- 3.4981797568003334
- 3.787451337178548
- 3.7734802691141764
- 3.692006616592407
- 3.7624511400858562
- 3.7001162338256837
- 3.746358633041382
- 3.4215233262379963
- 3.2271493593851726
- 3.52791303952535
- 2.7581554730733235
- 3.2362282530466717
- 3.846234903335571
- 3.5269721031188963
- 3.4462309106191
- 3.8884611320495606
- 3.590804491043091
- 4.161814734141032
- 3.259581460952759
- 3.3950299072265624
- 3.4021735827128095
- 2.618652556737264
- 3.1073388481140136
- 3.195121682484945
- 3.7102563349405924
- 3.301401201883952
- 3.8778146171569823
- 3.5272455565134684
- 2.453997427622477
- 2.745900100072225
- 3.184614102045695
- 3.5283050219217937
- 3.269557476043701
- 3.2602965672810873
- 3.7561333910624186
- 3.1381549294789632
- 3.41164010365804
- 3.189079828262329
- 3.2094162050882975
- 2.9659053834279376
- 3.1826945877075197
- 3.1032654857635498
- 3.5219059816996254
- 3.254458802541097
- 3.2304474512736
- 3.2567882251739504
- 3.233284667332967
- 3.2390184783935547
- 3.531792106628418
- 3.2547886562347412
- 3.116499169667562
- 3.2225054836273195
- 2.3207967710494994
- 2.984033727645874
- 2.6654625225067137
- 2.678781445821126
- 2.4207120895385743
- 2.5009442965189614
- 2.9068157291412353
- 2.9694378852844237
- 2.7515497461954754
- 2.615392411549886
- 2.71284867922465
- 3.0892067750295005
- 2.7652580038706462
- 2.7750068696339927
- 3.132057161331177
- 3.218123099009196
- 2.7009571266174315
- 2.4770767084757486
- 1.7455702193578084
- 2.5879653135935468
- 2.5959295908610027
- 2.677455759048462
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.875
- 0.0
- 0.604
- 0.0
- 0.702
- 0.0
- 0.0
- 0.769
- 0.0
- 0.75
- 0.227
- 0.608
- 0.0
- 0.0
- 0.76
- 0.475
- 0.64
- 0.012
- 0.785
- 0.0
- 0.0
- 0.844
- 0.84
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.86
- 0.283
- 0.817
- 0.0
- 0.0
- 0.26
- 0.0
- 0.842
- 0.0
- 0.0
- 0.85
- 0.0
- 0.673
- 0.0
- 0.0
- 0.0
- 0.625
- 0.0
- 0.0
- 0.0
- 0.004
- 0.0
- 0.0
- 0.617
- 0.0
- 0.0
- 0.0
- 0.002
- 0.002
- 0.885
- 0.0
- 0.002
- 0.0
- 0.021
- 0.54
- 0.887
- 0.0
- 0.881
- 0.0
- 0.0
- 0.0
- 0.002
- 0.887
- 0.898
- 0.0
- 0.0
- 0.883
- 0.635
- 0.969
- 0.0
- 0.785
- 0.781
- 0.0
- 0.946
- 0.875
- 0.679
- 0.892
- 0.875
- 0.887
- 0.0
- 0.006
- 0.912
- 0.883
- 0.756
- 0.0
- 0.725
- 0.892
- 0.952
- 0.008
train_loss:
- 1.987
- 1.853
- 0.785
- 0.713
- 1.3
- 1.77
- 1.265
- 1.551
- 1.022
- 1.509
- 1.31
- 1.053
- 0.878
- 0.625
- 0.526
- 0.567
- 1.022
- 0.853
- 0.478
- 0.329
- 0.762
- 1.132
- 0.759
- 0.89
- 1.287
- 0.732
- 0.863
- 0.693
- 0.706
- 0.715
- 0.664
- 0.773
- 0.496
- 0.989
- 0.762
- 0.661
- 0.532
- 0.755
- 0.872
- 0.65
- 0.721
- 0.884
- 0.614
- 0.443
- 0.712
- 0.63
- 0.61
- 0.501
- 0.649
- 0.647
- 0.753
- 0.596
- 0.726
- 0.562
- 0.467
- 0.698
- 0.597
- 0.788
- 0.567
- 0.612
- 0.705
- 0.624
- 0.544
- 0.613
- 0.577
- 0.448
- 0.797
- 0.577
- 0.691
- 0.587
- 0.595
- 0.532
- 0.54
- 0.591
- 0.721
- 0.569
- 0.594
- 0.559
- 0.403
- 0.289
- 0.559
- 0.367
- 0.291
- 0.553
- 0.311
- 0.708
- 0.396
- 0.722
- 0.473
- 0.667
- 0.556
- 0.513
- 0.637
- 0.629
- 0.403
- 0.506
- 0.349
- 0.461
- 0.324
- 0.719
unequal: 0
verbose: 1
