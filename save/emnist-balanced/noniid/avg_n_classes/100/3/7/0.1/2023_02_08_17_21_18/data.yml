avg_train_accuracy: 0.817
avg_train_loss: 0.018
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05574468085106383
- 0.05037234042553192
- 0.1596808510638298
- 0.04962765957446808
- 0.054787234042553194
- 0.06265957446808511
- 0.20292553191489363
- 0.2853191489361702
- 0.06175531914893617
- 0.061861702127659575
- 0.0701595744680851
- 0.3001063829787234
- 0.0599468085106383
- 0.057606382978723406
- 0.06069148936170213
- 0.05808510638297872
- 0.32840425531914896
- 0.36101063829787233
- 0.0651063829787234
- 0.06207446808510638
- 0.3708510638297872
- 0.05808510638297872
- 0.39404255319148934
- 0.39824468085106385
- 0.40824468085106386
- 0.07484042553191489
- 0.0747340425531915
- 0.42021276595744683
- 0.418031914893617
- 0.06563829787234042
- 0.423031914893617
- 0.1102127659574468
- 0.07468085106382978
- 0.09558510638297872
- 0.07696808510638298
- 0.09702127659574468
- 0.08164893617021277
- 0.09585106382978724
- 0.43957446808510636
- 0.4403191489361702
- 0.4409574468085106
- 0.12696808510638297
- 0.10042553191489362
- 0.1023936170212766
- 0.07819148936170213
- 0.06664893617021277
- 0.06430851063829787
- 0.10861702127659574
- 0.06765957446808511
- 0.09946808510638298
- 0.4477659574468085
- 0.4402127659574468
- 0.1100531914893617
- 0.13856382978723406
- 0.09771276595744681
- 0.11180851063829787
- 0.07680851063829787
- 0.11042553191489361
- 0.12404255319148937
- 0.10840425531914893
- 0.09132978723404256
- 0.0874468085106383
- 0.13196808510638297
- 0.11074468085106383
- 0.12351063829787234
- 0.46414893617021274
- 0.17638297872340425
- 0.06590425531914894
- 0.08473404255319149
- 0.10563829787234043
- 0.10159574468085106
- 0.4767021276595745
- 0.45914893617021274
- 0.18063829787234043
- 0.46154255319148935
- 0.45601063829787236
- 0.14069148936170212
- 0.19632978723404254
- 0.1402127659574468
- 0.12622340425531914
- 0.09968085106382979
- 0.48617021276595745
- 0.195
- 0.16143617021276596
- 0.11898936170212766
- 0.14441489361702128
- 0.13920212765957446
- 0.11265957446808511
- 0.1324468085106383
- 0.14718085106382978
- 0.12430851063829787
- 0.48904255319148937
- 0.22675531914893618
- 0.14936170212765956
- 0.5073404255319149
- 0.3255851063829787
- 0.17462765957446807
- 0.1721808510638298
- 0.15154255319148935
- 0.4996808510638298
test_loss_list:
- 3.86016793568929
- 15.294016621907552
- 3.8195342095692952
- 17.342188034057617
- 14.593048655192057
- 13.685884170532226
- 3.74382022857666
- 4.1863510799407955
- 12.964869295756023
- 14.796343231201172
- 13.860823834737142
- 4.1463545735677085
- 14.059287363688151
- 16.618821767171223
- 11.113152236938477
- 12.584016138712565
- 3.3585499350229897
- 3.6668127886454265
- 8.503147379557292
- 11.303476448059081
- 3.2327636528015136
- 9.54674441019694
- 3.1780433559417727
- 3.451936585108439
- 3.590526310602824
- 8.54548895517985
- 8.715896021525065
- 3.2578884665171306
- 3.5702768548329673
- 10.491283632914225
- 3.1081634267171223
- 7.17068608601888
- 8.939717814127604
- 6.941257762908935
- 9.73086680094401
- 7.384006557464599
- 10.263041725158692
- 8.46991247177124
- 2.830291083653768
- 3.170050032933553
- 3.3813796997070313
- 7.375006497701009
- 8.874836406707765
- 7.326277548472087
- 8.861531295776366
- 11.555877011617024
- 12.748300336201986
- 7.241645323435465
- 8.689848658243815
- 8.70337584177653
- 2.4691229629516602
- 2.8691268507639567
- 6.487804272969564
- 5.9398827044169105
- 8.99129665374756
- 6.137349459330241
- 8.551135228474935
- 7.053232339223226
- 7.482277304331461
- 9.411667747497559
- 8.581499773661296
- 10.135955467224122
- 6.540647780100505
- 8.941461817423503
- 7.306591815948487
- 2.2843776257832844
- 5.658417536417644
- 9.975840771993001
- 6.279796358744304
- 6.28925048828125
- 6.637980798085531
- 2.174449419975281
- 2.482992909749349
- 4.752582613627116
- 2.5276229667663572
- 2.8203125762939454
- 6.9850159327189125
- 5.230999603271484
- 5.699529088338216
- 6.398454666137695
- 7.124201024373372
- 2.2222071409225466
- 5.797919146219889
- 5.989040559132894
- 5.901227105458577
- 5.515917987823486
- 5.608991247812907
- 7.836618461608887
- 6.046084569295247
- 5.516003373463948
- 7.0387647946675616
- 2.0978289604187013
- 4.769916032155355
- 5.976619529724121
- 2.0046421988805134
- 3.795586754480998
- 4.7238364537556965
- 5.346266009012858
- 5.805183016459147
- 1.8379529809951782
train_accuracy:
- 0.094
- 0.421
- 0.29
- 0.392
- 0.608
- 0.94
- 0.356
- 0.517
- 0.94
- 0.952
- 0.898
- 0.579
- 0.846
- 0.808
- 0.871
- 0.796
- 0.581
- 0.656
- 0.927
- 0.892
- 0.69
- 0.763
- 0.719
- 0.731
- 0.742
- 0.821
- 0.869
- 0.763
- 0.765
- 0.879
- 0.781
- 0.927
- 0.96
- 0.971
- 0.971
- 0.944
- 0.975
- 0.931
- 0.775
- 0.779
- 0.775
- 0.929
- 0.956
- 0.954
- 0.883
- 0.946
- 0.942
- 0.952
- 0.942
- 0.979
- 0.779
- 0.804
- 0.956
- 0.952
- 0.975
- 0.952
- 0.985
- 0.942
- 0.971
- 0.971
- 0.981
- 0.985
- 0.963
- 0.985
- 0.975
- 0.8
- 0.948
- 0.896
- 0.948
- 0.948
- 0.969
- 0.787
- 0.827
- 0.969
- 0.8
- 0.831
- 0.904
- 0.975
- 0.94
- 0.96
- 0.923
- 0.8
- 0.929
- 0.958
- 0.952
- 0.977
- 0.96
- 0.981
- 0.971
- 0.933
- 0.946
- 0.821
- 0.95
- 0.985
- 0.829
- 0.977
- 0.975
- 0.969
- 0.965
- 0.817
train_loss:
- 3.738
- 1.133
- 3.66
- 0.956
- 0.835
- 1.408
- 3.581
- 2.773
- 0.596
- 0.248
- 0.733
- 2.914
- 1.324
- 1.662
- 0.905
- 1.656
- 3.088
- 2.231
- 0.471
- 1.421
- 2.663
- 0.949
- 2.251
- 1.788
- 1.729
- 0.566
- 0.9
- 2.074
- 1.582
- 1.024
- 1.897
- 0.508
- 0.938
- 0.378
- 0.412
- 0.315
- 0.331
- 0.844
- 2.195
- 1.525
- 1.432
- 0.445
- 0.148
- 0.457
- 0.746
- 0.249
- 0.201
- 0.425
- 1.103
- 0.75
- 2.174
- 1.449
- 0.513
- 0.507
- 0.473
- 1.122
- 0.504
- 0.524
- 0.527
- 0.205
- 0.505
- 0.154
- 0.516
- 0.278
- 0.267
- 2.268
- 0.594
- 1.043
- 0.552
- 0.66
- 0.286
- 1.983
- 1.425
- 0.443
- 1.534
- 1.279
- 0.756
- 0.72
- 0.695
- 0.536
- 0.598
- 1.785
- 0.393
- 0.42
- 0.489
- 0.454
- 0.287
- 0.611
- 0.239
- 0.526
- 0.178
- 1.92
- 0.535
- 0.492
- 1.687
- 0.546
- 0.68
- 0.456
- 0.391
- 1.762
unequal: 0
verbose: 1
