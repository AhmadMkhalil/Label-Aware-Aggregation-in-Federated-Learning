avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05
- 0.09654255319148936
- 0.2148936170212766
- 0.3388829787234043
- 0.3893617021276596
- 0.42861702127659573
- 0.4679255319148936
- 0.4650531914893617
- 0.5037765957446808
- 0.5052127659574468
- 0.5230851063829787
- 0.5350531914893617
- 0.5448936170212766
- 0.5417021276595745
- 0.5576595744680851
- 0.5648404255319149
- 0.5592021276595744
- 0.574840425531915
- 0.5725531914893617
- 0.586063829787234
- 0.5886702127659574
- 0.5950531914893618
- 0.5988829787234042
- 0.6025531914893617
- 0.6054787234042553
- 0.6109042553191489
- 0.6136170212765958
- 0.6132446808510639
- 0.6162765957446809
- 0.6193085106382978
- 0.612659574468085
- 0.6208510638297873
- 0.6273936170212766
- 0.626436170212766
- 0.631436170212766
- 0.6326063829787234
- 0.630904255319149
- 0.6352127659574468
- 0.6362765957446809
- 0.6376595744680851
- 0.6382978723404256
- 0.6373936170212766
- 0.640904255319149
- 0.6406382978723404
- 0.6399468085106383
- 0.6419680851063829
- 0.64
- 0.6450531914893617
- 0.6445744680851064
- 0.643936170212766
- 0.6445212765957447
- 0.6493085106382979
- 0.6470212765957447
- 0.6478191489361702
- 0.6475531914893617
- 0.647127659574468
- 0.6504787234042553
- 0.6498936170212766
- 0.6494148936170213
- 0.6507446808510639
- 0.6528723404255319
- 0.6529787234042553
- 0.6552659574468085
- 0.6551063829787234
- 0.6535106382978724
- 0.6571808510638298
- 0.6557446808510639
- 0.6552127659574468
- 0.6563297872340426
- 0.6575
- 0.6573404255319149
- 0.6588829787234043
- 0.6556382978723404
- 0.6577659574468085
- 0.6607446808510639
- 0.6601063829787234
- 0.6602659574468085
- 0.6631382978723405
- 0.6606382978723404
- 0.6611170212765958
- 0.6586702127659575
- 0.6621808510638297
- 0.6630851063829787
- 0.6592553191489362
- 0.6616489361702128
- 0.6660106382978723
- 0.6638297872340425
- 0.6653191489361702
- 0.6606914893617021
- 0.6595212765957447
- 0.6626595744680851
- 0.6630851063829787
- 0.6614893617021277
- 0.6681382978723405
- 0.6639893617021276
- 0.6671808510638297
- 0.6656382978723404
- 0.4156382978723404
- 0.6652659574468085
- 0.6679255319148936
test_loss_list:
- 3.7670123831431073
- 3.6467935180664064
- 3.3760259405771893
- 3.047484302520752
- 2.8541961034138996
- 2.723385982513428
- 2.7104039065043133
- 2.5725733407338462
- 2.565231196085612
- 2.4829723326365154
- 2.5004061603546144
- 2.4887689940134683
- 2.543754103978475
- 2.4350144386291506
- 2.485995047887166
- 2.4906278324127196
- 2.401379976272583
- 2.4676835536956787
- 2.3299541966120403
- 2.451570765177409
- 2.447311913172404
- 2.474289827346802
- 2.5386353588104247
- 2.6569791253407797
- 2.5062291399637857
- 2.655619430541992
- 2.489956630071004
- 2.534223534266154
- 2.4723354307810466
- 2.50884911219279
- 2.3202764797210693
- 2.6886659399668376
- 2.6783592637379963
- 2.5274408626556397
- 2.5520196596781415
- 2.695428902308146
- 2.408155255317688
- 2.6513507239023846
- 2.5272037569681802
- 2.564513645172119
- 2.4759868590037026
- 2.408811324437459
- 2.4626719268163044
- 2.381664482752482
- 2.397639773686727
- 2.405768675804138
- 2.1453411849339803
- 2.532229191462199
- 2.322970291773478
- 2.3007089535395306
- 2.0762742614746093
- 2.2711146593093874
- 2.248480404218038
- 2.292262880007426
- 2.2948541482289633
- 2.2552243677775063
- 2.253728849093119
- 2.259973684946696
- 2.187832719484965
- 2.461570210456848
- 2.4374990876515708
- 2.45690681775411
- 2.283795747756958
- 2.4971175146102906
- 2.325833557446798
- 2.502123395601908
- 2.3255493783950807
- 2.3418033488591514
- 2.2840196816126506
- 2.295094199180603
- 2.518207492828369
- 2.277241217295329
- 2.2426069418589276
- 2.479037243525187
- 2.5120670127868654
- 2.5278301525115965
- 2.5560095723470053
- 2.3934447209040326
- 2.3138251606623332
- 2.146441739400228
- 2.2674731159210206
- 2.442063322067261
- 2.3156622711817425
- 2.2947434759140015
- 2.2534516429901124
- 2.333928705851237
- 2.163210636774699
- 2.177598354021708
- 2.0397362009684246
- 2.1245281298955283
- 2.1035749117533364
- 1.8984103790918987
- 1.898444660504659
- 2.2247424586613973
- 2.1350090487798057
- 2.1041407616933188
- 2.026712679862976
- 1.9778401025136312
- 1.6714677667617799
- 1.632230904897054
train_accuracy:
- 0.062
- 0.0
- 0.252
- 0.0
- 0.492
- 0.535
- 0.604
- 0.0
- 0.0
- 0.623
- 0.648
- 0.656
- 0.683
- 0.0
- 0.0
- 0.71
- 0.719
- 0.735
- 0.713
- 0.75
- 0.744
- 0.0
- 0.744
- 0.74
- 0.742
- 0.794
- 0.763
- 0.769
- 0.792
- 0.769
- 0.773
- 0.798
- 0.769
- 0.79
- 0.777
- 0.798
- 0.817
- 0.8
- 0.0
- 0.823
- 0.804
- 0.0
- 0.808
- 0.808
- 0.79
- 0.806
- 0.817
- 0.802
- 0.817
- 0.812
- 0.0
- 0.831
- 0.817
- 0.806
- 0.833
- 0.0
- 0.825
- 0.829
- 0.823
- 0.8
- 0.833
- 0.817
- 0.0
- 0.827
- 0.0
- 0.838
- 0.0
- 0.827
- 0.827
- 0.819
- 0.825
- 0.0
- 0.831
- 0.835
- 0.844
- 0.833
- 0.817
- 0.852
- 0.827
- 0.794
- 0.0
- 0.819
- 0.817
- 0.0
- 0.844
- 0.796
- 0.823
- 0.815
- 0.0
- 0.821
- 0.819
- 0.0
- 0.838
- 0.835
- 0.835
- 0.848
- 0.0
- 0.919
- 0.846
- 0.0
train_loss:
- 2.878
- 1.89
- 3.483
- 1.569
- 2.079
- 1.877
- 2.365
- 1.242
- 1.718
- 1.1
- 1.487
- 1.503
- 1.387
- 1.009
- 1.314
- 1.297
- 1.032
- 1.241
- 0.907
- 1.367
- 1.33
- 1.259
- 1.212
- 1.495
- 1.122
- 1.47
- 1.211
- 1.086
- 1.177
- 1.134
- 0.908
- 1.36
- 1.361
- 1.084
- 1.06
- 1.296
- 1.157
- 1.299
- 1.041
- 1.036
- 1.007
- 1.091
- 0.994
- 1.033
- 0.973
- 1.026
- 0.818
- 1.234
- 1.015
- 0.985
- 0.758
- 0.955
- 0.956
- 0.968
- 0.938
- 0.93
- 0.926
- 0.889
- 0.946
- 1.122
- 1.138
- 1.162
- 0.928
- 1.125
- 0.955
- 1.113
- 0.941
- 0.893
- 0.915
- 0.907
- 1.089
- 0.912
- 0.917
- 1.09
- 1.084
- 1.095
- 1.084
- 0.87
- 0.894
- 0.676
- 0.882
- 1.059
- 0.829
- 0.86
- 0.832
- 0.803
- 0.876
- 0.836
- 0.604
- 0.839
- 0.839
- 0.626
- 0.642
- 1.06
- 0.856
- 0.802
- 0.822
- 0.431
- 0.839
- 0.601
unequal: 0
verbose: 1
