avg_train_accuracy: 0.806
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.038829787234042554
- 0.07196808510638297
- 0.1523936170212766
- 0.26595744680851063
- 0.35132978723404257
- 0.4077659574468085
- 0.4420212765957447
- 0.45680851063829786
- 0.48792553191489363
- 0.5047340425531915
- 0.5
- 0.523031914893617
- 0.5297872340425532
- 0.5418617021276596
- 0.5476595744680851
- 0.5543085106382979
- 0.1775
- 0.5586702127659574
- 0.5698404255319149
- 0.564468085106383
- 0.5735638297872341
- 0.5824468085106383
- 0.5857446808510638
- 0.5882978723404255
- 0.5941489361702128
- 0.594095744680851
- 0.6003191489361702
- 0.6029787234042553
- 0.6047872340425532
- 0.6032446808510639
- 0.6068617021276596
- 0.6108510638297873
- 0.6111170212765957
- 0.6132978723404255
- 0.6171276595744681
- 0.6166489361702128
- 0.6218085106382979
- 0.6229255319148936
- 0.6244148936170213
- 0.6245212765957446
- 0.6249468085106383
- 0.6252659574468085
- 0.629468085106383
- 0.6306914893617022
- 0.6315425531914893
- 0.6300531914893617
- 0.6364893617021277
- 0.6365425531914893
- 0.6378723404255319
- 0.6378191489361702
- 0.6400531914893617
- 0.6403191489361703
- 0.6406914893617022
- 0.6418085106382979
- 0.6431914893617021
- 0.6394148936170213
- 0.6402127659574468
- 0.645
- 0.6470744680851064
- 0.6481914893617021
- 0.6487234042553192
- 0.6490957446808511
- 0.6469148936170213
- 0.6510638297872341
- 0.6514893617021277
- 0.651595744680851
- 0.6500531914893617
- 0.651436170212766
- 0.6488297872340425
- 0.6552127659574468
- 0.656063829787234
- 0.6525531914893618
- 0.6564893617021277
- 0.656595744680851
- 0.6568085106382979
- 0.6567021276595745
- 0.6550531914893617
- 0.6576595744680851
- 0.6572340425531915
- 0.6561702127659574
- 0.6602659574468085
- 0.6596808510638298
- 0.6600531914893617
- 0.656595744680851
- 0.660904255319149
- 0.6633510638297873
- 0.6612234042553191
- 0.6636170212765957
- 0.664468085106383
- 0.6636702127659575
- 0.6635106382978724
- 0.6623404255319149
- 0.6640957446808511
- 0.6628191489361702
- 0.6657978723404255
- 0.665
- 0.6673936170212766
- 0.6632978723404256
- 0.6652127659574468
- 0.6661702127659574
test_loss_list:
- 3.7819355392456053
- 3.7295927492777508
- 3.5789304478963215
- 3.291103083292643
- 3.031762139002482
- 2.876759649912516
- 2.7802429898579915
- 2.657251625061035
- 2.8190688769022625
- 2.824847510655721
- 2.580137612024943
- 2.658075256347656
- 2.6328361415863037
- 2.8463831583658856
- 2.6180665111541748
- 2.6335878721872965
- 3.3296396732330322
- 2.1674877150853473
- 2.557147496541341
- 2.2587167580922443
- 2.3717234134674072
- 2.413963473637899
- 2.584175011316935
- 2.477623325983683
- 2.645515333811442
- 2.4940307903289796
- 2.4503310521443686
- 2.4062020206451415
- 2.456871611277262
- 2.2653931347529093
- 2.307967511812846
- 2.3378646612167358
- 2.221972386042277
- 2.298637334505717
- 2.298074941635132
- 2.3591521040598553
- 2.333356296221415
- 2.287012437184652
- 2.3298713906606037
- 2.2799013249079385
- 2.310451429684957
- 2.1339642079671224
- 2.267778000831604
- 2.2898934841156007
- 2.4197108379999794
- 2.066618342399597
- 2.4101615238189695
- 2.482232197125753
- 2.524508550961812
- 2.548905700047811
- 2.5347190793355305
- 2.392637785275777
- 2.3621594746907553
- 2.3253204266230267
- 2.511780727704366
- 2.3398568344116213
- 2.101276644070943
- 2.4527244408925375
- 2.27979327360789
- 2.473684787750244
- 2.2802047793070477
- 2.476187203725179
- 2.0638509941101075
- 2.439167240460714
- 2.4617489528656007
- 2.517851775487264
- 2.1239077774683635
- 2.0782999976476035
- 2.018468238512675
- 2.352939747174581
- 2.1970105886459352
- 2.162476760546366
- 2.1685109583536786
- 2.1458273474375407
- 2.1720085032780965
- 1.9785199054082234
- 2.0637381649017335
- 2.0988151995340982
- 2.0648179848988852
- 1.932584458986918
- 1.9844464778900146
- 2.063702867825826
- 2.214032220840454
- 1.8746458625793456
- 1.9794526561101278
- 2.2249304898579916
- 2.0880512173970542
- 2.0664697901407876
- 2.0276023372014365
- 2.0649770085016885
- 2.001610612869263
- 2.058060229619344
- 1.9953664541244507
- 2.0331300481160484
- 2.007696436246236
- 2.216586346626282
- 2.042454341252645
- 1.8885140816370647
- 2.2339950211842856
- 2.0041914065678914
train_accuracy:
- 0.054
- 0.0
- 0.177
- 0.342
- 0.458
- 0.527
- 0.546
- 0.0
- 0.656
- 0.648
- 0.0
- 0.646
- 0.677
- 0.694
- 0.692
- 0.0
- 0.398
- 0.725
- 0.683
- 0.0
- 0.0
- 0.715
- 0.74
- 0.725
- 0.735
- 0.0
- 0.0
- 0.754
- 0.0
- 0.0
- 0.756
- 0.0
- 0.744
- 0.0
- 0.763
- 0.754
- 0.775
- 0.765
- 0.0
- 0.779
- 0.758
- 0.0
- 0.765
- 0.804
- 0.802
- 0.0
- 0.81
- 0.777
- 0.785
- 0.808
- 0.802
- 0.0
- 0.806
- 0.81
- 0.8
- 0.0
- 0.798
- 0.812
- 0.798
- 0.792
- 0.0
- 0.798
- 0.0
- 0.815
- 0.802
- 0.804
- 0.0
- 0.767
- 0.0
- 0.798
- 0.0
- 0.827
- 0.0
- 0.831
- 0.0
- 0.798
- 0.823
- 0.0
- 0.812
- 0.8
- 0.0
- 0.0
- 0.842
- 0.0
- 0.0
- 0.842
- 0.812
- 0.81
- 0.81
- 0.802
- 0.0
- 0.806
- 0.0
- 0.842
- 0.821
- 0.838
- 0.806
- 0.0
- 0.835
- 0.806
train_loss:
- 3.831
- 2.143
- 2.723
- 2.485
- 2.218
- 1.995
- 1.831
- 1.319
- 2.193
- 2.085
- 1.183
- 1.495
- 1.483
- 1.798
- 1.431
- 1.35
- 0.647
- 1.382
- 1.673
- 0.88
- 1.22
- 1.175
- 1.54
- 1.147
- 1.471
- 1.132
- 1.103
- 1.208
- 1.087
- 0.812
- 1.179
- 1.07
- 0.762
- 1.124
- 1.087
- 1.04
- 1.041
- 1.031
- 1.03
- 1.064
- 1.031
- 0.732
- 0.966
- 0.919
- 1.269
- 0.736
- 1.255
- 1.237
- 1.184
- 1.201
- 1.222
- 0.906
- 0.91
- 0.972
- 1.164
- 0.942
- 0.679
- 1.16
- 0.87
- 1.122
- 0.909
- 1.133
- 0.726
- 1.135
- 1.115
- 1.117
- 0.691
- 0.644
- 0.686
- 1.115
- 0.845
- 0.929
- 0.87
- 0.872
- 0.865
- 0.638
- 0.827
- 0.821
- 0.886
- 0.653
- 0.85
- 0.779
- 1.067
- 0.612
- 0.905
- 1.042
- 0.8
- 0.805
- 0.876
- 0.787
- 0.866
- 0.788
- 0.842
- 0.799
- 0.844
- 1.018
- 0.782
- 0.622
- 1.013
- 0.857
unequal: 0
verbose: 1
