avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03787234042553191
- 0.07223404255319149
- 0.19085106382978723
- 0.29425531914893616
- 0.3502127659574468
- 0.40414893617021275
- 0.4471276595744681
- 0.4701063829787234
- 0.479468085106383
- 0.5034042553191489
- 0.5098404255319149
- 0.5159574468085106
- 0.5250531914893617
- 0.5422872340425532
- 0.5433510638297873
- 0.5613297872340426
- 0.5627659574468085
- 0.5725
- 0.578936170212766
- 0.580531914893617
- 0.5828723404255319
- 0.5845212765957447
- 0.591968085106383
- 0.6007446808510638
- 0.6045744680851064
- 0.5954787234042553
- 0.6079787234042553
- 0.6032978723404255
- 0.6114893617021276
- 0.6169148936170212
- 0.6145212765957446
- 0.6132978723404255
- 0.616968085106383
- 0.6145744680851064
- 0.6181382978723404
- 0.6263297872340425
- 0.6205851063829787
- 0.6264893617021277
- 0.6272340425531915
- 0.6328723404255319
- 0.630531914893617
- 0.6310638297872341
- 0.6336170212765957
- 0.6357446808510638
- 0.6342553191489362
- 0.6336170212765957
- 0.6372872340425532
- 0.6350531914893617
- 0.6372872340425532
- 0.6367021276595745
- 0.6382446808510638
- 0.6412234042553191
- 0.6407978723404255
- 0.6430851063829788
- 0.6446808510638298
- 0.6441489361702127
- 0.6483510638297872
- 0.6435106382978724
- 0.6446808510638298
- 0.6485106382978724
- 0.6484574468085106
- 0.6463297872340426
- 0.6522340425531915
- 0.6516489361702128
- 0.6498936170212766
- 0.6507446808510639
- 0.6545744680851063
- 0.6546808510638298
- 0.6474468085106383
- 0.6516489361702128
- 0.650904255319149
- 0.6530851063829787
- 0.6560106382978723
- 0.6539893617021276
- 0.6529787234042553
- 0.6568085106382979
- 0.6556382978723404
- 0.6569680851063829
- 0.6576595744680851
- 0.6579255319148937
- 0.6595212765957447
- 0.659468085106383
- 0.660904255319149
- 0.6604787234042553
- 0.6616489361702128
- 0.6614893617021277
- 0.6620212765957447
- 0.6620212765957447
- 0.6619148936170213
- 0.6620744680851064
- 0.6623936170212766
- 0.6637234042553192
- 0.6651595744680852
- 0.6643085106382979
- 0.6624468085106383
- 0.6638297872340425
- 0.6630851063829787
- 0.6656382978723404
- 0.6631914893617021
- 0.6663297872340426
test_loss_list:
- 3.7911076577504477
- 3.7584405612945555
- 3.6352273400624595
- 3.3386475372314455
- 3.0203477223714192
- 2.8489320627848307
- 2.7541306908925374
- 2.6868254152933755
- 2.5924801603953043
- 2.6910907236735024
- 2.625165402094523
- 2.4747037569681805
- 2.4290840339660646
- 2.586563901901245
- 2.4676494375864664
- 2.5892837715148924
- 2.4394465573628743
- 2.5594969749450684
- 2.5604213205973307
- 2.405472246805827
- 2.3724364550908406
- 2.308182331720988
- 2.300841375986735
- 2.435774021148682
- 2.453654138247172
- 2.102580418586731
- 2.390216778119405
- 2.0528585958480834
- 2.180925210316976
- 2.3613758150736492
- 2.1690139706929523
- 2.1321376895904542
- 2.112080036799113
- 1.9550938971837362
- 2.0599243307113646
- 2.2212275886535644
- 1.8930124568939208
- 2.0163439162572225
- 1.9872520812352499
- 2.191568652788798
- 2.161624412536621
- 2.0069520568847654
- 2.166846200625102
- 2.184063941637675
- 1.9893442185719807
- 1.9620091660817465
- 1.9531565697987874
- 1.9116369231541952
- 1.9265582275390625
- 1.7470746103922525
- 1.7145432233810425
- 1.8650485928853353
- 1.7113788572947184
- 1.831840484937032
- 1.8171162621180217
- 1.656313393910726
- 1.9734333976109824
- 1.822438244819641
- 1.6756361627578735
- 1.7709965403874715
- 1.780231409072876
- 1.7554413525263468
- 1.9653881613413493
- 1.7910465494791667
- 1.7666692241032917
- 1.6384043057759603
- 1.7430429140726724
- 1.8976867389678955
- 1.7447179667154948
- 1.5952795457839966
- 1.7176147127151489
- 1.556497163772583
- 1.6861120812098185
- 1.6853155263264974
- 1.6937327909469604
- 1.6950209951400756
- 1.6787999518712362
- 1.6918029975891113
- 1.5362264426549275
- 1.5230257574717203
- 1.6357395760218303
- 1.4774410184224447
- 1.6296191581090291
- 1.653393071492513
- 1.794083218574524
- 1.830525639851888
- 1.5263778988520305
- 1.6555167468388876
- 1.4796542263031005
- 1.6118185933430988
- 1.4535884793599447
- 1.576253735224406
- 1.5941853205362955
- 1.7549975315729778
- 1.6034066661198934
- 1.4699790859222412
- 1.4391200653711955
- 1.4112999184926351
- 1.5251345189412435
- 1.533029104868571
train_accuracy:
- 0.042
- 0.0
- 0.258
- 0.381
- 0.444
- 0.0
- 0.515
- 0.588
- 0.0
- 0.598
- 0.0
- 0.0
- 0.0
- 0.652
- 0.0
- 0.704
- 0.0
- 0.729
- 0.729
- 0.729
- 0.0
- 0.0
- 0.752
- 0.744
- 0.758
- 0.735
- 0.742
- 0.75
- 0.0
- 0.752
- 0.773
- 0.0
- 0.0
- 0.763
- 0.0
- 0.765
- 0.0
- 0.0
- 0.802
- 0.802
- 0.0
- 0.775
- 0.792
- 0.792
- 0.787
- 0.79
- 0.8
- 0.0
- 0.0
- 0.806
- 0.79
- 0.773
- 0.0
- 0.781
- 0.796
- 0.0
- 0.806
- 0.812
- 0.0
- 0.0
- 0.798
- 0.0
- 0.808
- 0.0
- 0.806
- 0.792
- 0.833
- 0.835
- 0.823
- 0.802
- 0.0
- 0.0
- 0.0
- 0.808
- 0.819
- 0.842
- 0.808
- 0.0
- 0.0
- 0.812
- 0.0
- 0.821
- 0.0
- 0.829
- 0.0
- 0.823
- 0.819
- 0.823
- 0.833
- 0.825
- 0.844
- 0.0
- 0.823
- 0.819
- 0.821
- 0.0
- 0.838
- 0.817
- 0.819
- 0.0
train_loss:
- 3.469
- 3.034
- 3.249
- 2.984
- 2.329
- 2.096
- 1.935
- 1.862
- 1.549
- 1.881
- 1.647
- 1.383
- 1.33
- 1.661
- 1.452
- 1.586
- 1.389
- 1.513
- 1.483
- 1.288
- 1.27
- 1.257
- 1.219
- 1.357
- 1.331
- 1.05
- 1.298
- 1.023
- 1.117
- 1.255
- 1.091
- 1.094
- 1.081
- 0.943
- 1.053
- 1.172
- 0.918
- 1.027
- 1.031
- 1.121
- 1.128
- 0.993
- 1.101
- 1.107
- 0.974
- 0.966
- 0.969
- 0.97
- 0.945
- 0.824
- 0.823
- 0.933
- 0.823
- 0.921
- 0.916
- 0.8
- 1.019
- 0.914
- 0.798
- 0.893
- 0.874
- 0.904
- 1.001
- 0.886
- 0.893
- 0.762
- 0.883
- 0.983
- 0.873
- 0.754
- 0.869
- 0.755
- 0.852
- 0.855
- 0.854
- 0.849
- 0.841
- 0.831
- 0.742
- 0.722
- 0.825
- 0.714
- 0.821
- 0.817
- 0.932
- 0.937
- 0.721
- 0.821
- 0.716
- 0.802
- 0.7
- 0.805
- 0.802
- 0.91
- 0.811
- 0.696
- 0.687
- 0.685
- 0.789
- 0.787
unequal: 0
verbose: 1
