avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033297872340425534
- 0.08617021276595745
- 0.20675531914893616
- 0.30377659574468086
- 0.404468085106383
- 0.4406914893617021
- 0.4642553191489362
- 0.4833510638297872
- 0.5019148936170212
- 0.503031914893617
- 0.5206914893617022
- 0.5256914893617022
- 0.5311702127659574
- 0.5359574468085107
- 0.5429787234042553
- 0.5517553191489362
- 0.555531914893617
- 0.5630851063829787
- 0.5695744680851064
- 0.5676063829787235
- 0.5737234042553192
- 0.5777659574468085
- 0.5807978723404256
- 0.5836702127659574
- 0.5862765957446808
- 0.5875531914893617
- 0.5921808510638298
- 0.5944148936170213
- 0.6002659574468086
- 0.5972872340425532
- 0.6022872340425532
- 0.6006382978723405
- 0.6112234042553192
- 0.608404255319149
- 0.6087765957446809
- 0.6164893617021276
- 0.6156914893617021
- 0.6176595744680851
- 0.616968085106383
- 0.6198404255319149
- 0.6224468085106383
- 0.6222872340425532
- 0.6238829787234043
- 0.6248936170212765
- 0.6255851063829787
- 0.6276595744680851
- 0.6311170212765957
- 0.6297340425531915
- 0.6339361702127659
- 0.6359574468085106
- 0.6350531914893617
- 0.6375
- 0.6377127659574469
- 0.6379787234042553
- 0.6429255319148937
- 0.6426595744680851
- 0.6407978723404255
- 0.6443617021276595
- 0.6446276595744681
- 0.645531914893617
- 0.6470212765957447
- 0.6493085106382979
- 0.6501063829787234
- 0.6491489361702127
- 0.6523936170212766
- 0.6463297872340426
- 0.6496808510638298
- 0.6491489361702127
- 0.6524468085106383
- 0.6528723404255319
- 0.6547340425531915
- 0.6533510638297872
- 0.6577127659574468
- 0.6572340425531915
- 0.66
- 0.6517021276595745
- 0.6587765957446808
- 0.6547872340425532
- 0.6566489361702128
- 0.6570744680851064
- 0.6586170212765957
- 0.6602659574468085
- 0.660904255319149
- 0.6557446808510639
- 0.6591489361702128
- 0.6605851063829787
- 0.6623936170212766
- 0.6625531914893616
- 0.6624468085106383
- 0.6593617021276595
- 0.6618085106382978
- 0.6595212765957447
- 0.6586702127659575
- 0.6607446808510639
- 0.6620212765957447
- 0.6612765957446809
- 0.6604787234042553
- 0.6607446808510639
- 0.6593617021276595
- 0.6633510638297873
test_loss_list:
- 3.7744175020853676
- 3.6677351919809977
- 3.3881402683258055
- 3.0486807028452554
- 2.8536806297302246
- 2.6868955834706623
- 2.5909658336639403
- 2.529198271433512
- 2.581818364461263
- 2.3665194606781004
- 2.3881354268391926
- 2.5003639316558837
- 2.342689749399821
- 2.2253977044423423
- 2.1852836322784426
- 2.2534989976882933
- 2.238198930422465
- 2.3297333494822183
- 2.4078197065989175
- 2.1044151624043783
- 2.173514264424642
- 2.1645143922170003
- 2.123671236038208
- 1.9758351850509643
- 2.13150448958079
- 1.9333816480636596
- 2.027276698748271
- 1.9095267629623414
- 2.1918081696828207
- 1.8813129297892253
- 2.0119218603769937
- 1.8578810437520346
- 2.1417765919367473
- 1.9444938882191976
- 1.8404823780059814
- 2.116124800046285
- 2.094362179438273
- 1.9535598850250244
- 1.8027916049957275
- 1.8883006111780802
- 1.9179179382324218
- 1.7698809003829956
- 1.8758930333455404
- 1.7214477380116782
- 1.6928490463892618
- 1.8280689907073975
- 1.9905205965042114
- 1.831465417544047
- 1.8186547819773355
- 1.8515873845418294
- 1.8343830315272014
- 1.7883109696706136
- 1.793286746342977
- 1.9356610091527302
- 1.9791161664326986
- 1.8180561542510987
- 1.6606820440292358
- 1.618742478688558
- 1.7448042964935302
- 1.5961844476064047
- 1.7336072969436644
- 1.7602782948811848
- 1.738458472887675
- 1.7173266220092773
- 1.720530875523885
- 1.6766463867823282
- 1.5356052970886231
- 1.8487660217285156
- 1.8784459686279298
- 1.736487463315328
- 1.5705027135213216
- 1.5372812239329021
- 1.830123912493388
- 1.6685415697097778
- 1.6704282220204671
- 1.6418887249628702
- 1.6690134572982789
- 1.8089772208531698
- 1.6882182884216308
- 1.664661259651184
- 1.6592001167933146
- 1.6243431886037192
- 1.6379699039459228
- 1.5941291586558024
- 1.6311197630564371
- 1.6351860586802165
- 1.62161252339681
- 1.608907971382141
- 1.6288168891270955
- 1.7663336483637493
- 1.4869405762354533
- 1.761617504755656
- 1.589488689104716
- 1.5945577541987102
- 1.9609003559748333
- 1.4810115257898966
- 1.7423307927449545
- 1.7531048488616943
- 1.6324076557159424
- 1.6422297350565593
train_accuracy:
- 0.0
- 0.102
- 0.281
- 0.377
- 0.0
- 0.571
- 0.56
- 0.629
- 0.658
- 0.0
- 0.683
- 0.681
- 0.0
- 0.683
- 0.723
- 0.721
- 0.748
- 0.0
- 0.727
- 0.0
- 0.0
- 0.773
- 0.0
- 0.0
- 0.0
- 0.0
- 0.748
- 0.0
- 0.754
- 0.775
- 0.74
- 0.002
- 0.783
- 0.0
- 0.0
- 0.815
- 0.792
- 0.777
- 0.746
- 0.0
- 0.754
- 0.0
- 0.76
- 0.763
- 0.829
- 0.0
- 0.802
- 0.0
- 0.767
- 0.808
- 0.777
- 0.808
- 0.808
- 0.804
- 0.815
- 0.85
- 0.0
- 0.81
- 0.842
- 0.0
- 0.821
- 0.0
- 0.0
- 0.796
- 0.835
- 0.835
- 0.854
- 0.833
- 0.817
- 0.0
- 0.787
- 0.0
- 0.825
- 0.0
- 0.0
- 0.86
- 0.819
- 0.821
- 0.84
- 0.0
- 0.838
- 0.819
- 0.808
- 0.86
- 0.867
- 0.0
- 0.85
- 0.825
- 0.0
- 0.848
- 0.831
- 0.829
- 0.0
- 0.817
- 0.835
- 0.0
- 0.802
- 0.856
- 0.833
- 0.0
train_loss:
- 3.079
- 2.955
- 2.766
- 2.121
- 2.547
- 2.03
- 1.881
- 1.757
- 1.913
- 1.389
- 1.558
- 1.719
- 1.482
- 1.231
- 1.194
- 1.366
- 1.329
- 1.505
- 1.482
- 1.127
- 1.252
- 1.234
- 1.242
- 1.06
- 1.2
- 1.017
- 1.164
- 0.996
- 1.308
- 0.992
- 1.119
- 0.956
- 1.252
- 1.109
- 0.92
- 1.229
- 1.207
- 1.05
- 0.893
- 1.05
- 1.031
- 0.881
- 1.028
- 0.884
- 0.861
- 1.009
- 1.149
- 1.002
- 0.984
- 0.987
- 0.985
- 0.97
- 0.966
- 1.093
- 1.092
- 0.944
- 0.817
- 0.811
- 0.943
- 0.801
- 0.936
- 0.926
- 0.929
- 0.914
- 0.921
- 0.924
- 0.774
- 1.039
- 1.018
- 0.903
- 0.772
- 0.761
- 1.015
- 0.892
- 0.887
- 0.907
- 0.893
- 1.004
- 0.879
- 0.866
- 0.879
- 0.87
- 0.868
- 0.877
- 0.865
- 0.862
- 0.843
- 0.856
- 0.856
- 0.971
- 0.742
- 0.974
- 0.841
- 0.841
- 1.071
- 0.738
- 0.95
- 0.972
- 0.83
- 0.829
unequal: 0
verbose: 1
