avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.049840425531914895
- 0.15127659574468086
- 0.24904255319148935
- 0.31042553191489364
- 0.3703723404255319
- 0.4051063829787234
- 0.43813829787234043
- 0.4668617021276596
- 0.4854787234042553
- 0.49329787234042555
- 0.5080851063829788
- 0.5167021276595745
- 0.5263297872340426
- 0.5319148936170213
- 0.5459574468085107
- 0.5563297872340426
- 0.5533510638297873
- 0.563031914893617
- 0.5712765957446808
- 0.5771808510638298
- 0.5692553191489361
- 0.5804255319148937
- 0.5856914893617021
- 0.5808510638297872
- 0.591968085106383
- 0.5874468085106384
- 0.6015957446808511
- 0.5979787234042553
- 0.6015957446808511
- 0.605
- 0.608404255319149
- 0.6071276595744681
- 0.6111170212765957
- 0.6119148936170212
- 0.6167553191489362
- 0.6184574468085107
- 0.6202659574468085
- 0.6244148936170213
- 0.6220212765957447
- 0.6242021276595745
- 0.6218617021276596
- 0.626968085106383
- 0.6293085106382978
- 0.6336170212765957
- 0.6322872340425532
- 0.6368085106382979
- 0.6352127659574468
- 0.6387234042553191
- 0.636436170212766
- 0.6391489361702127
- 0.6385106382978724
- 0.6420212765957447
- 0.6426063829787234
- 0.643031914893617
- 0.6434574468085107
- 0.6437765957446808
- 0.6463297872340426
- 0.6458510638297872
- 0.6459574468085106
- 0.6475531914893617
- 0.6504787234042553
- 0.648031914893617
- 0.6516489361702128
- 0.6527127659574468
- 0.6479787234042553
- 0.6493617021276595
- 0.6532978723404256
- 0.6527127659574468
- 0.6567021276595745
- 0.6564893617021277
- 0.6562234042553191
- 0.6599468085106382
- 0.661063829787234
- 0.6563829787234042
- 0.6611170212765958
- 0.6615425531914894
- 0.66
- 0.6582446808510638
- 0.6572872340425532
- 0.6616489361702128
- 0.6621808510638297
- 0.6631914893617021
- 0.6603191489361702
- 0.6616489361702128
- 0.6607978723404255
- 0.6598404255319149
- 0.6621808510638297
- 0.6623404255319149
- 0.6639893617021276
- 0.665372340425532
- 0.6664893617021277
- 0.6660106382978723
- 0.6659574468085107
- 0.6651595744680852
- 0.6665425531914894
- 0.6643617021276595
- 0.665904255319149
- 0.6674468085106383
- 0.6661702127659574
- 0.6697340425531915
test_loss_list:
- 3.743553867340088
- 3.583565855026245
- 3.3143150107065837
- 3.076690877278646
- 2.9082026068369546
- 2.777980213165283
- 2.6729027716318767
- 2.6455545298258465
- 2.587658427556356
- 2.4409152348836263
- 2.4015141487121583
- 2.2813835112253824
- 2.3023348236083985
- 2.2090582529703777
- 2.2428352053960166
- 2.368863665262858
- 2.189249170621236
- 2.205486528078715
- 2.1719654687245686
- 2.296727164586385
- 2.036852792104085
- 2.142392028172811
- 2.0827494780222575
- 1.9437580808003743
- 2.0375579404830932
- 1.9298494561513264
- 2.173643337885539
- 1.8910814301172891
- 1.878127522468567
- 1.8627492602666218
- 1.9687010002136232
- 1.797295176188151
- 1.936618947982788
- 1.7813527568181355
- 1.9103843037287394
- 1.9063921165466309
- 1.875874417622884
- 2.0466344277064006
- 1.9286559629440307
- 1.8912355772654215
- 1.7709750366210937
- 1.852775977452596
- 1.8713765525817871
- 2.03569238503774
- 1.852059799830119
- 2.050041790008545
- 1.8866623703638712
- 1.9766928815841676
- 1.8517236105600994
- 2.0111535453796385
- 1.887171597480774
- 1.8267182779312134
- 1.984086503982544
- 1.8375573619206746
- 1.8043297370274862
- 1.7853320407867432
- 1.7724690914154053
- 1.7763957071304322
- 1.7817393239339192
- 1.7631001154581705
- 1.7454180924097698
- 1.6161411205927532
- 1.8865981737772624
- 1.8791415739059447
- 1.608988250096639
- 1.5818186442057292
- 1.6883804941177367
- 1.5503397067387898
- 1.6803407843907674
- 1.66480446656545
- 1.5161322514216105
- 1.8104746516545613
- 1.6671483071645101
- 1.5188590351740519
- 1.6374837398529052
- 1.607560690244039
- 1.4904867712656658
- 1.6099360609054565
- 1.591992195447286
- 1.8009122037887573
- 1.6222418896357218
- 1.7831029558181763
- 1.4969654957453409
- 1.5845616086324057
- 1.46971782207489
- 1.5688185660044351
- 1.5715875657399496
- 1.5760988728205363
- 1.4476110140482585
- 1.559230972925822
- 1.8966148026784262
- 1.7672507206598917
- 1.6031991863250732
- 1.5781520827611288
- 1.5836012490590414
- 1.5752830918629963
- 1.5759647258122762
- 1.5922302261988321
- 1.5420942227045695
- 1.4228451251983643
train_accuracy:
- 0.075
- 0.0
- 0.0
- 0.417
- 0.479
- 0.492
- 0.529
- 0.577
- 0.0
- 0.631
- 0.633
- 0.0
- 0.0
- 0.0
- 0.7
- 0.66
- 0.646
- 0.642
- 0.0
- 0.731
- 0.667
- 0.0
- 0.748
- 0.002
- 0.771
- 0.0
- 0.777
- 0.75
- 0.752
- 0.75
- 0.767
- 0.0
- 0.783
- 0.794
- 0.0
- 0.767
- 0.744
- 0.777
- 0.796
- 0.758
- 0.0
- 0.0
- 0.76
- 0.773
- 0.767
- 0.804
- 0.783
- 0.8
- 0.798
- 0.773
- 0.767
- 0.808
- 0.806
- 0.779
- 0.802
- 0.771
- 0.0
- 0.804
- 0.798
- 0.812
- 0.815
- 0.0
- 0.767
- 0.81
- 0.827
- 0.81
- 0.821
- 0.817
- 0.829
- 0.0
- 0.01
- 0.0
- 0.812
- 0.792
- 0.004
- 0.823
- 0.781
- 0.819
- 0.84
- 0.842
- 0.84
- 0.846
- 0.0
- 0.831
- 0.815
- 0.806
- 0.833
- 0.819
- 0.004
- 0.823
- 0.808
- 0.823
- 0.84
- 0.842
- 0.84
- 0.792
- 0.831
- 0.0
- 0.0
- 0.0
train_loss:
- 3.401
- 3.257
- 2.657
- 2.407
- 2.259
- 2.087
- 1.945
- 2.078
- 2.007
- 1.699
- 1.618
- 1.353
- 1.514
- 1.282
- 1.45
- 1.62
- 1.407
- 1.361
- 1.361
- 1.501
- 1.144
- 1.263
- 1.286
- 1.084
- 1.233
- 1.052
- 1.358
- 1.034
- 1.007
- 0.993
- 1.137
- 0.977
- 1.126
- 0.969
- 1.099
- 1.083
- 1.092
- 1.221
- 1.065
- 1.075
- 0.906
- 1.054
- 1.05
- 1.17
- 1.038
- 1.152
- 1.008
- 1.156
- 1.004
- 1.129
- 0.985
- 0.995
- 1.109
- 0.972
- 0.985
- 0.97
- 0.973
- 0.961
- 0.953
- 0.96
- 0.95
- 0.808
- 1.068
- 1.068
- 0.815
- 0.796
- 0.92
- 0.796
- 0.909
- 0.904
- 0.785
- 1.021
- 0.892
- 0.775
- 0.887
- 0.903
- 0.764
- 0.887
- 0.887
- 0.995
- 0.889
- 0.994
- 0.757
- 0.873
- 0.749
- 0.868
- 0.867
- 0.863
- 0.74
- 0.844
- 1.09
- 0.972
- 0.86
- 0.856
- 0.849
- 0.846
- 0.841
- 0.83
- 0.843
- 0.715
unequal: 0
verbose: 1
