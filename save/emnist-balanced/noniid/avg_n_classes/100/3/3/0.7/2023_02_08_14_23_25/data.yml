avg_train_accuracy: 0.844
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02175531914893617
- 0.07095744680851064
- 0.23127659574468085
- 0.3178191489361702
- 0.376063829787234
- 0.4072872340425532
- 0.44388297872340426
- 0.4648936170212766
- 0.49351063829787234
- 0.4945212765957447
- 0.5128723404255319
- 0.5196808510638298
- 0.5323404255319149
- 0.545904255319149
- 0.5421808510638297
- 0.5540957446808511
- 0.5561702127659575
- 0.5685638297872341
- 0.5682978723404255
- 0.5731382978723404
- 0.5766489361702127
- 0.5831914893617022
- 0.5867021276595744
- 0.5887765957446809
- 0.5912234042553192
- 0.5944148936170213
- 0.6007446808510638
- 0.6011170212765957
- 0.6057978723404255
- 0.6079255319148936
- 0.6108510638297873
- 0.6151063829787234
- 0.6139361702127659
- 0.6207446808510638
- 0.6167553191489362
- 0.6205851063829787
- 0.6231914893617021
- 0.629095744680851
- 0.6277127659574468
- 0.6292553191489362
- 0.6306914893617022
- 0.6313297872340425
- 0.6348404255319149
- 0.6338297872340426
- 0.6361170212765958
- 0.6376063829787234
- 0.6387234042553191
- 0.6392021276595745
- 0.6414893617021277
- 0.6418617021276596
- 0.6433510638297872
- 0.6440425531914894
- 0.6438297872340426
- 0.6456382978723404
- 0.6486702127659575
- 0.6489893617021276
- 0.6500531914893617
- 0.6484574468085106
- 0.6498404255319149
- 0.650904255319149
- 0.6506914893617022
- 0.6534042553191489
- 0.6522872340425532
- 0.6522340425531915
- 0.6525
- 0.6560106382978723
- 0.6542021276595744
- 0.6563297872340426
- 0.6542021276595744
- 0.6556914893617021
- 0.6589893617021276
- 0.6574468085106383
- 0.656436170212766
- 0.6567553191489361
- 0.6573404255319149
- 0.6591489361702128
- 0.6598936170212766
- 0.6596276595744681
- 0.6604787234042553
- 0.6625531914893616
- 0.6605319148936171
- 0.661063829787234
- 0.6599468085106382
- 0.6644148936170213
- 0.6633510638297873
- 0.6623936170212766
- 0.6628191489361702
- 0.6610106382978723
- 0.6619148936170213
- 0.6651063829787234
- 0.6657978723404255
- 0.665
- 0.6622340425531915
- 0.6655319148936171
- 0.663563829787234
- 0.6664893617021277
- 0.666063829787234
- 0.6675531914893617
- 0.6695212765957447
- 0.6674468085106383
test_loss_list:
- 3.7771433035532636
- 3.70111509958903
- 3.4382898298899334
- 3.084235725402832
- 2.880111045837402
- 2.698166542053223
- 2.56953564008077
- 2.486084232330322
- 2.4741457589467366
- 2.3553074836730956
- 2.363008279800415
- 2.351547120412191
- 2.31925017674764
- 2.381822608311971
- 2.2036918576558433
- 2.269153116544088
- 2.1487761720021568
- 2.3066109879811605
- 2.1946661551793416
- 2.203241612116496
- 2.071676394144694
- 2.089701584180196
- 2.114468463261922
- 1.9994820419947306
- 1.9531214539210002
- 1.918382404645284
- 2.1177898597717286
- 1.9094729073842367
- 1.9718641217549642
- 1.9687637281417847
- 1.984714461962382
- 1.9382046922047933
- 1.8315283838907879
- 2.03898663520813
- 1.8408419386545818
- 1.9293798049290976
- 2.0435925245285036
- 2.0522932608922324
- 1.9190441036224366
- 1.8910552469889323
- 1.8876948515574137
- 1.8772899627685546
- 2.0049215030670164
- 1.8644761768976847
- 2.0076155869166055
- 1.8747180461883546
- 1.7363045485814412
- 1.6947540616989136
- 1.936801404953003
- 1.769689310391744
- 1.79227955977122
- 1.7815613873799643
- 1.6286743307113647
- 1.7157914066314697
- 1.7123572206497193
- 1.7193088897069295
- 1.8707954978942871
- 1.748845321337382
- 1.6279361375172934
- 1.7092949867248535
- 1.586855206489563
- 1.80188836256663
- 1.702189949353536
- 1.6801718521118163
- 1.8109961811701456
- 1.797683316866557
- 1.7026568714777628
- 1.6756607961654664
- 1.6860972611109415
- 1.6776540358861287
- 1.6282157071431478
- 1.6312231842676799
- 1.7833515516916911
- 1.7969248374303182
- 1.6823459657033284
- 1.658326826095581
- 1.6389541959762572
- 1.5220191399256389
- 1.7238312737147012
- 1.7519247007369996
- 1.5161704238255818
- 1.49200404326121
- 1.6971851873397827
- 1.5805874983469645
- 1.5858375485738119
- 1.462117846806844
- 1.4465719970067341
- 1.657858010927836
- 1.4571805779139202
- 1.6671009476979572
- 1.5568611001968384
- 1.841680342356364
- 1.6037766361236572
- 1.5764511092503866
- 1.4638628101348876
- 1.5109333483378093
- 1.5245288356145223
- 1.4080436754226684
- 1.614517045021057
- 1.6676328627268473
train_accuracy:
- 0.0
- 0.1
- 0.319
- 0.412
- 0.49
- 0.0
- 0.552
- 0.0
- 0.656
- 0.0
- 0.0
- 0.662
- 0.0
- 0.683
- 0.0
- 0.698
- 0.0
- 0.0
- 0.731
- 0.0
- 0.7
- 0.0
- 0.725
- 0.756
- 0.0
- 0.0
- 0.742
- 0.785
- 0.0
- 0.756
- 0.767
- 0.754
- 0.771
- 0.771
- 0.765
- 0.775
- 0.0
- 0.833
- 0.815
- 0.0
- 0.792
- 0.0
- 0.752
- 0.756
- 0.794
- 0.769
- 0.767
- 0.0
- 0.0
- 0.0
- 0.79
- 0.848
- 0.8
- 0.8
- 0.812
- 0.798
- 0.806
- 0.8
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.783
- 0.787
- 0.792
- 0.0
- 0.852
- 0.825
- 0.81
- 0.821
- 0.854
- 0.829
- 0.833
- 0.0
- 0.812
- 0.0
- 0.823
- 0.831
- 0.856
- 0.831
- 0.794
- 0.829
- 0.0
- 0.808
- 0.823
- 0.0
- 0.812
- 0.829
- 0.86
- 0.835
- 0.829
- 0.802
- 0.831
- 0.865
- 0.806
- 0.0
- 0.0
- 0.831
- 0.844
train_loss:
- 2.615
- 3.352
- 2.805
- 2.155
- 2.259
- 1.766
- 1.627
- 1.542
- 1.714
- 1.408
- 1.58
- 1.533
- 1.503
- 1.649
- 1.247
- 1.387
- 1.178
- 1.509
- 1.324
- 1.294
- 1.095
- 1.256
- 1.234
- 1.058
- 1.031
- 1.016
- 1.327
- 1.009
- 1.133
- 1.128
- 1.121
- 1.103
- 0.946
- 1.221
- 0.935
- 1.056
- 1.197
- 1.178
- 1.045
- 1.025
- 1.014
- 0.999
- 1.129
- 0.995
- 1.108
- 0.977
- 0.848
- 0.848
- 1.085
- 0.958
- 0.946
- 0.95
- 0.821
- 0.936
- 0.925
- 0.918
- 1.032
- 0.921
- 0.801
- 0.905
- 0.783
- 1.012
- 0.898
- 0.9
- 1.009
- 1.013
- 0.885
- 0.876
- 0.892
- 0.867
- 0.888
- 0.876
- 0.982
- 0.974
- 0.861
- 0.865
- 0.869
- 0.75
- 0.969
- 0.967
- 0.742
- 0.735
- 0.948
- 0.846
- 0.84
- 0.722
- 0.72
- 0.944
- 0.724
- 0.936
- 0.834
- 1.047
- 0.832
- 0.824
- 0.707
- 0.821
- 0.819
- 0.712
- 0.928
- 0.919
unequal: 0
verbose: 1
