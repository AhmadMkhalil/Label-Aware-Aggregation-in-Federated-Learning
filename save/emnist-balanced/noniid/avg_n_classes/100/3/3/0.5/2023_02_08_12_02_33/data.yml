avg_train_accuracy: 0.812
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03776595744680851
- 0.10122340425531914
- 0.22840425531914893
- 0.3004787234042553
- 0.36340425531914894
- 0.3971276595744681
- 0.4221808510638298
- 0.455
- 0.44196808510638297
- 0.48606382978723406
- 0.5026595744680851
- 0.49590425531914895
- 0.5231914893617021
- 0.5232978723404256
- 0.5386702127659575
- 0.5581382978723404
- 0.5585106382978723
- 0.5733510638297873
- 0.5743617021276596
- 0.5745744680851064
- 0.5688297872340425
- 0.5921276595744681
- 0.5837765957446809
- 0.5890425531914893
- 0.5989361702127659
- 0.6012765957446808
- 0.5939893617021277
- 0.5928191489361702
- 0.6121808510638298
- 0.6068617021276596
- 0.614095744680851
- 0.6127659574468085
- 0.6162234042553192
- 0.6236702127659575
- 0.6216489361702128
- 0.6231914893617021
- 0.6301595744680851
- 0.6307978723404255
- 0.6279787234042553
- 0.6317553191489361
- 0.6337765957446808
- 0.635531914893617
- 0.6372872340425532
- 0.6377127659574469
- 0.6386702127659575
- 0.6345212765957446
- 0.6409574468085106
- 0.6423936170212766
- 0.6421808510638298
- 0.6387234042553191
- 0.6462234042553191
- 0.6472872340425532
- 0.6473404255319148
- 0.646436170212766
- 0.6467553191489361
- 0.6478723404255319
- 0.649468085106383
- 0.649468085106383
- 0.6510106382978723
- 0.6507446808510639
- 0.6553723404255319
- 0.6544148936170213
- 0.6517021276595745
- 0.6533510638297872
- 0.6554255319148936
- 0.6564893617021277
- 0.6597340425531915
- 0.6598936170212766
- 0.6577659574468085
- 0.6596276595744681
- 0.6590425531914894
- 0.6614361702127659
- 0.6607446808510639
- 0.6617553191489361
- 0.6626595744680851
- 0.6626595744680851
- 0.6602127659574468
- 0.663563829787234
- 0.6607446808510639
- 0.6644148936170213
- 0.6642021276595744
- 0.665904255319149
- 0.6639893617021276
- 0.6650531914893617
- 0.6637765957446808
- 0.665904255319149
- 0.666063829787234
- 0.6667553191489362
- 0.6688829787234043
- 0.6688297872340425
- 0.6660106382978723
- 0.6696276595744681
- 0.669468085106383
- 0.6686702127659574
- 0.6725
- 0.6706914893617021
- 0.668936170212766
- 0.6667553191489362
- 0.6714361702127659
- 0.6725
test_loss_list:
- 3.7673488903045653
- 3.6803651237487793
- 3.479380486806234
- 3.1768333594004314
- 2.994374532699585
- 2.7888095283508303
- 2.6698191420237225
- 2.582949301401774
- 2.470513127644857
- 2.462924280166626
- 2.402033596038818
- 2.280666478474935
- 2.32835649172465
- 2.30961438814799
- 2.252808321317037
- 2.3958813317616783
- 2.2332927052179974
- 2.586481704711914
- 2.3761096636454266
- 2.2504293012619017
- 2.1113729238510133
- 2.322287119229635
- 2.142202180226644
- 2.13416024684906
- 2.37191592057546
- 2.3013578939437864
- 1.9995890871683757
- 1.9691227722167968
- 2.3069280608495077
- 2.1027941497166953
- 2.0750980297724406
- 2.073342119852702
- 2.0882765022913614
- 2.4789746618270874
- 2.095606317520142
- 2.215231237411499
- 2.4683671871821087
- 2.517548468907674
- 2.0751759974161783
- 2.228231067657471
- 2.332414925893148
- 2.3411024761199952
- 2.53096910794576
- 2.529361352920532
- 2.27098002910614
- 2.0578734127680463
- 2.0641471115748087
- 2.3136460685729983
- 2.212328462600708
- 1.9777300675710043
- 2.154357943534851
- 2.1774155934651693
- 2.457777886390686
- 2.280884977976481
- 2.033705774943034
- 1.9296396668752034
- 2.1962798484166464
- 2.1064447927474976
- 2.0944690974553426
- 2.170804058710734
- 2.167700643539429
- 2.1249970134099323
- 1.7746862427393595
- 1.93914800008138
- 1.917017928759257
- 1.8865288813908896
- 2.1019538895289105
- 1.8960827191670735
- 1.8258442163467408
- 2.2463612349828086
- 2.0498656256993613
- 2.1124882809321086
- 1.8845713567733764
- 2.259053529103597
- 2.318584753672282
- 1.924962215423584
- 1.8800690587361653
- 1.8980308787027995
- 1.749525367418925
- 1.9563618040084838
- 2.258440663019816
- 2.0755775340398155
- 1.9995027685165405
- 1.848775993982951
- 1.9875613753000896
- 2.2427926715215047
- 2.009950281778971
- 1.8412588326136272
- 1.9845675977071127
- 1.9770447174708048
- 1.76954154809316
- 1.958286501566569
- 2.0002403752009075
- 1.7656490182876587
- 1.9822814830144246
- 2.196181000073751
- 1.9463621918360392
- 1.7379265117645264
- 2.1470613288879394
- 1.9244936561584474
train_accuracy:
- 0.054
- 0.125
- 0.283
- 0.377
- 0.492
- 0.49
- 0.548
- 0.0
- 0.519
- 0.0
- 0.621
- 0.0
- 0.642
- 0.0
- 0.7
- 0.0
- 0.677
- 0.696
- 0.0
- 0.0
- 0.0
- 0.733
- 0.725
- 0.729
- 0.735
- 0.0
- 0.0
- 0.0
- 0.767
- 0.0
- 0.773
- 0.763
- 0.781
- 0.781
- 0.0
- 0.0
- 0.783
- 0.804
- 0.0
- 0.808
- 0.815
- 0.0
- 0.794
- 0.8
- 0.0
- 0.796
- 0.821
- 0.819
- 0.817
- 0.0
- 0.0
- 0.831
- 0.825
- 0.785
- 0.825
- 0.798
- 0.821
- 0.817
- 0.0
- 0.806
- 0.0
- 0.0
- 0.831
- 0.0
- 0.798
- 0.833
- 0.829
- 0.0
- 0.808
- 0.835
- 0.842
- 0.81
- 0.842
- 0.844
- 0.817
- 0.802
- 0.84
- 0.0
- 0.0
- 0.821
- 0.848
- 0.846
- 0.844
- 0.0
- 0.84
- 0.812
- 0.0
- 0.0
- 0.852
- 0.844
- 0.844
- 0.858
- 0.856
- 0.808
- 0.846
- 0.846
- 0.819
- 0.835
- 0.848
- 0.812
train_loss:
- 3.273
- 3.201
- 3.533
- 2.312
- 2.473
- 1.881
- 1.737
- 1.677
- 1.261
- 1.502
- 1.459
- 1.126
- 1.352
- 1.365
- 1.302
- 1.574
- 1.24
- 1.722
- 1.475
- 1.18
- 0.941
- 1.383
- 1.165
- 1.118
- 1.285
- 1.326
- 0.889
- 0.843
- 1.254
- 1.042
- 1.026
- 1.002
- 0.993
- 1.407
- 1.008
- 1.19
- 1.359
- 1.347
- 1.026
- 1.169
- 1.123
- 1.107
- 1.284
- 1.285
- 1.119
- 0.975
- 0.942
- 1.065
- 1.101
- 0.941
- 1.083
- 1.074
- 1.211
- 1.051
- 0.897
- 0.905
- 1.013
- 1.04
- 1.024
- 1.016
- 1.012
- 1.036
- 0.716
- 0.831
- 0.84
- 0.836
- 0.974
- 0.829
- 0.852
- 1.129
- 0.981
- 0.954
- 0.806
- 1.119
- 1.095
- 0.822
- 0.815
- 0.793
- 0.83
- 0.941
- 1.077
- 0.93
- 0.959
- 0.783
- 0.929
- 1.067
- 0.929
- 0.801
- 0.917
- 0.933
- 0.785
- 0.905
- 0.904
- 0.766
- 0.894
- 1.046
- 0.904
- 0.782
- 1.021
- 0.898
unequal: 0
verbose: 1
