avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.048297872340425534
- 0.11590425531914894
- 0.21515957446808512
- 0.28111702127659577
- 0.3371808510638298
- 0.3626063829787234
- 0.3926063829787234
- 0.42031914893617023
- 0.4157446808510638
- 0.4222872340425532
- 0.41914893617021276
- 0.4302127659574468
- 0.4504255319148936
- 0.4491489361702128
- 0.4551595744680851
- 0.4476063829787234
- 0.4682978723404255
- 0.4603191489361702
- 0.4745744680851064
- 0.47452127659574467
- 0.47829787234042553
- 0.49127659574468086
- 0.47797872340425535
- 0.4925
- 0.49340425531914894
- 0.4978723404255319
- 0.49851063829787234
- 0.5037234042553191
- 0.5088829787234043
- 0.5027659574468085
- 0.4947872340425532
- 0.504468085106383
- 0.5105851063829787
- 0.5091489361702127
- 0.5084042553191489
- 0.5188829787234043
- 0.5196808510638298
- 0.5171808510638298
- 0.5229787234042553
- 0.5213829787234042
- 0.518563829787234
- 0.5286702127659575
- 0.5218085106382979
- 0.526436170212766
- 0.5281382978723405
- 0.5287234042553192
- 0.5340425531914894
- 0.5354787234042553
- 0.5336702127659575
- 0.5354255319148936
- 0.5365425531914894
- 0.5359574468085107
- 0.5360106382978723
- 0.5367021276595745
- 0.5331914893617021
- 0.5387765957446808
- 0.539468085106383
- 0.5421808510638297
- 0.5498936170212766
- 0.5443085106382979
- 0.5432978723404255
- 0.5426595744680851
- 0.5456382978723404
- 0.5488297872340425
- 0.5503191489361702
- 0.5499468085106383
- 0.5473404255319149
- 0.5540425531914893
- 0.5504255319148936
- 0.5498936170212766
- 0.5572340425531915
- 0.5552127659574468
- 0.559468085106383
- 0.559468085106383
- 0.5564361702127659
- 0.5586702127659574
- 0.5530851063829787
- 0.5557978723404255
- 0.558031914893617
- 0.5563297872340426
- 0.5542021276595744
- 0.5624468085106383
- 0.5616489361702127
- 0.5578723404255319
- 0.563031914893617
- 0.5645744680851064
- 0.5618085106382978
- 0.5588297872340425
- 0.559468085106383
- 0.5614893617021277
- 0.5612765957446808
- 0.5628191489361702
- 0.5604787234042553
- 0.5610106382978723
- 0.5617021276595745
- 0.571063829787234
- 0.5677127659574468
- 0.5645744680851064
- 0.5625
- 0.5677127659574468
test_loss_list:
- 3.7925053278605145
- 3.6904204591115315
- 3.48015123685201
- 3.237593100865682
- 3.1023669465382895
- 2.9953574657440187
- 2.934190772374471
- 3.086891965866089
- 2.8541514174143474
- 2.8584551779429117
- 2.670152565638224
- 2.6208713404337565
- 2.822301816940308
- 2.6232467873891196
- 2.6664895089467366
- 2.484930671056112
- 2.6052268664042155
- 2.556283082962036
- 2.6911974302927653
- 2.679406261444092
- 2.652581281661987
- 3.0533573913574217
- 2.408755970001221
- 2.7552679920196534
- 2.585137399037679
- 2.6128463045756023
- 2.618074026107788
- 2.797307087580363
- 2.91730970064799
- 2.5804829756418863
- 2.281332499186198
- 2.6525409253438315
- 2.544419666926066
- 2.5743241437276203
- 2.289890155792236
- 2.485335756937663
- 2.4650405089060468
- 2.2952004289627075
- 2.4953863843282065
- 2.5161763922373455
- 2.0801347955067953
- 2.8560583209991455
- 2.151897357304891
- 2.4596783765157064
- 2.3754137547810874
- 2.444252284367879
- 2.394810841878255
- 2.4316471799214683
- 2.3545885785420735
- 2.4569307454427083
- 2.7400614166259767
- 2.4774226570129394
- 2.263067212104797
- 2.412955493927002
- 2.1297556002934774
- 2.325348046620687
- 1.966035591761271
- 2.3105203453699747
- 2.0251994276046754
- 2.1698108688990274
- 2.312840824127197
- 2.2463324960072835
- 1.9376967255274455
- 2.0753334617614745
- 2.034533928235372
- 2.267090910275777
- 2.510616594950358
- 2.1558492437998455
- 2.3366604550679524
- 2.234314028422038
- 1.8723198668162029
- 2.2244227727254233
- 1.845069136619568
- 1.8458793385823569
- 1.9987541421254476
- 1.9142613569895426
- 2.148702540397644
- 1.9611025905609132
- 2.169173336029053
- 2.1486437050501506
- 2.4387976264953615
- 1.7806701215108236
- 2.151877528826396
- 2.378373303413391
- 2.1262058464686078
- 1.7988427988688152
- 2.2754635858535766
- 2.264442801475525
- 2.2043987560272216
- 2.3907184569040933
- 2.23168984413147
- 1.9280050897598267
- 2.311817706425985
- 2.185635180473328
- 2.0301978905995686
- 1.8785058244069417
- 1.9353350989023845
- 2.0708044528961183
- 2.4235829734802246
- 2.0051390329996743
train_accuracy:
- 0.0
- 0.0
- 0.304
- 0.0
- 0.0
- 0.0
- 0.0
- 0.619
- 0.0
- 0.633
- 0.627
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.675
- 0.0
- 0.677
- 0.694
- 0.0
- 0.71
- 0.002
- 0.721
- 0.748
- 0.0
- 0.769
- 0.737
- 0.756
- 0.0
- 0.769
- 0.737
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.763
- 0.0
- 0.798
- 0.76
- 0.804
- 0.0
- 0.767
- 0.0
- 0.763
- 0.79
- 0.017
- 0.0
- 0.79
- 0.0
- 0.79
- 0.002
- 0.0
- 0.0
- 0.833
- 0.781
- 0.81
- 0.0
- 0.8
- 0.833
- 0.79
- 0.0
- 0.829
- 0.825
- 0.833
- 0.0
- 0.835
- 0.796
- 0.0
- 0.019
- 0.012
- 0.0
- 0.81
- 0.019
- 0.808
- 0.0
- 0.838
- 0.787
- 0.829
- 0.821
- 0.002
- 0.002
- 0.848
- 0.844
- 0.804
- 0.823
- 0.84
- 0.006
- 0.804
- 0.002
- 0.794
- 0.833
- 0.01
- 0.0
- 0.04
- 0.827
- 0.823
- 0.81
- 0.0
train_loss:
- 2.289
- 2.05
- 2.193
- 1.642
- 1.451
- 1.376
- 1.277
- 1.65
- 1.177
- 1.111
- 0.91
- 0.874
- 1.213
- 1.027
- 0.992
- 0.815
- 0.962
- 0.934
- 1.083
- 1.07
- 1.057
- 1.181
- 0.902
- 1.006
- 1.006
- 0.991
- 0.975
- 1.109
- 1.091
- 0.97
- 0.694
- 0.929
- 0.929
- 0.919
- 0.796
- 0.89
- 0.902
- 0.77
- 0.879
- 0.872
- 0.638
- 0.962
- 0.76
- 0.833
- 0.852
- 0.832
- 0.845
- 0.828
- 0.832
- 0.809
- 0.931
- 0.804
- 0.821
- 0.805
- 0.688
- 0.786
- 0.575
- 0.767
- 0.669
- 0.665
- 0.766
- 0.755
- 0.553
- 0.664
- 0.648
- 0.741
- 0.867
- 0.757
- 0.738
- 0.748
- 0.538
- 0.745
- 0.54
- 0.528
- 0.629
- 0.612
- 0.726
- 0.624
- 0.718
- 0.705
- 0.804
- 0.542
- 0.709
- 0.811
- 0.704
- 0.522
- 0.693
- 0.813
- 0.71
- 0.79
- 0.691
- 0.603
- 0.776
- 0.685
- 0.699
- 0.587
- 0.588
- 0.685
- 0.763
- 0.677
unequal: 0
verbose: 1
