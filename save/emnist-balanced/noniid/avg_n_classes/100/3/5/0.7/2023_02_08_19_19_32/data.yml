avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026595744680851064
- 0.1551063829787234
- 0.24414893617021277
- 0.2976063829787234
- 0.34574468085106386
- 0.3527659574468085
- 0.3756914893617021
- 0.3830851063829787
- 0.40058510638297873
- 0.4109042553191489
- 0.421968085106383
- 0.4095744680851064
- 0.4391489361702128
- 0.44920212765957446
- 0.46627659574468083
- 0.44553191489361704
- 0.45930851063829786
- 0.47047872340425534
- 0.4601595744680851
- 0.45904255319148934
- 0.48101063829787233
- 0.4798936170212766
- 0.4836170212765957
- 0.49590425531914895
- 0.48936170212765956
- 0.4958510638297872
- 0.506436170212766
- 0.48579787234042554
- 0.5060638297872341
- 0.5082446808510638
- 0.5088829787234043
- 0.5118617021276596
- 0.5070212765957447
- 0.5146808510638298
- 0.5213829787234042
- 0.5251595744680851
- 0.5237234042553192
- 0.5251595744680851
- 0.5277659574468085
- 0.5253723404255319
- 0.5329787234042553
- 0.5313297872340426
- 0.5341489361702128
- 0.5354787234042553
- 0.5337234042553192
- 0.5420744680851064
- 0.5293085106382979
- 0.5391489361702128
- 0.5323404255319149
- 0.541063829787234
- 0.5367553191489361
- 0.540904255319149
- 0.5367553191489361
- 0.5413297872340426
- 0.5452127659574468
- 0.5398404255319149
- 0.5495212765957447
- 0.5436170212765957
- 0.5478191489361702
- 0.5441489361702128
- 0.5484042553191489
- 0.5488829787234043
- 0.5484574468085106
- 0.5495744680851063
- 0.5462234042553191
- 0.5524468085106383
- 0.5472872340425532
- 0.5535106382978724
- 0.5529255319148936
- 0.5529255319148936
- 0.5561170212765958
- 0.5520744680851064
- 0.5544148936170212
- 0.5534042553191489
- 0.5515425531914894
- 0.5561170212765958
- 0.5508510638297872
- 0.5581382978723404
- 0.5601063829787234
- 0.5583510638297873
- 0.5588829787234042
- 0.5595744680851064
- 0.556968085106383
- 0.5602659574468085
- 0.5573404255319149
- 0.5555851063829788
- 0.5644148936170212
- 0.565531914893617
- 0.5649468085106383
- 0.5647872340425532
- 0.5598936170212766
- 0.5648936170212766
- 0.5650531914893617
- 0.5623404255319149
- 0.5626063829787235
- 0.5576595744680851
- 0.5631382978723404
- 0.5617021276595745
- 0.561968085106383
- 0.5643617021276596
test_loss_list:
- 3.8159831206003827
- 3.7191801293691
- 3.4226034673055015
- 3.2222143681844075
- 3.181174201965332
- 2.974807955423991
- 2.976980775197347
- 2.8934173266092937
- 2.9610111204783123
- 2.856521965662638
- 2.9223546918233234
- 2.740271504720052
- 2.8838823890686034
- 2.792456191380819
- 3.010676933924357
- 2.7569850858052574
- 2.6223058986663816
- 2.745816094080607
- 2.6534969425201416
- 2.5205045541127524
- 2.512448689142863
- 2.636272128423055
- 2.487014506657918
- 2.6015110397338868
- 2.4173103364308677
- 2.409174216588338
- 2.590893262227376
- 2.182934069633484
- 2.4059958616892496
- 2.6413700930277506
- 2.28557754834493
- 2.3425243123372397
- 2.230818616549174
- 2.4357196553548177
- 2.4569111919403075
- 2.3725108814239504
- 2.2199365870157877
- 2.140142943064372
- 2.20510909875234
- 2.167009499867757
- 2.342510372797648
- 2.37380451520284
- 2.32582615852356
- 2.3552654457092284
- 2.1186569341023764
- 2.698650099436442
- 2.178306409517924
- 2.3153989632924397
- 1.9322618198394776
- 2.340914243062337
- 2.187846253712972
- 2.0444127813975017
- 2.010551126797994
- 2.023895117441813
- 2.211138054529826
- 1.8217598072687784
- 2.468028361002604
- 1.9774737962086995
- 2.257368065516154
- 1.9946084705988567
- 1.9887474505106608
- 2.1755898841222128
- 2.2324987983703615
- 2.246707730293274
- 1.9319090795516969
- 2.1482741975784303
- 1.8955469417572022
- 1.97284161567688
- 1.9307559776306151
- 2.112549161911011
- 1.842680803934733
- 1.7984627978007
- 1.705980683962504
- 2.0894259071350096
- 1.843929082552592
- 1.8485893980662027
- 2.0383396021525066
- 2.106823827425639
- 1.8133522017796835
- 2.099216259320577
- 1.8635303751627603
- 1.8744541947046915
- 2.316497179667155
- 1.78163667678833
- 2.1420310592651366
- 2.004354887008667
- 1.7939870039621988
- 1.8330115350087484
- 1.6999218956629436
- 1.8311289215087891
- 1.8874383020401
- 1.9899791781107585
- 1.773732213973999
- 2.2773407220840456
- 1.920960308710734
- 1.9696472279230754
- 1.9155302572250366
- 1.7311471970876058
- 1.7406932544708251
- 1.74894083182017
train_accuracy:
- 0.0
- 0.0
- 0.377
- 0.477
- 0.506
- 0.0
- 0.0
- 0.569
- 0.579
- 0.0
- 0.631
- 0.0
- 0.677
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.673
- 0.685
- 0.706
- 0.694
- 0.0
- 0.725
- 0.0
- 0.729
- 0.0
- 0.721
- 0.754
- 0.0
- 0.002
- 0.742
- 0.0
- 0.0
- 0.004
- 0.765
- 0.0
- 0.775
- 0.767
- 0.758
- 0.787
- 0.779
- 0.006
- 0.787
- 0.004
- 0.771
- 0.002
- 0.771
- 0.0
- 0.0
- 0.0
- 0.004
- 0.0
- 0.771
- 0.798
- 0.781
- 0.79
- 0.004
- 0.0
- 0.0
- 0.004
- 0.006
- 0.0
- 0.004
- 0.0
- 0.806
- 0.796
- 0.785
- 0.796
- 0.0
- 0.002
- 0.002
- 0.781
- 0.792
- 0.785
- 0.0
- 0.798
- 0.798
- 0.8
- 0.0
- 0.794
- 0.79
- 0.819
- 0.812
- 0.806
- 0.823
- 0.825
- 0.792
- 0.01
- 0.006
- 0.804
- 0.0
- 0.0
- 0.85
- 0.0
- 0.0
- 0.0
- 0.79
- 0.798
- 0.0
train_loss:
- 3.056
- 2.087
- 1.798
- 1.579
- 1.697
- 1.34
- 1.262
- 1.188
- 1.362
- 1.099
- 1.272
- 1.046
- 1.216
- 1.181
- 1.319
- 1.136
- 0.935
- 1.08
- 1.071
- 0.882
- 0.89
- 1.003
- 0.842
- 0.985
- 0.813
- 0.804
- 0.943
- 0.643
- 0.788
- 1.052
- 0.764
- 0.75
- 0.739
- 0.883
- 0.869
- 0.855
- 0.738
- 0.71
- 0.712
- 0.695
- 0.835
- 0.828
- 0.802
- 0.808
- 0.673
- 0.91
- 0.812
- 0.793
- 0.545
- 0.781
- 0.774
- 0.658
- 0.644
- 0.651
- 0.749
- 0.519
- 0.869
- 0.645
- 0.748
- 0.616
- 0.611
- 0.713
- 0.724
- 0.711
- 0.617
- 0.709
- 0.605
- 0.607
- 0.593
- 0.723
- 0.601
- 0.478
- 0.479
- 0.689
- 0.586
- 0.581
- 0.675
- 0.694
- 0.59
- 0.663
- 0.591
- 0.561
- 0.791
- 0.589
- 0.668
- 0.684
- 0.561
- 0.553
- 0.455
- 0.546
- 0.652
- 0.667
- 0.568
- 0.758
- 0.659
- 0.657
- 0.644
- 0.543
- 0.557
- 0.538
unequal: 0
verbose: 1
