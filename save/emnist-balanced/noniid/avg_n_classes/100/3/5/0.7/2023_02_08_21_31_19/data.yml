avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024148936170212767
- 0.11212765957446809
- 0.2047872340425532
- 0.3047340425531915
- 0.34622340425531917
- 0.3673936170212766
- 0.398031914893617
- 0.4024468085106383
- 0.4220744680851064
- 0.4315425531914894
- 0.45143617021276594
- 0.45
- 0.45382978723404255
- 0.4523936170212766
- 0.4581914893617021
- 0.46595744680851064
- 0.47760638297872343
- 0.47367021276595744
- 0.4786170212765957
- 0.481968085106383
- 0.481968085106383
- 0.4863297872340426
- 0.49579787234042555
- 0.4956382978723404
- 0.4969148936170213
- 0.5017021276595744
- 0.4972872340425532
- 0.5062765957446809
- 0.5088297872340426
- 0.5048404255319149
- 0.509468085106383
- 0.5107446808510638
- 0.5186170212765957
- 0.517127659574468
- 0.5169680851063829
- 0.5160638297872341
- 0.5208510638297872
- 0.5277127659574468
- 0.5265425531914893
- 0.5226063829787234
- 0.5276595744680851
- 0.5322340425531915
- 0.5296808510638298
- 0.5343617021276595
- 0.5355851063829787
- 0.5345744680851063
- 0.5364361702127659
- 0.5363829787234042
- 0.5377127659574468
- 0.5413297872340426
- 0.5426595744680851
- 0.541595744680851
- 0.543031914893617
- 0.543936170212766
- 0.545904255319149
- 0.5471276595744681
- 0.5457978723404255
- 0.5530851063829787
- 0.5490425531914893
- 0.5462234042553191
- 0.5511170212765958
- 0.5537765957446809
- 0.5567021276595745
- 0.5542553191489362
- 0.5479787234042554
- 0.5518085106382978
- 0.555
- 0.561968085106383
- 0.5590957446808511
- 0.5568085106382978
- 0.5580851063829787
- 0.5578191489361702
- 0.5570744680851064
- 0.5598404255319149
- 0.5579787234042554
- 0.5650531914893617
- 0.560531914893617
- 0.5604787234042553
- 0.5647340425531915
- 0.5640957446808511
- 0.5683510638297873
- 0.5617553191489362
- 0.5618085106382978
- 0.5613829787234043
- 0.5641489361702128
- 0.5707978723404256
- 0.569627659574468
- 0.5656382978723404
- 0.574468085106383
- 0.564468085106383
- 0.5697340425531915
- 0.5742553191489361
- 0.5712765957446808
- 0.5731382978723404
- 0.5659574468085107
- 0.5641489361702128
- 0.564468085106383
- 0.5679787234042554
- 0.5653723404255319
- 0.5663297872340426
test_loss_list:
- 3.8039883359273277
- 3.7344305610656736
- 3.488412001927694
- 3.2403214391072592
- 3.1091232363382977
- 2.9479547627766927
- 2.9889636707305907
- 2.836557795206706
- 2.8442318280537924
- 2.8023384539286296
- 3.093433027267456
- 2.8953613821665445
- 2.9154109223683675
- 2.7153262646993
- 2.6760075918833413
- 2.64681253751119
- 2.9715567207336426
- 2.439935935338338
- 2.580779151916504
- 2.6833374881744385
- 2.509810145696004
- 2.5261613527933755
- 2.46897008895874
- 2.5747004985809325
- 2.4210970052083334
- 2.6258078479766844
- 2.2574563662211102
- 2.4143775780995687
- 2.3826962153116864
- 2.166815776824951
- 2.328595902125041
- 2.302223981221517
- 2.5077025445302326
- 2.4003513940175374
- 2.209627046585083
- 2.103972781499227
- 2.3882234128316244
- 2.3726794974009198
- 2.4115134970347087
- 2.170035376548767
- 2.3846081097920737
- 2.35327774365743
- 2.104625012079875
- 2.529094009399414
- 2.156768430074056
- 2.354666347503662
- 2.5482030073801676
- 2.226819082895915
- 2.159416626294454
- 2.3314294083913167
- 2.21233114083608
- 2.3450192324320476
- 2.22405624071757
- 2.1890168460210164
- 2.181953126589457
- 2.2549123843510945
- 2.0544546953837077
- 2.0420741653442382
- 2.2617653052012128
- 2.1638240098953245
- 1.9583052221934
- 1.945292010307312
- 1.8086547501881918
- 2.0700537888209025
- 2.1109570678075156
- 1.9289020967483521
- 2.204604787826538
- 1.7382775847117107
- 1.8944335985183716
- 2.1007160917917886
- 2.010526491800944
- 2.099571625391642
- 2.023804065386454
- 2.0077296924591064
- 1.9424712260564168
- 1.8293468713760377
- 2.018934278488159
- 2.051785462697347
- 1.8704765542348225
- 2.0424106121063232
- 1.8438780498504639
- 2.0152545881271364
- 2.271244773864746
- 1.999733462333679
- 1.9642127148310344
- 1.6818742974599203
- 1.8264751482009887
- 2.0368964433670045
- 1.6591832129160564
- 1.9960791969299316
- 1.967047462463379
- 1.7563331317901612
- 1.9761644728978476
- 1.8207674789428712
- 1.9820922454198202
- 1.9811224762598674
- 1.8898669910430907
- 1.7980814266204834
- 2.18252242565155
- 1.9019497664769491
train_accuracy:
- 0.0
- 0.148
- 0.288
- 0.452
- 0.506
- 0.556
- 0.0
- 0.631
- 0.652
- 0.662
- 0.679
- 0.0
- 0.669
- 0.0
- 0.0
- 0.0
- 0.742
- 0.0
- 0.0
- 0.0
- 0.729
- 0.0
- 0.0
- 0.0
- 0.75
- 0.002
- 0.002
- 0.0
- 0.75
- 0.004
- 0.0
- 0.004
- 0.785
- 0.771
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.796
- 0.012
- 0.79
- 0.0
- 0.792
- 0.0
- 0.79
- 0.008
- 0.802
- 0.794
- 0.0
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.798
- 0.819
- 0.0
- 0.042
- 0.802
- 0.0
- 0.0
- 0.804
- 0.004
- 0.0
- 0.812
- 0.819
- 0.002
- 0.815
- 0.833
- 0.0
- 0.81
- 0.006
- 0.0
- 0.827
- 0.831
- 0.037
- 0.819
- 0.817
- 0.831
- 0.0
- 0.842
- 0.838
- 0.829
- 0.004
- 0.008
- 0.819
- 0.002
- 0.812
- 0.819
- 0.844
- 0.838
- 0.002
- 0.819
- 0.84
- 0.823
- 0.008
- 0.0
train_loss:
- 2.258
- 2.492
- 2.265
- 1.957
- 1.733
- 1.369
- 1.517
- 1.246
- 1.168
- 1.114
- 1.469
- 1.241
- 1.236
- 1.039
- 1.006
- 1.003
- 1.308
- 0.809
- 0.959
- 1.067
- 0.931
- 0.897
- 0.87
- 1.036
- 0.845
- 0.981
- 0.696
- 0.81
- 0.796
- 0.678
- 0.806
- 0.801
- 0.908
- 0.914
- 0.788
- 0.627
- 0.882
- 0.858
- 0.836
- 0.752
- 0.849
- 0.828
- 0.737
- 0.97
- 0.699
- 0.85
- 0.95
- 0.824
- 0.7
- 0.805
- 0.807
- 0.795
- 0.802
- 0.802
- 0.79
- 0.785
- 0.677
- 0.644
- 0.758
- 0.789
- 0.665
- 0.664
- 0.529
- 0.757
- 0.763
- 0.652
- 0.73
- 0.53
- 0.637
- 0.745
- 0.744
- 0.733
- 0.751
- 0.733
- 0.629
- 0.632
- 0.734
- 0.718
- 0.62
- 0.713
- 0.624
- 0.713
- 0.799
- 0.714
- 0.716
- 0.509
- 0.602
- 0.68
- 0.508
- 0.699
- 0.69
- 0.604
- 0.677
- 0.567
- 0.689
- 0.679
- 0.69
- 0.584
- 0.762
- 0.7
unequal: 0
verbose: 1
