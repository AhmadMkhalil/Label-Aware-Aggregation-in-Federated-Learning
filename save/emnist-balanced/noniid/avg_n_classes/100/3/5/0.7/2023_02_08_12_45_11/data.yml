avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.030851063829787233
- 0.12111702127659575
- 0.24835106382978722
- 0.2926063829787234
- 0.31670212765957445
- 0.3350531914893617
- 0.3529255319148936
- 0.3882978723404255
- 0.3722340425531915
- 0.388563829787234
- 0.4072872340425532
- 0.4273936170212766
- 0.4318085106382979
- 0.4332446808510638
- 0.44218085106382976
- 0.4402659574468085
- 0.4521276595744681
- 0.4472872340425532
- 0.45398936170212767
- 0.47047872340425534
- 0.45611702127659576
- 0.4673936170212766
- 0.47372340425531917
- 0.4703723404255319
- 0.4797872340425532
- 0.4752127659574468
- 0.47606382978723405
- 0.4873936170212766
- 0.4898936170212766
- 0.4851063829787234
- 0.49329787234042555
- 0.49
- 0.4902659574468085
- 0.49292553191489363
- 0.4976595744680851
- 0.5035106382978723
- 0.5026595744680851
- 0.5047872340425532
- 0.4997340425531915
- 0.5118085106382979
- 0.5063297872340425
- 0.5079255319148936
- 0.5115425531914893
- 0.5147872340425532
- 0.5181914893617021
- 0.5151063829787234
- 0.5201063829787234
- 0.5212234042553191
- 0.5249468085106384
- 0.523936170212766
- 0.5222872340425532
- 0.5263829787234042
- 0.5212765957446809
- 0.5245212765957447
- 0.5232978723404256
- 0.5294148936170213
- 0.5300531914893617
- 0.5346276595744681
- 0.5333510638297873
- 0.5312765957446809
- 0.5338829787234043
- 0.5322872340425532
- 0.5351595744680852
- 0.5334042553191489
- 0.536595744680851
- 0.5394148936170213
- 0.5408510638297872
- 0.5425531914893617
- 0.544468085106383
- 0.5411170212765958
- 0.5390957446808511
- 0.5439893617021276
- 0.5416489361702128
- 0.5412765957446809
- 0.5417021276595745
- 0.5448936170212766
- 0.5452659574468085
- 0.5455851063829787
- 0.5475
- 0.5477659574468086
- 0.548936170212766
- 0.5467021276595745
- 0.5501063829787234
- 0.5492553191489362
- 0.5480851063829787
- 0.5540425531914893
- 0.5496276595744681
- 0.5495212765957447
- 0.548936170212766
- 0.5530851063829787
- 0.5554787234042553
- 0.5573936170212765
- 0.5600531914893617
- 0.5528191489361702
- 0.5555851063829788
- 0.558404255319149
- 0.5561702127659575
- 0.5603191489361702
- 0.5636702127659574
- 0.5607446808510639
test_loss_list:
- 3.7714457352956137
- 3.6802783902486165
- 3.4442352867126464
- 3.2369429715474447
- 3.0932054710388184
- 3.014498036702474
- 2.888623978296916
- 3.0686513551076255
- 2.830126241048177
- 2.749135961532593
- 2.9201997915903726
- 2.9350502777099607
- 2.896287790934245
- 2.844690901438395
- 2.8252123546600343
- 2.804662815729777
- 2.797334756851196
- 2.5932887331644694
- 2.754078934987386
- 2.931850938796997
- 2.5189936701456705
- 2.611136105855306
- 2.690017655690511
- 2.565166228612264
- 2.6703477414449055
- 2.4940733400980633
- 2.505991045633952
- 2.6679454199473063
- 2.8578070322672526
- 2.406576426823934
- 2.465228484471639
- 2.2732134246826172
- 2.540376450220744
- 2.3975708961486815
- 2.4939134820302327
- 2.537461700439453
- 2.496152038574219
- 2.3559992345174154
- 2.2257498836517335
- 2.558660799662272
- 2.217398290634155
- 2.503483947118123
- 2.2967932510375975
- 2.2970523770650226
- 2.480085471471151
- 2.24269588470459
- 2.480474961598714
- 2.222472856839498
- 2.264947417577108
- 2.3731733703613282
- 2.1721750577290853
- 2.6671311187744142
- 2.0486411301294964
- 2.3928383127848307
- 2.1068445666631064
- 2.3903083101908367
- 2.3292617273330687
- 2.5692158953348794
- 2.5725629329681396
- 2.2925573142369586
- 2.3763632361094156
- 2.3591636927922566
- 2.3021697044372558
- 2.123369199434916
- 1.9597412061691284
- 1.996120540301005
- 2.3152459065119424
- 2.1734168481826783
- 2.0058117373784383
- 2.5147702821095783
- 2.0549612061182656
- 2.258747534751892
- 2.2540243260065713
- 2.2221437803904216
- 2.0464010206858316
- 1.9814603900909424
- 2.206518465677897
- 1.9551187181472778
- 1.9950437370936076
- 1.9327496814727783
- 2.1756476990381874
- 2.0582064819335937
- 1.9361262702941895
- 2.146387996673584
- 1.9698654747009277
- 1.763836963971456
- 1.9375797382990518
- 2.0901758893330893
- 2.30105563322703
- 1.7701113001505533
- 2.1581424299875893
- 1.9562926785151165
- 1.773761609395345
- 2.0725007661183676
- 2.048296348253886
- 1.8656720940272014
- 2.091309142112732
- 1.85524614016215
- 1.8765257390340169
- 2.1547452052434286
train_accuracy:
- 0.0
- 0.0
- 0.342
- 0.423
- 0.0
- 0.0
- 0.504
- 0.569
- 0.56
- 0.562
- 0.0
- 0.6
- 0.61
- 0.648
- 0.65
- 0.0
- 0.0
- 0.0
- 0.0
- 0.662
- 0.0
- 0.679
- 0.69
- 0.0
- 0.717
- 0.0
- 0.729
- 0.731
- 0.702
- 0.69
- 0.0
- 0.0
- 0.0
- 0.0
- 0.748
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.702
- 0.702
- 0.731
- 0.0
- 0.783
- 0.0
- 0.0
- 0.742
- 0.737
- 0.0
- 0.748
- 0.785
- 0.0
- 0.0
- 0.006
- 0.0
- 0.779
- 0.787
- 0.76
- 0.758
- 0.0
- 0.0
- 0.792
- 0.742
- 0.0
- 0.0
- 0.746
- 0.767
- 0.754
- 0.0
- 0.0
- 0.75
- 0.0
- 0.798
- 0.746
- 0.752
- 0.0
- 0.0
- 0.781
- 0.771
- 0.0
- 0.771
- 0.004
- 0.0
- 0.004
- 0.004
- 0.76
- 0.815
- 0.796
- 0.76
- 0.781
- 0.804
- 0.0
- 0.767
- 0.0
- 0.821
- 0.002
- 0.0
- 0.825
- 0.0
train_loss:
- 2.269
- 2.018
- 2.559
- 1.895
- 1.439
- 1.312
- 1.015
- 1.474
- 1.169
- 0.931
- 1.298
- 1.299
- 1.264
- 1.241
- 1.205
- 1.185
- 1.163
- 0.979
- 1.103
- 1.299
- 0.961
- 0.932
- 1.073
- 0.903
- 1.048
- 0.873
- 0.886
- 1.003
- 1.172
- 0.856
- 0.86
- 0.692
- 0.959
- 0.837
- 0.953
- 0.952
- 0.955
- 0.81
- 0.664
- 0.93
- 0.785
- 0.915
- 0.779
- 0.785
- 0.905
- 0.778
- 0.899
- 0.757
- 0.74
- 0.871
- 0.727
- 1.013
- 0.61
- 0.865
- 0.728
- 0.825
- 0.849
- 0.957
- 0.961
- 0.832
- 0.834
- 0.818
- 0.835
- 0.705
- 0.568
- 0.553
- 0.806
- 0.798
- 0.675
- 0.901
- 0.685
- 0.773
- 0.807
- 0.794
- 0.664
- 0.66
- 0.777
- 0.652
- 0.657
- 0.647
- 0.753
- 0.756
- 0.645
- 0.757
- 0.635
- 0.522
- 0.631
- 0.738
- 0.844
- 0.525
- 0.741
- 0.611
- 0.506
- 0.718
- 0.727
- 0.625
- 0.71
- 0.61
- 0.607
- 0.714
unequal: 0
verbose: 1
