avg_train_accuracy: 0.831
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029521276595744682
- 0.17436170212765958
- 0.2631914893617021
- 0.34122340425531916
- 0.3891489361702128
- 0.4035106382978723
- 0.41882978723404257
- 0.4422872340425532
- 0.44765957446808513
- 0.4528723404255319
- 0.4656914893617021
- 0.468031914893617
- 0.4806382978723404
- 0.47882978723404257
- 0.48558510638297875
- 0.4894148936170213
- 0.49117021276595746
- 0.49675531914893617
- 0.501436170212766
- 0.49872340425531914
- 0.5026063829787234
- 0.500904255319149
- 0.5118617021276596
- 0.5176063829787234
- 0.515
- 0.5213297872340426
- 0.5232446808510638
- 0.5229255319148937
- 0.5238297872340425
- 0.5293617021276595
- 0.5327127659574468
- 0.533563829787234
- 0.5322340425531915
- 0.534468085106383
- 0.5371808510638297
- 0.5381382978723405
- 0.5416489361702128
- 0.5434574468085106
- 0.541595744680851
- 0.5409574468085107
- 0.5434574468085106
- 0.5465425531914894
- 0.5465425531914894
- 0.5465425531914894
- 0.5492021276595744
- 0.5515425531914894
- 0.5514361702127659
- 0.5520212765957446
- 0.5531382978723405
- 0.5556914893617021
- 0.5539893617021276
- 0.5631382978723404
- 0.5591489361702128
- 0.5578191489361702
- 0.5641489361702128
- 0.5636702127659574
- 0.5627659574468085
- 0.5607446808510639
- 0.5657446808510638
- 0.5653723404255319
- 0.5694148936170212
- 0.5685638297872341
- 0.5707978723404256
- 0.5717021276595745
- 0.5643085106382979
- 0.5680851063829787
- 0.5761702127659575
- 0.564468085106383
- 0.5664893617021277
- 0.5790425531914893
- 0.5731382978723404
- 0.5627127659574468
- 0.568936170212766
- 0.566063829787234
- 0.5753191489361702
- 0.5647872340425532
- 0.5761702127659575
- 0.5747340425531915
- 0.5770212765957446
- 0.5786170212765958
- 0.5694148936170212
- 0.574468085106383
- 0.5762765957446808
- 0.5721276595744681
- 0.5740425531914893
- 0.5711170212765957
- 0.5774468085106383
- 0.578936170212766
- 0.5806382978723404
- 0.574468085106383
- 0.5761170212765957
- 0.5817553191489362
- 0.5838829787234042
- 0.5792021276595745
- 0.5791489361702128
- 0.5778191489361703
- 0.5742021276595745
- 0.5837234042553191
- 0.5828723404255319
- 0.5794680851063829
test_loss_list:
- 3.792816400527954
- 3.6593958218892415
- 3.3560091400146486
- 3.0815933767954506
- 2.9747218322753906
- 2.8363061332702637
- 2.722790765762329
- 2.987863842646281
- 2.7746718597412108
- 2.658799918492635
- 2.771870133082072
- 2.5863150374094643
- 2.670784641901652
- 2.6887240600585938
- 2.643143819173177
- 2.6438772519429525
- 2.63556165377299
- 2.641053326924642
- 2.604757448832194
- 2.428557119369507
- 2.415802011489868
- 2.255294094085693
- 2.3370919704437254
- 2.487735726038615
- 2.1374257103602092
- 2.437929652531942
- 2.397202962239583
- 2.4019873682657877
- 2.2224770339330036
- 2.383306875228882
- 2.3724087270100913
- 2.320065588951111
- 2.357226235071818
- 2.1787796433766684
- 2.1256646299362183
- 2.1110331217447915
- 2.2641952594121295
- 2.1281627225875854
- 2.4458199405670165
- 2.2821020174026487
- 2.081956033706665
- 2.046531456311544
- 2.4519580078125
- 2.0540830771128338
- 2.2089539829889935
- 2.388839260737101
- 1.892656176884969
- 1.9090659999847412
- 1.976000607808431
- 1.9610989491144817
- 2.001060479482015
- 1.788916254043579
- 1.9413710371653239
- 2.0596411148707072
- 1.8743536567687988
- 2.1209035619099934
- 2.0847139596939086
- 1.897747532526652
- 1.7711843744913738
- 1.8648217089970907
- 1.8712957398096721
- 1.8622006352742513
- 2.0439157740275067
- 1.830192397435506
- 1.8739289156595866
- 1.991678360303243
- 1.6484916162490846
- 2.0012247546513877
- 1.9692163451512654
- 1.6351414759953817
- 1.830202185312907
- 2.1577489519119264
- 1.7694837188720702
- 1.9770614020029704
- 1.5964699649810792
- 1.9683038838704427
- 1.5848400894800823
- 1.7578068447113038
- 1.728121773401896
- 1.5862021843592327
- 1.9350168625513713
- 1.8556737836201986
- 1.7156476402282714
- 1.8790177313486736
- 1.6932421191533407
- 1.8673500903447469
- 1.7023896916707357
- 1.863615674972534
- 1.691865743001302
- 1.7128655624389648
- 1.7083533843358358
- 1.641095388730367
- 1.6612304576237997
- 1.6460119009017944
- 1.6259440724054972
- 1.6593923203150431
- 1.6555656417210898
- 1.598298535346985
- 1.7909970235824586
- 1.7983574787775676
train_accuracy:
- 0.042
- 0.25
- 0.419
- 0.0
- 0.581
- 0.631
- 0.669
- 0.648
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.715
- 0.0
- 0.0
- 0.767
- 0.731
- 0.0
- 0.0
- 0.74
- 0.0
- 0.0
- 0.0
- 0.0
- 0.773
- 0.002
- 0.765
- 0.746
- 0.0
- 0.0
- 0.0
- 0.769
- 0.781
- 0.0
- 0.779
- 0.0
- 0.758
- 0.781
- 0.0
- 0.798
- 0.0
- 0.0
- 0.0
- 0.792
- 0.0
- 0.0
- 0.0
- 0.004
- 0.0
- 0.821
- 0.808
- 0.0
- 0.0
- 0.008
- 0.808
- 0.867
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.002
- 0.0
- 0.804
- 0.804
- 0.0
- 0.0
- 0.002
- 0.006
- 0.81
- 0.831
- 0.806
- 0.867
- 0.0
- 0.85
- 0.0
- 0.006
- 0.0
- 0.0
- 0.808
- 0.817
- 0.021
- 0.81
- 0.812
- 0.81
- 0.808
- 0.867
- 0.869
- 0.0
- 0.0
- 0.0
- 0.819
- 0.825
- 0.823
- 0.002
- 0.0
- 0.004
- 0.821
- 0.831
train_loss:
- 2.398
- 2.816
- 1.792
- 1.542
- 1.614
- 1.277
- 1.207
- 1.504
- 1.286
- 1.083
- 1.184
- 1.001
- 1.153
- 1.109
- 1.075
- 1.071
- 1.03
- 1.006
- 1.024
- 0.869
- 0.847
- 0.689
- 0.831
- 0.943
- 0.673
- 0.911
- 0.909
- 0.886
- 0.761
- 0.885
- 0.883
- 0.856
- 0.844
- 0.705
- 0.711
- 0.708
- 0.828
- 0.688
- 0.911
- 0.773
- 0.686
- 0.673
- 0.88
- 0.663
- 0.773
- 0.885
- 0.562
- 0.542
- 0.647
- 0.653
- 0.624
- 0.53
- 0.635
- 0.736
- 0.629
- 0.737
- 0.738
- 0.616
- 0.509
- 0.607
- 0.61
- 0.6
- 0.714
- 0.599
- 0.583
- 0.697
- 0.496
- 0.684
- 0.696
- 0.488
- 0.579
- 0.768
- 0.589
- 0.653
- 0.483
- 0.676
- 0.479
- 0.577
- 0.565
- 0.471
- 0.653
- 0.673
- 0.568
- 0.655
- 0.548
- 0.649
- 0.561
- 0.659
- 0.549
- 0.541
- 0.545
- 0.544
- 0.536
- 0.535
- 0.539
- 0.545
- 0.525
- 0.542
- 0.634
- 0.623
unequal: 0
verbose: 1
