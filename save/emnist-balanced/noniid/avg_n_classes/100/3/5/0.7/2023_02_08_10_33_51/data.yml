avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04989361702127659
- 0.09202127659574467
- 0.24122340425531916
- 0.2992021276595745
- 0.3279787234042553
- 0.3598936170212766
- 0.36638297872340425
- 0.3886702127659574
- 0.39867021276595743
- 0.4002659574468085
- 0.42095744680851066
- 0.4374468085106383
- 0.4396808510638298
- 0.44324468085106383
- 0.45053191489361705
- 0.46202127659574466
- 0.4628191489361702
- 0.47462765957446806
- 0.47643617021276596
- 0.48223404255319147
- 0.4906382978723404
- 0.4903723404255319
- 0.5007446808510638
- 0.49617021276595746
- 0.5038829787234043
- 0.5043617021276596
- 0.5076063829787234
- 0.5096808510638298
- 0.5165425531914893
- 0.5228723404255319
- 0.5239893617021276
- 0.5203191489361703
- 0.5204255319148936
- 0.5308510638297872
- 0.5234574468085106
- 0.5232978723404256
- 0.5315425531914894
- 0.5298936170212766
- 0.5289893617021276
- 0.5370212765957447
- 0.5301595744680851
- 0.5314893617021277
- 0.5391489361702128
- 0.5337234042553192
- 0.5367021276595745
- 0.5384574468085106
- 0.5403191489361702
- 0.5370212765957447
- 0.5441489361702128
- 0.5426595744680851
- 0.5486170212765957
- 0.5517021276595745
- 0.5479255319148936
- 0.5485638297872341
- 0.5504255319148936
- 0.5616489361702127
- 0.5523936170212767
- 0.5477659574468086
- 0.556595744680851
- 0.5522340425531915
- 0.5482978723404255
- 0.5534042553191489
- 0.5638829787234042
- 0.5551595744680851
- 0.5573404255319149
- 0.5642553191489361
- 0.5611170212765958
- 0.5577127659574468
- 0.5658510638297872
- 0.5564893617021277
- 0.5732446808510638
- 0.5597340425531915
- 0.564468085106383
- 0.5663297872340426
- 0.5637234042553192
- 0.5669148936170213
- 0.5665425531914894
- 0.5645212765957447
- 0.5628723404255319
- 0.5604255319148936
- 0.5660106382978723
- 0.564627659574468
- 0.5756382978723404
- 0.5590957446808511
- 0.5614361702127659
- 0.5667021276595745
- 0.5727127659574468
- 0.570531914893617
- 0.5736702127659574
- 0.5671276595744681
- 0.5721808510638298
- 0.5738829787234042
- 0.5681914893617022
- 0.5738829787234042
- 0.5814893617021276
- 0.5794148936170213
- 0.5825
- 0.5818617021276595
- 0.5721808510638298
- 0.576063829787234
test_loss_list:
- 3.7755307865142824
- 3.6931010500590005
- 3.4730380312601725
- 3.2971355565389
- 3.214689407348633
- 3.1232381216684977
- 2.9858975505828855
- 3.022315346399943
- 3.00512087504069
- 2.775090436935425
- 2.7764156595865885
- 2.8700837961832684
- 2.8239388275146484
- 2.6765669186909995
- 2.657946179707845
- 2.7499577140808107
- 2.68274351755778
- 2.7157472642262777
- 2.508896818161011
- 2.526598971684774
- 2.6465843804677327
- 2.460838867823283
- 2.6416745535532633
- 2.585361051559448
- 2.249767427444458
- 2.357535098393758
- 2.357688053448995
- 2.365556675593058
- 2.7313423283894855
- 2.277441972096761
- 2.472041514714559
- 2.2907537508010862
- 2.4175644747416176
- 2.2519771401087443
- 2.230854008992513
- 2.4172570514678955
- 2.3712116559346517
- 2.5897689342498778
- 2.36844957669576
- 2.2037509886423745
- 2.3445043913523356
- 2.6076114972432456
- 2.1344758669535318
- 2.365027902921041
- 2.3236535358428956
- 2.1601811981201173
- 2.0971792793273925
- 2.2853784799575805
- 2.0253634071350097
- 2.0844587739308675
- 2.051826252937317
- 1.8756886053085327
- 2.231731456120809
- 1.957964474360148
- 2.2196571588516236
- 1.8233958848317464
- 2.182692362467448
- 2.4141581853230796
- 2.1633462381362913
- 2.162392454147339
- 2.185445221265157
- 2.417106997172038
- 1.9764673407872517
- 1.9682096020380655
- 1.919323058128357
- 1.7655092604955038
- 1.9400381994247438
- 1.9004443454742432
- 1.8832713524500528
- 2.2756916729609173
- 1.7192320203781128
- 2.12015540599823
- 2.0720622046788533
- 2.1111358722050984
- 2.061694273948669
- 2.054080284436544
- 1.8784751685460408
- 2.011757780710856
- 1.819744660059611
- 2.010776522954305
- 1.804355912208557
- 2.0369675238927205
- 1.659460147221883
- 2.240525550842285
- 1.9649516868591308
- 1.9808173640569051
- 1.7860255479812621
- 1.982636857032776
- 1.7994435516993206
- 2.2258544603983563
- 1.7635131327311198
- 1.7698251342773437
- 2.2055140908559165
- 1.7545521847407024
- 1.7831499528884889
- 1.9538607279459634
- 1.7698396762212119
- 1.781363205909729
- 1.9412440490722656
- 1.9403850666681925
train_accuracy:
- 0.0
- 0.0
- 0.348
- 0.0
- 0.0
- 0.0
- 0.0
- 0.579
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.633
- 0.662
- 0.042
- 0.698
- 0.725
- 0.1
- 0.713
- 0.717
- 0.702
- 0.0
- 0.723
- 0.737
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.8
- 0.002
- 0.798
- 0.0
- 0.781
- 0.817
- 0.0
- 0.823
- 0.777
- 0.827
- 0.823
- 0.781
- 0.0
- 0.0
- 0.0
- 0.0
- 0.802
- 0.812
- 0.796
- 0.804
- 0.221
- 0.006
- 0.823
- 0.838
- 0.81
- 0.833
- 0.817
- 0.81
- 0.0
- 0.0
- 0.802
- 0.819
- 0.006
- 0.81
- 0.012
- 0.806
- 0.0
- 0.24
- 0.821
- 0.817
- 0.821
- 0.175
- 0.825
- 0.0
- 0.256
- 0.854
- 0.815
- 0.852
- 0.825
- 0.012
- 0.833
- 0.0
- 0.019
- 0.838
- 0.002
- 0.263
- 0.85
- 0.812
- 0.008
- 0.006
- 0.815
- 0.86
- 0.0
- 0.844
- 0.002
- 0.833
- 0.0
- 0.0
- 0.0
train_loss:
- 2.724
- 2.116
- 2.251
- 1.996
- 1.752
- 1.663
- 1.342
- 1.459
- 1.435
- 0.978
- 1.135
- 1.296
- 1.291
- 1.036
- 0.995
- 1.15
- 1.176
- 1.125
- 0.946
- 0.897
- 1.04
- 0.899
- 1.001
- 1.031
- 0.706
- 0.859
- 0.828
- 0.812
- 1.093
- 0.803
- 0.919
- 0.79
- 0.928
- 0.759
- 0.778
- 0.893
- 0.875
- 1.016
- 0.875
- 0.716
- 0.856
- 0.979
- 0.708
- 0.831
- 0.83
- 0.704
- 0.697
- 0.808
- 0.693
- 0.679
- 0.654
- 0.549
- 0.764
- 0.666
- 0.749
- 0.54
- 0.762
- 0.875
- 0.739
- 0.767
- 0.756
- 0.84
- 0.627
- 0.641
- 0.632
- 0.512
- 0.622
- 0.613
- 0.596
- 0.836
- 0.517
- 0.712
- 0.692
- 0.679
- 0.696
- 0.707
- 0.607
- 0.708
- 0.596
- 0.697
- 0.599
- 0.676
- 0.484
- 0.793
- 0.69
- 0.667
- 0.58
- 0.658
- 0.57
- 0.757
- 0.594
- 0.577
- 0.753
- 0.585
- 0.549
- 0.64
- 0.569
- 0.558
- 0.66
- 0.651
unequal: 0
verbose: 1
