avg_train_accuracy: 0.852
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.031223404255319148
- 0.10920212765957447
- 0.2398404255319149
- 0.3080851063829787
- 0.36367021276595746
- 0.37138297872340426
- 0.39441489361702126
- 0.40585106382978725
- 0.4211170212765957
- 0.41867021276595745
- 0.43196808510638296
- 0.44042553191489364
- 0.4528191489361702
- 0.4571808510638298
- 0.455
- 0.46441489361702126
- 0.47462765957446806
- 0.4702127659574468
- 0.47106382978723405
- 0.48058510638297874
- 0.48271276595744683
- 0.4854255319148936
- 0.48393617021276597
- 0.4925531914893617
- 0.49877659574468086
- 0.49936170212765957
- 0.5000531914893617
- 0.5002127659574468
- 0.5016489361702128
- 0.5065425531914893
- 0.5112765957446809
- 0.5145212765957446
- 0.5136702127659575
- 0.5188297872340426
- 0.512127659574468
- 0.5160638297872341
- 0.5202659574468085
- 0.5210638297872341
- 0.5219148936170213
- 0.5318617021276596
- 0.525
- 0.5275531914893618
- 0.5306382978723404
- 0.5315425531914894
- 0.5380851063829787
- 0.5390425531914894
- 0.5404787234042553
- 0.5425
- 0.5411702127659574
- 0.539468085106383
- 0.5402127659574468
- 0.5453191489361702
- 0.5461702127659575
- 0.5490425531914893
- 0.5461702127659575
- 0.5491489361702128
- 0.5496808510638298
- 0.5474468085106383
- 0.5538297872340425
- 0.5542553191489362
- 0.5588829787234042
- 0.5559574468085107
- 0.5518085106382978
- 0.5548936170212766
- 0.5523936170212767
- 0.560531914893617
- 0.5551595744680851
- 0.5595744680851064
- 0.5614893617021277
- 0.5643085106382979
- 0.5573404255319149
- 0.5585106382978723
- 0.5559042553191489
- 0.5621808510638298
- 0.5606382978723404
- 0.5594148936170212
- 0.565
- 0.5602127659574468
- 0.5663297872340426
- 0.5625
- 0.5663829787234043
- 0.5652659574468085
- 0.5644148936170212
- 0.5667021276595745
- 0.5672872340425532
- 0.5681914893617022
- 0.5663297872340426
- 0.5754255319148937
- 0.5637765957446809
- 0.5655851063829788
- 0.571968085106383
- 0.5722340425531914
- 0.5767021276595745
- 0.5685106382978723
- 0.5771276595744681
- 0.574627659574468
- 0.5694148936170212
- 0.5747340425531915
- 0.574840425531915
- 0.5776595744680851
test_loss_list:
- 3.7745396169026693
- 3.640419985453288
- 3.339197603861491
- 3.1167322413126626
- 3.1477264563242593
- 2.914709037144979
- 2.8386529890696206
- 2.9102906608581542
- 2.8794615046183267
- 2.7587209065755207
- 2.7274833329518637
- 2.823550386428833
- 2.9217811107635496
- 2.775303087234497
- 2.5937545426686603
- 2.740379657745361
- 2.7093289438883463
- 2.5605016231536863
- 2.555887730916341
- 2.70104434967041
- 2.6323019568125408
- 2.667096306482951
- 2.479489157994588
- 2.704254201253255
- 2.64663511912028
- 2.668656972249349
- 2.6224354298909507
- 2.461224946975708
- 2.4667997868855793
- 2.4347831789652505
- 2.413728068669637
- 2.362577927907308
- 2.3387714036305747
- 2.493788016637166
- 2.321645555496216
- 2.512058048248291
- 2.3176020336151124
- 2.1717754411697388
- 2.2589123169581096
- 2.6901176007588705
- 2.428365879058838
- 2.3032784827550254
- 2.450726245244344
- 2.4087535349527993
- 2.2133005539576214
- 2.4466999689737956
- 2.190359837214152
- 2.221449788411458
- 2.655704917907715
- 2.1430915943781534
- 2.2191582822799685
- 2.1378724479675295
- 2.1437621196111043
- 2.3264333407084146
- 2.044554932912191
- 2.0994492959976196
- 2.106305742263794
- 2.2632732439041137
- 2.305635862350464
- 2.0443910344441734
- 2.0762748273213703
- 2.0246737718582155
- 2.2174271806081136
- 2.042850324312846
- 2.5464490477244057
- 1.8093844175338745
- 2.296676198641459
- 1.9547623586654663
- 2.01934388478597
- 1.8173419380187987
- 2.1964362255732217
- 2.184177831013997
- 2.4975665378570557
- 1.9481312147776286
- 1.9742151578267415
- 2.145888568560282
- 1.9426169443130492
- 2.193497699101766
- 1.9431025250752767
- 2.22550581296285
- 2.0818065277735394
- 2.158664860725403
- 2.1661376762390137
- 1.9394459040959675
- 2.111922974586487
- 2.034825253486633
- 2.123222834269206
- 1.8626760562260947
- 2.0744281895955403
- 2.0821012242635093
- 1.8744423325856527
- 1.918319231669108
- 1.8164382696151733
- 2.0409458367029827
- 1.8078710063298544
- 1.8230581235885621
- 2.294360485076904
- 2.000637353261312
- 1.8796150000890095
- 1.8140362532933554
train_accuracy:
- 0.0
- 0.156
- 0.342
- 0.463
- 0.523
- 0.544
- 0.0
- 0.0
- 0.573
- 0.0
- 0.0
- 0.652
- 0.667
- 0.66
- 0.0
- 0.0
- 0.669
- 0.0
- 0.0
- 0.0
- 0.719
- 0.71
- 0.0
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.0
- 0.729
- 0.0
- 0.752
- 0.0
- 0.0
- 0.771
- 0.779
- 0.777
- 0.773
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.0
- 0.798
- 0.808
- 0.0
- 0.0
- 0.004
- 0.785
- 0.002
- 0.0
- 0.0
- 0.0
- 0.812
- 0.002
- 0.767
- 0.0
- 0.794
- 0.806
- 0.815
- 0.0
- 0.002
- 0.006
- 0.002
- 0.0
- 0.8
- 0.81
- 0.002
- 0.794
- 0.006
- 0.002
- 0.812
- 0.794
- 0.821
- 0.819
- 0.787
- 0.819
- 0.846
- 0.002
- 0.817
- 0.783
- 0.844
- 0.825
- 0.84
- 0.004
- 0.0
- 0.0
- 0.004
- 0.821
- 0.002
- 0.006
- 0.846
- 0.852
train_loss:
- 2.276
- 2.776
- 1.817
- 1.562
- 1.988
- 1.341
- 1.248
- 1.426
- 1.423
- 1.146
- 1.119
- 1.275
- 1.428
- 1.221
- 0.995
- 1.185
- 1.126
- 0.923
- 0.968
- 1.098
- 1.064
- 1.025
- 0.908
- 1.038
- 0.985
- 1.019
- 0.97
- 0.809
- 0.823
- 0.819
- 0.789
- 0.77
- 0.755
- 0.892
- 0.781
- 0.918
- 0.778
- 0.621
- 0.761
- 0.961
- 0.899
- 0.726
- 0.841
- 0.841
- 0.709
- 0.826
- 0.721
- 0.683
- 0.924
- 0.711
- 0.698
- 0.699
- 0.671
- 0.77
- 0.69
- 0.676
- 0.664
- 0.769
- 0.757
- 0.674
- 0.628
- 0.665
- 0.757
- 0.653
- 0.827
- 0.544
- 0.719
- 0.627
- 0.619
- 0.525
- 0.723
- 0.714
- 0.82
- 0.615
- 0.632
- 0.715
- 0.617
- 0.72
- 0.604
- 0.667
- 0.697
- 0.696
- 0.707
- 0.611
- 0.685
- 0.709
- 0.71
- 0.609
- 0.692
- 0.695
- 0.583
- 0.557
- 0.594
- 0.672
- 0.588
- 0.58
- 0.773
- 0.687
- 0.55
- 0.544
unequal: 0
verbose: 1
