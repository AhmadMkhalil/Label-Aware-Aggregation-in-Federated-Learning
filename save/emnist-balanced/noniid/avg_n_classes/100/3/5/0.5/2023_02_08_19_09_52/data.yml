avg_train_accuracy: 0.81
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.015425531914893617
- 0.05345744680851064
- 0.1626063829787234
- 0.25111702127659574
- 0.2820744680851064
- 0.07297872340425532
- 0.3321808510638298
- 0.3531382978723404
- 0.3831914893617021
- 0.3997340425531915
- 0.40611702127659577
- 0.4144148936170213
- 0.4222872340425532
- 0.43606382978723407
- 0.4403723404255319
- 0.4493617021276596
- 0.45154255319148934
- 0.45372340425531915
- 0.4703191489361702
- 0.47335106382978726
- 0.4656914893617021
- 0.47164893617021275
- 0.47808510638297874
- 0.4778191489361702
- 0.4743617021276596
- 0.49234042553191487
- 0.49696808510638296
- 0.4950531914893617
- 0.4952127659574468
- 0.495
- 0.5072872340425532
- 0.49707446808510636
- 0.5000531914893617
- 0.5048404255319149
- 0.5041489361702127
- 0.5181914893617021
- 0.5133510638297872
- 0.5182446808510638
- 0.515531914893617
- 0.5231382978723405
- 0.5276595744680851
- 0.5132978723404256
- 0.531063829787234
- 0.5293085106382979
- 0.530904255319149
- 0.5295212765957447
- 0.5328191489361702
- 0.5287765957446808
- 0.5373936170212766
- 0.5351595744680852
- 0.5378191489361702
- 0.5344148936170213
- 0.5380851063829787
- 0.5417021276595745
- 0.5471276595744681
- 0.544468085106383
- 0.5429787234042553
- 0.5382978723404256
- 0.5484042553191489
- 0.5441489361702128
- 0.5507446808510639
- 0.548936170212766
- 0.5475
- 0.5504255319148936
- 0.5462765957446809
- 0.546595744680851
- 0.5456914893617021
- 0.5513297872340426
- 0.551595744680851
- 0.5495744680851063
- 0.5561702127659575
- 0.5570212765957446
- 0.5604787234042553
- 0.5561170212765958
- 0.5542021276595744
- 0.5578191489361702
- 0.5604787234042553
- 0.5562234042553191
- 0.5520212765957446
- 0.5607446808510639
- 0.5599468085106383
- 0.5590957446808511
- 0.5613829787234043
- 0.5592021276595744
- 0.5586170212765957
- 0.5608510638297872
- 0.5622340425531915
- 0.5638829787234042
- 0.5626063829787235
- 0.5642021276595744
- 0.5644148936170212
- 0.5625
- 0.5606382978723404
- 0.5640957446808511
- 0.5621276595744681
- 0.5618085106382978
- 0.5628191489361702
- 0.5664893617021277
- 0.5656914893617021
- 0.5672340425531915
test_loss_list:
- 3.8053444735209148
- 3.822025556564331
- 3.7204065990447996
- 3.6360196336110433
- 3.34309268951416
- 3.451553881963094
- 3.111036523183187
- 3.257270046869914
- 3.1866451199849446
- 3.1622210534413657
- 3.028824094136556
- 2.936916217803955
- 2.935313860575358
- 3.081475540796916
- 3.025744047164917
- 3.0446191310882567
- 2.963965819676717
- 2.7423508008321127
- 2.991629705429077
- 3.0023085435231525
- 2.5791857115427654
- 2.6717517375946045
- 2.715925556818644
- 2.5954251925150555
- 2.511206579208374
- 2.874494934082031
- 2.883185437520345
- 2.6512183570861816
- 2.510360933939616
- 2.4112193234761556
- 3.1156210199991863
- 2.465433340072632
- 2.3860185114542642
- 2.390349095662435
- 2.2956009260813395
- 2.957787275314331
- 2.5005726846059164
- 2.5744973373413087
- 2.474950329462687
- 2.6632270495096844
- 3.078885691960653
- 2.2739365609486897
- 2.6684914143880207
- 2.602069826126099
- 2.9813585567474363
- 2.4455840237935385
- 2.681515318552653
- 2.2772761948903404
- 2.9923698329925537
- 2.368859335581462
- 2.6456975428263347
- 2.4297712739308674
- 2.6654694493611655
- 2.716101942062378
- 2.9762769254048664
- 2.8993457889556886
- 2.6629576746622723
- 2.3896832052866617
- 2.9099189122517903
- 2.5615679931640627
- 3.3273664983113607
- 2.6531346893310546
- 2.424538501103719
- 2.9548799482981365
- 2.4841293652852374
- 2.3653896872202553
- 2.3416356213887535
- 2.262482552528381
- 2.303366117477417
- 2.073385877609253
- 2.253016826311747
- 2.7425180689493813
- 2.1674520587921142
- 2.464893363316854
- 2.410936161677043
- 2.7658904711405436
- 3.1493889077504478
- 2.3305594396591185
- 2.141438678105672
- 2.2545183912913003
- 2.4524928538004556
- 2.7699082724253334
- 2.3053003327051798
- 2.8526919809977214
- 2.5108320331573486
- 2.5198796463012694
- 2.474343907038371
- 2.5417993291219076
- 2.2363062874476114
- 2.13548015276591
- 2.4520348358154296
- 2.103896830876668
- 2.156619370778402
- 2.2755559412638346
- 2.150788377126058
- 2.3447187169392905
- 2.404606029192607
- 2.3828461154301963
- 2.6967023976643882
- 2.3790146748224896
train_accuracy:
- 0.025
- 0.081
- 0.0
- 0.362
- 0.0
- 0.002
- 0.0
- 0.49
- 0.573
- 0.577
- 0.0
- 0.654
- 0.0
- 0.0
- 0.673
- 0.652
- 0.66
- 0.677
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.763
- 0.777
- 0.0
- 0.015
- 0.796
- 0.75
- 0.0
- 0.002
- 0.0
- 0.773
- 0.0
- 0.0
- 0.0
- 0.781
- 0.769
- 0.0
- 0.767
- 0.819
- 0.823
- 0.0
- 0.777
- 0.769
- 0.0
- 0.0
- 0.802
- 0.79
- 0.0
- 0.0
- 0.819
- 0.792
- 0.773
- 0.804
- 0.829
- 0.0
- 0.787
- 0.0
- 0.0
- 0.0
- 0.825
- 0.0
- 0.0
- 0.804
- 0.0
- 0.0
- 0.787
- 0.812
- 0.0
- 0.833
- 0.0
- 0.85
- 0.856
- 0.819
- 0.0
- 0.002
- 0.838
- 0.819
- 0.002
- 0.842
- 0.823
- 0.81
- 0.815
- 0.002
- 0.844
- 0.002
- 0.006
- 0.002
- 0.796
- 0.838
- 0.81
- 0.0
- 0.833
- 0.806
- 0.848
- 0.81
train_loss:
- 2.925
- 3.209
- 2.072
- 2.676
- 1.582
- 0.709
- 1.796
- 2.042
- 1.639
- 1.52
- 1.137
- 1.121
- 1.065
- 1.365
- 1.312
- 1.242
- 1.252
- 0.991
- 1.158
- 1.175
- 0.715
- 0.91
- 0.913
- 0.911
- 0.642
- 1.049
- 1.012
- 0.84
- 0.874
- 0.612
- 1.199
- 0.823
- 0.614
- 0.578
- 0.605
- 1.152
- 0.767
- 0.755
- 0.773
- 0.933
- 1.075
- 0.603
- 0.916
- 0.913
- 1.061
- 0.721
- 0.874
- 0.557
- 1.006
- 0.749
- 0.847
- 0.686
- 0.857
- 0.837
- 0.988
- 0.992
- 0.826
- 0.681
- 0.966
- 0.827
- 1.085
- 0.819
- 0.653
- 0.941
- 0.652
- 0.643
- 0.652
- 0.632
- 0.624
- 0.489
- 0.603
- 0.898
- 0.659
- 0.743
- 0.769
- 0.899
- 1.011
- 0.655
- 0.483
- 0.608
- 0.732
- 0.854
- 0.609
- 0.849
- 0.736
- 0.726
- 0.743
- 0.711
- 0.601
- 0.601
- 0.705
- 0.449
- 0.581
- 0.724
- 0.584
- 0.686
- 0.702
- 0.686
- 0.811
- 0.707
unequal: 0
verbose: 1
