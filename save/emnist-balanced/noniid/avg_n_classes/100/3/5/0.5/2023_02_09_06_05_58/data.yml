avg_train_accuracy: 0.844
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021808510638297873
- 0.04
- 0.18111702127659574
- 0.2698404255319149
- 0.34425531914893615
- 0.35340425531914893
- 0.38601063829787235
- 0.4020744680851064
- 0.42686170212765956
- 0.4375
- 0.42914893617021277
- 0.455
- 0.45797872340425533
- 0.4548404255319149
- 0.46085106382978724
- 0.474468085106383
- 0.4697340425531915
- 0.4776595744680851
- 0.48664893617021276
- 0.4745744680851064
- 0.4752127659574468
- 0.49
- 0.49569148936170215
- 0.4867021276595745
- 0.5035106382978723
- 0.5011170212765957
- 0.49829787234042555
- 0.5105851063829787
- 0.5065957446808511
- 0.5121808510638298
- 0.5159574468085106
- 0.5167021276595745
- 0.5093085106382979
- 0.5230851063829787
- 0.524468085106383
- 0.5238829787234043
- 0.5252659574468085
- 0.5189893617021276
- 0.5336170212765957
- 0.5288297872340425
- 0.5325531914893618
- 0.5326063829787234
- 0.533563829787234
- 0.5344148936170213
- 0.5380851063829787
- 0.5412765957446809
- 0.5351595744680852
- 0.5379787234042553
- 0.5388297872340425
- 0.5405319148936171
- 0.34606382978723405
- 0.5447340425531915
- 0.5423404255319149
- 0.5436170212765957
- 0.5473936170212766
- 0.5466489361702128
- 0.5471808510638297
- 0.5480851063829787
- 0.5498404255319149
- 0.5447340425531915
- 0.5493085106382979
- 0.5509574468085107
- 0.5543617021276596
- 0.5506382978723404
- 0.5535638297872341
- 0.5561702127659575
- 0.5529255319148936
- 0.553936170212766
- 0.550372340425532
- 0.5571808510638298
- 0.5554255319148936
- 0.5587765957446809
- 0.5564893617021277
- 0.5600531914893617
- 0.5571808510638298
- 0.5579255319148936
- 0.5556382978723404
- 0.5546808510638298
- 0.5587765957446809
- 0.5627127659574468
- 0.5567021276595745
- 0.5556914893617021
- 0.558404255319149
- 0.5587234042553192
- 0.5564361702127659
- 0.5581382978723404
- 0.4345212765957447
- 0.5596808510638298
- 0.5628723404255319
- 0.5610106382978723
- 0.5601063829787234
- 0.5588829787234042
- 0.5604255319148936
- 0.5622872340425532
- 0.5621276595744681
- 0.5636702127659574
- 0.5640957446808511
- 0.5631914893617022
- 0.5613829787234043
- 0.5634574468085106
test_loss_list:
- 3.7970876916249594
- 3.8002006371815997
- 3.6872336514790853
- 3.4665578111012776
- 3.2873120943705243
- 3.0651515515645347
- 3.098345384597778
- 3.025503759384155
- 3.1216535218556722
- 3.1030846627553306
- 2.8556653308868407
- 3.121964324315389
- 3.095839096705119
- 2.915947160720825
- 3.07604692141215
- 3.2236542892456055
- 2.861122016906738
- 3.0076762040456138
- 3.310866009394328
- 2.8122100989023844
- 2.659959259033203
- 2.831984491348267
- 2.911148176193237
- 2.581803881327311
- 3.2347244135538737
- 2.8798132673899333
- 2.6705806700388592
- 2.9623648897806802
- 2.743798605600993
- 2.86193128267924
- 2.9421916103363035
- 2.9118161487579344
- 2.50219175974528
- 2.878195988337199
- 2.8854926013946534
- 2.624366709391276
- 2.757155599594116
- 2.4118724886576333
- 2.7922688357035317
- 2.481837431589762
- 2.7851829783121747
- 2.532904666264852
- 2.475586363474528
- 2.4890708827972414
- 2.700221554438273
- 3.043938153584798
- 2.3758626047770184
- 2.265212861696879
- 2.4569914595286053
- 2.4136309560139972
- 2.302653980255127
- 2.4172696431477863
- 2.2733134905497234
- 2.2988554588953654
- 2.2827157147725425
- 2.4432579962412517
- 2.4857426484425864
- 2.5241846307118734
- 2.317262366612752
- 2.574900821050008
- 2.5363108189900716
- 2.5308527247111003
- 2.286435834566752
- 2.4784633191426595
- 2.427680050532023
- 2.2811000108718873
- 2.4462066459655762
- 2.236667979558309
- 2.158979303042094
- 2.5000247287750246
- 2.2919399531682334
- 1.9942809025446573
- 2.2202592086791992
- 1.9422007815043132
- 2.2421185684204104
- 2.370948715209961
- 2.189557223320007
- 2.4786031246185303
- 2.774087832768758
- 2.1202910153071084
- 2.4258890342712403
- 2.196906674702962
- 2.334150349299113
- 2.3380664602915444
- 1.9844497934977214
- 2.3111012824376425
- 1.974804859161377
- 1.933118085861206
- 2.02776095867157
- 2.2108513863881427
- 2.228793110847473
- 2.276710810661316
- 2.584798434575399
- 2.282839585940043
- 2.096688469250997
- 2.095648857752482
- 2.256699029604594
- 2.0812396876017254
- 2.368374532063802
- 2.0669551626841227
train_accuracy:
- 0.025
- 0.0
- 0.248
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.671
- 0.627
- 0.0
- 0.692
- 0.0
- 0.656
- 0.673
- 0.721
- 0.0
- 0.698
- 0.754
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.783
- 0.756
- 0.723
- 0.765
- 0.0
- 0.744
- 0.765
- 0.773
- 0.0
- 0.785
- 0.779
- 0.0
- 0.81
- 0.0
- 0.821
- 0.748
- 0.785
- 0.821
- 0.0
- 0.0
- 0.0
- 0.804
- 0.76
- 0.0
- 0.0
- 0.0
- 0.167
- 0.0
- 0.002
- 0.817
- 0.0
- 0.8
- 0.0
- 0.815
- 0.802
- 0.0
- 0.812
- 0.858
- 0.0
- 0.802
- 0.0
- 0.817
- 0.781
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.775
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.827
- 0.004
- 0.781
- 0.352
- 0.79
- 0.819
- 0.881
- 0.777
- 0.002
- 0.79
- 0.0
- 0.0
- 0.004
- 0.871
- 0.004
- 0.808
- 0.844
train_loss:
- 2.883
- 2.719
- 2.987
- 2.28
- 1.565
- 1.007
- 1.229
- 1.262
- 1.424
- 1.403
- 0.924
- 1.306
- 1.343
- 1.03
- 1.198
- 1.444
- 0.983
- 1.145
- 1.316
- 0.993
- 0.732
- 0.865
- 1.089
- 0.668
- 1.223
- 1.047
- 0.883
- 1.019
- 0.81
- 0.968
- 0.944
- 0.962
- 0.649
- 0.939
- 0.931
- 0.785
- 0.924
- 0.595
- 0.91
- 0.751
- 0.896
- 0.747
- 0.726
- 0.713
- 0.851
- 1.013
- 0.729
- 0.542
- 0.673
- 0.657
- 0.383
- 0.871
- 0.659
- 0.657
- 0.645
- 0.817
- 0.803
- 0.793
- 0.629
- 0.779
- 0.792
- 0.77
- 0.631
- 0.778
- 0.808
- 0.643
- 0.777
- 0.608
- 0.474
- 0.739
- 0.595
- 0.462
- 0.587
- 0.489
- 0.578
- 0.725
- 0.6
- 0.713
- 0.841
- 0.628
- 0.749
- 0.612
- 0.734
- 0.744
- 0.479
- 0.717
- 0.337
- 0.585
- 0.575
- 0.713
- 0.705
- 0.714
- 0.82
- 0.7
- 0.559
- 0.573
- 0.688
- 0.56
- 0.667
- 0.554
unequal: 0
verbose: 1
