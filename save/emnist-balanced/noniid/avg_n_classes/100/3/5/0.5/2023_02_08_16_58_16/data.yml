avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024893617021276595
- 0.0927127659574468
- 0.2251595744680851
- 0.2828191489361702
- 0.34430851063829787
- 0.38
- 0.399468085106383
- 0.41627659574468084
- 0.4156382978723404
- 0.4376063829787234
- 0.43867021276595747
- 0.4341489361702128
- 0.44148936170212766
- 0.4408510638297872
- 0.46664893617021275
- 0.46547872340425533
- 0.4772872340425532
- 0.47452127659574467
- 0.4852659574468085
- 0.47191489361702127
- 0.48319148936170214
- 0.4924468085106383
- 0.49590425531914895
- 0.4897872340425532
- 0.49877659574468086
- 0.504095744680851
- 0.5022872340425532
- 0.5146808510638298
- 0.5160638297872341
- 0.5130851063829788
- 0.5146808510638298
- 0.5091489361702127
- 0.5161170212765958
- 0.5246808510638298
- 0.5287765957446808
- 0.5247872340425532
- 0.5232978723404256
- 0.5275531914893618
- 0.5334042553191489
- 0.5269148936170213
- 0.531436170212766
- 0.5362765957446809
- 0.5314893617021277
- 0.5391489361702128
- 0.5377659574468086
- 0.5414361702127659
- 0.5381914893617021
- 0.5403191489361702
- 0.5438829787234043
- 0.5483510638297873
- 0.5458510638297872
- 0.5477659574468086
- 0.5538297872340425
- 0.5490957446808511
- 0.5497872340425531
- 0.5488829787234043
- 0.5514361702127659
- 0.550372340425532
- 0.5524468085106383
- 0.5547340425531915
- 0.5531914893617021
- 0.5500531914893617
- 0.5540957446808511
- 0.554468085106383
- 0.5557446808510639
- 0.555372340425532
- 0.5580851063829787
- 0.5588297872340425
- 0.5648936170212766
- 0.561968085106383
- 0.5594148936170212
- 0.5542553191489362
- 0.5550531914893617
- 0.5568085106382978
- 0.5581382978723404
- 0.5581914893617022
- 0.5607978723404256
- 0.5571276595744681
- 0.5603191489361702
- 0.5573404255319149
- 0.5625531914893617
- 0.5636702127659574
- 0.5645212765957447
- 0.561595744680851
- 0.5626063829787235
- 0.5620744680851064
- 0.5641489361702128
- 0.5637765957446809
- 0.5631382978723404
- 0.5645212765957447
- 0.5624468085106383
- 0.5638297872340425
- 0.5643617021276596
- 0.565
- 0.5728191489361703
- 0.5681914893617022
- 0.5655851063829788
- 0.5673936170212766
- 0.5706382978723404
- 0.5697872340425532
test_loss_list:
- 3.7855071862538656
- 3.7196801789601643
- 3.4785415172576903
- 3.2060343742370607
- 3.1549093755086264
- 3.113345874150594
- 3.0871193695068357
- 3.125907882054647
- 2.9323778343200684
- 2.986153014500936
- 2.8517229906717936
- 2.695868721008301
- 2.7108018302917483
- 2.6267594877878824
- 3.1606947135925294
- 2.737019526163737
- 3.211020024617513
- 2.821027100880941
- 2.9648592217763263
- 2.4677734343210855
- 2.681872730255127
- 2.913094352086385
- 2.8422906589508057
- 2.6067674922943116
- 2.813669465382894
- 2.818235502243042
- 2.444663298924764
- 3.077416769663493
- 3.075468791325887
- 2.71881147702535
- 2.5595436000823977
- 2.4924132506052654
- 2.5475183804829915
- 2.712908684412638
- 2.7296421082814533
- 2.4803284867604574
- 2.280764842033386
- 2.436833422978719
- 2.5574730809529624
- 2.368094418843587
- 2.405924873352051
- 2.91161501566569
- 2.3801348495483396
- 2.6295776335398355
- 2.235400692621867
- 2.567936890920003
- 2.32779748916626
- 2.1737948338190716
- 2.338758697509766
- 2.1231884876887004
- 2.4960295136769615
- 2.214198603630066
- 2.0243988847732544
- 2.2193563652038573
- 2.250995890299479
- 1.9922841882705689
- 2.755927521387736
- 2.3695103454589845
- 2.8326912784576415
- 2.8132709821065265
- 2.9400324789683023
- 2.2466653458277386
- 2.488333781560262
- 2.476824862162272
- 2.513404378890991
- 2.3447009722391763
- 2.3222421741485597
- 2.2801050758361816
- 2.0287447770436606
- 2.3089659198125205
- 2.4694728406270343
- 2.1345562426249187
- 2.403772446314494
- 1.9796970224380492
- 2.2042225233713784
- 1.9304988543192545
- 2.435813989639282
- 2.140705248514811
- 2.1116245460510252
- 1.9418713156382243
- 2.423697373072306
- 2.6222923533121745
- 2.138565279642741
- 2.1247706508636472
- 2.077466376622518
- 2.5954009660085045
- 2.4058611329396564
- 2.17270307858785
- 2.0501517168680827
- 2.3304602909088135
- 2.087994874318441
- 2.286427551905314
- 2.379587494532267
- 2.0454591131210327
- 1.9420851802825927
- 2.3489553260803224
- 2.294363811810811
- 2.027605560620626
- 2.3733735593159992
- 2.0776150608062744
train_accuracy:
- 0.044
- 0.14
- 0.342
- 0.0
- 0.515
- 0.592
- 0.571
- 0.0
- 0.0
- 0.0
- 0.64
- 0.65
- 0.0
- 0.681
- 0.719
- 0.71
- 0.0
- 0.0
- 0.69
- 0.0
- 0.683
- 0.0
- 0.708
- 0.0
- 0.783
- 0.733
- 0.0
- 0.781
- 0.79
- 0.756
- 0.79
- 0.0
- 0.0
- 0.76
- 0.0
- 0.769
- 0.0
- 0.0
- 0.0
- 0.0
- 0.771
- 0.81
- 0.833
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.756
- 0.777
- 0.006
- 0.0
- 0.81
- 0.819
- 0.823
- 0.844
- 0.86
- 0.806
- 0.0
- 0.844
- 0.0
- 0.808
- 0.848
- 0.804
- 0.8
- 0.819
- 0.0
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.775
- 0.01
- 0.846
- 0.0
- 0.0
- 0.0
- 0.0
- 0.783
- 0.815
- 0.785
- 0.787
- 0.0
- 0.794
- 0.833
- 0.835
- 0.0
- 0.844
- 0.79
- 0.838
- 0.0
- 0.004
- 0.867
- 0.0
- 0.829
- 0.002
- 0.0
train_loss:
- 2.767
- 2.586
- 2.325
- 1.543
- 1.819
- 1.64
- 1.538
- 1.513
- 1.124
- 1.378
- 1.138
- 0.816
- 0.757
- 0.753
- 1.464
- 0.976
- 1.384
- 1.173
- 1.106
- 0.719
- 0.869
- 1.04
- 1.074
- 0.855
- 1.019
- 1.004
- 0.642
- 1.177
- 1.157
- 0.99
- 0.769
- 0.787
- 0.76
- 0.923
- 0.908
- 0.728
- 0.569
- 0.721
- 0.891
- 0.714
- 0.696
- 1.047
- 0.716
- 0.854
- 0.534
- 0.86
- 0.703
- 0.514
- 0.657
- 0.515
- 0.797
- 0.656
- 0.498
- 0.646
- 0.654
- 0.489
- 0.936
- 0.797
- 0.931
- 0.933
- 0.908
- 0.671
- 0.772
- 0.751
- 0.764
- 0.639
- 0.623
- 0.615
- 0.471
- 0.586
- 0.751
- 0.611
- 0.729
- 0.47
- 0.604
- 0.454
- 0.717
- 0.586
- 0.581
- 0.449
- 0.711
- 0.86
- 0.596
- 0.58
- 0.584
- 0.835
- 0.708
- 0.585
- 0.588
- 0.695
- 0.566
- 0.693
- 0.697
- 0.576
- 0.428
- 0.692
- 0.686
- 0.551
- 0.677
- 0.548
unequal: 0
verbose: 1
