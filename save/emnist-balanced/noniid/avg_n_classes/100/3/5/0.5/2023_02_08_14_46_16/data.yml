avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03537234042553192
- 0.09462765957446809
- 0.1803723404255319
- 0.26861702127659576
- 0.33893617021276595
- 0.3822340425531915
- 0.3658510638297872
- 0.4073936170212766
- 0.3904255319148936
- 0.42106382978723406
- 0.4175
- 0.45420212765957446
- 0.4471276595744681
- 0.4441489361702128
- 0.45914893617021274
- 0.46127659574468083
- 0.45132978723404255
- 0.4753191489361702
- 0.464468085106383
- 0.4602127659574468
- 0.4649468085106383
- 0.491436170212766
- 0.4732446808510638
- 0.5050531914893617
- 0.5078723404255319
- 0.49234042553191487
- 0.5023404255319149
- 0.5039893617021277
- 0.512340425531915
- 0.5192553191489362
- 0.5106382978723404
- 0.5223404255319148
- 0.5118085106382979
- 0.5217553191489361
- 0.5284574468085106
- 0.515904255319149
- 0.5276595744680851
- 0.5298936170212766
- 0.5321276595744681
- 0.5290957446808511
- 0.5338829787234043
- 0.5302127659574468
- 0.5351595744680852
- 0.5367021276595745
- 0.5408510638297872
- 0.5392021276595744
- 0.5435106382978724
- 0.5403191489361702
- 0.538031914893617
- 0.5446808510638298
- 0.5464893617021277
- 0.5424468085106383
- 0.5426063829787234
- 0.5405851063829787
- 0.5457446808510639
- 0.5473936170212766
- 0.5436702127659574
- 0.5528723404255319
- 0.5495744680851063
- 0.5538829787234043
- 0.5457446808510639
- 0.5488829787234043
- 0.545372340425532
- 0.5534574468085106
- 0.5542553191489362
- 0.5557978723404255
- 0.5564361702127659
- 0.5518085106382978
- 0.558031914893617
- 0.5568085106382978
- 0.555
- 0.5509042553191489
- 0.5578191489361702
- 0.5556914893617021
- 0.5569148936170213
- 0.5590425531914893
- 0.561063829787234
- 0.561063829787234
- 0.5616489361702127
- 0.5632978723404255
- 0.5650531914893617
- 0.5595744680851064
- 0.5592021276595744
- 0.5588829787234042
- 0.5653191489361702
- 0.5587234042553192
- 0.5666489361702127
- 0.5607978723404256
- 0.5645744680851064
- 0.5654787234042553
- 0.5678723404255319
- 0.568404255319149
- 0.5648936170212766
- 0.5645744680851064
- 0.5660106382978723
- 0.5685106382978723
- 0.5653191489361702
- 0.5667021276595745
- 0.5662765957446808
- 0.5693085106382979
test_loss_list:
- 3.823502861658732
- 3.8185589567820233
- 3.5997830867767333
- 3.3448941802978513
- 3.2603120454152426
- 3.3715910625457766
- 3.0604840469360353
- 3.334341843922933
- 2.9804757817586265
- 3.185943965911865
- 2.951351661682129
- 3.4880773862202963
- 3.040746161142985
- 2.935326801935832
- 3.196198345820109
- 3.1504263242085773
- 2.834984817504883
- 3.1757114505767823
- 2.745882501602173
- 2.646589059829712
- 2.589865738550822
- 3.098969831466675
- 2.5576851558685303
- 3.4496439107259116
- 3.4617301654815673
- 2.7401054032643635
- 2.805840015411377
- 2.8708587487538657
- 2.98425724029541
- 3.416333745320638
- 2.888877477645874
- 3.388334716161092
- 2.6475068537394204
- 2.9571233558654786
- 3.343254356384277
- 2.5902874851226807
- 2.9389181264241535
- 2.97080667813619
- 2.9567405478159587
- 2.9027427037556968
- 2.9507987531026205
- 2.578094129562378
- 2.856029094060262
- 2.8416725826263427
- 3.234630263646444
- 2.799313071568807
- 3.256783364613851
- 2.9031149037679036
- 2.6070549869537354
- 2.9249797852834067
- 2.792051086425781
- 2.7411977831522623
- 2.5479388427734375
- 2.2471627950668336
- 2.2564682579040527
- 2.386613834698995
- 2.4449530601501466
- 2.9981216208140054
- 2.705748764673869
- 2.6365000502268474
- 2.4552653662363686
- 2.387967883745829
- 2.3980472405751545
- 2.745291372934977
- 2.9348346932729084
- 2.5825356229146323
- 2.6737242476145426
- 2.430954271952311
- 2.6534903208414713
- 2.6438108412424723
- 2.5428079573313394
- 2.280838720003764
- 2.397757757504781
- 2.1033517916997275
- 2.362316109339396
- 2.2379159498214722
- 2.280282184282939
- 2.2069555505116782
- 2.502259531021118
- 2.248757085800171
- 3.334068603515625
- 2.469848213195801
- 2.161878137588501
- 2.206944319407145
- 2.4863776556650796
- 2.108714903195699
- 2.3048813756306967
- 2.4219672711690268
- 2.5314713096618653
- 2.4092482725779214
- 1.867604875564575
- 2.1828963406880697
- 2.184546634356181
- 2.477311185201009
- 2.097748753229777
- 3.2470882511138917
- 2.1092224502563477
- 2.180892376899719
- 2.1905596923828123
- 2.47878134727478
train_accuracy:
- 0.044
- 0.0
- 0.252
- 0.0
- 0.0
- 0.0
- 0.56
- 0.64
- 0.588
- 0.646
- 0.0
- 0.685
- 0.0
- 0.0
- 0.0
- 0.688
- 0.0
- 0.0
- 0.694
- 0.0
- 0.0
- 0.0
- 0.002
- 0.75
- 0.769
- 0.733
- 0.0
- 0.0
- 0.765
- 0.779
- 0.0
- 0.0
- 0.0
- 0.779
- 0.79
- 0.0
- 0.804
- 0.0
- 0.783
- 0.798
- 0.777
- 0.0
- 0.802
- 0.81
- 0.0
- 0.0
- 0.815
- 0.802
- 0.0
- 0.808
- 0.806
- 0.81
- 0.01
- 0.033
- 0.0
- 0.817
- 0.808
- 0.817
- 0.817
- 0.821
- 0.79
- 0.0
- 0.827
- 0.817
- 0.829
- 0.819
- 0.835
- 0.0
- 0.808
- 0.006
- 0.0
- 0.029
- 0.019
- 0.0
- 0.827
- 0.806
- 0.027
- 0.0
- 0.825
- 0.829
- 0.838
- 0.008
- 0.0
- 0.835
- 0.0
- 0.0
- 0.804
- 0.806
- 0.008
- 0.842
- 0.0
- 0.027
- 0.0
- 0.0
- 0.819
- 0.829
- 0.031
- 0.0
- 0.817
- 0.0
train_loss:
- 3.279
- 2.203
- 1.926
- 1.602
- 1.847
- 2.034
- 1.245
- 1.822
- 1.19
- 1.38
- 1.06
- 1.563
- 1.369
- 1.042
- 1.225
- 1.188
- 0.974
- 1.147
- 0.991
- 0.717
- 0.687
- 1.07
- 0.667
- 1.238
- 1.219
- 0.838
- 0.809
- 1.011
- 1.024
- 1.119
- 0.982
- 1.121
- 0.824
- 0.934
- 1.081
- 0.766
- 0.912
- 0.926
- 0.886
- 0.887
- 0.86
- 0.698
- 0.884
- 0.843
- 1.001
- 0.839
- 1.015
- 0.829
- 0.662
- 0.79
- 0.815
- 0.892
- 0.667
- 0.527
- 0.51
- 0.64
- 0.667
- 0.928
- 0.787
- 0.79
- 0.661
- 0.662
- 0.628
- 0.749
- 0.912
- 0.767
- 0.769
- 0.62
- 0.733
- 0.718
- 0.789
- 0.616
- 0.593
- 0.457
- 0.578
- 0.607
- 0.573
- 0.593
- 0.729
- 0.556
- 0.978
- 0.736
- 0.448
- 0.577
- 0.692
- 0.611
- 0.541
- 0.701
- 0.671
- 0.695
- 0.483
- 0.555
- 0.566
- 0.675
- 0.555
- 0.933
- 0.586
- 0.588
- 0.551
- 0.666
unequal: 0
verbose: 1
