avg_train_accuracy: 0.858
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.035851063829787234
- 0.12462765957446809
- 0.26191489361702125
- 0.3321276595744681
- 0.3753723404255319
- 0.39952127659574466
- 0.4199468085106383
- 0.43196808510638296
- 0.42909574468085104
- 0.44372340425531914
- 0.44005319148936173
- 0.4667021276595745
- 0.46420212765957447
- 0.4572340425531915
- 0.4743085106382979
- 0.4776595744680851
- 0.4837234042553191
- 0.48888297872340425
- 0.48186170212765955
- 0.4920744680851064
- 0.5013829787234042
- 0.4978723404255319
- 0.5048404255319149
- 0.5074468085106383
- 0.5026063829787234
- 0.5057978723404255
- 0.51
- 0.518563829787234
- 0.5145744680851064
- 0.5198404255319149
- 0.5241489361702127
- 0.5232446808510638
- 0.5310106382978723
- 0.5301063829787234
- 0.5258510638297872
- 0.5316489361702128
- 0.531063829787234
- 0.5318617021276596
- 0.5307446808510639
- 0.5294148936170213
- 0.5351063829787234
- 0.5343085106382979
- 0.5436170212765957
- 0.5419148936170213
- 0.5420212765957447
- 0.5441489361702128
- 0.5461702127659575
- 0.5413297872340426
- 0.5442553191489362
- 0.5490425531914893
- 0.5503191489361702
- 0.5482978723404255
- 0.5529787234042554
- 0.5455319148936171
- 0.5502127659574468
- 0.5521276595744681
- 0.5509042553191489
- 0.5517021276595745
- 0.5507978723404255
- 0.5531382978723405
- 0.5538829787234043
- 0.5550531914893617
- 0.5550531914893617
- 0.5564893617021277
- 0.5557978723404255
- 0.5546808510638298
- 0.5572340425531915
- 0.5574468085106383
- 0.5554787234042553
- 0.5618617021276596
- 0.5600531914893617
- 0.561063829787234
- 0.5605851063829788
- 0.5591489361702128
- 0.5579255319148936
- 0.5580851063829787
- 0.5610106382978723
- 0.5599468085106383
- 0.5642021276595744
- 0.563404255319149
- 0.563936170212766
- 0.5661170212765958
- 0.5685106382978723
- 0.5624468085106383
- 0.5659042553191489
- 0.566063829787234
- 0.5634574468085106
- 0.5645212765957447
- 0.5652659574468085
- 0.5692553191489361
- 0.3841489361702128
- 0.5707446808510638
- 0.5687765957446809
- 0.5687234042553192
- 0.5688829787234042
- 0.5684574468085106
- 0.5725
- 0.5694148936170212
- 0.5712234042553191
- 0.5703191489361702
test_loss_list:
- 3.7693747234344483
- 3.6442592334747315
- 3.3754653835296633
- 3.220084234873454
- 3.1727707227071127
- 3.069994306564331
- 3.065132548014323
- 3.0429114309946694
- 2.9103463459014893
- 2.9556682936350502
- 2.6626430988311767
- 3.2735176563262938
- 2.821534070968628
- 2.6511752160390216
- 2.8818119112650553
- 2.7328865655263264
- 2.9210651365915936
- 2.8743607298533123
- 2.7192213026682537
- 2.7555880387624105
- 3.160365676879883
- 2.7001056766510008
- 2.9207680638631186
- 2.777984568277995
- 2.634279025395711
- 2.569265104929606
- 2.460998837153117
- 2.854721647898356
- 2.518990014394124
- 2.636440528233846
- 2.798185068766276
- 2.5724164899190267
- 3.144201202392578
- 2.497980718612671
- 2.431108932495117
- 2.6219408480326334
- 2.47134627978007
- 2.492295430501302
- 2.461834526062012
- 2.2276067479451496
- 2.1965555795033773
- 2.420481793085734
- 2.731140791575114
- 3.0199735164642334
- 2.595860757827759
- 2.9769049008687336
- 2.9949886194864908
- 2.475047165552775
- 2.498664503097534
- 2.7036554368336994
- 2.7680183474222817
- 2.605882682800293
- 2.4157740879058838
- 2.1843192275365193
- 2.7692999903361004
- 2.678486255009969
- 2.076338987350464
- 2.354605677922567
- 2.23771781762441
- 2.3014441045125325
- 2.4884453773498536
- 2.3941966422398884
- 2.6867822964986163
- 2.9938612747192384
- 2.5964588006337483
- 2.3251042938232422
- 2.4412189388275145
- 2.109093607266744
- 2.556814374923706
- 2.928319667180379
- 2.33425208568573
- 2.3353130769729615
- 2.8420678997039794
- 2.9717702802022297
- 2.440944630304972
- 2.297494618097941
- 2.9993078899383545
- 2.1064490509033202
- 2.305761275291443
- 2.8217221450805665
- 2.28720244884491
- 2.5922032101949055
- 2.0672149499257406
- 2.422239875793457
- 2.51399595896403
- 2.447117986679077
- 2.372286024093628
- 2.507513370513916
- 1.9750788736343383
- 2.2743849261601765
- 2.4841475963592528
- 1.7552505254745483
- 2.190862685839335
- 2.2060985374450683
- 2.066193272272746
- 2.3581905698776247
- 2.201687717437744
- 2.079689860343933
- 2.05727326075236
- 2.0317629909515382
train_accuracy:
- 0.052
- 0.0
- 0.408
- 0.492
- 0.0
- 0.633
- 0.654
- 0.671
- 0.65
- 0.671
- 0.0
- 0.733
- 0.654
- 0.0
- 0.694
- 0.708
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.731
- 0.719
- 0.0
- 0.0
- 0.758
- 0.775
- 0.0
- 0.0
- 0.775
- 0.792
- 0.812
- 0.0
- 0.0
- 0.0
- 0.804
- 0.0
- 0.771
- 0.0
- 0.0
- 0.0
- 0.794
- 0.835
- 0.002
- 0.785
- 0.831
- 0.775
- 0.773
- 0.0
- 0.827
- 0.835
- 0.842
- 0.0
- 0.798
- 0.0
- 0.0
- 0.0
- 0.831
- 0.0
- 0.0
- 0.002
- 0.802
- 0.0
- 0.844
- 0.002
- 0.0
- 0.012
- 0.792
- 0.0
- 0.838
- 0.848
- 0.85
- 0.0
- 0.808
- 0.802
- 0.863
- 0.0
- 0.827
- 0.0
- 0.0
- 0.0
- 0.854
- 0.812
- 0.838
- 0.0
- 0.0
- 0.0
- 0.858
- 0.002
- 0.815
- 0.015
- 0.827
- 0.823
- 0.0
- 0.0
- 0.008
- 0.81
- 0.854
- 0.858
train_loss:
- 1.758
- 2.049
- 2.287
- 2.407
- 2.108
- 1.717
- 1.56
- 1.534
- 1.457
- 1.357
- 0.901
- 1.506
- 1.104
- 0.861
- 1.25
- 1.019
- 1.166
- 1.182
- 0.95
- 0.886
- 1.281
- 0.903
- 1.106
- 1.079
- 0.852
- 0.819
- 0.665
- 1.013
- 0.859
- 0.833
- 0.954
- 0.765
- 1.097
- 0.781
- 0.599
- 0.762
- 0.768
- 0.748
- 0.734
- 0.607
- 0.566
- 0.687
- 0.876
- 1.038
- 0.869
- 1.003
- 1.002
- 0.683
- 0.657
- 0.838
- 0.815
- 0.86
- 0.69
- 0.592
- 0.821
- 0.814
- 0.567
- 0.689
- 0.678
- 0.692
- 0.807
- 0.651
- 0.776
- 0.92
- 0.793
- 0.676
- 0.635
- 0.495
- 0.745
- 0.894
- 0.666
- 0.648
- 0.91
- 0.892
- 0.79
- 0.631
- 0.885
- 0.538
- 0.629
- 0.859
- 0.626
- 0.721
- 0.483
- 0.729
- 0.714
- 0.739
- 0.745
- 0.74
- 0.501
- 0.588
- 0.349
- 0.414
- 0.718
- 0.738
- 0.596
- 0.702
- 0.582
- 0.581
- 0.591
- 0.574
unequal: 0
verbose: 1
