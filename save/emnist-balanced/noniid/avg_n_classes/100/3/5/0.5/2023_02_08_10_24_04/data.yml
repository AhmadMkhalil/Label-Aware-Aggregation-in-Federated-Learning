avg_train_accuracy: 0.85
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027074468085106385
- 0.09324468085106383
- 0.18095744680851064
- 0.2566489361702128
- 0.31367021276595747
- 0.3395744680851064
- 0.36329787234042554
- 0.40537234042553194
- 0.4006382978723404
- 0.4067021276595745
- 0.4147872340425532
- 0.4491489361702128
- 0.43292553191489364
- 0.4440425531914894
- 0.4598404255319149
- 0.46952127659574466
- 0.4634042553191489
- 0.4702659574468085
- 0.4652127659574468
- 0.48601063829787233
- 0.48186170212765955
- 0.48792553191489363
- 0.48734042553191487
- 0.49617021276595746
- 0.48558510638297875
- 0.4920212765957447
- 0.49707446808510636
- 0.503031914893617
- 0.506436170212766
- 0.5111170212765958
- 0.5121808510638298
- 0.506436170212766
- 0.5185106382978724
- 0.5138829787234043
- 0.5261702127659574
- 0.5227127659574468
- 0.5236702127659575
- 0.5247872340425532
- 0.5310106382978723
- 0.5253191489361703
- 0.5270212765957447
- 0.5328191489361702
- 0.5362234042553191
- 0.5373936170212766
- 0.5324468085106383
- 0.5382446808510638
- 0.5282446808510638
- 0.5378723404255319
- 0.5390957446808511
- 0.5422872340425532
- 0.539468085106383
- 0.5415425531914894
- 0.5379787234042553
- 0.5421276595744681
- 0.5443617021276596
- 0.5432978723404255
- 0.5454787234042553
- 0.5464361702127659
- 0.5460106382978723
- 0.5492553191489362
- 0.5470744680851064
- 0.5490957446808511
- 0.5509574468085107
- 0.5518617021276596
- 0.5517553191489362
- 0.5474468085106383
- 0.551968085106383
- 0.55
- 0.5504255319148936
- 0.5553191489361702
- 0.5514361702127659
- 0.5562234042553191
- 0.5590425531914893
- 0.5568085106382978
- 0.5593617021276596
- 0.5576595744680851
- 0.5563297872340426
- 0.5534574468085106
- 0.5581914893617022
- 0.5562765957446808
- 0.5587765957446809
- 0.5582978723404255
- 0.5625
- 0.5600531914893617
- 0.5595212765957447
- 0.5610106382978723
- 0.5590425531914893
- 0.5645212765957447
- 0.563404255319149
- 0.5620744680851064
- 0.5639893617021277
- 0.5645744680851064
- 0.5650531914893617
- 0.5623936170212765
- 0.5672872340425532
- 0.565531914893617
- 0.5633510638297873
- 0.5661702127659575
- 0.5647872340425532
- 0.5627659574468085
test_loss_list:
- 3.8096121088663737
- 3.7699210611979166
- 3.5100221411387125
- 3.2845080057779947
- 3.142309300104777
- 3.077825117111206
- 3.002957811355591
- 3.1674446455637613
- 2.930898202260335
- 2.8835068639119465
- 2.7619712257385256
- 3.043952023188273
- 2.687043380737305
- 2.8626929251352946
- 3.0481959851582845
- 3.077468983332316
- 2.778698142369588
- 2.7939776452382405
- 2.790421485900879
- 3.283498242696126
- 2.976957000096639
- 3.1100865968068443
- 2.945811939239502
- 3.001345993677775
- 2.636948210398356
- 2.804606377283732
- 2.651817979812622
- 2.6727292569478354
- 2.911999438603719
- 2.9220109875996907
- 2.7080926418304445
- 2.551751095453898
- 2.9325809224446613
- 2.6574105167388917
- 3.1314390087127686
- 2.8835361131032307
- 2.6301020971934
- 2.648554004033407
- 3.111709178288778
- 2.576532882054647
- 2.5776452827453613
- 2.519955504735311
- 3.0619985389709474
- 3.093623628616333
- 2.5506658776601157
- 2.873185396194458
- 2.280338939030965
- 2.5300334103902182
- 2.7161446221669516
- 2.703010311126709
- 2.70286519686381
- 2.551297238667806
- 2.273678749402364
- 2.445348571141561
- 2.621606969833374
- 2.5071178531646727
- 2.5069799613952637
- 2.339630808830261
- 2.6945904445648194
- 2.9342534828186033
- 2.6069749641418456
- 2.4239160792032877
- 2.692680117289225
- 2.394589579900106
- 2.413557602564494
- 2.3715864276885985
- 2.5215068531036375
- 2.114860455195109
- 2.2725354480743407
- 2.1074662431081137
- 2.224094338417053
- 2.8123972988128663
- 2.846717087427775
- 2.5644274806976317
- 2.8447591400146486
- 2.5946967728932697
- 2.4692213598887127
- 2.118406531016032
- 2.473326924641927
- 2.2822081677118935
- 2.301487987836202
- 2.2583781067530313
- 2.538278595606486
- 2.3951865800221763
- 2.2840569035212197
- 2.701313616434733
- 2.2252390893300373
- 2.214211619695028
- 2.6997140153249104
- 2.4055957126617433
- 2.504097057978312
- 2.4520232423146564
- 2.2684438673655194
- 2.464083391825358
- 2.237450779279073
- 2.695584405263265
- 2.442723296483358
- 2.3921014340718587
- 2.479571984608968
- 2.008260024388631
train_accuracy:
- 0.046
- 0.14
- 0.0
- 0.39
- 0.456
- 0.0
- 0.596
- 0.61
- 0.588
- 0.596
- 0.638
- 0.69
- 0.0
- 0.0
- 0.0
- 0.694
- 0.0
- 0.0
- 0.0
- 0.721
- 0.713
- 0.0
- 0.737
- 0.752
- 0.0
- 0.746
- 0.0
- 0.0
- 0.76
- 0.0
- 0.0
- 0.767
- 0.0
- 0.0
- 0.79
- 0.798
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.815
- 0.8
- 0.0
- 0.815
- 0.794
- 0.0
- 0.81
- 0.785
- 0.0
- 0.004
- 0.0
- 0.0
- 0.794
- 0.0
- 0.812
- 0.825
- 0.806
- 0.8
- 0.84
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.827
- 0.0
- 0.0
- 0.0
- 0.0
- 0.854
- 0.798
- 0.0
- 0.852
- 0.0
- 0.844
- 0.004
- 0.835
- 0.0
- 0.004
- 0.0
- 0.856
- 0.029
- 0.798
- 0.863
- 0.021
- 0.0
- 0.0
- 0.856
- 0.027
- 0.806
- 0.84
- 0.848
- 0.0
- 0.858
- 0.863
- 0.0
- 0.829
- 0.85
train_loss:
- 1.747
- 2.61
- 1.37
- 1.623
- 1.495
- 1.376
- 1.258
- 1.496
- 1.155
- 0.801
- 0.829
- 1.341
- 0.807
- 1.016
- 1.226
- 1.23
- 0.971
- 0.958
- 0.924
- 1.341
- 1.09
- 1.08
- 1.087
- 1.079
- 0.668
- 0.809
- 0.834
- 0.836
- 0.996
- 0.99
- 0.82
- 0.808
- 0.943
- 0.767
- 1.119
- 0.93
- 0.773
- 0.769
- 1.044
- 0.76
- 0.729
- 0.74
- 1.013
- 1.019
- 0.733
- 0.844
- 0.577
- 0.7
- 0.821
- 0.843
- 0.84
- 0.657
- 0.534
- 0.69
- 0.802
- 0.631
- 0.634
- 0.65
- 0.758
- 0.904
- 0.807
- 0.65
- 0.767
- 0.628
- 0.625
- 0.624
- 0.771
- 0.499
- 0.62
- 0.471
- 0.629
- 0.865
- 0.867
- 0.756
- 0.868
- 0.721
- 0.777
- 0.502
- 0.725
- 0.586
- 0.604
- 0.592
- 0.698
- 0.751
- 0.575
- 0.856
- 0.596
- 0.599
- 0.826
- 0.722
- 0.708
- 0.715
- 0.588
- 0.697
- 0.564
- 0.813
- 0.694
- 0.698
- 0.677
- 0.467
unequal: 0
verbose: 1
