avg_train_accuracy: 0.006
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.031861702127659576
- 0.0973404255319149
- 0.21202127659574468
- 0.29569148936170214
- 0.34377659574468084
- 0.38611702127659575
- 0.41393617021276596
- 0.4195212765957447
- 0.42404255319148937
- 0.43361702127659574
- 0.44382978723404254
- 0.45
- 0.45420212765957446
- 0.46664893617021275
- 0.4728723404255319
- 0.48143617021276597
- 0.4800531914893617
- 0.4882446808510638
- 0.4901595744680851
- 0.49696808510638296
- 0.49351063829787234
- 0.49632978723404253
- 0.5020212765957447
- 0.5082446808510638
- 0.505531914893617
- 0.5101063829787233
- 0.5142553191489362
- 0.5161702127659574
- 0.5133510638297872
- 0.5213829787234042
- 0.5196808510638298
- 0.5246276595744681
- 0.5213297872340426
- 0.5296808510638298
- 0.528031914893617
- 0.5330851063829787
- 0.5334574468085106
- 0.5356914893617021
- 0.5437234042553192
- 0.5395744680851063
- 0.5418085106382978
- 0.5428191489361702
- 0.5375
- 0.5428191489361702
- 0.5427659574468086
- 0.5487765957446809
- 0.5476595744680851
- 0.5476063829787234
- 0.5499468085106383
- 0.5497872340425531
- 0.5487234042553192
- 0.548936170212766
- 0.5515425531914894
- 0.5511702127659575
- 0.5486170212765957
- 0.554468085106383
- 0.5556382978723404
- 0.5560106382978723
- 0.5543617021276596
- 0.5552127659574468
- 0.5575
- 0.5530851063829787
- 0.5561702127659575
- 0.558936170212766
- 0.5577659574468085
- 0.5612765957446808
- 0.5610106382978723
- 0.5570744680851064
- 0.558031914893617
- 0.5584574468085106
- 0.5576595744680851
- 0.5577127659574468
- 0.5618617021276596
- 0.5630851063829787
- 0.5600531914893617
- 0.5638829787234042
- 0.5624468085106383
- 0.5669148936170213
- 0.5617553191489362
- 0.5628723404255319
- 0.5662234042553191
- 0.5648404255319149
- 0.5613829787234043
- 0.5657446808510638
- 0.5620744680851064
- 0.5652659574468085
- 0.5664893617021277
- 0.5648404255319149
- 0.5673404255319149
- 0.5698936170212766
- 0.5670744680851064
- 0.5697340425531915
- 0.5736170212765958
- 0.5678723404255319
- 0.5711702127659575
- 0.5776063829787234
- 0.5736702127659574
- 0.5707446808510638
- 0.5709042553191489
- 0.5740425531914893
test_loss_list:
- 3.8140400950113933
- 3.8229834461212158
- 3.633486213684082
- 3.3439724985758463
- 3.177208801905314
- 3.1059562873840334
- 3.2716382948557534
- 3.0122883129119873
- 2.900354461669922
- 2.8902088451385497
- 2.851324186325073
- 2.7653596274058025
- 2.804907080332438
- 2.7825676568349205
- 3.0126220194498696
- 2.9573559379577636
- 2.777799123128255
- 2.937574812571208
- 2.8862291781107583
- 2.958728173573812
- 2.6775872198740642
- 2.5696919759114585
- 2.6233545684814454
- 2.838283141454061
- 2.633685935338338
- 2.843515691757202
- 2.889055404663086
- 2.7960472202301023
- 2.6231211694081624
- 2.8301754347483317
- 2.585828234354655
- 2.5402477995554604
- 2.4091989326477052
- 2.7059394931793213
- 2.4651602013905842
- 2.768102099100749
- 2.4886837927500407
- 2.7445449002583824
- 3.0089000447591148
- 2.4212467193603517
- 2.487293841044108
- 2.7283836046854657
- 2.440925677617391
- 2.751750793457031
- 2.407925392786662
- 2.6701113478342693
- 2.637629238764445
- 2.241701800028483
- 2.9400537713368733
- 2.1912886619567873
- 2.653610232671102
- 2.6658027172088623
- 2.3934983094533284
- 2.1401536242167154
- 2.607362305323283
- 2.5192323875427247
- 2.6408561102549233
- 2.675037810007731
- 2.625586887995402
- 2.393114172617594
- 2.3724903202056886
- 2.3631007925669354
- 2.657136189142863
- 2.571495812733968
- 2.551508728663127
- 2.618867422739665
- 2.2621917978922528
- 2.466959031422933
- 2.2579464546839394
- 2.4898702239990236
- 2.5093811066945393
- 2.23538401444753
- 2.8135479482014976
- 2.22688790957133
- 2.2600540335973105
- 2.259125550587972
- 2.408758544921875
- 2.4916575463612873
- 2.4199362881978352
- 2.471538028717041
- 2.7992121251424154
- 2.2359718815485636
- 2.274005823135376
- 2.8017109044392905
- 2.20082337697347
- 2.2490859858194985
- 2.2051964600880942
- 2.3931222502390543
- 2.164455895423889
- 2.1628077840805053
- 2.145241519610087
- 1.9357324997584024
- 2.141564350128174
- 2.200406537055969
- 2.1159775972366335
- 1.9077059459686279
- 2.0481830056508383
- 2.587113536198934
- 2.3476637013753257
- 2.1115685907999673
train_accuracy:
- 0.0
- 0.144
- 0.0
- 0.0
- 0.537
- 0.535
- 0.575
- 0.592
- 0.0
- 0.0
- 0.0
- 0.692
- 0.652
- 0.0
- 0.0
- 0.713
- 0.698
- 0.0
- 0.0
- 0.733
- 0.729
- 0.725
- 0.754
- 0.0
- 0.0
- 0.748
- 0.0
- 0.779
- 0.0
- 0.771
- 0.0
- 0.779
- 0.0
- 0.775
- 0.0
- 0.0
- 0.002
- 0.781
- 0.806
- 0.0
- 0.794
- 0.806
- 0.0
- 0.0
- 0.792
- 0.0
- 0.0
- 0.0
- 0.825
- 0.006
- 0.0
- 0.0
- 0.0
- 0.0
- 0.779
- 0.79
- 0.79
- 0.808
- 0.8
- 0.783
- 0.823
- 0.0
- 0.0
- 0.812
- 0.0
- 0.002
- 0.804
- 0.804
- 0.798
- 0.817
- 0.0
- 0.0
- 0.835
- 0.819
- 0.819
- 0.0
- 0.0
- 0.004
- 0.842
- 0.827
- 0.833
- 0.838
- 0.815
- 0.823
- 0.0
- 0.004
- 0.802
- 0.0
- 0.0
- 0.012
- 0.794
- 0.0
- 0.829
- 0.833
- 0.0
- 0.0
- 0.0
- 0.844
- 0.0
- 0.006
train_loss:
- 2.843
- 2.615
- 2.43
- 1.657
- 1.437
- 1.697
- 1.903
- 1.491
- 1.154
- 1.074
- 1.046
- 1.041
- 1.014
- 0.974
- 1.213
- 1.185
- 0.938
- 1.108
- 1.114
- 1.079
- 0.914
- 0.654
- 0.84
- 1.025
- 0.832
- 0.99
- 0.989
- 0.98
- 0.811
- 0.933
- 0.776
- 0.754
- 0.578
- 0.926
- 0.765
- 0.884
- 0.726
- 0.904
- 1.053
- 0.715
- 0.685
- 0.86
- 0.711
- 0.824
- 0.678
- 0.826
- 0.84
- 0.544
- 0.996
- 0.514
- 0.842
- 0.817
- 0.654
- 0.497
- 0.795
- 0.799
- 0.776
- 0.778
- 0.793
- 0.622
- 0.652
- 0.62
- 0.772
- 0.765
- 0.779
- 0.764
- 0.628
- 0.771
- 0.622
- 0.77
- 0.753
- 0.616
- 0.888
- 0.625
- 0.596
- 0.618
- 0.755
- 0.734
- 0.747
- 0.728
- 0.864
- 0.594
- 0.602
- 0.869
- 0.613
- 0.593
- 0.593
- 0.714
- 0.595
- 0.569
- 0.586
- 0.439
- 0.56
- 0.567
- 0.563
- 0.419
- 0.556
- 0.846
- 0.716
- 0.558
unequal: 0
verbose: 1
