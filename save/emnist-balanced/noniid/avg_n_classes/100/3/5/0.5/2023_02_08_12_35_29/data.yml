avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03335106382978723
- 0.0850531914893617
- 0.2323936170212766
- 0.31898936170212766
- 0.35888297872340424
- 0.4039893617021277
- 0.4127127659574468
- 0.423936170212766
- 0.4398404255319149
- 0.446063829787234
- 0.4622340425531915
- 0.46606382978723404
- 0.4725531914893617
- 0.4729255319148936
- 0.4794148936170213
- 0.48106382978723405
- 0.49186170212765956
- 0.4821808510638298
- 0.5013829787234042
- 0.49882978723404253
- 0.4940425531914894
- 0.506968085106383
- 0.5091489361702127
- 0.5075
- 0.5112234042553192
- 0.5134042553191489
- 0.513563829787234
- 0.5231382978723405
- 0.5251063829787234
- 0.5278191489361702
- 0.5255851063829787
- 0.5259574468085106
- 0.5247872340425532
- 0.5312765957446809
- 0.5355851063829787
- 0.5372872340425532
- 0.5350531914893617
- 0.5340425531914894
- 0.5347872340425532
- 0.536063829787234
- 0.5413297872340426
- 0.5451595744680852
- 0.5451595744680852
- 0.5479255319148936
- 0.5417021276595745
- 0.5454255319148936
- 0.5484574468085106
- 0.545372340425532
- 0.5502127659574468
- 0.550159574468085
- 0.5491489361702128
- 0.5520744680851064
- 0.5426595744680851
- 0.5508510638297872
- 0.551595744680851
- 0.5528723404255319
- 0.5525
- 0.5544148936170212
- 0.555
- 0.5525
- 0.556063829787234
- 0.558404255319149
- 0.5580851063829787
- 0.5552659574468085
- 0.5569148936170213
- 0.5590425531914893
- 0.5561170212765958
- 0.5609574468085107
- 0.5575
- 0.5647340425531915
- 0.5602127659574468
- 0.5533510638297873
- 0.560372340425532
- 0.5628723404255319
- 0.5625
- 0.5549468085106383
- 0.5653723404255319
- 0.5618617021276596
- 0.5633510638297873
- 0.5654787234042553
- 0.5619148936170213
- 0.5549468085106383
- 0.5636702127659574
- 0.5648936170212766
- 0.5661170212765958
- 0.5689893617021277
- 0.5614361702127659
- 0.5664893617021277
- 0.564468085106383
- 0.5688297872340425
- 0.5703191489361702
- 0.5681914893617022
- 0.5664361702127659
- 0.5706914893617021
- 0.5720212765957446
- 0.5649468085106383
- 0.5656914893617021
- 0.5718085106382979
- 0.5690957446808511
- 0.5728191489361703
test_loss_list:
- 3.7787673060099283
- 3.7136323738098143
- 3.484442882537842
- 3.2136598777770997
- 3.0707640647888184
- 3.0865654023488363
- 2.88287678082784
- 2.8803780555725096
- 2.9686885674794516
- 2.835093847910563
- 3.101145782470703
- 3.023264989852905
- 2.980273084640503
- 2.729849519729614
- 2.8628382364908855
- 2.7263302357991535
- 2.9487120660146076
- 2.5559270509084064
- 3.2127758502960204
- 3.006230586369832
- 2.546644716262817
- 2.863120101292928
- 2.9226128832499185
- 2.769295129776001
- 2.623016455968221
- 2.8052720069885253
- 2.551335271199544
- 3.0383322874705
- 2.6722548898061116
- 2.8330176067352295
- 2.6910798263549807
- 2.751000696818034
- 2.539854571024577
- 2.68538657506307
- 2.749104026158651
- 2.806173359553019
- 2.5749606386820476
- 2.435684150060018
- 2.4650157356262206
- 2.438095242182414
- 2.641066102981567
- 2.696909437179565
- 2.680799655914307
- 2.990999870300293
- 2.6090790875752767
- 2.7377972984313965
- 2.7116065343221027
- 2.58609255472819
- 2.6889773178100587
- 2.65043142636617
- 2.7110907077789306
- 2.672240651448568
- 2.361329126358032
- 2.57806910832723
- 2.5771687761942546
- 2.6011451498667397
- 2.42570219039917
- 2.3656112798055013
- 2.4004699325561525
- 2.2813732624053955
- 2.2689308452606203
- 2.6055998675028484
- 2.499081182479858
- 2.225026439030965
- 2.4705886681874594
- 2.325697196324666
- 2.220944054921468
- 2.496218687693278
- 2.2625035079320273
- 2.7919908142089844
- 2.5151347637176515
- 2.2179531621932984
- 2.696828908920288
- 2.84960205078125
- 2.5293523852030435
- 2.2473526318868
- 2.262712295850118
- 2.1981228590011597
- 2.2871106100082397
- 2.424702599843343
- 2.237201126416524
- 1.9845875724156699
- 2.382371679941813
- 2.4132830174763997
- 2.342925690015157
- 2.7702501424153647
- 2.102734537124634
- 2.444305528004964
- 1.9811674642562866
- 2.1783962694803876
- 2.3743046776453656
- 2.145111462275187
- 2.3098755915959677
- 2.3988045692443847
- 2.179087076187134
- 2.319729231198629
- 1.9267729584376017
- 2.1591285848617554
- 2.1344702021280924
- 2.2284595282872517
train_accuracy:
- 0.0
- 0.125
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.606
- 0.683
- 0.652
- 0.667
- 0.667
- 0.0
- 0.679
- 0.0
- 0.758
- 0.0
- 0.756
- 0.0
- 0.0
- 0.0
- 0.733
- 0.0
- 0.0
- 0.798
- 0.0
- 0.74
- 0.0
- 0.0
- 0.754
- 0.81
- 0.0
- 0.773
- 0.779
- 0.781
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.792
- 0.829
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.833
- 0.827
- 0.0
- 0.0
- 0.0
- 0.844
- 0.0
- 0.0
- 0.0
- 0.825
- 0.819
- 0.0
- 0.844
- 0.0
- 0.833
- 0.835
- 0.84
- 0.0
- 0.854
- 0.827
- 0.0
- 0.825
- 0.0
- 0.808
- 0.0
- 0.8
- 0.0
- 0.827
- 0.806
- 0.823
- 0.819
- 0.0
- 0.0
- 0.852
- 0.821
- 0.825
- 0.002
- 0.0
- 0.819
- 0.817
- 0.838
- 0.017
- 0.844
- 0.808
- 0.0
train_loss:
- 1.747
- 2.108
- 1.878
- 1.64
- 1.424
- 1.627
- 1.274
- 1.189
- 1.385
- 1.142
- 1.562
- 1.291
- 1.221
- 1.024
- 1.191
- 0.968
- 1.129
- 0.759
- 1.279
- 1.084
- 0.692
- 1.075
- 1.035
- 0.843
- 0.849
- 0.988
- 0.834
- 1.143
- 0.822
- 0.928
- 0.933
- 0.958
- 0.765
- 0.925
- 0.877
- 0.904
- 0.727
- 0.757
- 0.741
- 0.707
- 0.869
- 0.862
- 0.856
- 0.985
- 0.877
- 0.833
- 0.814
- 0.862
- 0.85
- 0.812
- 0.785
- 0.827
- 0.7
- 0.811
- 0.8
- 0.789
- 0.693
- 0.683
- 0.647
- 0.672
- 0.635
- 0.754
- 0.785
- 0.642
- 0.762
- 0.643
- 0.619
- 0.775
- 0.642
- 0.871
- 0.754
- 0.645
- 0.878
- 0.843
- 0.746
- 0.65
- 0.611
- 0.632
- 0.634
- 0.744
- 0.612
- 0.496
- 0.716
- 0.709
- 0.709
- 0.839
- 0.647
- 0.697
- 0.49
- 0.576
- 0.715
- 0.601
- 0.709
- 0.709
- 0.593
- 0.72
- 0.489
- 0.571
- 0.585
- 0.704
unequal: 0
verbose: 1
