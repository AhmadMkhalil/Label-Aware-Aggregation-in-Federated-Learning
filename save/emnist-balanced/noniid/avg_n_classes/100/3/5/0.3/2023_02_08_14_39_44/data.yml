avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05617021276595745
- 0.1250531914893617
- 0.21654255319148935
- 0.2622872340425532
- 0.36377659574468085
- 0.41473404255319146
- 0.433936170212766
- 0.42861702127659573
- 0.45393617021276594
- 0.45340425531914896
- 0.46930851063829787
- 0.4671808510638298
- 0.4804787234042553
- 0.4888297872340426
- 0.49361702127659574
- 0.49867021276595747
- 0.501968085106383
- 0.5081914893617021
- 0.5087234042553191
- 0.5113297872340425
- 0.5142021276595745
- 0.5108510638297873
- 0.5184574468085107
- 0.5129255319148937
- 0.2173404255319149
- 0.5222340425531915
- 0.518031914893617
- 0.5191489361702127
- 0.5262765957446809
- 0.5273936170212766
- 0.5320744680851064
- 0.5293085106382979
- 0.5348936170212766
- 0.5348936170212766
- 0.5393617021276595
- 0.536063829787234
- 0.5375531914893616
- 0.5415425531914894
- 0.24382978723404256
- 0.5407446808510639
- 0.5406914893617021
- 0.30606382978723407
- 0.2425531914893617
- 0.5416489361702128
- 0.546968085106383
- 0.31824468085106383
- 0.5535638297872341
- 0.5505851063829788
- 0.5509042553191489
- 0.551595744680851
- 0.5515425531914894
- 0.5531914893617021
- 0.5516489361702127
- 0.5478723404255319
- 0.5491489361702128
- 0.5488829787234043
- 0.5523936170212767
- 0.5550531914893617
- 0.5550531914893617
- 0.5572872340425532
- 0.5557446808510639
- 0.5528723404255319
- 0.5578191489361702
- 0.5582446808510638
- 0.5593617021276596
- 0.5609574468085107
- 0.5609042553191489
- 0.5596808510638298
- 0.5630851063829787
- 0.5620744680851064
- 0.4346808510638298
- 0.5604787234042553
- 0.5621276595744681
- 0.5620212765957446
- 0.5614361702127659
- 0.5663297872340426
- 0.5602659574468085
- 0.5601063829787234
- 0.5647872340425532
- 0.5669148936170213
- 0.5633510638297873
- 0.5628191489361702
- 0.5641489361702128
- 0.5620744680851064
- 0.5695212765957447
- 0.5667553191489362
- 0.5687765957446809
- 0.5668085106382978
- 0.5675
- 0.4676063829787234
- 0.5663829787234043
- 0.5690425531914893
- 0.5688297872340425
- 0.568031914893617
- 0.5680851063829787
- 0.5657446808510638
- 0.569627659574468
- 0.5698404255319149
- 0.5663297872340426
- 0.568936170212766
test_loss_list:
- 3.7860257879892987
- 3.7529749329884847
- 3.5419993591308594
- 3.3513322194417317
- 3.1433869870503743
- 3.3717422167460125
- 3.4331863816579182
- 3.129038308461507
- 3.233916772206624
- 3.011843007405599
- 3.284581054051717
- 3.0715341981252036
- 3.2374311606089274
- 3.3068574492136635
- 3.3410685857137046
- 3.3430243142445883
- 3.376835584640503
- 3.8390219084421795
- 3.35599227587382
- 3.4183403809865314
- 3.4539446099599203
- 3.0811384042104084
- 3.421602169672648
- 3.0080853525797524
- 3.4134309101104736
- 2.721926472981771
- 2.746938298543294
- 2.8160659154256185
- 3.0941789722442627
- 2.8447591813405353
- 3.1501050186157227
- 2.849436807632446
- 3.0969527626037596
- 2.9508367824554442
- 3.0757311312357585
- 2.9455405775705974
- 2.8260939725240073
- 3.1262300395965577
- 3.4144413312276205
- 2.6367590777079264
- 2.8541238339742026
- 2.7995764191945396
- 3.175317538579305
- 2.342479254404704
- 2.6832276312510173
- 2.972951520284017
- 2.4295376110076905
- 2.7023319594065347
- 2.7650293350219726
- 2.840366217295329
- 2.756852626800537
- 3.200411907831828
- 2.9532707595825194
- 2.674924774169922
- 2.711396191914876
- 2.585937433242798
- 2.8006674226125083
- 2.746843767166138
- 2.781621227264404
- 2.8372919305165607
- 2.599999087651571
- 2.494737917582194
- 2.809928919474284
- 2.888316650390625
- 2.798681516647339
- 2.7730179437001548
- 2.8773080253601075
- 2.5573792775472004
- 2.871740074157715
- 2.886531489690145
- 1.916423069636027
- 2.293279781341553
- 2.528666674296061
- 2.3328306913375854
- 2.57910285949707
- 2.5711044597625734
- 2.340739189783732
- 2.355096238454183
- 2.665275847117106
- 2.65505451520284
- 2.4046061579386393
- 2.2720715459187826
- 2.381927712758382
- 2.3482450501124066
- 2.86303674697876
- 2.6269802983601886
- 2.658059139251709
- 2.44624036471049
- 2.5078469467163087
- 1.9258603620529176
- 1.9179442358016967
- 2.212307653427124
- 2.2231436411539716
- 2.2295055262247723
- 2.688006664911906
- 2.1641209157307943
- 2.4831672064463297
- 2.4826205285390217
- 2.3614982732137046
- 2.2181129471460976
train_accuracy:
- 0.079
- 0.0
- 0.31
- 0.0
- 0.0
- 0.596
- 0.642
- 0.0
- 0.0
- 0.669
- 0.721
- 0.0
- 0.744
- 0.0
- 0.763
- 0.744
- 0.721
- 0.708
- 0.735
- 0.748
- 0.0
- 0.752
- 0.76
- 0.798
- 0.0
- 0.725
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.794
- 0.756
- 0.0
- 0.0
- 0.0
- 0.8
- 0.067
- 0.815
- 0.0
- 0.527
- 0.91
- 0.76
- 0.0
- 0.858
- 0.01
- 0.783
- 0.821
- 0.827
- 0.0
- 0.815
- 0.0
- 0.0
- 0.798
- 0.004
- 0.0
- 0.829
- 0.823
- 0.796
- 0.0
- 0.79
- 0.825
- 0.825
- 0.819
- 0.838
- 0.0
- 0.0
- 0.821
- 0.831
- 0.763
- 0.829
- 0.0
- 0.0
- 0.85
- 0.0
- 0.821
- 0.838
- 0.842
- 0.0
- 0.0
- 0.823
- 0.846
- 0.002
- 0.852
- 0.815
- 0.854
- 0.0
- 0.004
- 0.91
- 0.84
- 0.0
- 0.0
- 0.0
- 0.856
- 0.831
- 0.827
- 0.821
- 0.842
- 0.0
train_loss:
- 3.798
- 2.031
- 2.536
- 1.53
- 1.395
- 2.303
- 2.113
- 1.158
- 1.494
- 1.134
- 1.351
- 0.987
- 1.312
- 1.301
- 1.234
- 1.264
- 1.211
- 1.454
- 1.157
- 1.128
- 1.131
- 0.831
- 1.097
- 0.959
- 0.528
- 1.141
- 0.868
- 0.749
- 0.99
- 0.711
- 0.93
- 0.704
- 1.077
- 0.738
- 0.947
- 0.725
- 0.67
- 0.9
- 0.425
- 1.055
- 0.91
- 0.521
- 0.359
- 1.024
- 0.883
- 0.398
- 0.931
- 0.857
- 0.86
- 0.859
- 0.868
- 1.075
- 0.851
- 0.591
- 0.59
- 0.551
- 0.841
- 0.846
- 0.827
- 0.834
- 0.664
- 0.634
- 0.85
- 0.797
- 0.794
- 0.872
- 0.813
- 0.579
- 0.804
- 0.771
- 0.413
- 0.845
- 0.777
- 0.56
- 0.775
- 0.763
- 0.613
- 0.536
- 0.753
- 0.768
- 0.541
- 0.592
- 0.504
- 0.591
- 0.968
- 0.756
- 0.731
- 0.528
- 0.516
- 0.339
- 0.609
- 0.491
- 0.572
- 0.516
- 0.941
- 0.576
- 0.729
- 0.712
- 0.502
- 0.492
unequal: 0
verbose: 1
