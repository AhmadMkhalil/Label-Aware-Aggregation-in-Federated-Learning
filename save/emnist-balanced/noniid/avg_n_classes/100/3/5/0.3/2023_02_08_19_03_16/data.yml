avg_train_accuracy: 0.858
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.019202127659574467
- 0.04329787234042553
- 0.06340425531914894
- 0.1422340425531915
- 0.2528723404255319
- 0.06643617021276596
- 0.3109574468085106
- 0.3497872340425532
- 0.38904255319148934
- 0.39691489361702126
- 0.4149468085106383
- 0.4223404255319149
- 0.43425531914893617
- 0.43898936170212766
- 0.4419148936170213
- 0.46202127659574466
- 0.4700531914893617
- 0.47845744680851066
- 0.4772872340425532
- 0.4853723404255319
- 0.4836170212765957
- 0.4899468085106383
- 0.49446808510638296
- 0.49632978723404253
- 0.4958510638297872
- 0.49957446808510636
- 0.5131914893617021
- 0.5117553191489361
- 0.5039361702127659
- 0.5162234042553191
- 0.5098936170212766
- 0.5145212765957446
- 0.5173404255319148
- 0.5162234042553191
- 0.5209574468085106
- 0.515904255319149
- 0.5185106382978724
- 0.5221808510638298
- 0.3012234042553191
- 0.5286702127659575
- 0.5256382978723404
- 0.5324468085106383
- 0.5347872340425532
- 0.533563829787234
- 0.5401595744680852
- 0.5318085106382979
- 0.535904255319149
- 0.5345212765957447
- 0.5387765957446808
- 0.5369148936170213
- 0.5463297872340426
- 0.5445744680851063
- 0.5448404255319149
- 0.5394148936170213
- 0.5488297872340425
- 0.550159574468085
- 0.5448936170212766
- 0.550531914893617
- 0.550159574468085
- 0.5461702127659575
- 0.551968085106383
- 0.551063829787234
- 0.5489893617021276
- 0.5542021276595744
- 0.3401595744680851
- 0.5517021276595745
- 0.5556914893617021
- 0.4233510638297872
- 0.5622872340425532
- 0.551968085106383
- 0.5549468085106383
- 0.5583510638297873
- 0.5572340425531915
- 0.5582978723404255
- 0.5587765957446809
- 0.5586702127659574
- 0.5561702127659575
- 0.5618617021276596
- 0.5609574468085107
- 0.5639893617021277
- 0.5625
- 0.5621276595744681
- 0.5665425531914894
- 0.5629787234042554
- 0.5587765957446809
- 0.5625
- 0.5635106382978723
- 0.5597340425531915
- 0.5656914893617021
- 0.5669148936170213
- 0.564627659574468
- 0.5609042553191489
- 0.5600531914893617
- 0.4225
- 0.563031914893617
- 0.5636702127659574
- 0.5656382978723404
- 0.5679255319148936
- 0.5608510638297872
- 0.5683510638297873
test_loss_list:
- 3.8152566973368325
- 3.8279977639516196
- 4.738161582946777
- 3.581560354232788
- 3.4265969308217366
- 5.702337023417155
- 3.2439955043792725
- 3.4519174607594807
- 3.412355298995972
- 3.104937267303467
- 3.371516399383545
- 3.205999298095703
- 2.9851246738433836
- 3.055287233988444
- 3.001041603088379
- 3.003074131011963
- 3.2089380105336507
- 3.3089261563618977
- 3.281370226542155
- 3.294821278254191
- 3.026376972198486
- 3.134482103983561
- 3.403235101699829
- 3.237501122156779
- 3.0835094833374024
- 3.0906213919321694
- 3.667613353729248
- 3.7868781312306723
- 3.148253574371338
- 3.6979088592529297
- 3.039081646601359
- 3.358867120742798
- 3.385453503926595
- 2.9777639579772948
- 3.4340152676900226
- 2.9834076372782388
- 3.1189058113098143
- 2.9818122577667237
- 2.61737286567688
- 2.941834700902303
- 2.6754353046417236
- 2.9187546253204344
- 3.4521887079874674
- 3.081312503814697
- 3.3511021010080975
- 3.023190288543701
- 2.8361255327860513
- 2.8814871215820315
- 2.93879843711853
- 2.943102232615153
- 3.0791735363006594
- 3.143344758351644
- 3.5836725076039633
- 2.997565943400065
- 2.8634774843851725
- 2.8394783624013265
- 2.8426051425933836
- 3.1146851634979247
- 3.158649272918701
- 2.9496253554026284
- 3.0660586579640707
- 2.871549898783366
- 2.924853982925415
- 3.2372324307759603
- 2.7658897749582927
- 2.394576864242554
- 2.7461573950449627
- 2.0855373684565226
- 2.401508804957072
- 2.4164699045817057
- 2.473068784077962
- 2.569482742945353
- 2.8548162523905436
- 2.8363291962941486
- 2.933259115219116
- 3.021545426050822
- 2.877963088353475
- 3.0455807622273765
- 2.6411103947957355
- 2.6050745646158853
- 3.3549325211842853
- 2.987448428471883
- 3.405471398035685
- 3.0495280742645265
- 2.7317614618937176
- 2.643578681945801
- 2.6523326873779296
- 2.5792228476206462
- 2.9872758134206134
- 2.986588780085246
- 2.9240393892923993
- 2.618068742752075
- 2.679459311167399
- 2.3866608778635663
- 2.5043859163920086
- 2.699001474380493
- 2.571209497451782
- 3.127039162317912
- 2.6085215918223064
- 2.852245604197184
train_accuracy:
- 0.0
- 0.062
- 0.0
- 0.0
- 0.0
- 0.479
- 0.0
- 0.529
- 0.0
- 0.0
- 0.621
- 0.0
- 0.0
- 0.0
- 0.0
- 0.694
- 0.702
- 0.704
- 0.0
- 0.0
- 0.723
- 0.0
- 0.752
- 0.0
- 0.727
- 0.737
- 0.746
- 0.781
- 0.0
- 0.744
- 0.0
- 0.0
- 0.763
- 0.0
- 0.777
- 0.0
- 0.0
- 0.775
- 0.74
- 0.771
- 0.758
- 0.777
- 0.781
- 0.796
- 0.787
- 0.777
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.798
- 0.802
- 0.0
- 0.0
- 0.0
- 0.815
- 0.79
- 0.808
- 0.0
- 0.831
- 0.0
- 0.0
- 0.808
- 0.963
- 0.0
- 0.0
- 0.856
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.823
- 0.825
- 0.838
- 0.833
- 0.0
- 0.842
- 0.829
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.84
- 0.725
- 0.0
- 0.823
- 0.0
- 0.827
- 0.0
- 0.858
train_loss:
- 2.245
- 2.946
- 1.14
- 1.638
- 1.509
- 0.66
- 1.331
- 1.846
- 1.715
- 1.105
- 1.58
- 1.012
- 1.038
- 0.961
- 0.986
- 0.906
- 1.345
- 1.297
- 1.272
- 1.302
- 0.893
- 0.847
- 1.173
- 1.165
- 0.848
- 0.822
- 1.452
- 1.412
- 0.793
- 1.374
- 0.847
- 1.156
- 1.071
- 0.808
- 1.015
- 0.824
- 0.739
- 0.753
- 0.514
- 1.464
- 0.714
- 0.995
- 1.25
- 0.993
- 0.951
- 0.692
- 0.747
- 0.698
- 0.691
- 0.67
- 0.931
- 0.879
- 1.145
- 0.658
- 0.692
- 0.671
- 0.651
- 0.915
- 0.889
- 0.668
- 0.869
- 0.619
- 0.62
- 0.807
- 0.414
- 0.694
- 0.56
- 0.383
- 0.548
- 0.629
- 0.583
- 0.597
- 0.82
- 0.825
- 0.81
- 0.784
- 0.834
- 0.78
- 0.622
- 0.601
- 0.988
- 0.821
- 0.982
- 0.785
- 0.62
- 0.586
- 0.596
- 0.572
- 0.772
- 0.778
- 0.75
- 0.556
- 0.544
- 0.396
- 0.813
- 0.753
- 0.563
- 0.934
- 0.591
- 0.753
unequal: 0
verbose: 1
