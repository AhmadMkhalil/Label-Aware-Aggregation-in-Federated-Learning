avg_train_accuracy: 0.854
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05611702127659574
- 0.17659574468085107
- 0.2842021276595745
- 0.3447340425531915
- 0.39085106382978724
- 0.4010106382978723
- 0.4270744680851064
- 0.4326595744680851
- 0.4423936170212766
- 0.4570744680851064
- 0.46101063829787237
- 0.4620744680851064
- 0.4765957446808511
- 0.48058510638297874
- 0.484468085106383
- 0.48851063829787233
- 0.4812234042553192
- 0.5017021276595744
- 0.5011702127659574
- 0.5056382978723404
- 0.5090425531914894
- 0.5038297872340426
- 0.5143617021276595
- 0.5144148936170213
- 0.2567553191489362
- 0.5166489361702128
- 0.515
- 0.5192553191489362
- 0.5165425531914893
- 0.5269680851063829
- 0.5194148936170213
- 0.5263829787234042
- 0.5297872340425532
- 0.5352127659574468
- 0.5353191489361702
- 0.5351595744680852
- 0.5392021276595744
- 0.5303723404255319
- 0.5391489361702128
- 0.5375
- 0.5356914893617021
- 0.5424468085106383
- 0.5429255319148936
- 0.5423936170212766
- 0.5435106382978724
- 0.5490425531914893
- 0.5446808510638298
- 0.5440957446808511
- 0.5501063829787234
- 0.3191489361702128
- 0.5494148936170212
- 0.5472872340425532
- 0.3450531914893617
- 0.5563829787234043
- 0.5568617021276596
- 0.5579255319148936
- 0.5575
- 0.5599468085106383
- 0.5538829787234043
- 0.5529787234042554
- 0.5542021276595744
- 0.5632446808510638
- 0.5551063829787234
- 0.5549468085106383
- 0.5589893617021277
- 0.5545744680851064
- 0.5577127659574468
- 0.5570744680851064
- 0.5604787234042553
- 0.5612234042553191
- 0.5606914893617021
- 0.5607978723404256
- 0.5595212765957447
- 0.5578191489361702
- 0.3346276595744681
- 0.5596808510638298
- 0.5645744680851064
- 0.5628191489361702
- 0.4043617021276596
- 0.5681382978723404
- 0.5674468085106383
- 0.4378723404255319
- 0.5737234042553192
- 0.5743617021276596
- 0.566595744680851
- 0.5648936170212766
- 0.5661702127659575
- 0.5662234042553191
- 0.5676063829787235
- 0.5660106382978723
- 0.5648936170212766
- 0.5648404255319149
- 0.4328723404255319
- 0.5670744680851064
- 0.5659042553191489
- 0.5690425531914893
- 0.4492553191489362
- 0.5663829787234043
- 0.5709574468085107
- 0.5685638297872341
test_loss_list:
- 3.7555097707112632
- 3.5872628911336264
- 3.3796626281738282
- 3.3044454669952392
- 3.4300546646118164
- 3.2899532254536945
- 3.548665885925293
- 3.44543270111084
- 3.5059963766733806
- 3.3772522989908853
- 3.4639218775431315
- 3.2788053925832115
- 3.4730023256937663
- 3.470672025680542
- 3.49556360244751
- 3.5387586085001628
- 3.063951317469279
- 3.840872990290324
- 3.434578768412272
- 3.4400499375661213
- 3.4733135668436685
- 3.1373909250895182
- 3.5221622435251874
- 3.1339785130818685
- 2.820918712615967
- 2.9158148129781085
- 2.7824603080749513
- 2.9644291019439697
- 2.8943726666768392
- 3.090680694580078
- 2.870496400197347
- 2.8939786847432454
- 3.2168166923522947
- 3.593788267771403
- 3.2568743801116944
- 3.2602583980560302
- 3.720281581878662
- 2.8871131070454914
- 2.9886398760477704
- 2.84359437306722
- 2.837894229888916
- 3.159854981104533
- 3.2076852162679037
- 3.27394775390625
- 2.772382599512736
- 3.1575033219655353
- 2.87728128751119
- 2.7593198235829672
- 3.5032921981811525
- 2.613088143666585
- 2.5091407267252603
- 2.506124620437622
- 2.4974485047658286
- 2.6211358388264974
- 2.6014036814371746
- 2.6210350036621093
- 2.911563205718994
- 2.670012067159017
- 2.819071111679077
- 2.590660266876221
- 2.7678430875142417
- 2.6502330684661866
- 2.903184102376302
- 2.6073000049591064
- 2.929729560216268
- 2.5470976384480792
- 2.82408327738444
- 2.6563686656951906
- 3.202715202967326
- 2.8788243929545083
- 2.930192476908366
- 2.669454272588094
- 3.0463042068481445
- 2.848460845947266
- 2.5592693297068276
- 2.4570206133524577
- 2.6454701042175293
- 3.0063175519307452
- 2.1351677576700845
- 2.2010267623265585
- 2.3071425612767538
- 1.9616539446512857
- 2.272289171218872
- 2.253007470766703
- 2.1503290065129597
- 2.4379773267110187
- 2.475459845860799
- 2.565932181676229
- 2.679464251200358
- 2.6486239592234293
- 2.4613177426656088
- 2.625679995218913
- 2.0346607955296836
- 2.3338513501485187
- 2.127036061286926
- 2.713288116455078
- 2.0129048681259154
- 2.123734358151754
- 2.2435490115483603
- 2.6397726249694826
train_accuracy:
- 0.069
- 0.0
- 0.423
- 0.0
- 0.552
- 0.617
- 0.625
- 0.671
- 0.0
- 0.69
- 0.0
- 0.688
- 0.688
- 0.727
- 0.717
- 0.742
- 0.0
- 0.748
- 0.0
- 0.742
- 0.769
- 0.0
- 0.787
- 0.0
- 0.315
- 0.763
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.763
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.0
- 0.808
- 0.831
- 0.817
- 0.792
- 0.0
- 0.792
- 0.0
- 0.831
- 0.304
- 0.0
- 0.0
- 0.573
- 0.812
- 0.0
- 0.0
- 0.833
- 0.804
- 0.817
- 0.0
- 0.821
- 0.835
- 0.819
- 0.792
- 0.831
- 0.0
- 0.0
- 0.0
- 0.827
- 0.833
- 0.854
- 0.835
- 0.827
- 0.815
- 0.979
- 0.831
- 0.844
- 0.823
- 0.6
- 0.0
- 0.002
- 0.933
- 0.84
- 0.01
- 0.0
- 0.0
- 0.798
- 0.846
- 0.846
- 0.842
- 0.0
- 0.844
- 0.852
- 0.842
- 0.0
- 0.817
- 0.96
- 0.0
- 0.852
- 0.854
train_loss:
- 2.897
- 1.907
- 2.457
- 2.078
- 2.454
- 1.74
- 2.096
- 1.656
- 1.489
- 1.515
- 1.417
- 1.22
- 1.368
- 1.348
- 1.262
- 1.219
- 1.123
- 1.512
- 1.309
- 1.263
- 1.143
- 1.044
- 1.166
- 0.971
- 0.657
- 1.152
- 0.964
- 0.828
- 0.876
- 1.12
- 0.767
- 0.736
- 1.038
- 1.254
- 1.029
- 1.002
- 1.181
- 0.89
- 0.72
- 0.754
- 0.874
- 1.018
- 0.916
- 0.924
- 0.881
- 0.881
- 0.668
- 0.735
- 1.129
- 0.497
- 0.702
- 0.775
- 0.447
- 0.918
- 0.558
- 0.676
- 0.8
- 0.618
- 0.922
- 0.65
- 0.579
- 0.556
- 0.853
- 0.634
- 0.79
- 0.787
- 0.928
- 0.642
- 1.06
- 0.882
- 0.8
- 0.612
- 0.755
- 0.893
- 0.507
- 0.952
- 0.78
- 1.012
- 0.42
- 0.608
- 0.614
- 0.395
- 0.798
- 0.509
- 0.703
- 0.787
- 0.768
- 0.833
- 0.736
- 0.746
- 0.603
- 0.827
- 0.47
- 0.817
- 0.621
- 0.945
- 0.424
- 0.867
- 0.808
- 0.944
unequal: 0
verbose: 1
