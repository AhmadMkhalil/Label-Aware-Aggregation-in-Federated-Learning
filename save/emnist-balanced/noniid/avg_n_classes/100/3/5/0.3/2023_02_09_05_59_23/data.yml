avg_train_accuracy: 0.812
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037393617021276596
- 0.041329787234042556
- 0.14898936170212765
- 0.24643617021276595
- 0.0672872340425532
- 0.2756914893617021
- 0.334468085106383
- 0.3558510638297872
- 0.39877659574468083
- 0.4097340425531915
- 0.42473404255319147
- 0.4233510638297872
- 0.44718085106382977
- 0.4614893617021277
- 0.4656382978723404
- 0.4722872340425532
- 0.46856382978723404
- 0.48925531914893616
- 0.4940425531914894
- 0.49707446808510636
- 0.4902127659574468
- 0.485531914893617
- 0.2581914893617021
- 0.5019148936170212
- 0.5086702127659575
- 0.5029255319148936
- 0.5161170212765958
- 0.5136170212765957
- 0.5190957446808511
- 0.37829787234042556
- 0.5182446808510638
- 0.5261170212765958
- 0.5206382978723404
- 0.5299468085106382
- 0.5240425531914894
- 0.5277127659574468
- 0.5331382978723405
- 0.5364361702127659
- 0.533563829787234
- 0.5331382978723405
- 0.5373404255319149
- 0.536063829787234
- 0.5436170212765957
- 0.5417021276595745
- 0.5402659574468085
- 0.4692021276595745
- 0.5460106382978723
- 0.5438829787234043
- 0.5434042553191489
- 0.5464893617021277
- 0.5475
- 0.5488297872340425
- 0.5199468085106383
- 0.5493617021276596
- 0.5496808510638298
- 0.5504255319148936
- 0.5532978723404255
- 0.5531914893617021
- 0.5521276595744681
- 0.5499468085106383
- 0.5547872340425531
- 0.5540425531914893
- 0.5539893617021276
- 0.5543617021276596
- 0.5562234042553191
- 0.5548936170212766
- 0.5531914893617021
- 0.5522340425531915
- 0.555
- 0.5513829787234042
- 0.5100531914893617
- 0.5611170212765958
- 0.5582978723404255
- 0.5592021276595744
- 0.5596276595744681
- 0.560531914893617
- 0.5581382978723404
- 0.5585106382978723
- 0.5574468085106383
- 0.5595744680851064
- 0.5598936170212766
- 0.4656914893617021
- 0.265
- 0.5612765957446808
- 0.5600531914893617
- 0.5570212765957446
- 0.5617553191489362
- 0.5595744680851064
- 0.5585106382978723
- 0.5618085106382978
- 0.5623404255319149
- 0.5636170212765957
- 0.5620744680851064
- 0.5627659574468085
- 0.564468085106383
- 0.5661702127659575
- 0.5504787234042553
- 0.5585638297872341
- 0.5611702127659575
- 0.5656382978723404
test_loss_list:
- 3.7869049231211345
- 5.282207234700521
- 3.561823444366455
- 3.348360325495402
- 4.442344366709391
- 3.0760663986206054
- 2.992842248280843
- 2.948977073033651
- 3.0191498120625813
- 2.90708158493042
- 2.9590953095753987
- 2.8602569548288983
- 2.8843789672851563
- 3.0871554533640544
- 3.07839199701945
- 3.0904630025227866
- 2.9012461566925047
- 3.430772975285848
- 3.2128918902079264
- 3.27207187016805
- 2.9194980812072755
- 2.887237542470296
- 2.8461568705240885
- 3.0172058010101317
- 3.0442627493540444
- 2.8051717122395834
- 3.3839555581410727
- 2.96960192044576
- 3.5177436606089274
- 2.446736838022868
- 2.6306348832448325
- 3.1449359448750815
- 2.781873861948649
- 3.1855650424957274
- 2.884673862457275
- 3.004085782368978
- 2.9130253060658773
- 3.0785120328267417
- 2.995487934748332
- 2.876639773050944
- 2.723071037928263
- 2.7889813868204754
- 3.0946404711405435
- 2.8915884113311767
- 2.9221580537160237
- 2.0941885693868003
- 2.553661740620931
- 2.616988712946574
- 2.5747440497080487
- 2.8423731486002604
- 2.8227511278788247
- 2.731715087890625
- 2.0199175230662028
- 2.2749598964055378
- 2.4287926069895427
- 2.928284190495809
- 2.804318863550822
- 2.8372904300689696
- 2.8256641101837157
- 2.8311191113789875
- 3.1810328769683838
- 3.24619966506958
- 2.8924288686116535
- 2.9019814109802247
- 3.015201218922933
- 3.0855916372934975
- 2.8549435742696128
- 2.6359325059254965
- 2.7036968262990317
- 2.444559777577718
- 1.877221902211507
- 2.5116050465901694
- 2.5785195859273276
- 2.333700876235962
- 2.596368958155314
- 2.691422564188639
- 2.6383821805318197
- 2.51367049853007
- 2.450017925898234
- 2.798745304743449
- 3.0667490673065188
- 1.9740822140375773
- 2.8733304818471272
- 1.930334399541219
- 2.2963301801681517
- 2.205275775591532
- 2.3869567489624024
- 2.3058014853795368
- 2.2531330601374306
- 2.7958743222554525
- 2.2465861511230467
- 2.8331592750549315
- 2.439749835332235
- 2.517063709894816
- 2.4852678712209064
- 2.5939675521850587
- 1.696856934229533
- 2.1435529295603435
- 2.2938944721221923
- 2.4081614017486572
train_accuracy:
- 0.067
- 0.008
- 0.0
- 0.36
- 0.083
- 0.379
- 0.0
- 0.0
- 0.567
- 0.594
- 0.0
- 0.619
- 0.0
- 0.65
- 0.685
- 0.702
- 0.69
- 0.698
- 0.688
- 0.723
- 0.71
- 0.0
- 0.108
- 0.737
- 0.725
- 0.746
- 0.727
- 0.754
- 0.773
- 0.06
- 0.773
- 0.737
- 0.0
- 0.0
- 0.0
- 0.777
- 0.763
- 0.002
- 0.771
- 0.775
- 0.002
- 0.0
- 0.771
- 0.006
- 0.777
- 0.396
- 0.796
- 0.0
- 0.0
- 0.0
- 0.783
- 0.79
- 0.823
- 0.0
- 0.785
- 0.79
- 0.833
- 0.006
- 0.783
- 0.0
- 0.802
- 0.838
- 0.0
- 0.796
- 0.8
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.273
- 0.804
- 0.0
- 0.815
- 0.804
- 0.842
- 0.806
- 0.794
- 0.0
- 0.815
- 0.815
- 0.244
- 0.94
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.794
- 0.808
- 0.817
- 0.848
- 0.812
- 0.0
- 0.833
- 0.0
- 0.865
- 0.0
- 0.86
- 0.812
train_loss:
- 2.984
- 1.238
- 2.684
- 2.371
- 0.827
- 1.396
- 1.28
- 1.203
- 1.741
- 1.055
- 1.053
- 1.125
- 1.053
- 1.337
- 1.326
- 1.259
- 1.031
- 1.636
- 1.192
- 1.219
- 0.877
- 0.963
- 0.548
- 1.66
- 1.085
- 0.923
- 1.452
- 0.801
- 1.356
- 0.564
- 1.209
- 1.38
- 0.813
- 0.974
- 0.832
- 1.032
- 0.728
- 1.0
- 1.014
- 0.71
- 0.777
- 0.752
- 0.97
- 0.733
- 0.983
- 0.491
- 1.043
- 0.658
- 0.655
- 0.869
- 0.89
- 0.904
- 0.407
- 0.726
- 0.65
- 1.124
- 0.895
- 0.857
- 0.862
- 0.587
- 1.066
- 1.075
- 0.916
- 0.889
- 0.851
- 0.812
- 0.586
- 0.675
- 0.887
- 0.697
- 0.385
- 0.928
- 0.847
- 0.661
- 0.831
- 0.819
- 0.825
- 0.598
- 0.6
- 0.767
- 0.996
- 0.451
- 0.378
- 0.63
- 0.799
- 0.553
- 0.826
- 0.548
- 0.611
- 1.0
- 0.617
- 0.99
- 0.566
- 0.816
- 0.787
- 0.752
- 0.382
- 0.534
- 0.801
- 0.751
unequal: 0
verbose: 1
