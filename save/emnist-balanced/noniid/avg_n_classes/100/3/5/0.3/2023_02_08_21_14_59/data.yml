avg_train_accuracy: 0.635
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026595744680851064
- 0.05148936170212766
- 0.18718085106382978
- 0.3097340425531915
- 0.33404255319148934
- 0.35851063829787233
- 0.4051595744680851
- 0.13606382978723405
- 0.40164893617021274
- 0.4246808510638298
- 0.428031914893617
- 0.4503723404255319
- 0.154468085106383
- 0.4356914893617021
- 0.1624468085106383
- 0.4516489361702128
- 0.45909574468085107
- 0.47856382978723405
- 0.46904255319148935
- 0.47893617021276597
- 0.48686170212765956
- 0.4878723404255319
- 0.4904787234042553
- 0.5025531914893617
- 0.5023404255319149
- 0.5054787234042554
- 0.5107446808510638
- 0.27537234042553194
- 0.5043617021276596
- 0.5063829787234042
- 0.5173936170212766
- 0.3911702127659574
- 0.517127659574468
- 0.5223404255319148
- 0.5231382978723405
- 0.5242553191489362
- 0.5271808510638298
- 0.5283510638297872
- 0.531595744680851
- 0.5295744680851063
- 0.5364361702127659
- 0.5333510638297873
- 0.5350531914893617
- 0.5338829787234043
- 0.5412234042553191
- 0.5376595744680851
- 0.4321808510638298
- 0.5394148936170213
- 0.5440957446808511
- 0.5436170212765957
- 0.4354787234042553
- 0.5461702127659575
- 0.5441489361702128
- 0.5459574468085107
- 0.5486702127659574
- 0.5461170212765958
- 0.548031914893617
- 0.5477659574468086
- 0.5478723404255319
- 0.5500531914893617
- 0.5482978723404255
- 0.550531914893617
- 0.5538829787234043
- 0.5506914893617021
- 0.5503191489361702
- 0.5528723404255319
- 0.5511170212765958
- 0.5564893617021277
- 0.5557978723404255
- 0.5528191489361702
- 0.5532446808510638
- 0.5572340425531915
- 0.5548404255319149
- 0.5556914893617021
- 0.5551063829787234
- 0.5578191489361702
- 0.5547340425531915
- 0.5577127659574468
- 0.5543617021276596
- 0.5586170212765957
- 0.5577127659574468
- 0.558936170212766
- 0.5587765957446809
- 0.56
- 0.5605851063829788
- 0.5248404255319149
- 0.5627659574468085
- 0.5622340425531915
- 0.5602659574468085
- 0.5623936170212765
- 0.5606914893617021
- 0.5637234042553192
- 0.5630851063829787
- 0.5587765957446809
- 0.5622340425531915
- 0.5607446808510639
- 0.5590957446808511
- 0.5606382978723404
- 0.5635106382978723
- 0.5375
test_loss_list:
- 3.7985499477386475
- 3.791258214314779
- 3.6622824891408285
- 3.508528912862142
- 3.2891329447428386
- 3.1774013392130533
- 3.284137159983317
- 3.765752051671346
- 2.879673884709676
- 3.1673159186045328
- 2.907041473388672
- 2.978266798655192
- 3.5652565860748293
- 2.676739765803019
- 3.5372030353546142
- 2.6915155855814614
- 2.7397251160939535
- 3.2076097297668458
- 2.9151101016998293
- 3.1371708742777504
- 3.141620759963989
- 2.9138566780090334
- 2.8819970734914144
- 3.4299450874328614
- 3.1473514461517333
- 3.182228937149048
- 3.256114126841227
- 2.7905581919352214
- 2.6173687903086345
- 2.764070030848185
- 2.966587766011556
- 2.21456036567688
- 2.640641202926636
- 2.788767499923706
- 2.6680263805389406
- 2.908455432256063
- 2.6955609289805094
- 2.999728104273478
- 2.994435590108236
- 2.655111878712972
- 2.9419689242045086
- 2.706946725845337
- 2.7286199378967284
- 2.692274154027303
- 2.8130306657155355
- 2.6910129578908286
- 2.016662418047587
- 2.27743621190389
- 2.4398527431488035
- 2.5335551484425864
- 2.086164979934692
- 2.2892144966125487
- 2.3599194494883218
- 2.5869095452626545
- 2.6682966550191245
- 2.6941328875223793
- 2.7530313873291017
- 2.550089963277181
- 2.8143267822265625
- 2.845948781967163
- 2.5238644727071127
- 2.56132466952006
- 3.1099158573150634
- 2.893080358505249
- 2.5403292655944822
- 2.8559983603159584
- 2.9228153133392336
- 2.9733375199635823
- 2.8653819084167482
- 2.903697191874186
- 2.5980513668060303
- 3.216609795888265
- 2.9576476510365803
- 2.609813486735026
- 2.515433184305827
- 2.81423646291097
- 2.9456008752187093
- 2.8154041608174643
- 2.5972082646687826
- 2.826275463104248
- 2.616579764684041
- 2.6317127545674643
- 2.8284039942423504
- 2.6695589637756347
- 2.5412392902374266
- 1.70468017578125
- 2.4241430791219076
- 2.3130127716064455
- 2.5708757909138997
- 2.3727156861623127
- 2.6340434964497885
- 2.9930408922831218
- 3.0493467680613198
- 2.5250276120503745
- 2.7958176644643147
- 2.79804780960083
- 2.587873992919922
- 2.404597789446513
- 2.4276054430007936
- 1.7062675189971923
train_accuracy:
- 0.04
- 0.0
- 0.258
- 0.465
- 0.0
- 0.0
- 0.0
- 0.006
- 0.577
- 0.615
- 0.671
- 0.652
- 0.25
- 0.0
- 0.315
- 0.66
- 0.0
- 0.683
- 0.0
- 0.706
- 0.698
- 0.721
- 0.713
- 0.729
- 0.735
- 0.74
- 0.746
- 0.123
- 0.0
- 0.783
- 0.0
- 0.665
- 0.802
- 0.796
- 0.0
- 0.8
- 0.008
- 0.817
- 0.779
- 0.821
- 0.0
- 0.002
- 0.0
- 0.0
- 0.833
- 0.0
- 0.59
- 0.0
- 0.802
- 0.806
- 0.696
- 0.069
- 0.852
- 0.812
- 0.827
- 0.808
- 0.0
- 0.823
- 0.781
- 0.819
- 0.783
- 0.84
- 0.856
- 0.835
- 0.0
- 0.0
- 0.821
- 0.0
- 0.8
- 0.835
- 0.0
- 0.865
- 0.812
- 0.865
- 0.0
- 0.0
- 0.838
- 0.0
- 0.808
- 0.86
- 0.0
- 0.0
- 0.0
- 0.869
- 0.835
- 0.81
- 0.031
- 0.827
- 0.0
- 0.0
- 0.817
- 0.869
- 0.833
- 0.0
- 0.877
- 0.852
- 0.85
- 0.0
- 0.873
- 0.635
train_loss:
- 3.004
- 2.204
- 2.644
- 3.048
- 1.364
- 1.246
- 1.72
- 0.784
- 0.993
- 1.462
- 1.122
- 1.101
- 0.566
- 1.034
- 0.554
- 0.969
- 0.93
- 1.694
- 0.863
- 1.278
- 1.184
- 0.789
- 0.786
- 1.488
- 1.095
- 1.088
- 1.075
- 0.571
- 0.713
- 0.703
- 1.019
- 0.485
- 1.107
- 1.042
- 0.684
- 0.983
- 0.709
- 1.004
- 0.95
- 0.741
- 0.947
- 0.679
- 0.677
- 0.685
- 0.954
- 0.649
- 0.429
- 0.61
- 0.597
- 0.594
- 0.36
- 0.628
- 0.609
- 0.895
- 0.844
- 0.865
- 0.809
- 0.609
- 0.856
- 0.816
- 0.602
- 0.55
- 1.086
- 0.884
- 0.625
- 0.837
- 0.822
- 0.819
- 0.833
- 0.837
- 0.655
- 1.012
- 0.801
- 0.613
- 0.572
- 0.794
- 0.825
- 0.794
- 0.617
- 0.795
- 0.577
- 0.547
- 0.822
- 0.813
- 0.602
- 0.381
- 0.806
- 0.548
- 0.78
- 0.528
- 0.774
- 0.971
- 0.946
- 0.551
- 0.783
- 0.77
- 0.54
- 0.583
- 0.533
- 0.34
unequal: 0
verbose: 1
