avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0526063829787234
- 0.0450531914893617
- 0.20143617021276597
- 0.08095744680851064
- 0.3054787234042553
- 0.35095744680851065
- 0.3721276595744681
- 0.39101063829787236
- 0.15436170212765957
- 0.4249468085106383
- 0.4373936170212766
- 0.4378723404255319
- 0.4557978723404255
- 0.43946808510638297
- 0.4529255319148936
- 0.46143617021276595
- 0.4723404255319149
- 0.4710106382978723
- 0.48590425531914894
- 0.4850531914893617
- 0.4901595744680851
- 0.488936170212766
- 0.49606382978723407
- 0.4943085106382979
- 0.4924468085106383
- 0.49898936170212765
- 0.5037765957446808
- 0.5082446808510638
- 0.5131382978723404
- 0.5125
- 0.512340425531915
- 0.5126595744680851
- 0.5138829787234043
- 0.5169148936170213
- 0.5170212765957447
- 0.5253723404255319
- 0.5205851063829787
- 0.5287234042553192
- 0.5226063829787234
- 0.5233510638297872
- 0.5268085106382979
- 0.1776595744680851
- 0.5258510638297872
- 0.5311702127659574
- 0.5320212765957447
- 0.5373404255319149
- 0.5367553191489361
- 0.5390425531914894
- 0.5367021276595745
- 0.541968085106383
- 0.541968085106383
- 0.5389893617021276
- 0.540904255319149
- 0.538031914893617
- 0.5446808510638298
- 0.5422340425531915
- 0.5420212765957447
- 0.5470212765957447
- 0.5429787234042553
- 0.5470212765957447
- 0.5477659574468086
- 0.5505851063829788
- 0.5502127659574468
- 0.5480851063829787
- 0.551968085106383
- 0.5515425531914894
- 0.5544148936170212
- 0.546063829787234
- 0.5548936170212766
- 0.5552659574468085
- 0.5577659574468085
- 0.551968085106383
- 0.5572340425531915
- 0.5583510638297873
- 0.5610106382978723
- 0.5542021276595744
- 0.5520212765957446
- 0.5573936170212765
- 0.5593617021276596
- 0.555
- 0.4526595744680851
- 0.5567021276595745
- 0.5586702127659574
- 0.5585106382978723
- 0.5574468085106383
- 0.5572872340425532
- 0.5609574468085107
- 0.5582446808510638
- 0.5567553191489362
- 0.555372340425532
- 0.5631914893617022
- 0.5612234042553191
- 0.5583510638297873
- 0.5606382978723404
- 0.5586702127659574
- 0.4047340425531915
- 0.5622340425531915
- 0.560372340425532
- 0.560531914893617
- 0.563031914893617
test_loss_list:
- 3.8008223946889244
- 5.495846850077311
- 3.4260669072469074
- 4.302654984792073
- 3.0551418622334796
- 3.0718679332733156
- 3.131199073791504
- 2.9501934019724527
- 3.4359794902801513
- 2.985799414316813
- 3.1022078132629396
- 2.7840852324167886
- 3.036927604675293
- 2.8611551189422606
- 2.8345082982381187
- 2.877098887761434
- 3.224198128382365
- 2.9342585754394532
- 3.2853585465749107
- 3.218283697764079
- 3.192753340403239
- 3.037765754063924
- 3.2293887170155844
- 3.0688360786437987
- 2.985377689997355
- 3.011047067642212
- 2.997298402786255
- 3.249160639444987
- 3.244408124287923
- 3.1662986691792807
- 2.865979674657186
- 2.993613862991333
- 3.0013007227579753
- 2.849758405685425
- 2.954345239003499
- 3.2172796312967935
- 2.8726264381408693
- 3.165381409327189
- 2.868887650171916
- 2.977604455947876
- 2.8053658485412596
- 4.384556293487549
- 2.5005269559224446
- 2.6884735838572182
- 2.9694491640726723
- 3.001681474049886
- 2.995335947672526
- 3.1187206172943114
- 2.815294768015544
- 3.0050832748413088
- 3.197098550796509
- 2.8367854150136314
- 2.8082048161824544
- 2.633487221399943
- 3.103110466003418
- 2.943554344177246
- 2.772729342778524
- 2.8077176570892335
- 2.678488988876343
- 3.0272496700286866
- 3.105973803202311
- 3.1872890504201252
- 2.9032703018188477
- 2.6807247257232665
- 3.008874905904134
- 2.819807907740275
- 3.068875281016032
- 2.723943904240926
- 3.3820005639394126
- 3.2572402572631836
- 3.0812943998972573
- 2.7086288420359295
- 3.0568788846333823
- 3.1262198321024575
- 3.1227887598673503
- 2.877854127883911
- 2.6858800983428956
- 2.893911428451538
- 3.039466120402018
- 2.6138683319091798
- 2.1073041741053262
- 2.313067299524943
- 2.4386867968241375
- 2.6668346150716147
- 2.4882166290283205
- 2.64251625696818
- 2.6207726701100666
- 2.6215888118743895
- 2.3786900806427003
- 2.5007096354166665
- 2.7930068492889406
- 2.7225206089019776
- 2.5113778273264566
- 2.8384056949615477
- 2.4950081793467205
- 2.322103052139282
- 2.2882691844304404
- 2.2631122318903607
- 2.5797637780507405
- 2.5918363412221272
train_accuracy:
- 0.069
- 0.0
- 0.0
- 0.425
- 0.0
- 0.552
- 0.612
- 0.562
- 0.408
- 0.621
- 0.0
- 0.656
- 0.0
- 0.69
- 0.704
- 0.681
- 0.71
- 0.704
- 0.0
- 0.742
- 0.742
- 0.0
- 0.765
- 0.0
- 0.742
- 0.0
- 0.0
- 0.771
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.779
- 0.0
- 0.0
- 0.0
- 0.0
- 0.41
- 0.0
- 0.0
- 0.804
- 0.0
- 0.792
- 0.825
- 0.0
- 0.823
- 0.823
- 0.0
- 0.81
- 0.815
- 0.817
- 0.802
- 0.0
- 0.838
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.84
- 0.802
- 0.827
- 0.0
- 0.0
- 0.0
- 0.829
- 0.829
- 0.829
- 0.825
- 0.827
- 0.0
- 0.825
- 0.0
- 0.904
- 0.0
- 0.835
- 0.0
- 0.0
- 0.823
- 0.833
- 0.0
- 0.0
- 0.0
- 0.833
- 0.821
- 0.0
- 0.844
- 0.0
- 0.906
- 0.0
- 0.0
- 0.817
- 0.0
train_loss:
- 2.115
- 0.973
- 1.656
- 0.595
- 1.468
- 1.999
- 1.157
- 1.189
- 0.523
- 1.587
- 1.497
- 1.198
- 0.884
- 1.057
- 1.033
- 0.982
- 1.281
- 0.939
- 1.213
- 1.239
- 1.243
- 0.836
- 1.173
- 0.823
- 0.803
- 0.735
- 0.785
- 1.082
- 1.051
- 1.117
- 0.899
- 0.802
- 0.764
- 0.832
- 0.73
- 0.985
- 0.776
- 0.997
- 0.804
- 0.677
- 0.773
- 0.457
- 0.735
- 0.727
- 0.917
- 0.974
- 0.982
- 0.902
- 0.708
- 0.96
- 0.889
- 0.667
- 0.65
- 0.744
- 0.881
- 0.942
- 0.718
- 0.696
- 0.703
- 0.889
- 0.88
- 0.844
- 0.615
- 0.705
- 0.889
- 0.658
- 0.827
- 0.664
- 1.041
- 0.799
- 0.861
- 0.694
- 0.825
- 0.812
- 0.822
- 0.629
- 0.632
- 0.576
- 0.769
- 0.675
- 0.349
- 0.624
- 0.546
- 0.805
- 0.566
- 0.86
- 0.568
- 0.559
- 0.677
- 0.58
- 0.77
- 0.787
- 0.612
- 0.758
- 0.61
- 0.329
- 0.478
- 0.639
- 0.761
- 0.813
unequal: 0
verbose: 1
