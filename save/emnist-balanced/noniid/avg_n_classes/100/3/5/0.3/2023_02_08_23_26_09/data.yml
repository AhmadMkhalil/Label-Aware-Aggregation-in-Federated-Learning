avg_train_accuracy: 0.831
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04218085106382979
- 0.12531914893617022
- 0.05601063829787234
- 0.2545212765957447
- 0.3083510638297872
- 0.34132978723404256
- 0.38398936170212766
- 0.3998404255319149
- 0.13297872340425532
- 0.40914893617021275
- 0.43170212765957444
- 0.43053191489361703
- 0.4498404255319149
- 0.4428723404255319
- 0.460531914893617
- 0.18335106382978725
- 0.4724468085106383
- 0.4660106382978723
- 0.4829787234042553
- 0.4857446808510638
- 0.4897340425531915
- 0.4876063829787234
- 0.29617021276595745
- 0.4958510638297872
- 0.49936170212765957
- 0.4950531914893617
- 0.5053723404255319
- 0.49888297872340426
- 0.36090425531914894
- 0.5084042553191489
- 0.5029787234042553
- 0.28117021276595744
- 0.5197872340425532
- 0.5210106382978723
- 0.5223404255319148
- 0.3721276595744681
- 0.5218617021276596
- 0.5239893617021276
- 0.360531914893617
- 0.5251595744680851
- 0.5294148936170213
- 0.5303723404255319
- 0.5287765957446808
- 0.4504787234042553
- 0.5368617021276596
- 0.538031914893617
- 0.5345212765957447
- 0.5412765957446809
- 0.5407446808510639
- 0.5398936170212766
- 0.5360106382978723
- 0.5387234042553192
- 0.5441489361702128
- 0.5426595744680851
- 0.5466489361702128
- 0.5463297872340426
- 0.4760106382978723
- 0.5515425531914894
- 0.5498404255319149
- 0.546063829787234
- 0.5509574468085107
- 0.5487765957446809
- 0.5472340425531915
- 0.5483510638297873
- 0.5522340425531915
- 0.5498404255319149
- 0.5532446808510638
- 0.5010638297872341
- 0.5610106382978723
- 0.5542021276595744
- 0.5552127659574468
- 0.5566489361702127
- 0.5537234042553192
- 0.5584574468085106
- 0.48558510638297875
- 0.5599468085106383
- 0.5549468085106383
- 0.5590957446808511
- 0.5564361702127659
- 0.5544148936170212
- 0.5588829787234042
- 0.5588829787234042
- 0.4761170212765957
- 0.5643085106382979
- 0.5252659574468085
- 0.4528191489361702
- 0.5687765957446809
- 0.5201063829787234
- 0.5776595744680851
- 0.5682446808510638
- 0.565531914893617
- 0.5647340425531915
- 0.5649468085106383
- 0.5662234042553191
- 0.5635638297872341
- 0.5645212765957447
- 0.5688829787234042
- 0.5662765957446808
- 0.5642021276595744
- 0.5625
test_loss_list:
- 3.8015362580617267
- 3.7143799114227294
- 5.87836758295695
- 3.3698465696970623
- 3.2230503686269123
- 3.154198061625163
- 3.2306567351023356
- 3.270266876220703
- 4.86183869043986
- 2.9533675734202065
- 3.163284044265747
- 3.031009149551392
- 3.2203504848480224
- 3.0196907075246173
- 3.249078458150228
- 3.414819939931234
- 3.157058213551839
- 2.9007013829549155
- 3.0796124903361
- 3.142587798436483
- 3.114338617324829
- 2.888821891148885
- 2.7572754700978597
- 2.7215249411265057
- 2.9281760183970134
- 2.768831876118978
- 3.0015464274088544
- 2.75124005317688
- 2.365817108154297
- 2.588494135538737
- 2.483916810353597
- 3.1114372952779132
- 2.3421116479237876
- 2.8646033827463784
- 2.6869826825459797
- 2.611613343556722
- 2.3365499369303384
- 2.3830521392822264
- 2.546522347132365
- 2.4636294078826904
- 2.8103134123484295
- 2.713698476155599
- 2.7661376825968422
- 2.1053525988260904
- 2.301278214454651
- 2.334696135520935
- 2.461417744954427
- 2.637199675242106
- 2.651739877065023
- 2.51389754931132
- 2.649051440556844
- 2.618758061726888
- 2.678819777170817
- 2.5048708788553875
- 2.757434787750244
- 2.579961627324422
- 1.9144294627507528
- 2.035510025024414
- 2.4004881477355955
- 2.3302689663569134
- 2.516302111943563
- 2.585621627171834
- 2.4227021249135334
- 2.444696944554647
- 2.62795285542806
- 2.6808724562327066
- 2.4526708126068115
- 1.8752946281433105
- 2.1967074235280353
- 2.3747946071624755
- 2.28050772190094
- 2.325396607716878
- 2.2472740983963013
- 2.4982607332865396
- 1.7819672664006552
- 2.2592463302612305
- 2.217494554519653
- 2.313802574475606
- 2.253453110059102
- 2.3092428636550903
- 2.4100772253672282
- 2.4956811237335206
- 1.9081574519475302
- 2.3806743319829304
- 1.6131575520833332
- 1.9332921409606934
- 1.9496799834569296
- 1.822233034769694
- 1.7571122105916341
- 2.043071182568868
- 2.0067709064483643
- 2.1782530784606933
- 2.267742540041606
- 2.1145812463760376
- 2.3325552845001223
- 2.384602839152018
- 2.4696376736958823
- 2.349732656478882
- 2.4213943099975586
- 2.2280418729782103
train_accuracy:
- 0.065
- 0.0
- 0.125
- 0.346
- 0.444
- 0.494
- 0.552
- 0.575
- 0.325
- 0.608
- 0.675
- 0.65
- 0.71
- 0.685
- 0.0
- 0.127
- 0.717
- 0.658
- 0.675
- 0.688
- 0.737
- 0.735
- 0.879
- 0.765
- 0.754
- 0.0
- 0.752
- 0.754
- 0.21
- 0.0
- 0.0
- 0.758
- 0.0
- 0.785
- 0.79
- 0.887
- 0.0
- 0.0
- 0.675
- 0.775
- 0.796
- 0.769
- 0.754
- 0.725
- 0.808
- 0.002
- 0.794
- 0.0
- 0.798
- 0.0
- 0.796
- 0.0
- 0.792
- 0.0
- 0.0
- 0.0
- 0.2
- 0.0
- 0.0
- 0.777
- 0.81
- 0.798
- 0.0
- 0.0
- 0.802
- 0.804
- 0.0
- 0.163
- 0.0
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.371
- 0.808
- 0.0
- 0.831
- 0.002
- 0.0
- 0.815
- 0.823
- 0.852
- 0.821
- 0.804
- 0.61
- 0.042
- 0.471
- 0.0
- 0.833
- 0.004
- 0.0
- 0.823
- 0.002
- 0.0
- 0.833
- 0.842
- 0.835
- 0.002
- 0.831
train_loss:
- 2.072
- 1.819
- 0.774
- 2.287
- 1.493
- 1.244
- 1.678
- 1.66
- 0.541
- 1.582
- 1.403
- 1.062
- 1.329
- 1.11
- 1.335
- 0.571
- 1.821
- 0.859
- 1.29
- 1.203
- 1.125
- 0.858
- 0.488
- 1.29
- 1.065
- 0.795
- 1.069
- 0.781
- 0.533
- 1.159
- 0.673
- 0.341
- 0.757
- 1.35
- 0.944
- 0.399
- 0.613
- 0.735
- 0.358
- 1.026
- 1.226
- 0.959
- 0.915
- 0.395
- 0.68
- 0.65
- 0.621
- 0.904
- 0.941
- 0.661
- 0.605
- 0.58
- 0.886
- 0.697
- 0.827
- 0.618
- 0.412
- 0.627
- 0.851
- 0.567
- 0.862
- 0.801
- 0.56
- 0.613
- 0.804
- 0.822
- 0.63
- 0.335
- 0.469
- 0.856
- 0.565
- 0.5
- 0.612
- 0.823
- 0.363
- 0.804
- 0.528
- 0.845
- 0.565
- 0.558
- 0.805
- 0.746
- 0.356
- 1.082
- 0.334
- 0.268
- 0.816
- 0.29
- 0.486
- 0.762
- 0.52
- 0.768
- 0.756
- 0.502
- 0.753
- 0.729
- 0.741
- 0.771
- 0.735
- 0.506
unequal: 0
verbose: 1
