avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029734042553191488
- 0.03590425531914894
- 0.19553191489361701
- 0.2827127659574468
- 0.33914893617021274
- 0.3840425531914894
- 0.4048936170212766
- 0.4246276595744681
- 0.4179787234042553
- 0.4403723404255319
- 0.44659574468085106
- 0.45111702127659575
- 0.18079787234042552
- 0.4578191489361702
- 0.465
- 0.46675531914893614
- 0.47606382978723405
- 0.4828723404255319
- 0.4913297872340426
- 0.4973936170212766
- 0.2052127659574468
- 0.4978723404255319
- 0.330531914893617
- 0.49420212765957444
- 0.504468085106383
- 0.5095744680851064
- 0.5095744680851064
- 0.5174468085106383
- 0.5160638297872341
- 0.5159574468085106
- 0.5203723404255319
- 0.5252659574468085
- 0.5252127659574468
- 0.5285106382978724
- 0.5302659574468085
- 0.5262234042553191
- 0.5228723404255319
- 0.5254787234042553
- 0.5319148936170213
- 0.5352659574468085
- 0.5347872340425532
- 0.5370212765957447
- 0.5413829787234042
- 0.5413829787234042
- 0.5431914893617021
- 0.5454787234042553
- 0.5433510638297873
- 0.5385106382978724
- 0.5389893617021276
- 0.5475
- 0.5470212765957447
- 0.5479255319148936
- 0.546595744680851
- 0.5479255319148936
- 0.5492553191489362
- 0.5451063829787234
- 0.5504787234042553
- 0.5453191489361702
- 0.5499468085106383
- 0.5528191489361702
- 0.5550531914893617
- 0.5540425531914893
- 0.5528191489361702
- 0.5547872340425531
- 0.5564361702127659
- 0.5547872340425531
- 0.5504787234042553
- 0.5522872340425532
- 0.5497872340425531
- 0.5567021276595745
- 0.5582978723404255
- 0.5562765957446808
- 0.37755319148936173
- 0.5602659574468085
- 0.5547340425531915
- 0.5607978723404256
- 0.5581382978723404
- 0.5605851063829788
- 0.5602127659574468
- 0.5599468085106383
- 0.5581914893617022
- 0.5595744680851064
- 0.464468085106383
- 0.5611170212765958
- 0.5638829787234042
- 0.5623404255319149
- 0.5635106382978723
- 0.563404255319149
- 0.5631914893617022
- 0.565
- 0.5659042553191489
- 0.5693617021276596
- 0.5711702127659575
- 0.5714361702127659
- 0.564627659574468
- 0.5666489361702127
- 0.5645744680851064
- 0.5701063829787234
- 0.4326595744680851
- 0.5742553191489361
test_loss_list:
- 3.7929914633433026
- 3.821267236073812
- 3.763515831629435
- 3.638024171193441
- 3.566183395385742
- 3.4325580024719238
- 3.366622298558553
- 3.4104488849639893
- 3.190732177098592
- 3.1667819182078043
- 3.1888752365112305
- 3.13348619778951
- 3.293064578374227
- 2.775407053629557
- 2.8307172775268556
- 3.029638923009237
- 3.162759033838908
- 3.3113798332214355
- 3.396905012130737
- 3.298267091115316
- 3.2934649721781413
- 2.9118950366973877
- 2.488869997660319
- 2.3839216581980387
- 2.5431219482421876
- 2.819828764597575
- 2.864752950668335
- 3.204839073816935
- 3.070352474848429
- 3.2742889467875163
- 3.3628761863708494
- 3.7538386376698814
- 3.49202885945638
- 3.3903549989064534
- 3.552836936314901
- 3.0492049249013267
- 3.175555769602458
- 3.148342653910319
- 3.3789474232991537
- 3.3819107246398925
- 2.9320306555430093
- 3.0808525053660074
- 3.716035248438517
- 3.34747101465861
- 3.7951886971791584
- 3.4006686878204344
- 3.0481075763702394
- 2.8981346225738527
- 2.960152123769124
- 3.6394553248087567
- 3.454162327448527
- 3.309708776473999
- 3.005572058359782
- 3.2130675570170086
- 2.9319038740793864
- 2.870533415476481
- 3.1163534704844156
- 2.950533634821574
- 2.8442993450164793
- 3.232250696818034
- 2.8388355032602948
- 3.054687522252401
- 2.781847480138143
- 3.043737414677938
- 3.163759953180949
- 3.19169921875
- 2.84454340616862
- 2.7941308275858563
- 2.8237153911590576
- 3.0752828470865885
- 3.1994995721181234
- 2.8206993516286216
- 2.352963914871216
- 2.9112957890828453
- 2.5943250370025637
- 2.685309995015462
- 2.696893434524536
- 2.969192819595337
- 2.6410480054219563
- 2.6265506394704183
- 2.658198877970378
- 2.7330550384521484
- 1.8837251774470012
- 2.3300916131337486
- 3.063169460296631
- 2.9029978052775065
- 2.515363877614339
- 2.845192575454712
- 2.520954449971517
- 2.505942897796631
- 2.561745802561442
- 2.77593687693278
- 2.7680882263183593
- 2.5757632001241046
- 2.4560216999053956
- 3.1654709815979003
- 2.576198123296102
- 2.6176931699117025
- 2.1231030003229776
- 2.264073394139608
train_accuracy:
- 0.0
- 0.0
- 0.265
- 0.0
- 0.525
- 0.0
- 0.565
- 0.0
- 0.0
- 0.665
- 0.0
- 0.0
- 0.006
- 0.7
- 0.721
- 0.0
- 0.717
- 0.694
- 0.715
- 0.771
- 0.725
- 0.737
- 0.771
- 0.76
- 0.742
- 0.74
- 0.746
- 0.787
- 0.717
- 0.731
- 0.0
- 0.821
- 0.0
- 0.0
- 0.815
- 0.0
- 0.75
- 0.75
- 0.779
- 0.8
- 0.0
- 0.0
- 0.792
- 0.798
- 0.808
- 0.796
- 0.821
- 0.0
- 0.796
- 0.802
- 0.0
- 0.796
- 0.0
- 0.8
- 0.0
- 0.0
- 0.0
- 0.827
- 0.0
- 0.85
- 0.002
- 0.808
- 0.0
- 0.821
- 0.802
- 0.852
- 0.0
- 0.844
- 0.0
- 0.0
- 0.79
- 0.0
- 0.783
- 0.825
- 0.794
- 0.0
- 0.806
- 0.863
- 0.817
- 0.0
- 0.004
- 0.819
- 0.777
- 0.0
- 0.873
- 0.86
- 0.852
- 0.85
- 0.85
- 0.0
- 0.817
- 0.885
- 0.885
- 0.0
- 0.85
- 0.86
- 0.0
- 0.833
- 0.787
- 0.0
train_loss:
- 2.158
- 1.993
- 2.696
- 2.382
- 2.049
- 1.901
- 1.732
- 1.602
- 1.139
- 1.125
- 1.028
- 1.065
- 0.571
- 0.879
- 0.977
- 0.866
- 1.32
- 1.221
- 1.181
- 1.236
- 0.625
- 1.714
- 0.564
- 0.864
- 0.859
- 1.132
- 1.141
- 1.424
- 1.123
- 1.064
- 1.045
- 1.292
- 1.017
- 1.036
- 0.967
- 0.824
- 0.709
- 0.773
- 0.991
- 0.964
- 0.799
- 0.701
- 1.209
- 0.929
- 1.172
- 0.956
- 0.703
- 0.696
- 0.673
- 1.124
- 0.878
- 0.961
- 0.715
- 0.897
- 0.664
- 0.68
- 0.887
- 0.634
- 0.636
- 0.833
- 0.685
- 0.87
- 0.705
- 0.849
- 0.819
- 0.815
- 0.633
- 0.618
- 0.662
- 0.869
- 0.815
- 0.616
- 0.41
- 1.146
- 0.574
- 0.574
- 0.57
- 0.772
- 0.659
- 0.63
- 0.575
- 0.545
- 0.438
- 0.528
- 0.963
- 0.751
- 0.587
- 0.754
- 0.558
- 0.548
- 0.548
- 0.742
- 0.74
- 0.558
- 0.627
- 0.922
- 0.591
- 0.538
- 0.384
- 0.583
unequal: 0
verbose: 1
