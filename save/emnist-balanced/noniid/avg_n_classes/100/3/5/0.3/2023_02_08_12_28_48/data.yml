avg_train_accuracy: 0.8
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04351063829787234
- 0.1321276595744681
- 0.2572872340425532
- 0.3126063829787234
- 0.3388829787234043
- 0.3816489361702128
- 0.40893617021276596
- 0.42351063829787233
- 0.43446808510638296
- 0.4452659574468085
- 0.45622340425531915
- 0.44920212765957446
- 0.4693617021276596
- 0.4798404255319149
- 0.4699468085106383
- 0.4785106382978723
- 0.4746808510638298
- 0.48079787234042554
- 0.49882978723404253
- 0.4973404255319149
- 0.5005851063829787
- 0.4947872340425532
- 0.5065957446808511
- 0.5135106382978724
- 0.5048936170212766
- 0.5063829787234042
- 0.5196808510638298
- 0.5055851063829787
- 0.5198404255319149
- 0.5157446808510638
- 0.5163297872340425
- 0.5168085106382979
- 0.515531914893617
- 0.5229255319148937
- 0.5343617021276595
- 0.5283510638297872
- 0.5337765957446808
- 0.534468085106383
- 0.5263297872340426
- 0.3118085106382979
- 0.5272872340425532
- 0.5282978723404256
- 0.5319148936170213
- 0.5367553191489361
- 0.5377127659574468
- 0.2967021276595745
- 0.5364893617021277
- 0.5392021276595744
- 0.5403191489361702
- 0.5438829787234043
- 0.5406914893617021
- 0.5443617021276596
- 0.5404787234042553
- 0.3119148936170213
- 0.5468085106382978
- 0.5446276595744681
- 0.39180851063829786
- 0.5460106382978723
- 0.5418085106382978
- 0.5449468085106383
- 0.5454255319148936
- 0.543563829787234
- 0.5512765957446808
- 0.5500531914893617
- 0.5482978723404255
- 0.5522872340425532
- 0.5482978723404255
- 0.5483510638297873
- 0.5540957446808511
- 0.5511702127659575
- 0.5481382978723405
- 0.5552127659574468
- 0.5543085106382979
- 0.5512765957446808
- 0.5582446808510638
- 0.551968085106383
- 0.5561702127659575
- 0.5523936170212767
- 0.5507978723404255
- 0.5607978723404256
- 0.5590425531914893
- 0.5529787234042554
- 0.44079787234042556
- 0.5661170212765958
- 0.5609042553191489
- 0.4398936170212766
- 0.5582446808510638
- 0.560372340425532
- 0.5609574468085107
- 0.560372340425532
- 0.560531914893617
- 0.49446808510638296
- 0.5639893617021277
- 0.561595744680851
- 0.5622872340425532
- 0.47590425531914893
- 0.5641489361702128
- 0.5677127659574468
- 0.5600531914893617
- 0.5593085106382979
test_loss_list:
- 3.7967911783854165
- 3.7191193866729737
- 3.5162138970692953
- 3.311064748764038
- 3.2008581670125325
- 3.286730937957764
- 3.1098505719502767
- 3.38293571472168
- 3.3453207206726074
- 3.3474383036295574
- 3.307608954111735
- 3.122509857813517
- 3.365693343480428
- 3.818266083399455
- 3.2147329807281495
- 3.200521078109741
- 3.1275053787231446
- 3.0220224761962893
- 3.7351456101735434
- 3.374459749857585
- 3.4314163239796955
- 3.0511106077829995
- 3.382339083353678
- 3.8236310323079428
- 3.1624254258473714
- 3.1090448824564616
- 3.818880615234375
- 3.205603221257528
- 3.3326824474334718
- 3.022016299565633
- 3.036677131652832
- 2.9203787358601887
- 2.993861742019653
- 2.992158975601196
- 3.6055802663167316
- 3.277797508239746
- 3.3116611512502034
- 2.9640355332692465
- 2.8518736712137858
- 2.7132020886739094
- 2.5556621837615965
- 2.6844904804229737
- 2.7743311087290445
- 2.996318664550781
- 3.0276726563771565
- 2.7319373416900636
- 2.3712787214914957
- 2.765010792414347
- 2.873339614868164
- 3.2977290757497153
- 3.1027491823832194
- 3.029526507059733
- 2.7285629336039223
- 2.9083333174387613
- 2.4781749629974366
- 2.73496067682902
- 2.292697235743205
- 2.477751922607422
- 2.450578829447428
- 2.527072925567627
- 2.4946990553538004
- 2.5971717675526937
- 2.7689258289337157
- 2.8250854937235514
- 2.5430235417683917
- 3.0463784408569334
- 2.6179074160257976
- 2.6052776432037352
- 2.8916691080729167
- 2.5470141569773355
- 2.6179226303100585
- 2.6226846981048584
- 2.721093330383301
- 2.5841762034098306
- 3.0524258931477863
- 2.6372883415222166
- 2.7960085614522296
- 2.6283988984425863
- 2.55959020614624
- 2.8156941731770835
- 2.8890519682566325
- 2.6223741817474364
- 2.3190169366200766
- 2.4911233870188396
- 2.8999956862131753
- 2.0139420557022096
- 2.3076737356185912
- 2.266669586499532
- 2.4823813756306965
- 2.8882780424753824
- 2.67638897895813
- 1.9006223328908285
- 2.5696937656402588
- 2.2858182605107626
- 2.504042313893636
- 1.8590373086929322
- 1.9608407878875733
- 2.2059377336502077
- 2.155384432474772
- 2.148565049171448
train_accuracy:
- 0.083
- 0.177
- 0.375
- 0.0
- 0.0
- 0.0
- 0.0
- 0.625
- 0.621
- 0.694
- 0.66
- 0.0
- 0.719
- 0.723
- 0.0
- 0.0
- 0.727
- 0.704
- 0.765
- 0.725
- 0.74
- 0.733
- 0.713
- 0.765
- 0.0
- 0.723
- 0.767
- 0.0
- 0.773
- 0.0
- 0.0
- 0.0
- 0.748
- 0.0
- 0.79
- 0.773
- 0.804
- 0.765
- 0.0
- 0.683
- 0.002
- 0.802
- 0.031
- 0.792
- 0.0
- 0.388
- 0.8
- 0.0
- 0.0
- 0.815
- 0.79
- 0.812
- 0.0
- 0.915
- 0.308
- 0.819
- 0.36
- 0.831
- 0.0
- 0.0
- 0.821
- 0.821
- 0.787
- 0.821
- 0.0
- 0.785
- 0.0
- 0.823
- 0.002
- 0.0
- 0.838
- 0.0
- 0.808
- 0.0
- 0.835
- 0.0
- 0.002
- 0.844
- 0.0
- 0.0
- 0.84
- 0.002
- 0.737
- 0.812
- 0.8
- 0.487
- 0.815
- 0.002
- 0.0
- 0.848
- 0.002
- 0.942
- 0.817
- 0.825
- 0.84
- 0.758
- 0.0
- 0.14
- 0.817
- 0.8
train_loss:
- 2.892
- 2.794
- 2.567
- 1.562
- 1.4
- 1.77
- 1.288
- 1.647
- 1.519
- 1.542
- 1.456
- 1.041
- 1.306
- 1.637
- 0.996
- 1.092
- 0.936
- 0.975
- 1.519
- 1.229
- 1.172
- 0.878
- 1.172
- 1.396
- 0.99
- 0.868
- 1.354
- 0.917
- 1.073
- 0.823
- 0.933
- 0.822
- 0.919
- 0.827
- 1.27
- 0.976
- 0.953
- 0.691
- 0.769
- 0.462
- 0.648
- 0.715
- 0.61
- 0.914
- 0.912
- 0.518
- 0.857
- 1.07
- 0.953
- 1.161
- 0.88
- 0.942
- 0.627
- 0.383
- 0.748
- 0.851
- 0.525
- 0.952
- 0.705
- 0.664
- 0.625
- 0.616
- 0.939
- 0.863
- 0.61
- 1.088
- 0.619
- 0.675
- 0.797
- 0.606
- 0.655
- 0.586
- 0.858
- 0.629
- 1.034
- 0.556
- 0.836
- 0.707
- 0.633
- 0.83
- 0.771
- 0.535
- 0.335
- 0.841
- 0.996
- 0.54
- 0.855
- 0.622
- 0.824
- 0.987
- 0.775
- 0.382
- 1.092
- 0.566
- 0.822
- 0.348
- 0.581
- 0.478
- 0.573
- 0.589
unequal: 0
verbose: 1
