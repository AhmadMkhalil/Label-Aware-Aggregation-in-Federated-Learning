avg_train_accuracy: 0.812
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04851063829787234
- 0.06611702127659574
- 0.1222340425531915
- 0.2595212765957447
- 0.34882978723404257
- 0.43175531914893617
- 0.48351063829787233
- 0.5267021276595745
- 0.5548404255319149
- 0.5767021276595745
- 0.5923936170212766
- 0.6038829787234042
- 0.6182978723404255
- 0.6289361702127659
- 0.6385106382978724
- 0.6486702127659575
- 0.6548936170212766
- 0.6591489361702128
- 0.6670212765957447
- 0.6731914893617021
- 0.6777127659574468
- 0.6814361702127659
- 0.6854787234042553
- 0.6890425531914893
- 0.6924468085106383
- 0.6978723404255319
- 0.7020744680851064
- 0.7021808510638298
- 0.7048404255319148
- 0.7054255319148937
- 0.7098404255319148
- 0.7157978723404256
- 0.718563829787234
- 0.7185106382978723
- 0.7210106382978724
- 0.7232446808510639
- 0.7229787234042553
- 0.7275
- 0.73
- 0.7298936170212766
- 0.7297340425531915
- 0.7321808510638298
- 0.7372872340425531
- 0.7353723404255319
- 0.7370744680851063
- 0.7389893617021277
- 0.7399468085106383
- 0.7399468085106383
- 0.7412765957446809
- 0.741436170212766
- 0.7411702127659574
- 0.7417021276595744
- 0.7433510638297872
- 0.745
- 0.7467553191489362
- 0.7477127659574468
- 0.7460638297872341
- 0.7453723404255319
- 0.7484574468085107
- 0.7514893617021277
- 0.75
- 0.748563829787234
- 0.7484042553191489
- 0.7518085106382979
- 0.7528191489361702
- 0.7525531914893617
- 0.7543085106382978
- 0.7543617021276596
- 0.753563829787234
- 0.7547340425531915
- 0.7556382978723404
- 0.7535106382978723
- 0.7563829787234042
- 0.7560638297872341
- 0.7584042553191489
- 0.7572340425531915
- 0.7583510638297872
- 0.758031914893617
- 0.7597340425531914
- 0.7602127659574468
- 0.7587234042553191
- 0.762127659574468
- 0.7614893617021277
- 0.7618617021276596
- 0.7615957446808511
- 0.7602127659574468
- 0.7611702127659574
- 0.7611170212765958
- 0.761968085106383
- 0.7628723404255319
- 0.7633510638297872
- 0.7648404255319149
- 0.764468085106383
- 0.7634042553191489
- 0.7640957446808511
- 0.7669680851063829
- 0.7646276595744681
- 0.7643085106382979
- 0.7683510638297872
- 0.7661702127659574
test_loss_list:
- 3.7770629755655922
- 3.7280618953704834
- 3.6035082944234214
- 3.3166054185231526
- 2.9363611348470053
- 2.581633949279785
- 2.3389711316426594
- 2.1730705579121907
- 2.045510255495707
- 1.959941873550415
- 1.8568658892313639
- 1.7796819909413655
- 1.716131590207418
- 1.6506200313568116
- 1.6724849112828573
- 1.6449866151809693
- 1.559039486249288
- 1.5254142793019612
- 1.55235911210378
- 1.5417737738291422
- 1.4529359896977743
- 1.4318509038289389
- 1.4738671588897705
- 1.3809967041015625
- 1.355440305074056
- 1.3321101570129394
- 1.3891368595759075
- 1.2958275286356609
- 1.3643566211064657
- 1.3754333432515462
- 1.368098134994507
- 1.3705038865407309
- 1.3613245360056558
- 1.283679927190145
- 1.3467297410964967
- 1.2569244893391927
- 1.3107938798268637
- 1.2247612953186036
- 1.2025001303354899
- 1.2739715305964152
- 1.1745285765329996
- 1.168743945757548
- 1.1359877189000447
- 1.2203607670466106
- 1.2446765065193177
- 1.2598402166366578
- 1.2486450544993082
- 1.2676884468396505
- 1.2673711887995402
- 1.1647517148653665
- 1.1369103797276814
- 1.2250045824050904
- 1.2308283670743307
- 1.234425701300303
- 1.240392549832662
- 1.1437377580006918
- 1.1335749212900799
- 1.1047903712590534
- 1.0806030607223511
- 1.0647426160176594
- 1.0511931077639263
- 1.0460072326660157
- 1.0353060928980509
- 1.1405757228533426
- 1.1586781446139018
- 1.0576162060101828
- 1.04014151096344
- 1.0308420443534851
- 1.115704091389974
- 1.0332542157173157
- 1.0155659039815268
- 1.0086765853563944
- 1.077801513671875
- 1.1221555161476136
- 1.1188164385159811
- 1.127112329006195
- 1.0383920240402222
- 1.1248100399971008
- 1.0279105154673258
- 1.1200637976328531
- 1.130852391719818
- 1.1312217036883037
- 1.14094318151474
- 1.0387788693110147
- 1.1039522504806518
- 1.0280646181106567
- 1.1174106295903523
- 1.0156151135762532
- 1.0960908007621766
- 1.1162279653549194
- 1.1195486736297608
- 1.0203672496477763
- 1.0831208984057108
- 1.1071106163660684
- 1.1240452440579731
- 1.1355685432751974
- 1.1538723802566528
- 1.039196039835612
- 1.0013273207346598
- 1.092552401224772
train_accuracy:
- 0.06
- 0.077
- 0.125
- 0.246
- 0.383
- 0.448
- 0.475
- 0.573
- 0.592
- 0.608
- 0.627
- 0.638
- 0.652
- 0.654
- 0.671
- 0.715
- 0.733
- 0.0
- 0.74
- 0.75
- 0.0
- 0.731
- 0.765
- 0.729
- 0.75
- 0.731
- 0.775
- 0.0
- 0.754
- 0.746
- 0.75
- 0.763
- 0.792
- 0.8
- 0.779
- 0.802
- 0.802
- 0.771
- 0.783
- 0.798
- 0.771
- 0.796
- 0.783
- 0.783
- 0.773
- 0.777
- 0.792
- 0.79
- 0.796
- 0.808
- 0.775
- 0.794
- 0.812
- 0.819
- 0.802
- 0.8
- 0.783
- 0.827
- 0.0
- 0.8
- 0.806
- 0.821
- 0.821
- 0.81
- 0.838
- 0.819
- 0.81
- 0.84
- 0.817
- 0.808
- 0.815
- 0.792
- 0.823
- 0.81
- 0.817
- 0.833
- 0.0
- 0.827
- 0.81
- 0.804
- 0.835
- 0.81
- 0.823
- 0.835
- 0.802
- 0.819
- 0.825
- 0.819
- 0.838
- 0.812
- 0.804
- 0.819
- 0.81
- 0.835
- 0.817
- 0.817
- 0.806
- 0.842
- 0.815
- 0.812
train_loss:
- 3.841
- 3.373
- 3.734
- 3.558
- 2.811
- 2.542
- 2.328
- 2.556
- 2.392
- 2.264
- 1.87
- 1.8
- 1.726
- 1.669
- 1.881
- 1.836
- 1.553
- 1.515
- 1.715
- 1.672
- 1.43
- 1.404
- 1.59
- 1.372
- 1.342
- 1.309
- 1.498
- 1.302
- 1.47
- 1.46
- 1.445
- 1.436
- 1.407
- 1.213
- 1.396
- 1.185
- 1.38
- 1.165
- 1.159
- 1.338
- 1.153
- 1.14
- 1.125
- 1.31
- 1.296
- 1.283
- 1.268
- 1.27
- 1.266
- 1.085
- 1.082
- 1.255
- 1.239
- 1.23
- 1.223
- 1.075
- 1.05
- 1.037
- 1.032
- 1.035
- 1.035
- 1.021
- 1.037
- 1.195
- 1.175
- 1.023
- 1.014
- 1.01
- 1.172
- 1.012
- 0.996
- 0.998
- 1.178
- 1.159
- 1.145
- 1.147
- 0.99
- 1.15
- 0.994
- 1.142
- 1.13
- 1.13
- 1.128
- 0.967
- 1.133
- 0.971
- 1.111
- 0.961
- 1.107
- 1.095
- 1.108
- 0.952
- 1.118
- 1.086
- 1.098
- 1.091
- 1.092
- 0.947
- 0.948
- 1.079
unequal: 0
verbose: 1
