avg_train_accuracy: 0.833
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03170212765957447
- 0.04
- 0.1102659574468085
- 0.1947872340425532
- 0.31718085106382976
- 0.4023404255319149
- 0.4617553191489362
- 0.5018617021276596
- 0.5343085106382979
- 0.5564893617021277
- 0.5701595744680851
- 0.5827127659574468
- 0.5943617021276596
- 0.6054255319148936
- 0.6175531914893617
- 0.6245744680851064
- 0.6280851063829788
- 0.6404255319148936
- 0.6470744680851064
- 0.6497872340425532
- 0.66
- 0.6610106382978723
- 0.6656382978723404
- 0.6704787234042553
- 0.6770744680851064
- 0.678031914893617
- 0.6852659574468085
- 0.686595744680851
- 0.6895212765957447
- 0.6913297872340426
- 0.6930851063829787
- 0.6979255319148936
- 0.7018085106382979
- 0.7022872340425532
- 0.7047872340425532
- 0.7088829787234042
- 0.7076595744680851
- 0.7105851063829787
- 0.7135106382978723
- 0.7138297872340426
- 0.7168617021276595
- 0.7162765957446808
- 0.7168085106382979
- 0.7188297872340426
- 0.7223936170212766
- 0.722872340425532
- 0.7245744680851064
- 0.7255851063829787
- 0.7283510638297872
- 0.728563829787234
- 0.731436170212766
- 0.7303191489361702
- 0.7302127659574468
- 0.734095744680851
- 0.7354255319148936
- 0.7373404255319149
- 0.7397872340425532
- 0.7410638297872341
- 0.7393617021276596
- 0.7414893617021276
- 0.7418617021276596
- 0.7407978723404255
- 0.7437765957446808
- 0.7477127659574468
- 0.7471276595744681
- 0.7460638297872341
- 0.7479255319148936
- 0.7461170212765957
- 0.7471276595744681
- 0.7460638297872341
- 0.7467553191489362
- 0.7497872340425532
- 0.7512234042553192
- 0.7515425531914893
- 0.7507446808510638
- 0.7528191489361702
- 0.7525
- 0.7523936170212766
- 0.7526063829787234
- 0.7570744680851064
- 0.756436170212766
- 0.7556914893617022
- 0.7567021276595745
- 0.7571808510638298
- 0.7587234042553191
- 0.7584574468085107
- 0.7561170212765957
- 0.7564893617021277
- 0.7598936170212766
- 0.7562765957446809
- 0.7589893617021276
- 0.7593085106382979
- 0.7588829787234043
- 0.7632978723404256
- 0.762127659574468
- 0.7591489361702127
- 0.7642553191489362
- 0.7619148936170212
- 0.7628723404255319
- 0.7631914893617021
test_loss_list:
- 3.772655204137166
- 3.729958979288737
- 3.6001625219980875
- 3.316988786061605
- 2.9514177894592284
- 2.6193454519907635
- 2.3921933587392172
- 2.2181864261627195
- 2.0891008154551187
- 2.006232582728068
- 1.9104190397262573
- 1.8315663290023805
- 1.7450980456670124
- 1.739138797124227
- 1.7055392058690388
- 1.676942752202352
- 1.6013989814122518
- 1.6083687289555868
- 1.5945264387130738
- 1.511511518160502
- 1.5329626448949178
- 1.4577617168426513
- 1.424896092414856
- 1.393392235438029
- 1.360070382754008
- 1.3467532793680828
- 1.3854047520955404
- 1.3861825704574584
- 1.3057709582646688
- 1.2902085161209107
- 1.2709649244944254
- 1.234006994565328
- 1.2951362387339274
- 1.227916607062022
- 1.19959552526474
- 1.2665341679255169
- 1.1902982385953267
- 1.181539270877838
- 1.2338429737091063
- 1.1666773255666096
- 1.150979065100352
- 1.1349920439720154
- 1.1248032307624818
- 1.1169581802686055
- 1.101363570690155
- 1.0883267100652059
- 1.0871931648254394
- 1.0837704292933146
- 1.1418092648188274
- 1.0766512616475423
- 1.1398469519615173
- 1.1576743078231813
- 1.0825023476282756
- 1.1380190936724346
- 1.0713078959782918
- 1.1331556097666422
- 1.1434531633059184
- 1.1546957008043925
- 1.0819434706370037
- 1.131303555170695
- 1.1412598013877868
- 1.0736844817797342
- 1.0440083742141724
- 1.1042858131726583
- 1.1150631229082744
- 1.0471280256907145
- 1.1134917728106182
- 1.0360817797978719
- 1.0210438656806946
- 1.013286035855611
- 0.9932873551050821
- 1.0596289229393006
- 1.0800737698872884
- 1.088662756284078
- 1.0155913750330607
- 1.0028243136405945
- 1.068927185535431
- 0.9919897039731344
- 0.9757942700386047
- 1.040298135280609
- 0.9744032843907674
- 0.9570231509208679
- 1.0280938204129537
- 1.0471924002965292
- 1.0518168886502584
- 1.054843491713206
- 0.9945148801803589
- 1.0493017911911011
- 1.058981302579244
- 0.9877687390645346
- 1.04779851992925
- 0.982236967086792
- 0.9582857092221578
- 1.0141820581754049
- 0.9542229294776916
- 0.9336378701527913
- 1.0092929633458456
- 0.9379110566775004
- 0.9253988480567932
- 0.9895112037658691
train_accuracy:
- 0.0
- 0.052
- 0.133
- 0.206
- 0.319
- 0.45
- 0.523
- 0.533
- 0.556
- 0.608
- 0.0
- 0.625
- 0.644
- 0.662
- 0.646
- 0.702
- 0.675
- 0.719
- 0.715
- 0.694
- 0.713
- 0.731
- 0.74
- 0.719
- 0.735
- 0.775
- 0.754
- 0.76
- 0.769
- 0.0
- 0.769
- 0.758
- 0.767
- 0.752
- 0.0
- 0.775
- 0.775
- 0.777
- 0.769
- 0.79
- 0.785
- 0.775
- 0.779
- 0.79
- 0.773
- 0.779
- 0.792
- 0.79
- 0.783
- 0.0
- 0.785
- 0.81
- 0.81
- 0.796
- 0.806
- 0.808
- 0.812
- 0.796
- 0.806
- 0.808
- 0.81
- 0.808
- 0.794
- 0.806
- 0.821
- 0.821
- 0.798
- 0.829
- 0.819
- 0.831
- 0.823
- 0.802
- 0.8
- 0.817
- 0.823
- 0.823
- 0.84
- 0.846
- 0.827
- 0.844
- 0.81
- 0.819
- 0.819
- 0.806
- 0.804
- 0.827
- 0.0
- 0.821
- 0.844
- 0.825
- 0.85
- 0.0
- 0.802
- 0.831
- 0.856
- 0.829
- 0.856
- 0.821
- 0.825
- 0.833
train_loss:
- 3.256
- 3.818
- 3.746
- 3.572
- 3.293
- 2.549
- 2.775
- 2.197
- 2.449
- 2.305
- 1.89
- 1.803
- 1.752
- 2.002
- 1.937
- 1.899
- 1.595
- 1.813
- 1.78
- 1.499
- 1.723
- 1.438
- 1.411
- 1.385
- 1.375
- 1.344
- 1.577
- 1.562
- 1.33
- 1.303
- 1.288
- 1.27
- 1.475
- 1.238
- 1.228
- 1.421
- 1.24
- 1.212
- 1.407
- 1.188
- 1.18
- 1.173
- 1.161
- 1.146
- 1.147
- 1.149
- 1.13
- 1.114
- 1.321
- 1.098
- 1.317
- 1.312
- 1.118
- 1.295
- 1.092
- 1.262
- 1.268
- 1.26
- 1.075
- 1.248
- 1.251
- 1.053
- 1.06
- 1.232
- 1.235
- 1.06
- 1.225
- 1.044
- 1.017
- 1.022
- 1.01
- 1.197
- 1.182
- 1.184
- 1.021
- 0.994
- 1.163
- 1.014
- 1.0
- 1.15
- 0.981
- 0.992
- 1.165
- 1.141
- 1.154
- 1.155
- 0.981
- 1.137
- 1.147
- 0.99
- 1.122
- 0.972
- 0.956
- 1.12
- 0.95
- 0.95
- 1.104
- 0.964
- 0.946
- 1.111
unequal: 0
verbose: 1
