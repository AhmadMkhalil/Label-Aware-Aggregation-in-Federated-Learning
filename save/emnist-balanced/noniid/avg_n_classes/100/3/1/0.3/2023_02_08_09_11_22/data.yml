avg_train_accuracy: 0.0
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.036170212765957444
- 0.051382978723404256
- 0.0848404255319149
- 0.16627659574468084
- 0.31196808510638296
- 0.4252659574468085
- 0.48531914893617023
- 0.5240957446808511
- 0.5495212765957447
- 0.5728723404255319
- 0.5854255319148937
- 0.6042021276595745
- 0.618563829787234
- 0.6231382978723404
- 0.6314893617021277
- 0.6437234042553192
- 0.646595744680851
- 0.6571276595744681
- 0.6604255319148936
- 0.6660106382978723
- 0.67
- 0.673031914893617
- 0.6785638297872341
- 0.68
- 0.6825
- 0.6840957446808511
- 0.6906914893617021
- 0.688404255319149
- 0.6940957446808511
- 0.6966489361702127
- 0.698936170212766
- 0.6973404255319149
- 0.7035106382978723
- 0.7077659574468085
- 0.7067021276595745
- 0.7074468085106383
- 0.7107978723404256
- 0.7120212765957447
- 0.7152127659574468
- 0.7131914893617022
- 0.7179787234042553
- 0.7184574468085106
- 0.7190425531914894
- 0.7225
- 0.7220212765957447
- 0.7258510638297873
- 0.7243617021276596
- 0.7276595744680852
- 0.7292021276595745
- 0.7320212765957447
- 0.7304787234042553
- 0.7306914893617021
- 0.7302127659574468
- 0.7339893617021277
- 0.7320212765957447
- 0.7373404255319149
- 0.7368617021276596
- 0.7405851063829787
- 0.7384574468085107
- 0.7368085106382979
- 0.7386170212765958
- 0.7423936170212766
- 0.7426595744680851
- 0.7468085106382979
- 0.7416489361702128
- 0.7462765957446809
- 0.7435106382978723
- 0.7498936170212765
- 0.7446276595744681
- 0.7452127659574468
- 0.7472340425531915
- 0.7482446808510639
- 0.7493085106382978
- 0.7489893617021277
- 0.7506914893617022
- 0.7474468085106383
- 0.7480851063829788
- 0.750904255319149
- 0.7506382978723404
- 0.7539361702127659
- 0.7526063829787234
- 0.7546276595744681
- 0.7540425531914894
- 0.7532978723404256
- 0.7540425531914894
- 0.756436170212766
- 0.757127659574468
- 0.7568085106382979
- 0.7575
- 0.7584574468085107
- 0.7565425531914893
- 0.7579255319148936
- 0.7598936170212766
- 0.7606382978723404
- 0.7606914893617022
- 0.7590425531914894
- 0.7604787234042554
- 0.7618085106382979
- 0.7621808510638298
- 0.7600531914893617
test_loss_list:
- 3.7906065050760906
- 3.7694072850545246
- 3.7146435165405274
- 3.543941354751587
- 3.236918509801229
- 2.821934337615967
- 2.4857825247446694
- 2.2554151980082193
- 2.1088572772343954
- 2.0084679238001506
- 1.9057496945063273
- 1.8595523738861084
- 1.805174954732259
- 1.7325975052515665
- 1.7252508274714151
- 1.7028474267323812
- 1.691047984759013
- 1.6646587419509888
- 1.6552579816182453
- 1.6403910827636718
- 1.6412474711736043
- 1.541024465560913
- 1.5777752828598022
- 1.5702126026153564
- 1.4937120707829794
- 1.5623851792017618
- 1.5394133965174357
- 1.4560337527592977
- 1.5082339970270793
- 1.431013250350952
- 1.3738589255015055
- 1.3540372069676716
- 1.4134613180160522
- 1.4127700328826904
- 1.411651759147644
- 1.4227560170491536
- 1.436787052154541
- 1.4358044465382893
- 1.4329891729354858
- 1.444841775894165
- 1.4237155326207478
- 1.4263369369506835
- 1.4215220260620116
- 1.4351419035593669
- 1.4240509796142578
- 1.3244933414459228
- 1.3121999231974284
- 1.3507247638702393
- 1.36907084941864
- 1.3784277439117432
- 1.377708026568095
- 1.3623579518000284
- 1.2720180932680767
- 1.3440984280904134
- 1.3605251868565877
- 1.361686676343282
- 1.3473672739664713
- 1.3604056056340534
- 1.3568345324198405
- 1.384416176478068
- 1.3820286258061727
- 1.3662280384699503
- 1.3909100532531737
- 1.3782258145014445
- 1.2682387280464171
- 1.3365865699450175
- 1.343972195784251
- 1.2273977287610371
- 1.2081753913561504
- 1.1963852326075235
- 1.2633959396680197
- 1.267245598634084
- 1.2824072217941285
- 1.1794661259651185
- 1.1339252559343973
- 1.2397328559557597
- 1.2458070421218872
- 1.2419835424423218
- 1.2531500705083212
- 1.2444047888120016
- 1.2629610912005107
- 1.2679863206545512
- 1.2666359972953796
- 1.2739257462819418
- 1.1636955229441326
- 1.2403938166300457
- 1.2716994778315227
- 1.2538187305132549
- 1.25941064675649
- 1.2714326810836791
- 1.2637638815244039
- 1.271832493940989
- 1.174901377360026
- 1.229968721071879
- 1.2579126071929931
- 1.1383751861254374
- 1.1205047082901
- 1.0961311173439026
- 1.0814812541007996
- 1.0615070756276448
train_accuracy:
- 0.035
- 0.052
- 0.096
- 0.185
- 0.34
- 0.485
- 0.55
- 0.592
- 0.606
- 0.61
- 0.6
- 0.658
- 0.658
- 0.679
- 0.696
- 0.708
- 0.713
- 0.696
- 0.704
- 0.694
- 0.719
- 0.0
- 0.723
- 0.74
- 0.723
- 0.702
- 0.752
- 0.0
- 0.763
- 0.0
- 0.0
- 0.769
- 0.76
- 0.777
- 0.763
- 0.735
- 0.798
- 0.769
- 0.775
- 0.79
- 0.787
- 0.754
- 0.777
- 0.767
- 0.79
- 0.0
- 0.8
- 0.767
- 0.783
- 0.775
- 0.802
- 0.796
- 0.802
- 0.802
- 0.785
- 0.796
- 0.792
- 0.796
- 0.79
- 0.8
- 0.773
- 0.781
- 0.794
- 0.808
- 0.0
- 0.806
- 0.8
- 0.79
- 0.815
- 0.0
- 0.802
- 0.802
- 0.787
- 0.0
- 0.792
- 0.819
- 0.81
- 0.767
- 0.8
- 0.792
- 0.806
- 0.808
- 0.821
- 0.821
- 0.0
- 0.802
- 0.783
- 0.819
- 0.815
- 0.819
- 0.812
- 0.794
- 0.0
- 0.8
- 0.817
- 0.833
- 0.823
- 0.806
- 0.806
- 0.0
train_loss:
- 3.847
- 3.825
- 3.79
- 2.994
- 3.509
- 3.183
- 2.868
- 2.633
- 2.417
- 2.286
- 1.765
- 2.072
- 1.997
- 1.543
- 1.881
- 1.836
- 1.774
- 1.736
- 1.725
- 1.663
- 1.626
- 1.338
- 1.595
- 1.618
- 1.288
- 1.524
- 1.559
- 1.245
- 1.51
- 1.184
- 1.175
- 1.164
- 1.449
- 1.439
- 1.425
- 1.422
- 1.405
- 1.376
- 1.39
- 1.355
- 1.377
- 1.357
- 1.363
- 1.338
- 1.353
- 1.109
- 1.071
- 1.313
- 1.299
- 1.302
- 1.289
- 1.284
- 1.037
- 1.287
- 1.255
- 1.27
- 1.257
- 1.242
- 1.243
- 1.247
- 1.228
- 1.226
- 1.223
- 1.211
- 1.017
- 1.226
- 1.199
- 1.006
- 0.961
- 0.95
- 1.192
- 1.193
- 1.182
- 0.958
- 0.937
- 1.17
- 1.158
- 1.155
- 1.149
- 1.155
- 1.138
- 1.139
- 1.167
- 1.145
- 0.945
- 1.132
- 1.132
- 1.134
- 1.144
- 1.119
- 1.1
- 1.115
- 0.924
- 1.135
- 1.117
- 0.926
- 0.882
- 0.891
- 0.864
- 0.857
unequal: 0
verbose: 1
