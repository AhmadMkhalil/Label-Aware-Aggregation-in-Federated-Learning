avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04425531914893617
- 0.045904255319148934
- 0.08319148936170213
- 0.1949468085106383
- 0.30186170212765956
- 0.35904255319148937
- 0.3952127659574468
- 0.42686170212765956
- 0.44898936170212767
- 0.4570212765957447
- 0.48781914893617023
- 0.49632978723404253
- 0.5089893617021276
- 0.5162765957446809
- 0.5123936170212766
- 0.5361702127659574
- 0.5492553191489362
- 0.5606382978723404
- 0.5632978723404255
- 0.5686170212765957
- 0.5781382978723404
- 0.5786702127659574
- 0.5922340425531915
- 0.5878723404255319
- 0.5939893617021277
- 0.5976595744680852
- 0.5987765957446809
- 0.6068085106382979
- 0.6142553191489362
- 0.6132446808510639
- 0.6202659574468085
- 0.6130851063829788
- 0.621968085106383
- 0.6277127659574468
- 0.6274468085106383
- 0.6339893617021276
- 0.6353191489361703
- 0.6360106382978723
- 0.6397872340425532
- 0.6445744680851064
- 0.6418085106382979
- 0.6424468085106383
- 0.6478191489361702
- 0.6510638297872341
- 0.6506914893617022
- 0.6546276595744681
- 0.6540425531914894
- 0.6558510638297872
- 0.6575
- 0.6575531914893618
- 0.6583510638297873
- 0.6604255319148936
- 0.6633510638297873
- 0.6646808510638298
- 0.6635106382978724
- 0.6664361702127659
- 0.6675531914893617
- 0.6697872340425531
- 0.6618617021276596
- 0.6711170212765958
- 0.6715425531914894
- 0.6745212765957447
- 0.6718085106382978
- 0.6748404255319149
- 0.6717553191489362
- 0.6745212765957447
- 0.6742553191489362
- 0.6733510638297873
- 0.6727659574468086
- 0.6775
- 0.6748936170212766
- 0.5873936170212766
- 0.6762234042553191
- 0.680531914893617
- 0.681595744680851
- 0.6823404255319149
- 0.679468085106383
- 0.6828191489361702
- 0.680531914893617
- 0.6835106382978723
- 0.6825
- 0.6842553191489362
- 0.6855851063829788
- 0.6848404255319149
- 0.6861702127659575
- 0.6855851063829788
- 0.6840425531914893
- 0.6877127659574468
- 0.685
- 0.6880851063829787
- 0.6862234042553191
- 0.6863297872340426
- 0.6902127659574468
- 0.6845212765957447
- 0.6864893617021277
- 0.6865425531914894
- 0.6896808510638298
- 0.6877659574468085
- 0.69
- 0.6871808510638298
test_loss_list:
- 3.782919012705485
- 3.7543271827697753
- 3.6653719266255695
- 3.437630100250244
- 3.1365985361735027
- 2.942260030110677
- 2.801315565109253
- 2.697680441538493
- 2.6084494749704996
- 2.547459446589152
- 2.5122499561309812
- 2.451245387395223
- 2.4140235392252603
- 2.3623313522338867
- 2.3564037704467773
- 2.338803071975708
- 2.2929304091135663
- 2.299158368110657
- 2.2525878938039146
- 2.231731282869975
- 2.216613144874573
- 2.1917005936304728
- 2.241527600288391
- 2.168478954633077
- 2.1616137425104776
- 2.1225478712717694
- 2.101510999997457
- 2.140857357978821
- 2.15820689201355
- 2.0818036206563315
- 2.0999693314234418
- 2.0319434785842896
- 2.068882261912028
- 2.0484779691696167
- 2.0439242537816367
- 2.012036099433899
- 2.002791558901469
- 1.9754402430852254
- 2.015899887084961
- 2.0067572100957234
- 1.9470164982477824
- 1.940427419344584
- 1.9441768836975097
- 1.9268202384312947
- 1.8963954369227092
- 1.9132597414652506
- 1.8753246434529622
- 1.892456111907959
- 1.8784965658187867
- 1.8458629846572876
- 1.8116211700439453
- 1.831588093439738
- 1.816774417559306
- 1.8181546831130981
- 1.8053274615605672
- 1.8172857252756756
- 1.8320506779352823
- 1.8077198696136474
- 1.7393033758799235
- 1.7993449115753173
- 1.7951563215255737
- 1.8226093975702922
- 1.7589313427607218
- 1.789138394991557
- 1.7656666819254558
- 1.7593072080612182
- 1.7370192035039267
- 1.7278417650858562
- 1.7112233797709147
- 1.7276183128356934
- 1.7182859245936075
- 1.377573823928833
- 1.434079392751058
- 1.550884666442871
- 1.5569677448272705
- 1.5849806213378905
- 1.5762064266204834
- 1.583741364479065
- 1.5540957864125569
- 1.58217244942983
- 1.5778173112869263
- 1.5440719890594483
- 1.6080305608113608
- 1.5835131057103475
- 1.601185139020284
- 1.583317724863688
- 1.5500208234786987
- 1.5751272741953533
- 1.5556211058298748
- 1.5847081279754638
- 1.5616004610061645
- 1.564049924214681
- 1.575908997853597
- 1.5299365250269572
- 1.5256558879216513
- 1.5421751610438028
- 1.545980717341105
- 1.524026838938395
- 1.510738828976949
- 1.5291186650594075
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.498
- 0.542
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.583
- 0.627
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.7
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.777
- 0.0
- 0.0
- 0.727
- 0.0
- 0.742
- 0.0
- 0.75
- 0.752
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.748
- 0.0
- 0.731
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.76
- 0.785
- 0.758
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.779
- 0.838
- 0.833
- 0.0
- 0.0
- 0.0
- 0.277
- 0.0
- 0.804
- 0.775
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.785
- 0.0
- 0.79
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.852
- 0.0
train_loss:
- 1.379
- 1.83
- 1.77
- 1.668
- 1.08
- 0.984
- 0.923
- 0.876
- 0.843
- 0.495
- 1.082
- 0.76
- 0.75
- 0.728
- 0.449
- 0.689
- 0.697
- 0.921
- 0.431
- 0.645
- 0.633
- 0.635
- 0.855
- 0.418
- 0.617
- 0.628
- 0.603
- 0.594
- 0.787
- 0.4
- 0.574
- 0.39
- 0.567
- 0.571
- 0.568
- 0.746
- 0.567
- 0.553
- 0.544
- 0.714
- 0.547
- 0.368
- 0.528
- 0.52
- 0.525
- 0.512
- 0.347
- 0.505
- 0.675
- 0.504
- 0.502
- 0.492
- 0.483
- 0.641
- 0.49
- 0.63
- 0.629
- 0.627
- 0.334
- 0.619
- 0.617
- 0.615
- 0.47
- 0.605
- 0.319
- 0.609
- 0.465
- 0.455
- 0.306
- 0.591
- 0.452
- 0.169
- 0.396
- 0.564
- 0.567
- 0.568
- 0.288
- 0.567
- 0.427
- 0.422
- 0.287
- 0.286
- 0.554
- 0.417
- 0.546
- 0.421
- 0.422
- 0.542
- 0.416
- 0.543
- 0.413
- 0.408
- 0.536
- 0.289
- 0.406
- 0.4
- 0.541
- 0.407
- 0.406
- 0.404
unequal: 0
verbose: 1
