avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.051117021276595745
- 0.07228723404255319
- 0.13840425531914893
- 0.29164893617021276
- 0.36840425531914894
- 0.41388297872340424
- 0.4480851063829787
- 0.4702127659574468
- 0.48861702127659573
- 0.5139893617021276
- 0.527127659574468
- 0.5296808510638298
- 0.5324468085106383
- 0.5484574468085106
- 0.5542553191489362
- 0.5660106382978723
- 0.5697340425531915
- 0.5740425531914893
- 0.5878723404255319
- 0.5767553191489362
- 0.5938829787234042
- 0.6021808510638298
- 0.6012234042553192
- 0.6063829787234043
- 0.6064893617021276
- 0.6037765957446809
- 0.6175
- 0.620531914893617
- 0.621436170212766
- 0.6222340425531915
- 0.6275531914893617
- 0.6292021276595745
- 0.6336702127659575
- 0.6346808510638298
- 0.6361170212765958
- 0.6388829787234043
- 0.6370744680851064
- 0.6452659574468085
- 0.6408510638297872
- 0.6462765957446809
- 0.6482978723404256
- 0.6498404255319149
- 0.6444148936170213
- 0.6485106382978724
- 0.6497340425531914
- 0.6531382978723405
- 0.6523936170212766
- 0.6543085106382979
- 0.6503191489361703
- 0.6540425531914894
- 0.6584042553191489
- 0.6587234042553192
- 0.6587234042553192
- 0.6612234042553191
- 0.6527127659574468
- 0.6626063829787234
- 0.6621276595744681
- 0.6618085106382978
- 0.660372340425532
- 0.6572340425531915
- 0.6643085106382979
- 0.6661702127659574
- 0.6689893617021276
- 0.6659574468085107
- 0.6667021276595745
- 0.6708510638297872
- 0.6659574468085107
- 0.6703191489361702
- 0.6697872340425531
- 0.6698404255319149
- 0.6688297872340425
- 0.6718085106382978
- 0.6711170212765958
- 0.6662234042553191
- 0.6748936170212766
- 0.6755851063829788
- 0.6740957446808511
- 0.6752127659574468
- 0.6745212765957447
- 0.6747340425531915
- 0.6729787234042554
- 0.6772872340425532
- 0.6801063829787234
- 0.6747872340425531
- 0.6794148936170212
- 0.6752659574468085
- 0.6769148936170213
- 0.6768617021276596
- 0.6804787234042553
- 0.6814893617021277
- 0.6826063829787234
- 0.6822340425531915
- 0.6823936170212765
- 0.6823404255319149
- 0.6776595744680851
- 0.6852127659574468
- 0.6826063829787234
- 0.6867553191489362
- 0.6843617021276596
- 0.686968085106383
test_loss_list:
- 3.7737720680236815
- 3.7132344881693524
- 3.5096907138824465
- 3.1683122221628826
- 2.894276425043742
- 2.701973657608032
- 2.576216449737549
- 2.5049677499135337
- 2.441427116394043
- 2.3948848311106365
- 2.356174357732137
- 2.3426522509257
- 2.3059739780426027
- 2.2700611209869384
- 2.2588072061538695
- 2.239365045229594
- 2.202149117787679
- 2.195861519177755
- 2.1997064781188964
- 2.1801019446055094
- 2.1636011664072674
- 2.149753123919169
- 2.136949650446574
- 2.115552740097046
- 2.1204838689168293
- 2.078501485188802
- 2.10872163772583
- 2.0882264693578083
- 2.052886063257853
- 2.038862806955973
- 2.060892980893453
- 2.032424740791321
- 2.0307059478759766
- 2.030600644747416
- 1.9916457335154216
- 2.000276622772217
- 2.0058803097407023
- 1.9978350178400675
- 1.9920323340098063
- 1.9868146006266276
- 1.9697159592310587
- 1.9779961395263672
- 1.9482452440261842
- 1.9197887881596882
- 1.863214635848999
- 1.9097025378545125
- 1.8944556872049967
- 1.8721463362375894
- 1.883429282506307
- 1.8857598431905112
- 1.8741662168502808
- 1.8660069131851196
- 1.8191979646682739
- 1.8518943834304809
- 1.784185800552368
- 1.8404267311096192
- 1.8173151302337647
- 1.8257503032684326
- 1.8026223436991373
- 1.7662270450592041
- 1.8159443775812785
- 1.7969794050852457
- 1.7784136819839478
- 1.7783252207438152
- 1.7539054250717163
- 1.765795553525289
- 1.7550136788686117
- 1.7499890486399332
- 1.7500807460149128
- 1.7263156048456827
- 1.718849809964498
- 1.734014557202657
- 1.6973567374547323
- 1.6723095719019572
- 1.7031408580144247
- 1.6978708473841349
- 1.696782169342041
- 1.6563915999730427
- 1.6791309849421183
- 1.6815382623672486
- 1.6860686667760214
- 1.6588840468724568
- 1.6690823427836101
- 1.6650958681106567
- 1.6489879035949706
- 1.645036940574646
- 1.6303441683451334
- 1.5980231666564941
- 1.6453885793685914
- 1.632207644780477
- 1.611761096318563
- 1.6036786905924478
- 1.5957819509506226
- 1.6174421644210815
- 1.595811398824056
- 1.563183938662211
- 1.576768372853597
- 1.6164071194330851
- 1.5556196435292562
- 1.5506356048583985
train_accuracy:
- 0.056
- 0.0
- 0.0
- 0.0
- 0.417
- 0.0
- 0.0
- 0.546
- 0.594
- 0.602
- 0.642
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.652
- 0.0
- 0.725
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.696
- 0.0
- 0.0
- 0.0
- 0.754
- 0.0
- 0.0
- 0.0
- 0.771
- 0.0
- 0.729
- 0.0
- 0.746
- 0.787
- 0.0
- 0.723
- 0.0
- 0.796
- 0.0
- 0.792
- 0.0
- 0.808
- 0.0
- 0.798
- 0.0
- 0.0
- 0.756
- 0.798
- 0.0
- 0.0
- 0.746
- 0.771
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.804
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.783
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.81
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.0
train_loss:
- 1.904
- 1.355
- 0.754
- 1.103
- 0.986
- 0.912
- 0.856
- 0.815
- 0.778
- 0.77
- 1.015
- 0.463
- 0.448
- 0.693
- 0.68
- 0.665
- 0.66
- 0.422
- 0.865
- 0.411
- 0.633
- 0.619
- 0.614
- 0.609
- 0.59
- 0.406
- 0.781
- 0.598
- 0.589
- 0.394
- 0.769
- 0.571
- 0.568
- 0.566
- 0.38
- 0.551
- 0.555
- 0.723
- 0.537
- 0.532
- 0.535
- 0.703
- 0.537
- 0.528
- 0.366
- 0.511
- 0.523
- 0.519
- 0.347
- 0.504
- 0.666
- 0.667
- 0.35
- 0.651
- 0.344
- 0.644
- 0.511
- 0.487
- 0.333
- 0.337
- 0.639
- 0.48
- 0.484
- 0.474
- 0.334
- 0.47
- 0.473
- 0.62
- 0.47
- 0.463
- 0.455
- 0.607
- 0.316
- 0.318
- 0.592
- 0.315
- 0.45
- 0.45
- 0.447
- 0.437
- 0.454
- 0.44
- 0.588
- 0.433
- 0.574
- 0.302
- 0.3
- 0.294
- 0.565
- 0.432
- 0.43
- 0.418
- 0.431
- 0.563
- 0.283
- 0.295
- 0.417
- 0.544
- 0.293
- 0.42
unequal: 0
verbose: 1
