avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.034840425531914895
- 0.11547872340425532
- 0.20063829787234042
- 0.2951595744680851
- 0.37792553191489364
- 0.43361702127659574
- 0.46882978723404256
- 0.48138297872340424
- 0.5092021276595745
- 0.5217021276595745
- 0.5364361702127659
- 0.5431914893617021
- 0.5541489361702128
- 0.5586702127659574
- 0.5728191489361703
- 0.5784574468085106
- 0.5803191489361702
- 0.5828723404255319
- 0.5896808510638298
- 0.5923936170212766
- 0.6006382978723405
- 0.606063829787234
- 0.6100531914893617
- 0.6158510638297873
- 0.6173404255319149
- 0.6183510638297872
- 0.6222340425531915
- 0.626968085106383
- 0.6287234042553191
- 0.6331914893617021
- 0.6365425531914893
- 0.6390425531914894
- 0.6379255319148937
- 0.6413829787234042
- 0.6415425531914893
- 0.6422340425531915
- 0.6480851063829787
- 0.6491489361702127
- 0.6501063829787234
- 0.6554787234042553
- 0.6542553191489362
- 0.6559574468085106
- 0.659468085106383
- 0.6590425531914894
- 0.6572340425531915
- 0.6628191489361702
- 0.6636702127659575
- 0.6648404255319149
- 0.6674468085106383
- 0.6693085106382979
- 0.6677127659574468
- 0.6698936170212766
- 0.6702127659574468
- 0.6705319148936171
- 0.6675531914893617
- 0.6676063829787234
- 0.671595744680851
- 0.674468085106383
- 0.675531914893617
- 0.6727127659574468
- 0.676595744680851
- 0.6758510638297872
- 0.6811170212765958
- 0.6762765957446808
- 0.6755851063829788
- 0.678031914893617
- 0.679468085106383
- 0.680531914893617
- 0.681595744680851
- 0.6817021276595745
- 0.6829787234042554
- 0.6823936170212765
- 0.6843617021276596
- 0.6832978723404255
- 0.6843085106382979
- 0.683031914893617
- 0.6851063829787234
- 0.6867553191489362
- 0.6859042553191489
- 0.6883510638297873
- 0.6871808510638298
- 0.6877127659574468
- 0.690531914893617
- 0.688031914893617
- 0.6847872340425532
- 0.686063829787234
- 0.6891489361702128
- 0.6894148936170212
- 0.6890957446808511
- 0.691595744680851
- 0.6887765957446809
- 0.6846276595744681
- 0.6917021276595745
- 0.6907446808510638
- 0.6913297872340426
- 0.6920744680851064
- 0.6918617021276596
- 0.6946808510638298
- 0.6907978723404256
- 0.6904787234042553
test_loss_list:
- 3.76879934946696
- 3.6734836673736573
- 3.42657128016154
- 3.0887465318044027
- 2.8600793075561524
- 2.702873503367106
- 2.602831128438314
- 2.500071948369344
- 2.455966256459554
- 2.4111982790629067
- 2.402169672648112
- 2.3401767794291177
- 2.3027526982625326
- 2.3205284118652343
- 2.3255409479141234
- 2.302219867706299
- 2.26925230662028
- 2.2383870283762612
- 2.2132878923416137
- 2.1555160665512085
- 2.190679980913798
- 2.1554400157928466
- 2.186379305521647
- 2.1418586715062458
- 2.1054871606826784
- 2.111530179977417
- 2.1140495347976684
- 2.0585969893137612
- 2.097934096654256
- 2.059456699689229
- 2.0028693596522014
- 2.015931239128113
- 1.98505646387736
- 1.9688871494928997
- 1.987200713157654
- 1.9578808577855429
- 1.9612412071228027
- 1.9717641115188598
- 1.891861522992452
- 1.8876898352305094
- 1.921969108581543
- 1.8796895122528077
- 1.8875154002507528
- 1.9007735617955526
- 1.8603155899047852
- 1.8348295291264851
- 1.8849875179926554
- 1.8401221291224161
- 1.8896300061543783
- 1.8595635191599529
- 1.8216705497105916
- 1.8246324857076008
- 1.8241410716374715
- 1.836313977241516
- 1.8002820301055908
- 1.75569721698761
- 1.7228653875986735
- 1.7591575479507446
- 1.761284515062968
- 1.7420241705576578
- 1.7560051075617473
- 1.7502760950724283
- 1.764076166152954
- 1.7259253883361816
- 1.7101698954900106
- 1.723075613975525
- 1.7174549643198649
- 1.6917175690333048
- 1.7068160168329876
- 1.6930765724182129
- 1.669093262354533
- 1.6923402468363444
- 1.6952552811304729
- 1.683164463043213
- 1.680884648958842
- 1.6810040728251139
- 1.6527045329411825
- 1.6540274302164713
- 1.6625585826237996
- 1.6678155247370403
- 1.6280598068237304
- 1.6080898062388103
- 1.6313666089375813
- 1.6236158307393391
- 1.5723928038279216
- 1.6108650970458984
- 1.5729670206705728
- 1.589210565884908
- 1.5988225428263347
- 1.604892717997233
- 1.5952731307347616
- 1.583743896484375
- 1.5650634940465291
- 1.5525897216796876
- 1.5198677078882854
- 1.593756210009257
- 1.5872404352823892
- 1.5595663404464721
- 1.5601134665807088
- 1.548684377670288
train_accuracy:
- 0.0
- 0.142
- 0.21
- 0.0
- 0.0
- 0.494
- 0.0
- 0.54
- 0.6
- 0.0
- 0.0
- 0.0
- 0.0
- 0.658
- 0.0
- 0.0
- 0.0
- 0.696
- 0.683
- 0.0
- 0.717
- 0.0
- 0.0
- 0.0
- 0.713
- 0.0
- 0.729
- 0.771
- 0.729
- 0.758
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.769
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.821
- 0.827
- 0.0
- 0.0
- 0.819
- 0.0
- 0.817
- 0.796
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.0
- 0.8
- 0.0
- 0.0
- 0.0
- 0.0
- 0.823
- 0.804
- 0.831
- 0.0
- 0.0
- 0.825
- 0.0
- 0.8
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.838
- 0.0
- 0.0
- 0.838
- 0.0
- 0.829
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 1.339
- 1.8
- 1.683
- 1.069
- 1.372
- 1.261
- 1.174
- 0.493
- 1.065
- 0.754
- 0.721
- 0.711
- 0.705
- 0.691
- 0.903
- 0.667
- 0.659
- 0.64
- 0.633
- 0.429
- 0.824
- 0.618
- 0.806
- 0.609
- 0.599
- 0.589
- 0.578
- 0.584
- 0.744
- 0.558
- 0.39
- 0.554
- 0.375
- 0.54
- 0.528
- 0.527
- 0.535
- 0.523
- 0.365
- 0.357
- 0.671
- 0.503
- 0.508
- 0.654
- 0.344
- 0.495
- 0.65
- 0.491
- 0.625
- 0.641
- 0.494
- 0.63
- 0.625
- 0.476
- 0.33
- 0.325
- 0.323
- 0.467
- 0.606
- 0.466
- 0.459
- 0.594
- 0.595
- 0.454
- 0.445
- 0.442
- 0.445
- 0.431
- 0.45
- 0.439
- 0.445
- 0.573
- 0.569
- 0.432
- 0.564
- 0.56
- 0.438
- 0.431
- 0.564
- 0.427
- 0.431
- 0.42
- 0.549
- 0.419
- 0.289
- 0.415
- 0.419
- 0.419
- 0.545
- 0.535
- 0.545
- 0.286
- 0.409
- 0.4
- 0.28
- 0.534
- 0.528
- 0.4
- 0.404
- 0.404
unequal: 0
verbose: 1
