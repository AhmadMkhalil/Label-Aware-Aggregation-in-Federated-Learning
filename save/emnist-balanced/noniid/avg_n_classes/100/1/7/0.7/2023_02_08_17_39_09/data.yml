avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04117021276595745
- 0.08175531914893618
- 0.14085106382978724
- 0.24425531914893617
- 0.34324468085106385
- 0.4032978723404255
- 0.4479255319148936
- 0.46430851063829787
- 0.48723404255319147
- 0.49127659574468086
- 0.5121808510638298
- 0.510904255319149
- 0.5282978723404256
- 0.5391489361702128
- 0.5475
- 0.5556914893617021
- 0.564627659574468
- 0.5623404255319149
- 0.5781914893617022
- 0.5757978723404256
- 0.5863297872340425
- 0.588936170212766
- 0.5845212765957447
- 0.5976595744680852
- 0.6048404255319149
- 0.6080851063829787
- 0.6112234042553192
- 0.6123936170212766
- 0.6184042553191489
- 0.6179787234042553
- 0.6131382978723404
- 0.6215425531914893
- 0.6260638297872341
- 0.6248936170212765
- 0.6291489361702127
- 0.628031914893617
- 0.6311170212765957
- 0.6360106382978723
- 0.6392553191489362
- 0.6410106382978723
- 0.6395744680851064
- 0.6447872340425532
- 0.6425
- 0.6481914893617021
- 0.649468085106383
- 0.6487234042553192
- 0.6488829787234043
- 0.6511170212765958
- 0.6536170212765957
- 0.6569680851063829
- 0.6554787234042553
- 0.6555851063829787
- 0.6594148936170213
- 0.6597872340425532
- 0.660904255319149
- 0.6602659574468085
- 0.6621276595744681
- 0.4095744680851064
- 0.6608510638297872
- 0.6651063829787234
- 0.6662234042553191
- 0.6642553191489362
- 0.6671276595744681
- 0.6697872340425531
- 0.6701063829787234
- 0.6707978723404255
- 0.6628723404255319
- 0.671968085106383
- 0.6735106382978724
- 0.6728723404255319
- 0.6720744680851064
- 0.6707446808510639
- 0.6737765957446809
- 0.6707978723404255
- 0.6760106382978723
- 0.6777127659574468
- 0.6771808510638297
- 0.675159574468085
- 0.6776595744680851
- 0.680531914893617
- 0.6778723404255319
- 0.6784042553191489
- 0.6823404255319149
- 0.6814893617021277
- 0.681595744680851
- 0.6806382978723404
- 0.6838829787234042
- 0.6829787234042554
- 0.6841489361702128
- 0.6843617021276596
- 0.6842021276595744
- 0.6826595744680851
- 0.6861702127659575
- 0.6852127659574468
- 0.6871808510638298
- 0.6851063829787234
- 0.6868085106382978
- 0.6893617021276596
- 0.6841489361702128
- 0.681595744680851
test_loss_list:
- 3.774538507461548
- 3.705589329401652
- 3.5433144124348956
- 3.3082556692759195
- 3.0353661982218423
- 2.8467777093251545
- 2.735892972946167
- 2.665827760696411
- 2.5855774370829265
- 2.560292879740397
- 2.5024659474690756
- 2.4810061581929523
- 2.4613727696736656
- 2.405372486114502
- 2.401644140879313
- 2.409326130549113
- 2.3687872250874835
- 2.3296348571777346
- 2.373037004470825
- 2.355431470870972
- 2.2709361044565837
- 2.2570579719543455
- 2.21828776995341
- 2.2696618254979453
- 2.255629164377848
- 2.2443188047409057
- 2.2917405780156455
- 2.2082488854726154
- 2.2319403457641602
- 2.210015579859416
- 2.14682421207428
- 2.246718530654907
- 2.2225591214497884
- 2.188516206741333
- 2.159066958427429
- 2.1543098862965904
- 2.1194886191685995
- 2.0928750038146973
- 2.1281243324279786
- 2.111249154408773
- 2.048985104560852
- 2.0884767055511473
- 2.0911983569463093
- 2.0503214168548585
- 2.0490197388331097
- 2.0630276234944662
- 2.039993124008179
- 2.0044082164764405
- 2.0316178957621256
- 2.0177928002675376
- 1.968225523630778
- 1.9416450468699138
- 1.9577493143081666
- 1.9772978003819783
- 1.933272344271342
- 1.922551104227702
- 1.917191530863444
- 2.0377059094111125
- 1.644595781962077
- 1.7364124409357706
- 1.8087950293223063
- 1.7810623502731324
- 1.7369582811991373
- 1.7677811749776204
- 1.7705912971496582
- 1.7732018756866454
- 1.7285464493433635
- 1.7861545356114705
- 1.7846394697825114
- 1.7544853973388672
- 1.7813654549916584
- 1.7217935482660929
- 1.7296237071355185
- 1.7041941658655801
- 1.704516528447469
- 1.704572410583496
- 1.6938004557291666
- 1.7149695205688475
- 1.699983057975769
- 1.7318099721272786
- 1.685312754313151
- 1.6689371538162232
- 1.7068340094884236
- 1.69240647315979
- 1.6597390286127727
- 1.655288438796997
- 1.6767172813415527
- 1.6645594215393067
- 1.6569278701146444
- 1.636535669962565
- 1.6873633464177449
- 1.6828239854176839
- 1.67279043674469
- 1.6768694178263346
- 1.6444465970993043
- 1.678572670618693
- 1.6575453503926596
- 1.6714247496922812
- 1.6699915011723836
- 1.6387608782450358
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.388
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.612
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.717
- 0.0
- 0.696
- 0.0
- 0.0
- 0.715
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.737
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.767
- 0.773
- 0.0
- 0.0
- 0.771
- 0.76
- 0.769
- 0.0
- 0.0
- 0.0
- 0.785
- 0.777
- 0.0
- 0.0
- 0.0
- 0.854
- 0.0
- 0.787
- 0.796
- 0.0
- 0.798
- 0.0
- 0.0
- 0.0
- 0.0
- 0.8
- 0.0
- 0.0
- 0.8
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.81
- 0.812
- 0.0
- 0.8
- 0.0
- 0.0
- 0.0
- 0.812
- 0.798
- 0.0
- 0.0
- 0.0
- 0.817
- 0.81
- 0.0
- 0.0
- 0.8
- 0.81
- 0.0
- 0.825
- 0.0
train_loss:
- 1.308
- 1.788
- 1.231
- 1.575
- 1.023
- 0.935
- 1.222
- 0.832
- 0.809
- 0.479
- 0.752
- 0.457
- 0.446
- 0.46
- 0.689
- 0.667
- 0.91
- 0.434
- 0.636
- 0.625
- 0.647
- 0.625
- 0.413
- 0.81
- 0.603
- 0.595
- 0.775
- 0.402
- 0.775
- 0.581
- 0.388
- 0.743
- 0.741
- 0.559
- 0.557
- 0.546
- 0.543
- 0.539
- 0.53
- 0.541
- 0.367
- 0.52
- 0.526
- 0.524
- 0.512
- 0.507
- 0.496
- 0.509
- 0.661
- 0.502
- 0.508
- 0.338
- 0.49
- 0.485
- 0.487
- 0.479
- 0.487
- 0.182
- 0.441
- 0.457
- 0.603
- 0.462
- 0.311
- 0.45
- 0.455
- 0.461
- 0.316
- 0.594
- 0.598
- 0.456
- 0.446
- 0.315
- 0.293
- 0.302
- 0.445
- 0.438
- 0.439
- 0.427
- 0.432
- 0.561
- 0.435
- 0.431
- 0.562
- 0.418
- 0.439
- 0.424
- 0.554
- 0.426
- 0.426
- 0.417
- 0.552
- 0.546
- 0.417
- 0.551
- 0.419
- 0.537
- 0.543
- 0.539
- 0.53
- 0.284
unequal: 0
verbose: 1
