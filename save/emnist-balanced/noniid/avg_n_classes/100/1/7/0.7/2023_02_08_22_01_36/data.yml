avg_train_accuracy: 0.808
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.034148936170212765
- 0.05361702127659575
- 0.08648936170212766
- 0.15015957446808512
- 0.2451063829787234
- 0.3321276595744681
- 0.40611702127659577
- 0.4475
- 0.48340425531914893
- 0.5107978723404255
- 0.5233510638297872
- 0.5336170212765957
- 0.5493617021276596
- 0.564627659574468
- 0.5695744680851064
- 0.5746808510638298
- 0.5868617021276595
- 0.2681914893617021
- 0.5901063829787234
- 0.5965957446808511
- 0.603404255319149
- 0.6076595744680852
- 0.6145744680851064
- 0.6185106382978723
- 0.6195212765957446
- 0.6234042553191489
- 0.6301063829787235
- 0.6302127659574468
- 0.6326063829787234
- 0.6390425531914894
- 0.6410106382978723
- 0.6402659574468085
- 0.644468085106383
- 0.6494148936170213
- 0.6499468085106384
- 0.6515425531914893
- 0.6502659574468085
- 0.655
- 0.6552127659574468
- 0.6552659574468085
- 0.6559574468085106
- 0.6604255319148936
- 0.6620744680851064
- 0.6596276595744681
- 0.6646276595744681
- 0.6586702127659575
- 0.6629787234042553
- 0.6664361702127659
- 0.6670212765957447
- 0.6721276595744681
- 0.6688297872340425
- 0.6726063829787234
- 0.6729787234042554
- 0.671968085106383
- 0.668936170212766
- 0.6743085106382979
- 0.6735106382978724
- 0.6713297872340426
- 0.6739893617021276
- 0.6756914893617021
- 0.6787765957446809
- 0.6775
- 0.6777659574468086
- 0.6786702127659574
- 0.6809574468085107
- 0.6823404255319149
- 0.6803191489361702
- 0.680531914893617
- 0.6821276595744681
- 0.6833510638297873
- 0.6828191489361702
- 0.6833510638297873
- 0.680531914893617
- 0.6833510638297873
- 0.6830851063829787
- 0.6840425531914893
- 0.686595744680851
- 0.6852659574468085
- 0.6878723404255319
- 0.6849468085106383
- 0.6835638297872341
- 0.6854255319148936
- 0.6867553191489362
- 0.6878191489361702
- 0.69
- 0.688404255319149
- 0.6887765957446809
- 0.6894148936170212
- 0.6906914893617021
- 0.6904255319148936
- 0.6905851063829788
- 0.6873404255319149
- 0.6912765957446808
- 0.6928191489361702
- 0.6902659574468085
- 0.688936170212766
- 0.6878191489361702
- 0.6913829787234043
- 0.6911702127659575
- 0.6919148936170213
test_loss_list:
- 3.7882233587900798
- 3.754908390045166
- 3.6557074769337974
- 3.43943408648173
- 3.1740052382151287
- 2.9497602430979413
- 2.758274923960368
- 2.6069153785705566
- 2.4898947429656983
- 2.424371420542399
- 2.347031831741333
- 2.3329859892527263
- 2.2995375855763753
- 2.2766469446818034
- 2.233585311571757
- 2.2165864197413128
- 2.2305037800470986
- 2.533168150583903
- 2.034980216026306
- 2.0366418520609537
- 2.061464743614197
- 2.049332661628723
- 2.0338289737701416
- 2.014631239573161
- 2.041168835957845
- 2.028516443570455
- 2.037536684672038
- 1.962314476966858
- 1.9749059597651164
- 2.0101741218566893
- 1.9799272600809734
- 1.9207704401016235
- 1.9702763668696086
- 1.9803100442886352
- 1.9868951829274495
- 1.9910728470484416
- 1.9442613697052002
- 1.9380604060490927
- 1.9673649326960245
- 1.95941965897878
- 1.9429220883051554
- 1.9391892528533936
- 1.9362972815831503
- 1.834211940765381
- 1.8814998499552409
- 1.8138066116968792
- 1.86245845635732
- 1.8634915987650553
- 1.8288647031784058
- 1.8328586578369142
- 1.8361061191558838
- 1.8554497162501018
- 1.8123785066604614
- 1.790769216219584
- 1.7554791688919067
- 1.7807990185419718
- 1.7756273969014487
- 1.7570793549219768
- 1.7334171199798585
- 1.7265517250696818
- 1.7693309116363525
- 1.7597627607981363
- 1.7296359078089396
- 1.7753321536382038
- 1.7344975757598877
- 1.7264449389775594
- 1.7563199313481648
- 1.7748694562911986
- 1.6924469645818074
- 1.6638617610931397
- 1.7295843267440796
- 1.7204133971532185
- 1.7341819747289022
- 1.7169851573308308
- 1.680907104810079
- 1.7151671489079794
- 1.7031837368011475
- 1.7198889938990276
- 1.7041634972890218
- 1.672898801167806
- 1.6838301912943523
- 1.6888182735443116
- 1.6689960797627768
- 1.652092808087667
- 1.6355805667241414
- 1.6551277430852254
- 1.61336253007253
- 1.591608681678772
- 1.6125094254811605
- 1.6089681975046795
- 1.6138203779856364
- 1.58694517771403
- 1.597279896736145
- 1.6022239716847737
- 1.5827113103866577
- 1.5823906993865966
- 1.538344430923462
- 1.5404465357462565
- 1.5797877089182535
- 1.5453627268473307
train_accuracy:
- 0.0
- 0.056
- 0.0
- 0.0
- 0.0
- 0.377
- 0.0
- 0.0
- 0.546
- 0.0
- 0.0
- 0.0
- 0.617
- 0.0
- 0.0
- 0.0
- 0.683
- 0.496
- 0.0
- 0.696
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.721
- 0.0
- 0.0
- 0.0
- 0.746
- 0.0
- 0.748
- 0.769
- 0.746
- 0.763
- 0.748
- 0.75
- 0.0
- 0.0
- 0.0
- 0.75
- 0.752
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.758
- 0.0
- 0.0
- 0.775
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.763
- 0.806
- 0.777
- 0.756
- 0.8
- 0.0
- 0.0
- 0.79
- 0.796
- 0.0
- 0.0
- 0.769
- 0.0
- 0.8
- 0.796
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.767
- 0.0
- 0.771
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.775
- 0.0
- 0.0
- 0.0
- 0.808
train_loss:
- 1.897
- 0.918
- 1.285
- 1.668
- 1.082
- 1.001
- 0.933
- 0.862
- 1.132
- 0.77
- 0.734
- 0.706
- 0.697
- 0.67
- 0.419
- 0.645
- 0.85
- 0.186
- 0.817
- 0.592
- 0.784
- 0.574
- 0.566
- 0.565
- 0.556
- 0.358
- 0.722
- 0.36
- 0.529
- 0.695
- 0.515
- 0.346
- 0.502
- 0.675
- 0.663
- 0.65
- 0.508
- 0.493
- 0.654
- 0.646
- 0.478
- 0.631
- 0.625
- 0.33
- 0.468
- 0.32
- 0.462
- 0.456
- 0.467
- 0.463
- 0.457
- 0.6
- 0.444
- 0.447
- 0.299
- 0.452
- 0.445
- 0.302
- 0.438
- 0.436
- 0.565
- 0.426
- 0.431
- 0.564
- 0.43
- 0.423
- 0.553
- 0.552
- 0.437
- 0.295
- 0.555
- 0.543
- 0.413
- 0.54
- 0.415
- 0.412
- 0.537
- 0.538
- 0.534
- 0.413
- 0.276
- 0.524
- 0.408
- 0.407
- 0.408
- 0.529
- 0.408
- 0.402
- 0.402
- 0.396
- 0.389
- 0.398
- 0.517
- 0.514
- 0.391
- 0.516
- 0.268
- 0.394
- 0.381
- 0.384
unequal: 0
verbose: 1
