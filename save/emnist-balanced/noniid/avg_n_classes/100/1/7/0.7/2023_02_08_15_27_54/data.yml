avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03531914893617021
- 0.03462765957446808
- 0.13398936170212766
- 0.22856382978723405
- 0.32563829787234044
- 0.4001595744680851
- 0.45324468085106384
- 0.47122340425531917
- 0.4993085106382979
- 0.5167021276595745
- 0.525
- 0.535904255319149
- 0.544468085106383
- 0.5520744680851064
- 0.5662765957446808
- 0.569627659574468
- 0.5670212765957446
- 0.5771808510638298
- 0.5904787234042553
- 0.5929255319148936
- 0.5995212765957447
- 0.5997340425531915
- 0.6090425531914894
- 0.609468085106383
- 0.614468085106383
- 0.6204255319148936
- 0.625
- 0.630904255319149
- 0.6254787234042554
- 0.6355851063829787
- 0.6356914893617022
- 0.6362765957446809
- 0.6404787234042553
- 0.6431914893617021
- 0.6423936170212766
- 0.6469148936170213
- 0.6505319148936171
- 0.6481382978723405
- 0.6524468085106383
- 0.6542021276595744
- 0.6555319148936171
- 0.6540425531914894
- 0.6568085106382979
- 0.6584042553191489
- 0.658936170212766
- 0.6598404255319149
- 0.6593085106382979
- 0.6628191489361702
- 0.6651595744680852
- 0.6641489361702128
- 0.6627659574468086
- 0.666595744680851
- 0.6632978723404256
- 0.6698936170212766
- 0.6715425531914894
- 0.6722340425531915
- 0.6725531914893617
- 0.6743085106382979
- 0.6708510638297872
- 0.6732446808510638
- 0.6748936170212766
- 0.6738829787234043
- 0.6782978723404255
- 0.6787765957446809
- 0.6793085106382979
- 0.6770744680851064
- 0.678936170212766
- 0.6802127659574468
- 0.6797340425531915
- 0.6823936170212765
- 0.6780851063829787
- 0.6831914893617022
- 0.6828191489361702
- 0.683936170212766
- 0.6786702127659574
- 0.6857978723404256
- 0.6869148936170213
- 0.683404255319149
- 0.6817021276595745
- 0.6844148936170212
- 0.6843617021276596
- 0.6874468085106383
- 0.6864893617021277
- 0.6876595744680851
- 0.688031914893617
- 0.6831382978723404
- 0.6863829787234043
- 0.6862765957446808
- 0.6882978723404255
- 0.6907978723404256
- 0.6880851063829787
- 0.6919148936170213
- 0.6914361702127659
- 0.6904787234042553
- 0.6911702127659575
- 0.559468085106383
- 0.6931914893617022
- 0.6916489361702127
- 0.6931914893617022
- 0.6909042553191489
test_loss_list:
- 3.7843500328063966
- 3.748970896402995
- 3.6127594757080077
- 3.318141695658366
- 2.995781291325887
- 2.782697277069092
- 2.6577476914723714
- 2.5687406571706135
- 2.501305551528931
- 2.4457953770955405
- 2.402315305074056
- 2.3719805685679116
- 2.36444229443868
- 2.3255839411417645
- 2.3510820388793947
- 2.2756057659784954
- 2.268198571205139
- 2.2539534044265745
- 2.26168834845225
- 2.257276784578959
- 2.214589557647705
- 2.1839914592107137
- 2.1867990477879844
- 2.1632350889841714
- 2.165181409517924
- 2.1875451676050823
- 2.1238052479426064
- 2.170148615837097
- 2.130033491452535
- 2.150494802792867
- 2.105601913134257
- 2.072869612375895
- 2.09241206963857
- 2.092397429148356
- 2.0411737171808877
- 2.05024254322052
- 2.09737846215566
- 2.0180482133229574
- 2.0345863501230874
- 2.0117316182454426
- 2.0151916042963665
- 1.9751803191502888
- 1.9375078137715658
- 1.9701455783843995
- 1.986303644180298
- 1.9955869023005168
- 1.9064339224497477
- 1.9231335878372193
- 1.9252255328496297
- 1.9087254619598388
- 1.8707292032241822
- 1.8825002257029215
- 1.8720993439356486
- 1.9070892413457234
- 1.8758173767725628
- 1.8587302780151367
- 1.8368859672546387
- 1.8562166945139567
- 1.8109672689437866
- 1.8044610500335694
- 1.7862030029296876
- 1.7695003986358642
- 1.804734344482422
- 1.7887872346242268
- 1.7918349393208821
- 1.7462495454152425
- 1.7493835703531901
- 1.761856525739034
- 1.708808913230896
- 1.745590583483378
- 1.7369389295578004
- 1.739600307146708
- 1.7390296824773153
- 1.733394136428833
- 1.6684806489944457
- 1.7035898526509603
- 1.7076440970102946
- 1.6730050373077392
- 1.6308038187026979
- 1.6232149155934652
- 1.6626481485366822
- 1.6623966153462728
- 1.6483206510543824
- 1.6221248038609823
- 1.6378389406204223
- 1.6007327206929525
- 1.586007884343465
- 1.5806466309229532
- 1.6082122882207235
- 1.6259612051645915
- 1.5813247696558634
- 1.6161249033610026
- 1.6031282138824463
- 1.5784096145629882
- 1.5571040884653726
- 1.4648660453160605
- 1.3257705958684285
- 1.4179806423187256
- 1.4730437358220418
- 1.4648791980743407
train_accuracy:
- 0.031
- 0.0
- 0.177
- 0.0
- 0.0
- 0.0
- 0.0
- 0.531
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.7
- 0.0
- 0.0
- 0.0
- 0.725
- 0.0
- 0.742
- 0.0
- 0.0
- 0.756
- 0.0
- 0.752
- 0.0
- 0.0
- 0.765
- 0.763
- 0.0
- 0.0
- 0.769
- 0.0
- 0.0
- 0.0
- 0.779
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.802
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.787
- 0.0
- 0.783
- 0.0
- 0.781
- 0.0
- 0.787
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.806
- 0.794
- 0.785
- 0.825
- 0.0
- 0.821
- 0.0
- 0.802
- 0.0
- 0.0
- 0.0
- 0.829
- 0.0
- 0.0
- 0.625
- 0.833
- 0.0
- 0.0
- 0.0
train_loss:
- 1.973
- 1.409
- 1.778
- 1.189
- 1.046
- 0.954
- 1.231
- 0.516
- 1.102
- 0.766
- 0.744
- 0.721
- 0.702
- 0.691
- 0.913
- 0.446
- 0.429
- 0.426
- 0.635
- 0.63
- 0.618
- 0.399
- 0.8
- 0.402
- 0.585
- 0.768
- 0.571
- 0.75
- 0.381
- 0.734
- 0.555
- 0.54
- 0.705
- 0.7
- 0.544
- 0.695
- 0.686
- 0.526
- 0.678
- 0.517
- 0.508
- 0.507
- 0.508
- 0.653
- 0.647
- 0.639
- 0.493
- 0.491
- 0.49
- 0.489
- 0.335
- 0.476
- 0.334
- 0.615
- 0.619
- 0.466
- 0.468
- 0.603
- 0.325
- 0.462
- 0.454
- 0.317
- 0.593
- 0.457
- 0.591
- 0.444
- 0.319
- 0.448
- 0.305
- 0.576
- 0.308
- 0.567
- 0.568
- 0.569
- 0.304
- 0.436
- 0.429
- 0.43
- 0.303
- 0.291
- 0.417
- 0.422
- 0.424
- 0.419
- 0.419
- 0.291
- 0.289
- 0.279
- 0.536
- 0.54
- 0.409
- 0.534
- 0.533
- 0.41
- 0.407
- 0.158
- 0.506
- 0.385
- 0.51
- 0.389
unequal: 0
verbose: 1
