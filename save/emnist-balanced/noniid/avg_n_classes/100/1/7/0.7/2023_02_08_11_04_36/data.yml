avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03845744680851064
- 0.06223404255319149
- 0.13744680851063829
- 0.2618617021276596
- 0.3371808510638298
- 0.40430851063829787
- 0.4448936170212766
- 0.46835106382978725
- 0.47925531914893615
- 0.5070212765957447
- 0.5220744680851064
- 0.5365425531914894
- 0.5411170212765958
- 0.5478191489361702
- 0.5637234042553192
- 0.5759042553191489
- 0.5786170212765958
- 0.5868085106382979
- 0.5891489361702128
- 0.5969148936170213
- 0.596968085106383
- 0.6036702127659574
- 0.6066489361702128
- 0.6145212765957446
- 0.6173936170212766
- 0.6253723404255319
- 0.6237765957446808
- 0.6304255319148936
- 0.6362765957446809
- 0.6376595744680851
- 0.6396276595744681
- 0.6370744680851064
- 0.6444148936170213
- 0.6448404255319149
- 0.6437234042553192
- 0.6493617021276595
- 0.6490957446808511
- 0.6504255319148936
- 0.6528723404255319
- 0.6508510638297872
- 0.6573936170212766
- 0.6592553191489362
- 0.6588297872340425
- 0.6653191489361702
- 0.6617021276595745
- 0.6625531914893616
- 0.6654787234042553
- 0.6664361702127659
- 0.668031914893617
- 0.6666489361702128
- 0.6718617021276596
- 0.6703191489361702
- 0.6714361702127659
- 0.6725
- 0.6739893617021276
- 0.6749468085106383
- 0.6757978723404255
- 0.6754787234042553
- 0.6731914893617021
- 0.6786170212765957
- 0.6775531914893617
- 0.6776063829787234
- 0.676968085106383
- 0.6790425531914893
- 0.6779787234042554
- 0.6800531914893617
- 0.6806914893617021
- 0.6812234042553191
- 0.6825531914893617
- 0.6822872340425532
- 0.6823404255319149
- 0.684468085106383
- 0.6787234042553192
- 0.6833510638297873
- 0.685531914893617
- 0.6857978723404256
- 0.6858510638297872
- 0.6864361702127659
- 0.6864361702127659
- 0.6865425531914894
- 0.6881914893617022
- 0.6868617021276596
- 0.6882978723404255
- 0.6877127659574468
- 0.688404255319149
- 0.6856914893617021
- 0.686063829787234
- 0.6877659574468085
- 0.6897872340425532
- 0.6881914893617022
- 0.6900531914893617
- 0.6882978723404255
- 0.6893617021276596
- 0.6928191489361702
- 0.6929787234042554
- 0.6926063829787235
- 0.6925531914893617
- 0.6932446808510638
- 0.6940425531914893
- 0.694468085106383
test_loss_list:
- 3.7839863300323486
- 3.7329276116689045
- 3.5617165342966715
- 3.227520341873169
- 2.950773951212565
- 2.771119654973348
- 2.656878188451131
- 2.56026104927063
- 2.500629218419393
- 2.452368895212809
- 2.4002002080281577
- 2.386075105667114
- 2.339001054763794
- 2.3366036430994668
- 2.3149728536605836
- 2.317159662246704
- 2.262696067492167
- 2.2743406120936074
- 2.2299702723821
- 2.235309017499288
- 2.199821483294169
- 2.1792895571390787
- 2.1435308901468915
- 2.126857137680054
- 2.1456826575597128
- 2.1636485719680785
- 2.0944729121526082
- 2.1344523366292316
- 2.136727941830953
- 2.134045335451762
- 2.12091961701711
- 2.047477518717448
- 2.12325474580129
- 2.0958675146102905
- 2.0264953645070394
- 2.050046733220418
- 2.014394056002299
- 2.020199643770854
- 2.0409831460316976
- 1.9721945158640544
- 1.996806058883667
- 2.0200765164693197
- 1.992273645401001
- 2.026715860366821
- 1.9749178902308147
- 1.9458619165420532
- 1.9771040932337443
- 1.9451057402292888
- 1.9230079857508342
- 1.9286823972066243
- 1.9307860390345255
- 1.9463796393076578
- 1.9133808851242065
- 1.9163047488530476
- 1.885396949450175
- 1.8736408138275147
- 1.887176014582316
- 1.8301504611968995
- 1.7999171288808187
- 1.8525458876291911
- 1.8046111647288006
- 1.818166454633077
- 1.7573290554682415
- 1.7818931818008423
- 1.7964443476994831
- 1.7792727200190226
- 1.7672824414571127
- 1.7765555651982625
- 1.7735895697275799
- 1.7645241912206013
- 1.7586976146698
- 1.7471408875783285
- 1.6735944000879923
- 1.7137222146987916
- 1.7255072784423828
- 1.705348736445109
- 1.7257896900177
- 1.7202324151992798
- 1.7092397753397623
- 1.694388715426127
- 1.6828708187739054
- 1.651782374382019
- 1.7070242722829183
- 1.7025875202814738
- 1.6999051729838053
- 1.6335023419062296
- 1.6534240833918254
- 1.6734138997395833
- 1.6088032563527426
- 1.6406947326660157
- 1.6417788235346475
- 1.6427073001861572
- 1.6209832032521565
- 1.5700718943277996
- 1.63208962281545
- 1.5989977836608886
- 1.609533012708028
- 1.579595971107483
- 1.5803044589360555
- 1.5391247574488323
train_accuracy:
- 0.0
- 0.054
- 0.0
- 0.0
- 0.0
- 0.0
- 0.519
- 0.0
- 0.0
- 0.0
- 0.0
- 0.594
- 0.0
- 0.667
- 0.675
- 0.0
- 0.0
- 0.0
- 0.662
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.698
- 0.713
- 0.0
- 0.71
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.771
- 0.0
- 0.796
- 0.0
- 0.781
- 0.748
- 0.0
- 0.0
- 0.812
- 0.0
- 0.0
- 0.796
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.819
- 0.8
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.771
- 0.0
- 0.0
- 0.0
- 0.823
- 0.76
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.838
- 0.0
- 0.81
- 0.779
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.0
- 0.812
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 1.339
- 1.33
- 1.265
- 1.134
- 0.589
- 0.929
- 0.868
- 0.846
- 0.805
- 0.48
- 0.749
- 0.985
- 0.716
- 0.689
- 0.921
- 0.885
- 0.665
- 0.86
- 0.656
- 0.837
- 0.623
- 0.61
- 0.595
- 0.604
- 0.784
- 0.766
- 0.589
- 0.741
- 0.751
- 0.566
- 0.739
- 0.556
- 0.704
- 0.715
- 0.549
- 0.529
- 0.536
- 0.534
- 0.518
- 0.362
- 0.517
- 0.671
- 0.663
- 0.653
- 0.498
- 0.504
- 0.487
- 0.489
- 0.481
- 0.491
- 0.624
- 0.617
- 0.474
- 0.616
- 0.47
- 0.473
- 0.464
- 0.328
- 0.32
- 0.594
- 0.459
- 0.461
- 0.315
- 0.443
- 0.446
- 0.446
- 0.448
- 0.439
- 0.434
- 0.565
- 0.444
- 0.43
- 0.301
- 0.434
- 0.43
- 0.435
- 0.552
- 0.55
- 0.551
- 0.424
- 0.419
- 0.296
- 0.545
- 0.543
- 0.412
- 0.289
- 0.413
- 0.408
- 0.411
- 0.404
- 0.4
- 0.401
- 0.404
- 0.4
- 0.404
- 0.403
- 0.399
- 0.403
- 0.392
- 0.275
unequal: 0
verbose: 1
