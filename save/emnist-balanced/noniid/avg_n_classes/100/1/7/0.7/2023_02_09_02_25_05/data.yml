avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02920212765957447
- 0.06037234042553191
- 0.17186170212765958
- 0.2721808510638298
- 0.34180851063829787
- 0.38590425531914896
- 0.43425531914893617
- 0.45835106382978724
- 0.478031914893617
- 0.49872340425531914
- 0.5081914893617021
- 0.523563829787234
- 0.5314893617021277
- 0.5338829787234043
- 0.549468085106383
- 0.5502659574468085
- 0.5610106382978723
- 0.566968085106383
- 0.5760106382978724
- 0.5797340425531915
- 0.586063829787234
- 0.5897340425531915
- 0.5914893617021276
- 0.5979255319148936
- 0.603404255319149
- 0.61
- 0.6110106382978724
- 0.6116489361702128
- 0.6184574468085107
- 0.6194148936170213
- 0.6238297872340426
- 0.6271808510638298
- 0.6290425531914894
- 0.6284574468085107
- 0.6338829787234043
- 0.6372872340425532
- 0.635531914893617
- 0.6389361702127659
- 0.6382446808510638
- 0.6453723404255319
- 0.6430851063829788
- 0.6438829787234043
- 0.648031914893617
- 0.6510106382978723
- 0.6512234042553191
- 0.6527127659574468
- 0.6556382978723404
- 0.656063829787234
- 0.6568085106382979
- 0.6527659574468085
- 0.6618085106382978
- 0.6625531914893616
- 0.6610106382978723
- 0.6627127659574468
- 0.6656382978723404
- 0.6631914893617021
- 0.6651595744680852
- 0.6614893617021277
- 0.665904255319149
- 0.6651063829787234
- 0.6657446808510639
- 0.663936170212766
- 0.6688829787234043
- 0.6711170212765958
- 0.6713297872340426
- 0.6670744680851064
- 0.6718617021276596
- 0.6736702127659574
- 0.6732446808510638
- 0.673031914893617
- 0.6754787234042553
- 0.6739893617021276
- 0.6734042553191489
- 0.6767021276595745
- 0.6743085106382979
- 0.675
- 0.6696808510638298
- 0.678031914893617
- 0.6767021276595745
- 0.6723404255319149
- 0.6783510638297873
- 0.681595744680851
- 0.6779255319148936
- 0.6790957446808511
- 0.6778723404255319
- 0.6806382978723404
- 0.6820744680851064
- 0.6826595744680851
- 0.6829787234042554
- 0.681063829787234
- 0.6806382978723404
- 0.6836170212765957
- 0.6779787234042554
- 0.6823936170212765
- 0.6820212765957446
- 0.6845212765957447
- 0.6847340425531915
- 0.6796276595744681
- 0.6836170212765957
- 0.6850531914893617
test_loss_list:
- 3.790007054011027
- 3.732536153793335
- 3.557588170369466
- 3.258186502456665
- 3.0045023663838704
- 2.8660153039296468
- 2.7548666445414227
- 2.673431628545125
- 2.5964183680216473
- 2.5575300089518227
- 2.506386753718058
- 2.4681523768107096
- 2.432462107340495
- 2.4172674147288005
- 2.3907311503092448
- 2.3810598341623943
- 2.3586272271474202
- 2.3600635878245035
- 2.372008310953776
- 2.3522541109720865
- 2.2905410544077554
- 2.2773385651906333
- 2.2437697299321493
- 2.251521021525065
- 2.2561836004257203
- 2.204755121866862
- 2.190352069536845
- 2.1966769170761107
- 2.1861882130304973
- 2.1634772539138796
- 2.158074959119161
- 2.1695723215738933
- 2.1176993529001873
- 2.0957294940948485
- 2.0993289454778035
- 2.0618280824025472
- 2.069554842313131
- 2.064426129659017
- 2.018284180959066
- 2.019463454882304
- 1.9885659964879354
- 1.9700063975652058
- 2.0127487897872927
- 2.0088592767715454
- 2.001134549776713
- 2.0038532129923503
- 1.9698822037378947
- 1.9668341493606567
- 1.988382601737976
- 1.9345024458567301
- 1.9318879826863606
- 1.945137899716695
- 1.9407327620188395
- 1.9370059045155843
- 1.9599304183324178
- 1.9172853151957194
- 1.904604040781657
- 1.8718138933181763
- 1.86732293287913
- 1.8097430610656737
- 1.8193787288665773
- 1.8114883057276407
- 1.856219228108724
- 1.836916979153951
- 1.8143311325709026
- 1.7883035850524902
- 1.8119611469904582
- 1.7683013280232747
- 1.8058985662460327
- 1.7846222877502442
- 1.7880468400319418
- 1.7717317930857341
- 1.73526176293691
- 1.7415623887379965
- 1.7068316125869751
- 1.7613758452733357
- 1.6993748903274537
- 1.7130653540293375
- 1.6679244915644327
- 1.7060405937830607
- 1.6979445060094198
- 1.7095096365610758
- 1.6803057416280112
- 1.6817630847295126
- 1.6938175439834595
- 1.6886795775095622
- 1.660587166150411
- 1.6750614023208619
- 1.6706962013244628
- 1.6574370908737182
- 1.6606313180923462
- 1.628757824897766
- 1.5989607191085815
- 1.6207670227686564
- 1.6337836297353108
- 1.630522492726644
- 1.616762269337972
- 1.5684787321090699
- 1.6023772700627645
- 1.586451423962911
train_accuracy:
- 0.0
- 0.0
- 0.223
- 0.352
- 0.433
- 0.0
- 0.513
- 0.0
- 0.0
- 0.0
- 0.0
- 0.627
- 0.0
- 0.652
- 0.0
- 0.667
- 0.0
- 0.669
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.717
- 0.0
- 0.719
- 0.0
- 0.0
- 0.0
- 0.723
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.746
- 0.783
- 0.792
- 0.0
- 0.763
- 0.0
- 0.763
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.781
- 0.0
- 0.794
- 0.0
- 0.0
- 0.002
- 0.0
- 0.804
- 0.0
- 0.0
- 0.0
- 0.769
- 0.0
- 0.0
- 0.775
- 0.806
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.808
- 0.783
- 0.79
- 0.0
- 0.781
- 0.0
train_loss:
- 1.428
- 1.852
- 1.239
- 1.144
- 1.026
- 0.96
- 1.252
- 0.861
- 0.523
- 1.09
- 0.781
- 0.768
- 0.742
- 0.734
- 0.96
- 0.474
- 0.708
- 0.672
- 0.877
- 0.864
- 0.664
- 0.639
- 0.436
- 0.621
- 0.803
- 0.61
- 0.606
- 0.585
- 0.78
- 0.585
- 0.759
- 0.559
- 0.567
- 0.557
- 0.557
- 0.566
- 0.54
- 0.54
- 0.362
- 0.533
- 0.543
- 0.358
- 0.674
- 0.691
- 0.673
- 0.507
- 0.681
- 0.493
- 0.661
- 0.51
- 0.503
- 0.664
- 0.635
- 0.644
- 0.632
- 0.503
- 0.483
- 0.337
- 0.488
- 0.341
- 0.33
- 0.335
- 0.618
- 0.469
- 0.47
- 0.321
- 0.6
- 0.482
- 0.457
- 0.463
- 0.595
- 0.454
- 0.472
- 0.451
- 0.459
- 0.573
- 0.314
- 0.587
- 0.447
- 0.3
- 0.573
- 0.578
- 0.432
- 0.428
- 0.422
- 0.442
- 0.436
- 0.57
- 0.424
- 0.434
- 0.422
- 0.423
- 0.296
- 0.418
- 0.413
- 0.552
- 0.424
- 0.291
- 0.411
- 0.433
unequal: 0
verbose: 1
