avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.019148936170212766
- 0.03308510638297872
- 0.09632978723404255
- 0.1798404255319149
- 0.31170212765957445
- 0.385
- 0.4306382978723404
- 0.46324468085106385
- 0.4883510638297872
- 0.5114893617021277
- 0.5198936170212766
- 0.5333510638297873
- 0.5457446808510639
- 0.5473404255319149
- 0.5638829787234042
- 0.5617021276595745
- 0.5622340425531915
- 0.581063829787234
- 0.5883510638297872
- 0.5938297872340426
- 0.5995212765957447
- 0.6029255319148936
- 0.6028191489361702
- 0.611968085106383
- 0.6171276595744681
- 0.6189893617021277
- 0.6172340425531915
- 0.6236170212765958
- 0.6281914893617021
- 0.6338297872340426
- 0.6334042553191489
- 0.6310106382978723
- 0.6405851063829787
- 0.6423404255319148
- 0.6427659574468085
- 0.6482978723404256
- 0.6479255319148937
- 0.6496808510638298
- 0.6540957446808511
- 0.6512234042553191
- 0.33526595744680854
- 0.6554787234042553
- 0.6568617021276596
- 0.6596276595744681
- 0.6597340425531915
- 0.6608510638297872
- 0.6628723404255319
- 0.6617553191489361
- 0.6656914893617021
- 0.6675
- 0.6651595744680852
- 0.6682446808510638
- 0.6687765957446808
- 0.6678723404255319
- 0.6698404255319149
- 0.6710106382978723
- 0.6665425531914894
- 0.6671276595744681
- 0.6727127659574468
- 0.6697340425531915
- 0.6727659574468086
- 0.675372340425532
- 0.6771808510638297
- 0.6740957446808511
- 0.6709574468085107
- 0.6771276595744681
- 0.6745212765957447
- 0.6718617021276596
- 0.6790957446808511
- 0.678936170212766
- 0.679468085106383
- 0.6782446808510638
- 0.6794148936170212
- 0.6781382978723405
- 0.6789893617021276
- 0.6813829787234043
- 0.6804787234042553
- 0.6841489361702128
- 0.6824468085106383
- 0.6811702127659575
- 0.6827127659574468
- 0.6829255319148936
- 0.6834574468085106
- 0.6836170212765957
- 0.684468085106383
- 0.6810106382978723
- 0.6859042553191489
- 0.6861702127659575
- 0.6859574468085107
- 0.6861170212765958
- 0.6869148936170213
- 0.6831914893617022
- 0.6872872340425532
- 0.6854787234042553
- 0.6892021276595744
- 0.689468085106383
- 0.6895744680851064
- 0.6898404255319149
- 0.6900531914893617
- 0.6904787234042553
test_loss_list:
- 3.7889930534362795
- 3.7611953099568685
- 3.661820208231608
- 3.403416674931844
- 3.090322068532308
- 2.8574910449981687
- 2.6956434535980223
- 2.59849326133728
- 2.525167277654012
- 2.4744506168365477
- 2.41585223197937
- 2.3964645957946775
- 2.3584488995869957
- 2.3300871499379476
- 2.3287591775258383
- 2.292825773557027
- 2.2657623624801637
- 2.2472310813268024
- 2.255772519111633
- 2.209366014798482
- 2.199468986193339
- 2.2103519678115844
- 2.160817505518595
- 2.1574035183588665
- 2.1643634923299153
- 2.172275424003601
- 2.097709757486979
- 2.13095666885376
- 2.1172780640920004
- 2.1223947270711263
- 2.0785378328959148
- 2.0532190656661986
- 2.085024981498718
- 2.0599542888005575
- 2.0371849807103475
- 2.0223022238413493
- 1.9989130481084187
- 2.0140535195668536
- 2.016658633550008
- 1.9972911389668782
- 2.296573880513509
- 1.768725225130717
- 1.8241618728637696
- 1.8331222836176555
- 1.8591059494018554
- 1.8474031829833983
- 1.8663527758916219
- 1.8442462730407714
- 1.8435711781183879
- 1.8404108810424804
- 1.833042526245117
- 1.8200646511713663
- 1.8447791894276937
- 1.8080651505788168
- 1.820821681022644
- 1.841011527379354
- 1.7892760864893595
- 1.78596200466156
- 1.7343675883611043
- 1.7675512011845906
- 1.7532855463027954
- 1.7651070658365886
- 1.769014573097229
- 1.7472716490427653
- 1.6987476205825807
- 1.7420891984303792
- 1.6751871315638225
- 1.6542733271916708
- 1.7008018096288045
- 1.7097137514750163
- 1.6686960776646933
- 1.67037060101827
- 1.6815117406845093
- 1.6765587107340494
- 1.6224684190750123
- 1.6434423828125
- 1.6475799004236857
- 1.6571880451838175
- 1.662481993039449
- 1.6186113786697387
- 1.6333581415812175
- 1.6416999276479085
- 1.6316697279612222
- 1.6064576292037964
- 1.5802120526631673
- 1.547259683609009
- 1.5577934058507283
- 1.5586042213439941
- 1.561681653658549
- 1.5478371159235635
- 1.5666507116953532
- 1.5104514487584433
- 1.5108801778157552
- 1.5047846126556397
- 1.5105683215459187
- 1.5264114507039388
- 1.4947956641515097
- 1.5131200408935548
- 1.5291390069325765
- 1.4990237379074096
train_accuracy:
- 0.0
- 0.0
- 0.129
- 0.0
- 0.0
- 0.44
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.765
- 0.723
- 0.0
- 0.0
- 0.752
- 0.74
- 0.0
- 0.0
- 0.756
- 0.0
- 0.81
- 0.0
- 0.0
- 0.758
- 0.0
- 0.0
- 0.573
- 0.0
- 0.798
- 0.775
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.777
- 0.0
- 0.787
- 0.0
- 0.0
- 0.85
- 0.844
- 0.0
- 0.0
- 0.0
- 0.0
- 0.846
- 0.819
- 0.0
- 0.0
- 0.819
- 0.0
- 0.802
- 0.0
- 0.0
- 0.798
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.831
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.846
- 0.0
- 0.85
- 0.0
- 0.854
- 0.0
- 0.0
- 0.0
- 0.0
- 0.85
- 0.0
- 0.0
- 0.827
- 0.0
train_loss:
- 1.906
- 0.911
- 1.771
- 1.208
- 1.075
- 1.376
- 0.914
- 0.868
- 1.153
- 1.094
- 0.766
- 1.026
- 1.0
- 0.452
- 0.949
- 0.688
- 0.437
- 0.67
- 0.885
- 0.659
- 0.646
- 0.85
- 0.422
- 0.625
- 0.802
- 0.811
- 0.419
- 0.583
- 0.776
- 0.572
- 0.572
- 0.383
- 0.731
- 0.56
- 0.548
- 0.555
- 0.551
- 0.53
- 0.706
- 0.533
- 0.205
- 0.668
- 0.668
- 0.68
- 0.661
- 0.665
- 0.665
- 0.483
- 0.647
- 0.67
- 0.483
- 0.639
- 0.645
- 0.495
- 0.481
- 0.635
- 0.484
- 0.482
- 0.328
- 0.319
- 0.466
- 0.616
- 0.618
- 0.466
- 0.328
- 0.596
- 0.31
- 0.318
- 0.45
- 0.454
- 0.451
- 0.452
- 0.582
- 0.444
- 0.301
- 0.579
- 0.575
- 0.57
- 0.577
- 0.304
- 0.426
- 0.558
- 0.424
- 0.437
- 0.434
- 0.283
- 0.419
- 0.425
- 0.413
- 0.547
- 0.554
- 0.282
- 0.42
- 0.277
- 0.402
- 0.535
- 0.424
- 0.41
- 0.538
- 0.411
unequal: 0
verbose: 1
