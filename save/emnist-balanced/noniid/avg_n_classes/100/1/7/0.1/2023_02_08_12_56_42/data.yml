avg_train_accuracy: 0.998
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022021276595744682
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.031595744680851065
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.021914893617021276
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.03946808510638298
- 0.02127659574468085
- 0.04111702127659574
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.04654255319148936
- 0.02127659574468085
- 0.027180851063829788
- 0.021595744680851063
- 0.02127659574468085
- 0.02127659574468085
- 0.08117021276595744
- 0.07797872340425532
- 0.022446808510638298
- 0.07510638297872341
- 0.12898936170212766
- 0.05377659574468085
- 0.17388297872340425
- 0.21654255319148935
- 0.022127659574468085
- 0.029787234042553193
- 0.04031914893617021
- 0.2600531914893617
- 0.12058510638297873
- 0.31111702127659574
- 0.3475531914893617
- 0.37707446808510636
- 0.13702127659574467
- 0.041648936170212765
- 0.02127659574468085
- 0.02127659574468085
- 0.3913829787234043
- 0.4211170212765957
- 0.1427659574468085
- 0.11292553191489361
- 0.09574468085106383
- 0.02127659574468085
- 0.02851063829787234
- 0.4324468085106383
- 0.18930851063829787
- 0.46414893617021274
- 0.05452127659574468
- 0.47106382978723405
- 0.48058510638297874
- 0.24265957446808512
- 0.021382978723404257
- 0.5077127659574469
- 0.056648936170212764
- 0.037393617021276596
- 0.04468085106382979
- 0.021648936170212765
- 0.5119148936170212
- 0.16196808510638297
- 0.5249468085106384
- 0.5253191489361703
- 0.5367021276595745
- 0.21079787234042552
- 0.16361702127659575
- 0.5440425531914893
- 0.5574468085106383
- 0.5590957446808511
- 0.2602127659574468
- 0.5766489361702127
- 0.2525
- 0.07175531914893617
- 0.5773404255319149
- 0.5818617021276595
- 0.2948404255319149
- 0.1726063829787234
- 0.06707446808510638
test_loss_list:
- 3.7845906448364257
- 27.82613286336263
- 34.42113967895508
- 41.09639841715495
- 24.87442008972168
- 3.802017526626587
- 3.7993793964385985
- 19.980951614379883
- 3.802792126337687
- 21.44071283976237
- 3.8001479562123617
- 18.838292795817058
- 23.044338811238607
- 33.90614679972331
- 25.48293764750163
- 19.188824106852213
- 28.27491470336914
- 3.80836581548055
- 10.760112113952637
- 15.611731834411621
- 12.450883293151856
- 13.902686958312989
- 16.232590878804526
- 3.800984624226888
- 3.788468650182088
- 9.063828099568685
- 16.144082946777345
- 17.382185846964518
- 3.771908893585205
- 11.960218442281088
- 3.74485325495402
- 18.18421775817871
- 9.916849950154623
- 12.597700691223144
- 12.076458676656086
- 3.7312537225087485
- 11.77708480834961
- 10.702122853597006
- 10.55818130493164
- 12.310303688049316
- 16.514859517415363
- 3.698520409266154
- 3.657381264368693
- 7.2100667381286625
- 3.559660046895345
- 3.4620758533477782
- 6.67011100769043
- 3.3317544714609784
- 3.1864076964060466
- 12.786701787312825
- 7.1314952850341795
- 16.204103571573892
- 3.121844237645467
- 5.2555145835876464
- 2.9413922023773194
- 2.830189816157023
- 2.737591479619344
- 5.265344492594401
- 13.130030937194825
- 20.376108830769855
- 27.56260454813639
- 2.6803017330169676
- 2.5405658785502117
- 6.043384342193604
- 8.132165114084879
- 9.719753901163736
- 16.057057889302573
- 8.661497599283853
- 2.4527484289805095
- 4.3461957454681395
- 2.3554758167266847
- 8.609622147878012
- 2.2825425402323405
- 2.2501283645629884
- 4.264190384546915
- 10.998098843892416
- 2.162462164560954
- 10.033716328938802
- 14.050783398946127
- 9.211478309631348
- 11.035673764546713
- 2.018335860570272
- 5.642074826558431
- 1.9106416622797648
- 1.915825769106547
- 1.8971565024058024
- 5.427289810180664
- 6.51454329808553
- 1.8438245344161988
- 1.8294115161895752
- 1.8332786877950034
- 4.824085629781087
- 1.800670035680135
- 5.294401028951009
- 8.57104689280192
- 1.7131506745020548
- 1.7329799556732177
- 4.450810289382934
- 6.320566933949788
- 9.089325993855795
train_accuracy:
- 0.027
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 0.006
- 0.102
- 1.0
- 0.163
- 0.285
- 1.0
- 1.0
- 1.0
- 0.248
- 1.0
- 0.371
- 0.4
- 0.427
- 1.0
- 1.0
- 1.0
- 1.0
- 0.442
- 0.515
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.465
- 1.0
- 0.56
- 0.998
- 0.5
- 0.59
- 1.0
- 1.0
- 0.531
- 0.996
- 0.998
- 1.0
- 1.0
- 0.612
- 1.0
- 0.631
- 0.606
- 0.669
- 1.0
- 1.0
- 0.602
- 0.673
- 0.656
- 1.0
- 0.675
- 1.0
- 1.0
- 0.685
- 0.69
- 1.0
- 1.0
- 0.998
train_loss:
- 3.835
- 0.557
- 0.385
- 0.009
- 1.061
- 4.146
- 3.851
- 1.663
- 4.143
- 1.277
- 4.17
- 0.522
- 0.986
- 1.009
- 1.585
- 1.327
- 0.188
- 4.405
- 1.018
- 0.372
- 0.307
- 1.34
- 0.992
- 4.326
- 3.941
- 0.562
- 0.384
- 1.025
- 4.293
- 0.445
- 4.139
- 1.572
- 0.544
- 0.054
- 0.394
- 4.214
- 0.745
- 0.288
- 0.913
- 0.649
- 0.032
- 4.333
- 3.886
- 0.329
- 3.964
- 3.694
- 0.343
- 3.726
- 3.391
- 0.346
- 0.334
- 0.544
- 3.84
- 0.198
- 3.36
- 3.088
- 2.929
- 0.197
- 0.221
- 0.678
- 0.048
- 3.65
- 2.814
- 0.26
- 0.021
- 0.011
- 0.536
- 0.438
- 3.139
- 0.14
- 2.802
- 0.379
- 2.846
- 2.519
- 0.141
- 0.362
- 2.78
- 0.418
- 0.03
- 0.349
- 0.297
- 2.912
- 0.365
- 2.558
- 2.329
- 2.22
- 0.154
- 0.29
- 2.483
- 2.158
- 2.125
- 0.14
- 2.273
- 0.184
- 0.282
- 2.376
- 1.998
- 0.133
- 0.204
- 0.54
unequal: 0
verbose: 1
