avg_train_accuracy: 1.0
avg_train_loss: 0.001
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03425531914893617
- 0.05223404255319149
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.023510638297872342
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.038138297872340424
- 0.02127659574468085
- 0.02127659574468085
- 0.029414893617021275
- 0.07143617021276595
- 0.0775
- 0.02127659574468085
- 0.02127659574468085
- 0.026329787234042553
- 0.06792553191489362
- 0.035159574468085104
- 0.024627659574468084
- 0.025904255319148937
- 0.03659574468085106
- 0.034574468085106384
- 0.030904255319148935
- 0.07361702127659575
- 0.02127659574468085
- 0.04069148936170213
- 0.033138297872340426
- 0.0425
- 0.0424468085106383
- 0.11478723404255319
- 0.0701595744680851
- 0.039095744680851065
- 0.03973404255319149
- 0.165
- 0.02127659574468085
- 0.19196808510638297
- 0.07063829787234042
- 0.04654255319148936
- 0.04042553191489362
- 0.2372340425531915
- 0.036808510638297876
- 0.02303191489361702
- 0.3326595744680851
- 0.05941489361702128
- 0.08808510638297873
- 0.40106382978723404
- 0.4473404255319149
- 0.10159574468085106
- 0.4622872340425532
- 0.21308510638297873
- 0.4932446808510638
- 0.11659574468085106
- 0.1422872340425532
- 0.5229255319148937
- 0.25398936170212766
- 0.5325
- 0.17760638297872341
- 0.12468085106382978
- 0.05420212765957447
- 0.05824468085106383
- 0.10670212765957447
- 0.0772872340425532
- 0.047180851063829785
- 0.5728723404255319
- 0.3211702127659574
- 0.17186170212765958
- 0.08718085106382979
- 0.5596808510638298
- 0.5590425531914893
- 0.21968085106382979
- 0.5624468085106383
- 0.30840425531914895
- 0.17143617021276597
- 0.1322340425531915
- 0.11856382978723404
- 0.1201595744680851
- 0.08015957446808511
- 0.07734042553191489
- 0.0925531914893617
- 0.5930319148936171
- 0.3142553191489362
- 0.5984574468085107
- 0.37388297872340426
- 0.1998936170212766
test_loss_list:
- 3.79028733253479
- 3.768868834177653
- 29.63163480122884
- 22.7496137491862
- 28.714506174723308
- 20.960269165039062
- 20.863222986857096
- 3.802532920837402
- 19.673930486043293
- 19.814496205647785
- 18.554952087402345
- 3.807894309361776
- 22.826277262369793
- 3.8063329537709554
- 20.5662052154541
- 3.8037337843577066
- 14.495176277160645
- 22.957306798299154
- 3.803649880091349
- 14.924423217773438
- 17.530082880655925
- 19.828928502400718
- 28.926348317464193
- 3.8005927054087323
- 14.94626449584961
- 16.015168546040854
- 17.366977513631184
- 3.749785966873169
- 3.735112501780192
- 11.831992225646973
- 10.711219202677409
- 11.133860104878744
- 3.6592600599924725
- 9.338487167358398
- 18.415082753499348
- 15.953923937479654
- 10.937131055196126
- 13.528423703511557
- 12.959290301005046
- 3.6041656907399497
- 7.463819643656413
- 9.584607632954915
- 10.203178062438965
- 10.492750854492188
- 10.279034220377604
- 3.5020951970418293
- 6.834830099741618
- 8.489170888264974
- 11.202216860453287
- 3.3580624198913576
- 13.104032160441081
- 3.1530273310343424
- 5.517551161448161
- 7.455866820017497
- 8.267182909647623
- 2.8990142663319904
- 6.894218839009603
- 9.36893700917562
- 2.690686518351237
- 5.31855904897054
- 7.153166433970133
- 2.5068822797139485
- 2.385448497136434
- 6.70786070505778
- 2.2518275101979572
- 5.260893414815267
- 2.183882926305135
- 6.211604016621908
- 4.829554786682129
- 2.021881227493286
- 3.8699099254608154
- 1.9793477328618367
- 5.693581485748291
- 7.319797649383545
- 11.252372703552247
- 8.847109400431314
- 5.242839120229085
- 9.183020083109538
- 10.018146031697592
- 1.8257446527481078
- 4.449799092610677
- 5.927711970011393
- 6.096795450846354
- 1.7092335732777912
- 1.6815003442764282
- 5.073635851542155
- 1.6660259199142455
- 4.308651561737061
- 6.156555506388346
- 5.57349905649821
- 6.0274808311462404
- 6.596803391774495
- 8.2564687983195
- 6.018642965952555
- 5.60600902557373
- 1.5612731266021729
- 3.540424092610677
- 1.5564421129226684
- 3.0875714588165284
- 5.835601272583008
train_accuracy:
- 0.044
- 0.067
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.01
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.044
- 1.0
- 1.0
- 1.0
- 0.067
- 1.0
- 0.154
- 1.0
- 1.0
- 1.0
- 0.229
- 1.0
- 1.0
- 0.379
- 1.0
- 0.994
- 0.465
- 0.544
- 1.0
- 0.56
- 1.0
- 0.606
- 1.0
- 1.0
- 0.598
- 1.0
- 0.623
- 1.0
- 1.0
- 0.996
- 1.0
- 1.0
- 0.996
- 0.996
- 0.596
- 1.0
- 1.0
- 1.0
- 0.65
- 0.667
- 1.0
- 0.662
- 1.0
- 1.0
- 1.0
- 1.0
- 0.998
- 0.996
- 0.998
- 0.998
- 0.662
- 1.0
- 0.683
- 1.0
- 1.0
train_loss:
- 3.84
- 3.784
- 0.34
- 0.826
- 0.014
- 0.668
- 1.115
- 4.195
- 1.507
- 0.553
- 0.463
- 4.194
- 0.96
- 4.172
- 2.011
- 4.146
- 1.363
- 0.784
- 4.291
- 0.75
- 0.543
- 0.494
- 1.163
- 4.276
- 1.063
- 0.368
- 0.505
- 4.219
- 3.888
- 0.695
- 0.561
- 0.265
- 4.094
- 0.407
- 0.58
- 0.088
- 0.332
- 0.017
- 0.193
- 4.137
- 0.389
- 0.209
- 0.272
- 0.081
- 0.338
- 4.024
- 0.18
- 0.263
- 0.288
- 3.918
- 0.647
- 3.765
- 0.205
- 0.175
- 0.184
- 3.571
- 0.241
- 0.018
- 3.36
- 0.124
- 0.202
- 3.176
- 2.732
- 0.175
- 2.752
- 0.182
- 2.611
- 0.191
- 0.207
- 2.625
- 0.092
- 2.346
- 0.18
- 0.012
- 0.288
- 0.206
- 0.12
- 0.117
- 0.429
- 2.875
- 0.217
- 0.118
- 0.414
- 2.632
- 2.122
- 0.152
- 2.152
- 0.176
- 0.163
- 0.23
- 0.165
- 0.135
- 0.199
- 0.165
- 0.114
- 2.466
- 0.067
- 2.041
- 0.16
- 0.132
unequal: 0
verbose: 1
