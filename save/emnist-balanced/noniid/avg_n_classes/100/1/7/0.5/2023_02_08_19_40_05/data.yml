avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03180851063829787
- 0.058031914893617025
- 0.15648936170212766
- 0.2371808510638298
- 0.05356382978723404
- 0.3223404255319149
- 0.3956914893617021
- 0.4398404255319149
- 0.4622340425531915
- 0.4957446808510638
- 0.10803191489361702
- 0.5178723404255319
- 0.5242553191489362
- 0.5426595744680851
- 0.5509042553191489
- 0.5588829787234042
- 0.5625531914893617
- 0.5742021276595745
- 0.5752659574468085
- 0.5765957446808511
- 0.5820212765957447
- 0.6007446808510638
- 0.6037765957446809
- 0.6098404255319149
- 0.6138829787234042
- 0.6141489361702127
- 0.6195212765957446
- 0.6205851063829787
- 0.6175531914893617
- 0.4040957446808511
- 0.6288829787234043
- 0.6256914893617022
- 0.6302659574468085
- 0.6337234042553191
- 0.6343085106382979
- 0.635904255319149
- 0.6476063829787234
- 0.645
- 0.648031914893617
- 0.6507978723404255
- 0.6460638297872341
- 0.6519148936170213
- 0.6595744680851063
- 0.656436170212766
- 0.6576595744680851
- 0.6601595744680852
- 0.6612765957446809
- 0.666063829787234
- 0.6677127659574468
- 0.6627659574468086
- 0.6690425531914893
- 0.6668085106382978
- 0.6706914893617021
- 0.668563829787234
- 0.6718617021276596
- 0.6739893617021276
- 0.5102127659574468
- 0.6674468085106383
- 0.6714361702127659
- 0.676063829787234
- 0.5263829787234042
- 0.6708510638297872
- 0.6759042553191489
- 0.6772872340425532
- 0.6762234042553191
- 0.6775
- 0.678936170212766
- 0.6768617021276596
- 0.6813829787234043
- 0.6790425531914893
- 0.6820212765957446
- 0.6819148936170213
- 0.6826063829787234
- 0.6828191489361702
- 0.6852127659574468
- 0.6854255319148936
- 0.6843085106382979
- 0.681595744680851
- 0.6838829787234042
- 0.6875531914893617
- 0.6861702127659575
- 0.6857446808510639
- 0.6877127659574468
- 0.688936170212766
- 0.6893085106382979
- 0.6367021276595745
- 0.6889893617021277
- 0.6882446808510638
- 0.6849468085106383
- 0.6898404255319149
- 0.6861702127659575
- 0.6861170212765958
- 0.6867021276595745
- 0.6918085106382978
- 0.6924468085106383
- 0.6897872340425532
- 0.6928723404255319
- 0.6953723404255319
- 0.6955851063829788
- 0.6945744680851064
test_loss_list:
- 3.7880961004892986
- 3.746890172958374
- 3.604821809132894
- 3.3216228103637695
- 4.474368851979573
- 3.002617410024007
- 2.779492212931315
- 2.6224468580881752
- 2.5466058540344236
- 2.4719715245564777
- 4.120636253356934
- 2.321293598810832
- 2.306246983210246
- 2.311561985015869
- 2.291218992869059
- 2.28686474164327
- 2.2626572942733763
- 2.2788683573404946
- 2.2616901143391925
- 2.2310526116689045
- 2.261445746421814
- 2.246433348655701
- 2.1934701871871947
- 2.2132212257385255
- 2.2446169010798136
- 2.191623649597168
- 2.2421944316228233
- 2.237492178281148
- 2.1567413806915283
- 2.076332712173462
- 1.9977442423502605
- 2.0381194353103638
- 1.990016606648763
- 2.0521499888102213
- 2.0235813172658283
- 2.0810882886250814
- 2.018506588935852
- 1.9798315175374348
- 2.0063509305318195
- 1.9723815472920736
- 2.031570463180542
- 2.0051292832692464
- 1.9903080224990846
- 1.960389585494995
- 1.9892770338058472
- 1.993029276529948
- 1.9821693754196168
- 1.982582319577535
- 2.0125217485427855
- 1.94466996828715
- 1.95145041624705
- 1.9126417748133342
- 1.9442576456069947
- 1.9525747601191203
- 1.9028201707204182
- 1.946551677385966
- 1.6927401860555014
- 1.7108156951268514
- 1.7958287445704142
- 1.7781958484649658
- 1.6708261680603027
- 1.5406773424148559
- 1.5853542645772298
- 1.6267905569076537
- 1.6180744473139446
- 1.69150621732076
- 1.697453776995341
- 1.6476610787709554
- 1.7338784233729045
- 1.6977827421824137
- 1.705429565111796
- 1.683681658109029
- 1.7180204661687215
- 1.6974506743748983
- 1.685743474960327
- 1.6953449614842733
- 1.7037270800272624
- 1.6917600059509277
- 1.7180116399129233
- 1.703531896273295
- 1.7202351554234823
- 1.7490502802530925
- 1.6932825660705566
- 1.7352339283625284
- 1.6603850762049357
- 1.2721567964553833
- 1.4126975043614705
- 1.4991313378016153
- 1.5324366839726766
- 1.5407311852773031
- 1.4869502782821655
- 1.5547976938883463
- 1.5448002926508586
- 1.5199787092208863
- 1.5379674752553305
- 1.560748963356018
- 1.5736895434061686
- 1.5929616181055706
- 1.5642053906122844
- 1.56271524588267
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.612
- 0.0
- 0.0
- 0.0
- 0.0
- 0.575
- 0.704
- 0.0
- 0.0
- 0.0
- 0.0
- 0.648
- 0.677
- 0.0
- 0.0
- 0.0
- 0.679
- 0.0
- 0.0
- 0.0
- 0.717
- 0.0
- 0.737
- 0.731
- 0.0
- 0.685
- 0.74
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.75
- 0.0
- 0.0
- 0.0
- 0.0
- 0.775
- 0.781
- 0.783
- 0.0
- 0.792
- 0.0
- 0.0
- 0.779
- 0.0
- 0.773
- 0.794
- 0.0
- 0.0
- 0.0
- 0.748
- 0.0
- 0.79
- 0.781
- 0.777
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.8
- 0.0
- 0.794
- 0.0
- 0.802
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.8
- 0.515
- 0.0
- 0.0
- 0.002
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.8
- 0.0
- 0.0
- 0.0
train_loss:
- 1.783
- 1.068
- 1.667
- 0.869
- 0.187
- 0.722
- 1.228
- 1.133
- 0.6
- 1.005
- 0.185
- 0.965
- 0.537
- 0.926
- 0.557
- 0.858
- 0.519
- 0.506
- 0.517
- 0.51
- 0.495
- 0.488
- 0.494
- 0.77
- 1.024
- 0.5
- 0.997
- 0.744
- 0.491
- 0.213
- 0.969
- 0.436
- 0.446
- 0.668
- 0.446
- 0.417
- 0.443
- 0.445
- 0.409
- 0.677
- 0.415
- 0.646
- 0.643
- 0.42
- 0.423
- 0.403
- 0.623
- 0.617
- 0.817
- 0.434
- 0.612
- 0.413
- 0.406
- 0.598
- 0.397
- 0.595
- 0.193
- 0.308
- 0.546
- 0.362
- 0.186
- 0.291
- 0.346
- 0.555
- 0.35
- 0.545
- 0.533
- 0.356
- 0.734
- 0.369
- 0.35
- 0.359
- 0.528
- 0.534
- 0.536
- 0.371
- 0.532
- 0.348
- 0.52
- 0.54
- 0.523
- 0.516
- 0.355
- 0.518
- 0.351
- 0.168
- 0.271
- 0.297
- 0.316
- 0.312
- 0.348
- 0.314
- 0.315
- 0.34
- 0.504
- 0.332
- 0.496
- 0.493
- 0.505
- 0.324
unequal: 0
verbose: 1
