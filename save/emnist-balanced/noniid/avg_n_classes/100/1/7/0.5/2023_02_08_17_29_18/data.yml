avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04824468085106383
- 0.10345744680851064
- 0.18936170212765957
- 0.27872340425531916
- 0.37053191489361703
- 0.4140957446808511
- 0.4493617021276596
- 0.08531914893617021
- 0.4798936170212766
- 0.5027127659574468
- 0.2328191489361702
- 0.5184042553191489
- 0.5263829787234042
- 0.5402127659574468
- 0.5564893617021277
- 0.5669148936170213
- 0.5692553191489361
- 0.5836170212765958
- 0.5860106382978724
- 0.593563829787234
- 0.39851063829787237
- 0.5956382978723405
- 0.6042553191489362
- 0.606063829787234
- 0.6184042553191489
- 0.6218085106382979
- 0.6236170212765958
- 0.6287234042553191
- 0.6273936170212766
- 0.6303191489361702
- 0.6364893617021277
- 0.6409574468085106
- 0.6443085106382979
- 0.644468085106383
- 0.6464893617021277
- 0.6475531914893617
- 0.6503191489361703
- 0.4600531914893617
- 0.6555851063829787
- 0.6562234042553191
- 0.6593085106382979
- 0.661595744680851
- 0.6626595744680851
- 0.6598404255319149
- 0.5587234042553192
- 0.6597340425531915
- 0.6608510638297872
- 0.664468085106383
- 0.6671808510638297
- 0.6697872340425531
- 0.6707978723404255
- 0.6693085106382979
- 0.6686170212765957
- 0.6693085106382979
- 0.6731914893617021
- 0.6005851063829787
- 0.6737765957446809
- 0.6748404255319149
- 0.6765425531914894
- 0.6740425531914893
- 0.6755851063829788
- 0.676595744680851
- 0.6781382978723405
- 0.6758510638297872
- 0.6743085106382979
- 0.6807978723404255
- 0.6782978723404255
- 0.6774468085106383
- 0.6806914893617021
- 0.6813297872340426
- 0.6812234042553191
- 0.6818617021276596
- 0.6825531914893617
- 0.6727127659574468
- 0.45398936170212767
- 0.6846808510638298
- 0.685
- 0.6829787234042554
- 0.6823404255319149
- 0.6843085106382979
- 0.6602127659574468
- 0.6868617021276596
- 0.6862765957446808
- 0.683936170212766
- 0.6873404255319149
- 0.6868617021276596
- 0.6905851063829788
- 0.6846276595744681
- 0.6851595744680851
- 0.6915425531914894
- 0.6926595744680851
- 0.6623404255319149
- 0.6886702127659574
- 0.691063829787234
- 0.6894148936170212
- 0.6881382978723404
- 0.6927127659574468
- 0.6879255319148936
- 0.6854787234042553
- 0.6936170212765957
test_loss_list:
- 3.7760252571105957
- 3.6765629768371584
- 3.45127498626709
- 3.166150951385498
- 2.9104807726542155
- 2.7396973673502605
- 2.638918285369873
- 4.025555826822917
- 2.44899037361145
- 2.4093394247690836
- 2.9078593571980793
- 2.233493372599284
- 2.2216114616394043
- 2.2233535941441853
- 2.2063381052017212
- 2.2123562637964884
- 2.223851197560628
- 2.200970390637716
- 2.1637180852890014
- 2.169854737917582
- 2.3272624651590985
- 1.984354837735494
- 2.0073858944574994
- 2.0370617278416954
- 2.016837935447693
- 2.051124582290649
- 2.0429500675201417
- 2.0374180126190184
- 2.0719968763987224
- 2.016344065666199
- 2.0175934425989785
- 2.063467439015706
- 2.033201559384664
- 2.027353237469991
- 2.0643914302190143
- 2.0298197237650553
- 2.034455270767212
- 1.9589479319254557
- 1.7824222803115846
- 1.8424966382980346
- 1.85435906569163
- 1.9189215024312338
- 1.899438632329305
- 1.898538252512614
- 1.6161506589253742
- 1.6093468809127807
- 1.6898285230000814
- 1.6867961676915486
- 1.764066333770752
- 1.77069167137146
- 1.8053245782852172
- 1.794468911488851
- 1.761752781867981
- 1.7790370607376098
- 1.7647302389144897
- 1.483700450261434
- 1.5474974950154623
- 1.6298124122619628
- 1.6742450745900472
- 1.655308698018392
- 1.6539869451522826
- 1.6471694978078206
- 1.6849930334091185
- 1.6844278160730999
- 1.7040051015218098
- 1.717943147023519
- 1.7158779605229695
- 1.693684991200765
- 1.6634569215774535
- 1.6530661090215046
- 1.6725625960032144
- 1.7095261081059774
- 1.6957198413213095
- 1.2221159823735555
- 1.9126100587844848
- 1.31580575466156
- 1.4213054275512695
- 1.4339993000030518
- 1.4728916708628337
- 1.509992504119873
- 1.2040704425175985
- 1.307230666478475
- 1.3931420612335206
- 1.392564377784729
- 1.4576031637191773
- 1.4789980109532674
- 1.5136581325531007
- 1.5111079104741414
- 1.5431323671340942
- 1.4859337647755941
- 1.5212173811594645
- 1.2414998992284139
- 1.284215397834778
- 1.339139544169108
- 1.3985666624704998
- 1.4443203512827556
- 1.4161340268452962
- 1.4712870868047079
- 1.4816955089569093
- 1.4513968801498414
train_accuracy:
- 0.0
- 0.129
- 0.225
- 0.0
- 0.44
- 0.0
- 0.562
- 0.525
- 0.0
- 0.0
- 0.075
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.679
- 0.0
- 0.727
- 0.019
- 0.0
- 0.0
- 0.0
- 0.0
- 0.729
- 0.737
- 0.0
- 0.0
- 0.744
- 0.767
- 0.0
- 0.752
- 0.0
- 0.0
- 0.0
- 0.785
- 0.8
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.49
- 0.798
- 0.0
- 0.794
- 0.804
- 0.0
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.935
- 0.0
- 0.012
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.804
- 0.808
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.0
- 0.821
- 0.677
- 0.942
- 0.815
- 0.825
- 0.0
- 0.0
- 0.002
- 0.779
- 0.817
- 0.0
- 0.829
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.81
- 0.006
- 0.521
- 0.002
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
train_loss:
- 1.708
- 1.061
- 1.559
- 0.816
- 1.321
- 0.694
- 1.129
- 0.214
- 1.05
- 1.007
- 0.195
- 0.953
- 0.548
- 0.532
- 0.521
- 1.216
- 0.512
- 0.818
- 0.52
- 0.496
- 0.197
- 0.453
- 0.474
- 0.448
- 0.756
- 1.001
- 0.717
- 0.712
- 0.426
- 0.463
- 0.454
- 0.934
- 0.697
- 0.677
- 0.671
- 0.449
- 0.447
- 0.204
- 0.9
- 0.883
- 0.643
- 0.847
- 0.629
- 0.408
- 0.199
- 0.337
- 0.371
- 0.387
- 0.822
- 0.594
- 0.806
- 0.602
- 0.382
- 0.379
- 0.378
- 0.164
- 0.31
- 0.555
- 0.764
- 0.368
- 0.355
- 0.378
- 0.573
- 0.354
- 0.363
- 0.758
- 0.346
- 0.362
- 0.374
- 0.369
- 0.356
- 0.37
- 0.55
- 0.173
- 0.1
- 0.532
- 0.503
- 0.338
- 0.334
- 0.332
- 0.143
- 0.519
- 0.508
- 0.329
- 0.326
- 0.509
- 0.694
- 0.327
- 0.328
- 0.344
- 0.692
- 0.145
- 0.296
- 0.501
- 0.497
- 0.313
- 0.516
- 0.312
- 0.31
- 0.51
unequal: 0
verbose: 1
