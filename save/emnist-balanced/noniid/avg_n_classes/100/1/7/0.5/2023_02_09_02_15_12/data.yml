avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04345744680851064
- 0.09329787234042553
- 0.21053191489361703
- 0.3071276595744681
- 0.3677659574468085
- 0.42936170212765956
- 0.4526595744680851
- 0.46941489361702127
- 0.503563829787234
- 0.5127127659574469
- 0.20090425531914893
- 0.06686170212765957
- 0.06547872340425531
- 0.521595744680851
- 0.5331382978723405
- 0.5462234042553191
- 0.5555851063829788
- 0.5685106382978723
- 0.5776595744680851
- 0.581968085106383
- 0.5832446808510638
- 0.5941489361702128
- 0.5945744680851064
- 0.5914893617021276
- 0.6029787234042553
- 0.605
- 0.6107446808510638
- 0.6157446808510638
- 0.6163829787234043
- 0.6194148936170213
- 0.6182978723404255
- 0.6196276595744681
- 0.6224468085106383
- 0.6303191489361702
- 0.6290425531914894
- 0.6364893617021277
- 0.6327659574468085
- 0.6405851063829787
- 0.4348936170212766
- 0.6405851063829787
- 0.6433510638297872
- 0.6419148936170213
- 0.48095744680851066
- 0.6493617021276595
- 0.5961170212765957
- 0.6497872340425532
- 0.6445212765957447
- 0.5880319148936171
- 0.6525
- 0.6563829787234042
- 0.586968085106383
- 0.3891489361702128
- 0.6531382978723405
- 0.6532978723404256
- 0.6592021276595744
- 0.6559574468085106
- 0.6625
- 0.6159042553191489
- 0.6648936170212766
- 0.6652659574468085
- 0.6655851063829787
- 0.6628723404255319
- 0.6673404255319149
- 0.665
- 0.6673936170212766
- 0.6711702127659575
- 0.6697340425531915
- 0.6681382978723405
- 0.6701063829787234
- 0.6731382978723405
- 0.6717021276595745
- 0.6761702127659575
- 0.6709574468085107
- 0.5906382978723405
- 0.6721276595744681
- 0.6723936170212766
- 0.6713297872340426
- 0.6778723404255319
- 0.6792553191489362
- 0.6770212765957446
- 0.6754255319148936
- 0.6801063829787234
- 0.6816489361702127
- 0.6810106382978723
- 0.6817021276595745
- 0.6835106382978723
- 0.6804787234042553
- 0.6812234042553191
- 0.6764893617021277
- 0.6808510638297872
- 0.6836170212765957
- 0.6857978723404256
- 0.6823936170212765
- 0.6864893617021277
- 0.6847340425531915
- 0.6850531914893617
- 0.6823404255319149
- 0.6842553191489362
- 0.6820212765957446
- 0.6893085106382979
test_loss_list:
- 3.768418544133504
- 3.6695760981241863
- 3.422262700398763
- 3.1326631704966226
- 2.8890718523661296
- 2.722767588297526
- 2.6330006726582846
- 2.531567211151123
- 2.476241423288981
- 2.4338204924265545
- 3.1534113470713296
- 6.193248875935873
- 7.0430780665079755
- 2.2222956879933675
- 2.262987451553345
- 2.2530159743626914
- 2.2968447653452557
- 2.2509735504786175
- 2.2223936716715493
- 2.2390639845530194
- 2.2176253350575763
- 2.2225474325815835
- 2.209096131324768
- 2.2263143396377565
- 2.183847510019938
- 2.208490716616313
- 2.1526104084650677
- 2.1396012910207114
- 2.137351597150167
- 2.1569785849253336
- 2.1288700008392336
- 2.0935432624816896
- 2.12918097337087
- 2.1160084851582845
- 2.058292358716329
- 2.113529955546061
- 2.1355976168314617
- 2.1079224077860514
- 2.040746766726176
- 1.746806003252665
- 1.8049863179524739
- 1.8706366920471191
- 1.832638692855835
- 1.6576851399739583
- 1.4581126340230306
- 1.5725931803385416
- 1.6678367948532105
- 1.4356284189224242
- 1.5269020334879557
- 1.6228945207595826
- 1.3917938566207886
- 2.1895570850372312
- 1.4223675950368246
- 1.5150144131978354
- 1.5522969802220663
- 1.578058312733968
- 1.5886354033152263
- 1.3489166831970214
- 1.444105798403422
- 1.508245309193929
- 1.5744233926137288
- 1.2253457911809285
- 1.3875660657882691
- 1.476641936302185
- 1.484600806236267
- 1.5178549019495646
- 1.5253573767344157
- 1.55054674466451
- 1.5628176657358805
- 1.5591729227701823
- 1.5688201045989991
- 1.5778973261515299
- 1.5940957101186117
- 1.3555104303359986
- 1.3798015483220418
- 1.4582787450154622
- 1.4786792182922364
- 1.4931783199310302
- 1.4948513380686441
- 1.5043376223246256
- 1.5177151266733806
- 1.500158454577128
- 1.5593212270736694
- 1.5212507836023967
- 1.5239131132761636
- 1.532757789293925
- 1.5617793083190918
- 1.5484407488505045
- 1.1685171635945637
- 1.3329163026809692
- 1.3609212525685628
- 1.3932685995101928
- 1.4269724067052205
- 1.427800432840983
- 1.4551231098175048
- 1.101251532236735
- 1.2442926820119222
- 1.3231993659337362
- 1.3597661511103312
- 1.358850483894348
train_accuracy:
- 0.054
- 0.0
- 0.271
- 0.379
- 0.0
- 0.0
- 0.0
- 0.54
- 0.0
- 0.0
- 0.346
- 0.179
- 0.781
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.71
- 0.688
- 0.0
- 0.0
- 0.0
- 0.0
- 0.71
- 0.746
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.729
- 0.744
- 0.0
- 0.754
- 0.665
- 0.0
- 0.0
- 0.75
- 0.929
- 0.763
- 0.935
- 0.769
- 0.0
- 0.567
- 0.763
- 0.0
- 0.665
- 0.981
- 0.781
- 0.002
- 0.0
- 0.0
- 0.0
- 0.852
- 0.0
- 0.798
- 0.792
- 0.41
- 0.792
- 0.794
- 0.79
- 0.0
- 0.792
- 0.0
- 0.0
- 0.0
- 0.796
- 0.802
- 0.0
- 0.906
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.804
- 0.0
- 0.892
- 0.01
- 0.004
- 0.817
- 0.812
- 0.0
- 0.0
- 0.89
- 0.021
- 0.0
- 0.0
- 0.0
train_loss:
- 1.743
- 1.66
- 1.595
- 1.448
- 0.759
- 0.725
- 0.676
- 0.661
- 1.04
- 1.015
- 0.239
- 0.105
- 0.086
- 0.547
- 0.551
- 0.911
- 0.879
- 0.872
- 0.87
- 0.847
- 0.51
- 0.822
- 0.829
- 0.514
- 0.512
- 0.521
- 0.521
- 0.492
- 0.486
- 0.492
- 0.487
- 0.464
- 0.463
- 0.732
- 0.486
- 0.713
- 0.451
- 0.454
- 0.229
- 0.406
- 0.43
- 0.426
- 0.184
- 0.919
- 0.147
- 0.914
- 0.386
- 0.151
- 0.626
- 0.612
- 0.153
- 0.073
- 0.598
- 0.352
- 0.634
- 0.361
- 0.627
- 0.14
- 0.832
- 0.826
- 0.82
- 0.142
- 0.575
- 0.565
- 0.354
- 0.586
- 0.6
- 0.364
- 0.363
- 0.378
- 0.383
- 0.587
- 0.37
- 0.163
- 0.315
- 0.332
- 0.345
- 0.563
- 0.362
- 0.361
- 0.345
- 0.368
- 0.552
- 0.361
- 0.554
- 0.561
- 0.553
- 0.347
- 0.159
- 0.29
- 0.543
- 0.336
- 0.543
- 0.336
- 0.341
- 0.141
- 0.287
- 0.511
- 0.342
- 0.328
unequal: 0
verbose: 1
