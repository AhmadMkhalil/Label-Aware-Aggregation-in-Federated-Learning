avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04367021276595745
- 0.04281914893617021
- 0.12170212765957447
- 0.2049468085106383
- 0.020425531914893616
- 0.3151063829787234
- 0.3874468085106383
- 0.4243085106382979
- 0.4643617021276596
- 0.4806382978723404
- 0.48819148936170215
- 0.5108510638297873
- 0.5226595744680851
- 0.5243617021276595
- 0.5406382978723404
- 0.5387765957446808
- 0.5580851063829787
- 0.5638829787234042
- 0.5652127659574468
- 0.5707446808510638
- 0.22058510638297874
- 0.58
- 0.5821808510638298
- 0.5932978723404255
- 0.5976595744680852
- 0.6001063829787234
- 0.6038297872340426
- 0.6110106382978724
- 0.616968085106383
- 0.6138297872340426
- 0.6186702127659575
- 0.6295744680851064
- 0.63
- 0.6245744680851064
- 0.6380851063829788
- 0.6322872340425532
- 0.6322340425531915
- 0.637340425531915
- 0.6425531914893617
- 0.6451063829787234
- 0.6478191489361702
- 0.6538297872340425
- 0.6570744680851064
- 0.6578723404255319
- 0.6591489361702128
- 0.6532446808510638
- 0.6590957446808511
- 0.6552127659574468
- 0.6604787234042553
- 0.6538297872340425
- 0.666063829787234
- 0.6689893617021276
- 0.6656914893617021
- 0.6693617021276596
- 0.5068085106382979
- 0.6675531914893617
- 0.6714893617021277
- 0.6731914893617021
- 0.6675531914893617
- 0.6735106382978724
- 0.6737234042553192
- 0.6721808510638297
- 0.6770744680851064
- 0.6798404255319149
- 0.6790425531914893
- 0.6805851063829788
- 0.6727659574468086
- 0.6822872340425532
- 0.6788829787234043
- 0.678936170212766
- 0.5917553191489362
- 0.6800531914893617
- 0.6852659574468085
- 0.6832446808510638
- 0.6864361702127659
- 0.6837765957446809
- 0.6872872340425532
- 0.6838829787234042
- 0.6888297872340425
- 0.6853191489361702
- 0.6875531914893617
- 0.6884574468085106
- 0.6888829787234042
- 0.6887234042553192
- 0.686968085106383
- 0.6925
- 0.685372340425532
- 0.6860106382978723
- 0.5857446808510638
- 0.6916489361702127
- 0.6909042553191489
- 0.6925
- 0.6924468085106383
- 0.691968085106383
- 0.6886170212765957
- 0.6913297872340426
- 0.6877127659574468
- 0.694468085106383
- 0.6536170212765957
- 0.6905851063829788
test_loss_list:
- 3.7824472490946452
- 4.674196968078613
- 3.645026626586914
- 3.3786114025115968
- 4.982346439361573
- 3.0408217843373615
- 2.825250832239787
- 2.701465304692586
- 2.619963353474935
- 2.5860698795318604
- 2.552643928527832
- 2.519500535329183
- 2.529111010233561
- 2.456625839869181
- 2.4643853759765624
- 2.488028008143107
- 2.468618625005086
- 2.437363688151042
- 2.3984690729777016
- 2.436603759129842
- 2.8993983459472656
- 2.2047049633661904
- 2.207797139485677
- 2.2372691456476845
- 2.252489512761434
- 2.227232650121053
- 2.2236060444513956
- 2.2246772464116416
- 2.2519569412867226
- 2.149220701853434
- 2.1947639910380046
- 2.2262569077809653
- 2.2530966409047446
- 2.2990157906214397
- 2.164928477605184
- 2.227465170224508
- 2.25673908551534
- 2.253610617319743
- 2.217452629407247
- 2.155186807314555
- 2.1925829680760702
- 2.1196429443359377
- 2.183052824338277
- 2.1801079591115315
- 2.150213836034139
- 2.1878922669092815
- 2.1671084769566855
- 2.1144052998224896
- 2.1584604740142823
- 2.120316677093506
- 2.0611941830317178
- 2.0933739932378135
- 2.0121233669916787
- 2.010852068265279
- 1.8654777352015177
- 1.8261031818389892
- 1.876410566965739
- 1.9194673331578573
- 1.9541217629114787
- 1.8506874624888103
- 1.983338589668274
- 1.8344155899683634
- 1.8954513835906983
- 1.930964937210083
- 1.8831765063603718
- 1.9339594793319703
- 1.983933669726054
- 1.9263985617955526
- 1.9975564845403035
- 1.8341194105148315
- 1.538297856648763
- 1.6077337535222371
- 1.705148696899414
- 1.726803789138794
- 1.7696182139714558
- 1.6962235275904338
- 1.7909517526626586
- 1.7402049271265665
- 1.7663315677642821
- 1.8349637730916342
- 1.8192212708791098
- 1.8442592239379882
- 1.8352104616165161
- 1.7612006251017254
- 1.7108014551798503
- 1.8214650042851765
- 1.7505452728271484
- 1.8549287350972494
- 1.5147411028544109
- 1.5390583419799804
- 1.579118274052938
- 1.6456673240661621
- 1.6940085061391195
- 1.6608805545171101
- 1.6328273264567057
- 1.7136318238576254
- 1.7780525414148967
- 1.7114994430541992
- 1.3087399323781332
- 1.4108248058954875
train_accuracy:
- 0.025
- 0.0
- 0.144
- 0.252
- 0.794
- 0.0
- 0.452
- 0.0
- 0.0
- 0.579
- 0.0
- 0.0
- 0.0
- 0.0
- 0.627
- 0.0
- 0.0
- 0.696
- 0.0
- 0.0
- 0.979
- 0.0
- 0.0
- 0.688
- 0.0
- 0.0
- 0.0
- 0.0
- 0.692
- 0.0
- 0.723
- 0.76
- 0.76
- 0.0
- 0.758
- 0.752
- 0.0
- 0.754
- 0.75
- 0.0
- 0.79
- 0.781
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.325
- 0.0
- 0.779
- 0.0
- 0.798
- 0.0
- 0.802
- 0.802
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.765
- 0.785
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.815
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.963
- 0.0
- 0.819
- 0.827
- 0.806
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.954
- 0.0
train_loss:
- 1.796
- 0.402
- 1.576
- 0.865
- 0.163
- 0.724
- 1.237
- 0.636
- 1.076
- 1.049
- 0.607
- 0.989
- 0.954
- 0.59
- 0.908
- 0.574
- 0.886
- 0.881
- 0.556
- 0.526
- 0.232
- 0.824
- 0.496
- 0.804
- 0.772
- 0.498
- 0.489
- 0.763
- 0.713
- 0.511
- 0.465
- 0.974
- 0.732
- 0.456
- 0.724
- 0.45
- 0.439
- 0.443
- 0.678
- 0.456
- 0.668
- 0.688
- 0.882
- 0.871
- 0.66
- 0.431
- 0.642
- 0.436
- 0.416
- 0.436
- 0.445
- 0.626
- 0.453
- 0.422
- 0.215
- 0.34
- 0.576
- 0.563
- 0.358
- 0.393
- 0.369
- 0.411
- 0.582
- 0.77
- 0.613
- 0.572
- 0.383
- 0.775
- 0.371
- 0.419
- 0.193
- 0.303
- 0.535
- 0.534
- 0.743
- 0.367
- 0.737
- 0.361
- 0.568
- 0.35
- 0.56
- 0.718
- 0.721
- 0.375
- 0.384
- 0.714
- 0.383
- 0.354
- 0.185
- 0.729
- 0.542
- 0.533
- 0.704
- 0.524
- 0.354
- 0.522
- 0.336
- 0.699
- 0.183
- 0.506
unequal: 0
verbose: 1
