avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022287234042553193
- 0.023457446808510637
- 0.0600531914893617
- 0.15324468085106382
- 0.2797340425531915
- 0.37388297872340426
- 0.41973404255319147
- 0.13813829787234042
- 0.4595744680851064
- 0.48345744680851066
- 0.4928723404255319
- 0.516595744680851
- 0.5328723404255319
- 0.2627127659574468
- 0.18170212765957447
- 0.05968085106382979
- 0.5429255319148936
- 0.5515425531914894
- 0.5606382978723404
- 0.568404255319149
- 0.5777127659574468
- 0.5845744680851064
- 0.5825531914893617
- 0.5947872340425532
- 0.6023936170212766
- 0.5952127659574468
- 0.6041489361702128
- 0.6029255319148936
- 0.6176063829787234
- 0.6173936170212766
- 0.6181914893617021
- 0.6217021276595744
- 0.6199468085106383
- 0.6260638297872341
- 0.6292021276595745
- 0.6393085106382979
- 0.6336170212765957
- 0.6336702127659575
- 0.6418617021276596
- 0.5182978723404256
- 0.6386702127659575
- 0.6436170212765957
- 0.6527659574468085
- 0.6534574468085106
- 0.6519680851063829
- 0.6568085106382979
- 0.6587234042553192
- 0.5361170212765958
- 0.6571276595744681
- 0.6545212765957447
- 0.6516489361702128
- 0.6598936170212766
- 0.6648936170212766
- 0.6612765957446809
- 0.666968085106383
- 0.6695744680851063
- 0.6684574468085106
- 0.6679255319148936
- 0.6729787234042554
- 0.6727659574468086
- 0.6698404255319149
- 0.6743617021276596
- 0.6747872340425531
- 0.6720744680851064
- 0.6200531914893617
- 0.6711170212765958
- 0.6728723404255319
- 0.6704787234042553
- 0.6703191489361702
- 0.6709574468085107
- 0.6793085106382979
- 0.6772872340425532
- 0.6809042553191489
- 0.680531914893617
- 0.6797872340425531
- 0.6786702127659574
- 0.6779255319148936
- 0.6843085106382979
- 0.6825531914893617
- 0.6864893617021277
- 0.6847872340425532
- 0.6847340425531915
- 0.6838297872340425
- 0.683031914893617
- 0.6863297872340426
- 0.6848936170212766
- 0.6822340425531915
- 0.6867553191489362
- 0.6834574468085106
- 0.6876063829787235
- 0.6885638297872341
- 0.6454787234042553
- 0.6855851063829788
- 0.6184042553191489
- 0.6901063829787234
- 0.6885106382978723
- 0.6895744680851064
- 0.686968085106383
- 0.6868617021276596
- 0.6859042553191489
test_loss_list:
- 3.7949807262420654
- 3.773483409881592
- 3.690978479385376
- 3.484432274500529
- 3.190765546162923
- 2.918420432408651
- 2.7557493368784587
- 4.259947891235352
- 2.5589285945892333
- 2.499610242843628
- 2.4323251247406006
- 2.3983382320404054
- 2.3951763025919597
- 2.8077906958262124
- 4.098822876612346
- 5.473680171966553
- 2.10530766805013
- 2.1706541633605956
- 2.157496231396993
- 2.1540732383728027
- 2.1663742701212567
- 2.141214380264282
- 2.146736660003662
- 2.1516930214564005
- 2.146584507624308
- 2.1387791220347085
- 2.159032897949219
- 2.1285784753163655
- 2.0882939608891804
- 2.0883274157842
- 2.139272405306498
- 2.0823169803619384
- 2.083312258720398
- 2.1407476727167767
- 2.096738665898641
- 2.103630021413167
- 2.1157870880762735
- 2.0942655261357626
- 2.0553041299184165
- 1.7874728965759277
- 1.8258151626586914
- 1.9121826394399006
- 1.942310357093811
- 1.8936615737279257
- 1.9687186765670777
- 1.9603855244318644
- 1.9452741066614787
- 1.6949227746327717
- 1.675573499997457
- 1.7673616631825766
- 1.7988293170928955
- 1.8097991879781088
- 1.824883500734965
- 1.825403265953064
- 1.8013982518513998
- 1.7879907576243084
- 1.8280259482065837
- 1.8413465372721354
- 1.80864648660024
- 1.8363300021489461
- 1.832850325902303
- 1.8087311999003093
- 1.8247423887252807
- 1.8405250740051269
- 1.4073091538747151
- 1.55675320148468
- 1.5983888546625773
- 1.6374120982487996
- 1.630010313987732
- 1.6511823383967081
- 1.6087017647425335
- 1.5815014934539795
- 1.6636571470896404
- 1.6499236742655436
- 1.6198674551645915
- 1.6424983247121174
- 1.679520969390869
- 1.6289391326904297
- 1.6579561185836793
- 1.6419236024220785
- 1.668247431119283
- 1.621940155029297
- 1.6665394941965739
- 1.6243985970815022
- 1.6107079076766968
- 1.635006554921468
- 1.7024140882492065
- 1.6175930325190226
- 1.6412518692016602
- 1.608615789413452
- 1.6766252215703328
- 1.2904717874526979
- 1.3319698429107667
- 1.2537365659077961
- 1.2614842828114827
- 1.344038543701172
- 1.406661361058553
- 1.4365599981943766
- 1.4593757534027099
- 1.490020219484965
train_accuracy:
- 0.023
- 0.0
- 0.06
- 0.0
- 0.0
- 0.465
- 0.0
- 0.662
- 0.579
- 0.0
- 0.0
- 0.606
- 0.633
- 0.842
- 0.446
- 0.302
- 0.0
- 0.0
- 0.0
- 0.0
- 0.706
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.742
- 0.0
- 0.0
- 0.785
- 0.696
- 0.0
- 0.758
- 0.8
- 0.0
- 0.0
- 0.808
- 0.0
- 0.533
- 0.806
- 0.0
- 0.0
- 0.81
- 0.815
- 0.756
- 0.0
- 0.0
- 0.773
- 0.767
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.498
- 0.769
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.821
- 0.779
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.844
- 0.865
- 0.0
- 0.542
- 0.0
- 0.81
- 0.787
- 0.0
- 0.785
- 0.0
train_loss:
- 1.79
- 1.782
- 1.042
- 0.973
- 1.459
- 1.315
- 0.712
- 0.214
- 1.134
- 1.054
- 0.605
- 0.586
- 1.319
- 0.202
- 0.117
- 0.087
- 0.931
- 0.846
- 0.86
- 0.825
- 0.813
- 0.509
- 0.489
- 0.801
- 0.806
- 0.496
- 0.469
- 0.478
- 0.48
- 0.472
- 0.447
- 0.476
- 0.452
- 0.448
- 0.48
- 0.958
- 0.434
- 0.457
- 0.721
- 0.194
- 0.341
- 0.372
- 0.876
- 0.677
- 0.64
- 0.886
- 0.669
- 0.199
- 0.358
- 0.353
- 0.352
- 0.609
- 0.822
- 0.389
- 0.615
- 0.604
- 0.576
- 0.576
- 0.605
- 0.593
- 0.392
- 0.595
- 0.59
- 0.573
- 0.186
- 0.333
- 0.338
- 0.338
- 0.359
- 0.34
- 0.379
- 0.384
- 0.54
- 0.561
- 0.377
- 0.36
- 0.35
- 0.556
- 0.554
- 0.556
- 0.547
- 0.36
- 0.355
- 0.358
- 0.364
- 0.348
- 0.336
- 0.356
- 0.349
- 0.363
- 0.707
- 0.174
- 0.312
- 0.14
- 0.48
- 0.493
- 0.488
- 0.502
- 0.307
- 0.307
unequal: 0
verbose: 1
