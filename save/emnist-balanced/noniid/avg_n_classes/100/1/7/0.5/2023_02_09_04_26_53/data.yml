avg_train_accuracy: 0.858
avg_train_loss: 0.001
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0225
- 0.039787234042553195
- 0.11569148936170212
- 0.20457446808510638
- 0.29148936170212764
- 0.3805851063829787
- 0.4251595744680851
- 0.10829787234042554
- 0.44941489361702125
- 0.4731382978723404
- 0.1752659574468085
- 0.4959574468085106
- 0.5104255319148936
- 0.5198404255319149
- 0.25622340425531914
- 0.5304787234042553
- 0.5407978723404255
- 0.5375
- 0.5446276595744681
- 0.5668617021276596
- 0.5711170212765957
- 0.5793085106382979
- 0.5857978723404256
- 0.3561170212765957
- 0.5829255319148936
- 0.5963297872340425
- 0.35808510638297875
- 0.5936702127659574
- 0.5982446808510639
- 0.6120212765957447
- 0.612659574468085
- 0.6177659574468085
- 0.620904255319149
- 0.6192021276595745
- 0.6263829787234042
- 0.6341489361702127
- 0.6327127659574469
- 0.6342021276595745
- 0.6433510638297872
- 0.6476595744680851
- 0.6419148936170213
- 0.6447872340425532
- 0.6406914893617022
- 0.6528723404255319
- 0.6544148936170213
- 0.6554255319148936
- 0.6586170212765957
- 0.6562234042553191
- 0.48132978723404257
- 0.6563829787234042
- 0.6570744680851064
- 0.6600531914893617
- 0.6589893617021276
- 0.6644148936170213
- 0.5485638297872341
- 0.6593617021276595
- 0.6697340425531915
- 0.6658510638297872
- 0.6654255319148936
- 0.6712234042553191
- 0.6743617021276596
- 0.6752659574468085
- 0.6682978723404255
- 0.675
- 0.6770744680851064
- 0.5223404255319148
- 0.6705851063829787
- 0.6777659574468086
- 0.6778723404255319
- 0.5963829787234043
- 0.6778723404255319
- 0.6775
- 0.6762765957446808
- 0.6830851063829787
- 0.6806914893617021
- 0.6836702127659574
- 0.6875
- 0.6830851063829787
- 0.6859574468085107
- 0.6802127659574468
- 0.686595744680851
- 0.6864361702127659
- 0.625
- 0.6840957446808511
- 0.6825531914893617
- 0.6393617021276595
- 0.43882978723404253
- 0.6907978723404256
- 0.689468085106383
- 0.6890957446808511
- 0.6854255319148936
- 0.6879255319148936
- 0.6865425531914894
- 0.6928723404255319
- 0.6898404255319149
- 0.6918085106382978
- 0.6560106382978723
- 0.6925531914893617
- 0.6906382978723404
- 0.6593617021276595
test_loss_list:
- 5.258259855906169
- 3.755966691970825
- 3.6567175579071045
- 3.404537391662598
- 3.1052345657348632
- 2.87764092763265
- 2.732896852493286
- 3.7734165636698407
- 2.54992514928182
- 2.5341201559702555
- 3.2793490886688232
- 2.3690610980987548
- 2.373022969563802
- 2.3621192836761473
- 2.834600327809652
- 2.2399639749526976
- 2.245606547991435
- 2.250704935391744
- 2.2720370801289875
- 2.2607221301396687
- 2.246906978289286
- 2.249154907862345
- 2.244496989250183
- 2.342343142827352
- 2.013477470080058
- 2.0573998244603473
- 2.2804270044962567
- 1.9276656707127888
- 1.9768979994455973
- 2.0321750195821124
- 2.0258764966328937
- 2.0199189519882204
- 2.0019632148742676
- 2.028505360285441
- 1.9896194632848103
- 2.016083246866862
- 2.006505912144979
- 2.0345105791091918
- 2.045479426383972
- 2.062049862543742
- 2.005690253575643
- 1.9815947135289511
- 2.00937335173289
- 2.030696268081665
- 1.9908736244837444
- 1.9640535449981689
- 1.9817940521240234
- 1.906243275006612
- 1.9075569836298625
- 1.7093389701843262
- 1.7385780493418375
- 1.7757811959584553
- 1.7932936557133992
- 1.8108670234680175
- 1.6041602039337157
- 1.5579867728551229
- 1.68090651512146
- 1.7126363325119018
- 1.7113409074147543
- 1.7330193074544271
- 1.7705271784464518
- 1.7707684055964152
- 1.774432323773702
- 1.7710484091440837
- 1.7632570473353069
- 1.7640890407562255
- 1.5091206455230712
- 1.6058710606892903
- 1.6438223505020142
- 1.4642914501825968
- 1.4439908075332641
- 1.5159832763671874
- 1.5476010322570801
- 1.6002697070439658
- 1.6224277846018473
- 1.6068170722325643
- 1.6181318950653076
- 1.641415851910909
- 1.6333010260264078
- 1.617731884320577
- 1.6426141834259034
- 1.6673394107818604
- 1.3662011702855428
- 1.3800768804550172
- 1.4219204775492351
- 1.2192153549194336
- 1.8618862946828207
- 1.212135186990102
- 1.3050572554270425
- 1.3528405364354452
- 1.377063946723938
- 1.4208058341344199
- 1.4208339246114094
- 1.425815553665161
- 1.4632101265589397
- 1.4765894110997517
- 1.211073211034139
- 1.267075883547465
- 1.3485431051254273
- 1.1694641009966533
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.588
- 0.0
- 0.0
- 0.602
- 0.0
- 0.0
- 0.617
- 0.408
- 0.0
- 0.0
- 0.0
- 0.642
- 0.0
- 0.0
- 0.0
- 0.698
- 0.558
- 0.0
- 0.0
- 0.052
- 0.721
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.765
- 0.763
- 0.0
- 0.0
- 0.763
- 0.0
- 0.0
- 0.0
- 0.0
- 0.863
- 0.0
- 0.0
- 0.0
- 0.0
- 0.781
- 0.483
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.0
- 0.775
- 0.0
- 0.0
- 0.0
- 0.467
- 0.0
- 0.808
- 0.0
- 0.892
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.783
- 0.0
- 0.0
- 0.815
- 0.0
- 0.812
- 0.0
- 0.596
- 0.002
- 0.0
- 0.446
- 0.958
- 0.794
- 0.017
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.556
- 0.117
- 0.0
- 0.858
train_loss:
- 0.327
- 1.631
- 0.955
- 1.547
- 1.399
- 1.279
- 0.674
- 0.192
- 1.131
- 0.611
- 0.174
- 1.019
- 0.976
- 0.556
- 0.171
- 0.483
- 0.893
- 0.532
- 0.525
- 0.872
- 0.838
- 0.834
- 0.823
- 0.206
- 0.463
- 0.769
- 0.169
- 0.424
- 0.447
- 1.049
- 0.456
- 0.742
- 0.469
- 0.455
- 0.44
- 0.71
- 0.447
- 0.701
- 0.682
- 0.915
- 0.436
- 0.451
- 0.428
- 0.675
- 0.427
- 0.413
- 0.648
- 0.43
- 0.197
- 0.369
- 0.374
- 0.382
- 0.399
- 0.613
- 0.183
- 0.358
- 0.798
- 0.353
- 0.356
- 0.819
- 0.794
- 0.785
- 0.374
- 0.566
- 0.582
- 0.184
- 0.345
- 0.766
- 0.571
- 0.164
- 0.54
- 0.333
- 0.343
- 0.749
- 0.529
- 0.555
- 0.558
- 0.551
- 0.544
- 0.366
- 0.548
- 0.725
- 0.176
- 0.303
- 0.319
- 0.151
- 0.077
- 0.504
- 0.308
- 0.308
- 0.312
- 0.509
- 0.329
- 0.331
- 0.515
- 0.505
- 0.144
- 0.478
- 0.292
- 0.121
unequal: 0
verbose: 1
