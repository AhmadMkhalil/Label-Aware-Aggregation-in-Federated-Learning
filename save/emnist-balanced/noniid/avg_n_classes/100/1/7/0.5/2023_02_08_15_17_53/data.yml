avg_train_accuracy: 0.848
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03537234042553192
- 0.05882978723404255
- 0.13356382978723405
- 0.03521276595744681
- 0.2204787234042553
- 0.30664893617021277
- 0.38063829787234044
- 0.431436170212766
- 0.4525
- 0.4717021276595745
- 0.5030851063829788
- 0.5108510638297873
- 0.5228723404255319
- 0.5388297872340425
- 0.541595744680851
- 0.5413297872340426
- 0.5554787234042553
- 0.5604787234042553
- 0.5682446808510638
- 0.5734574468085106
- 0.16792553191489362
- 0.5727127659574468
- 0.5781914893617022
- 0.5827127659574468
- 0.5828723404255319
- 0.5824468085106383
- 0.5837765957446809
- 0.5881914893617022
- 0.6011170212765957
- 0.5962765957446808
- 0.5948404255319149
- 0.6037234042553191
- 0.6051063829787234
- 0.6098936170212766
- 0.6143617021276596
- 0.6195744680851064
- 0.6203723404255319
- 0.6148404255319149
- 0.622872340425532
- 0.6265425531914893
- 0.6267021276595744
- 0.6299468085106383
- 0.6311170212765957
- 0.6310106382978723
- 0.6291489361702127
- 0.32585106382978724
- 0.6377659574468085
- 0.6345744680851064
- 0.6392021276595745
- 0.6422872340425532
- 0.635904255319149
- 0.6474468085106383
- 0.4277659574468085
- 0.6472340425531915
- 0.6482446808510638
- 0.6499468085106384
- 0.6470212765957447
- 0.6511170212765958
- 0.6521808510638298
- 0.6553723404255319
- 0.6575
- 0.6547872340425532
- 0.6572340425531915
- 0.6493085106382979
- 0.6593617021276595
- 0.6592021276595744
- 0.5135106382978724
- 0.6628723404255319
- 0.6582978723404256
- 0.6642553191489362
- 0.6653191489361702
- 0.6654255319148936
- 0.6619148936170213
- 0.5598936170212766
- 0.6629255319148936
- 0.6665425531914894
- 0.6700531914893617
- 0.6689893617021276
- 0.6624468085106383
- 0.6716489361702128
- 0.6727659574468086
- 0.6681382978723405
- 0.6725
- 0.6738297872340425
- 0.67
- 0.676063829787234
- 0.6739893617021276
- 0.6377659574468085
- 0.6736702127659574
- 0.6746808510638298
- 0.6782446808510638
- 0.6778191489361702
- 0.6761702127659575
- 0.6762234042553191
- 0.678936170212766
- 0.6797872340425531
- 0.6804255319148936
- 0.6827127659574468
- 0.6776063829787234
- 0.6795744680851064
test_loss_list:
- 3.78804235458374
- 3.749593286514282
- 3.621459887822469
- 4.823732363382975
- 3.2960910765329996
- 3.0278811105092367
- 2.87084867477417
- 2.772016166051229
- 2.714919424057007
- 2.6305880769093832
- 2.6044206364949543
- 2.5874239603678384
- 2.5682370313008627
- 2.5431357415517173
- 2.5165652656555175
- 2.5135779698689777
- 2.5127535915374755
- 2.5206469122568764
- 2.5595743719736737
- 2.5458819007873537
- 3.882827943166097
- 2.390261042912801
- 2.3277264642715454
- 2.3548139731089273
- 2.361304028828939
- 2.315461235046387
- 2.3309556261698403
- 2.2935332330067952
- 2.373884464899699
- 2.2984242661794028
- 2.2708799250920615
- 2.270902519226074
- 2.3261421791712444
- 2.277679344813029
- 2.307197847366333
- 2.322697285016378
- 2.2914288743336995
- 2.2672465817133585
- 2.2627624448140464
- 2.262327257792155
- 2.252101090749105
- 2.274346569379171
- 2.2445492776234945
- 2.1619531043370563
- 2.2484405914942425
- 2.610508451461792
- 1.921976284980774
- 1.961144429842631
- 1.999799755414327
- 2.021566454569499
- 1.9969636265436808
- 2.023535181681315
- 2.1024058294296264
- 1.7475771141052245
- 1.8453395827611287
- 1.8778886477152505
- 1.8289465634028117
- 1.8634765688578288
- 1.862740486462911
- 1.8922100337346395
- 1.903138845761617
- 1.871074136098226
- 1.8862531137466432
- 1.8853663714726765
- 1.8406819264094034
- 1.8657022285461426
- 1.7598183997472128
- 1.5959109592437744
- 1.6428956651687623
- 1.6598917229970296
- 1.695005750656128
- 1.702177831331889
- 1.679051211675008
- 1.4966824817657471
- 1.4474193859100342
- 1.5415389887491862
- 1.5581205495198567
- 1.595558737119039
- 1.245637534459432
- 1.38265869140625
- 1.4600764497121175
- 1.4674977763493855
- 1.4873476934432983
- 1.5097252813975017
- 1.5152255853017171
- 1.5313940699895223
- 1.5702517064412436
- 1.24348757425944
- 1.346452504793803
- 1.4043495925267537
- 1.452583646774292
- 1.4732262945175172
- 1.5050154177347819
- 1.5131344906489055
- 1.5056989224751791
- 1.5187748591105144
- 1.5260932048161824
- 1.5601182301839194
- 1.5358926312128702
- 1.5264826981226602
train_accuracy:
- 0.05
- 0.0
- 0.175
- 0.731
- 0.267
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.575
- 0.0
- 0.0
- 0.0
- 0.608
- 0.683
- 0.673
- 0.0
- 0.0
- 0.638
- 0.556
- 0.0
- 0.0
- 0.765
- 0.763
- 0.0
- 0.0
- 0.644
- 0.717
- 0.0
- 0.673
- 0.702
- 0.669
- 0.679
- 0.0
- 0.787
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.74
- 0.0
- 0.706
- 0.0
- 0.829
- 0.706
- 0.754
- 0.004
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.754
- 0.0
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.769
- 0.0
- 0.756
- 0.0
- 0.744
- 0.842
- 0.0
- 0.658
- 0.0
- 0.0
- 0.0
- 0.844
- 0.742
- 0.852
- 0.0
- 0.0
- 0.775
- 0.75
- 0.0
- 0.0
- 0.0
- 0.602
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.758
- 0.844
- 0.792
- 0.0
- 0.848
train_loss:
- 1.067
- 1.034
- 1.658
- 0.237
- 1.452
- 1.363
- 1.251
- 1.157
- 0.627
- 0.616
- 1.012
- 0.586
- 0.573
- 1.286
- 0.938
- 0.553
- 1.22
- 0.855
- 1.21
- 1.164
- 0.23
- 1.226
- 0.518
- 0.826
- 0.482
- 0.52
- 0.488
- 0.515
- 1.065
- 0.502
- 0.495
- 0.752
- 0.492
- 0.742
- 0.732
- 0.993
- 0.733
- 0.472
- 0.705
- 0.72
- 0.713
- 0.961
- 0.717
- 0.457
- 0.449
- 0.248
- 0.653
- 0.43
- 0.65
- 0.655
- 0.405
- 0.643
- 0.193
- 0.652
- 0.609
- 0.634
- 0.426
- 0.408
- 0.414
- 0.846
- 0.842
- 0.411
- 0.604
- 0.391
- 0.404
- 0.391
- 0.19
- 0.556
- 0.381
- 0.576
- 0.583
- 0.58
- 0.378
- 0.172
- 0.325
- 0.347
- 0.562
- 0.355
- 0.148
- 0.532
- 0.541
- 0.343
- 0.538
- 0.558
- 0.342
- 0.553
- 0.55
- 0.149
- 0.285
- 0.328
- 0.521
- 0.343
- 0.518
- 0.524
- 0.533
- 0.52
- 0.525
- 0.709
- 0.345
- 0.338
unequal: 0
verbose: 1
