avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029680851063829786
- 0.07191489361702127
- 0.0275
- 0.1849468085106383
- 0.30606382978723407
- 0.3921276595744681
- 0.4270744680851064
- 0.45930851063829786
- 0.49398936170212765
- 0.516436170212766
- 0.5254787234042553
- 0.5390425531914894
- 0.5562234042553191
- 0.5614361702127659
- 0.561063829787234
- 0.5682446808510638
- 0.5734574468085106
- 0.5803191489361702
- 0.596436170212766
- 0.6002127659574468
- 0.6078191489361702
- 0.6142553191489362
- 0.6110638297872341
- 0.6169148936170212
- 0.6245212765957446
- 0.6281382978723404
- 0.6241489361702127
- 0.38563829787234044
- 0.6315425531914893
- 0.635531914893617
- 0.6388297872340426
- 0.6367021276595745
- 0.6459574468085106
- 0.6432978723404256
- 0.6467553191489361
- 0.6475531914893617
- 0.6486170212765957
- 0.648031914893617
- 0.6497872340425532
- 0.6523404255319148
- 0.6532978723404256
- 0.6560106382978723
- 0.6520212765957447
- 0.6531914893617021
- 0.6590425531914894
- 0.6618085106382978
- 0.6590957446808511
- 0.6633510638297873
- 0.6615425531914894
- 0.6670212765957447
- 0.6635106382978724
- 0.6670744680851064
- 0.6714361702127659
- 0.6712765957446809
- 0.6698936170212766
- 0.49409574468085105
- 0.6717021276595745
- 0.6701063829787234
- 0.6709574468085107
- 0.6736170212765957
- 0.576063829787234
- 0.6740425531914893
- 0.6718617021276596
- 0.6697872340425531
- 0.6761170212765958
- 0.6768617021276596
- 0.6726063829787234
- 0.6728723404255319
- 0.6764893617021277
- 0.6740957446808511
- 0.6734574468085106
- 0.6792553191489362
- 0.6801063829787234
- 0.6772872340425532
- 0.6776063829787234
- 0.6802659574468085
- 0.6805851063829788
- 0.6822340425531915
- 0.681595744680851
- 0.6831914893617022
- 0.681063829787234
- 0.6840425531914893
- 0.5474468085106383
- 0.24659574468085108
- 0.6812234042553191
- 0.6828723404255319
- 0.6831914893617022
- 0.6821276595744681
- 0.6823936170212765
- 0.6864893617021277
- 0.6851595744680851
- 0.6879787234042554
- 0.6867021276595745
- 0.6879787234042554
- 0.6861702127659575
- 0.6895212765957447
- 0.6354255319148936
- 0.6886702127659574
- 0.6897872340425532
- 0.6890425531914893
test_loss_list:
- 3.7809784698486326
- 3.7069522921244302
- 5.014187412261963
- 3.389922574361165
- 3.071436293919881
- 2.8215450350443523
- 2.674313850402832
- 2.5638135306040444
- 2.5105435943603513
- 2.483472598393758
- 2.4681577650705973
- 2.4272142028808594
- 2.426135698954264
- 2.397040122350057
- 2.3779224427541097
- 2.370725809733073
- 2.370062920252482
- 2.353481060663859
- 2.3406961806615194
- 2.3277800273895264
- 2.3815801270802814
- 2.3508489672342936
- 2.3724127213160195
- 2.321837255160014
- 2.3432646878560384
- 2.3307291316986083
- 2.3250192085901897
- 2.235968748728434
- 2.059222175280253
- 2.1098038736979166
- 2.184838186899821
- 2.139275674819946
- 2.1580113204320273
- 2.1787051979700722
- 2.1376134236653646
- 2.122177670796712
- 2.096772034962972
- 2.067274560928345
- 2.070891470909119
- 2.0558985614776613
- 2.0641213989257814
- 2.102167158126831
- 2.092568939526876
- 2.0562017742792764
- 2.04770467599233
- 2.1022634585698445
- 2.0291625261306763
- 2.0390097379684446
- 1.9908381748199462
- 2.0722712500890097
- 2.029035731951396
- 1.9938030894597372
- 2.0948167689641317
- 2.0212809960047404
- 1.974829200108846
- 1.7271552817026774
- 1.6831807565689088
- 1.7365709288914999
- 1.7992831754684449
- 1.8291719659169514
- 1.485412532488505
- 1.5959719848632812
- 1.6608794180552164
- 1.7068688360850017
- 1.6754240783055623
- 1.771996194521586
- 1.7423456907272339
- 1.7159777196248371
- 1.7320475641886393
- 1.7284875440597534
- 1.7281804354985555
- 1.7393561395009358
- 1.758773045539856
- 1.739059952100118
- 1.6934553400675456
- 1.7228260962168376
- 1.7677310085296631
- 1.7403372128804524
- 1.7169413296381633
- 1.7671078936258953
- 1.7543837292989095
- 1.746994153658549
- 1.6189050277074177
- 3.139049644470215
- 1.379917942682902
- 1.4535320981343587
- 1.5156739997863768
- 1.5355506134033203
- 1.5389031171798706
- 1.5924148750305176
- 1.6067823537190755
- 1.5826332473754883
- 1.5921783939997356
- 1.6105603806177775
- 1.6018956995010376
- 1.6306190983454387
- 1.2554201634724935
- 1.3966471846898396
- 1.4594274838765462
- 1.5059642314910888
train_accuracy:
- 0.0
- 0.094
- 0.0
- 0.242
- 0.0
- 0.465
- 0.0
- 0.0
- 0.562
- 0.59
- 0.0
- 0.629
- 0.627
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.698
- 0.0
- 0.0
- 0.683
- 0.0
- 0.0
- 0.0
- 0.727
- 0.0
- 0.254
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.775
- 0.0
- 0.0
- 0.748
- 0.0
- 0.0
- 0.781
- 0.804
- 0.796
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.86
- 0.0
- 0.0
- 0.763
- 0.0
- 0.81
- 0.01
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.004
- 0.0
- 0.804
- 0.823
- 0.817
- 0.0
- 0.808
- 0.0
- 0.004
- 0.0
- 0.894
- 0.844
- 0.033
- 0.0
- 0.012
- 0.0
- 0.0
- 0.0
- 0.0
- 0.792
- 0.0
- 0.0
- 0.0
- 0.0
- 0.781
- 0.0
- 0.0
- 0.0
train_loss:
- 1.777
- 1.751
- 0.318
- 0.815
- 0.778
- 1.257
- 0.652
- 0.607
- 1.454
- 0.968
- 0.574
- 0.906
- 0.892
- 0.872
- 0.552
- 0.532
- 0.558
- 0.52
- 0.536
- 0.803
- 1.038
- 0.775
- 0.486
- 0.771
- 0.986
- 0.743
- 0.476
- 0.247
- 0.98
- 0.706
- 0.654
- 0.43
- 0.659
- 0.895
- 0.69
- 0.44
- 0.452
- 0.423
- 0.443
- 0.428
- 0.43
- 0.625
- 0.418
- 0.436
- 0.626
- 0.81
- 0.426
- 0.616
- 0.425
- 0.596
- 0.418
- 0.607
- 0.788
- 0.603
- 0.406
- 0.215
- 0.549
- 0.386
- 0.557
- 0.548
- 0.194
- 0.54
- 0.357
- 0.354
- 0.356
- 0.73
- 0.372
- 0.365
- 0.554
- 0.355
- 0.346
- 0.562
- 0.535
- 0.365
- 0.373
- 0.353
- 0.523
- 0.537
- 0.378
- 0.698
- 0.357
- 0.526
- 0.2
- 0.087
- 0.299
- 0.312
- 0.497
- 0.325
- 0.322
- 0.681
- 0.337
- 0.513
- 0.505
- 0.501
- 0.341
- 0.5
- 0.171
- 0.458
- 0.308
- 0.481
unequal: 0
verbose: 1
