avg_train_accuracy: 0.792
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027819148936170213
- 0.07547872340425532
- 0.16585106382978723
- 0.25361702127659574
- 0.34164893617021275
- 0.40797872340425534
- 0.45648936170212767
- 0.4808510638297872
- 0.5079787234042553
- 0.5371808510638297
- 0.5486170212765957
- 0.5586170212765957
- 0.5713297872340426
- 0.5802127659574469
- 0.5889893617021277
- 0.5971808510638298
- 0.6017553191489362
- 0.6047340425531915
- 0.6061702127659574
- 0.6175531914893617
- 0.6223404255319149
- 0.6276595744680851
- 0.6330851063829788
- 0.6346276595744681
- 0.6387765957446808
- 0.6377659574468085
- 0.6386702127659575
- 0.6431914893617021
- 0.6482446808510638
- 0.6500531914893617
- 0.6497340425531914
- 0.6547872340425532
- 0.6570212765957447
- 0.44
- 0.6559574468085106
- 0.6602659574468085
- 0.6621276595744681
- 0.6591489361702128
- 0.6627127659574468
- 0.5056914893617022
- 0.6612234042553191
- 0.6640425531914894
- 0.666968085106383
- 0.6712234042553191
- 0.6692021276595744
- 0.6698936170212766
- 0.581436170212766
- 0.6692553191489362
- 0.6713297872340426
- 0.6678191489361702
- 0.6713297872340426
- 0.6763829787234042
- 0.6702127659574468
- 0.6764361702127659
- 0.6754787234042553
- 0.6767021276595745
- 0.678936170212766
- 0.6781914893617021
- 0.6717553191489362
- 0.6795212765957447
- 0.6791489361702128
- 0.6792553191489362
- 0.6779787234042554
- 0.681595744680851
- 0.6265425531914893
- 0.6807446808510639
- 0.6818617021276596
- 0.6836702127659574
- 0.6057978723404255
- 0.6824468085106383
- 0.6810106382978723
- 0.6829255319148936
- 0.6807446808510639
- 0.5711170212765957
- 0.685
- 0.6818085106382978
- 0.6867021276595745
- 0.685372340425532
- 0.6881382978723404
- 0.6859042553191489
- 0.6893085106382979
- 0.6896808510638298
- 0.6881382978723404
- 0.6874468085106383
- 0.6866489361702127
- 0.6872340425531915
- 0.6895744680851064
- 0.6863829787234043
- 0.6901063829787234
- 0.6915425531914894
- 0.6877127659574468
- 0.6873404255319149
- 0.6596808510638298
- 0.6906914893617021
- 0.6917553191489362
- 0.6496276595744681
- 0.6926063829787235
- 0.6897340425531915
- 0.690531914893617
- 0.6916489361702127
test_loss_list:
- 3.783001772562663
- 3.7270280170440673
- 3.5765624618530274
- 3.310206594467163
- 3.0253983465830485
- 2.807583017349243
- 2.6471856816609702
- 2.5569181791941324
- 2.4507134532928467
- 2.423806374867757
- 2.3874154154459637
- 2.379782282511393
- 2.3526121091842653
- 2.3228301668167113
- 2.3361031103134153
- 2.3182406600316368
- 2.2665841674804685
- 2.2918755133946735
- 2.249419651031494
- 2.244059675534566
- 2.2710864782333373
- 2.241448149681091
- 2.2671022256215414
- 2.270073579152425
- 2.246363973617554
- 2.250138545036316
- 2.2027494589487713
- 2.2202518939971925
- 2.2183654435475666
- 2.1761508067448934
- 2.154511020978292
- 2.2165484539667766
- 2.167118730545044
- 2.056737542152405
- 1.8547885306676228
- 1.9618868589401246
- 1.988354058265686
- 2.0062634134292603
- 2.015928502082825
- 1.8874409294128418
- 1.7641482830047608
- 1.8546473455429078
- 1.8743012809753419
- 1.9093626387914022
- 1.9171600008010865
- 1.9458025693893433
- 1.6447119029362995
- 1.6355174493789673
- 1.7561317125956217
- 1.7786591561635334
- 1.7757289409637451
- 1.8275203800201416
- 1.796257996559143
- 1.8352601432800293
- 1.8512169488271077
- 1.8322194576263429
- 1.8644390312830608
- 1.8429657649993896
- 1.8590259806315104
- 1.8661573584874471
- 1.827964990933736
- 1.8407481988271077
- 1.8891989771525066
- 1.8385149065653483
- 1.4671633052825928
- 1.6150666443506876
- 1.67626806418101
- 1.711946660677592
- 1.4665759388605755
- 1.4558553981781006
- 1.5764175669352214
- 1.6262405427296955
- 1.5607335646947225
- 1.459038872718811
- 1.396802430152893
- 1.424686468442281
- 1.5512787214914958
- 1.5411580610275268
- 1.5651990493138632
- 1.5337791315714517
- 1.591891622543335
- 1.609379218419393
- 1.5988704029719034
- 1.6449249521891276
- 1.64756165822347
- 1.6402355845769245
- 1.6485412486394246
- 1.6598194678624472
- 1.636045888264974
- 1.5917690054575602
- 1.6511131477355958
- 1.5769562784830728
- 1.2475343831380208
- 1.373820923169454
- 1.4357112058003743
- 1.19550731976827
- 1.252152026494344
- 1.3589771254857381
- 1.3737914562225342
- 1.428012851079305
train_accuracy:
- 0.015
- 0.0
- 0.196
- 0.271
- 0.0
- 0.0
- 0.0
- 0.583
- 0.0
- 0.644
- 0.656
- 0.681
- 0.706
- 0.0
- 0.0
- 0.0
- 0.0
- 0.7
- 0.706
- 0.748
- 0.0
- 0.0
- 0.733
- 0.0
- 0.0
- 0.781
- 0.744
- 0.0
- 0.0
- 0.0
- 0.0
- 0.775
- 0.771
- 0.106
- 0.769
- 0.0
- 0.783
- 0.0
- 0.0
- 0.931
- 0.802
- 0.0
- 0.785
- 0.0
- 0.781
- 0.0
- 0.19
- 0.792
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.0
- 0.792
- 0.0
- 0.0
- 0.833
- 0.833
- 0.906
- 0.0
- 0.829
- 0.8
- 0.94
- 0.0
- 0.017
- 0.0
- 0.0
- 0.721
- 0.806
- 0.0
- 0.8
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.846
- 0.0
- 0.0
- 0.0
- 0.0
- 0.94
- 0.81
- 0.0
- 0.665
- 0.002
- 0.86
- 0.85
- 0.792
train_loss:
- 1.01
- 1.709
- 1.616
- 0.895
- 0.789
- 0.721
- 0.676
- 0.658
- 0.614
- 1.366
- 0.947
- 0.91
- 0.572
- 0.856
- 0.882
- 0.834
- 0.539
- 0.526
- 0.519
- 0.769
- 0.766
- 0.516
- 0.736
- 0.729
- 0.707
- 0.469
- 0.476
- 0.726
- 0.69
- 0.463
- 0.449
- 0.719
- 0.692
- 0.237
- 0.618
- 0.669
- 0.629
- 0.392
- 0.431
- 0.185
- 0.373
- 0.609
- 0.61
- 0.813
- 0.615
- 0.591
- 0.203
- 0.344
- 0.589
- 0.379
- 0.394
- 0.566
- 0.388
- 0.594
- 0.58
- 0.374
- 0.573
- 0.392
- 0.364
- 0.547
- 0.392
- 0.57
- 0.363
- 0.571
- 0.188
- 0.288
- 0.524
- 0.514
- 0.147
- 0.296
- 0.302
- 0.331
- 0.385
- 0.161
- 0.296
- 0.323
- 0.5
- 0.526
- 0.511
- 0.362
- 0.527
- 0.508
- 0.545
- 0.336
- 0.338
- 0.333
- 0.519
- 0.334
- 0.511
- 0.339
- 0.319
- 0.346
- 0.167
- 0.479
- 0.309
- 0.144
- 0.473
- 0.295
- 0.474
- 0.483
unequal: 0
verbose: 1
