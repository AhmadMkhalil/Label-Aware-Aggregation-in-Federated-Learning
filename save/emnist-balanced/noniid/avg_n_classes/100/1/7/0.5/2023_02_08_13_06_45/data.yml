avg_train_accuracy: 0.012
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05143617021276596
- 0.1049468085106383
- 0.02122340425531915
- 0.1697872340425532
- 0.2922872340425532
- 0.3822340425531915
- 0.4280851063829787
- 0.4673404255319149
- 0.4926595744680851
- 0.49872340425531914
- 0.5172872340425532
- 0.5243617021276595
- 0.5422872340425532
- 0.5451595744680852
- 0.5476063829787234
- 0.1826063829787234
- 0.5585638297872341
- 0.5641489361702128
- 0.573936170212766
- 0.5762234042553191
- 0.2968085106382979
- 0.10409574468085106
- 0.5748936170212766
- 0.584627659574468
- 0.5953723404255319
- 0.598404255319149
- 0.5995744680851064
- 0.6046276595744681
- 0.6101595744680851
- 0.614468085106383
- 0.6220744680851064
- 0.6243085106382978
- 0.6242553191489362
- 0.6278191489361702
- 0.6321808510638298
- 0.6285106382978723
- 0.629095744680851
- 0.5578191489361702
- 0.6315425531914893
- 0.5502127659574468
- 0.6389893617021276
- 0.6376063829787234
- 0.6451595744680851
- 0.6397872340425532
- 0.6437765957446808
- 0.643563829787234
- 0.6189361702127659
- 0.6524468085106383
- 0.651436170212766
- 0.6505851063829787
- 0.6498936170212766
- 0.6533510638297872
- 0.6537234042553192
- 0.6578191489361702
- 0.6567021276595745
- 0.6499468085106384
- 0.6562765957446809
- 0.6632978723404256
- 0.6645212765957447
- 0.6640957446808511
- 0.6630851063829787
- 0.6660106382978723
- 0.6649468085106383
- 0.663936170212766
- 0.6670212765957447
- 0.6690425531914893
- 0.6714361702127659
- 0.6656914893617021
- 0.6717021276595745
- 0.6704255319148936
- 0.6675531914893617
- 0.6674468085106383
- 0.6723404255319149
- 0.6692553191489362
- 0.6736170212765957
- 0.6701063829787234
- 0.6742021276595744
- 0.6747872340425531
- 0.6575531914893618
- 0.6747872340425531
- 0.6825
- 0.5305851063829787
- 0.679468085106383
- 0.6783510638297873
- 0.678936170212766
- 0.6790425531914893
- 0.6803191489361702
- 0.6777127659574468
- 0.6808510638297872
- 0.6895744680851064
- 0.6804787234042553
- 0.676063829787234
- 0.6785638297872341
- 0.6807446808510639
- 0.6863829787234043
- 0.6801063829787234
- 0.6726063829787234
- 0.6869148936170213
- 0.6857978723404256
- 0.6801595744680851
test_loss_list:
- 3.7831438223520917
- 3.7243447335561117
- 5.17267307917277
- 3.4610339164733888
- 3.1394916788736977
- 2.8699188296000164
- 2.733335771560669
- 2.649125461578369
- 2.610932321548462
- 2.5303218269348147
- 2.5051069323221844
- 2.4859783458709717
- 2.42804030418396
- 2.4226267528533936
- 2.4245257631937664
- 3.321335589090983
- 2.1194735622406005
- 2.186805950800578
- 2.2117957735061644
- 2.2088097524642945
- 2.64577654838562
- 5.179897899627686
- 1.9737363306681315
- 2.038963926633199
- 2.062619873682658
- 2.0329265149434406
- 2.0626445150375368
- 2.043490514755249
- 2.11703383286794
- 2.1064919408162437
- 2.079821448326111
- 2.0788883113861085
- 2.0684468094507853
- 2.060780104001363
- 2.012316428820292
- 2.045688354174296
- 1.99739417552948
- 1.702704898516337
- 1.7833012358347575
- 1.6768632078170775
- 1.6753084357579549
- 1.7408591286341348
- 1.7962257464726765
- 1.7971805620193482
- 1.8287797673543293
- 1.8037301286061604
- 1.467917005221049
- 1.596837844848633
- 1.6586760663986206
- 1.7207282574971516
- 1.7194386418660481
- 1.7473702081044515
- 1.7388340107599893
- 1.747625339825948
- 1.7486723152796428
- 1.7498906358083088
- 1.758633902867635
- 1.7159109910329182
- 1.7354831552505494
- 1.7312666479746501
- 1.7644564342498779
- 1.773353346188863
- 1.775663480758667
- 1.7653613662719727
- 1.74892337958018
- 1.764326688448588
- 1.7832244873046874
- 1.7426077127456665
- 1.7360182523727417
- 1.7593486722310383
- 1.7158605845769246
- 1.753416838645935
- 1.7610101413726806
- 1.2705035972595216
- 1.4476013628641764
- 1.5416389147440592
- 1.5113647174835205
- 1.5371576102574667
- 1.145990256468455
- 1.3121718565622966
- 1.0686777671178183
- 1.6204289038976034
- 1.1839384857813517
- 1.3113257010777792
- 1.3550319862365723
- 1.3990079307556151
- 1.4352888854344685
- 1.4507519261042277
- 1.4804318698247274
- 1.099651850859324
- 1.281933946609497
- 1.08287131468455
- 1.20714226881663
- 1.2683186960220336
- 1.0180742796262106
- 1.17506862004598
- 1.0582972574234009
- 1.130080045859019
- 1.2187647167841593
- 1.255912405649821
train_accuracy:
- 0.0
- 0.142
- 0.0
- 0.0
- 0.358
- 0.452
- 0.519
- 0.535
- 0.594
- 0.571
- 0.0
- 0.0
- 0.0
- 0.627
- 0.0
- 0.19
- 0.652
- 0.665
- 0.0
- 0.0
- 0.767
- 0.24
- 0.0
- 0.0
- 0.679
- 0.677
- 0.0
- 0.0
- 0.706
- 0.702
- 0.0
- 0.0
- 0.0
- 0.715
- 0.0
- 0.733
- 0.0
- 0.277
- 0.74
- 0.662
- 0.0
- 0.0
- 0.746
- 0.0
- 0.0
- 0.744
- 0.667
- 0.0
- 0.763
- 0.763
- 0.0
- 0.771
- 0.015
- 0.0
- 0.777
- 0.0
- 0.0
- 0.006
- 0.781
- 0.0
- 0.0
- 0.0
- 0.004
- 0.775
- 0.779
- 0.785
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.779
- 0.698
- 0.785
- 0.002
- 0.0
- 0.787
- 0.748
- 0.0
- 0.917
- 0.977
- 0.0
- 0.0
- 0.0
- 0.798
- 0.031
- 0.806
- 0.796
- 0.658
- 0.14
- 0.915
- 0.794
- 0.779
- 0.812
- 0.04
- 0.829
- 0.0
- 0.8
- 0.012
train_loss:
- 1.014
- 1.013
- 0.275
- 0.821
- 1.413
- 1.271
- 1.164
- 1.085
- 1.488
- 0.627
- 0.983
- 0.967
- 0.578
- 0.554
- 0.538
- 0.232
- 0.903
- 0.518
- 0.838
- 0.519
- 0.188
- 0.117
- 0.441
- 0.475
- 0.776
- 0.478
- 0.461
- 0.468
- 0.725
- 1.005
- 0.734
- 0.711
- 0.449
- 0.707
- 0.464
- 0.445
- 0.444
- 0.186
- 0.38
- 0.149
- 0.389
- 0.393
- 0.877
- 0.413
- 0.624
- 0.401
- 0.155
- 0.606
- 0.619
- 0.611
- 0.389
- 0.594
- 0.379
- 0.62
- 0.61
- 0.412
- 0.595
- 0.39
- 0.37
- 0.611
- 0.372
- 0.587
- 0.565
- 0.583
- 0.583
- 0.567
- 0.572
- 0.374
- 0.587
- 0.577
- 0.39
- 0.373
- 0.77
- 0.188
- 0.515
- 0.338
- 0.336
- 0.344
- 0.162
- 0.305
- 0.113
- 0.058
- 0.288
- 0.5
- 0.304
- 0.523
- 0.509
- 0.527
- 0.716
- 0.137
- 0.285
- 0.12
- 0.255
- 0.305
- 0.109
- 0.286
- 0.108
- 0.491
- 0.486
- 0.312
unequal: 0
verbose: 1
