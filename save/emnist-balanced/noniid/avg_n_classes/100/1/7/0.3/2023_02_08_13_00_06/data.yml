avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02574468085106383
- 0.0849468085106383
- 0.03228723404255319
- 0.02127659574468085
- 0.1422872340425532
- 0.03
- 0.2272872340425532
- 0.3228191489361702
- 0.363031914893617
- 0.4302127659574468
- 0.44420212765957445
- 0.4735106382978723
- 0.49090425531914894
- 0.5177127659574469
- 0.5245212765957447
- 0.06930851063829788
- 0.5286702127659575
- 0.5457446808510639
- 0.20968085106382978
- 0.5433510638297873
- 0.5655851063829788
- 0.566063829787234
- 0.5820744680851064
- 0.2561702127659575
- 0.5773936170212766
- 0.5947872340425532
- 0.591063829787234
- 0.22547872340425532
- 0.6038297872340426
- 0.6032446808510639
- 0.6097872340425532
- 0.6051063829787234
- 0.614095744680851
- 0.6142553191489362
- 0.6222340425531915
- 0.6266489361702128
- 0.628563829787234
- 0.4397872340425532
- 0.6315425531914893
- 0.2693617021276596
- 0.6361170212765958
- 0.38111702127659575
- 0.6353191489361703
- 0.6298404255319149
- 0.6343617021276595
- 0.3850531914893617
- 0.29340425531914893
- 0.6398936170212766
- 0.4271808510638298
- 0.37946808510638297
- 0.24324468085106382
- 0.6437765957446808
- 0.6418617021276596
- 0.643031914893617
- 0.6502127659574468
- 0.6473936170212766
- 0.6503723404255319
- 0.4475
- 0.6492553191489362
- 0.6518085106382979
- 0.5167021276595745
- 0.6559574468085106
- 0.6536702127659575
- 0.4973404255319149
- 0.29904255319148937
- 0.15893617021276596
- 0.655904255319149
- 0.5715425531914894
- 0.6596276595744681
- 0.6593085106382979
- 0.6597340425531915
- 0.6589893617021276
- 0.6575531914893618
- 0.6702127659574468
- 0.5554255319148936
- 0.6658510638297872
- 0.5438829787234043
- 0.6678191489361702
- 0.5997340425531915
- 0.6676595744680851
- 0.6632978723404256
- 0.6652659574468085
- 0.6682446808510638
- 0.5820212765957447
- 0.46164893617021274
- 0.6791489361702128
- 0.6699468085106383
- 0.67
- 0.6680851063829787
- 0.6697340425531915
- 0.6715425531914894
- 0.5907978723404256
- 0.6776595744680851
- 0.6722340425531915
- 0.6726063829787234
- 0.596063829787234
- 0.36425531914893616
- 0.4551063829787234
- 0.6879787234042554
- 0.6788829787234043
test_loss_list:
- 3.7805671660105387
- 3.727229652404785
- 8.166242148081462
- 10.439888534545899
- 3.5750092188517253
- 7.415582466125488
- 3.2349437872568765
- 2.9695446395874026
- 2.779487994511922
- 2.6510321299235025
- 2.6041106287638347
- 2.528676977157593
- 2.4894675159454347
- 2.4714020538330077
- 2.4514679018656413
- 6.681651039123535
- 2.2933346605300904
- 2.286693638165792
- 3.541894915898641
- 2.226148856480916
- 2.2131224139531454
- 2.265075937906901
- 2.2239639711380006
- 2.9820065116882324
- 2.0762168041865032
- 2.1054903841018677
- 2.143604497909546
- 3.2370268376668294
- 1.9606694014867148
- 1.9816146485010784
- 2.016570192972819
- 2.041979546546936
- 2.036502849260966
- 2.0633493423461915
- 2.034123338063558
- 2.038692374229431
- 2.0966748841603597
- 2.2293675136566162
- 1.8996790361404419
- 2.9403676350911456
- 1.7329555622736612
- 2.266490494410197
- 1.65460418065389
- 1.689716862042745
- 1.7369042571385702
- 2.10836532274882
- 2.6728680578867596
- 1.4974388233820597
- 2.20879594484965
- 2.0559470144907634
- 3.186926673253377
- 1.3339159727096557
- 1.4433196051915487
- 1.5239676666259765
- 1.5489340511957805
- 1.5906282711029052
- 1.6360002295176188
- 2.0320307270685833
- 1.4555397987365724
- 1.5093114074071248
- 1.7590813080469767
- 1.4583770831425984
- 1.515883413950602
- 1.7772443421681723
- 3.1579890124003094
- 5.433206221262614
- 1.3680234305063883
- 1.5769754600524903
- 1.3538939952850342
- 1.417898424466451
- 1.4690700451532999
- 1.4906523354848227
- 1.5389399560292563
- 1.5741359583536785
- 1.6567588313420614
- 1.4565536085764568
- 1.6177164936065673
- 1.356772255897522
- 1.4707743692398072
- 1.3364228852589926
- 1.3994692738850911
- 1.4449892536799114
- 1.4922498337427774
- 1.5382340002059935
- 2.054760915438334
- 1.2947202269236247
- 1.376671756108602
- 1.4243133099873861
- 1.4489215024312336
- 1.4803668053944905
- 1.5305972385406494
- 1.494339354832967
- 1.3704329458872477
- 1.4227264563242594
- 1.4521327702204387
- 1.4820499420166016
- 2.9467223199208576
- 1.78239116191864
- 1.1678519996007284
- 1.27431361357371
train_accuracy:
- 0.033
- 0.094
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.502
- 0.492
- 0.0
- 0.0
- 0.602
- 0.0
- 0.833
- 0.59
- 0.0
- 0.896
- 0.625
- 0.673
- 0.656
- 0.0
- 0.588
- 0.0
- 0.69
- 0.0
- 0.965
- 0.733
- 0.0
- 0.704
- 0.0
- 0.0
- 0.696
- 0.0
- 0.0
- 0.752
- 0.915
- 0.0
- 0.688
- 0.733
- 0.912
- 0.0
- 0.0
- 0.0
- 0.94
- 0.983
- 0.746
- 0.985
- 0.917
- 0.948
- 0.058
- 0.731
- 0.002
- 0.002
- 0.779
- 0.785
- 0.952
- 0.733
- 0.008
- 0.971
- 0.0
- 0.0
- 0.925
- 1.0
- 1.0
- 0.021
- 0.99
- 0.754
- 0.031
- 0.002
- 0.777
- 0.0
- 0.783
- 0.912
- 0.054
- 0.983
- 0.777
- 0.977
- 0.0
- 0.763
- 0.769
- 0.775
- 0.95
- 0.94
- 0.779
- 0.0
- 0.021
- 0.792
- 0.794
- 0.0
- 0.944
- 0.0
- 0.0
- 0.0
- 0.95
- 0.977
- 0.988
- 0.802
- 0.0
train_loss:
- 2.675
- 2.651
- 0.338
- 0.153
- 2.651
- 0.206
- 1.259
- 1.178
- 1.087
- 1.898
- 1.002
- 0.947
- 0.913
- 1.545
- 0.85
- 0.259
- 0.871
- 0.838
- 0.22
- 0.717
- 1.332
- 0.74
- 0.729
- 0.208
- 0.695
- 1.218
- 0.658
- 0.213
- 1.206
- 0.782
- 0.723
- 0.622
- 0.636
- 0.619
- 0.637
- 0.701
- 0.604
- 0.179
- 1.023
- 0.239
- 1.039
- 0.179
- 1.027
- 0.579
- 0.57
- 0.176
- 0.144
- 1.02
- 0.156
- 0.133
- 0.072
- 1.031
- 0.525
- 0.533
- 0.524
- 0.522
- 0.511
- 0.154
- 0.526
- 0.495
- 0.129
- 0.495
- 0.512
- 0.136
- 0.059
- 0.031
- 0.51
- 0.092
- 0.485
- 0.474
- 0.506
- 0.525
- 0.473
- 1.202
- 0.14
- 0.426
- 0.124
- 0.484
- 0.091
- 0.468
- 0.516
- 0.487
- 0.809
- 0.134
- 0.064
- 0.439
- 0.456
- 0.489
- 0.491
- 0.796
- 0.459
- 0.15
- 0.812
- 0.476
- 0.455
- 0.117
- 0.034
- 0.188
- 0.832
- 0.431
unequal: 0
verbose: 1
