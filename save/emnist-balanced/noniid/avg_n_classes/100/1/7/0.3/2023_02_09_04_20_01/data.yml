avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03031914893617021
- 0.07148936170212766
- 0.10531914893617021
- 0.02127659574468085
- 0.02127659574468085
- 0.21324468085106382
- 0.32441489361702125
- 0.3974468085106383
- 0.4325531914893617
- 0.465
- 0.48388297872340424
- 0.5008510638297873
- 0.09675531914893618
- 0.5180851063829788
- 0.5386170212765957
- 0.5496276595744681
- 0.5513829787234042
- 0.5623936170212765
- 0.1700531914893617
- 0.5677659574468085
- 0.5699468085106383
- 0.19340425531914893
- 0.5769148936170213
- 0.5923936170212766
- 0.1854255319148936
- 0.5861170212765957
- 0.5903723404255319
- 0.6089893617021277
- 0.6026063829787234
- 0.40595744680851065
- 0.6053191489361702
- 0.31377659574468086
- 0.6102127659574468
- 0.6214893617021277
- 0.3821276595744681
- 0.625531914893617
- 0.451968085106383
- 0.6222340425531915
- 0.46574468085106385
- 0.1671276595744681
- 0.6323404255319149
- 0.3304787234042553
- 0.6347340425531914
- 0.632127659574468
- 0.4097340425531915
- 0.16654255319148936
- 0.6358510638297873
- 0.6342553191489362
- 0.5142553191489362
- 0.6406382978723404
- 0.6454255319148936
- 0.6411702127659574
- 0.6494148936170213
- 0.518936170212766
- 0.28127659574468084
- 0.3731914893617021
- 0.6515425531914893
- 0.6527127659574468
- 0.5734574468085106
- 0.6492553191489362
- 0.6593617021276595
- 0.515904255319149
- 0.6522340425531915
- 0.658563829787234
- 0.538563829787234
- 0.438563829787234
- 0.6612765957446809
- 0.6620212765957447
- 0.6607978723404255
- 0.5154787234042553
- 0.6607978723404255
- 0.524468085106383
- 0.6643085106382979
- 0.6671808510638297
- 0.5752127659574469
- 0.6704255319148936
- 0.6672872340425532
- 0.5809042553191489
- 0.349468085106383
- 0.6728723404255319
- 0.665904255319149
- 0.5585106382978723
- 0.39324468085106384
- 0.6720212765957447
- 0.6711170212765958
- 0.6739893617021276
- 0.6727127659574468
- 0.6735106382978724
- 0.6390957446808511
- 0.5219680851063829
- 0.6781914893617021
- 0.6745212765957447
- 0.6756914893617021
- 0.6740425531914893
- 0.6746276595744681
- 0.6743617021276596
- 0.6733510638297873
- 0.5975531914893617
- 0.6814893617021277
- 0.6809042553191489
test_loss_list:
- 6.803228085835775
- 3.743399591445923
- 3.614768387476603
- 6.541609891255697
- 8.162199147542317
- 3.3308188184102376
- 3.0557037925720216
- 2.8124127546946207
- 2.6718411668141684
- 2.5754879983266195
- 2.5537962245941164
- 2.4978575388590496
- 3.835030829111735
- 2.3409437878926593
- 2.335307102203369
- 2.346387424468994
- 2.3218583631515504
- 2.350576117833455
- 3.538971554438273
- 2.1654559342066446
- 2.2334952322642008
- 3.2864833863576255
- 2.0594792493184406
- 2.085815421740214
- 3.699336166381836
- 2.028797658284505
- 2.098423234621684
- 2.099241296450297
- 2.148571179707845
- 2.306930274963379
- 1.9580791664123536
- 2.4835653368632
- 1.819889996846517
- 1.8903695805867513
- 2.4253684743245443
- 1.848224811553955
- 2.110399276415507
- 1.7255875714619955
- 2.064831193288167
- 3.848550802866618
- 1.5567278480529785
- 2.5382911364237466
- 1.553601147333781
- 1.6318509594599406
- 2.080835420290629
- 4.761185735066732
- 1.5463527202606202
- 1.5916527398427327
- 1.805483512878418
- 1.481268982887268
- 1.5479801193873088
- 1.6148272593816122
- 1.6338706350326537
- 1.806131722132365
- 3.1550957679748537
- 2.286634117762248
- 1.3935848569869995
- 1.481636085510254
- 1.6092059516906738
- 1.4407291094462076
- 1.4959264691670735
- 1.8149065033594767
- 1.4680241282780966
- 1.4866855255762736
- 1.5689796606699626
- 1.948061803181966
- 1.2921106068293253
- 1.3718335262934367
- 1.4391564989089967
- 1.7252862469355266
- 1.377125186920166
- 1.7437586657206217
- 1.3599282582600911
- 1.4203197065989177
- 1.5448564497629802
- 1.3415345191955566
- 1.4131502628326416
- 1.6314066346486409
- 2.769428777694702
- 1.2796989885965984
- 1.3667506678899128
- 1.593656088511149
- 2.5276193904876707
- 1.2340768766403198
- 1.3323250850041708
- 1.3949547211329143
- 1.394588762919108
- 1.4279243675867717
- 1.3027565685908
- 1.7251624552408855
- 1.2404176918665568
- 1.3228379027048747
- 1.3758882284164429
- 1.4344942665100098
- 1.4447822920481364
- 1.4936675834655762
- 1.5140007750193278
- 1.5150035778681437
- 1.3536037985483806
- 1.3977028512954712
train_accuracy:
- 0.633
- 0.073
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.683
- 0.596
- 0.648
- 0.0
- 0.0
- 0.0
- 0.481
- 0.0
- 0.0
- 0.802
- 0.0
- 0.0
- 0.933
- 0.0
- 0.0
- 0.0
- 0.0
- 0.992
- 0.0
- 0.896
- 0.0
- 0.706
- 0.883
- 0.727
- 0.919
- 0.0
- 0.969
- 0.946
- 0.0
- 0.915
- 0.027
- 0.01
- 0.965
- 0.998
- 0.0
- 0.0
- 0.965
- 0.0
- 0.0
- 0.002
- 0.0
- 0.954
- 0.979
- 0.977
- 0.767
- 0.0
- 0.971
- 0.0
- 0.75
- 0.981
- 0.0
- 0.0
- 0.894
- 0.996
- 0.729
- 0.0
- 0.763
- 0.975
- 0.75
- 0.977
- 0.0
- 0.0
- 0.973
- 0.0
- 0.765
- 0.985
- 0.894
- 0.0
- 0.792
- 0.902
- 0.963
- 0.787
- 0.002
- 0.0
- 0.0
- 0.0
- 0.935
- 0.99
- 0.0
- 0.758
- 0.773
- 0.0
- 0.017
- 0.0
- 0.775
- 0.965
- 0.771
- 0.0
train_loss:
- 0.402
- 1.355
- 1.404
- 0.265
- 0.191
- 1.348
- 2.215
- 2.001
- 0.988
- 0.942
- 0.924
- 0.878
- 0.216
- 1.618
- 1.451
- 1.378
- 0.759
- 0.774
- 0.198
- 1.381
- 0.715
- 0.214
- 0.814
- 0.723
- 0.179
- 0.675
- 0.653
- 1.206
- 0.651
- 0.201
- 0.618
- 0.176
- 0.653
- 1.112
- 0.164
- 1.61
- 0.149
- 0.651
- 0.128
- 0.13
- 1.144
- 0.123
- 1.048
- 0.568
- 0.136
- 0.061
- 0.606
- 0.567
- 0.137
- 0.556
- 0.548
- 0.549
- 0.55
- 0.165
- 0.1
- 0.086
- 1.016
- 0.949
- 0.12
- 0.5
- 0.945
- 0.113
- 0.535
- 0.558
- 0.149
- 0.095
- 0.514
- 0.534
- 0.511
- 0.117
- 0.49
- 0.089
- 0.525
- 0.515
- 0.137
- 0.472
- 0.481
- 0.11
- 0.078
- 0.479
- 0.507
- 0.108
- 0.089
- 0.907
- 0.463
- 0.492
- 0.499
- 0.48
- 0.132
- 0.083
- 0.477
- 0.474
- 0.468
- 0.458
- 0.484
- 0.46
- 0.457
- 0.157
- 0.808
- 0.48
unequal: 0
verbose: 1
