avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04085106382978723
- 0.07468085106382978
- 0.06069148936170213
- 0.022393617021276596
- 0.08388297872340425
- 0.19670212765957445
- 0.040638297872340426
- 0.28632978723404257
- 0.3747340425531915
- 0.43611702127659574
- 0.08542553191489362
- 0.43898936170212766
- 0.1025531914893617
- 0.03537234042553192
- 0.46638297872340423
- 0.4929787234042553
- 0.5065425531914893
- 0.06303191489361702
- 0.5084574468085107
- 0.2351595744680851
- 0.522127659574468
- 0.5377127659574468
- 0.19797872340425532
- 0.5383510638297873
- 0.5544148936170212
- 0.5638829787234042
- 0.5685106382978723
- 0.5753723404255319
- 0.17845744680851064
- 0.0851595744680851
- 0.5771276595744681
- 0.23340425531914893
- 0.5827659574468085
- 0.593936170212766
- 0.5959574468085106
- 0.602872340425532
- 0.6050531914893617
- 0.35771276595744683
- 0.6043085106382978
- 0.24372340425531916
- 0.6108510638297873
- 0.6184042553191489
- 0.6184574468085107
- 0.624468085106383
- 0.6301063829787235
- 0.6334574468085107
- 0.4949468085106383
- 0.630904255319149
- 0.6318085106382979
- 0.6343617021276595
- 0.6388297872340426
- 0.6428191489361702
- 0.6432446808510638
- 0.6432446808510638
- 0.6503723404255319
- 0.6504255319148936
- 0.6540957446808511
- 0.6578191489361702
- 0.6029255319148936
- 0.6582978723404256
- 0.658563829787234
- 0.5326595744680851
- 0.6585106382978724
- 0.6591489361702128
- 0.6611170212765958
- 0.6648404255319149
- 0.6686170212765957
- 0.6677659574468086
- 0.6658510638297872
- 0.5682978723404255
- 0.6654787234042553
- 0.6689893617021276
- 0.6711702127659575
- 0.5369148936170213
- 0.6749468085106383
- 0.5678191489361702
- 0.3974468085106383
- 0.6710106382978723
- 0.5820744680851064
- 0.6707446808510639
- 0.6756914893617021
- 0.6771276595744681
- 0.6812234042553191
- 0.6764893617021277
- 0.6762765957446808
- 0.5789893617021277
- 0.6780851063829787
- 0.5662765957446808
- 0.6843085106382979
- 0.6781382978723405
- 0.6756382978723404
- 0.6767021276595745
- 0.5768617021276595
- 0.6856382978723404
- 0.6808510638297872
- 0.6826595744680851
- 0.6821276595744681
- 0.6813297872340426
- 0.683031914893617
- 0.6818085106382978
test_loss_list:
- 7.82358419418335
- 3.7752550888061522
- 6.060565700531006
- 9.17617078145345
- 3.685728921890259
- 3.4385128434499106
- 5.556099815368652
- 3.0707571506500244
- 2.803132667541504
- 2.6652058347066245
- 4.64633747736613
- 2.493148612976074
- 4.739403502146403
- 6.332857494354248
- 2.392284456888835
- 2.3656827100118
- 2.346280647913615
- 7.49600440343221
- 2.2963330205281576
- 3.235236593882243
- 2.226168141365051
- 2.2218319892883303
- 3.2193843841552736
- 2.1525755898157755
- 2.1390065733591714
- 2.1724056069056195
- 2.1769043175379434
- 2.184260859489441
- 3.9851999473571778
- 6.491806189219157
- 1.878960951169332
- 2.990663274129232
- 1.7799567476908367
- 1.89909925142924
- 1.9603595527013142
- 1.9316939814885457
- 1.940208241144816
- 2.3328643449147544
- 1.7468628231684367
- 2.9123748620351155
- 1.697959731419881
- 1.7636364046732584
- 1.770359098116557
- 1.790112935702006
- 1.805575785636902
- 1.8233643054962159
- 1.9648417361577353
- 1.667422947883606
- 1.710728735923767
- 1.7487111361821492
- 1.7126064682006836
- 1.7496536954243977
- 1.7382341464360556
- 1.7840989891688028
- 1.7532656812667846
- 1.7473716656366984
- 1.7679998779296875
- 1.7946098820368448
- 1.6610141277313233
- 1.6390575218200683
- 1.641336997350057
- 1.7541652917861938
- 1.4457536522547405
- 1.507697795232137
- 1.5406787522633871
- 1.5506823587417602
- 1.609464201927185
- 1.6140717188517253
- 1.5970857175191244
- 1.6620947313308716
- 1.4781610266367595
- 1.5199747673670452
- 1.5511967452367146
- 1.6962775214513144
- 1.3668137486775715
- 1.5789589309692382
- 2.426596508026123
- 1.2195601669947307
- 1.4198406791687013
- 1.2201948801676432
- 1.3020821078618368
- 1.3470285654067993
- 1.4051537752151488
- 1.4401335509618123
- 1.4186674404144286
- 1.5478938945134482
- 1.3037915325164795
- 1.4544760433832804
- 1.2000142494837442
- 1.300189471244812
- 1.339318512280782
- 1.364554459253947
- 1.5491705338160198
- 1.2589566230773925
- 1.3229940636952717
- 1.3439781506856283
- 1.3920013014475505
- 1.4245841884613037
- 1.4110994132359822
- 1.4625284481048584
train_accuracy:
- 0.0
- 0.0
- 0.929
- 0.023
- 0.075
- 0.215
- 0.835
- 0.0
- 0.0
- 0.481
- 0.688
- 0.0
- 0.956
- 0.0
- 0.0
- 0.573
- 0.0
- 0.571
- 0.0
- 0.96
- 0.602
- 0.656
- 0.969
- 0.625
- 0.665
- 0.0
- 0.0
- 0.0
- 0.887
- 0.99
- 0.694
- 0.573
- 0.0
- 0.679
- 0.679
- 0.0
- 0.0
- 0.952
- 0.0
- 0.967
- 0.044
- 0.71
- 0.0
- 0.0
- 0.723
- 0.0
- 0.902
- 0.0
- 0.729
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.756
- 0.0
- 0.0
- 0.79
- 0.796
- 0.0
- 0.0
- 0.923
- 0.0
- 0.748
- 0.0
- 0.0
- 0.0
- 0.767
- 0.0
- 0.985
- 0.0
- 0.0
- 0.0
- 0.965
- 0.787
- 0.998
- 0.971
- 0.0
- 0.998
- 0.029
- 0.0
- 0.779
- 0.787
- 0.0
- 0.815
- 0.935
- 0.81
- 0.858
- 0.16
- 0.0
- 0.787
- 0.769
- 0.979
- 0.787
- 0.0
- 0.029
- 0.023
- 0.783
- 0.0
- 0.0
train_loss:
- 0.387
- 1.414
- 0.322
- 0.135
- 2.622
- 1.362
- 0.178
- 1.201
- 2.022
- 1.827
- 0.158
- 1.082
- 0.191
- 0.163
- 0.939
- 0.863
- 0.873
- 0.172
- 0.875
- 0.162
- 0.787
- 1.414
- 0.17
- 0.829
- 0.754
- 0.711
- 0.723
- 0.735
- 0.202
- 0.113
- 0.686
- 0.171
- 0.676
- 1.171
- 0.649
- 0.687
- 0.653
- 0.183
- 0.674
- 0.162
- 0.655
- 1.091
- 0.607
- 0.585
- 1.062
- 1.003
- 0.172
- 0.53
- 0.587
- 0.552
- 0.627
- 0.54
- 0.586
- 0.544
- 0.58
- 0.588
- 0.562
- 0.917
- 0.182
- 0.474
- 0.552
- 0.199
- 0.52
- 0.49
- 0.495
- 0.523
- 0.872
- 0.505
- 0.51
- 0.138
- 0.461
- 0.522
- 0.519
- 0.151
- 0.879
- 0.112
- 0.094
- 0.443
- 0.122
- 0.449
- 0.461
- 0.821
- 0.812
- 0.477
- 0.48
- 0.144
- 0.449
- 0.141
- 0.444
- 0.455
- 0.447
- 0.471
- 0.132
- 0.418
- 0.449
- 0.452
- 0.441
- 0.765
- 0.45
- 0.446
unequal: 0
verbose: 1
