avg_train_accuracy: 0.004
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.031329787234042554
- 0.052074468085106386
- 0.14143617021276594
- 0.23861702127659573
- 0.03877659574468085
- 0.3044148936170213
- 0.048723404255319146
- 0.398031914893617
- 0.4473404255319149
- 0.4765957446808511
- 0.08638297872340425
- 0.05276595744680851
- 0.49867021276595747
- 0.1023404255319149
- 0.5123936170212766
- 0.14840425531914894
- 0.525904255319149
- 0.5309574468085106
- 0.2623936170212766
- 0.12159574468085106
- 0.5422872340425532
- 0.5534574468085106
- 0.5636702127659574
- 0.5662765957446808
- 0.29595744680851066
- 0.12585106382978722
- 0.5765425531914894
- 0.5812234042553192
- 0.5922872340425532
- 0.5960106382978724
- 0.2251063829787234
- 0.13382978723404254
- 0.5985106382978723
- 0.6013829787234043
- 0.6092553191489362
- 0.39324468085106384
- 0.6112765957446809
- 0.6147872340425532
- 0.6138829787234042
- 0.40797872340425534
- 0.626436170212766
- 0.6260638297872341
- 0.6321808510638298
- 0.6343617021276595
- 0.4928723404255319
- 0.6345744680851064
- 0.6384574468085107
- 0.4754255319148936
- 0.636436170212766
- 0.6404787234042553
- 0.641595744680851
- 0.45526595744680853
- 0.6441489361702127
- 0.6421808510638298
- 0.5154787234042553
- 0.6488829787234043
- 0.6487765957446808
- 0.6513297872340426
- 0.653936170212766
- 0.5789893617021277
- 0.6516489361702128
- 0.4897872340425532
- 0.24835106382978722
- 0.658031914893617
- 0.6557978723404255
- 0.5964893617021276
- 0.661063829787234
- 0.6606914893617021
- 0.5253723404255319
- 0.1873936170212766
- 0.24132978723404255
- 0.6578191489361702
- 0.6570744680851064
- 0.6646276595744681
- 0.6642021276595744
- 0.5095744680851064
- 0.29069148936170214
- 0.6637234042553192
- 0.6642553191489362
- 0.6298936170212766
- 0.6667553191489362
- 0.6630851063829787
- 0.4597872340425532
- 0.6694148936170212
- 0.665
- 0.6676595744680851
- 0.6677127659574468
- 0.6673404255319149
- 0.6731914893617021
- 0.6722872340425532
- 0.6679255319148936
- 0.6112765957446809
- 0.6719148936170213
- 0.6745212765957447
- 0.6356382978723404
- 0.6746276595744681
- 0.6722872340425532
- 0.586063829787234
- 0.6730851063829787
- 0.6729787234042554
test_loss_list:
- 3.7810249487559
- 3.745804926554362
- 3.6360218715667725
- 3.3812046432495118
- 5.767971579233805
- 3.043815975189209
- 6.145896059672038
- 2.7660597292582194
- 2.5793074067433674
- 2.5176673698425294
- 5.523140767415365
- 9.78795851389567
- 2.328248281478882
- 4.0454684829711915
- 2.2415641212463377
- 4.2127534294128415
- 2.152723026275635
- 2.1540368588765464
- 2.8690854930877685
- 4.9651847839355465
- 2.0484584538141886
- 2.0825916210810345
- 2.0923316192626955
- 2.0870518048604327
- 2.646708536148071
- 3.6540716171264647
- 1.906679957707723
- 1.9703836011886597
- 1.9822728141148884
- 2.0076271359125775
- 3.2986838754018146
- 4.639715461730957
- 1.834190961519877
- 1.9052125279108683
- 1.9222332731882732
- 2.3474879837036133
- 1.7611649084091185
- 1.822755142847697
- 1.8701017300287883
- 2.304282522201538
- 1.755263129870097
- 1.7818303712209065
- 1.8077501487731933
- 1.8565634425481161
- 1.9265039698282878
- 1.6403875875473022
- 1.7371747907002766
- 1.9972155650456747
- 1.57177703221639
- 1.6459975051879883
- 1.6705863746007283
- 2.1181415367126464
- 1.579693636894226
- 1.6405721092224121
- 1.7920722770690918
- 1.477204696337382
- 1.5330178785324096
- 1.5994267638524373
- 1.6073086373011272
- 1.6414938990275065
- 1.50111093044281
- 1.9577234919865927
- 4.20621906598409
- 1.4303549067179362
- 1.4868140935897827
- 1.5705623737970988
- 1.4313912359873453
- 1.5253545411427816
- 1.7883164421717326
- 4.554687951405843
- 3.792406975428263
- 1.324129530588786
- 1.4275014511744182
- 1.4512158012390137
- 1.4988326501846314
- 1.7404964447021485
- 3.1059115028381346
- 1.3504123830795287
- 1.4159677028656006
- 1.3881346877415974
- 1.271396780014038
- 1.3874297285079955
- 1.917402442296346
- 1.2944781589508056
- 1.3888468742370605
- 1.4401059293746947
- 1.4434683434168498
- 1.4697073936462401
- 1.5062404441833497
- 1.509070905049642
- 1.544104455312093
- 1.5293611097335815
- 1.3650195439656576
- 1.4364135837554932
- 1.443992904027303
- 1.332948800722758
- 1.423790415128072
- 1.5180307706197103
- 1.2977246475219726
- 1.3483014329274496
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.981
- 0.36
- 0.921
- 0.442
- 0.0
- 0.552
- 0.898
- 0.908
- 0.0
- 0.727
- 0.588
- 0.971
- 0.0
- 0.0
- 0.692
- 0.817
- 0.0
- 0.0
- 0.0
- 0.673
- 0.917
- 0.513
- 0.665
- 0.0
- 0.685
- 0.688
- 0.904
- 0.502
- 0.713
- 0.0
- 0.0
- 0.823
- 0.71
- 0.0
- 0.0
- 0.958
- 0.0
- 0.735
- 0.744
- 0.748
- 0.892
- 0.0
- 0.752
- 0.981
- 0.0
- 0.0
- 0.0
- 0.954
- 0.006
- 0.0
- 0.767
- 0.765
- 0.758
- 0.777
- 0.0
- 0.985
- 0.0
- 0.963
- 0.927
- 0.767
- 0.775
- 0.973
- 0.073
- 0.783
- 0.981
- 0.985
- 0.988
- 0.0
- 0.0
- 0.0
- 0.775
- 0.929
- 0.99
- 0.025
- 0.033
- 0.975
- 0.0
- 0.771
- 0.923
- 0.771
- 0.01
- 0.0
- 0.779
- 0.0
- 0.798
- 0.0
- 0.0
- 0.89
- 0.787
- 0.806
- 0.975
- 0.796
- 0.0
- 0.981
- 0.004
- 0.004
train_loss:
- 1.53
- 1.657
- 2.596
- 1.336
- 0.263
- 1.187
- 0.161
- 2.036
- 1.022
- 0.94
- 0.22
- 0.113
- 0.944
- 0.198
- 1.609
- 0.173
- 0.823
- 0.82
- 0.151
- 0.082
- 0.779
- 0.74
- 0.738
- 0.767
- 0.171
- 0.165
- 0.744
- 0.682
- 1.212
- 0.698
- 0.186
- 0.117
- 0.679
- 0.642
- 1.143
- 0.161
- 0.653
- 0.645
- 0.61
- 0.151
- 1.166
- 0.603
- 1.03
- 1.037
- 0.227
- 0.583
- 0.566
- 0.168
- 0.611
- 0.58
- 0.588
- 0.152
- 0.496
- 0.54
- 0.139
- 0.55
- 0.538
- 0.562
- 0.523
- 0.123
- 0.536
- 0.139
- 0.035
- 0.993
- 0.505
- 0.112
- 0.465
- 0.895
- 0.148
- 0.087
- 0.07
- 0.476
- 0.495
- 0.511
- 0.876
- 0.15
- 0.064
- 0.478
- 0.502
- 0.14
- 0.502
- 0.478
- 0.13
- 0.468
- 0.467
- 0.835
- 0.479
- 0.52
- 0.833
- 0.476
- 0.484
- 0.147
- 0.435
- 0.828
- 0.125
- 0.445
- 0.486
- 0.15
- 0.44
- 0.46
unequal: 0
verbose: 1
