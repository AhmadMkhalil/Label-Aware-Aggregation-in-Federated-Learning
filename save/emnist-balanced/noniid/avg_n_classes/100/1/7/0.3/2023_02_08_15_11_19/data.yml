avg_train_accuracy: 0.794
avg_train_loss: 0.012
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03324468085106383
- 0.06180851063829787
- 0.02127659574468085
- 0.09648936170212766
- 0.19356382978723405
- 0.30484042553191487
- 0.389468085106383
- 0.059468085106382976
- 0.02920212765957447
- 0.022180851063829787
- 0.41579787234042553
- 0.4650531914893617
- 0.0676063829787234
- 0.03946808510638298
- 0.46404255319148935
- 0.14292553191489363
- 0.4902127659574468
- 0.5067553191489361
- 0.12840425531914892
- 0.06196808510638298
- 0.5139361702127659
- 0.526436170212766
- 0.5371276595744681
- 0.5397340425531915
- 0.5518085106382978
- 0.5598936170212766
- 0.1829787234042553
- 0.13159574468085106
- 0.5677127659574468
- 0.21872340425531914
- 0.566595744680851
- 0.18212765957446808
- 0.09196808510638298
- 0.5742553191489361
- 0.3104787234042553
- 0.5786170212765958
- 0.5875531914893617
- 0.5930319148936171
- 0.5906382978723405
- 0.5945212765957447
- 0.6008510638297873
- 0.6025531914893617
- 0.6020744680851063
- 0.30936170212765957
- 0.603563829787234
- 0.38601063829787235
- 0.607872340425532
- 0.6159042553191489
- 0.39595744680851064
- 0.6143085106382978
- 0.6242021276595745
- 0.6256382978723404
- 0.47617021276595745
- 0.631436170212766
- 0.48101063829787233
- 0.628031914893617
- 0.46888297872340423
- 0.6272340425531915
- 0.45989361702127657
- 0.31138297872340426
- 0.6335106382978724
- 0.5100531914893617
- 0.6368085106382979
- 0.5345212765957447
- 0.6410106382978723
- 0.6408510638297872
- 0.6407978723404255
- 0.6406382978723404
- 0.6457978723404255
- 0.646436170212766
- 0.5052127659574468
- 0.6436702127659575
- 0.6467021276595745
- 0.6517021276595745
- 0.6479255319148937
- 0.651595744680851
- 0.6528723404255319
- 0.6529255319148937
- 0.6585106382978724
- 0.5485106382978724
- 0.6591489361702128
- 0.656063829787234
- 0.5140957446808511
- 0.6643085106382979
- 0.66
- 0.6644148936170213
- 0.6692553191489362
- 0.6627127659574468
- 0.6634042553191489
- 0.5688829787234042
- 0.6657446808510639
- 0.6681914893617021
- 0.6658510638297872
- 0.5578191489361702
- 0.6730851063829787
- 0.5704787234042553
- 0.6745744680851063
- 0.6742553191489362
- 0.6705319148936171
- 0.6755851063829788
test_loss_list:
- 7.723824933369954
- 3.767820234298706
- 6.982280406951904
- 3.665160191853841
- 3.453190310796102
- 3.13433344523112
- 2.8721473948160807
- 5.656429538726806
- 7.859798208872477
- 10.576709111531576
- 2.6475613212585447
- 2.569111868540446
- 5.052135938008626
- 8.62828488667806
- 2.4195357735951744
- 3.6551119804382326
- 2.3404774125417074
- 2.362511860529582
- 3.7881541856129965
- 7.598116798400879
- 2.1579004542032876
- 2.218963737487793
- 2.234691648483276
- 2.2264198541641234
- 2.2334017022450765
- 2.2443839645385744
- 3.790448013941447
- 4.656957467397054
- 2.0158627541859944
- 3.561358331044515
- 1.923721022605896
- 3.9245377572377524
- 5.064346669514974
- 1.8170106665293375
- 2.5763818645477294
- 1.8188453642527262
- 1.8761178382237753
- 1.925782740910848
- 1.9285512002309164
- 1.9285861841837566
- 1.940736157099406
- 1.9451863972345989
- 1.9844691673914592
- 2.418867276509603
- 1.8180516942342122
- 2.243714450200399
- 1.6970961459477742
- 1.7334728876749674
- 2.4469088554382323
- 1.6972119919459026
- 1.7620031674702963
- 1.7797748867670695
- 1.9114296738306682
- 1.6552213191986085
- 2.113799435297648
- 1.5810292116800944
- 1.9119534508387248
- 1.5379970820744833
- 1.9258410151799519
- 2.577584120432536
- 1.4181960821151733
- 1.6781384134292603
- 1.4318575922648111
- 1.695993717511495
- 1.400949403444926
- 1.479718763033549
- 1.5320240259170532
- 1.6179711612065633
- 1.6200841601689657
- 1.6219580109914145
- 1.8787535762786864
- 1.5318568325042725
- 1.5878489557902018
- 1.5575681924819946
- 1.595608687400818
- 1.6187092129389444
- 1.6428179788589476
- 1.7040044705073039
- 1.6725390227635701
- 1.7294997517267863
- 1.4928549941380818
- 1.594928952852885
- 1.7435437615712484
- 1.3788542572657267
- 1.4951301447550456
- 1.4954886611302693
- 1.5295275243123372
- 1.6069774580001832
- 1.5762779760360717
- 1.645746372540792
- 1.4880665238698323
- 1.4906426461537678
- 1.5777555227279663
- 1.7621441650390626
- 1.3590589634577432
- 1.6432338953018188
- 1.3844142611821493
- 1.4268652852376302
- 1.5035814682642619
- 1.5479816722869872
train_accuracy:
- 0.865
- 0.069
- 0.0
- 0.123
- 0.0
- 0.383
- 0.0
- 0.896
- 0.988
- 0.0
- 0.0
- 0.0
- 0.742
- 0.804
- 0.0
- 0.69
- 0.573
- 0.592
- 0.896
- 0.969
- 0.0
- 0.602
- 0.64
- 0.625
- 0.0
- 0.0
- 0.988
- 0.96
- 0.0
- 0.967
- 0.0
- 0.988
- 0.988
- 0.0
- 0.985
- 0.0
- 0.706
- 0.729
- 0.0
- 0.696
- 0.0
- 0.0
- 0.0
- 0.919
- 0.713
- 0.908
- 0.0
- 0.0
- 0.952
- 0.0
- 0.0
- 0.0
- 0.948
- 0.742
- 0.981
- 0.0
- 0.981
- 0.748
- 0.963
- 0.931
- 0.0
- 0.963
- 0.0
- 0.91
- 0.0
- 0.0
- 0.002
- 0.0
- 0.763
- 0.0
- 0.965
- 0.0
- 0.0
- 0.0
- 0.746
- 0.0
- 0.0
- 0.781
- 0.76
- 0.975
- 0.0
- 0.0
- 0.996
- 0.783
- 0.781
- 0.769
- 0.775
- 0.0
- 0.0
- 0.981
- 0.777
- 0.0
- 0.796
- 0.985
- 0.077
- 0.983
- 0.075
- 0.796
- 0.002
- 0.794
train_loss:
- 0.303
- 1.389
- 0.365
- 1.312
- 1.373
- 1.214
- 2.022
- 0.209
- 0.154
- 0.114
- 1.191
- 0.948
- 0.17
- 0.102
- 0.93
- 0.14
- 0.874
- 0.865
- 0.22
- 0.107
- 0.848
- 1.46
- 0.774
- 0.766
- 0.781
- 1.337
- 0.179
- 0.103
- 1.364
- 0.138
- 0.737
- 0.174
- 0.156
- 0.735
- 0.116
- 0.625
- 1.184
- 1.157
- 0.654
- 0.649
- 0.683
- 0.661
- 0.639
- 0.221
- 0.611
- 0.176
- 0.577
- 0.59
- 0.13
- 0.533
- 1.049
- 0.579
- 0.184
- 1.506
- 0.122
- 0.56
- 0.145
- 0.587
- 0.15
- 0.091
- 0.558
- 0.115
- 0.561
- 0.1
- 0.57
- 0.544
- 0.54
- 0.543
- 0.938
- 0.533
- 0.149
- 0.53
- 0.536
- 0.549
- 0.521
- 0.551
- 0.539
- 0.516
- 0.539
- 0.17
- 0.912
- 0.478
- 0.159
- 0.943
- 0.479
- 0.895
- 0.499
- 0.489
- 0.533
- 0.143
- 0.466
- 0.491
- 0.497
- 0.128
- 0.471
- 0.105
- 0.809
- 0.837
- 0.826
- 1.159
unequal: 0
verbose: 1
