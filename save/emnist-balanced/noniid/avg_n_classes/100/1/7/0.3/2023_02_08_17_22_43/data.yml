avg_train_accuracy: 0.829
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03452127659574468
- 0.03776595744680851
- 0.14367021276595746
- 0.24212765957446808
- 0.04537234042553191
- 0.31053191489361703
- 0.4198404255319149
- 0.45648936170212767
- 0.5013297872340425
- 0.08313829787234042
- 0.5070212765957447
- 0.5218085106382979
- 0.5462765957446809
- 0.550531914893617
- 0.5519148936170213
- 0.5734574468085106
- 0.5847340425531915
- 0.5913829787234043
- 0.12590425531914895
- 0.5918617021276595
- 0.5962765957446808
- 0.6035106382978723
- 0.6086170212765958
- 0.6086702127659575
- 0.6226063829787234
- 0.6227127659574468
- 0.6293617021276596
- 0.6306382978723404
- 0.3672872340425532
- 0.6314893617021277
- 0.6367553191489361
- 0.6333510638297872
- 0.47085106382978725
- 0.6437234042553192
- 0.6463829787234042
- 0.6431914893617021
- 0.27122340425531916
- 0.6487234042553192
- 0.6507978723404255
- 0.390531914893617
- 0.2001063829787234
- 0.6524468085106383
- 0.31579787234042556
- 0.6542553191489362
- 0.46664893617021275
- 0.6526063829787234
- 0.6602659574468085
- 0.6614361702127659
- 0.660904255319149
- 0.6595744680851063
- 0.4277127659574468
- 0.663031914893617
- 0.6626063829787234
- 0.6678191489361702
- 0.666968085106383
- 0.6712234042553191
- 0.6693617021276596
- 0.6678191489361702
- 0.49234042553191487
- 0.2652127659574468
- 0.6747872340425531
- 0.6747340425531915
- 0.6709574468085107
- 0.6776063829787234
- 0.6761702127659575
- 0.6770212765957446
- 0.6776063829787234
- 0.6814893617021277
- 0.679468085106383
- 0.5072872340425532
- 0.6754255319148936
- 0.4904787234042553
- 0.6765425531914894
- 0.5114893617021277
- 0.6794148936170212
- 0.5642021276595744
- 0.6810106382978723
- 0.681968085106383
- 0.6843617021276596
- 0.6192021276595745
- 0.6869148936170213
- 0.5825531914893617
- 0.6877659574468085
- 0.5819148936170213
- 0.3535106382978723
- 0.6908510638297872
- 0.6892021276595744
- 0.6817021276595745
- 0.689627659574468
- 0.5727659574468085
- 0.6857978723404256
- 0.6849468085106383
- 0.5412234042553191
- 0.6877659574468085
- 0.685
- 0.6879255319148936
- 0.6893085106382979
- 0.6502659574468085
- 0.6872340425531915
- 0.6920744680851064
test_loss_list:
- 3.778708086013794
- 5.645499629974365
- 3.6518710327148436
- 3.391328035990397
- 4.822437477111817
- 3.010810550053914
- 2.753608617782593
- 2.5942573833465574
- 2.501490166982015
- 4.777753938039144
- 2.3531561597188313
- 2.34155291557312
- 2.310029673576355
- 2.3298758538564046
- 2.3310195144017536
- 2.3287281592686973
- 2.353242613474528
- 2.328453256289164
- 4.859343268076579
- 2.051198164621989
- 2.1362056875228883
- 2.161130348841349
- 2.12421871026357
- 2.198173071543376
- 2.2057646703720093
- 2.2305411815643312
- 2.248413790067037
- 2.184544316927592
- 2.4871618684132892
- 1.9338348197937012
- 2.0191330512364707
- 2.1153928422927857
- 2.1307774511973063
- 1.8627325280507405
- 1.901017344792684
- 1.9452880493799845
- 3.013002471923828
- 1.7930251677831015
- 1.8462492815653484
- 2.65715212504069
- 3.4212358474731444
- 1.6094197877248129
- 2.7648089122772217
- 1.5733098332087199
- 1.9275992743174235
- 1.5310270818074545
- 1.597943007151286
- 1.6474411249160767
- 1.6767099952697755
- 1.759340147972107
- 2.0470999177296956
- 1.5588702440261841
- 1.6285828193028768
- 1.6463465897242229
- 1.67785609404246
- 1.6979917287826538
- 1.699455647468567
- 1.7283423074086508
- 1.8444338432947796
- 3.038496421178182
- 1.4352661752700806
- 1.5556081215540567
- 1.5843436861038207
- 1.6299315230051676
- 1.6792498588562013
- 1.7153154150644938
- 1.727180584271749
- 1.7371420510609945
- 1.7770498577753704
- 1.8055583016077676
- 1.5122759087880453
- 2.006251770655314
- 1.3854973157246908
- 1.9136813179651897
- 1.3286339410146077
- 1.570513383547465
- 1.2982857322692871
- 1.3894818099339803
- 1.4377627325057984
- 1.4248219807942708
- 1.3249888722101848
- 1.4536384232838948
- 1.3071398703257242
- 1.4717846552530924
- 2.6290030670166016
- 1.2344387499491374
- 1.3179917812347413
- 1.3748985703786214
- 1.4191229104995728
- 1.5686445395151773
- 1.2791463057200114
- 1.3537265300750732
- 1.7046450662612915
- 1.2481098159154256
- 1.3612200864156088
- 1.3362317673365276
- 1.4011454582214355
- 1.261819944381714
- 1.2932030550638836
- 1.3170065355300904
train_accuracy:
- 0.029
- 0.812
- 0.012
- 0.0
- 0.562
- 0.335
- 0.525
- 0.0
- 0.569
- 0.956
- 0.0
- 0.583
- 0.677
- 0.0
- 0.0
- 0.648
- 0.0
- 0.717
- 0.877
- 0.715
- 0.0
- 0.0
- 0.0
- 0.7
- 0.752
- 0.0
- 0.735
- 0.758
- 0.89
- 0.0
- 0.769
- 0.721
- 0.648
- 0.0
- 0.752
- 0.725
- 0.965
- 0.0
- 0.0
- 0.99
- 0.529
- 0.004
- 0.969
- 0.0
- 0.977
- 0.0
- 0.0
- 0.773
- 0.0
- 0.0
- 0.954
- 0.792
- 0.0
- 0.81
- 0.0
- 0.779
- 0.783
- 0.0
- 0.954
- 0.979
- 0.01
- 0.794
- 0.0
- 0.796
- 0.8
- 0.792
- 0.8
- 0.0
- 0.765
- 0.954
- 0.035
- 0.954
- 0.81
- 0.971
- 0.012
- 0.977
- 0.802
- 0.0
- 0.806
- 0.956
- 0.0
- 0.969
- 0.806
- 0.975
- 0.975
- 0.787
- 0.0
- 0.781
- 0.821
- 0.944
- 0.773
- 0.0
- 0.981
- 0.0
- 0.785
- 0.0
- 0.79
- 0.908
- 0.79
- 0.829
train_loss:
- 1.503
- 0.375
- 1.345
- 1.311
- 0.166
- 2.252
- 1.963
- 0.966
- 1.656
- 0.157
- 0.884
- 0.839
- 1.469
- 0.791
- 0.777
- 1.291
- 1.277
- 1.259
- 0.26
- 0.725
- 0.695
- 1.175
- 0.725
- 0.662
- 1.097
- 1.062
- 1.111
- 0.706
- 0.225
- 0.689
- 0.618
- 0.596
- 0.226
- 0.529
- 1.035
- 0.567
- 0.196
- 0.562
- 0.552
- 0.141
- 0.154
- 0.575
- 0.151
- 0.531
- 0.142
- 0.54
- 0.521
- 0.912
- 0.517
- 0.514
- 0.18
- 0.924
- 0.528
- 0.529
- 0.49
- 0.882
- 0.524
- 0.514
- 0.19
- 0.099
- 0.46
- 0.843
- 0.479
- 0.853
- 0.82
- 0.819
- 0.827
- 0.819
- 0.468
- 0.186
- 0.465
- 0.159
- 0.519
- 0.133
- 0.444
- 0.119
- 0.458
- 0.792
- 0.785
- 0.139
- 0.44
- 0.109
- 0.441
- 0.105
- 0.061
- 0.807
- 0.793
- 0.431
- 0.767
- 0.142
- 0.448
- 0.446
- 0.129
- 0.794
- 0.445
- 0.451
- 0.428
- 0.14
- 0.433
- 0.775
unequal: 0
verbose: 1
