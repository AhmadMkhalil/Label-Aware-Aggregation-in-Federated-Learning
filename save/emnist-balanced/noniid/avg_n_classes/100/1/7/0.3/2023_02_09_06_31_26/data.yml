avg_train_accuracy: 0.946
avg_train_loss: 0.001
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.043617021276595745
- 0.06712765957446809
- 0.05377659574468085
- 0.05484042553191489
- 0.13627659574468085
- 0.26340425531914896
- 0.3551595744680851
- 0.4079255319148936
- 0.4247872340425532
- 0.45952127659574465
- 0.4775531914893617
- 0.07792553191489361
- 0.4991489361702128
- 0.5092021276595745
- 0.5271808510638298
- 0.5382446808510638
- 0.5488297872340425
- 0.558031914893617
- 0.5751595744680851
- 0.18111702127659574
- 0.5763829787234043
- 0.19585106382978723
- 0.5820212765957447
- 0.5922340425531915
- 0.33313829787234045
- 0.5997340425531915
- 0.5984574468085107
- 0.6095212765957447
- 0.6138297872340426
- 0.10601063829787234
- 0.3020744680851064
- 0.15420212765957447
- 0.12845744680851065
- 0.07
- 0.051702127659574465
- 0.6105851063829787
- 0.3252127659574468
- 0.6148936170212767
- 0.43579787234042555
- 0.6246808510638298
- 0.49569148936170215
- 0.6228191489361702
- 0.6270744680851064
- 0.6332978723404256
- 0.46047872340425533
- 0.6279787234042553
- 0.5229787234042553
- 0.6362765957446809
- 0.638563829787234
- 0.5178191489361702
- 0.6390957446808511
- 0.6436170212765957
- 0.6462234042553191
- 0.6518617021276596
- 0.6538829787234043
- 0.6554255319148936
- 0.6517553191489361
- 0.656595744680851
- 0.6557446808510639
- 0.6602127659574468
- 0.6614893617021277
- 0.6592553191489362
- 0.6587234042553192
- 0.6652127659574468
- 0.6637234042553192
- 0.6676595744680851
- 0.6681914893617021
- 0.6188297872340426
- 0.6658510638297872
- 0.6668617021276596
- 0.6720212765957447
- 0.6690957446808511
- 0.6693085106382979
- 0.6702659574468085
- 0.6751063829787234
- 0.6732446808510638
- 0.673936170212766
- 0.6726595744680851
- 0.6745744680851063
- 0.6762234042553191
- 0.6766489361702127
- 0.6805851063829788
- 0.6796808510638298
- 0.6814893617021277
- 0.6798404255319149
- 0.6828191489361702
- 0.6845212765957447
- 0.681968085106383
- 0.6803191489361702
- 0.5745744680851064
- 0.3951063829787234
- 0.6860106382978723
- 0.6004255319148936
- 0.6863829787234043
- 0.5993617021276596
- 0.36106382978723406
- 0.2801063829787234
- 0.6875
- 0.5782978723404255
- 0.48851063829787233
test_loss_list:
- 3.776561222076416
- 3.711130952835083
- 5.764792149861654
- 8.314836247762043
- 3.4631801795959474
- 3.1642668374379475
- 2.9269981479644773
- 2.753449796040853
- 2.6672078450520833
- 2.61169194539388
- 2.579822292327881
- 4.610124740600586
- 2.417698122660319
- 2.4419242413838704
- 2.3661084175109863
- 2.414588139851888
- 2.420447063446045
- 2.327477477391561
- 2.375270388921102
- 3.791080551147461
- 2.080898774464925
- 3.4081383323669434
- 1.9794700479507445
- 2.0787153228123985
- 2.446262566248576
- 1.9738526312510172
- 2.0532680320739747
- 2.0325432221094766
- 2.0395414145787556
- 4.9516530672709145
- 2.457388060887655
- 4.1086717732747395
- 4.393006483713786
- 7.145027122497559
- 8.120632228851319
- 1.560022497177124
- 2.705301834742228
- 1.5840982675552369
- 2.167931725184123
- 1.580630474090576
- 1.8003774658838907
- 1.5030448325475056
- 1.6024024820327758
- 1.635656026204427
- 2.004914633433024
- 1.538029588063558
- 1.8524272441864014
- 1.4983900165557862
- 1.5480434068044027
- 1.7381902424494426
- 1.4709522104263306
- 1.5194870980580648
- 1.551169514656067
- 1.5960091018676759
- 1.6248747205734253
- 1.6498763211568197
- 1.6492197481791178
- 1.6831654262542726
- 1.7043892319997151
- 1.7112560335795084
- 1.7377622922261555
- 1.7228753105799357
- 1.7387046575546266
- 1.7299989906946818
- 1.7614226611455281
- 1.7493370310465495
- 1.7552447239557902
- 1.4494786659876506
- 1.4618546374638874
- 1.5434654919306436
- 1.5508481931686402
- 1.5574151293436687
- 1.627314182917277
- 1.6283986457188924
- 1.6201290702819824
- 1.622581075032552
- 1.601774401664734
- 1.597040713628133
- 1.6220853249231975
- 1.6587783368428548
- 1.682530590693156
- 1.6895052433013915
- 1.6809816376368205
- 1.6676497173309326
- 1.6877002795537313
- 1.6994730393091837
- 1.6476725498835245
- 1.6677461830774942
- 1.666102925936381
- 1.6712866989771524
- 2.504615494410197
- 1.3584446414311726
- 1.5398004134496053
- 1.3189376227060954
- 1.3460300906499227
- 2.7039629459381103
- 3.5364710489908853
- 1.099833264350891
- 1.5288650019963583
- 1.7907325506210328
train_accuracy:
- 0.052
- 0.0
- 0.969
- 0.948
- 0.0
- 0.0
- 0.0
- 0.0
- 0.517
- 0.0
- 0.0
- 0.883
- 0.585
- 0.615
- 0.631
- 0.0
- 0.0
- 0.0
- 0.0
- 0.917
- 0.66
- 0.944
- 0.0
- 0.0
- 0.965
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.99
- 0.988
- 0.956
- 0.496
- 0.037
- 0.0
- 0.915
- 0.737
- 0.988
- 0.715
- 0.954
- 0.002
- 0.0
- 0.729
- 0.956
- 0.0
- 0.975
- 0.74
- 0.0
- 0.86
- 0.0
- 0.0
- 0.0
- 0.0
- 0.783
- 0.0
- 0.765
- 0.798
- 0.794
- 0.758
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.975
- 0.8
- 0.808
- 0.785
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.0
- 0.785
- 0.842
- 0.0
- 0.842
- 0.0
- 0.0
- 0.0
- 0.958
- 0.856
- 0.0
- 0.965
- 0.0
- 0.94
- 0.998
- 0.985
- 0.0
- 0.985
- 0.946
train_loss:
- 2.702
- 1.544
- 0.327
- 0.089
- 1.376
- 1.243
- 2.065
- 1.887
- 0.993
- 0.934
- 0.895
- 0.242
- 0.9
- 0.809
- 0.888
- 0.821
- 0.746
- 0.819
- 1.26
- 0.325
- 0.752
- 0.214
- 0.688
- 0.693
- 0.176
- 1.178
- 0.634
- 0.634
- 0.646
- 0.28
- 0.227
- 0.094
- 0.097
- 0.043
- 0.048
- 0.635
- 0.111
- 0.611
- 0.112
- 1.065
- 0.154
- 0.542
- 0.58
- 1.014
- 0.136
- 0.552
- 0.112
- 1.019
- 0.533
- 0.165
- 0.548
- 0.561
- 0.548
- 0.959
- 0.928
- 0.937
- 0.55
- 0.914
- 0.531
- 0.892
- 0.878
- 0.52
- 0.525
- 0.551
- 0.517
- 0.901
- 0.533
- 0.184
- 0.531
- 0.473
- 0.863
- 0.528
- 0.502
- 0.449
- 0.839
- 0.504
- 0.541
- 0.51
- 0.519
- 0.839
- 0.481
- 0.807
- 0.482
- 0.81
- 0.488
- 0.472
- 0.501
- 0.5
- 0.483
- 0.158
- 0.107
- 0.484
- 0.122
- 0.489
- 0.134
- 0.056
- 0.112
- 0.448
- 0.093
- 0.078
unequal: 0
verbose: 1
