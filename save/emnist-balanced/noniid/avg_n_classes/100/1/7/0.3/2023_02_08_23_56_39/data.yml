avg_train_accuracy: 0.825
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022446808510638298
- 0.03127659574468085
- 0.05686170212765958
- 0.039946808510638296
- 0.17377659574468085
- 0.2796276595744681
- 0.36127659574468085
- 0.43170212765957444
- 0.4567553191489362
- 0.4875531914893617
- 0.4973404255319149
- 0.521436170212766
- 0.5221808510638298
- 0.08590425531914894
- 0.5253723404255319
- 0.5401063829787234
- 0.3173404255319149
- 0.533563829787234
- 0.5504787234042553
- 0.12063829787234043
- 0.556968085106383
- 0.5643617021276596
- 0.2727127659574468
- 0.5661702127659575
- 0.5764893617021276
- 0.2849468085106383
- 0.568031914893617
- 0.581436170212766
- 0.26345744680851063
- 0.5841489361702128
- 0.5921276595744681
- 0.5970212765957447
- 0.41452127659574467
- 0.604095744680851
- 0.4579255319148936
- 0.602872340425532
- 0.3026595744680851
- 0.608563829787234
- 0.33324468085106385
- 0.6092553191489362
- 0.6117553191489362
- 0.6181914893617021
- 0.48398936170212764
- 0.1651063829787234
- 0.11851063829787234
- 0.6206382978723404
- 0.6206914893617022
- 0.6225
- 0.6260106382978723
- 0.45085106382978724
- 0.23691489361702128
- 0.6273404255319149
- 0.6283510638297872
- 0.6330851063829788
- 0.6401595744680851
- 0.6347340425531914
- 0.6442021276595745
- 0.645531914893617
- 0.6475
- 0.5213297872340426
- 0.6456382978723404
- 0.6487234042553192
- 0.6517553191489361
- 0.6513829787234042
- 0.6525531914893618
- 0.6562765957446809
- 0.6540425531914894
- 0.6577127659574468
- 0.6533510638297872
- 0.4283510638297872
- 0.6584042553191489
- 0.6602127659574468
- 0.6584042553191489
- 0.535904255319149
- 0.19872340425531915
- 0.6577127659574468
- 0.5937234042553191
- 0.6598936170212766
- 0.4110106382978723
- 0.6686702127659574
- 0.6672872340425532
- 0.6687234042553192
- 0.5554787234042553
- 0.38601063829787235
- 0.6726063829787234
- 0.5594148936170212
- 0.6672340425531915
- 0.4798404255319149
- 0.6740957446808511
- 0.6743085106382979
- 0.6725531914893617
- 0.6723936170212766
- 0.6771808510638297
- 0.6745212765957447
- 0.5447340425531915
- 0.6760106382978723
- 0.6731914893617021
- 0.6795744680851064
- 0.5848936170212766
- 0.6793085106382979
test_loss_list:
- 9.65080130259196
- 3.7853273296356202
- 3.7474701754252115
- 4.712825539906819
- 3.528451566696167
- 3.2015396785736083
- 2.9607137044270835
- 2.7558393128712972
- 2.678977565765381
- 2.6428099918365477
- 2.6235995356241864
- 2.6365422280629476
- 2.6197601890563966
- 4.383242244720459
- 2.3823724206288657
- 2.414543418884277
- 2.8042536799112954
- 2.213852891921997
- 2.285569141705831
- 3.8476000181833903
- 2.0962301794687908
- 2.1908067941665648
- 2.8768715318044027
- 2.039812266031901
- 2.101208980878194
- 2.7291018199920654
- 2.0332943216959634
- 2.049275379180908
- 2.823973429997762
- 1.9194908507664998
- 1.9752810033162436
- 1.9774119488398234
- 2.214949862162272
- 1.829626948038737
- 2.1047236839930217
- 1.7872275749842326
- 2.88586462020874
- 1.7365410947799682
- 2.4891846211751303
- 1.6341560506820678
- 1.7135857550303142
- 1.7473684024810792
- 1.958036529223124
- 3.471383730570475
- 4.63704891204834
- 1.543119535446167
- 1.599601395924886
- 1.670525614420573
- 1.7090296713511148
- 2.0299235598246255
- 3.433569993972778
- 1.4810874462127686
- 1.547794179916382
- 1.596404406229655
- 1.636484793027242
- 1.669770255088806
- 1.685714610417684
- 1.69308274269104
- 1.6994653606414796
- 1.778592227300008
- 1.525351842244466
- 1.5639248005549113
- 1.60586306254069
- 1.5967929379145305
- 1.6497173770268758
- 1.6276657247543336
- 1.6632712109883627
- 1.6727628008524578
- 1.7016338729858398
- 2.2747722991307575
- 1.493470729192098
- 1.5514560842514038
- 1.552516034444173
- 1.792595828374227
- 4.259662717183431
- 1.4033122777938842
- 1.4770743004480997
- 1.3606673049926759
- 2.1676602602005004
- 1.2965337737401326
- 1.4027347135543824
- 1.4509436066945394
- 1.6785429128011067
- 2.665619173049927
- 1.2715228525797526
- 1.4899170557657877
- 1.2544367265701295
- 1.897740332285563
- 1.2422295538584391
- 1.312530042330424
- 1.379468936920166
- 1.3961327171325684
- 1.4081676562627157
- 1.4391380993525187
- 1.6798590596516927
- 1.3404275623957316
- 1.402226274808248
- 1.4175990613301594
- 1.580395123163859
- 1.2772701088587444
train_accuracy:
- 0.0
- 0.042
- 0.0
- 0.094
- 0.179
- 0.0
- 0.423
- 0.544
- 0.542
- 0.606
- 0.604
- 0.596
- 0.0
- 0.073
- 0.0
- 0.0
- 0.7
- 0.0
- 0.66
- 0.921
- 0.0
- 0.656
- 0.883
- 0.0
- 0.0
- 0.925
- 0.0
- 0.002
- 0.929
- 0.0
- 0.002
- 0.704
- 0.952
- 0.71
- 0.892
- 0.0
- 0.975
- 0.042
- 0.95
- 0.737
- 0.713
- 0.731
- 0.89
- 0.977
- 0.812
- 0.0
- 0.742
- 0.0
- 0.723
- 0.925
- 0.963
- 0.0
- 0.0
- 0.0
- 0.75
- 0.0
- 0.735
- 0.74
- 0.75
- 0.981
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.906
- 0.0
- 0.777
- 0.76
- 0.977
- 0.965
- 0.775
- 0.823
- 0.777
- 0.929
- 0.048
- 0.781
- 0.781
- 0.973
- 0.91
- 0.783
- 0.923
- 0.025
- 0.952
- 0.771
- 0.0
- 0.802
- 0.0
- 0.812
- 0.821
- 0.938
- 0.0
- 0.808
- 0.781
- 0.96
- 0.825
train_loss:
- 0.198
- 1.458
- 1.534
- 0.302
- 1.274
- 1.261
- 1.119
- 1.018
- 1.734
- 1.609
- 0.862
- 2.133
- 0.869
- 0.251
- 0.903
- 0.792
- 0.256
- 0.821
- 0.744
- 0.221
- 0.815
- 0.738
- 0.205
- 0.713
- 0.692
- 0.172
- 0.714
- 0.678
- 0.18
- 0.696
- 0.614
- 1.136
- 0.191
- 1.173
- 0.13
- 1.152
- 0.153
- 0.614
- 0.158
- 0.557
- 0.614
- 0.587
- 0.142
- 0.123
- 0.044
- 0.599
- 0.583
- 0.558
- 1.02
- 0.148
- 0.128
- 0.57
- 0.555
- 0.597
- 0.987
- 0.544
- 0.962
- 0.961
- 0.962
- 0.155
- 0.531
- 0.573
- 0.509
- 0.55
- 0.529
- 0.555
- 0.532
- 0.534
- 0.56
- 0.168
- 0.526
- 0.483
- 0.49
- 0.151
- 0.035
- 0.525
- 0.15
- 0.475
- 0.125
- 0.52
- 0.84
- 0.872
- 0.152
- 0.066
- 0.904
- 0.119
- 0.48
- 0.102
- 0.469
- 0.482
- 0.449
- 0.485
- 0.474
- 0.459
- 0.128
- 0.477
- 0.443
- 0.801
- 0.124
- 0.479
unequal: 0
verbose: 1
