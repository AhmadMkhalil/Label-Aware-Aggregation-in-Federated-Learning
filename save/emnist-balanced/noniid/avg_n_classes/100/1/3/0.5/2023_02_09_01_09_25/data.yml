avg_train_accuracy: 0.777
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.036808510638297876
- 0.05452127659574468
- 0.12909574468085105
- 0.22409574468085106
- 0.3270212765957447
- 0.39218085106382977
- 0.4618617021276596
- 0.5062765957446809
- 0.5421808510638297
- 0.5540957446808511
- 0.5854787234042553
- 0.6010106382978724
- 0.6155851063829787
- 0.628031914893617
- 0.6377659574468085
- 0.6434574468085107
- 0.6493617021276595
- 0.6591489361702128
- 0.6644148936170213
- 0.6664893617021277
- 0.6687765957446808
- 0.6726595744680851
- 0.6812234042553191
- 0.6809574468085107
- 0.6887234042553192
- 0.6916489361702127
- 0.6921276595744681
- 0.6958510638297872
- 0.6957978723404256
- 0.6973404255319149
- 0.7023404255319149
- 0.7045744680851064
- 0.7057978723404256
- 0.7088829787234042
- 0.711436170212766
- 0.7134574468085106
- 0.7150531914893618
- 0.7150531914893618
- 0.7177127659574468
- 0.7176595744680851
- 0.7187234042553191
- 0.7209042553191489
- 0.7228191489361702
- 0.7229787234042553
- 0.7283510638297872
- 0.726968085106383
- 0.7290425531914894
- 0.7300531914893617
- 0.7320744680851063
- 0.7327127659574468
- 0.7319148936170212
- 0.7345212765957447
- 0.731063829787234
- 0.7352659574468086
- 0.736968085106383
- 0.7396808510638297
- 0.7392553191489362
- 0.7398936170212767
- 0.7368085106382979
- 0.7412765957446809
- 0.7422872340425531
- 0.7417553191489362
- 0.7371276595744681
- 0.7434574468085107
- 0.7428191489361702
- 0.7436702127659575
- 0.7470212765957447
- 0.7454787234042554
- 0.7450531914893617
- 0.7471808510638298
- 0.7459574468085106
- 0.7477659574468085
- 0.750904255319149
- 0.749095744680851
- 0.75
- 0.7499468085106383
- 0.7490425531914894
- 0.7502659574468085
- 0.7505851063829787
- 0.7504787234042554
- 0.751968085106383
- 0.7536702127659575
- 0.751968085106383
- 0.7535106382978723
- 0.7518085106382979
- 0.7548936170212766
- 0.7546276595744681
- 0.754468085106383
- 0.7551595744680851
- 0.7560638297872341
- 0.7545744680851064
- 0.756968085106383
- 0.7579787234042553
- 0.7570212765957447
- 0.7557446808510638
- 0.7588829787234043
- 0.7592553191489362
- 0.7579255319148936
- 0.7570212765957447
- 0.7588829787234043
test_loss_list:
- 3.7776252683003744
- 3.7327047189076743
- 3.614161116282145
- 3.3524012978871665
- 3.033666982650757
- 2.7334517828623452
- 2.5047197278340656
- 2.334965604146322
- 2.1920057328542075
- 2.075046434402466
- 1.990701405207316
- 1.9142065016428629
- 1.865218456586202
- 1.8055475838979085
- 1.7854845348993937
- 1.7332861359914145
- 1.7200538158416747
- 1.7006729332605999
- 1.657077021598816
- 1.6472711674372356
- 1.6120504728953045
- 1.5779708115259807
- 1.588056812286377
- 1.5490355110168457
- 1.5237501780192058
- 1.5441920026143392
- 1.517246783574422
- 1.5211109972000123
- 1.4940970834096272
- 1.4641103696823121
- 1.4742538626988728
- 1.4757475058237712
- 1.4450016450881957
- 1.4643478282292683
- 1.472425045967102
- 1.4088000281651816
- 1.4444748369852702
- 1.392576535542806
- 1.4259686994552612
- 1.375709114074707
- 1.36730340162913
- 1.3636279662450155
- 1.3567876307169597
- 1.3464941612879435
- 1.3566840505599975
- 1.374609924952189
- 1.3794886684417724
- 1.366791009902954
- 1.3545810031890868
- 1.3342632643381755
- 1.3173443826039632
- 1.3053589661916096
- 1.2815860716501872
- 1.2986819346745808
- 1.335157798131307
- 1.3218622477849324
- 1.3053578440348308
- 1.3108837032318115
- 1.262442987759908
- 1.2775514245033264
- 1.3090021673838297
- 1.293993124961853
- 1.2559736704826354
- 1.2700606004397075
- 1.2468030087153117
- 1.230140158335368
- 1.2345288316408793
- 1.262004280090332
- 1.2321787810325622
- 1.2533385372161865
- 1.2321669626235963
- 1.2452510611216228
- 1.2286190525690714
- 1.2432337784767151
- 1.2345005679130554
- 1.2031404344240824
- 1.206970313390096
- 1.1904119936625164
- 1.1978565295537313
- 1.1925185585021973
- 1.1724275906880697
- 1.2192655595143636
- 1.182716109752655
- 1.197872990767161
- 1.1474298731486003
- 1.1688780244191488
- 1.1857693163553873
- 1.1738240416844685
- 1.1792234539985658
- 1.1589148712158204
- 1.141461362838745
- 1.1613978743553162
- 1.163580020268758
- 1.1553619925181071
- 1.1236292258898417
- 1.1794035418828328
- 1.1371148244539897
- 1.1395454478263856
- 1.1573391119639078
- 1.1568626753489177
train_accuracy:
- 0.046
- 0.0
- 0.115
- 0.242
- 0.377
- 0.0
- 0.508
- 0.521
- 0.59
- 0.0
- 0.0
- 0.69
- 0.667
- 0.656
- 0.7
- 0.71
- 0.0
- 0.0
- 0.0
- 0.719
- 0.729
- 0.0
- 0.723
- 0.735
- 0.0
- 0.731
- 0.742
- 0.748
- 0.75
- 0.767
- 0.763
- 0.752
- 0.742
- 0.737
- 0.737
- 0.0
- 0.765
- 0.0
- 0.771
- 0.8
- 0.765
- 0.765
- 0.0
- 0.0
- 0.773
- 0.79
- 0.804
- 0.798
- 0.794
- 0.794
- 0.787
- 0.0
- 0.0
- 0.81
- 0.804
- 0.802
- 0.785
- 0.794
- 0.0
- 0.806
- 0.8
- 0.827
- 0.0
- 0.785
- 0.781
- 0.821
- 0.0
- 0.825
- 0.823
- 0.806
- 0.0
- 0.785
- 0.815
- 0.787
- 0.0
- 0.0
- 0.0
- 0.0
- 0.783
- 0.0
- 0.796
- 0.817
- 0.0
- 0.81
- 0.821
- 0.8
- 0.833
- 0.785
- 0.0
- 0.823
- 0.823
- 0.808
- 0.798
- 0.781
- 0.0
- 0.825
- 0.829
- 0.802
- 0.0
- 0.777
train_loss:
- 3.138
- 2.491
- 3.067
- 2.269
- 3.313
- 1.935
- 2.308
- 2.639
- 2.47
- 1.093
- 1.434
- 1.777
- 1.333
- 1.668
- 1.609
- 1.575
- 1.524
- 1.504
- 1.18
- 1.138
- 1.128
- 0.814
- 1.395
- 1.094
- 0.795
- 1.322
- 1.328
- 1.285
- 1.012
- 1.03
- 1.252
- 1.233
- 0.995
- 1.229
- 1.203
- 1.005
- 1.194
- 0.966
- 1.159
- 0.713
- 0.949
- 0.93
- 0.936
- 0.906
- 1.115
- 1.116
- 1.354
- 1.136
- 0.893
- 0.89
- 0.876
- 0.892
- 0.678
- 1.082
- 1.286
- 1.065
- 1.053
- 1.052
- 0.657
- 0.846
- 1.024
- 1.053
- 0.644
- 1.047
- 0.829
- 0.839
- 0.808
- 1.019
- 0.806
- 0.998
- 0.623
- 1.024
- 0.793
- 1.015
- 1.007
- 0.815
- 0.797
- 0.794
- 0.997
- 0.796
- 0.777
- 1.161
- 0.792
- 0.95
- 0.607
- 0.787
- 0.972
- 0.974
- 0.758
- 0.961
- 0.76
- 0.964
- 0.951
- 0.761
- 0.773
- 1.124
- 0.767
- 0.745
- 0.946
- 0.938
unequal: 0
verbose: 1
