avg_train_accuracy: 0.81
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03771276595744681
- 0.06595744680851064
- 0.12840425531914892
- 0.20643617021276595
- 0.3175531914893617
- 0.40824468085106386
- 0.47856382978723405
- 0.5183510638297872
- 0.5478191489361702
- 0.57
- 0.5829787234042553
- 0.5977659574468085
- 0.6098936170212766
- 0.6172340425531915
- 0.6287765957446808
- 0.6324468085106383
- 0.6445744680851064
- 0.6487234042553192
- 0.6559574468085106
- 0.6634574468085106
- 0.6677659574468086
- 0.6698936170212766
- 0.6764361702127659
- 0.6791489361702128
- 0.6860106382978723
- 0.6861702127659575
- 0.69
- 0.6944148936170212
- 0.6957978723404256
- 0.6964893617021276
- 0.7013829787234043
- 0.7035638297872341
- 0.7056914893617021
- 0.7055851063829788
- 0.7098936170212766
- 0.7104255319148937
- 0.7119148936170213
- 0.713936170212766
- 0.7151595744680851
- 0.714627659574468
- 0.7177127659574468
- 0.720531914893617
- 0.7223936170212766
- 0.7252659574468086
- 0.7238829787234042
- 0.7254255319148936
- 0.7272872340425532
- 0.7279255319148936
- 0.7336170212765958
- 0.7304255319148936
- 0.7271276595744681
- 0.731436170212766
- 0.7313829787234043
- 0.7346276595744681
- 0.7370744680851063
- 0.7360106382978724
- 0.7388297872340426
- 0.7387234042553191
- 0.7389893617021277
- 0.7436702127659575
- 0.7406914893617021
- 0.7439893617021277
- 0.7444148936170213
- 0.7479255319148936
- 0.7451063829787234
- 0.7454787234042554
- 0.7476595744680851
- 0.7469148936170212
- 0.7495212765957446
- 0.749468085106383
- 0.7496808510638298
- 0.7498936170212765
- 0.750531914893617
- 0.7519148936170212
- 0.7527127659574468
- 0.7513297872340425
- 0.756968085106383
- 0.7545212765957446
- 0.7582978723404256
- 0.7578191489361702
- 0.757127659574468
- 0.7590425531914894
- 0.7573936170212766
- 0.7584042553191489
- 0.7590425531914894
- 0.7598404255319149
- 0.7560106382978723
- 0.7559574468085106
- 0.7612765957446809
- 0.7600531914893617
- 0.7592553191489362
- 0.7593085106382979
- 0.7593617021276595
- 0.7609574468085106
- 0.7625531914893617
- 0.7641489361702127
- 0.7634042553191489
- 0.7628191489361702
- 0.7654255319148936
- 0.7641489361702127
test_loss_list:
- 3.7830317401885987
- 3.7465714613596597
- 3.6498344230651854
- 3.415257584253947
- 3.0529829851786294
- 2.6794696998596192
- 2.3684868558247882
- 2.1833602444330853
- 2.0356329011917116
- 1.9319448391596477
- 1.8456886879603067
- 1.7900119161605834
- 1.7306297556559245
- 1.6904987732569376
- 1.6573100741704305
- 1.620733036994934
- 1.5834244251251222
- 1.556316164334615
- 1.5394984277089436
- 1.5127593310674032
- 1.4906190967559814
- 1.4577455886205037
- 1.4546691020329794
- 1.4459911346435548
- 1.423904422124227
- 1.3987403837839762
- 1.4044330724080403
- 1.3833073870340984
- 1.3575875234603882
- 1.3629692045847575
- 1.3253828779856365
- 1.345350325902303
- 1.3135081100463868
- 1.305302340189616
- 1.3059247732162476
- 1.312583810488383
- 1.2672767289479574
- 1.3053337128957112
- 1.2929377683003744
- 1.2757051372528077
- 1.2792859522501627
- 1.2423093549410502
- 1.2535998264948527
- 1.254146020412445
- 1.2354609672228496
- 1.2414857522646585
- 1.2594523763656615
- 1.2188469489415488
- 1.209561452070872
- 1.223070498307546
- 1.1827777417500813
- 1.1859127879142761
- 1.1631736493110656
- 1.201053293546041
- 1.1931153464317321
- 1.191720335483551
- 1.1915590397516886
- 1.186143061319987
- 1.1894289382298788
- 1.1735936578114827
- 1.187725384235382
- 1.1539054918289184
- 1.1749303714434305
- 1.165068083604177
- 1.1427184597651163
- 1.1182250253359476
- 1.156527448495229
- 1.1543210220336915
- 1.1319133194287618
- 1.1327021280924479
- 1.1165019234021505
- 1.117065970102946
- 1.1289750933647156
- 1.1132822847366333
- 1.1039374868075054
- 1.1017043256759644
- 1.100273873011271
- 1.0917944264411927
- 1.084419651031494
- 1.0853414273262023
- 1.0815791034698485
- 1.0731983844439188
- 1.1039508239428202
- 1.0979614639282227
- 1.1008244768778483
- 1.1303045813242594
- 1.1003214033444721
- 1.0782849327723185
- 1.1102283175786336
- 1.0971537446975708
- 1.0915925439198813
- 1.0698104294141133
- 1.087912769317627
- 1.090652510325114
- 1.0919012188911439
- 1.113573156197866
- 1.0876555434862774
- 1.1124459942181906
- 1.1230862585703532
- 1.091352562904358
train_accuracy:
- 0.044
- 0.0
- 0.123
- 0.0
- 0.335
- 0.45
- 0.529
- 0.546
- 0.0
- 0.0
- 0.6
- 0.677
- 0.688
- 0.644
- 0.0
- 0.675
- 0.0
- 0.677
- 0.69
- 0.708
- 0.0
- 0.0
- 0.719
- 0.0
- 0.733
- 0.727
- 0.737
- 0.729
- 0.773
- 0.737
- 0.0
- 0.0
- 0.0
- 0.75
- 0.752
- 0.769
- 0.0
- 0.744
- 0.767
- 0.0
- 0.773
- 0.779
- 0.0
- 0.769
- 0.767
- 0.0
- 0.781
- 0.0
- 0.0
- 0.779
- 0.763
- 0.0
- 0.0
- 0.817
- 0.787
- 0.777
- 0.796
- 0.002
- 0.785
- 0.0
- 0.819
- 0.794
- 0.796
- 0.825
- 0.0
- 0.0
- 0.823
- 0.8
- 0.004
- 0.0
- 0.0
- 0.833
- 0.831
- 0.783
- 0.0
- 0.808
- 0.81
- 0.0
- 0.829
- 0.017
- 0.817
- 0.8
- 0.833
- 0.831
- 0.833
- 0.817
- 0.0
- 0.0
- 0.808
- 0.815
- 0.844
- 0.806
- 0.823
- 0.808
- 0.833
- 0.819
- 0.0
- 0.817
- 0.819
- 0.81
train_loss:
- 3.175
- 3.158
- 2.43
- 2.961
- 2.765
- 2.517
- 1.758
- 2.114
- 1.518
- 1.446
- 1.389
- 1.703
- 1.282
- 0.9
- 1.229
- 1.179
- 1.171
- 1.14
- 1.423
- 1.112
- 1.081
- 0.786
- 1.332
- 1.305
- 1.301
- 1.013
- 1.267
- 1.244
- 0.965
- 0.971
- 0.955
- 1.207
- 0.933
- 0.92
- 1.159
- 1.147
- 0.665
- 1.37
- 1.129
- 0.889
- 1.115
- 0.644
- 1.087
- 1.083
- 0.868
- 1.068
- 1.279
- 0.855
- 0.827
- 1.04
- 0.618
- 0.834
- 0.607
- 1.225
- 1.014
- 1.011
- 1.013
- 1.003
- 1.009
- 0.798
- 0.988
- 0.791
- 0.988
- 0.98
- 0.585
- 0.572
- 1.167
- 0.974
- 0.778
- 0.751
- 0.766
- 0.949
- 0.945
- 0.76
- 0.748
- 0.741
- 0.94
- 0.741
- 0.75
- 0.729
- 0.736
- 0.73
- 1.104
- 0.92
- 0.915
- 1.103
- 0.727
- 0.722
- 1.089
- 0.905
- 0.896
- 0.721
- 0.89
- 0.905
- 0.885
- 1.071
- 0.71
- 1.075
- 1.065
- 0.884
unequal: 0
verbose: 1
