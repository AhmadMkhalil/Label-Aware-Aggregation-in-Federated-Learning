avg_train_accuracy: 0.821
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04441489361702128
- 0.06388297872340426
- 0.105
- 0.18946808510638297
- 0.3126063829787234
- 0.3873936170212766
- 0.42398936170212764
- 0.4600531914893617
- 0.48734042553191487
- 0.5196276595744681
- 0.5363297872340426
- 0.5543085106382979
- 0.5714361702127659
- 0.5787765957446809
- 0.5952659574468085
- 0.6040425531914894
- 0.6108510638297873
- 0.6186170212765958
- 0.6193617021276596
- 0.6264893617021277
- 0.6375531914893617
- 0.639468085106383
- 0.6484042553191489
- 0.651436170212766
- 0.6541489361702127
- 0.6570744680851064
- 0.6612234042553191
- 0.6650531914893617
- 0.6721276595744681
- 0.6754787234042553
- 0.676968085106383
- 0.6782978723404255
- 0.6845212765957447
- 0.685531914893617
- 0.6924468085106383
- 0.6917553191489362
- 0.695
- 0.7002659574468085
- 0.700531914893617
- 0.6970744680851064
- 0.6986702127659574
- 0.705
- 0.7042021276595745
- 0.7065957446808511
- 0.7103191489361702
- 0.708936170212766
- 0.713404255319149
- 0.7126595744680851
- 0.7177127659574468
- 0.7175
- 0.7197340425531915
- 0.7238297872340426
- 0.7217021276595744
- 0.7226595744680852
- 0.7258510638297873
- 0.7273936170212766
- 0.7259042553191489
- 0.7278191489361702
- 0.7296808510638297
- 0.7328191489361702
- 0.7334574468085107
- 0.7322340425531915
- 0.7325
- 0.7339893617021277
- 0.7349468085106383
- 0.7352127659574468
- 0.7369148936170212
- 0.7375
- 0.7365425531914893
- 0.7363829787234043
- 0.7402659574468086
- 0.7367553191489362
- 0.7408510638297873
- 0.7402127659574468
- 0.7407978723404255
- 0.7429787234042553
- 0.7438829787234043
- 0.7456382978723404
- 0.7453191489361702
- 0.7430851063829788
- 0.7450531914893617
- 0.7470212765957447
- 0.7453723404255319
- 0.7469148936170212
- 0.7479255319148936
- 0.747872340425532
- 0.7487765957446808
- 0.7494148936170213
- 0.7482446808510639
- 0.749095744680851
- 0.7510106382978723
- 0.7499468085106383
- 0.7505851063829787
- 0.7514893617021277
- 0.7522872340425532
- 0.7510106382978723
- 0.7525531914893617
- 0.7552659574468085
- 0.7532446808510638
- 0.7529255319148936
test_loss_list:
- 3.783036985397339
- 3.737652006149292
- 3.6250017420450846
- 3.3608587392171225
- 3.035717102686564
- 2.773887357711792
- 2.564439760843913
- 2.436917448043823
- 2.3209146817525226
- 2.2291619412104287
- 2.161337138811747
- 2.0946932776769
- 2.0626816956202187
- 1.9954034773508709
- 1.9769039996465048
- 1.916647965113322
- 1.874197513262431
- 1.8651906490325927
- 1.8199862480163573
- 1.78544953028361
- 1.770815315246582
- 1.7183772071202597
- 1.725995054244995
- 1.6963568433125813
- 1.7037058607737223
- 1.656331246693929
- 1.6254360882441203
- 1.6068049462636311
- 1.6177888615926106
- 1.5963807996114094
- 1.5687713845570883
- 1.547223604520162
- 1.5525276041030884
- 1.5464398543039957
- 1.545634617805481
- 1.531071008046468
- 1.4833513927459716
- 1.5041660038630167
- 1.4784167989095052
- 1.4813639704386394
- 1.4573004134496053
- 1.451023645401001
- 1.447800259590149
- 1.4065887053807578
- 1.4077267058690388
- 1.4009128141403198
- 1.3679106473922729
- 1.3807298390070597
- 1.4086612176895141
- 1.3660318803787233
- 1.3638655376434325
- 1.3374460538228352
- 1.3619168249766032
- 1.3298905022939047
- 1.3596791474024454
- 1.3249165121714275
- 1.3277164300282795
- 1.3273799403508504
- 1.315642517407735
- 1.315024863878886
- 1.3407257572809854
- 1.324312580426534
- 1.3401121139526366
- 1.3443783982594808
- 1.3382461897532145
- 1.3242458931605021
- 1.2982502794265747
- 1.2885270531972248
- 1.3073674933115642
- 1.2617161083221435
- 1.3095590702692668
- 1.2732678294181823
- 1.2737420058250428
- 1.261729854742686
- 1.2674116237958273
- 1.2536957796414694
- 1.2363884957631428
- 1.2382848397890727
- 1.2077346301078797
- 1.2338570022583009
- 1.2358391896883647
- 1.2159821407000224
- 1.1928618812561036
- 1.2036228076616924
- 1.1760037755966186
- 1.1666682155927022
- 1.1579978704452514
- 1.1705243865648904
- 1.1666340470314025
- 1.1247378039360045
- 1.150614356994629
- 1.1600345849990845
- 1.1783342838287354
- 1.143619998296102
- 1.1651721707979839
- 1.159377675851186
- 1.151988247235616
- 1.1608027044932048
- 1.1565603105227154
- 1.1610952321688335
train_accuracy:
- 0.0
- 0.075
- 0.129
- 0.217
- 0.0
- 0.419
- 0.442
- 0.519
- 0.506
- 0.577
- 0.615
- 0.625
- 0.633
- 0.638
- 0.665
- 0.648
- 0.0
- 0.671
- 0.0
- 0.0
- 0.706
- 0.673
- 0.721
- 0.719
- 0.723
- 0.0
- 0.74
- 0.74
- 0.723
- 0.729
- 0.758
- 0.0
- 0.733
- 0.76
- 0.758
- 0.721
- 0.748
- 0.758
- 0.0
- 0.0
- 0.737
- 0.758
- 0.0
- 0.0
- 0.775
- 0.758
- 0.0
- 0.798
- 0.79
- 0.0
- 0.767
- 0.769
- 0.798
- 0.787
- 0.8
- 0.787
- 0.79
- 0.0
- 0.792
- 0.773
- 0.8
- 0.0
- 0.804
- 0.804
- 0.802
- 0.808
- 0.0
- 0.798
- 0.0
- 0.794
- 0.794
- 0.8
- 0.79
- 0.79
- 0.0
- 0.808
- 0.0
- 0.8
- 0.806
- 0.794
- 0.0
- 0.0
- 0.0
- 0.827
- 0.819
- 0.0
- 0.0
- 0.819
- 0.831
- 0.0
- 0.833
- 0.81
- 0.806
- 0.821
- 0.8
- 0.804
- 0.0
- 0.0
- 0.0
- 0.821
train_loss:
- 2.48
- 3.126
- 3.06
- 1.615
- 2.095
- 1.92
- 1.79
- 2.202
- 1.62
- 1.986
- 1.92
- 1.445
- 2.185
- 1.384
- 1.706
- 1.66
- 1.288
- 1.581
- 0.898
- 0.89
- 1.521
- 0.856
- 1.445
- 1.438
- 1.407
- 1.124
- 1.102
- 1.094
- 1.34
- 1.328
- 1.053
- 1.051
- 1.333
- 1.268
- 1.535
- 1.269
- 1.014
- 1.244
- 0.986
- 0.96
- 0.975
- 1.205
- 1.197
- 0.718
- 0.933
- 0.929
- 0.943
- 1.16
- 1.377
- 0.926
- 0.906
- 0.917
- 1.129
- 1.125
- 1.329
- 0.871
- 0.878
- 1.1
- 1.094
- 1.084
- 1.286
- 1.06
- 1.285
- 1.269
- 1.277
- 1.053
- 0.853
- 0.85
- 1.043
- 0.85
- 1.235
- 0.838
- 1.035
- 0.809
- 1.04
- 1.021
- 0.812
- 1.028
- 0.812
- 1.003
- 1.021
- 0.812
- 0.6
- 0.79
- 0.785
- 0.79
- 0.775
- 0.987
- 0.785
- 0.593
- 0.968
- 0.972
- 1.148
- 0.771
- 0.96
- 0.951
- 0.94
- 0.958
- 0.763
- 0.943
unequal: 0
verbose: 1
