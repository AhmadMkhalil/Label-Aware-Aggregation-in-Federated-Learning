avg_train_accuracy: 0.808
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.025159574468085106
- 0.055
- 0.11457446808510638
- 0.22946808510638297
- 0.3406382978723404
- 0.4179787234042553
- 0.4628191489361702
- 0.504468085106383
- 0.5186702127659575
- 0.5428723404255319
- 0.5677127659574468
- 0.5797872340425532
- 0.5891489361702128
- 0.6019148936170213
- 0.6148404255319149
- 0.6229787234042553
- 0.6268085106382979
- 0.6376595744680851
- 0.6416489361702128
- 0.6506914893617022
- 0.6605851063829787
- 0.6640957446808511
- 0.6693085106382979
- 0.6736702127659574
- 0.6757978723404255
- 0.6846808510638298
- 0.6874468085106383
- 0.6851595744680851
- 0.691968085106383
- 0.6968085106382979
- 0.699468085106383
- 0.699840425531915
- 0.7006914893617021
- 0.7062234042553192
- 0.706968085106383
- 0.7106914893617021
- 0.7120744680851064
- 0.716063829787234
- 0.7135638297872341
- 0.7138829787234042
- 0.7165425531914894
- 0.7187765957446809
- 0.7215957446808511
- 0.721063829787234
- 0.7228191489361702
- 0.7238829787234042
- 0.7259042553191489
- 0.725
- 0.731436170212766
- 0.7332978723404255
- 0.7312765957446808
- 0.733563829787234
- 0.7349468085106383
- 0.7361170212765957
- 0.7381382978723404
- 0.7383510638297872
- 0.7400531914893617
- 0.7389361702127659
- 0.739468085106383
- 0.7412234042553192
- 0.7417553191489362
- 0.7422340425531915
- 0.7453723404255319
- 0.7476063829787234
- 0.7448936170212765
- 0.7470212765957447
- 0.7453723404255319
- 0.7471808510638298
- 0.7487765957446808
- 0.7489361702127659
- 0.7499468085106383
- 0.7516489361702128
- 0.7500531914893617
- 0.7521808510638298
- 0.7532978723404256
- 0.7534574468085107
- 0.7550531914893617
- 0.7557446808510638
- 0.7562765957446809
- 0.7571808510638298
- 0.7545212765957446
- 0.7551063829787235
- 0.7559574468085106
- 0.7579255319148936
- 0.7565957446808511
- 0.7600531914893617
- 0.7566489361702128
- 0.7593617021276595
- 0.7591489361702127
- 0.7607978723404255
- 0.7613297872340425
- 0.7601063829787233
- 0.760531914893617
- 0.7595744680851064
- 0.7586170212765957
- 0.7614893617021277
- 0.7610106382978723
- 0.7641489361702127
- 0.7625531914893617
- 0.7629787234042553
test_loss_list:
- 3.7809656715393065
- 3.743361727396647
- 3.6475226338704427
- 3.38624267578125
- 3.0001008764902752
- 2.670900494257609
- 2.4355612246195477
- 2.2648143132527667
- 2.167839345932007
- 2.045283497174581
- 2.0015959533055625
- 1.9569540850321452
- 1.8962099011739095
- 1.8526817735036214
- 1.8068026781082154
- 1.7628771225611368
- 1.7428230508168538
- 1.6990201489130656
- 1.6825365495681763
- 1.6353598642349243
- 1.6530115032196044
- 1.6329789606730143
- 1.5930945491790771
- 1.589516650835673
- 1.5697553825378419
- 1.577644149462382
- 1.5534908119837443
- 1.4929293823242187
- 1.4975607299804687
- 1.4868911759058634
- 1.4638431406021117
- 1.4347393051783244
- 1.422840272585551
- 1.3992946020762125
- 1.3869122234980265
- 1.4124584372838338
- 1.3886101293563842
- 1.402868585586548
- 1.3858766110738119
- 1.3487751547495523
- 1.3555816904703777
- 1.329575252532959
- 1.3624407450358074
- 1.340926316579183
- 1.3377084096272787
- 1.284035382270813
- 1.2961202891667685
- 1.277025043964386
- 1.282977364063263
- 1.2611896689732869
- 1.2599286278088888
- 1.2751977237065633
- 1.264260283311208
- 1.2406947573026021
- 1.258536152044932
- 1.2317376931508381
- 1.253818473815918
- 1.232733562787374
- 1.2217056091626486
- 1.2018260717391969
- 1.2143793773651124
- 1.2009705154101054
- 1.2082200972239177
- 1.2088189419110615
- 1.1925907786687215
- 1.1891691064834595
- 1.172889638741811
- 1.1868264253934224
- 1.171231263478597
- 1.1935713561375936
- 1.1801408036549885
- 1.1640528758366904
- 1.1634838445981344
- 1.1809141802787781
- 1.1761461480458577
- 1.1460527642567953
- 1.1689230052630106
- 1.1667859228452047
- 1.1617460608482362
- 1.1575969139734903
- 1.1242293850580851
- 1.1421245002746583
- 1.143820469379425
- 1.1429043674468995
- 1.1368881416320802
- 1.1363731447855632
- 1.1132392223676046
- 1.1116831668217977
- 1.1306993214289347
- 1.1261597458521526
- 1.1384158658981323
- 1.1372452219327291
- 1.1309955867131551
- 1.1100266591707866
- 1.1016724975903829
- 1.1356696772575379
- 1.0945998708407083
- 1.107550080617269
- 1.1299396642049153
- 1.1403069631258647
train_accuracy:
- 0.021
- 0.048
- 0.113
- 0.208
- 0.365
- 0.481
- 0.494
- 0.0
- 0.0
- 0.0
- 0.612
- 0.61
- 0.0
- 0.0
- 0.679
- 0.696
- 0.669
- 0.656
- 0.0
- 0.688
- 0.725
- 0.671
- 0.698
- 0.729
- 0.0
- 0.713
- 0.683
- 0.0
- 0.756
- 0.0
- 0.769
- 0.702
- 0.0
- 0.775
- 0.779
- 0.787
- 0.733
- 0.0
- 0.742
- 0.785
- 0.756
- 0.735
- 0.808
- 0.796
- 0.8
- 0.765
- 0.0
- 0.0
- 0.796
- 0.763
- 0.804
- 0.0
- 0.0
- 0.8
- 0.763
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.765
- 0.815
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.817
- 0.779
- 0.79
- 0.804
- 0.804
- 0.0
- 0.806
- 0.0
- 0.829
- 0.817
- 0.0
- 0.0
- 0.79
- 0.0
- 0.815
- 0.796
- 0.796
- 0.0
- 0.829
- 0.0
- 0.823
- 0.827
- 0.831
- 0.802
- 0.815
- 0.794
- 0.0
- 0.804
- 0.821
- 0.829
- 0.829
- 0.825
- 0.808
train_loss:
- 2.454
- 3.129
- 2.383
- 1.611
- 2.707
- 2.448
- 2.251
- 1.621
- 1.077
- 1.456
- 1.827
- 1.766
- 1.334
- 1.697
- 1.622
- 1.27
- 1.213
- 1.544
- 1.186
- 1.181
- 1.763
- 1.425
- 1.419
- 1.393
- 1.346
- 1.631
- 1.338
- 0.782
- 1.288
- 1.024
- 1.283
- 1.001
- 1.001
- 0.99
- 0.978
- 1.211
- 1.208
- 1.175
- 1.196
- 0.707
- 1.16
- 0.925
- 1.381
- 1.154
- 0.904
- 0.678
- 0.904
- 0.877
- 1.119
- 0.879
- 0.882
- 1.092
- 1.081
- 0.852
- 1.061
- 0.864
- 1.072
- 0.827
- 1.067
- 0.837
- 0.816
- 0.822
- 1.042
- 1.018
- 0.803
- 1.01
- 0.827
- 0.801
- 1.019
- 0.991
- 1.006
- 0.792
- 0.802
- 0.988
- 0.975
- 0.795
- 0.978
- 0.964
- 0.976
- 0.792
- 0.781
- 0.757
- 0.964
- 0.953
- 0.775
- 0.948
- 0.562
- 0.942
- 0.938
- 0.951
- 0.949
- 0.939
- 0.955
- 0.762
- 0.761
- 1.112
- 0.757
- 0.922
- 0.918
- 1.104
unequal: 0
verbose: 1
