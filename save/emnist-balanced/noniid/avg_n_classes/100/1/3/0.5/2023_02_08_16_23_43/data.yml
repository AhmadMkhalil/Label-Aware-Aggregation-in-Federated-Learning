avg_train_accuracy: 0.802
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027606382978723403
- 0.051382978723404256
- 0.1424468085106383
- 0.25930851063829785
- 0.3727659574468085
- 0.44361702127659575
- 0.4790957446808511
- 0.5137765957446808
- 0.5377127659574468
- 0.5540425531914893
- 0.5759574468085107
- 0.5865425531914894
- 0.5990425531914894
- 0.6065957446808511
- 0.6177127659574468
- 0.6269148936170212
- 0.6323404255319149
- 0.6372872340425532
- 0.6426595744680851
- 0.6523404255319148
- 0.6578723404255319
- 0.661063829787234
- 0.6650531914893617
- 0.6706914893617021
- 0.6732978723404255
- 0.6731382978723405
- 0.681968085106383
- 0.683404255319149
- 0.6885638297872341
- 0.6905851063829788
- 0.6946808510638298
- 0.6948404255319149
- 0.6989893617021277
- 0.7008510638297872
- 0.7036170212765958
- 0.7054255319148937
- 0.7070212765957447
- 0.7047340425531915
- 0.711968085106383
- 0.7143085106382979
- 0.714627659574468
- 0.7159574468085106
- 0.7194148936170213
- 0.7196276595744681
- 0.7204787234042553
- 0.724095744680851
- 0.7216489361702128
- 0.7239361702127659
- 0.7256914893617021
- 0.7278191489361702
- 0.7287765957446809
- 0.7293085106382978
- 0.729095744680851
- 0.7323936170212766
- 0.7340425531914894
- 0.7325
- 0.733563829787234
- 0.734095744680851
- 0.7351063829787234
- 0.7356382978723405
- 0.735531914893617
- 0.7386170212765958
- 0.7375
- 0.7377659574468085
- 0.7412765957446809
- 0.7409042553191489
- 0.7400531914893617
- 0.7406382978723405
- 0.7429255319148936
- 0.7409574468085106
- 0.7460106382978723
- 0.7467021276595744
- 0.7446808510638298
- 0.746968085106383
- 0.7457978723404255
- 0.7470744680851064
- 0.7470744680851064
- 0.7492553191489362
- 0.7497872340425532
- 0.7469148936170212
- 0.7479255319148936
- 0.749468085106383
- 0.7500531914893617
- 0.7494148936170213
- 0.7500531914893617
- 0.7498404255319149
- 0.7512234042553192
- 0.7510106382978723
- 0.7518617021276596
- 0.752127659574468
- 0.7528191489361702
- 0.7539893617021277
- 0.7527127659574468
- 0.7536170212765958
- 0.7560106382978723
- 0.7536170212765958
- 0.7561702127659574
- 0.7539361702127659
- 0.7573936170212766
- 0.7578191489361702
test_loss_list:
- 3.783462645212809
- 3.7453071753184
- 3.6178643894195557
- 3.306889746983846
- 2.9244888655344643
- 2.6161308765411375
- 2.386672773361206
- 2.241896181106567
- 2.116556404431661
- 2.030261368751526
- 1.9599842898050943
- 1.8901425123214721
- 1.8438076273600261
- 1.802861475944519
- 1.7670189174016318
- 1.7388487148284912
- 1.699239020347595
- 1.654747192064921
- 1.6324449809392294
- 1.605326590538025
- 1.5891332991917928
- 1.5744269514083862
- 1.5579137674967447
- 1.5560170269012452
- 1.5453422514597575
- 1.513587818145752
- 1.4923474248250326
- 1.4977596028645834
- 1.4848103920618694
- 1.460467300415039
- 1.445555804570516
- 1.451852814356486
- 1.4319717741012574
- 1.4139111264546713
- 1.4191037273406983
- 1.4290003983179729
- 1.4139740165074666
- 1.3694453763961791
- 1.3622657680511474
- 1.3694251680374145
- 1.3461133495966593
- 1.36734934647878
- 1.3577184708913168
- 1.3460897095998128
- 1.3439192183812458
- 1.334373517036438
- 1.3404434140523274
- 1.3455881436665853
- 1.32636478583018
- 1.3273460578918457
- 1.3034799337387084
- 1.3281970755259196
- 1.3007364511489867
- 1.2944615761439004
- 1.2908470304807027
- 1.284777084986369
- 1.2859913714726765
- 1.2652362132072448
- 1.274943417708079
- 1.264714860121409
- 1.2224887681007386
- 1.2112929034233093
- 1.2163420248031616
- 1.2243827533721925
- 1.211453516483307
- 1.2361390908559164
- 1.2267387493451436
- 1.1965407474835714
- 1.1752720101674399
- 1.1834444244702658
- 1.1613167635599773
- 1.1780618023872376
- 1.1849861685434977
- 1.2012386878331502
- 1.1673710775375366
- 1.1469392426808676
- 1.142784942785899
- 1.1453462076187133
- 1.1511041267712911
- 1.1296648693084717
- 1.1323500339190165
- 1.112098507086436
- 1.1106055879592895
- 1.09120752175649
- 1.1287798062960306
- 1.1245775588353475
- 1.1075350554784138
- 1.1205886785189312
- 1.1196133502324421
- 1.1107631635665893
- 1.098633681933085
- 1.092117255528768
- 1.1082181819279988
- 1.0982789580027263
- 1.0984048334757488
- 1.106707513332367
- 1.0983235875765482
- 1.1013846023877463
- 1.1093042254447938
- 1.0986183563868204
train_accuracy:
- 0.029
- 0.056
- 0.15
- 0.258
- 0.417
- 0.4
- 0.0
- 0.535
- 0.54
- 0.0
- 0.619
- 0.604
- 0.0
- 0.621
- 0.644
- 0.679
- 0.679
- 0.0
- 0.0
- 0.713
- 0.0
- 0.0
- 0.713
- 0.725
- 0.717
- 0.0
- 0.0
- 0.725
- 0.733
- 0.0
- 0.735
- 0.754
- 0.735
- 0.756
- 0.754
- 0.802
- 0.798
- 0.756
- 0.0
- 0.0
- 0.792
- 0.785
- 0.763
- 0.773
- 0.783
- 0.765
- 0.769
- 0.783
- 0.796
- 0.804
- 0.821
- 0.8
- 0.0
- 0.0
- 0.783
- 0.0
- 0.777
- 0.808
- 0.785
- 0.823
- 0.0
- 0.777
- 0.0
- 0.819
- 0.0
- 0.806
- 0.806
- 0.0
- 0.794
- 0.787
- 0.0
- 0.833
- 0.817
- 0.831
- 0.0
- 0.8
- 0.829
- 0.787
- 0.0
- 0.796
- 0.821
- 0.0
- 0.0
- 0.0
- 0.817
- 0.802
- 0.0
- 0.81
- 0.796
- 0.838
- 0.0
- 0.0
- 0.798
- 0.808
- 0.804
- 0.0
- 0.804
- 0.8
- 0.0
- 0.802
train_loss:
- 2.432
- 3.128
- 3.747
- 2.269
- 2.677
- 2.448
- 1.252
- 2.128
- 2.012
- 1.483
- 2.243
- 1.411
- 1.364
- 1.316
- 1.269
- 1.264
- 1.232
- 0.891
- 0.871
- 1.177
- 1.148
- 1.414
- 1.122
- 1.668
- 1.365
- 1.076
- 1.063
- 1.312
- 1.307
- 1.03
- 1.027
- 1.268
- 1.254
- 1.001
- 1.23
- 1.459
- 1.213
- 0.739
- 0.952
- 1.187
- 0.94
- 1.398
- 1.169
- 1.15
- 1.141
- 1.127
- 1.141
- 1.349
- 1.136
- 1.117
- 0.894
- 1.317
- 0.89
- 1.085
- 0.876
- 1.078
- 1.066
- 0.864
- 1.083
- 1.049
- 0.652
- 0.64
- 0.834
- 1.031
- 0.84
- 1.237
- 1.017
- 0.815
- 0.819
- 0.808
- 0.616
- 1.017
- 1.003
- 1.209
- 0.807
- 0.793
- 0.782
- 0.77
- 0.993
- 0.777
- 0.778
- 0.579
- 0.759
- 0.564
- 1.168
- 0.97
- 0.791
- 0.968
- 0.96
- 0.951
- 0.765
- 0.766
- 0.946
- 0.944
- 0.938
- 0.923
- 0.932
- 0.923
- 0.93
- 0.758
unequal: 0
verbose: 1
