avg_train_accuracy: 0.815
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027340425531914892
- 0.05446808510638298
- 0.1201063829787234
- 0.18723404255319148
- 0.289468085106383
- 0.37968085106382976
- 0.46085106382978724
- 0.49803191489361703
- 0.5293085106382979
- 0.556968085106383
- 0.5720744680851064
- 0.5951595744680851
- 0.6033510638297872
- 0.6151063829787234
- 0.6236170212765958
- 0.6356914893617022
- 0.644468085106383
- 0.6512234042553191
- 0.6554787234042553
- 0.6618085106382978
- 0.6670744680851064
- 0.6735638297872341
- 0.6766489361702127
- 0.6818617021276596
- 0.6832446808510638
- 0.6883510638297873
- 0.6924468085106383
- 0.6967021276595745
- 0.6979255319148936
- 0.7026595744680851
- 0.6986702127659574
- 0.7050531914893617
- 0.7052127659574469
- 0.7089893617021277
- 0.7129255319148936
- 0.7138829787234042
- 0.7143085106382979
- 0.7140425531914893
- 0.7152127659574468
- 0.7179787234042553
- 0.7209574468085106
- 0.7225
- 0.7237765957446809
- 0.7243617021276596
- 0.729468085106383
- 0.7263829787234043
- 0.7251063829787234
- 0.7281914893617021
- 0.7303723404255319
- 0.7288829787234042
- 0.7300531914893617
- 0.7331914893617021
- 0.7348404255319149
- 0.7352659574468086
- 0.734468085106383
- 0.7351063829787234
- 0.7370744680851063
- 0.7360106382978724
- 0.7379787234042553
- 0.738563829787234
- 0.7403723404255319
- 0.7400531914893617
- 0.7420212765957447
- 0.7417021276595744
- 0.743031914893617
- 0.7421808510638298
- 0.7438297872340426
- 0.7431382978723404
- 0.7447340425531915
- 0.7445212765957446
- 0.7445744680851064
- 0.7440425531914894
- 0.7449468085106383
- 0.7468617021276596
- 0.7438297872340426
- 0.7476595744680851
- 0.7496276595744681
- 0.7468085106382979
- 0.7473404255319149
- 0.7491489361702127
- 0.7505851063829787
- 0.7517553191489361
- 0.7506914893617022
- 0.7514893617021277
- 0.750904255319149
- 0.7500531914893617
- 0.7520744680851064
- 0.7542021276595745
- 0.7527659574468085
- 0.7531914893617021
- 0.7545212765957446
- 0.756968085106383
- 0.755
- 0.755904255319149
- 0.7549468085106383
- 0.7553191489361702
- 0.7556382978723404
- 0.7573936170212766
- 0.7573404255319149
- 0.7543085106382978
test_loss_list:
- 3.789109163284302
- 3.760496155420939
- 3.685719769795736
- 3.482991720835368
- 3.1261811033884683
- 2.782046012878418
- 2.495768845876058
- 2.291141637166341
- 2.1315287510553995
- 2.0260703070958455
- 1.9468486658732096
- 1.8786174392700195
- 1.8337401008605958
- 1.7934079424540201
- 1.762538873354594
- 1.7157350158691407
- 1.6975954484939575
- 1.6707326173782349
- 1.6604667822519938
- 1.608421417872111
- 1.5958503103256225
- 1.594072750409444
- 1.54697772026062
- 1.551781260172526
- 1.5417485109965006
- 1.5005116478602092
- 1.5078882201512656
- 1.504471435546875
- 1.4787169869740804
- 1.46693039894104
- 1.4273378149668376
- 1.4504352219899495
- 1.4122034851710001
- 1.4107099262873333
- 1.3922564284006755
- 1.3951084327697754
- 1.3958434041341146
- 1.3687689367930094
- 1.3371163813273113
- 1.3528426297505696
- 1.3572230529785156
- 1.343119428952535
- 1.354518904685974
- 1.3287004137039184
- 1.3408351421356202
- 1.331902372042338
- 1.3081329981486003
- 1.288050537109375
- 1.292250280380249
- 1.2905224355061848
- 1.3097512706120809
- 1.290438110033671
- 1.2971890687942504
- 1.2902067470550538
- 1.2680845499038695
- 1.2708930412928263
- 1.2715508087476095
- 1.258930472532908
- 1.2630562202135722
- 1.2856171782811483
- 1.3030620034535725
- 1.268117019335429
- 1.285462776819865
- 1.273593823115031
- 1.2658791438738506
- 1.2856492519378662
- 1.2515881903966268
- 1.2582212980588277
- 1.2593761038780213
- 1.2649576099713644
- 1.2377579871813456
- 1.2325687638918559
- 1.234485194683075
- 1.253862799803416
- 1.2183116443951925
- 1.2164786346753438
- 1.226014633178711
- 1.2278062510490417
- 1.2237964924176534
- 1.2326042262713115
- 1.2267558550834656
- 1.2296026428540547
- 1.2479736471176148
- 1.230372519493103
- 1.222905125617981
- 1.2045511881510416
- 1.2191815058390298
- 1.2063014515240986
- 1.216487709681193
- 1.20915811697642
- 1.2121089990933736
- 1.1851287659009297
- 1.199156993230184
- 1.220573876698812
- 1.2101032463709513
- 1.2103939231236776
- 1.1921715060869853
- 1.1973329671223958
- 1.2021614416440327
- 1.176777712504069
train_accuracy:
- 0.0
- 0.04
- 0.0
- 0.192
- 0.306
- 0.0
- 0.0
- 0.542
- 0.596
- 0.627
- 0.631
- 0.631
- 0.681
- 0.685
- 0.0
- 0.694
- 0.679
- 0.681
- 0.719
- 0.0
- 0.729
- 0.769
- 0.696
- 0.775
- 0.729
- 0.775
- 0.742
- 0.721
- 0.713
- 0.76
- 0.0
- 0.773
- 0.804
- 0.769
- 0.0
- 0.0
- 0.0
- 0.752
- 0.0
- 0.773
- 0.771
- 0.752
- 0.765
- 0.812
- 0.763
- 0.781
- 0.0
- 0.0
- 0.775
- 0.0
- 0.787
- 0.785
- 0.783
- 0.785
- 0.783
- 0.777
- 0.817
- 0.821
- 0.781
- 0.817
- 0.79
- 0.8
- 0.821
- 0.792
- 0.0
- 0.8
- 0.829
- 0.775
- 0.779
- 0.823
- 0.0
- 0.838
- 0.0
- 0.838
- 0.8
- 0.8
- 0.802
- 0.806
- 0.846
- 0.0
- 0.835
- 0.0
- 0.819
- 0.804
- 0.0
- 0.812
- 0.815
- 0.798
- 0.0
- 0.0
- 0.0
- 0.0
- 0.842
- 0.819
- 0.808
- 0.792
- 0.856
- 0.846
- 0.794
- 0.815
train_loss:
- 2.49
- 2.521
- 3.097
- 3.024
- 2.18
- 1.975
- 2.343
- 1.685
- 1.119
- 1.918
- 1.425
- 2.136
- 1.678
- 1.625
- 1.579
- 1.542
- 1.832
- 1.475
- 1.451
- 0.842
- 1.127
- 1.378
- 0.801
- 1.35
- 1.338
- 0.775
- 1.311
- 1.272
- 0.746
- 1.258
- 0.737
- 1.222
- 0.979
- 0.956
- 0.972
- 0.951
- 0.929
- 0.93
- 0.686
- 0.911
- 1.155
- 0.907
- 1.125
- 0.911
- 1.106
- 0.877
- 0.884
- 0.668
- 0.863
- 0.868
- 1.318
- 1.081
- 1.074
- 1.068
- 0.852
- 0.839
- 1.067
- 0.847
- 1.061
- 1.256
- 1.241
- 0.844
- 1.024
- 1.033
- 1.039
- 1.22
- 0.833
- 1.025
- 1.013
- 1.009
- 0.807
- 1.009
- 0.999
- 1.004
- 0.807
- 0.802
- 1.003
- 0.991
- 0.784
- 0.976
- 0.98
- 0.982
- 1.149
- 0.99
- 0.961
- 0.789
- 0.968
- 0.957
- 0.961
- 0.966
- 0.947
- 0.778
- 0.939
- 1.115
- 0.951
- 0.954
- 0.761
- 0.946
- 0.935
- 0.759
unequal: 0
verbose: 1
