avg_train_accuracy: 0.842
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.028404255319148936
- 0.055212765957446806
- 0.12111702127659575
- 0.22739361702127658
- 0.3545744680851064
- 0.4378191489361702
- 0.48090425531914893
- 0.5178191489361702
- 0.538563829787234
- 0.5588829787234042
- 0.5737765957446809
- 0.589095744680851
- 0.6013829787234043
- 0.611436170212766
- 0.6202659574468085
- 0.6332446808510638
- 0.6394148936170213
- 0.6473404255319148
- 0.6549468085106382
- 0.6604787234042553
- 0.6678723404255319
- 0.6736702127659574
- 0.6794148936170212
- 0.6834574468085106
- 0.6861170212765958
- 0.6907978723404256
- 0.6952127659574469
- 0.6957978723404256
- 0.7002127659574469
- 0.7035638297872341
- 0.7059042553191489
- 0.7087765957446809
- 0.7101063829787234
- 0.7120744680851064
- 0.7155851063829787
- 0.7176595744680851
- 0.7180851063829787
- 0.7200531914893618
- 0.7230319148936171
- 0.7242021276595745
- 0.7254787234042553
- 0.7272872340425532
- 0.7282978723404255
- 0.7291489361702128
- 0.7307978723404255
- 0.7331914893617021
- 0.735
- 0.7357446808510638
- 0.7368617021276596
- 0.7384042553191489
- 0.7408510638297873
- 0.7403723404255319
- 0.7396276595744681
- 0.743031914893617
- 0.7428191489361702
- 0.743563829787234
- 0.744095744680851
- 0.7439893617021277
- 0.7433510638297872
- 0.7463829787234042
- 0.7450531914893617
- 0.748031914893617
- 0.7498936170212765
- 0.749468085106383
- 0.750904255319149
- 0.7508510638297873
- 0.7507446808510638
- 0.7529255319148936
- 0.7526595744680851
- 0.7527659574468085
- 0.7545744680851064
- 0.7547340425531915
- 0.7563829787234042
- 0.755531914893617
- 0.7545744680851064
- 0.7550531914893617
- 0.7564893617021277
- 0.7586170212765957
- 0.7593085106382979
- 0.758031914893617
- 0.7586702127659575
- 0.7596276595744681
- 0.7618617021276596
- 0.7613297872340425
- 0.7610106382978723
- 0.7604255319148936
- 0.762127659574468
- 0.7631382978723404
- 0.763031914893617
- 0.760904255319149
- 0.7629255319148937
- 0.7626595744680851
- 0.7643617021276595
- 0.7633510638297872
- 0.7631382978723404
- 0.7660638297872341
- 0.7658510638297872
- 0.765531914893617
- 0.7654787234042553
- 0.7651595744680851
test_loss_list:
- 3.778812961578369
- 3.7310698223114014
- 3.602096265157064
- 3.3160199451446535
- 2.9376634248097737
- 2.6108201440175374
- 2.3733269119262697
- 2.1993929735819497
- 2.0632599767049156
- 1.9650427802403767
- 1.895826015472412
- 1.812919561068217
- 1.7639857705434163
- 1.720254634221395
- 1.6693787320454916
- 1.6278403695424397
- 1.6188502105077107
- 1.5794076283772787
- 1.5605300267537434
- 1.5189054314295451
- 1.5249752140045165
- 1.4926462841033936
- 1.4736059045791625
- 1.4745732911427816
- 1.4475869782765707
- 1.4296525065104166
- 1.436484122276306
- 1.3976851415634155
- 1.3936148675282796
- 1.3834006214141845
- 1.3743323214848837
- 1.357829073270162
- 1.334201871554057
- 1.3326647694905598
- 1.3473041216532389
- 1.316588036219279
- 1.313620007832845
- 1.2986177078882852
- 1.2864329306284588
- 1.2992415316899617
- 1.284354510307312
- 1.2870602877934774
- 1.2643317159016927
- 1.250620584487915
- 1.2417869512240092
- 1.2311688017845155
- 1.2115403254826864
- 1.2215687092145284
- 1.231852560043335
- 1.2097494133313498
- 1.2091554180781046
- 1.1844647606213887
- 1.164082822004954
- 1.168298848470052
- 1.1655450503031413
- 1.1492699360847474
- 1.1517068680127462
- 1.1491667135556538
- 1.1666558225949606
- 1.1489314150810241
- 1.147812245686849
- 1.1459591142336527
- 1.1467083644866944
- 1.1304044111569722
- 1.1433772873878478
- 1.1200263126691183
- 1.1147946898142498
- 1.1153205211957296
- 1.1120136094093322
- 1.0973825144767761
- 1.1035185384750366
- 1.0787554264068604
- 1.0769721285502116
- 1.0696235799789429
- 1.0945626012484233
- 1.070923421382904
- 1.068638105392456
- 1.0842090344429016
- 1.0706851569811504
- 1.083152932325999
- 1.0616943923632305
- 1.05415252606074
- 1.0520668117205303
- 1.0406820472081502
- 1.0582350738843282
- 1.0552777274449667
- 1.066241080760956
- 1.0695086590449014
- 1.0564822268486023
- 1.052104884783427
- 1.0474131425221762
- 1.050937557220459
- 1.0642466847101848
- 1.052772252559662
- 1.0335841488838196
- 1.0528704476356507
- 1.0399553712209066
- 1.0356745862960814
- 1.0233340676625569
- 1.0266878867149354
train_accuracy:
- 0.031
- 0.0
- 0.0
- 0.244
- 0.365
- 0.0
- 0.544
- 0.55
- 0.562
- 0.0
- 0.633
- 0.0
- 0.677
- 0.654
- 0.0
- 0.64
- 0.681
- 0.679
- 0.0
- 0.71
- 0.729
- 0.71
- 0.685
- 0.756
- 0.75
- 0.735
- 0.748
- 0.756
- 0.0
- 0.763
- 0.758
- 0.775
- 0.777
- 0.758
- 0.0
- 0.787
- 0.781
- 0.0
- 0.775
- 0.767
- 0.785
- 0.808
- 0.781
- 0.806
- 0.775
- 0.779
- 0.767
- 0.792
- 0.0
- 0.806
- 0.781
- 0.769
- 0.765
- 0.76
- 0.76
- 0.0
- 0.0
- 0.821
- 0.794
- 0.794
- 0.802
- 0.817
- 0.804
- 0.0
- 0.0
- 0.0
- 0.0
- 0.823
- 0.804
- 0.812
- 0.844
- 0.0
- 0.0
- 0.0
- 0.81
- 0.0
- 0.771
- 0.823
- 0.783
- 0.817
- 0.808
- 0.0
- 0.815
- 0.0
- 0.787
- 0.823
- 0.835
- 0.85
- 0.815
- 0.8
- 0.0
- 0.798
- 0.831
- 0.79
- 0.0
- 0.796
- 0.8
- 0.0
- 0.794
- 0.842
train_loss:
- 2.876
- 2.865
- 2.779
- 2.636
- 2.419
- 1.808
- 2.034
- 2.223
- 1.467
- 1.682
- 1.609
- 1.286
- 1.507
- 1.448
- 1.181
- 1.163
- 1.586
- 1.314
- 1.537
- 1.081
- 1.467
- 1.236
- 1.233
- 1.395
- 1.173
- 1.172
- 1.35
- 0.966
- 1.125
- 1.119
- 1.096
- 1.112
- 0.9
- 1.07
- 1.239
- 1.062
- 1.04
- 1.056
- 1.032
- 1.186
- 1.006
- 1.166
- 1.004
- 0.987
- 0.832
- 0.983
- 0.819
- 0.974
- 1.12
- 0.97
- 0.949
- 0.794
- 0.789
- 0.94
- 0.936
- 0.783
- 0.928
- 0.917
- 1.055
- 0.916
- 0.911
- 0.904
- 0.901
- 0.891
- 1.04
- 0.749
- 0.742
- 0.887
- 0.872
- 0.869
- 0.869
- 0.726
- 0.725
- 0.72
- 0.995
- 0.721
- 0.726
- 0.986
- 0.846
- 0.977
- 0.708
- 0.699
- 0.84
- 0.713
- 0.965
- 0.83
- 0.959
- 0.967
- 0.818
- 0.829
- 0.69
- 0.826
- 0.941
- 0.825
- 0.683
- 0.946
- 0.806
- 0.808
- 0.675
- 0.802
unequal: 0
verbose: 1
