avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.045904255319148934
- 0.06803191489361703
- 0.08579787234042553
- 0.19601063829787235
- 0.3141489361702128
- 0.39835106382978724
- 0.451063829787234
- 0.490531914893617
- 0.5181914893617021
- 0.5437234042553192
- 0.5587765957446809
- 0.5770744680851064
- 0.5904255319148937
- 0.5989893617021277
- 0.6129255319148936
- 0.6205851063829787
- 0.6278191489361702
- 0.6372340425531915
- 0.6423936170212766
- 0.6475531914893617
- 0.6523404255319148
- 0.6595212765957447
- 0.6654787234042553
- 0.6689893617021276
- 0.6712765957446809
- 0.6762234042553191
- 0.6806382978723404
- 0.6844148936170212
- 0.6863297872340426
- 0.6914361702127659
- 0.6921808510638298
- 0.6956914893617021
- 0.6973404255319149
- 0.7009574468085107
- 0.7028723404255319
- 0.7040425531914893
- 0.7067553191489362
- 0.7086170212765958
- 0.7102127659574468
- 0.7113829787234043
- 0.7132978723404255
- 0.713936170212766
- 0.716968085106383
- 0.7177127659574468
- 0.7172340425531915
- 0.7218617021276595
- 0.7218617021276595
- 0.7253191489361702
- 0.7271276595744681
- 0.7254255319148936
- 0.725531914893617
- 0.7292021276595745
- 0.7297340425531915
- 0.73
- 0.7304787234042553
- 0.7325531914893617
- 0.7311170212765957
- 0.7328191489361702
- 0.7353191489361702
- 0.7348936170212766
- 0.7362234042553192
- 0.7368085106382979
- 0.7384574468085107
- 0.737872340425532
- 0.7384574468085107
- 0.7404255319148936
- 0.7391489361702127
- 0.7409574468085106
- 0.741436170212766
- 0.7417021276595744
- 0.7447872340425532
- 0.7442553191489362
- 0.7448404255319149
- 0.7448404255319149
- 0.7460638297872341
- 0.7461702127659574
- 0.7468085106382979
- 0.7486170212765958
- 0.7477659574468085
- 0.7502659574468085
- 0.7506382978723404
- 0.7522872340425532
- 0.7531914893617021
- 0.7512234042553192
- 0.754468085106383
- 0.7529787234042553
- 0.7549468085106383
- 0.7552127659574468
- 0.7570212765957447
- 0.7547872340425532
- 0.7570212765957447
- 0.7568085106382979
- 0.7573404255319149
- 0.7585106382978724
- 0.7569148936170212
- 0.758031914893617
- 0.7596808510638298
- 0.7595744680851064
- 0.7620744680851064
- 0.759468085106383
test_loss_list:
- 3.784447285334269
- 3.746671199798584
- 3.651629056930542
- 3.4216135629018147
- 3.058428529103597
- 2.729882287979126
- 2.49238702138265
- 2.306967913309733
- 2.164626766840617
- 2.054556818008423
- 1.9656744718551635
- 1.900876340866089
- 1.8446708774566651
- 1.7862017885843913
- 1.7431838528315227
- 1.6971144247055054
- 1.6647136529286704
- 1.6614550097783407
- 1.6164187971750896
- 1.5977401415506998
- 1.5511676836013795
- 1.531460477511088
- 1.529794413248698
- 1.5032377926508587
- 1.4693958902359008
- 1.4385365597407023
- 1.4473383871714274
- 1.4391479857762655
- 1.3970950015385946
- 1.4123254362742106
- 1.3887012990315755
- 1.3807740306854248
- 1.3674144665400187
- 1.345434061686198
- 1.335806679725647
- 1.3186561409632365
- 1.3010199801127116
- 1.3248921219507854
- 1.298105352719625
- 1.2764808019002278
- 1.2663242061932882
- 1.2547423505783082
- 1.2605233502388
- 1.249751652876536
- 1.2271611301104228
- 1.2362391742070515
- 1.2300278488794962
- 1.235784298578898
- 1.2256204271316529
- 1.1965956942240397
- 1.1904834214846294
- 1.2082940204938253
- 1.191423519452413
- 1.1811383732159932
- 1.1837596956888834
- 1.1660765226682026
- 1.1535740661621094
- 1.1510158332188924
- 1.1264631152153015
- 1.150859035650889
- 1.1160306429862976
- 1.1375905283292134
- 1.1233166948954265
- 1.1151525966326397
- 1.0994087211290995
- 1.1093185917536417
- 1.11312726020813
- 1.1062049301465353
- 1.0797444502512614
- 1.0796831623713175
- 1.081719957192739
- 1.0920255057017008
- 1.0595582509040833
- 1.0644034878412882
- 1.0607455841700235
- 1.070766433874766
- 1.0809576026598613
- 1.0577507702509563
- 1.0547536381085714
- 1.0385300858815512
- 1.0464551830291748
- 1.052685209910075
- 1.0676510294278463
- 1.0747478922208151
- 1.090287024974823
- 1.0617558217048646
- 1.0360699979464214
- 1.044692181746165
- 1.045844884713491
- 1.0430876843134562
- 1.021993137995402
- 1.0247360459963482
- 1.0256280906995137
- 1.0303722302118936
- 1.0086751993497212
- 1.001331595579783
- 1.0095674832661947
- 1.0251701664924622
- 1.009690645535787
- 1.0067116816838582
train_accuracy:
- 0.052
- 0.077
- 0.106
- 0.0
- 0.0
- 0.412
- 0.0
- 0.504
- 0.517
- 0.623
- 0.617
- 0.0
- 0.0
- 0.658
- 0.0
- 0.667
- 0.662
- 0.673
- 0.702
- 0.0
- 0.0
- 0.752
- 0.0
- 0.725
- 0.729
- 0.748
- 0.76
- 0.733
- 0.75
- 0.756
- 0.729
- 0.773
- 0.0
- 0.783
- 0.0
- 0.0
- 0.765
- 0.787
- 0.0
- 0.773
- 0.771
- 0.775
- 0.792
- 0.0
- 0.769
- 0.763
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.783
- 0.0
- 0.792
- 0.796
- 0.777
- 0.777
- 0.798
- 0.0
- 0.804
- 0.804
- 0.79
- 0.79
- 0.792
- 0.785
- 0.806
- 0.821
- 0.794
- 0.806
- 0.808
- 0.0
- 0.798
- 0.821
- 0.812
- 0.0
- 0.0
- 0.794
- 0.796
- 0.792
- 0.0
- 0.833
- 0.0
- 0.808
- 0.0
- 0.812
- 0.0
- 0.808
- 0.825
- 0.812
- 0.0
- 0.812
- 0.0
- 0.827
- 0.827
- 0.0
- 0.0
- 0.825
- 0.817
- 0.819
- 0.0
train_loss:
- 2.396
- 3.327
- 3.285
- 3.149
- 2.049
- 2.269
- 2.107
- 1.959
- 1.845
- 2.068
- 1.692
- 1.905
- 1.57
- 1.521
- 1.49
- 1.456
- 1.419
- 1.855
- 1.371
- 1.562
- 1.093
- 1.289
- 1.49
- 1.265
- 1.031
- 1.026
- 1.41
- 1.388
- 0.982
- 1.36
- 1.149
- 1.334
- 1.12
- 1.115
- 1.11
- 1.102
- 1.097
- 1.436
- 1.07
- 0.886
- 1.049
- 1.047
- 1.208
- 1.029
- 0.854
- 1.195
- 1.025
- 1.177
- 1.161
- 0.829
- 0.822
- 1.137
- 0.983
- 0.973
- 0.975
- 0.96
- 0.791
- 0.945
- 0.788
- 1.096
- 0.789
- 1.088
- 0.923
- 0.763
- 0.764
- 0.913
- 0.914
- 0.904
- 0.767
- 0.746
- 0.897
- 0.881
- 0.743
- 0.894
- 0.878
- 0.877
- 1.028
- 0.731
- 0.876
- 0.737
- 0.862
- 0.861
- 1.0
- 0.995
- 1.134
- 0.859
- 0.716
- 0.851
- 0.855
- 0.843
- 0.705
- 0.844
- 0.827
- 0.829
- 0.698
- 0.833
- 0.824
- 0.968
- 0.823
- 0.821
unequal: 0
verbose: 1
