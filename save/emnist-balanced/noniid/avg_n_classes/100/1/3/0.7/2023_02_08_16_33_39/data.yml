avg_train_accuracy: 0.802
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.030638297872340424
- 0.08037234042553192
- 0.1449468085106383
- 0.20712765957446808
- 0.3025531914893617
- 0.3815425531914894
- 0.42792553191489363
- 0.4629255319148936
- 0.49377659574468086
- 0.5120744680851064
- 0.5374468085106383
- 0.5529787234042554
- 0.5714361702127659
- 0.5804255319148937
- 0.5915425531914894
- 0.6048936170212766
- 0.616968085106383
- 0.6249468085106383
- 0.6284574468085107
- 0.6320212765957447
- 0.645904255319149
- 0.6496808510638298
- 0.6530851063829787
- 0.659468085106383
- 0.6673404255319149
- 0.6688829787234043
- 0.6714893617021277
- 0.676595744680851
- 0.6823404255319149
- 0.6852659574468085
- 0.6854255319148936
- 0.6938829787234042
- 0.6938297872340425
- 0.6969148936170213
- 0.6995212765957447
- 0.7018085106382979
- 0.703936170212766
- 0.7067553191489362
- 0.7081914893617022
- 0.7106914893617021
- 0.7133510638297872
- 0.7126063829787234
- 0.7145744680851064
- 0.7172340425531915
- 0.7173936170212766
- 0.7199468085106383
- 0.7215425531914894
- 0.7202127659574468
- 0.7227659574468085
- 0.7272340425531915
- 0.7266489361702128
- 0.7275
- 0.7283510638297872
- 0.7267021276595744
- 0.728404255319149
- 0.7275
- 0.730531914893617
- 0.7302127659574468
- 0.7325
- 0.735
- 0.7313297872340425
- 0.734468085106383
- 0.7358510638297873
- 0.736968085106383
- 0.7385106382978723
- 0.7374468085106383
- 0.738563829787234
- 0.7401595744680851
- 0.736968085106383
- 0.7377659574468085
- 0.7393617021276596
- 0.7412765957446809
- 0.7415425531914893
- 0.7423936170212766
- 0.7402659574468086
- 0.7432978723404255
- 0.7439361702127659
- 0.7442021276595745
- 0.7463829787234042
- 0.7461170212765957
- 0.7439361702127659
- 0.7472340425531915
- 0.7466489361702128
- 0.7482978723404256
- 0.7488829787234043
- 0.7473404255319149
- 0.7471808510638298
- 0.7481382978723404
- 0.7472872340425532
- 0.7479255319148936
- 0.7489361702127659
- 0.7510106382978723
- 0.7501595744680851
- 0.7511170212765957
- 0.7513297872340425
- 0.7524468085106383
- 0.7507446808510638
- 0.7493085106382978
- 0.7513829787234042
- 0.7515425531914893
test_loss_list:
- 3.7790091387430826
- 3.7319733715057373
- 3.593663822809855
- 3.3226736036936444
- 2.9722971725463867
- 2.6710266208648683
- 2.44944585164388
- 2.3148141129811606
- 2.2037572065989175
- 2.103525783220927
- 2.022076789538066
- 1.9485568189620972
- 1.8828965441385905
- 1.8243499565124512
- 1.7844503323237102
- 1.7341676998138427
- 1.7081390953063964
- 1.6531901280085246
- 1.6302027050654093
- 1.597925426165263
- 1.5857867288589478
- 1.5536618502934774
- 1.5212630701065064
- 1.5289192310969035
- 1.4937931108474731
- 1.459357992808024
- 1.4536850547790527
- 1.4357283385594686
- 1.4047369813919068
- 1.3941769552230836
- 1.3728192456563313
- 1.3559853792190553
- 1.3648333263397217
- 1.3455066219965617
- 1.3330313396453857
- 1.3521741739908855
- 1.331117016474406
- 1.3212520662943523
- 1.316912088394165
- 1.3306765381495158
- 1.2913132158915201
- 1.2988475624720255
- 1.286950217882792
- 1.2952096581459045
- 1.2631928730010986
- 1.2559838104248047
- 1.2377257378896078
- 1.2310306119918824
- 1.2343635574976604
- 1.2448150436083476
- 1.2096964836120605
- 1.2125126846631369
- 1.2261370174090067
- 1.227212474346161
- 1.2105132738749187
- 1.1912277436256409
- 1.1862358562151591
- 1.1862193195025126
- 1.2042707769076029
- 1.1784497618675231
- 1.189555606842041
- 1.1846943497657776
- 1.159379620552063
- 1.1530048656463623
- 1.1411925268173218
- 1.1294083229700724
- 1.1686376523971558
- 1.1276379950841269
- 1.1277693072954813
- 1.1303264260292054
- 1.152640061378479
- 1.1342677386601765
- 1.1459296607971192
- 1.162296335697174
- 1.128719263871511
- 1.1115960240364076
- 1.1046031761169433
- 1.128751433690389
- 1.1161053816477458
- 1.1321520352363585
- 1.089261527856191
- 1.0970708640416462
- 1.1131011843681335
- 1.0922486090660095
- 1.119253294467926
- 1.0976415554682413
- 1.0947046057383218
- 1.1172482228279115
- 1.091401863892873
- 1.0820103255907694
- 1.0904156732559205
- 1.0860751525561014
- 1.0531794301668802
- 1.0624512187639872
- 1.0612688533465067
- 1.040760758717855
- 1.0337538290023804
- 1.0319286330540975
- 1.05105703830719
- 1.0514749089876811
train_accuracy:
- 0.0
- 0.092
- 0.0
- 0.202
- 0.333
- 0.394
- 0.0
- 0.0
- 0.527
- 0.0
- 0.565
- 0.588
- 0.64
- 0.642
- 0.648
- 0.654
- 0.0
- 0.706
- 0.0
- 0.0
- 0.671
- 0.696
- 0.0
- 0.713
- 0.721
- 0.0
- 0.0
- 0.725
- 0.723
- 0.723
- 0.769
- 0.756
- 0.0
- 0.787
- 0.771
- 0.742
- 0.0
- 0.0
- 0.0
- 0.763
- 0.0
- 0.746
- 0.0
- 0.785
- 0.756
- 0.763
- 0.0
- 0.763
- 0.777
- 0.787
- 0.0
- 0.823
- 0.798
- 0.779
- 0.794
- 0.0
- 0.802
- 0.796
- 0.781
- 0.806
- 0.0
- 0.771
- 0.777
- 0.827
- 0.0
- 0.777
- 0.773
- 0.0
- 0.796
- 0.796
- 0.802
- 0.817
- 0.831
- 0.823
- 0.838
- 0.798
- 0.0
- 0.802
- 0.0
- 0.823
- 0.0
- 0.0
- 0.806
- 0.831
- 0.794
- 0.0
- 0.838
- 0.81
- 0.844
- 0.794
- 0.79
- 0.838
- 0.0
- 0.844
- 0.831
- 0.798
- 0.802
- 0.792
- 0.806
- 0.802
train_loss:
- 2.856
- 2.835
- 2.753
- 2.618
- 2.427
- 2.241
- 1.698
- 1.97
- 2.214
- 1.794
- 2.034
- 1.665
- 1.336
- 1.55
- 1.521
- 1.488
- 1.691
- 1.174
- 1.391
- 1.115
- 1.575
- 1.107
- 1.074
- 1.499
- 1.479
- 1.035
- 1.217
- 1.215
- 1.006
- 0.985
- 0.971
- 0.965
- 1.144
- 1.129
- 1.119
- 1.289
- 1.106
- 1.102
- 1.075
- 1.243
- 0.911
- 1.057
- 1.046
- 1.215
- 0.87
- 1.026
- 0.863
- 0.848
- 1.0
- 1.18
- 0.852
- 1.0
- 0.995
- 0.98
- 0.975
- 0.812
- 0.962
- 0.96
- 1.123
- 0.963
- 0.954
- 0.946
- 0.793
- 0.942
- 0.787
- 0.783
- 1.081
- 0.783
- 0.767
- 0.91
- 1.068
- 0.916
- 1.066
- 1.053
- 0.754
- 0.754
- 0.749
- 0.892
- 0.904
- 1.04
- 0.754
- 0.89
- 1.025
- 0.883
- 1.024
- 0.888
- 0.879
- 1.011
- 0.725
- 0.868
- 0.857
- 0.875
- 0.724
- 0.87
- 0.859
- 0.715
- 0.703
- 0.71
- 0.845
- 0.84
unequal: 0
verbose: 1
