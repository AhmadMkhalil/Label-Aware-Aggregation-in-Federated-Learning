avg_train_accuracy: 0.812
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.052393617021276595
- 0.09292553191489361
- 0.1451063829787234
- 0.24
- 0.35
- 0.4231382978723404
- 0.4682978723404255
- 0.504468085106383
- 0.5269680851063829
- 0.5515425531914894
- 0.5631914893617022
- 0.578031914893617
- 0.5930319148936171
- 0.6015425531914894
- 0.6131382978723404
- 0.626436170212766
- 0.631436170212766
- 0.640531914893617
- 0.6476063829787234
- 0.6520212765957447
- 0.6606382978723404
- 0.665904255319149
- 0.67
- 0.6740957446808511
- 0.6774468085106383
- 0.6796808510638298
- 0.6862765957446808
- 0.6882978723404255
- 0.6927127659574468
- 0.6945744680851064
- 0.6949468085106383
- 0.6986702127659574
- 0.7048404255319148
- 0.7044680851063829
- 0.7068617021276595
- 0.709627659574468
- 0.7101595744680851
- 0.7126063829787234
- 0.7151063829787234
- 0.7163297872340425
- 0.7159574468085106
- 0.7176595744680851
- 0.7216489361702128
- 0.7217553191489362
- 0.7220744680851063
- 0.722872340425532
- 0.7273404255319149
- 0.7265425531914894
- 0.7276063829787234
- 0.7272340425531915
- 0.7290425531914894
- 0.7291489361702128
- 0.7327127659574468
- 0.7317553191489362
- 0.7346276595744681
- 0.7361702127659574
- 0.7363297872340425
- 0.7370212765957447
- 0.736436170212766
- 0.7382978723404255
- 0.7411702127659574
- 0.7401063829787234
- 0.7420744680851064
- 0.740531914893617
- 0.7424468085106383
- 0.7454787234042554
- 0.7460638297872341
- 0.7463829787234042
- 0.7474468085106383
- 0.748563829787234
- 0.7473936170212766
- 0.746436170212766
- 0.7487234042553191
- 0.7482446808510639
- 0.7515957446808511
- 0.7491489361702127
- 0.7518085106382979
- 0.7525531914893617
- 0.7497340425531915
- 0.7528723404255319
- 0.7524468085106383
- 0.7539361702127659
- 0.7548936170212766
- 0.7557978723404255
- 0.7567553191489361
- 0.7569148936170212
- 0.7576063829787234
- 0.7577127659574469
- 0.7563829787234042
- 0.7576595744680851
- 0.7597340425531914
- 0.7589893617021276
- 0.7593617021276595
- 0.7611170212765958
- 0.7570212765957447
- 0.7602659574468085
- 0.7612234042553192
- 0.7633510638297872
- 0.7623936170212766
- 0.7617021276595745
test_loss_list:
- 3.7807503859202067
- 3.7278070958455403
- 3.5747809314727785
- 3.294025354385376
- 2.941132214864095
- 2.6367196877797445
- 2.4435028076171874
- 2.2914021396636963
- 2.166973253885905
- 2.0865657981236776
- 2.0021815792719524
- 1.9416670179367066
- 1.8963379542032877
- 1.8271263313293458
- 1.7946618366241456
- 1.7761589701970417
- 1.7238077020645142
- 1.6973758347829182
- 1.6589000924428303
- 1.6183565123875936
- 1.6142123540242512
- 1.5942095041275024
- 1.5946708552042643
- 1.5580435276031495
- 1.5482988357543945
- 1.5045567973454794
- 1.5262663269042969
- 1.4938237396876017
- 1.488252156575521
- 1.4836239004135132
- 1.4629334036509196
- 1.46633816242218
- 1.487544027964274
- 1.4386275418599446
- 1.4172016541163126
- 1.416486169497172
- 1.3805511776606243
- 1.3626002391179404
- 1.3627043596903483
- 1.343548329671224
- 1.3467820151646932
- 1.3487239408493041
- 1.3252580372492473
- 1.3465052445729573
- 1.299740481376648
- 1.3079901297887166
- 1.3005639028549194
- 1.281563908259074
- 1.270768690109253
- 1.2553081798553467
- 1.282626785437266
- 1.240977838039398
- 1.2431081740061443
- 1.23051611661911
- 1.2354761672019958
- 1.2320451354980468
- 1.2258402983347574
- 1.2299226824442546
- 1.205577045281728
- 1.210458006064097
- 1.2238221375147502
- 1.2118172113100687
- 1.2038048656781515
- 1.1717535328865052
- 1.1731954026222229
- 1.2020145440101624
- 1.188600488503774
- 1.1727890515327453
- 1.175959350268046
- 1.1429891459147135
- 1.1210604580243428
- 1.128880167802175
- 1.1352328316370646
- 1.1386135586102804
- 1.1097716681162517
- 1.1062762037913005
- 1.1092942976951599
- 1.0939408437410991
- 1.089459425608317
- 1.1018631426493326
- 1.0740879042943319
- 1.1045447572072347
- 1.0670283436775208
- 1.0761089968681334
- 1.0976062575976053
- 1.0888209708531698
- 1.0719750428199768
- 1.0728384407361349
- 1.0642399454116822
- 1.049018681049347
- 1.0702308098475137
- 1.066456151008606
- 1.066631805896759
- 1.05664826075236
- 1.0356570641199747
- 1.0306934062639872
- 1.0241356213887534
- 1.0545747947692872
- 1.0300449339548747
- 1.034175313313802
train_accuracy:
- 0.048
- 0.104
- 0.165
- 0.0
- 0.396
- 0.431
- 0.523
- 0.0
- 0.619
- 0.0
- 0.0
- 0.0
- 0.629
- 0.644
- 0.667
- 0.646
- 0.669
- 0.0
- 0.0
- 0.698
- 0.692
- 0.719
- 0.0
- 0.717
- 0.713
- 0.0
- 0.727
- 0.0
- 0.783
- 0.723
- 0.758
- 0.74
- 0.765
- 0.75
- 0.748
- 0.758
- 0.802
- 0.785
- 0.0
- 0.756
- 0.0
- 0.798
- 0.763
- 0.763
- 0.798
- 0.0
- 0.806
- 0.0
- 0.76
- 0.777
- 0.752
- 0.0
- 0.75
- 0.0
- 0.769
- 0.783
- 0.779
- 0.0
- 0.821
- 0.0
- 0.819
- 0.821
- 0.758
- 0.825
- 0.0
- 0.835
- 0.0
- 0.844
- 0.84
- 0.0
- 0.0
- 0.775
- 0.842
- 0.0
- 0.804
- 0.0
- 0.792
- 0.0
- 0.0
- 0.856
- 0.833
- 0.838
- 0.838
- 0.84
- 0.0
- 0.8
- 0.773
- 0.792
- 0.802
- 0.0
- 0.0
- 0.802
- 0.8
- 0.852
- 0.0
- 0.0
- 0.0
- 0.802
- 0.0
- 0.812
train_loss:
- 2.339
- 3.316
- 2.744
- 2.598
- 2.84
- 2.201
- 2.048
- 1.58
- 1.507
- 1.744
- 1.682
- 1.619
- 1.568
- 1.269
- 1.478
- 1.694
- 1.424
- 1.385
- 1.35
- 1.114
- 1.311
- 1.296
- 1.484
- 1.257
- 1.238
- 1.029
- 1.399
- 1.184
- 1.359
- 1.35
- 1.157
- 1.326
- 1.488
- 1.119
- 1.104
- 1.105
- 0.921
- 0.912
- 1.062
- 0.891
- 1.059
- 1.047
- 1.042
- 1.188
- 0.873
- 1.007
- 1.016
- 0.843
- 0.829
- 0.834
- 1.14
- 0.827
- 0.981
- 0.814
- 0.96
- 0.965
- 0.954
- 0.943
- 0.794
- 0.943
- 1.094
- 0.928
- 0.934
- 0.78
- 0.765
- 1.068
- 0.909
- 0.915
- 0.904
- 0.762
- 0.76
- 0.745
- 0.896
- 0.895
- 0.745
- 0.733
- 0.88
- 0.735
- 0.726
- 0.871
- 0.731
- 0.859
- 0.733
- 0.866
- 1.004
- 0.854
- 0.716
- 0.854
- 0.852
- 0.714
- 0.852
- 0.842
- 0.841
- 0.844
- 0.704
- 0.71
- 0.704
- 0.969
- 0.696
- 0.837
unequal: 0
verbose: 1
