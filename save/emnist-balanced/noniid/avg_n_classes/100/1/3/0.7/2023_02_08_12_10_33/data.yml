avg_train_accuracy: 0.846
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05303191489361702
- 0.0752127659574468
- 0.16946808510638298
- 0.2870744680851064
- 0.38063829787234044
- 0.45351063829787236
- 0.5028191489361702
- 0.5300531914893617
- 0.559468085106383
- 0.5758510638297872
- 0.5879255319148936
- 0.6015425531914894
- 0.612872340425532
- 0.621968085106383
- 0.6317021276595745
- 0.6394148936170213
- 0.6498936170212766
- 0.6570212765957447
- 0.6629787234042553
- 0.6678723404255319
- 0.6735106382978724
- 0.6761170212765958
- 0.6830851063829787
- 0.6856914893617021
- 0.6871276595744681
- 0.6912765957446808
- 0.6938829787234042
- 0.7
- 0.7053723404255319
- 0.7077127659574468
- 0.7104787234042553
- 0.7123404255319149
- 0.7121808510638298
- 0.7157978723404256
- 0.7195212765957447
- 0.7204255319148937
- 0.7232978723404255
- 0.7232978723404255
- 0.7251063829787234
- 0.7248936170212766
- 0.7265957446808511
- 0.7280319148936171
- 0.7307446808510638
- 0.7304787234042553
- 0.7320744680851063
- 0.7332978723404255
- 0.7353191489361702
- 0.7350531914893617
- 0.7368085106382979
- 0.7406382978723405
- 0.7379255319148936
- 0.7383510638297872
- 0.7401063829787234
- 0.7392021276595745
- 0.7411702127659574
- 0.7439361702127659
- 0.7426063829787234
- 0.7413297872340425
- 0.7431382978723404
- 0.7463829787234042
- 0.7425
- 0.7465957446808511
- 0.75
- 0.7483510638297872
- 0.7458510638297873
- 0.7506382978723404
- 0.7485106382978723
- 0.7516489361702128
- 0.7497340425531915
- 0.7517021276595744
- 0.7513829787234042
- 0.7526063829787234
- 0.7537234042553191
- 0.7540425531914894
- 0.7554255319148936
- 0.754468085106383
- 0.7557978723404255
- 0.7557446808510638
- 0.7525531914893617
- 0.7554255319148936
- 0.7588829787234043
- 0.7573404255319149
- 0.7588829787234043
- 0.7582978723404256
- 0.7595212765957446
- 0.7602127659574468
- 0.7588297872340426
- 0.7604787234042554
- 0.7584042553191489
- 0.7611702127659574
- 0.7578723404255319
- 0.7612234042553192
- 0.7620212765957447
- 0.763031914893617
- 0.7626063829787234
- 0.7638297872340426
- 0.7632446808510638
- 0.7639361702127659
- 0.7630851063829788
- 0.7638297872340426
test_loss_list:
- 3.7735009638468426
- 3.715988473892212
- 3.5551187864939373
- 3.2310830275217692
- 2.8366226291656496
- 2.538919941584269
- 2.314104232788086
- 2.155704000790914
- 2.0457713651657103
- 1.9813966703414918
- 1.8992299270629882
- 1.8535044082005818
- 1.8194698746999105
- 1.7663150707880655
- 1.7425695403416952
- 1.7017233085632324
- 1.6863941605885824
- 1.6685795656840006
- 1.630702880223592
- 1.6273780107498168
- 1.611874408721924
- 1.5533168427149455
- 1.5457420651117961
- 1.5121216837565103
- 1.5103864860534668
- 1.4957462946573894
- 1.4594969701766969
- 1.4821205155054729
- 1.4472613477706908
- 1.4290562597910563
- 1.3939452028274537
- 1.4162612215677897
- 1.3944886255264282
- 1.3784707117080688
- 1.3598174540201824
- 1.3430209509531656
- 1.338212480545044
- 1.3103470373153687
- 1.293553261756897
- 1.2940071487426759
- 1.2945021645228068
- 1.300823511282603
- 1.2842843755086264
- 1.275018170674642
- 1.2582743295033774
- 1.259723182519277
- 1.2581639512379965
- 1.224082372188568
- 1.2294444982210795
- 1.2480455875396728
- 1.2025990851720174
- 1.224274963537852
- 1.209642509619395
- 1.2115135502815246
- 1.1892844446500141
- 1.2083298881848654
- 1.1789597113927206
- 1.1699797018369038
- 1.1802250250180562
- 1.1526810495058695
- 1.1443536440531412
- 1.1539460476239523
- 1.1267761270205179
- 1.1390758053461711
- 1.1327403903007507
- 1.1357958738009135
- 1.135815978050232
- 1.1350763861338298
- 1.1074477124214173
- 1.127515717347463
- 1.1269262099266053
- 1.1216187866528828
- 1.0995780165990194
- 1.1297521138191222
- 1.1115153074264525
- 1.1122793555259705
- 1.1076856938997905
- 1.1052406748135886
- 1.088163656393687
- 1.116686120033264
- 1.0878882845242819
- 1.0970904286702474
- 1.0952550983428955
- 1.086049518585205
- 1.10889324426651
- 1.111874074935913
- 1.0950018509229025
- 1.0675048756599426
- 1.0590599759419759
- 1.0733675122261048
- 1.0588867743810018
- 1.058249241511027
- 1.0308563502629597
- 1.026402473449707
- 1.0245368727048239
- 1.0389301204681396
- 1.0367841545740764
- 1.0361120319366455
- 1.043466948668162
- 1.0317210388183593
train_accuracy:
- 0.06
- 0.073
- 0.0
- 0.315
- 0.433
- 0.496
- 0.0
- 0.0
- 0.627
- 0.635
- 0.0
- 0.665
- 0.685
- 0.0
- 0.698
- 0.704
- 0.648
- 0.74
- 0.723
- 0.758
- 0.748
- 0.742
- 0.0
- 0.0
- 0.737
- 0.76
- 0.0
- 0.771
- 0.767
- 0.785
- 0.0
- 0.79
- 0.781
- 0.781
- 0.783
- 0.792
- 0.79
- 0.0
- 0.0
- 0.792
- 0.0
- 0.796
- 0.815
- 0.0
- 0.0
- 0.8
- 0.798
- 0.804
- 0.819
- 0.779
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.792
- 0.0
- 0.0
- 0.0
- 0.823
- 0.806
- 0.802
- 0.0
- 0.829
- 0.0
- 0.827
- 0.833
- 0.831
- 0.831
- 0.84
- 0.0
- 0.833
- 0.0
- 0.84
- 0.842
- 0.844
- 0.0
- 0.844
- 0.0
- 0.844
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.0
- 0.0
- 0.85
- 0.0
- 0.0
- 0.0
- 0.842
- 0.0
- 0.846
train_loss:
- 3.355
- 2.371
- 2.732
- 2.571
- 1.932
- 2.145
- 2.341
- 1.853
- 1.75
- 1.958
- 1.609
- 1.81
- 1.755
- 1.458
- 1.648
- 1.381
- 1.577
- 1.538
- 1.308
- 1.473
- 1.445
- 1.039
- 1.217
- 1.001
- 1.174
- 1.157
- 0.954
- 1.309
- 1.131
- 1.113
- 0.921
- 1.253
- 1.074
- 1.056
- 1.055
- 1.047
- 1.037
- 0.866
- 0.861
- 1.02
- 1.001
- 1.165
- 0.997
- 0.983
- 0.979
- 0.987
- 0.972
- 0.811
- 0.956
- 1.103
- 0.804
- 0.945
- 0.942
- 0.933
- 0.784
- 1.088
- 0.784
- 0.766
- 0.912
- 0.774
- 0.757
- 0.905
- 0.767
- 0.908
- 0.897
- 0.89
- 0.883
- 0.887
- 0.745
- 0.886
- 0.869
- 0.877
- 0.732
- 1.007
- 0.862
- 0.864
- 0.862
- 0.869
- 0.721
- 0.995
- 0.873
- 0.847
- 0.855
- 0.856
- 0.986
- 0.989
- 0.847
- 0.708
- 0.697
- 0.828
- 0.7
- 0.831
- 0.705
- 0.703
- 0.698
- 0.827
- 0.832
- 0.822
- 0.818
- 0.835
unequal: 0
verbose: 1
