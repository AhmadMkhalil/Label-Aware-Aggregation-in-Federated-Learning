avg_train_accuracy: 0.838
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0525
- 0.05526595744680851
- 0.10803191489361702
- 0.22702127659574467
- 0.3347340425531915
- 0.4124468085106383
- 0.4613829787234043
- 0.5020212765957447
- 0.5254787234042553
- 0.5499468085106383
- 0.5695212765957447
- 0.5831382978723404
- 0.5975
- 0.608404255319149
- 0.6215425531914893
- 0.6310638297872341
- 0.6392021276595745
- 0.6478723404255319
- 0.6545744680851063
- 0.6613297872340426
- 0.668563829787234
- 0.6702127659574468
- 0.6786702127659574
- 0.6795212765957447
- 0.6844148936170212
- 0.6881382978723404
- 0.6890957446808511
- 0.6964893617021276
- 0.6985106382978723
- 0.6992553191489361
- 0.7022340425531914
- 0.7055851063829788
- 0.7083510638297872
- 0.7104255319148937
- 0.7134574468085106
- 0.7130851063829787
- 0.7157978723404256
- 0.7192553191489361
- 0.7190425531914894
- 0.7198936170212766
- 0.7231382978723404
- 0.7257446808510638
- 0.7281914893617021
- 0.7287765957446809
- 0.7293617021276596
- 0.731968085106383
- 0.7337234042553191
- 0.7339893617021277
- 0.7368617021276596
- 0.7359574468085106
- 0.7392553191489362
- 0.737659574468085
- 0.7398936170212767
- 0.7420212765957447
- 0.7410106382978724
- 0.744095744680851
- 0.7424468085106383
- 0.7437765957446808
- 0.7460638297872341
- 0.7443617021276596
- 0.7476063829787234
- 0.7472340425531915
- 0.7491489361702127
- 0.7485106382978723
- 0.7499468085106383
- 0.7526595744680851
- 0.7520212765957447
- 0.7526595744680851
- 0.7538829787234043
- 0.7529787234042553
- 0.7536702127659575
- 0.7563297872340425
- 0.755904255319149
- 0.7557446808510638
- 0.7578191489361702
- 0.758031914893617
- 0.7582446808510638
- 0.7596808510638298
- 0.7589893617021276
- 0.7586702127659575
- 0.7592553191489362
- 0.7627659574468085
- 0.7620212765957447
- 0.7634574468085107
- 0.7627659574468085
- 0.7620744680851064
- 0.7619148936170212
- 0.7636702127659575
- 0.7636702127659575
- 0.7633510638297872
- 0.7632978723404256
- 0.7650531914893617
- 0.7645212765957446
- 0.7653723404255319
- 0.7644148936170213
- 0.7635106382978724
- 0.7645744680851064
- 0.7673404255319148
- 0.7668085106382979
- 0.7660638297872341
test_loss_list:
- 3.786298408508301
- 3.7520337009429934
- 3.652561467488607
- 3.386511027018229
- 3.0202228260040282
- 2.704932276407878
- 2.478576234181722
- 2.3088202985127766
- 2.178774175643921
- 2.0818267997105915
- 1.9852690172195435
- 1.9142453400293986
- 1.8469793065388997
- 1.8031822061538696
- 1.7470994806289672
- 1.6924736483891805
- 1.6831975158055623
- 1.651576418876648
- 1.6091647831598919
- 1.5961821921666464
- 1.5548965915044148
- 1.5414728927612305
- 1.5319162305196126
- 1.5017505995432536
- 1.4845546913146972
- 1.4613688770929973
- 1.4598751179377238
- 1.4310660934448243
- 1.433521580696106
- 1.413955594698588
- 1.3918936681747436
- 1.3987711397806804
- 1.3709657716751098
- 1.386040865580241
- 1.3479089148839314
- 1.3380404504140218
- 1.3369891500473023
- 1.31956911722819
- 1.3025380420684813
- 1.286661728223165
- 1.2910900338490805
- 1.2765371068318685
- 1.27155708471934
- 1.2885182825724284
- 1.2846188131968181
- 1.2962109343210857
- 1.275708236694336
- 1.2817180140813191
- 1.2756723515192667
- 1.2837988948822021
- 1.2421873529752097
- 1.2478218603134155
- 1.234597124258677
- 1.220435191790263
- 1.2247987842559815
- 1.1990480756759643
- 1.2070456711451212
- 1.205763773918152
- 1.1848964540163676
- 1.2095965925852459
- 1.170919004281362
- 1.185850644906362
- 1.1718614466985067
- 1.1564142115910847
- 1.1507640846570333
- 1.135065373579661
- 1.1375707181294759
- 1.1496644894282022
- 1.1472675291697185
- 1.1415469511349996
- 1.139801701704661
- 1.1380405497550965
- 1.158311016559601
- 1.1227368291219075
- 1.1445031174023945
- 1.1086878633499146
- 1.1067600313822428
- 1.1420454223950705
- 1.097547033627828
- 1.0908204229672749
- 1.0812057360013325
- 1.0839301959673564
- 1.09200706243515
- 1.0862178874015809
- 1.0965292723973592
- 1.0961223832766216
- 1.0865557781855266
- 1.0614286653200786
- 1.080551994641622
- 1.089897867043813
- 1.0605310225486755
- 1.0636069869995117
- 1.0531649502118428
- 1.0669349161783854
- 1.0538715100288392
- 1.041060390472412
- 1.030995604991913
- 1.055697681903839
- 1.0471113379796346
- 1.042767635981242
train_accuracy:
- 0.048
- 0.054
- 0.123
- 0.0
- 0.342
- 0.467
- 0.49
- 0.525
- 0.0
- 0.579
- 0.621
- 0.635
- 0.606
- 0.0
- 0.698
- 0.702
- 0.702
- 0.721
- 0.696
- 0.721
- 0.702
- 0.0
- 0.0
- 0.0
- 0.763
- 0.729
- 0.771
- 0.0
- 0.742
- 0.0
- 0.773
- 0.0
- 0.0
- 0.804
- 0.75
- 0.742
- 0.0
- 0.76
- 0.0
- 0.0
- 0.792
- 0.821
- 0.0
- 0.769
- 0.779
- 0.825
- 0.771
- 0.79
- 0.783
- 0.796
- 0.0
- 0.783
- 0.0
- 0.8
- 0.823
- 0.802
- 0.0
- 0.819
- 0.783
- 0.8
- 0.0
- 0.806
- 0.0
- 0.792
- 0.0
- 0.0
- 0.844
- 0.796
- 0.81
- 0.0
- 0.79
- 0.819
- 0.831
- 0.829
- 0.817
- 0.8
- 0.0
- 0.0
- 0.0
- 0.86
- 0.823
- 0.833
- 0.81
- 0.812
- 0.81
- 0.817
- 0.8
- 0.831
- 0.808
- 0.856
- 0.827
- 0.823
- 0.0
- 0.819
- 0.81
- 0.0
- 0.798
- 0.835
- 0.81
- 0.838
train_loss:
- 3.384
- 2.89
- 2.813
- 2.199
- 2.47
- 2.268
- 2.104
- 1.979
- 2.201
- 1.792
- 1.726
- 1.656
- 1.603
- 1.563
- 1.522
- 1.222
- 1.449
- 1.41
- 1.375
- 1.578
- 1.333
- 1.309
- 1.286
- 1.261
- 1.046
- 1.029
- 1.22
- 1.204
- 1.378
- 1.174
- 0.971
- 1.148
- 1.138
- 1.314
- 0.932
- 0.92
- 1.094
- 1.097
- 0.901
- 0.908
- 1.054
- 1.063
- 0.876
- 1.209
- 1.199
- 1.19
- 1.179
- 1.185
- 1.172
- 1.163
- 1.002
- 0.992
- 0.996
- 0.831
- 0.983
- 0.819
- 0.965
- 0.956
- 0.963
- 1.106
- 0.8
- 0.953
- 0.939
- 0.787
- 0.782
- 0.783
- 0.93
- 0.922
- 0.923
- 0.919
- 0.914
- 0.917
- 1.051
- 0.763
- 1.046
- 0.763
- 0.9
- 1.045
- 0.753
- 0.749
- 0.743
- 0.88
- 1.022
- 0.883
- 1.023
- 0.879
- 0.873
- 0.735
- 0.88
- 1.009
- 0.729
- 0.864
- 0.854
- 0.855
- 0.855
- 0.717
- 0.718
- 0.991
- 0.852
- 0.852
unequal: 0
verbose: 1
