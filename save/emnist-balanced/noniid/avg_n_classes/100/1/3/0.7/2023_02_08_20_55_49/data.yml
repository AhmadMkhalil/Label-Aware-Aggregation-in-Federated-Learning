avg_train_accuracy: 0.812
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03547872340425532
- 0.0673404255319149
- 0.12781914893617022
- 0.22957446808510637
- 0.3350531914893617
- 0.42271276595744683
- 0.4714893617021277
- 0.5111170212765958
- 0.5362234042553191
- 0.5604255319148936
- 0.5718617021276595
- 0.5876063829787234
- 0.5951595744680851
- 0.6124468085106383
- 0.6182978723404255
- 0.629468085106383
- 0.6392021276595745
- 0.6458510638297872
- 0.6518617021276596
- 0.6579255319148937
- 0.6663297872340426
- 0.6691489361702128
- 0.6732978723404255
- 0.678031914893617
- 0.6825
- 0.6873404255319149
- 0.6912234042553191
- 0.6941489361702128
- 0.6946808510638298
- 0.6976595744680851
- 0.7004255319148937
- 0.7040425531914893
- 0.7048936170212766
- 0.706063829787234
- 0.7092553191489361
- 0.7134574468085106
- 0.7162234042553192
- 0.7171276595744681
- 0.7167553191489362
- 0.7186170212765958
- 0.7190425531914894
- 0.7225531914893617
- 0.7239361702127659
- 0.7247872340425532
- 0.728404255319149
- 0.7267553191489362
- 0.729468085106383
- 0.7302127659574468
- 0.7312765957446808
- 0.7304787234042553
- 0.7327659574468085
- 0.7345744680851064
- 0.7350531914893617
- 0.7351595744680851
- 0.7361702127659574
- 0.7362765957446809
- 0.7386170212765958
- 0.7401063829787234
- 0.7416489361702128
- 0.740531914893617
- 0.7394148936170213
- 0.7414893617021276
- 0.7417021276595744
- 0.7452659574468085
- 0.7429255319148936
- 0.7444148936170213
- 0.7446808510638298
- 0.7466489361702128
- 0.745904255319149
- 0.7482446808510639
- 0.7489893617021277
- 0.7478191489361702
- 0.7488297872340426
- 0.7478191489361702
- 0.7493085106382978
- 0.7500531914893617
- 0.7525
- 0.7511702127659574
- 0.7531382978723404
- 0.7521808510638298
- 0.7510106382978723
- 0.7538297872340426
- 0.7537765957446808
- 0.7540425531914894
- 0.755
- 0.7554787234042554
- 0.7556382978723404
- 0.7559574468085106
- 0.7573404255319149
- 0.7572340425531915
- 0.7587234042553191
- 0.7573936170212766
- 0.757127659574468
- 0.7562765957446809
- 0.7584574468085107
- 0.7590957446808511
- 0.7586702127659575
- 0.7607446808510638
- 0.760904255319149
- 0.7595744680851064
test_loss_list:
- 3.780117925008138
- 3.7362330881754557
- 3.615150286356608
- 3.3411893049875894
- 2.9828029600779216
- 2.655535265604655
- 2.3920616785685223
- 2.2057915512720743
- 2.054730281829834
- 1.9782219394048055
- 1.870786968866984
- 1.840039930343628
- 1.7747540521621703
- 1.7582266648610434
- 1.6915496810277304
- 1.6807015784581503
- 1.6184557930628458
- 1.6161773490905762
- 1.562219950358073
- 1.5510794401168824
- 1.5348418919245401
- 1.4856798124313355
- 1.475558902422587
- 1.471526985168457
- 1.470377378463745
- 1.4218191989262898
- 1.4259176365534465
- 1.4099682982762654
- 1.4004185899098713
- 1.3751688385009766
- 1.3577534914016725
- 1.3472695191701254
- 1.323942076365153
- 1.3144387420018513
- 1.337212994893392
- 1.31195156733195
- 1.2821144374211628
- 1.2829585107167563
- 1.284372386932373
- 1.2586906989415487
- 1.2666477235158284
- 1.2726970156033834
- 1.252062215010325
- 1.2541127212842305
- 1.2306995956103006
- 1.2251317683855694
- 1.2608766380945842
- 1.2683181810379027
- 1.2585650126139323
- 1.2293310109774271
- 1.2197155984242758
- 1.1930352354049683
- 1.2004130943616231
- 1.2011210385958353
- 1.180296847820282
- 1.1585057838757833
- 1.1769558612505595
- 1.1738389865557353
- 1.1654471492767333
- 1.1743694106737772
- 1.151234852472941
- 1.1576295828819274
- 1.137344150543213
- 1.1287229291598002
- 1.131971356868744
- 1.1174928641319275
- 1.1255651704470317
- 1.1187677892049153
- 1.1125163586934408
- 1.1253175290425619
- 1.113691624800364
- 1.0885029562314352
- 1.1240205232302347
- 1.1141358168919882
- 1.1026197123527526
- 1.0955631025632222
- 1.11305699189504
- 1.0926942737897236
- 1.0747663291295368
- 1.0870956428845724
- 1.067017372449239
- 1.0971064766248066
- 1.0818069569269817
- 1.1039186453819274
- 1.077887418270111
- 1.0778125421206157
- 1.0923395737012227
- 1.094174473285675
- 1.071863849957784
- 1.0577001516024271
- 1.090097869237264
- 1.0666089566548664
- 1.048315207163493
- 1.0281172180175782
- 1.044849885304769
- 1.0389970930417378
- 1.0282189297676085
- 1.055944159825643
- 1.049927954673767
- 1.0346526781717935
train_accuracy:
- 0.0
- 0.067
- 0.15
- 0.256
- 0.365
- 0.473
- 0.508
- 0.531
- 0.575
- 0.61
- 0.0
- 0.0
- 0.585
- 0.0
- 0.648
- 0.685
- 0.0
- 0.69
- 0.0
- 0.685
- 0.692
- 0.685
- 0.737
- 0.715
- 0.719
- 0.71
- 0.727
- 0.721
- 0.721
- 0.0
- 0.0
- 0.0
- 0.777
- 0.0
- 0.752
- 0.737
- 0.792
- 0.74
- 0.75
- 0.777
- 0.756
- 0.767
- 0.763
- 0.0
- 0.767
- 0.0
- 0.756
- 0.765
- 0.754
- 0.765
- 0.79
- 0.771
- 0.0
- 0.0
- 0.769
- 0.792
- 0.752
- 0.767
- 0.765
- 0.0
- 0.779
- 0.773
- 0.765
- 0.81
- 0.798
- 0.787
- 0.0
- 0.775
- 0.806
- 0.779
- 0.808
- 0.0
- 0.81
- 0.783
- 0.804
- 0.783
- 0.781
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.787
- 0.0
- 0.0
- 0.802
- 0.821
- 0.0
- 0.812
- 0.8
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.804
- 0.787
- 0.812
train_loss:
- 2.825
- 2.832
- 2.301
- 2.645
- 2.002
- 2.239
- 2.047
- 2.251
- 1.458
- 1.709
- 1.339
- 1.831
- 1.243
- 1.726
- 1.179
- 1.393
- 1.135
- 1.548
- 1.097
- 1.27
- 1.259
- 1.034
- 1.01
- 1.205
- 1.38
- 0.979
- 1.15
- 1.145
- 1.133
- 0.937
- 0.918
- 0.911
- 0.906
- 0.903
- 1.234
- 1.056
- 0.87
- 0.876
- 1.02
- 0.849
- 1.02
- 1.164
- 0.994
- 0.99
- 0.836
- 0.979
- 1.293
- 1.275
- 1.111
- 0.951
- 0.95
- 0.807
- 0.938
- 0.934
- 0.928
- 0.772
- 0.917
- 0.924
- 0.914
- 0.914
- 0.906
- 0.913
- 0.898
- 0.767
- 0.888
- 0.748
- 0.891
- 0.894
- 0.886
- 0.89
- 0.875
- 0.741
- 1.005
- 0.87
- 0.873
- 0.871
- 1.004
- 0.858
- 0.718
- 0.85
- 0.707
- 0.987
- 0.845
- 0.979
- 0.849
- 0.852
- 0.965
- 0.965
- 0.845
- 0.696
- 0.967
- 0.83
- 0.688
- 0.679
- 0.818
- 0.827
- 0.688
- 0.945
- 0.822
- 0.82
unequal: 0
verbose: 1
