avg_train_accuracy: 0.825
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.032872340425531915
- 0.04776595744680851
- 0.1376063829787234
- 0.24058510638297873
- 0.32085106382978723
- 0.41819148936170214
- 0.4736170212765957
- 0.5071808510638298
- 0.5398404255319149
- 0.560372340425532
- 0.5799468085106383
- 0.5944680851063829
- 0.6067021276595744
- 0.6140425531914894
- 0.6289361702127659
- 0.6376595744680851
- 0.6474468085106383
- 0.6519680851063829
- 0.6553191489361702
- 0.6633510638297873
- 0.6737765957446809
- 0.6752127659574468
- 0.6823936170212765
- 0.6843085106382979
- 0.6836702127659574
- 0.6937765957446809
- 0.6963297872340426
- 0.7021808510638298
- 0.6989893617021277
- 0.7049468085106383
- 0.705
- 0.7084574468085106
- 0.7131914893617022
- 0.7163829787234043
- 0.709627659574468
- 0.7185106382978723
- 0.7204787234042553
- 0.722872340425532
- 0.7262234042553192
- 0.7273404255319149
- 0.7274468085106383
- 0.7319148936170212
- 0.7313829787234043
- 0.7311170212765957
- 0.7358510638297873
- 0.735
- 0.733563829787234
- 0.7336702127659575
- 0.7389361702127659
- 0.7411170212765957
- 0.7338297872340426
- 0.7439893617021277
- 0.7420212765957447
- 0.7438297872340426
- 0.7425
- 0.7443617021276596
- 0.7417021276595744
- 0.7486170212765958
- 0.24691489361702126
- 0.7420212765957447
- 0.7438297872340426
- 0.7477127659574468
- 0.745531914893617
- 0.7476063829787234
- 0.7495212765957446
- 0.747872340425532
- 0.7434042553191489
- 0.7515425531914893
- 0.7497340425531915
- 0.749095744680851
- 0.33393617021276595
- 0.7476595744680851
- 0.7503723404255319
- 0.7473404255319149
- 0.7506382978723404
- 0.7523936170212766
- 0.7520212765957447
- 0.7548404255319149
- 0.7542021276595745
- 0.5751595744680851
- 0.7548936170212766
- 0.7499468085106383
- 0.7539893617021277
- 0.7531914893617021
- 0.7560106382978723
- 0.7562765957446809
- 0.7582978723404256
- 0.7575531914893617
- 0.7603191489361703
- 0.7595744680851064
- 0.7611702127659574
- 0.7617021276595745
- 0.7610638297872341
- 0.760531914893617
- 0.7617553191489361
- 0.7572340425531915
- 0.7595744680851064
- 0.7636170212765957
- 0.7589361702127659
- 0.7599468085106383
test_loss_list:
- 3.7813354301452637
- 3.730258118311564
- 3.6089420096079508
- 3.328522968292236
- 2.9638952255249023
- 2.6313552888234457
- 2.39652818997701
- 2.21808501402537
- 2.091529420216878
- 2.0154614432652793
- 1.9500120798746745
- 1.8981156301498414
- 1.8357366450627646
- 1.8207444365819294
- 1.7791539843877155
- 1.754736558596293
- 1.7377964019775392
- 1.7174543221791585
- 1.6993687963485717
- 1.6648949988683064
- 1.617043752670288
- 1.6313647476832072
- 1.6175266377131143
- 1.585597701072693
- 1.571154777208964
- 1.5769598309199016
- 1.5804346481959024
- 1.5727807490030925
- 1.574176665941874
- 1.5182578833897908
- 1.5189625533421833
- 1.5347304821014405
- 1.519322264989217
- 1.5276791206995646
- 1.496250613530477
- 1.4749371592203777
- 1.456274692217509
- 1.4614314381281535
- 1.4730322933197022
- 1.453336278597514
- 1.4410267480214436
- 1.4324407227834066
- 1.4634893941879272
- 1.4311404625574748
- 1.4402056709925333
- 1.4301155233383178
- 1.4269667991002402
- 1.4345110114415487
- 1.4313826926549276
- 1.4086383199691772
- 1.4098465061187744
- 1.4018239609400431
- 1.4095288403828938
- 1.4173719183603923
- 1.3826055606206258
- 1.390974866549174
- 1.337993590037028
- 1.380705540974935
- 3.175103899637858
- 1.10002734820048
- 1.1555194981892905
- 1.1792060804367066
- 1.1895569705963134
- 1.181521203517914
- 1.1904151423772176
- 1.212014667193095
- 1.1829004724820456
- 1.2146093996365865
- 1.1997884472211202
- 1.186531351407369
- 2.648954203923543
- 0.9945256082216899
- 1.0324119130770366
- 1.048765669663747
- 1.0580573058128357
- 1.0760069584846497
- 1.0751987012227375
- 1.1061375268300375
- 1.107727760473887
- 1.4773966932296754
- 0.9286193029085795
- 0.9660956509908041
- 0.98179181655248
- 0.996355546315511
- 1.000735870997111
- 1.0158603588740032
- 1.028715536594391
- 1.037604377269745
- 1.0196943116188049
- 1.040758900642395
- 1.0569377303123475
- 1.0691314991315206
- 1.0610752153396605
- 1.0540496762593587
- 1.077376716931661
- 1.0514055148760477
- 1.0640058247248332
- 1.0597042751312256
- 1.0546389015515645
- 1.037345950603485
train_accuracy:
- 0.035
- 0.0
- 0.158
- 0.288
- 0.352
- 0.0
- 0.513
- 0.577
- 0.596
- 0.638
- 0.0
- 0.629
- 0.694
- 0.0
- 0.696
- 0.694
- 0.702
- 0.725
- 0.71
- 0.76
- 0.0
- 0.74
- 0.742
- 0.0
- 0.0
- 0.76
- 0.756
- 0.756
- 0.0
- 0.0
- 0.781
- 0.779
- 0.781
- 0.802
- 0.752
- 0.0
- 0.0
- 0.763
- 0.775
- 0.79
- 0.0
- 0.8
- 0.767
- 0.808
- 0.792
- 0.0
- 0.0
- 0.798
- 0.787
- 0.798
- 0.0
- 0.785
- 0.787
- 0.812
- 0.792
- 0.835
- 0.812
- 0.0
- 0.946
- 0.0
- 0.0
- 0.808
- 0.812
- 0.0
- 0.804
- 0.783
- 0.0
- 0.808
- 0.794
- 0.0
- 0.938
- 0.838
- 0.0
- 0.0
- 0.0
- 0.804
- 0.0
- 0.806
- 0.798
- 0.923
- 0.838
- 0.0
- 0.842
- 0.798
- 0.821
- 0.0
- 0.835
- 0.0
- 0.825
- 0.817
- 0.844
- 0.844
- 0.84
- 0.0
- 0.81
- 0.821
- 0.0
- 0.856
- 0.0
- 0.825
train_loss:
- 3.845
- 1.615
- 3.732
- 3.559
- 2.29
- 2.073
- 2.756
- 1.793
- 2.39
- 1.597
- 1.544
- 2.092
- 1.444
- 1.386
- 1.928
- 1.861
- 1.842
- 1.796
- 1.269
- 1.244
- 1.248
- 1.663
- 1.638
- 1.19
- 0.753
- 1.596
- 1.54
- 1.543
- 1.107
- 1.11
- 1.088
- 1.476
- 1.476
- 1.422
- 0.67
- 1.036
- 1.032
- 0.995
- 1.373
- 0.977
- 1.0
- 0.995
- 1.311
- 1.027
- 1.348
- 1.002
- 0.961
- 0.919
- 1.302
- 0.992
- 0.608
- 1.31
- 0.917
- 1.239
- 0.9
- 1.266
- 0.639
- 0.943
- 0.314
- 0.525
- 0.892
- 1.228
- 0.906
- 0.9
- 0.902
- 1.206
- 0.546
- 1.214
- 0.879
- 0.555
- 0.223
- 0.872
- 0.483
- 0.51
- 0.507
- 0.855
- 0.829
- 1.136
- 1.134
- 0.193
- 1.197
- 0.464
- 0.779
- 0.461
- 0.831
- 0.772
- 1.148
- 0.809
- 0.819
- 1.117
- 1.122
- 1.112
- 0.809
- 0.826
- 1.09
- 0.502
- 0.819
- 0.783
- 0.481
- 0.813
unequal: 0
verbose: 1
