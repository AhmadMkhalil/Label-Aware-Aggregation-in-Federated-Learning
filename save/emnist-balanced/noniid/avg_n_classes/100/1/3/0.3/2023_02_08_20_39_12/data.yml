avg_train_accuracy: 0.798
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037127659574468085
- 0.07037234042553192
- 0.12388297872340426
- 0.20175531914893616
- 0.31627659574468087
- 0.4092021276595745
- 0.4626595744680851
- 0.5028191489361702
- 0.5275531914893618
- 0.5598404255319149
- 0.5743085106382979
- 0.5863829787234043
- 0.6064893617021276
- 0.6120212765957447
- 0.6238297872340426
- 0.6306382978723404
- 0.0901063829787234
- 0.619468085106383
- 0.6398936170212766
- 0.6497340425531914
- 0.6588829787234043
- 0.6563297872340426
- 0.6628723404255319
- 0.673936170212766
- 0.6787765957446809
- 0.6839893617021277
- 0.6882978723404255
- 0.6927127659574468
- 0.6999468085106383
- 0.6909042553191489
- 0.6955851063829788
- 0.7017021276595745
- 0.7073936170212766
- 0.7115957446808511
- 0.7098404255319148
- 0.4194148936170213
- 0.7163829787234043
- 0.7195744680851064
- 0.7230851063829787
- 0.7206382978723405
- 0.7179787234042553
- 0.7229787234042553
- 0.7263829787234043
- 0.7236170212765958
- 0.7275
- 0.7273404255319149
- 0.7312234042553192
- 0.7303723404255319
- 0.7336702127659575
- 0.7243085106382978
- 0.7328191489361702
- 0.7345744680851064
- 0.7345212765957447
- 0.7301063829787234
- 0.7302659574468086
- 0.737659574468085
- 0.7395212765957446
- 0.7361170212765957
- 0.7318617021276596
- 0.7345212765957447
- 0.7422872340425531
- 0.7434042553191489
- 0.7427659574468085
- 0.7435106382978723
- 0.7466489361702128
- 0.7466489361702128
- 0.7425
- 0.7453723404255319
- 0.7493617021276596
- 0.7476063829787234
- 0.7504787234042554
- 0.749095744680851
- 0.7493617021276596
- 0.7495744680851064
- 0.7502659574468085
- 0.7462765957446809
- 0.7520744680851064
- 0.7521808510638298
- 0.7545744680851064
- 0.754095744680851
- 0.7506914893617022
- 0.7563297872340425
- 0.7538829787234043
- 0.755531914893617
- 0.756968085106383
- 0.756968085106383
- 0.7578191489361702
- 0.758563829787234
- 0.759468085106383
- 0.7585106382978724
- 0.76
- 0.7577659574468085
- 0.7612234042553192
- 0.7572872340425532
- 0.7608510638297873
- 0.7597872340425532
- 0.763563829787234
- 0.7627659574468085
- 0.7602659574468085
- 0.7604255319148936
test_loss_list:
- 3.770935379664103
- 3.7148365847269695
- 3.5903307596842446
- 3.308204288482666
- 2.959903685251872
- 2.6282475630442304
- 2.3818380705515545
- 2.217756288846334
- 2.0818713410695393
- 2.00273454507192
- 1.9289079046249389
- 1.869084448814392
- 1.8289925161997478
- 1.787221302986145
- 1.7547573471069335
- 1.722813229560852
- 4.618583552042643
- 1.5309262148539224
- 1.5421519009272258
- 1.5198305702209474
- 1.5094857327143352
- 1.4948919169108073
- 1.4709459161758422
- 1.4601897128423056
- 1.4590092738469442
- 1.4543015400568644
- 1.4345691935221354
- 1.4341209570566813
- 1.4355813535054525
- 1.4116171630223593
- 1.3777727858225504
- 1.370860824584961
- 1.3704522148768108
- 1.3554053767522176
- 1.3578085978825887
- 1.8917205874125163
- 1.1561010471979778
- 1.1996508558591208
- 1.204326577981313
- 1.2075558718045551
- 1.2171244271596273
- 1.208688670794169
- 1.2192624719937641
- 1.2077087036768595
- 1.2153018426895141
- 1.2060323198636373
- 1.191291139125824
- 1.213749717871348
- 1.2157211804389954
- 1.2007423535982769
- 1.1790462191899618
- 1.1977668166160584
- 1.1905914457639057
- 1.1815183607737223
- 1.193425269126892
- 1.1560302503903708
- 1.1513305672009786
- 1.1584993052482604
- 1.1663224252065023
- 1.1478478797276814
- 1.1474902478853861
- 1.1478933048248292
- 1.1385984897613526
- 1.1555132007598876
- 1.1310903509457906
- 1.1681289021174113
- 1.1171805302302042
- 1.1529093980789185
- 1.15284810145696
- 1.1431300870577494
- 1.154427715142568
- 1.1659864886601765
- 1.1294055104255676
- 1.1667125312487285
- 1.1569559208552043
- 1.1361584051450093
- 1.144632753531138
- 1.1400786932309468
- 1.1337691497802735
- 1.143541878859202
- 1.1238963468869527
- 1.13678111632665
- 1.1245720942815145
- 1.1281127580006918
- 1.1399133547147116
- 1.1162194021542866
- 1.1218667507171631
- 1.116430459022522
- 1.1494361408551534
- 1.1437114342053731
- 1.1237919131914775
- 1.1223938822746278
- 1.1316115991274516
- 1.1263319738705952
- 1.1415851640701293
- 1.1235684927304586
- 1.123919817606608
- 1.1280143729845682
- 1.1314058844248454
- 1.1181586384773254
train_accuracy:
- 0.029
- 0.073
- 0.15
- 0.0
- 0.308
- 0.402
- 0.483
- 0.535
- 0.54
- 0.608
- 0.0
- 0.0
- 0.65
- 0.64
- 0.683
- 0.698
- 0.971
- 0.0
- 0.698
- 0.679
- 0.71
- 0.0
- 0.0
- 0.702
- 0.673
- 0.723
- 0.744
- 0.694
- 0.698
- 0.0
- 0.0
- 0.71
- 0.746
- 0.765
- 0.771
- 0.733
- 0.737
- 0.717
- 0.729
- 0.765
- 0.773
- 0.781
- 0.725
- 0.0
- 0.775
- 0.781
- 0.0
- 0.0
- 0.777
- 0.771
- 0.777
- 0.0
- 0.796
- 0.773
- 0.8
- 0.0
- 0.792
- 0.802
- 0.0
- 0.0
- 0.781
- 0.0
- 0.81
- 0.777
- 0.0
- 0.794
- 0.0
- 0.815
- 0.785
- 0.777
- 0.808
- 0.783
- 0.0
- 0.783
- 0.0
- 0.0
- 0.0
- 0.783
- 0.796
- 0.806
- 0.792
- 0.806
- 0.812
- 0.779
- 0.781
- 0.0
- 0.808
- 0.0
- 0.787
- 0.796
- 0.804
- 0.804
- 0.808
- 0.0
- 0.8
- 0.804
- 0.802
- 0.806
- 0.0
- 0.798
train_loss:
- 2.652
- 3.797
- 3.719
- 1.391
- 3.287
- 3.021
- 1.888
- 1.799
- 0.961
- 1.616
- 1.533
- 1.51
- 2.034
- 2.0
- 1.938
- 1.337
- 0.262
- 0.718
- 1.281
- 1.24
- 1.724
- 0.712
- 0.714
- 1.171
- 1.629
- 1.6
- 1.107
- 1.57
- 1.557
- 0.657
- 0.653
- 0.658
- 1.075
- 1.048
- 1.043
- 0.227
- 1.544
- 1.423
- 1.399
- 0.984
- 0.984
- 1.377
- 1.372
- 0.958
- 0.947
- 0.944
- 0.973
- 0.932
- 1.298
- 0.564
- 0.559
- 0.912
- 0.912
- 0.539
- 0.567
- 0.552
- 0.875
- 0.897
- 0.533
- 0.574
- 0.885
- 0.867
- 0.89
- 0.876
- 0.885
- 1.224
- 0.55
- 0.857
- 1.208
- 0.847
- 1.194
- 1.162
- 0.541
- 1.189
- 0.835
- 0.534
- 0.846
- 0.845
- 1.166
- 1.154
- 0.528
- 0.816
- 0.814
- 0.822
- 1.146
- 0.843
- 1.133
- 0.814
- 1.132
- 0.814
- 0.808
- 0.818
- 1.121
- 0.503
- 1.119
- 0.81
- 0.828
- 0.797
- 0.793
- 0.798
unequal: 0
verbose: 1
