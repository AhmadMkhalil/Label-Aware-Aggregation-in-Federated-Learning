avg_train_accuracy: 0.819
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03409574468085107
- 0.04398936170212766
- 0.08047872340425533
- 0.1702659574468085
- 0.28404255319148936
- 0.38207446808510637
- 0.4617553191489362
- 0.49079787234042555
- 0.5275
- 0.546063829787234
- 0.5642553191489361
- 0.5888829787234042
- 0.6026063829787234
- 0.6135106382978723
- 0.6214893617021277
- 0.6213297872340425
- 0.6352659574468085
- 0.648031914893617
- 0.6503723404255319
- 0.6636170212765957
- 0.6673404255319149
- 0.6725
- 0.6777127659574468
- 0.6857978723404256
- 0.6934574468085106
- 0.691595744680851
- 0.7013297872340426
- 0.7022340425531914
- 0.7008510638297872
- 0.7037234042553191
- 0.7107978723404256
- 0.7142021276595745
- 0.7139893617021277
- 0.7179787234042553
- 0.7245744680851064
- 0.7221808510638298
- 0.73
- 0.7275
- 0.7305851063829787
- 0.7322340425531915
- 0.7287234042553191
- 0.7348404255319149
- 0.735
- 0.7397340425531915
- 0.7383510638297872
- 0.7404787234042554
- 0.7428191489361702
- 0.7425531914893617
- 0.739095744680851
- 0.7437765957446808
- 0.7459574468085106
- 0.7461170212765957
- 0.7467553191489362
- 0.7488297872340426
- 0.7475
- 0.7485106382978723
- 0.748563829787234
- 0.7506914893617022
- 0.7527659574468085
- 0.7526595744680851
- 0.7481382978723404
- 0.7511170212765957
- 0.753563829787234
- 0.7561170212765957
- 0.754095744680851
- 0.7497340425531915
- 0.7503191489361702
- 0.7567553191489361
- 0.7578191489361702
- 0.7575531914893617
- 0.7590425531914894
- 0.7579787234042553
- 0.76
- 0.7592021276595745
- 0.760531914893617
- 0.762340425531915
- 0.7587765957446808
- 0.7613297872340425
- 0.7612765957446809
- 0.7626595744680851
- 0.7601063829787233
- 0.7582446808510638
- 0.7629255319148937
- 0.7623936170212766
- 0.766436170212766
- 0.7625
- 0.7629787234042553
- 0.7621808510638298
- 0.7660638297872341
- 0.7670212765957447
- 0.7638297872340426
- 0.7665425531914893
- 0.7627127659574469
- 0.7653191489361703
- 0.7632446808510638
- 0.7681382978723404
- 0.7678723404255319
- 0.7541489361702127
- 0.766436170212766
- 0.7703191489361703
test_loss_list:
- 3.790598815282186
- 3.7640107663472495
- 3.704536641438802
- 3.5301148796081545
- 3.187171376546224
- 2.829475975036621
- 2.571703255971273
- 2.3606122016906737
- 2.2205692021052044
- 2.0956599712371826
- 1.9958942095438639
- 1.9179544512430826
- 1.8666918563842774
- 1.8217284965515137
- 1.7803094879786174
- 1.739369576772054
- 1.685248344739278
- 1.6639436864852906
- 1.635915509859721
- 1.6099649731318155
- 1.603065554300944
- 1.5697041861216228
- 1.5487553024291991
- 1.553231430053711
- 1.5351699272791544
- 1.496190422375997
- 1.5138630533218385
- 1.4887470356623331
- 1.4764297310511272
- 1.468594079017639
- 1.453864132563273
- 1.4638138214747112
- 1.4249839401245117
- 1.4237116893132529
- 1.419788467089335
- 1.3889743455251058
- 1.3985072565078736
- 1.402705257733663
- 1.3841143576304118
- 1.3779785998662313
- 1.372836004892985
- 1.3907480557759604
- 1.3866304206848143
- 1.396537750562032
- 1.3821290270487467
- 1.377623880704244
- 1.38087686697642
- 1.3840558910369873
- 1.3776849826176962
- 1.355557386080424
- 1.3424118534723917
- 1.3514657386144002
- 1.3607814693450928
- 1.3533654308319092
- 1.331447274684906
- 1.3636437209447225
- 1.3690241607030234
- 1.3295580021540323
- 1.322352910041809
- 1.3260436042149861
- 1.3098574304580688
- 1.3349431943893433
- 1.3083230193456015
- 1.3046978569030763
- 1.300995979309082
- 1.278947462240855
- 1.2864840825398762
- 1.2714396905899048
- 1.2839689962069194
- 1.271705482006073
- 1.2784455728530884
- 1.2632876960436503
- 1.2803619996706646
- 1.25005730231603
- 1.2551033131281535
- 1.2717304229736328
- 1.2416420324643453
- 1.2470658866564432
- 1.2695937450726826
- 1.2465349213282266
- 1.2573700404167176
- 1.2348171838124593
- 1.2175357548395793
- 1.2325282104810078
- 1.2450141938527426
- 1.2457685740788778
- 1.2328483700752257
- 1.2192957139015197
- 1.2184965666135152
- 1.2206355516115825
- 1.2182579596837362
- 1.2447363615036011
- 1.220198860168457
- 1.210699733098348
- 1.2222340210278828
- 1.1955165719985963
- 1.2427441533406576
- 1.207118825117747
- 1.216465167204539
- 1.2215481774012247
train_accuracy:
- 0.0
- 0.0
- 0.083
- 0.177
- 0.285
- 0.44
- 0.519
- 0.0
- 0.567
- 0.596
- 0.581
- 0.617
- 0.64
- 0.0
- 0.0
- 0.662
- 0.0
- 0.735
- 0.0
- 0.706
- 0.723
- 0.742
- 0.737
- 0.752
- 0.76
- 0.0
- 0.767
- 0.758
- 0.0
- 0.0
- 0.0
- 0.775
- 0.76
- 0.781
- 0.796
- 0.0
- 0.0
- 0.806
- 0.775
- 0.0
- 0.0
- 0.785
- 0.798
- 0.806
- 0.0
- 0.804
- 0.821
- 0.794
- 0.0
- 0.794
- 0.792
- 0.823
- 0.0
- 0.79
- 0.787
- 0.794
- 0.817
- 0.8
- 0.796
- 0.825
- 0.0
- 0.806
- 0.812
- 0.833
- 0.835
- 0.796
- 0.0
- 0.827
- 0.802
- 0.804
- 0.0
- 0.815
- 0.821
- 0.835
- 0.0
- 0.829
- 0.0
- 0.8
- 0.821
- 0.8
- 0.833
- 0.0
- 0.823
- 0.815
- 0.838
- 0.815
- 0.815
- 0.835
- 0.0
- 0.808
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.835
- 0.825
- 0.0
- 0.0
- 0.819
train_loss:
- 1.629
- 1.636
- 3.787
- 3.683
- 2.39
- 2.17
- 2.908
- 1.85
- 2.518
- 1.666
- 1.572
- 1.515
- 2.089
- 1.416
- 1.386
- 0.776
- 0.769
- 1.293
- 1.265
- 1.234
- 1.216
- 1.218
- 1.173
- 1.634
- 1.593
- 1.114
- 1.549
- 1.08
- 0.702
- 0.675
- 1.077
- 1.442
- 0.655
- 1.041
- 1.407
- 0.645
- 1.017
- 1.37
- 1.011
- 0.991
- 0.624
- 1.319
- 1.317
- 1.3
- 0.948
- 1.29
- 1.273
- 1.262
- 0.939
- 0.928
- 0.925
- 0.887
- 0.873
- 1.242
- 0.89
- 1.204
- 1.207
- 0.93
- 0.905
- 0.9
- 0.573
- 0.897
- 0.896
- 1.199
- 0.887
- 0.574
- 0.558
- 0.892
- 0.866
- 0.858
- 0.851
- 0.843
- 1.159
- 0.551
- 0.83
- 1.136
- 0.527
- 0.86
- 1.14
- 0.848
- 0.84
- 0.559
- 0.839
- 0.849
- 1.114
- 0.828
- 0.81
- 0.836
- 0.825
- 0.803
- 0.798
- 1.11
- 0.534
- 0.798
- 0.799
- 0.826
- 1.079
- 0.514
- 0.814
- 1.08
unequal: 0
verbose: 1
