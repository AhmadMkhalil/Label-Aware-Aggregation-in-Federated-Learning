avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03691489361702128
- 0.054627659574468086
- 0.13808510638297872
- 0.21781914893617021
- 0.3382978723404255
- 0.4220212765957447
- 0.49638297872340426
- 0.5331382978723405
- 0.5648404255319149
- 0.5882978723404255
- 0.6020744680851063
- 0.620904255319149
- 0.6301063829787235
- 0.6443617021276595
- 0.6534574468085106
- 0.665904255319149
- 0.6732446808510638
- 0.6754255319148936
- 0.6843085106382979
- 0.6876595744680851
- 0.6936170212765957
- 0.6954255319148936
- 0.6947872340425532
- 0.7026595744680851
- 0.7035106382978723
- 0.7125531914893617
- 0.6994148936170212
- 0.7175531914893617
- 0.7221276595744681
- 0.721063829787234
- 0.7138297872340426
- 0.7229255319148936
- 0.7275531914893617
- 0.7265425531914894
- 0.7323936170212766
- 0.5699468085106383
- 0.7231382978723404
- 0.7336702127659575
- 0.737659574468085
- 0.7356382978723405
- 0.738031914893617
- 0.7377659574468085
- 0.7412765957446809
- 0.7407978723404255
- 0.7380851063829788
- 0.7423936170212766
- 0.7423404255319149
- 0.7457446808510638
- 0.7439893617021277
- 0.7379255319148936
- 0.7447872340425532
- 0.7463829787234042
- 0.7490425531914894
- 0.7498404255319149
- 0.7512765957446809
- 0.7453723404255319
- 0.7507446808510638
- 0.752127659574468
- 0.7538829787234043
- 0.7506382978723404
- 0.7448936170212765
- 0.7538829787234043
- 0.7511170212765957
- 0.754095744680851
- 0.7517021276595744
- 0.7595744680851064
- 0.7553723404255319
- 0.7603191489361703
- 0.7590425531914894
- 0.7547872340425532
- 0.7605851063829787
- 0.759468085106383
- 0.7599468085106383
- 0.6810106382978723
- 0.760904255319149
- 0.758563829787234
- 0.7604255319148936
- 0.7629255319148937
- 0.7586702127659575
- 0.7587765957446808
- 0.7643085106382979
- 0.7570744680851064
- 0.7641489361702127
- 0.7639893617021276
- 0.7638297872340426
- 0.764468085106383
- 0.7642553191489362
- 0.7608510638297873
- 0.7637765957446808
- 0.7667021276595745
- 0.7627659574468085
- 0.7651063829787234
- 0.7661170212765958
- 0.7662234042553191
- 0.7628723404255319
- 0.7592021276595745
- 0.765
- 0.7691489361702127
- 0.7662765957446809
- 0.7667021276595745
test_loss_list:
- 3.7822951825459796
- 3.754925775527954
- 3.683510522842407
- 3.498220952351888
- 3.135072011947632
- 2.7508630243937175
- 2.4473140875498456
- 2.240372381210327
- 2.077916630109151
- 1.9836618852615358
- 1.9130303144454956
- 1.8545906813939412
- 1.7823995558420818
- 1.7474637174606322
- 1.7177637354532878
- 1.6776712560653686
- 1.6411373583475748
- 1.6139347664515178
- 1.6189560906092326
- 1.5985416428248087
- 1.579981943766276
- 1.5575428660710653
- 1.5354011869430542
- 1.535771632194519
- 1.5235402488708496
- 1.5282608540852864
- 1.519974373181661
- 1.4951941823959352
- 1.4881498177846273
- 1.4965997012456258
- 1.4702842156092326
- 1.44785528977712
- 1.4703148285547891
- 1.4407111978530884
- 1.4387608655293782
- 1.5354125579198201
- 1.1711181974411011
- 1.2278472836812337
- 1.229828679561615
- 1.2591270351409911
- 1.2470287346839906
- 1.2587587420145672
- 1.2606300862630209
- 1.2479902942975363
- 1.2361197543144227
- 1.2354381163914998
- 1.264493498802185
- 1.247739930152893
- 1.2300715708732606
- 1.2391353543599446
- 1.2378180774052938
- 1.2321799683570862
- 1.2180170528093974
- 1.2294117871920267
- 1.217037692864736
- 1.240702699025472
- 1.233245579401652
- 1.2205705006917318
- 1.2298501451810202
- 1.2374849828084309
- 1.2305072951316833
- 1.2333008615175882
- 1.2118864393234252
- 1.2148551893234254
- 1.2179385781288148
- 1.2361287069320679
- 1.2379647588729858
- 1.2229296000798544
- 1.228010454972585
- 1.2168199880917867
- 1.2166897813479105
- 1.2073786687850951
- 1.1876767659187317
- 1.133881565729777
- 0.9719668086369833
- 1.0209045934677123
- 1.0279034304618835
- 1.0418623614311218
- 1.0784863837560017
- 1.0625638302167257
- 1.06914159933726
- 1.0902128791809083
- 1.0866770402590433
- 1.0975434033075968
- 1.1054490558306376
- 1.0664838298161825
- 1.108154332637787
- 1.086676520506541
- 1.1006342180569966
- 1.1159143654505412
- 1.100409746170044
- 1.128550587495168
- 1.1098380231857299
- 1.119223546187083
- 1.0914594721794129
- 1.1082851266860962
- 1.1056486256917317
- 1.0992666188875835
- 1.1069192632039389
- 1.0908063093821208
train_accuracy:
- 0.04
- 0.067
- 0.16
- 0.229
- 0.367
- 0.427
- 0.552
- 0.0
- 0.627
- 0.652
- 0.0
- 0.669
- 0.623
- 0.0
- 0.713
- 0.0
- 0.729
- 0.719
- 0.775
- 0.74
- 0.0
- 0.758
- 0.0
- 0.783
- 0.76
- 0.735
- 0.727
- 0.785
- 0.0
- 0.785
- 0.779
- 0.79
- 0.819
- 0.794
- 0.756
- 0.981
- 0.0
- 0.808
- 0.0
- 0.752
- 0.0
- 0.794
- 0.0
- 0.81
- 0.821
- 0.0
- 0.804
- 0.802
- 0.0
- 0.0
- 0.0
- 0.783
- 0.0
- 0.808
- 0.0
- 0.829
- 0.777
- 0.0
- 0.831
- 0.0
- 0.0
- 0.831
- 0.0
- 0.815
- 0.771
- 0.86
- 0.804
- 0.0
- 0.835
- 0.84
- 0.0
- 0.854
- 0.0
- 0.979
- 0.854
- 0.804
- 0.798
- 0.854
- 0.785
- 0.0
- 0.0
- 0.835
- 0.0
- 0.842
- 0.819
- 0.0
- 0.819
- 0.81
- 0.812
- 0.825
- 0.821
- 0.792
- 0.829
- 0.817
- 0.0
- 0.775
- 0.827
- 0.842
- 0.833
- 0.0
train_loss:
- 2.718
- 3.811
- 2.716
- 2.586
- 2.4
- 2.166
- 2.808
- 1.801
- 2.369
- 2.22
- 1.508
- 2.03
- 1.388
- 1.358
- 1.289
- 1.305
- 1.243
- 1.246
- 1.649
- 1.591
- 1.177
- 1.138
- 0.728
- 1.539
- 1.076
- 1.481
- 0.684
- 1.443
- 1.088
- 1.426
- 0.67
- 0.674
- 1.385
- 1.016
- 1.004
- 0.287
- 0.523
- 1.306
- 0.898
- 1.282
- 0.944
- 0.926
- 0.923
- 0.933
- 0.576
- 0.901
- 1.216
- 0.89
- 0.539
- 0.558
- 0.508
- 0.909
- 0.904
- 0.835
- 0.902
- 0.876
- 0.895
- 0.892
- 1.189
- 0.863
- 0.538
- 1.141
- 0.897
- 0.836
- 0.866
- 1.171
- 1.148
- 0.813
- 1.16
- 0.837
- 0.83
- 0.86
- 0.822
- 0.221
- 0.83
- 0.825
- 0.787
- 0.8
- 1.151
- 0.822
- 0.785
- 0.828
- 0.818
- 0.798
- 1.108
- 0.49
- 1.114
- 0.492
- 1.105
- 1.058
- 0.763
- 1.097
- 0.818
- 0.764
- 0.778
- 0.489
- 0.785
- 1.076
- 0.766
- 0.477
unequal: 0
verbose: 1
