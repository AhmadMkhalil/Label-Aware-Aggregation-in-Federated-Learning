avg_train_accuracy: 0.823
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03430851063829787
- 0.06659574468085107
- 0.11361702127659574
- 0.2249468085106383
- 0.3519148936170213
- 0.4297340425531915
- 0.4803191489361702
- 0.5151595744680851
- 0.5325
- 0.5639893617021277
- 0.5726595744680851
- 0.5927127659574468
- 0.6052127659574468
- 0.6189361702127659
- 0.6234574468085107
- 0.6394148936170213
- 0.6443617021276595
- 0.654468085106383
- 0.6640425531914894
- 0.6598936170212766
- 0.6761170212765958
- 0.6806914893617021
- 0.6821808510638298
- 0.6911702127659575
- 0.6943617021276596
- 0.6988829787234042
- 0.7025
- 0.7053723404255319
- 0.708031914893617
- 0.7098404255319148
- 0.7096808510638298
- 0.7111702127659575
- 0.7144680851063829
- 0.7168085106382979
- 0.7217553191489362
- 0.7203191489361702
- 0.7189893617021277
- 0.7183510638297872
- 0.7230319148936171
- 0.7241489361702128
- 0.7312765957446808
- 0.7267021276595744
- 0.7289893617021277
- 0.7205851063829787
- 0.7306914893617021
- 0.7300531914893617
- 0.7340425531914894
- 0.7332978723404255
- 0.7341489361702128
- 0.7348404255319149
- 0.7379255319148936
- 0.7395212765957446
- 0.7407446808510638
- 0.740531914893617
- 0.7396276595744681
- 0.7437234042553191
- 0.74
- 0.7438829787234043
- 0.7452127659574468
- 0.7488829787234043
- 0.747872340425532
- 0.7393085106382978
- 0.746968085106383
- 0.7494148936170213
- 0.7501063829787235
- 0.7492553191489362
- 0.7486170212765958
- 0.7515425531914893
- 0.7515957446808511
- 0.7489361702127659
- 0.7523404255319149
- 0.753563829787234
- 0.7515425531914893
- 0.7545212765957446
- 0.7534574468085107
- 0.755
- 0.7586170212765957
- 0.7565425531914893
- 0.7544148936170213
- 0.7561170212765957
- 0.7569148936170212
- 0.7517021276595744
- 0.7587765957446808
- 0.7590425531914894
- 0.7596276595744681
- 0.7559574468085106
- 0.7586702127659575
- 0.7581914893617021
- 0.7591489361702127
- 0.7579255319148936
- 0.7615425531914893
- 0.7593617021276595
- 0.7645744680851064
- 0.7568085106382979
- 0.7620212765957447
- 0.7618085106382979
- 0.7602659574468085
- 0.7626063829787234
- 0.7661702127659574
- 0.7651063829787234
test_loss_list:
- 3.7792578665415446
- 3.7369279511769613
- 3.628014389673869
- 3.349102923075358
- 2.9675778198242186
- 2.5819895680745444
- 2.366690839131673
- 2.1898623148600262
- 2.0666155592600504
- 1.9602175887425741
- 1.8860764821370444
- 1.8309031454722087
- 1.789564963976542
- 1.7277812910079957
- 1.711396746635437
- 1.6751668802897135
- 1.6328662045796711
- 1.6089545567830403
- 1.6020102898279827
- 1.5721247180302937
- 1.556360224088033
- 1.5292635440826416
- 1.5255950927734374
- 1.5163957675298054
- 1.4964980204900107
- 1.4962725400924684
- 1.4917081832885741
- 1.4719321902592977
- 1.4826604064305624
- 1.4715186516443888
- 1.46805713335673
- 1.445150639216105
- 1.459038987159729
- 1.461475478808085
- 1.4150480238596599
- 1.4499705712000528
- 1.4086829153696696
- 1.4064821418126423
- 1.3885321776072184
- 1.3856135718027751
- 1.3904853630065919
- 1.4097778781255086
- 1.3717929410934449
- 1.3832643191019693
- 1.3593789418538411
- 1.3573599990208944
- 1.3477380402882895
- 1.3351674930254618
- 1.3292623933156331
- 1.3210882139205933
- 1.3234272289276123
- 1.3320418500900268
- 1.3330603694915772
- 1.3156436562538147
- 1.319583588441213
- 1.3163358887036642
- 1.302863866488139
- 1.3150632095336914
- 1.3057190823554992
- 1.3037299569447836
- 1.2898969570795695
- 1.27918541431427
- 1.2741333786646525
- 1.3024882078170776
- 1.27680916706721
- 1.279666777451833
- 1.2705447189013164
- 1.3034167798360188
- 1.2900228309631347
- 1.258985883394877
- 1.2804989504814148
- 1.2862510402997336
- 1.275055357615153
- 1.2559572903315226
- 1.2848750440279644
- 1.2705165282885234
- 1.2297696900367736
- 1.2615259981155396
- 1.246256136894226
- 1.2906739672025045
- 1.261712183157603
- 1.2103093266487122
- 1.2375937628746032
- 1.2268179321289063
- 1.24670578956604
- 1.2400364176432292
- 1.2655055149396262
- 1.243277153968811
- 1.256737109820048
- 1.2424526063601176
- 1.2470581698417664
- 1.2530489222208658
- 1.2212431454658508
- 1.2176716073354086
- 1.2164256882667541
- 1.22693306128184
- 1.218547158241272
- 1.249362550576528
- 1.251166081428528
- 1.2562645268440247
train_accuracy:
- 0.0
- 0.056
- 0.104
- 0.0
- 0.356
- 0.0
- 0.0
- 0.0
- 0.0
- 0.588
- 0.598
- 0.0
- 0.0
- 0.0
- 0.0
- 0.692
- 0.731
- 0.7
- 0.694
- 0.69
- 0.721
- 0.0
- 0.754
- 0.706
- 0.74
- 0.727
- 0.754
- 0.733
- 0.737
- 0.758
- 0.752
- 0.796
- 0.767
- 0.796
- 0.773
- 0.763
- 0.771
- 0.794
- 0.775
- 0.0
- 0.0
- 0.748
- 0.817
- 0.808
- 0.798
- 0.763
- 0.0
- 0.0
- 0.754
- 0.785
- 0.0
- 0.846
- 0.0
- 0.787
- 0.823
- 0.0
- 0.8
- 0.804
- 0.767
- 0.0
- 0.823
- 0.0
- 0.798
- 0.842
- 0.0
- 0.831
- 0.0
- 0.819
- 0.0
- 0.0
- 0.835
- 0.833
- 0.802
- 0.838
- 0.777
- 0.821
- 0.844
- 0.829
- 0.821
- 0.823
- 0.821
- 0.0
- 0.835
- 0.0
- 0.823
- 0.798
- 0.81
- 0.815
- 0.819
- 0.0
- 0.854
- 0.831
- 0.852
- 0.0
- 0.0
- 0.0
- 0.806
- 0.827
- 0.844
- 0.823
train_loss:
- 1.578
- 2.678
- 3.744
- 2.479
- 3.312
- 2.042
- 1.054
- 1.012
- 0.939
- 1.599
- 0.885
- 1.463
- 1.39
- 1.366
- 1.334
- 1.329
- 1.271
- 1.267
- 1.711
- 0.72
- 1.647
- 1.178
- 1.139
- 1.562
- 1.528
- 1.524
- 1.506
- 1.07
- 1.442
- 1.438
- 1.031
- 1.048
- 1.4
- 1.359
- 1.04
- 1.361
- 0.995
- 0.648
- 1.02
- 0.987
- 0.966
- 1.295
- 0.961
- 0.575
- 0.953
- 0.62
- 0.981
- 0.938
- 0.916
- 0.923
- 0.935
- 1.247
- 0.913
- 0.897
- 0.903
- 0.906
- 0.892
- 0.889
- 0.87
- 0.882
- 0.886
- 0.552
- 0.854
- 1.184
- 0.873
- 0.845
- 0.86
- 1.131
- 0.834
- 0.845
- 1.146
- 1.121
- 0.812
- 0.858
- 1.128
- 1.149
- 0.849
- 0.854
- 0.825
- 1.098
- 1.12
- 0.547
- 0.859
- 0.835
- 0.83
- 0.822
- 1.089
- 0.817
- 0.802
- 0.818
- 1.094
- 1.083
- 0.821
- 0.518
- 0.813
- 0.791
- 0.798
- 1.056
- 1.059
- 1.054
unequal: 0
verbose: 1
