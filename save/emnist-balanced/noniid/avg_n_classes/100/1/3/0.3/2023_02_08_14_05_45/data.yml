avg_train_accuracy: 0.821
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04382978723404255
- 0.07888297872340426
- 0.16920212765957446
- 0.2910106382978723
- 0.391968085106383
- 0.4639893617021277
- 0.49675531914893617
- 0.5006382978723404
- 0.5411702127659574
- 0.5638829787234042
- 0.5727127659574468
- 0.5920212765957447
- 0.6004787234042553
- 0.6177659574468085
- 0.6246808510638298
- 0.6352127659574468
- 0.6447872340425532
- 0.6487234042553192
- 0.6614361702127659
- 0.661063829787234
- 0.6728191489361702
- 0.6752127659574468
- 0.6794148936170212
- 0.6823936170212765
- 0.6865425531914894
- 0.6945744680851064
- 0.6972872340425532
- 0.6993085106382979
- 0.7022872340425532
- 0.7021808510638298
- 0.708031914893617
- 0.7122340425531914
- 0.7118085106382979
- 0.7153191489361702
- 0.7136170212765958
- 0.7176595744680851
- 0.7227659574468085
- 0.7234574468085107
- 0.7231914893617021
- 0.7253191489361702
- 0.7242021276595745
- 0.7277127659574468
- 0.7263829787234043
- 0.7296276595744681
- 0.7302127659574468
- 0.7297872340425532
- 0.7357978723404255
- 0.7358510638297873
- 0.7379255319148936
- 0.7344148936170213
- 0.7398404255319149
- 0.7396808510638297
- 0.7362234042553192
- 0.7418617021276596
- 0.7409574468085106
- 0.7426063829787234
- 0.7430851063829788
- 0.7420744680851064
- 0.7448404255319149
- 0.7444148936170213
- 0.7471276595744681
- 0.7479255319148936
- 0.7493617021276596
- 0.7489361702127659
- 0.7511170212765957
- 0.7476063829787234
- 0.7463829787234042
- 0.7481914893617021
- 0.745
- 0.7517553191489361
- 0.7511170212765957
- 0.7501595744680851
- 0.7539893617021277
- 0.7503723404255319
- 0.7516489361702128
- 0.7560638297872341
- 0.7426595744680851
- 0.7570744680851064
- 0.7559574468085106
- 0.7554787234042554
- 0.7536170212765958
- 0.7563297872340425
- 0.7514893617021277
- 0.756436170212766
- 0.7578723404255319
- 0.7559574468085106
- 0.7650531914893617
- 0.7548404255319149
- 0.7626595744680851
- 0.760904255319149
- 0.7590957446808511
- 0.7543617021276596
- 0.763563829787234
- 0.7610106382978723
- 0.7622872340425532
- 0.7619148936170212
- 0.7573404255319149
- 0.7640957446808511
- 0.7596276595744681
- 0.7620744680851064
test_loss_list:
- 3.774111255009969
- 3.708843520482381
- 3.5376072057088215
- 3.219448375701904
- 2.8368726762135825
- 2.5241800594329833
- 2.3316728337605794
- 2.217239739100138
- 2.0750160296758016
- 1.9963130807876588
- 1.9396332375208536
- 1.8744472853342693
- 1.8371657466888427
- 1.8067877213160197
- 1.7754364935557048
- 1.7590627113978068
- 1.7012783193588257
- 1.7148034381866455
- 1.6815391381581624
- 1.646465311050415
- 1.6632600164413451
- 1.6574660952885945
- 1.6390511020024618
- 1.5963603560129802
- 1.5894175974527995
- 1.623346357345581
- 1.5897254721323648
- 1.5720909722646077
- 1.5559353001912435
- 1.5324984979629517
- 1.5472433646519979
- 1.5555058781305948
- 1.527544240951538
- 1.5179682095845541
- 1.506281156539917
- 1.4895393562316894
- 1.5030712461471558
- 1.4922350772221884
- 1.4612347904841105
- 1.4749605878194174
- 1.4777051099141438
- 1.4381333446502687
- 1.4232095289230347
- 1.4212157042821247
- 1.4314509105682374
- 1.4270845031738282
- 1.4288439305623373
- 1.4118456093470255
- 1.4337113396326702
- 1.3839312012990315
- 1.400550503730774
- 1.3784849770863852
- 1.3690289322535196
- 1.3896363162994385
- 1.398750244776408
- 1.4091688553492228
- 1.3926590903600058
- 1.3848772287368774
- 1.3847492996851603
- 1.3590939442316692
- 1.3614543517430624
- 1.3573986752827962
- 1.385783977508545
- 1.3925874598821004
- 1.363655420144399
- 1.3603243446350097
- 1.3423840729395549
- 1.3481025274594625
- 1.3246789320309957
- 1.2823749574025471
- 1.297850116888682
- 1.3056094392140707
- 1.2973266331354778
- 1.3230629301071166
- 1.297945994536082
- 1.3214414342244467
- 1.2808482623100281
- 1.30610902150472
- 1.272945483525594
- 1.2728952050209046
- 1.2511170450846354
- 1.2771045748392742
- 1.2378768905003865
- 1.256194855372111
- 1.251715778509776
- 1.2891695769627889
- 1.2621137603123982
- 1.2462798110644022
- 1.2614378873507182
- 1.2701980511347453
- 1.261439828077952
- 1.2091832192738852
- 1.2461111577351889
- 1.2416068005561829
- 1.2325531482696532
- 1.2505319118499756
- 1.2311561902364094
- 1.246142828464508
- 1.234565920829773
- 1.239710750579834
train_accuracy:
- 0.046
- 0.094
- 0.219
- 0.294
- 0.46
- 0.481
- 0.515
- 0.0
- 0.59
- 0.0
- 0.0
- 0.0
- 0.633
- 0.64
- 0.671
- 0.681
- 0.0
- 0.0
- 0.706
- 0.0
- 0.719
- 0.715
- 0.733
- 0.0
- 0.742
- 0.754
- 0.744
- 0.742
- 0.737
- 0.0
- 0.752
- 0.779
- 0.779
- 0.0
- 0.0
- 0.781
- 0.787
- 0.771
- 0.763
- 0.808
- 0.781
- 0.794
- 0.0
- 0.0
- 0.0
- 0.0
- 0.806
- 0.808
- 0.81
- 0.0
- 0.783
- 0.798
- 0.0
- 0.792
- 0.794
- 0.798
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.81
- 0.821
- 0.79
- 0.827
- 0.0
- 0.825
- 0.0
- 0.0
- 0.0
- 0.827
- 0.781
- 0.0
- 0.817
- 0.0
- 0.806
- 0.0
- 0.823
- 0.0
- 0.796
- 0.825
- 0.804
- 0.0
- 0.823
- 0.0
- 0.792
- 0.821
- 0.0
- 0.8
- 0.81
- 0.0
- 0.0
- 0.819
- 0.794
- 0.815
- 0.812
- 0.0
- 0.831
- 0.825
- 0.821
train_loss:
- 2.642
- 2.649
- 3.692
- 3.479
- 3.174
- 2.899
- 1.872
- 1.005
- 1.666
- 1.58
- 0.902
- 1.492
- 1.441
- 1.397
- 1.912
- 1.319
- 1.331
- 1.254
- 1.75
- 1.254
- 1.671
- 1.652
- 1.626
- 1.17
- 1.145
- 1.521
- 1.548
- 1.115
- 1.115
- 0.718
- 1.5
- 1.432
- 1.059
- 1.077
- 1.055
- 1.029
- 1.367
- 1.018
- 1.011
- 0.986
- 1.002
- 1.001
- 0.634
- 0.961
- 0.612
- 0.626
- 1.313
- 0.952
- 1.294
- 0.623
- 1.295
- 0.945
- 0.592
- 1.274
- 1.237
- 1.245
- 0.915
- 0.913
- 0.901
- 0.916
- 0.898
- 0.89
- 1.201
- 1.181
- 0.883
- 0.886
- 0.566
- 0.557
- 0.57
- 0.577
- 0.867
- 0.851
- 0.871
- 1.162
- 0.542
- 1.139
- 0.56
- 1.147
- 0.543
- 0.838
- 0.552
- 0.827
- 0.555
- 0.828
- 0.816
- 1.102
- 0.808
- 0.811
- 0.813
- 1.122
- 0.81
- 0.522
- 1.115
- 0.782
- 0.802
- 1.11
- 0.516
- 1.097
- 0.809
- 1.075
unequal: 0
verbose: 1
