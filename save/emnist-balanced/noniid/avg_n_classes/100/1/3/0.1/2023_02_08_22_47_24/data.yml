avg_train_accuracy: 0.765
avg_train_loss: 0.013
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041648936170212765
- 0.059574468085106386
- 0.07468085106382978
- 0.02127659574468085
- 0.02127659574468085
- 0.060159574468085106
- 0.07734042553191489
- 0.1402659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.029095744680851063
- 0.04015957446808511
- 0.13234042553191488
- 0.18462765957446808
- 0.25292553191489364
- 0.29819148936170214
- 0.3414893617021277
- 0.38324468085106383
- 0.43
- 0.4598404255319149
- 0.02127659574468085
- 0.47414893617021275
- 0.4976595744680851
- 0.5198404255319149
- 0.02148936170212766
- 0.5215425531914893
- 0.546968085106383
- 0.11085106382978724
- 0.5652127659574468
- 0.5836702127659574
- 0.19632978723404254
- 0.02154255319148936
- 0.02127659574468085
- 0.5862765957446808
- 0.5985106382978723
- 0.2371808510638298
- 0.11159574468085107
- 0.6072872340425531
- 0.04930851063829787
- 0.620531914893617
- 0.6234042553191489
- 0.6280851063829788
- 0.08728723404255319
- 0.17808510638297873
- 0.07085106382978723
- 0.13936170212765958
- 0.6360638297872341
- 0.6441489361702127
- 0.10117021276595745
- 0.18356382978723404
- 0.6568085106382979
- 0.6578723404255319
- 0.6593617021276595
- 0.6648404255319149
- 0.3551063829787234
- 0.6683510638297873
- 0.6723936170212766
- 0.408031914893617
- 0.6821808510638298
- 0.681063829787234
- 0.6821808510638298
- 0.41962765957446807
- 0.6884574468085106
- 0.6888297872340425
- 0.699840425531915
- 0.13127659574468084
- 0.2298936170212766
- 0.7024468085106383
- 0.22452127659574467
- 0.7054255319148937
- 0.27882978723404256
- 0.7112234042553192
- 0.28898936170212763
- 0.715
- 0.7136170212765958
- 0.7117553191489362
- 0.7113297872340425
- 0.7132446808510639
- 0.7193085106382979
- 0.47058510638297874
- 0.17409574468085107
- 0.725
- 0.7246276595744681
- 0.7223404255319149
- 0.7284574468085107
- 0.7288297872340426
- 0.20920212765957447
- 0.7360638297872341
- 0.7375531914893617
- 0.45159574468085106
- 0.7370744680851063
- 0.4524468085106383
- 0.7327659574468085
- 0.728404255319149
- 0.7317021276595744
- 0.5101595744680851
- 0.7340425531914894
- 0.7279787234042553
test_loss_list:
- 3.7874793275197347
- 3.761879237492879
- 3.6959158325195314
- 30.514528427124024
- 37.434142100016274
- 3.7833747990926105
- 3.7510584449768065
- 3.648607447942098
- 24.5362532043457
- 30.345129979451496
- 28.52244140625
- 26.20581522623698
- 3.770913330713908
- 3.7028726800282796
- 3.5563640530904133
- 3.39304368019104
- 3.1836227989196777
- 2.9985559813181557
- 2.756410207748413
- 2.5777640374501547
- 2.420764849980672
- 2.291847867965698
- 21.022280298868814
- 2.2252796045939127
- 2.1084215291341146
- 2.0197123209635417
- 20.826815287272137
- 1.8985259532928467
- 1.8193556833267213
- 7.673178005218506
- 1.7200857273737589
- 1.6948004992802939
- 5.952949345906576
- 16.14345058441162
- 21.63341069539388
- 1.600939450263977
- 1.5320986859003702
- 7.88889035542806
- 6.740881576538086
- 1.4329279740651448
- 10.13062307993571
- 1.373353344599406
- 1.354070364634196
- 1.3514925543467204
- 8.36949312845866
- 5.258262996673584
- 8.60731751759847
- 7.24244150797526
- 1.2818196137746176
- 1.2466036065419515
- 7.192672119140625
- 6.771777598063151
- 1.2199792051315308
- 1.212630917231242
- 1.226639297803243
- 1.2183608245849609
- 5.268372243245443
- 1.192102681795756
- 1.1886104202270509
- 4.403882048924764
- 1.1717314060529074
- 1.1694972785313924
- 1.1706101393699646
- 4.392921148935954
- 1.1484860603014628
- 1.1563735183080037
- 1.1576069037119547
- 6.880898939768473
- 5.3771364212036135
- 1.0281942701339721
- 5.295347461700439
- 1.0248465164502463
- 4.189302059809367
- 1.0256061792373656
- 4.149711958567301
- 1.0313879346847534
- 1.0309791787465414
- 1.041845081647237
- 1.0560523295402526
- 1.0681797297795614
- 1.0573687450091045
- 4.236274919509888
- 5.632920157114665
- 0.9806841055552165
- 0.9889893714586894
- 1.005382874806722
- 1.0091601785024007
- 1.0180965979894003
- 5.764987487792968
- 0.9946251201629639
- 1.0052213629086812
- 4.708037150700887
- 0.9614933943748474
- 3.6035734272003173
- 0.8715555961926779
- 0.9027562689781189
- 0.9242345221837361
- 3.505721616744995
- 0.9130033953984579
- 0.9280802750587464
train_accuracy:
- 0.037
- 0.069
- 0.094
- 1.0
- 1.0
- 0.06
- 0.075
- 0.152
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.017
- 0.131
- 0.196
- 0.3
- 0.308
- 0.371
- 0.373
- 0.494
- 0.544
- 1.0
- 0.502
- 0.573
- 0.515
- 1.0
- 0.535
- 0.6
- 1.0
- 0.596
- 0.581
- 1.0
- 1.0
- 1.0
- 0.594
- 0.638
- 1.0
- 0.998
- 0.61
- 1.0
- 0.721
- 0.635
- 0.652
- 1.0
- 1.0
- 1.0
- 1.0
- 0.665
- 0.671
- 1.0
- 1.0
- 0.746
- 0.748
- 0.708
- 0.71
- 1.0
- 0.702
- 0.723
- 1.0
- 0.702
- 0.767
- 0.773
- 1.0
- 0.715
- 0.787
- 0.742
- 0.998
- 1.0
- 0.717
- 1.0
- 0.733
- 0.998
- 0.725
- 0.998
- 0.76
- 0.735
- 0.748
- 0.725
- 0.771
- 0.76
- 1.0
- 1.0
- 0.737
- 0.796
- 0.758
- 0.779
- 0.771
- 0.998
- 0.769
- 0.773
- 1.0
- 0.808
- 1.0
- 0.808
- 0.773
- 0.765
- 1.0
- 0.796
- 0.765
train_loss:
- 3.845
- 3.822
- 3.779
- 0.512
- 0.01
- 4.277
- 3.811
- 3.745
- 0.433
- 0.011
- 1.59
- 0.628
- 4.21
- 3.816
- 3.725
- 3.611
- 3.454
- 3.302
- 3.092
- 2.915
- 2.77
- 2.622
- 0.155
- 3.005
- 2.493
- 2.361
- 0.388
- 2.672
- 2.247
- 0.182
- 2.423
- 2.175
- 0.117
- 0.469
- 0.018
- 2.624
- 2.071
- 0.258
- 0.129
- 2.288
- 0.186
- 2.166
- 1.879
- 1.796
- 0.159
- 0.252
- 0.142
- 0.343
- 2.272
- 1.766
- 0.131
- 0.158
- 2.017
- 1.73
- 1.781
- 1.703
- 0.147
- 1.791
- 1.662
- 0.125
- 1.809
- 1.569
- 1.528
- 0.123
- 1.696
- 1.499
- 1.574
- 0.225
- 0.256
- 1.789
- 0.113
- 1.666
- 0.1
- 1.585
- 0.089
- 1.659
- 1.459
- 1.436
- 1.405
- 1.492
- 1.464
- 0.223
- 0.218
- 1.675
- 1.408
- 1.418
- 1.37
- 1.398
- 0.139
- 1.5
- 1.392
- 0.2
- 1.475
- 0.199
- 1.469
- 1.323
- 1.34
- 0.152
- 1.457
- 1.31
unequal: 0
verbose: 1
