avg_train_accuracy: 1.0
avg_train_loss: 0.001
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04627659574468085
- 0.08244680851063829
- 0.14111702127659576
- 0.2474468085106383
- 0.02127659574468085
- 0.02127659574468085
- 0.22994680851063828
- 0.02127659574468085
- 0.02127659574468085
- 0.03797872340425532
- 0.09
- 0.17404255319148937
- 0.29271276595744683
- 0.02127659574468085
- 0.34882978723404257
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.36425531914893616
- 0.43622340425531914
- 0.03898936170212766
- 0.02127659574468085
- 0.46558510638297873
- 0.48904255319148937
- 0.5109574468085106
- 0.030904255319148935
- 0.024148936170212767
- 0.0225
- 0.03138297872340425
- 0.022340425531914895
- 0.5178723404255319
- 0.540904255319149
- 0.5587234042553192
- 0.1375531914893617
- 0.055638297872340425
- 0.04664893617021276
- 0.040372340425531915
- 0.5656382978723404
- 0.580531914893617
- 0.591968085106383
- 0.1951595744680851
- 0.6023404255319149
- 0.27680851063829787
- 0.21718085106382978
- 0.6111170212765957
- 0.3230851063829787
- 0.15393617021276595
- 0.6174468085106383
- 0.3048936170212766
- 0.624468085106383
- 0.6311170212765957
- 0.6370744680851064
- 0.3320744680851064
- 0.6393617021276595
- 0.3320212765957447
- 0.6477127659574468
- 0.3504255319148936
- 0.648563829787234
- 0.6568617021276596
- 0.6605319148936171
- 0.08138297872340426
- 0.6740957446808511
- 0.19393617021276596
- 0.6767021276595745
- 0.3929787234042553
- 0.6694148936170212
- 0.6790957446808511
- 0.6764893617021277
- 0.6795212765957447
- 0.6809574468085107
- 0.37611702127659574
- 0.6826595744680851
- 0.6860106382978723
- 0.691595744680851
- 0.6885638297872341
- 0.3777659574468085
- 0.6949468085106383
- 0.4165957446808511
- 0.694627659574468
- 0.6961702127659575
- 0.6995212765957447
- 0.7029255319148936
- 0.7059574468085107
- 0.7066489361702127
- 0.7021808510638298
- 0.7075531914893617
- 0.7071808510638298
- 0.7118617021276595
- 0.7120212765957447
- 0.7113829787234043
- 0.7154787234042553
- 0.7140425531914893
- 0.3878191489361702
- 0.7175
- 0.7193617021276596
- 0.7176595744680851
- 0.14925531914893617
- 0.7254255319148936
- 0.43611702127659574
- 0.23941489361702128
test_loss_list:
- 3.775627250671387
- 3.719320805867513
- 3.5441150665283203
- 3.2343677520751952
- 22.52279685974121
- 28.521161244710285
- 3.2615041446685793
- 31.564002227783202
- 28.86981341044108
- 3.744158067703247
- 3.5332921028137205
- 3.1989559809366863
- 2.8947610155741375
- 15.93978385925293
- 2.6932561016082763
- 25.1844305674235
- 13.926024258931477
- 18.01637924194336
- 2.610897299448649
- 2.3708616574605306
- 9.626239217122396
- 17.5553236134847
- 2.2205634911855063
- 2.0731368923187254
- 1.9752892891565959
- 13.402057647705078
- 17.713222427368166
- 20.70016782124837
- 11.881207516988118
- 12.896732800801596
- 1.9570166985193889
- 1.812144225438436
- 1.7275876188278199
- 6.926690362294515
- 10.251480941772462
- 13.183471120198568
- 10.178626899719239
- 1.6092861064275106
- 1.5750704924265544
- 1.5346001307169597
- 6.1544107246398925
- 1.4804524676005046
- 6.295441805521647
- 8.502210451761881
- 1.4208304421106974
- 5.421777763366699
- 6.510759092966715
- 1.3804124259948731
- 4.339598512649536
- 1.360661538441976
- 1.372527494430542
- 1.365215802192688
- 4.176966260274251
- 1.321816128094991
- 5.52486811319987
- 1.278635973930359
- 4.131884797414144
- 1.2637301286061604
- 1.2617917664845784
- 1.2682857354482016
- 9.523808619181315
- 1.20636177221934
- 6.152423591613769
- 1.1787955554326375
- 3.789890171686808
- 1.1527813911437987
- 1.1450155512491862
- 1.161386918226878
- 1.1750707244873047
- 1.1622704887390136
- 5.483614482879639
- 1.1146186685562134
- 1.130073745250702
- 1.1260097376505533
- 1.1446173135439555
- 5.293638172149659
- 1.1137133073806762
- 3.7549503803253175
- 1.049836733341217
- 1.0729492179552713
- 1.0885142572720845
- 1.0902725299199423
- 1.092870930035909
- 1.102794465223948
- 1.1319072802861532
- 1.1191686487197876
- 1.1217390338579813
- 1.1314567589759827
- 1.1304035886128743
- 1.1365683921178182
- 1.1322659246126812
- 1.153820453484853
- 5.382921492258708
- 1.0712100370724995
- 1.0933102703094482
- 1.1040369900067648
- 8.182676493326824
- 1.0042130502065023
- 3.63356006304423
- 5.517190780639648
train_accuracy:
- 0.052
- 0.1
- 0.169
- 0.271
- 1.0
- 1.0
- 0.263
- 1.0
- 1.0
- 0.01
- 0.085
- 0.208
- 0.321
- 1.0
- 0.356
- 1.0
- 1.0
- 1.0
- 0.377
- 0.438
- 1.0
- 1.0
- 0.483
- 0.517
- 0.562
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.54
- 0.55
- 0.627
- 1.0
- 1.0
- 1.0
- 1.0
- 0.569
- 0.644
- 0.598
- 1.0
- 0.625
- 1.0
- 1.0
- 0.65
- 1.0
- 0.998
- 0.648
- 1.0
- 0.669
- 0.692
- 0.7
- 1.0
- 0.702
- 1.0
- 0.704
- 1.0
- 0.683
- 0.713
- 0.727
- 1.0
- 0.725
- 0.998
- 0.719
- 1.0
- 0.698
- 0.727
- 0.731
- 0.727
- 0.752
- 1.0
- 0.752
- 0.742
- 0.737
- 0.76
- 1.0
- 0.758
- 1.0
- 0.742
- 0.742
- 0.725
- 0.746
- 0.746
- 0.729
- 0.742
- 0.754
- 0.742
- 0.756
- 0.754
- 0.75
- 0.76
- 0.769
- 1.0
- 0.758
- 0.775
- 0.74
- 1.0
- 0.756
- 1.0
- 1.0
train_loss:
- 3.841
- 3.806
- 3.707
- 3.524
- 0.209
- 0.01
- 3.947
- 0.342
- 1.354
- 4.179
- 3.749
- 3.484
- 3.219
- 0.243
- 3.371
- 0.403
- 0.43
- 0.013
- 3.383
- 2.844
- 0.144
- 0.367
- 3.09
- 2.562
- 2.393
- 0.181
- 0.013
- 0.008
- 0.849
- 0.446
- 2.973
- 2.381
- 2.247
- 0.201
- 0.16
- 0.015
- 0.324
- 2.609
- 2.19
- 2.058
- 0.148
- 2.186
- 0.181
- 0.016
- 2.202
- 0.099
- 0.137
- 2.168
- 0.099
- 2.024
- 1.866
- 1.802
- 0.136
- 1.962
- 0.165
- 1.9
- 0.112
- 1.903
- 1.739
- 1.714
- 0.282
- 1.905
- 0.121
- 1.816
- 0.157
- 1.794
- 1.601
- 1.606
- 1.577
- 1.556
- 0.223
- 1.663
- 1.538
- 1.518
- 1.485
- 0.142
- 1.628
- 0.178
- 1.679
- 1.46
- 1.471
- 1.488
- 1.467
- 1.397
- 1.409
- 1.446
- 1.398
- 1.381
- 1.373
- 1.358
- 1.358
- 1.304
- 0.204
- 1.526
- 1.36
- 1.331
- 0.293
- 1.573
- 0.216
- 0.148
unequal: 0
verbose: 1
