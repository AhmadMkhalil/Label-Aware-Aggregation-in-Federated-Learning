avg_train_accuracy: 0.785
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03861702127659575
- 0.047606382978723404
- 0.06968085106382979
- 0.14037234042553193
- 0.2451063829787234
- 0.3492021276595745
- 0.4394148936170213
- 0.5051595744680851
- 0.545372340425532
- 0.5762765957446808
- 0.5952659574468085
- 0.6113829787234043
- 0.6302127659574468
- 0.6407978723404255
- 0.6528723404255319
- 0.6587234042553192
- 0.6700531914893617
- 0.6737765957446809
- 0.6835638297872341
- 0.6902127659574468
- 0.6946808510638298
- 0.7004255319148937
- 0.7049468085106383
- 0.7096808510638298
- 0.711968085106383
- 0.7154787234042553
- 0.7191489361702128
- 0.72
- 0.7247340425531915
- 0.7256914893617021
- 0.7282978723404255
- 0.7311702127659574
- 0.7317553191489362
- 0.7345212765957447
- 0.7374468085106383
- 0.7374468085106383
- 0.7410106382978724
- 0.7428191489361702
- 0.745
- 0.7423404255319149
- 0.746968085106383
- 0.7479787234042553
- 0.7484574468085107
- 0.7519148936170212
- 0.7518617021276596
- 0.7551063829787235
- 0.7536170212765958
- 0.7561702127659574
- 0.7574468085106383
- 0.7590957446808511
- 0.7598404255319149
- 0.762127659574468
- 0.7598404255319149
- 0.7593617021276595
- 0.764468085106383
- 0.7645212765957446
- 0.7658510638297872
- 0.7661170212765958
- 0.7672340425531915
- 0.7690425531914894
- 0.7691489361702127
- 0.7696808510638298
- 0.7701063829787234
- 0.77
- 0.7725
- 0.7730851063829787
- 0.7727659574468085
- 0.772127659574468
- 0.7720212765957447
- 0.7734574468085106
- 0.775
- 0.7757978723404255
- 0.7756382978723404
- 0.7748936170212766
- 0.7760106382978723
- 0.7764893617021277
- 0.7775
- 0.7779787234042553
- 0.7787234042553192
- 0.7787765957446808
- 0.7803723404255319
- 0.7783510638297872
- 0.7777127659574468
- 0.778563829787234
- 0.7794148936170213
- 0.7822872340425532
- 0.7790425531914894
- 0.7807446808510639
- 0.7818085106382979
- 0.7826595744680851
- 0.7836702127659575
- 0.7816489361702128
- 0.7825
- 0.7842553191489362
- 0.7817553191489361
- 0.7826595744680851
- 0.7831914893617021
- 0.7827659574468085
- 0.7839893617021276
- 0.7836702127659575
test_loss_list:
- 3.7896273803710936
- 3.7708023961385093
- 3.7271414375305176
- 3.60704771677653
- 3.328991896311442
- 2.9284332529703776
- 2.548187157313029
- 2.23288454691569
- 2.0174556382497153
- 1.853956478436788
- 1.7345003763834634
- 1.6456336641311646
- 1.5493873389561972
- 1.4876344919204711
- 1.4302551253636677
- 1.3877062924702963
- 1.3549689865112304
- 1.3218827470143637
- 1.3027399889628093
- 1.2766141160329183
- 1.2398562304178873
- 1.2106520144144695
- 1.1918961604436238
- 1.1865131290753683
- 1.1534963806470235
- 1.1394947862625122
- 1.1247472437222799
- 1.1061807791392009
- 1.117136439482371
- 1.087557225227356
- 1.0782934935887654
- 1.0610805741945903
- 1.0664563465118408
- 1.0692792773246764
- 1.0587969819704692
- 1.034831489721934
- 1.0467252039909363
- 1.04337558110555
- 1.018948527177175
- 1.0059386690457661
- 1.0194370047251384
- 0.9896874682108561
- 1.0003100458780925
- 1.0054795678456625
- 0.9759383138020833
- 0.9694902880986531
- 0.982019993464152
- 0.9587404974301657
- 0.9695102079709371
- 0.9426397848129272
- 0.9427697316805521
- 0.9296560406684875
- 0.9206003435452779
- 0.9211923432350159
- 0.90861567735672
- 0.9173376091321309
- 0.9245550727844238
- 0.9041834235191345
- 0.8974679319063822
- 0.8930332255363465
- 0.8857329607009887
- 0.8830877550443014
- 0.8798128286997478
- 0.8723058915138244
- 0.8893555347124735
- 0.8690430887540181
- 0.865484291712443
- 0.8613942734400432
- 0.8811585974693298
- 0.855964469909668
- 0.8748014092445373
- 0.8553827293713887
- 0.849309253692627
- 0.8478971330324808
- 0.8431578620274862
- 0.8559610056877136
- 0.8390896161397298
- 0.83766219774882
- 0.8536983919143677
- 0.8327317627271017
- 0.8304380297660827
- 0.8230837464332581
- 0.8208111731211344
- 0.818528388341268
- 0.8365745131174723
- 0.817169717947642
- 0.8153887955347697
- 0.8321781396865845
- 0.81170671860377
- 0.8341928823788961
- 0.8111770677566529
- 0.8277502036094666
- 0.8090462040901184
- 0.8268817973136902
- 0.811691091855367
- 0.8257974616686503
- 0.8101366623242696
- 0.806534492969513
- 0.8173914154370626
- 0.8234764885902405
train_accuracy:
- 0.044
- 0.065
- 0.079
- 0.156
- 0.254
- 0.373
- 0.0
- 0.546
- 0.535
- 0.61
- 0.627
- 0.667
- 0.642
- 0.658
- 0.675
- 0.708
- 0.717
- 0.721
- 0.7
- 0.723
- 0.719
- 0.737
- 0.737
- 0.746
- 0.727
- 0.752
- 0.769
- 0.0
- 0.754
- 0.0
- 0.742
- 0.0
- 0.765
- 0.781
- 0.742
- 0.737
- 0.79
- 0.775
- 0.787
- 0.74
- 0.804
- 0.737
- 0.794
- 0.75
- 0.794
- 0.8
- 0.8
- 0.817
- 0.746
- 0.798
- 0.756
- 0.0
- 0.812
- 0.756
- 0.787
- 0.806
- 0.763
- 0.754
- 0.763
- 0.808
- 0.779
- 0.812
- 0.798
- 0.815
- 0.802
- 0.794
- 0.0
- 0.777
- 0.821
- 0.798
- 0.787
- 0.0
- 0.81
- 0.819
- 0.775
- 0.79
- 0.771
- 0.825
- 0.806
- 0.806
- 0.0
- 0.827
- 0.819
- 0.823
- 0.823
- 0.831
- 0.812
- 0.781
- 0.819
- 0.835
- 0.821
- 0.838
- 0.0
- 0.838
- 0.821
- 0.815
- 0.815
- 0.835
- 0.84
- 0.785
train_loss:
- 3.849
- 3.378
- 3.341
- 3.271
- 3.131
- 2.901
- 2.653
- 2.794
- 2.584
- 2.407
- 1.982
- 1.896
- 2.081
- 1.755
- 1.693
- 1.649
- 1.825
- 1.565
- 1.756
- 1.711
- 1.475
- 1.439
- 1.431
- 1.594
- 1.379
- 1.362
- 1.355
- 1.341
- 1.503
- 1.301
- 1.298
- 1.28
- 1.436
- 1.434
- 1.43
- 1.23
- 1.405
- 1.389
- 1.222
- 1.208
- 1.357
- 1.192
- 1.34
- 1.337
- 1.17
- 1.16
- 1.31
- 1.137
- 1.31
- 1.135
- 1.136
- 1.118
- 1.116
- 1.117
- 1.104
- 1.245
- 1.245
- 1.095
- 1.088
- 1.085
- 1.085
- 1.068
- 1.066
- 1.062
- 1.208
- 1.055
- 1.051
- 1.066
- 1.197
- 1.057
- 1.186
- 1.044
- 1.041
- 1.042
- 1.025
- 1.173
- 1.025
- 1.026
- 1.167
- 1.03
- 1.018
- 1.014
- 1.009
- 1.013
- 1.143
- 1.017
- 1.0
- 1.144
- 1.004
- 1.123
- 1.003
- 1.133
- 0.993
- 1.129
- 0.988
- 1.119
- 0.994
- 0.973
- 1.117
- 1.107
unequal: 0
verbose: 1
