avg_train_accuracy: 0.79
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04867021276595745
- 0.08473404255319149
- 0.14436170212765959
- 0.2352659574468085
- 0.35132978723404257
- 0.4223936170212766
- 0.4570744680851064
- 0.49957446808510636
- 0.5212765957446809
- 0.5381914893617021
- 0.5579787234042554
- 0.5679787234042554
- 0.5823936170212766
- 0.5862765957446808
- 0.5983510638297872
- 0.6087234042553191
- 0.6161702127659574
- 0.6234574468085107
- 0.6306914893617022
- 0.6338297872340426
- 0.6343085106382979
- 0.6427127659574469
- 0.6470744680851064
- 0.6481382978723405
- 0.6547872340425532
- 0.6565425531914894
- 0.6598404255319149
- 0.663563829787234
- 0.6637234042553192
- 0.6670744680851064
- 0.38563829787234044
- 0.6694148936170212
- 0.6744148936170212
- 0.6762234042553191
- 0.6776063829787234
- 0.6797872340425531
- 0.6807446808510639
- 0.6851595744680851
- 0.6832446808510638
- 0.6861702127659575
- 0.6895744680851064
- 0.6895212765957447
- 0.6885106382978723
- 0.6909042553191489
- 0.6862234042553191
- 0.6959574468085107
- 0.6958510638297872
- 0.6960106382978724
- 0.6963829787234043
- 0.6984574468085106
- 0.6988829787234042
- 0.6957978723404256
- 0.7018085106382979
- 0.7032978723404255
- 0.7042021276595745
- 0.7043617021276596
- 0.7052659574468085
- 0.7013297872340426
- 0.7010106382978724
- 0.7063297872340426
- 0.7062234042553192
- 0.7075
- 0.7077127659574468
- 0.7067021276595745
- 0.7073404255319149
- 0.7081382978723404
- 0.7104255319148937
- 0.7126595744680851
- 0.7148404255319148
- 0.7130851063829787
- 0.7132446808510639
- 0.711063829787234
- 0.7125531914893617
- 0.7138829787234042
- 0.7161702127659575
- 0.7177127659574468
- 0.7164893617021276
- 0.7168085106382979
- 0.7217021276595744
- 0.7168085106382979
- 0.72
- 0.7179255319148936
- 0.7202659574468085
- 0.7222872340425532
- 0.721968085106383
- 0.7209042553191489
- 0.7211170212765957
- 0.7236702127659574
- 0.7240425531914894
- 0.7237234042553191
- 0.7217021276595744
- 0.7239893617021277
- 0.7252127659574468
- 0.7261702127659575
- 0.7273404255319149
- 0.7271276595744681
- 0.7252659574468086
- 0.7262765957446808
- 0.7237765957446809
- 0.7244148936170213
test_loss_list:
- 3.7795228099823
- 3.725033648808797
- 3.5836423110961912
- 3.28916251818339
- 2.9515257994333903
- 2.711723283131917
- 2.5615344142913816
- 2.4163350741068523
- 2.321342980066935
- 2.2504597234725954
- 2.174778140385946
- 2.139612092971802
- 2.085145837465922
- 2.0442605527242024
- 1.9982626342773437
- 2.000857637723287
- 1.989292696317037
- 1.9436535135904949
- 1.921860081354777
- 1.9373843145370484
- 1.906287930806478
- 1.8801860809326172
- 1.90956485748291
- 1.8667268006006876
- 1.895851780573527
- 1.846530392964681
- 1.8201946210861206
- 1.824384527206421
- 1.8131893459955852
- 1.7902968295415242
- 2.2075970649719237
- 1.5504018672307331
- 1.626704092025757
- 1.6319531138737997
- 1.639664494196574
- 1.6662676556905112
- 1.6386146434148152
- 1.6658210706710816
- 1.6211886564890543
- 1.6344818305969238
- 1.6319559510548909
- 1.6435008891423544
- 1.6031671555836995
- 1.6056863896052043
- 1.5931221675872802
- 1.6471247816085814
- 1.610048575401306
- 1.5959565019607544
- 1.5986356035868328
- 1.5958661063512167
- 1.5963091198603312
- 1.565765749613444
- 1.592951176961263
- 1.5457228453954062
- 1.6083233006795248
- 1.5830804840723673
- 1.583908878962199
- 1.5678537480036419
- 1.5343276135126749
- 1.5139239597320557
- 1.5254819377263387
- 1.518745036125183
- 1.5088796679178873
- 1.480103063583374
- 1.4993165349960327
- 1.4695771487553915
- 1.479912363688151
- 1.5087587420145672
- 1.5162041616439819
- 1.4876224915186564
- 1.493789898554484
- 1.4937608734766643
- 1.4924135398864746
- 1.474613577524821
- 1.4648277346293133
- 1.460843415260315
- 1.4512212546666463
- 1.4721772782007854
- 1.4867754538853963
- 1.4364444478352865
- 1.435293002128601
- 1.4248444255193073
- 1.4098071511586507
- 1.4343623288472493
- 1.4452760489781697
- 1.4523849598566692
- 1.4355963484446208
- 1.4078899606068929
- 1.4322555208206176
- 1.4141651344299317
- 1.4131268676122029
- 1.437189860343933
- 1.4287690019607544
- 1.4396046161651612
- 1.4609694147109986
- 1.4347901964187622
- 1.4083031590779622
- 1.3903806527455649
- 1.398924428621928
- 1.383493480682373
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.523
- 0.577
- 0.0
- 0.619
- 0.0
- 0.0
- 0.677
- 0.0
- 0.0
- 0.0
- 0.69
- 0.0
- 0.0
- 0.0
- 0.0
- 0.723
- 0.723
- 0.0
- 0.721
- 0.0
- 0.0
- 0.74
- 0.0
- 0.0
- 0.848
- 0.742
- 0.763
- 0.0
- 0.771
- 0.767
- 0.0
- 0.771
- 0.0
- 0.767
- 0.773
- 0.767
- 0.765
- 0.794
- 0.0
- 0.785
- 0.0
- 0.794
- 0.815
- 0.0
- 0.812
- 0.775
- 0.798
- 0.806
- 0.775
- 0.0
- 0.827
- 0.0
- 0.0
- 0.0
- 0.827
- 0.823
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.798
- 0.792
- 0.835
- 0.0
- 0.0
- 0.0
- 0.84
- 0.0
- 0.0
- 0.79
- 0.798
- 0.0
- 0.0
- 0.0
- 0.79
- 0.798
- 0.85
- 0.0
- 0.0
- 0.0
- 0.817
- 0.798
- 0.0
- 0.0
- 0.0
- 0.806
- 0.804
- 0.0
- 0.852
- 0.0
- 0.798
- 0.79
train_loss:
- 1.809
- 1.104
- 1.663
- 1.558
- 2.006
- 2.363
- 1.696
- 1.125
- 1.521
- 1.022
- 0.626
- 1.337
- 1.295
- 0.929
- 0.898
- 1.191
- 1.178
- 0.847
- 1.136
- 1.099
- 0.815
- 1.081
- 1.354
- 0.783
- 1.313
- 0.772
- 0.774
- 1.011
- 0.742
- 0.74
- 0.248
- 1.297
- 1.212
- 0.93
- 0.941
- 1.173
- 0.929
- 1.158
- 0.681
- 0.912
- 0.901
- 0.887
- 0.679
- 0.657
- 0.432
- 1.084
- 0.875
- 0.653
- 0.857
- 0.854
- 0.862
- 0.636
- 0.852
- 0.656
- 1.045
- 0.63
- 0.829
- 0.423
- 0.418
- 0.633
- 0.625
- 0.615
- 0.629
- 0.41
- 0.616
- 0.406
- 0.614
- 0.794
- 0.998
- 0.616
- 0.781
- 0.59
- 0.586
- 0.594
- 0.598
- 0.586
- 0.576
- 0.769
- 0.761
- 0.403
- 0.586
- 0.579
- 0.572
- 0.747
- 0.757
- 0.756
- 0.574
- 0.564
- 0.741
- 0.567
- 0.561
- 0.737
- 0.74
- 0.737
- 0.911
- 0.553
- 0.554
- 0.371
- 0.545
- 0.55
unequal: 0
verbose: 1
