avg_train_accuracy: 0.808
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.030797872340425532
- 0.05218085106382979
- 0.09510638297872341
- 0.21872340425531914
- 0.3227127659574468
- 0.4187234042553192
- 0.4718085106382979
- 0.5004787234042554
- 0.5225531914893617
- 0.5523936170212767
- 0.5540425531914893
- 0.581436170212766
- 0.585531914893617
- 0.5997340425531915
- 0.6073404255319149
- 0.6184042553191489
- 0.624095744680851
- 0.6277127659574468
- 0.6287234042553191
- 0.6370744680851064
- 0.644468085106383
- 0.6523936170212766
- 0.6529787234042553
- 0.6567553191489361
- 0.659468085106383
- 0.653936170212766
- 0.6643617021276595
- 0.6636170212765957
- 0.6681914893617021
- 0.6702127659574468
- 0.6718085106382978
- 0.678031914893617
- 0.6777659574468086
- 0.6828723404255319
- 0.6784574468085106
- 0.6800531914893617
- 0.6876063829787235
- 0.688404255319149
- 0.5153191489361703
- 0.6891489361702128
- 0.6847340425531915
- 0.6921808510638298
- 0.6934574468085106
- 0.6948404255319149
- 0.6924468085106383
- 0.6961702127659575
- 0.6967553191489362
- 0.6990425531914893
- 0.6997340425531915
- 0.6981914893617022
- 0.7017553191489362
- 0.6983510638297873
- 0.7006382978723404
- 0.7036702127659574
- 0.7033510638297872
- 0.7022872340425532
- 0.7031382978723404
- 0.703936170212766
- 0.7040425531914893
- 0.7057446808510638
- 0.7075531914893617
- 0.7049468085106383
- 0.706063829787234
- 0.7091489361702128
- 0.7109574468085106
- 0.7090425531914893
- 0.7103191489361702
- 0.7101595744680851
- 0.7070744680851064
- 0.7076595744680851
- 0.7075531914893617
- 0.7094680851063829
- 0.7124468085106384
- 0.7147340425531915
- 0.7117021276595744
- 0.7142021276595745
- 0.7164893617021276
- 0.7159042553191489
- 0.715
- 0.7176063829787234
- 0.7154255319148937
- 0.7163829787234043
- 0.716063829787234
- 0.7167553191489362
- 0.7172872340425532
- 0.716436170212766
- 0.7195212765957447
- 0.7153723404255319
- 0.7209042553191489
- 0.7209574468085106
- 0.7173936170212766
- 0.7156382978723405
- 0.7160106382978724
- 0.7218085106382979
- 0.7184574468085106
- 0.7228191489361702
- 0.7207446808510638
- 0.7176595744680851
- 0.7200531914893618
- 0.721968085106383
test_loss_list:
- 3.786261361440023
- 3.7499506219228107
- 3.647322546641032
- 3.3963367557525634
- 3.06116291364034
- 2.7585668055216472
- 2.5450004069010417
- 2.399954833984375
- 2.311863161722819
- 2.239214162826538
- 2.195823718706767
- 2.1815440241495767
- 2.121345876057943
- 2.0840561898549397
- 2.073164348602295
- 2.095052312215169
- 2.08793283144633
- 2.0118833573659263
- 2.001176743507385
- 1.9838955577214559
- 1.9936243041356405
- 2.010644017855326
- 1.9890927330652872
- 1.9237051709493
- 1.9212386496861775
- 1.904102741877238
- 1.9268899695078532
- 1.8885563945770263
- 1.915202775001526
- 1.8861036348342894
- 1.8654725297292074
- 1.8870294507344563
- 1.830505232810974
- 1.8883074013392132
- 1.8224794228871664
- 1.8306335067749024
- 1.837053942680359
- 1.8332456747690837
- 1.6416181929906208
- 1.4772288688023885
- 1.5203885984420777
- 1.6172953128814698
- 1.6415194702148437
- 1.6317469755808511
- 1.6067477703094482
- 1.634123641649882
- 1.5903011020024618
- 1.6185505088170369
- 1.6296363751093546
- 1.6065151484807332
- 1.5872381607691446
- 1.6152993790308634
- 1.604684755007426
- 1.616281410853068
- 1.600575057665507
- 1.590195279121399
- 1.5822951459884644
- 1.5650697231292725
- 1.5524517822265624
- 1.5778356138865153
- 1.604550592104594
- 1.5638513485590617
- 1.5502640183766683
- 1.5257188113530478
- 1.4959936825434368
- 1.526649643580119
- 1.5414296277364095
- 1.5476218859354656
- 1.498581682840983
- 1.5443982394536335
- 1.5266819032033285
- 1.5158948183059693
- 1.538374786376953
- 1.5186880000432332
- 1.494320987065633
- 1.5264447291692098
- 1.4765066194534302
- 1.466541026433309
- 1.5323788944880168
- 1.5281278959910074
- 1.4949128786722818
- 1.4879248205820719
- 1.4661758629480999
- 1.508935407002767
- 1.4624789571762085
- 1.4920403480529785
- 1.4891257699330647
- 1.4720226669311522
- 1.487855478922526
- 1.4835875813166302
- 1.4499154822031657
- 1.444557819366455
- 1.4763264989852904
- 1.4392904122670491
- 1.4553700367609659
- 1.4403731520970662
- 1.4345154666900635
- 1.422874010403951
- 1.450333728790283
- 1.4038275067011516
train_accuracy:
- 0.044
- 0.067
- 0.094
- 0.252
- 0.0
- 0.479
- 0.55
- 0.0
- 0.0
- 0.65
- 0.0
- 0.646
- 0.0
- 0.694
- 0.675
- 0.0
- 0.708
- 0.713
- 0.717
- 0.717
- 0.742
- 0.735
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.746
- 0.0
- 0.0
- 0.0
- 0.756
- 0.769
- 0.0
- 0.0
- 0.0
- 0.769
- 0.696
- 0.785
- 0.779
- 0.771
- 0.785
- 0.781
- 0.0
- 0.0
- 0.781
- 0.798
- 0.773
- 0.81
- 0.0
- 0.798
- 0.0
- 0.8
- 0.79
- 0.0
- 0.773
- 0.806
- 0.804
- 0.819
- 0.792
- 0.804
- 0.777
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.815
- 0.796
- 0.796
- 0.0
- 0.0
- 0.802
- 0.0
- 0.0
- 0.0
- 0.812
- 0.812
- 0.81
- 0.0
- 0.802
- 0.808
- 0.835
- 0.81
- 0.808
- 0.815
- 0.84
- 0.0
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.821
- 0.0
- 0.0
- 0.808
train_loss:
- 2.501
- 2.475
- 2.382
- 2.245
- 0.843
- 2.42
- 2.209
- 0.69
- 0.656
- 1.428
- 0.62
- 1.689
- 0.961
- 0.914
- 1.215
- 1.498
- 1.482
- 0.851
- 0.824
- 0.842
- 1.078
- 1.329
- 1.042
- 0.774
- 0.747
- 0.511
- 0.992
- 0.751
- 0.984
- 0.716
- 0.732
- 0.945
- 0.728
- 1.152
- 0.468
- 0.677
- 0.906
- 0.914
- 0.247
- 0.89
- 0.634
- 1.09
- 1.083
- 0.859
- 0.645
- 0.842
- 0.62
- 0.836
- 0.834
- 0.622
- 0.619
- 0.819
- 0.807
- 0.814
- 0.816
- 0.607
- 0.609
- 0.605
- 0.594
- 0.798
- 0.998
- 0.592
- 0.601
- 0.581
- 0.39
- 0.573
- 0.78
- 0.772
- 0.392
- 0.565
- 0.569
- 0.57
- 0.954
- 0.76
- 0.395
- 0.744
- 0.573
- 0.552
- 0.943
- 0.929
- 0.548
- 0.586
- 0.569
- 0.915
- 0.555
- 0.74
- 0.736
- 0.549
- 0.731
- 0.727
- 0.558
- 0.365
- 0.735
- 0.544
- 0.72
- 0.554
- 0.53
- 0.534
- 0.721
- 0.53
unequal: 0
verbose: 1
