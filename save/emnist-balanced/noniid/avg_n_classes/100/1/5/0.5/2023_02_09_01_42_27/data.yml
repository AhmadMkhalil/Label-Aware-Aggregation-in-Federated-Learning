avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05686170212765958
- 0.1072340425531915
- 0.16489361702127658
- 0.28388297872340423
- 0.3922340425531915
- 0.4542553191489362
- 0.4943085106382979
- 0.5261702127659574
- 0.535904255319149
- 0.5469148936170213
- 0.5637234042553192
- 0.574468085106383
- 0.5870212765957447
- 0.5976063829787234
- 0.5993085106382978
- 0.6121808510638298
- 0.6109042553191489
- 0.6217553191489362
- 0.6264893617021277
- 0.6313297872340425
- 0.6377659574468085
- 0.637127659574468
- 0.6423936170212766
- 0.6437765957446808
- 0.6500531914893617
- 0.6552127659574468
- 0.6575
- 0.6625531914893616
- 0.6622872340425532
- 0.6679787234042553
- 0.671595744680851
- 0.6690957446808511
- 0.6736702127659574
- 0.6747340425531915
- 0.6776595744680851
- 0.676063829787234
- 0.6790425531914893
- 0.6855851063829788
- 0.6869148936170213
- 0.6851063829787234
- 0.6862765957446808
- 0.6826595744680851
- 0.6889893617021277
- 0.6903191489361702
- 0.6939893617021277
- 0.6943085106382979
- 0.6962234042553191
- 0.6986702127659574
- 0.7003191489361702
- 0.6917553191489362
- 0.7
- 0.7037765957446809
- 0.7028191489361703
- 0.7051063829787234
- 0.7062765957446808
- 0.7065425531914894
- 0.7063829787234043
- 0.7083510638297872
- 0.7097872340425532
- 0.7096808510638298
- 0.7056382978723404
- 0.7058510638297872
- 0.7086702127659574
- 0.7112234042553192
- 0.7107978723404256
- 0.7045744680851064
- 0.7140425531914893
- 0.714627659574468
- 0.7137765957446809
- 0.7135106382978723
- 0.7129255319148936
- 0.7093085106382979
- 0.7174468085106382
- 0.7178723404255319
- 0.7167021276595744
- 0.716968085106383
- 0.7169148936170213
- 0.7177127659574468
- 0.7193085106382979
- 0.7197340425531915
- 0.7204255319148937
- 0.7215425531914894
- 0.7183510638297872
- 0.7199468085106383
- 0.7210106382978724
- 0.7211702127659575
- 0.7219148936170213
- 0.7210106382978724
- 0.7257978723404256
- 0.7219148936170213
- 0.7252659574468086
- 0.7136170212765958
- 0.7218617021276595
- 0.7187234042553191
- 0.7232446808510639
- 0.723404255319149
- 0.7262765957446808
- 0.7249468085106383
- 0.7235106382978723
- 0.7250531914893616
test_loss_list:
- 3.7745793596903483
- 3.7092199484507242
- 3.5307757568359377
- 3.1977034854888915
- 2.853676077524821
- 2.619443089167277
- 2.4450466124216717
- 2.3281422742207845
- 2.2547885592778525
- 2.1850868686040243
- 2.123337621688843
- 2.092490577697754
- 2.06337872505188
- 2.044708924293518
- 1.9835415077209473
- 1.9923319880167643
- 1.9344409290949505
- 1.9375326617558797
- 1.875809899965922
- 1.8642070484161377
- 1.8547666597366332
- 1.8460216999053956
- 1.8185937595367432
- 1.798362806638082
- 1.7948550605773925
- 1.7539991346995036
- 1.767344339688619
- 1.7546663014094035
- 1.7372818104426067
- 1.7495428196589151
- 1.73229771455129
- 1.7113429148991903
- 1.7058141040802002
- 1.666920067469279
- 1.6707699584960938
- 1.6708182986577351
- 1.651680596669515
- 1.644430882136027
- 1.6667083660761515
- 1.6537271944681804
- 1.6396988455454509
- 1.6056666231155396
- 1.6063084506988525
- 1.6063482236862183
- 1.6134634256362914
- 1.6135436121622722
- 1.604461997350057
- 1.6249240271250407
- 1.6118578433990478
- 1.605272634824117
- 1.5936416292190552
- 1.5809295543034871
- 1.5996647612253825
- 1.5456659205754597
- 1.5750233999888101
- 1.53424174785614
- 1.5220751031239828
- 1.5331579192479452
- 1.5678641239802042
- 1.562159776687622
- 1.4844669914245605
- 1.5194131962458293
- 1.5236855681737265
- 1.5155099868774413
- 1.4999104611078897
- 1.4631603749593098
- 1.4890801016489665
- 1.5270179319381714
- 1.5016838041941325
- 1.4967653608322145
- 1.4580683517456055
- 1.4581493298212687
- 1.4472005049387613
- 1.5064356803894043
- 1.5022662734985353
- 1.481512695948283
- 1.4970424699783325
- 1.4463113816579183
- 1.4664345200856526
- 1.4864324887593587
- 1.4738259363174437
- 1.4384251928329468
- 1.4814568440119424
- 1.4315727392832438
- 1.4471894216537475
- 1.4696974261601765
- 1.48004123210907
- 1.41689280351003
- 1.459524647394816
- 1.4512623167037964
- 1.439950410525004
- 1.4033424139022828
- 1.3637572145462036
- 1.4055718660354615
- 1.366770814259847
- 1.3861338710784912
- 1.3858171049753825
- 1.3690881633758545
- 1.384089511235555
- 1.3693661340077719
train_accuracy:
- 0.065
- 0.113
- 0.0
- 0.0
- 0.412
- 0.527
- 0.579
- 0.0
- 0.0
- 0.0
- 0.648
- 0.0
- 0.0
- 0.66
- 0.688
- 0.0
- 0.0
- 0.0
- 0.0
- 0.721
- 0.763
- 0.0
- 0.729
- 0.746
- 0.742
- 0.0
- 0.719
- 0.75
- 0.0
- 0.0
- 0.76
- 0.756
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.804
- 0.808
- 0.817
- 0.0
- 0.0
- 0.823
- 0.0
- 0.775
- 0.79
- 0.0
- 0.0
- 0.777
- 0.0
- 0.79
- 0.785
- 0.802
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.787
- 0.783
- 0.819
- 0.0
- 0.0
- 0.804
- 0.0
- 0.802
- 0.792
- 0.821
- 0.0
- 0.804
- 0.0
- 0.792
- 0.0
- 0.812
- 0.819
- 0.0
- 0.846
- 0.804
- 0.0
- 0.821
- 0.0
- 0.81
- 0.0
- 0.838
- 0.806
- 0.815
- 0.827
- 0.844
- 0.0
- 0.846
- 0.0
- 0.792
- 0.827
- 0.0
- 0.842
- 0.0
- 0.817
- 0.0
- 0.835
- 0.0
train_loss:
- 1.734
- 2.419
- 1.648
- 2.142
- 1.946
- 1.246
- 1.162
- 1.116
- 1.067
- 0.619
- 0.995
- 1.34
- 1.295
- 1.256
- 0.903
- 1.543
- 0.897
- 1.169
- 0.854
- 0.849
- 1.114
- 0.821
- 0.814
- 0.779
- 1.066
- 0.779
- 0.757
- 1.016
- 0.755
- 0.986
- 0.997
- 0.726
- 0.966
- 0.712
- 0.698
- 0.704
- 0.916
- 0.682
- 0.902
- 0.681
- 0.678
- 0.442
- 0.676
- 0.654
- 0.863
- 0.862
- 0.628
- 1.077
- 0.857
- 0.431
- 0.835
- 0.846
- 0.84
- 0.627
- 0.822
- 0.631
- 0.628
- 0.612
- 1.005
- 0.805
- 0.426
- 0.403
- 0.596
- 0.6
- 0.8
- 0.393
- 0.578
- 0.965
- 0.787
- 0.586
- 0.594
- 0.593
- 0.574
- 0.948
- 0.755
- 0.776
- 0.75
- 0.587
- 0.565
- 0.75
- 0.751
- 0.587
- 0.744
- 0.573
- 0.559
- 0.741
- 0.918
- 0.575
- 0.721
- 0.558
- 0.739
- 0.369
- 0.38
- 0.363
- 0.555
- 0.54
- 0.534
- 0.544
- 0.524
- 0.526
unequal: 0
verbose: 1
