avg_train_accuracy: 0.0
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.030425531914893618
- 0.0873936170212766
- 0.21111702127659573
- 0.33074468085106384
- 0.3887765957446809
- 0.44457446808510637
- 0.48164893617021276
- 0.512127659574468
- 0.5296276595744681
- 0.5484574468085106
- 0.5643085106382979
- 0.5779255319148936
- 0.5847340425531915
- 0.5978191489361702
- 0.6054787234042553
- 0.6143617021276596
- 0.6203191489361702
- 0.6236170212765958
- 0.6345744680851064
- 0.6418617021276596
- 0.6443617021276595
- 0.6505319148936171
- 0.6537234042553192
- 0.6548936170212766
- 0.658936170212766
- 0.6628191489361702
- 0.6637765957446808
- 0.665372340425532
- 0.6651063829787234
- 0.673031914893617
- 0.6746808510638298
- 0.6765425531914894
- 0.6738297872340425
- 0.6786170212765957
- 0.6835638297872341
- 0.6831914893617022
- 0.6856382978723404
- 0.6882978723404255
- 0.6888829787234042
- 0.6869148936170213
- 0.6936702127659574
- 0.6879255319148936
- 0.6902127659574468
- 0.6971276595744681
- 0.6986170212765958
- 0.6985638297872341
- 0.6956914893617021
- 0.6966489361702127
- 0.7011702127659575
- 0.704095744680851
- 0.7018085106382979
- 0.7040425531914893
- 0.7044680851063829
- 0.7081382978723404
- 0.705531914893617
- 0.7092021276595745
- 0.705
- 0.7051063829787234
- 0.7113829787234043
- 0.7127127659574468
- 0.711436170212766
- 0.7098404255319148
- 0.7081914893617022
- 0.7128191489361703
- 0.7136170212765958
- 0.7128191489361703
- 0.7118617021276595
- 0.7124468085106384
- 0.7175
- 0.7170744680851063
- 0.7161702127659575
- 0.7187234042553191
- 0.7182446808510639
- 0.7132978723404255
- 0.7162765957446808
- 0.7197340425531915
- 0.7204255319148937
- 0.7177127659574468
- 0.7198404255319149
- 0.7215425531914894
- 0.5237234042553192
- 0.7180851063829787
- 0.721436170212766
- 0.719095744680851
- 0.7231914893617021
- 0.7193085106382979
- 0.7214893617021276
- 0.7227659574468085
- 0.7219148936170213
- 0.7206382978723405
- 0.7242021276595745
- 0.7254787234042553
- 0.7255851063829787
- 0.7236702127659574
- 0.7247872340425532
- 0.7254255319148936
- 0.7262765957446808
- 0.7279255319148936
- 0.7272340425531915
- 0.7242553191489361
test_loss_list:
- 3.768615264892578
- 3.69045202255249
- 3.492592287063599
- 3.13973206837972
- 2.8217785135904947
- 2.585149501164754
- 2.4050372568766276
- 2.2857441679636636
- 2.199194885889689
- 2.1156091753641766
- 2.062004934946696
- 2.0243425607681274
- 1.9816646067301433
- 1.934227574666341
- 1.910647408167521
- 1.9185402870178223
- 1.8667281818389894
- 1.8505299425125121
- 1.8503300460179646
- 1.849571426709493
- 1.8150658305486043
- 1.806870271364848
- 1.8330300331115723
- 1.786158905029297
- 1.7701994625727335
- 1.802617359161377
- 1.75246209303538
- 1.7368913809458415
- 1.717161742846171
- 1.6960390599568684
- 1.7122602081298828
- 1.7092040141423543
- 1.6853499905268352
- 1.6882545693715414
- 1.704852754275004
- 1.6736456632614136
- 1.7117365566889444
- 1.662916711171468
- 1.6992183113098145
- 1.663509791692098
- 1.7005922921498617
- 1.6313771979014078
- 1.6438250144322712
- 1.656968420346578
- 1.676004327138265
- 1.6836934502919514
- 1.6017871809005737
- 1.6116868543624878
- 1.62185772895813
- 1.617886226971944
- 1.6172041559219361
- 1.6036718066533406
- 1.6050325314203897
- 1.6254381370544433
- 1.6173481114705404
- 1.6126741886138916
- 1.5507422908147177
- 1.562834636370341
- 1.6023116254806518
- 1.6221071688334148
- 1.5819615761439005
- 1.5686461130777996
- 1.5046187543869018
- 1.5530734491348266
- 1.5680334234237672
- 1.5368807077407838
- 1.5119136635462442
- 1.5087585274378459
- 1.5464295864105224
- 1.4835141309102375
- 1.4862437629699707
- 1.5232538175582886
- 1.519463537534078
- 1.494776782989502
- 1.4835635709762574
- 1.4461704683303833
- 1.4983020305633545
- 1.4525519100824993
- 1.50210959593455
- 1.4604992373784382
- 1.600043150583903
- 1.2161990777651468
- 1.3088985220591227
- 1.2815784088770548
- 1.3357740338643391
- 1.3090743192036947
- 1.3267023229599
- 1.309044148127238
- 1.3421886730194093
- 1.3069434022903443
- 1.3826853068669638
- 1.3011042563120525
- 1.3696760209401448
- 1.3051397546132406
- 1.323572047551473
- 1.3414062706629435
- 1.3622510703404744
- 1.3535576709111532
- 1.3730942980448404
- 1.3455289125442504
train_accuracy:
- 0.0
- 0.092
- 0.215
- 0.337
- 0.0
- 0.0
- 0.0
- 0.562
- 0.0
- 0.0
- 0.0
- 0.629
- 0.0
- 0.0
- 0.0
- 0.658
- 0.0
- 0.0
- 0.0
- 0.681
- 0.0
- 0.0
- 0.696
- 0.706
- 0.769
- 0.715
- 0.723
- 0.715
- 0.0
- 0.0
- 0.0
- 0.731
- 0.0
- 0.777
- 0.765
- 0.771
- 0.744
- 0.0
- 0.787
- 0.758
- 0.763
- 0.792
- 0.765
- 0.0
- 0.735
- 0.0
- 0.0
- 0.0
- 0.773
- 0.796
- 0.0
- 0.0
- 0.0
- 0.771
- 0.785
- 0.808
- 0.0
- 0.0
- 0.81
- 0.775
- 0.823
- 0.0
- 0.0
- 0.779
- 0.825
- 0.781
- 0.783
- 0.0
- 0.79
- 0.79
- 0.0
- 0.798
- 0.798
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.794
- 0.0
- 0.544
- 0.0
- 0.0
- 0.0
- 0.84
- 0.825
- 0.8
- 0.831
- 0.0
- 0.0
- 0.829
- 0.0
- 0.823
- 0.842
- 0.804
- 0.0
- 0.792
- 0.792
- 0.842
- 0.0
train_loss:
- 2.449
- 2.407
- 2.31
- 2.134
- 0.774
- 1.243
- 1.648
- 1.539
- 1.03
- 1.012
- 1.368
- 1.304
- 0.935
- 0.904
- 0.88
- 1.182
- 0.849
- 0.531
- 0.812
- 1.098
- 0.791
- 1.073
- 1.322
- 0.766
- 1.027
- 0.998
- 0.748
- 0.741
- 0.721
- 0.733
- 0.704
- 0.703
- 0.701
- 0.705
- 0.916
- 0.921
- 1.148
- 0.676
- 1.131
- 0.666
- 0.872
- 0.665
- 0.643
- 0.858
- 1.079
- 1.073
- 0.669
- 0.636
- 0.846
- 0.845
- 0.845
- 0.838
- 0.613
- 1.015
- 0.801
- 0.813
- 0.63
- 0.41
- 1.012
- 1.014
- 0.816
- 0.407
- 0.41
- 0.573
- 0.985
- 0.781
- 0.592
- 0.393
- 0.76
- 0.593
- 0.583
- 0.969
- 0.761
- 0.372
- 0.765
- 0.583
- 0.739
- 0.569
- 0.732
- 0.592
- 0.194
- 0.516
- 0.917
- 0.344
- 0.724
- 0.54
- 0.526
- 0.547
- 0.521
- 0.537
- 0.892
- 0.555
- 0.697
- 0.548
- 0.52
- 0.709
- 0.693
- 0.702
- 0.698
- 0.349
unequal: 0
verbose: 1
