avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041382978723404254
- 0.1000531914893617
- 0.20138297872340424
- 0.2823936170212766
- 0.4048936170212766
- 0.4394148936170213
- 0.4975
- 0.5124468085106383
- 0.5396276595744681
- 0.5561702127659575
- 0.5726063829787233
- 0.5767553191489362
- 0.5887765957446809
- 0.5951063829787234
- 0.6063829787234043
- 0.6108510638297873
- 0.6147340425531915
- 0.623031914893617
- 0.6262765957446809
- 0.6320212765957447
- 0.6329787234042553
- 0.6399468085106383
- 0.6404787234042553
- 0.6428723404255319
- 0.6461702127659574
- 0.649468085106383
- 0.6546808510638298
- 0.6606382978723404
- 0.6586170212765957
- 0.6583510638297873
- 0.6643085106382979
- 0.6663297872340426
- 0.6686170212765957
- 0.6706914893617021
- 0.6749468085106383
- 0.675
- 0.676595744680851
- 0.6825531914893617
- 0.6801063829787234
- 0.6817553191489362
- 0.6852127659574468
- 0.6892553191489361
- 0.6917021276595745
- 0.6901063829787234
- 0.6902659574468085
- 0.6912234042553191
- 0.6858510638297872
- 0.6923936170212766
- 0.6960106382978724
- 0.696968085106383
- 0.6962234042553191
- 0.6982446808510638
- 0.6998936170212766
- 0.699840425531915
- 0.7044148936170213
- 0.7025
- 0.7071276595744681
- 0.7076063829787234
- 0.706063829787234
- 0.7031382978723404
- 0.7074468085106383
- 0.7079787234042553
- 0.7081382978723404
- 0.709627659574468
- 0.7113297872340425
- 0.7085106382978723
- 0.7078191489361703
- 0.7153191489361702
- 0.7075531914893617
- 0.7117553191489362
- 0.7121276595744681
- 0.715
- 0.7147872340425532
- 0.7168085106382979
- 0.7142553191489361
- 0.716063829787234
- 0.7168085106382979
- 0.7165425531914894
- 0.7180851063829787
- 0.7171276595744681
- 0.7161702127659575
- 0.7187234042553191
- 0.716968085106383
- 0.7196276595744681
- 0.7153723404255319
- 0.7163829787234043
- 0.7195212765957447
- 0.7207978723404256
- 0.7204255319148937
- 0.7211170212765957
- 0.7199468085106383
- 0.7243617021276596
- 0.7206914893617021
- 0.7197872340425532
- 0.7228191489361702
- 0.7220744680851063
- 0.7207446808510638
- 0.7242553191489361
- 0.7206382978723405
- 0.7230319148936171
test_loss_list:
- 3.771072050730387
- 3.7049633026123048
- 3.499264990488688
- 3.162854331334432
- 2.84865195274353
- 2.6383201694488525
- 2.465458402633667
- 2.350382308959961
- 2.2557489474614463
- 2.2023881085713706
- 2.172929844856262
- 2.0997282552719114
- 2.1013371674219767
- 2.053063062032064
- 2.0203254318237303
- 2.0434055693944297
- 1.9902018690109253
- 1.9994197956720987
- 1.9879942019780477
- 1.969944871266683
- 1.9377632490793864
- 1.9680712366104125
- 1.9203231795628866
- 1.9243397251764933
- 1.8913514105478924
- 1.8592323096593222
- 1.8573988755544026
- 1.8448475058873495
- 1.8577490504582723
- 1.8326118993759155
- 1.8221257686614991
- 1.8097050825754801
- 1.830796397527059
- 1.7566004276275635
- 1.7986116139094035
- 1.7934827534357707
- 1.7479840485254923
- 1.7948836231231688
- 1.7283111651738485
- 1.703676815032959
- 1.7165960597991943
- 1.7484648895263672
- 1.7373594490687052
- 1.7294707775115967
- 1.6723713890711467
- 1.6595065752665201
- 1.6462424898147583
- 1.6340758879979451
- 1.6393428166707358
- 1.6279259045918784
- 1.6348031489054362
- 1.6303824631373087
- 1.6412749242782594
- 1.5926395018895467
- 1.6403912130991618
- 1.5966589069366455
- 1.6304397424062094
- 1.6026853783925374
- 1.599474328358968
- 1.5773964436848957
- 1.5826883443196615
- 1.611759918530782
- 1.587457257906596
- 1.5453030745188394
- 1.5710592699050903
- 1.5555013386408487
- 1.5122539520263671
- 1.571862392425537
- 1.5191593011220297
- 1.5241135803858439
- 1.520060846010844
- 1.5141717386245728
- 1.5263802003860474
- 1.5035508330663045
- 1.4923044363657634
- 1.497713754971822
- 1.5035601743062337
- 1.4637552293141682
- 1.4803159093856813
- 1.4808768192927042
- 1.4642363214492797
- 1.5135298411051432
- 1.4688288577397663
- 1.478555653889974
- 1.4595069233576456
- 1.4249927711486816
- 1.471286374727885
- 1.4467115879058838
- 1.4466730054219563
- 1.4389083925882975
- 1.461903494199117
- 1.4733755620320639
- 1.4384005022048951
- 1.4225809081395466
- 1.451197706858317
- 1.4046384286880493
- 1.4295802768071493
- 1.429127384821574
- 1.4120970074335735
- 1.4040792147318522
train_accuracy:
- 0.048
- 0.119
- 0.248
- 0.0
- 0.479
- 0.0
- 0.0
- 0.0
- 0.0
- 0.648
- 0.656
- 0.0
- 0.675
- 0.683
- 0.0
- 0.679
- 0.723
- 0.725
- 0.694
- 0.721
- 0.719
- 0.0
- 0.0
- 0.75
- 0.727
- 0.0
- 0.752
- 0.0
- 0.758
- 0.0
- 0.0
- 0.765
- 0.0
- 0.0
- 0.752
- 0.0
- 0.0
- 0.775
- 0.775
- 0.0
- 0.0
- 0.0
- 0.777
- 0.773
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.771
- 0.767
- 0.79
- 0.0
- 0.794
- 0.0
- 0.802
- 0.812
- 0.0
- 0.802
- 0.0
- 0.808
- 0.0
- 0.0
- 0.808
- 0.819
- 0.0
- 0.785
- 0.0
- 0.794
- 0.804
- 0.0
- 0.0
- 0.0
- 0.0
- 0.804
- 0.796
- 0.781
- 0.0
- 0.0
- 0.815
- 0.794
- 0.0
- 0.0
- 0.0
- 0.825
- 0.819
- 0.817
- 0.0
- 0.823
- 0.819
- 0.819
- 0.0
- 0.815
- 0.0
- 0.796
- 0.817
- 0.833
- 0.821
- 0.0
train_loss:
- 1.707
- 2.397
- 2.291
- 1.5
- 1.916
- 0.728
- 1.613
- 0.644
- 1.045
- 1.362
- 1.693
- 0.952
- 1.253
- 0.578
- 0.875
- 1.159
- 0.837
- 1.121
- 1.121
- 1.094
- 0.79
- 1.344
- 0.79
- 0.757
- 0.758
- 0.77
- 1.017
- 0.733
- 0.994
- 0.492
- 0.964
- 0.953
- 0.935
- 0.734
- 0.93
- 0.921
- 0.688
- 1.148
- 0.686
- 0.673
- 0.689
- 0.877
- 0.881
- 0.863
- 0.673
- 0.428
- 0.436
- 0.668
- 0.871
- 0.429
- 0.851
- 0.624
- 0.842
- 0.639
- 1.034
- 0.623
- 1.008
- 0.614
- 0.805
- 0.613
- 0.813
- 1.001
- 0.614
- 0.608
- 0.793
- 0.6
- 0.416
- 0.966
- 0.411
- 0.784
- 0.598
- 0.783
- 0.77
- 0.576
- 0.571
- 0.759
- 0.759
- 0.579
- 0.576
- 0.581
- 0.571
- 0.929
- 0.554
- 0.736
- 0.382
- 0.571
- 0.744
- 0.546
- 0.753
- 0.554
- 0.72
- 0.9
- 0.53
- 0.544
- 0.72
- 0.559
- 0.537
- 0.725
- 0.535
- 0.539
unequal: 0
verbose: 1
