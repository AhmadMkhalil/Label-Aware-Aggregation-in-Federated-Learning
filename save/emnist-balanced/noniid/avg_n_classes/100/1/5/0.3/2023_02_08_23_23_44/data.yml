avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.050691489361702126
- 0.06409574468085107
- 0.11829787234042553
- 0.21893617021276596
- 0.3091489361702128
- 0.3642021276595745
- 0.43792553191489364
- 0.06351063829787235
- 0.45904255319148934
- 0.49159574468085104
- 0.5109574468085106
- 0.5242021276595744
- 0.5470744680851064
- 0.09287234042553191
- 0.5623404255319149
- 0.13446808510638297
- 0.5693617021276596
- 0.22324468085106383
- 0.5786702127659574
- 0.2806382978723404
- 0.5882446808510639
- 0.5881382978723404
- 0.6038829787234042
- 0.6137765957446808
- 0.6176595744680851
- 0.34164893617021275
- 0.6128191489361702
- 0.6264893617021277
- 0.6336702127659575
- 0.6325531914893617
- 0.6336170212765957
- 0.645531914893617
- 0.6457446808510638
- 0.6507978723404255
- 0.6547340425531915
- 0.6562765957446809
- 0.6513829787234042
- 0.660904255319149
- 0.665
- 0.663563829787234
- 0.6693085106382979
- 0.6640425531914894
- 0.6663829787234042
- 0.6687765957446808
- 0.6757978723404255
- 0.674468085106383
- 0.6734042553191489
- 0.6695744680851063
- 0.4528191489361702
- 0.14117021276595745
- 0.6775
- 0.6811702127659575
- 0.6832446808510638
- 0.6797872340425531
- 0.6876595744680851
- 0.6859042553191489
- 0.685
- 0.6840957446808511
- 0.6835638297872341
- 0.6884574468085106
- 0.6864361702127659
- 0.6898936170212766
- 0.6921276595744681
- 0.5445212765957447
- 0.3002127659574468
- 0.6906914893617021
- 0.6932446808510638
- 0.6889893617021277
- 0.6957978723404256
- 0.6873936170212765
- 0.6982446808510638
- 0.6990957446808511
- 0.7008510638297872
- 0.6972340425531914
- 0.7008510638297872
- 0.7051595744680851
- 0.6987765957446809
- 0.7052127659574469
- 0.7032446808510638
- 0.5464893617021277
- 0.6972340425531914
- 0.7022340425531914
- 0.7043085106382979
- 0.7085106382978723
- 0.7072872340425532
- 0.7044680851063829
- 0.7045212765957447
- 0.7056382978723404
- 0.7118617021276595
- 0.7092553191489361
- 0.7095212765957447
- 0.7108510638297872
- 0.7064893617021276
- 0.7098936170212766
- 0.7144148936170213
- 0.7138829787234042
- 0.7154255319148937
- 0.7130319148936171
- 0.7118085106382979
- 0.7160106382978724
test_loss_list:
- 3.7817925198872886
- 3.749650262196859
- 3.6452796173095705
- 3.375855401357015
- 3.0419156138102212
- 2.7607369899749754
- 2.575435981750488
- 5.158262570699056
- 2.3894053014119465
- 2.2835985024770102
- 2.2273926162719726
- 2.170239896774292
- 2.1160983196894327
- 4.688027578989665
- 2.00260479927063
- 3.526260945002238
- 1.8484393660227458
- 3.0695721244812013
- 1.7479014046986898
- 2.8339774481455486
- 1.6940881458918253
- 1.7199860588709512
- 1.714564297993978
- 1.7287042840321858
- 1.7262386878331502
- 2.3520915063222247
- 1.5812388674418132
- 1.6021703084309895
- 1.6103591616948445
- 1.6068646732966105
- 1.6346110566457113
- 1.6189857641855876
- 1.6480999898910522
- 1.6285361735026043
- 1.64302916208903
- 1.641808352470398
- 1.6456128152211507
- 1.6350491666793823
- 1.638243759473165
- 1.6261381387710572
- 1.6342732906341553
- 1.6242151800791422
- 1.629285740852356
- 1.6086741987864177
- 1.6359773317972819
- 1.6341942389806112
- 1.624000465075175
- 1.6387394634882608
- 1.9074129056930542
- 4.858837140401205
- 1.330845659573873
- 1.3853260246912638
- 1.3897899961471558
- 1.4110858201980592
- 1.4235989475250244
- 1.449270668029785
- 1.45477037747701
- 1.4370923074086508
- 1.4384612258275349
- 1.4549511003494262
- 1.4698848724365234
- 1.4737300984064738
- 1.4735699542363485
- 1.63275998433431
- 3.2347684065500895
- 1.1969512232144675
- 1.2561900424957275
- 1.2916581455866496
- 1.3103546126683554
- 1.3244296884536744
- 1.330337586402893
- 1.355638009707133
- 1.3579655996958415
- 1.352135682106018
- 1.3413845745722452
- 1.370216908454895
- 1.3589987866083781
- 1.3705751101175945
- 1.3637103462219238
- 1.5641226307551066
- 1.165593129793803
- 1.2113583580652874
- 1.2464336148897808
- 1.2579919338226317
- 1.2808862845102946
- 1.2764290142059327
- 1.2789574607213339
- 1.2818009185791015
- 1.2946777582168578
- 1.3126784785588583
- 1.3108685461680094
- 1.3262834485371908
- 1.3016508785883585
- 1.3167138655980428
- 1.3179204018910726
- 1.3077147579193116
- 1.3102112261454264
- 1.323501043319702
- 1.2997835365931194
- 1.311781579653422
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.246
- 0.36
- 0.0
- 0.0
- 0.815
- 0.0
- 0.546
- 0.0
- 0.562
- 0.0
- 0.983
- 0.623
- 0.894
- 0.625
- 0.821
- 0.0
- 0.988
- 0.646
- 0.0
- 0.7
- 0.698
- 0.683
- 0.942
- 0.0
- 0.685
- 0.725
- 0.677
- 0.677
- 0.0
- 0.0
- 0.71
- 0.756
- 0.754
- 0.0
- 0.0
- 0.767
- 0.0
- 0.0
- 0.0
- 0.777
- 0.0
- 0.727
- 0.0
- 0.0
- 0.779
- 0.871
- 0.967
- 0.002
- 0.737
- 0.0
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.796
- 0.756
- 0.0
- 0.0
- 0.806
- 0.971
- 0.983
- 0.756
- 0.773
- 0.76
- 0.777
- 0.765
- 0.0
- 0.0
- 0.76
- 0.0
- 0.783
- 0.769
- 0.815
- 0.758
- 0.0
- 0.95
- 0.0
- 0.0
- 0.785
- 0.769
- 0.758
- 0.785
- 0.769
- 0.0
- 0.0
- 0.769
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.825
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 1.529
- 2.679
- 2.649
- 2.48
- 1.246
- 1.128
- 1.892
- 0.186
- 0.975
- 1.674
- 0.895
- 0.851
- 1.478
- 0.195
- 1.449
- 0.197
- 1.403
- 0.136
- 0.704
- 0.108
- 1.365
- 0.726
- 1.295
- 1.778
- 1.207
- 0.169
- 0.623
- 1.161
- 1.157
- 0.633
- 1.167
- 1.176
- 1.108
- 1.087
- 1.555
- 1.08
- 0.609
- 1.056
- 1.054
- 0.657
- 0.632
- 0.617
- 0.601
- 0.628
- 1.415
- 0.992
- 0.586
- 0.558
- 0.254
- 0.106
- 1.047
- 0.974
- 0.575
- 0.569
- 1.37
- 0.953
- 0.587
- 0.55
- 0.536
- 0.944
- 0.545
- 0.941
- 0.918
- 0.214
- 0.086
- 0.951
- 0.519
- 0.558
- 1.303
- 0.544
- 0.554
- 0.9
- 0.888
- 0.53
- 0.527
- 0.877
- 0.532
- 0.881
- 0.56
- 0.193
- 0.5
- 0.487
- 0.85
- 0.861
- 0.504
- 0.506
- 0.495
- 0.507
- 0.858
- 0.85
- 0.511
- 0.516
- 0.519
- 0.513
- 0.486
- 0.834
- 0.494
- 0.507
- 0.507
- 0.496
unequal: 0
verbose: 1
