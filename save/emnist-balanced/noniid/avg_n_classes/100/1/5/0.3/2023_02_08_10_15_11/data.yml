avg_train_accuracy: 0.821
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02143617021276596
- 0.027180851063829788
- 0.04765957446808511
- 0.10154255319148936
- 0.20329787234042554
- 0.3228191489361702
- 0.39106382978723403
- 0.4295744680851064
- 0.46558510638297873
- 0.5062765957446809
- 0.5295212765957447
- 0.5457446808510639
- 0.5455319148936171
- 0.5585106382978723
- 0.5749468085106383
- 0.5918085106382979
- 0.18069148936170212
- 0.5984574468085107
- 0.6059574468085106
- 0.6165957446808511
- 0.6219148936170212
- 0.6287234042553191
- 0.6223936170212766
- 0.6267021276595744
- 0.6304255319148936
- 0.34585106382978725
- 0.6365957446808511
- 0.6505319148936171
- 0.6515425531914893
- 0.6528191489361702
- 0.6586170212765957
- 0.659468085106383
- 0.6668617021276596
- 0.6714361702127659
- 0.6697872340425531
- 0.6768617021276596
- 0.6724468085106383
- 0.6768085106382978
- 0.681595744680851
- 0.4775531914893617
- 0.6831914893617022
- 0.6842021276595744
- 0.6842021276595744
- 0.6765425531914894
- 0.685
- 0.48425531914893616
- 0.6924468085106383
- 0.6862765957446808
- 0.6925531914893617
- 0.6845744680851064
- 0.6965957446808511
- 0.6881382978723404
- 0.6932978723404255
- 0.6886702127659574
- 0.6951595744680851
- 0.6969148936170213
- 0.7025
- 0.6965425531914894
- 0.7057446808510638
- 0.7050531914893617
- 0.7052127659574469
- 0.7054787234042553
- 0.7097872340425532
- 0.706436170212766
- 0.6992021276595745
- 0.7023936170212766
- 0.71
- 0.7098936170212766
- 0.7146808510638298
- 0.6392021276595745
- 0.7053191489361702
- 0.7104787234042553
- 0.713404255319149
- 0.7132446808510639
- 0.7147340425531915
- 0.7103723404255319
- 0.7149468085106383
- 0.6343617021276595
- 0.714627659574468
- 0.7151595744680851
- 0.7129255319148936
- 0.7126063829787234
- 0.716436170212766
- 0.7137234042553191
- 0.7199468085106383
- 0.7171808510638298
- 0.7194148936170213
- 0.7182446808510639
- 0.7179787234042553
- 0.7202127659574468
- 0.7192021276595745
- 0.7187765957446809
- 0.7145744680851064
- 0.7111170212765957
- 0.7197872340425532
- 0.7187765957446809
- 0.7202659574468085
- 0.6294148936170213
- 0.7232446808510639
- 0.7230319148936171
test_loss_list:
- 9.601719182332356
- 3.78339075088501
- 3.7477416642506918
- 3.6323797639211017
- 3.3712907600402833
- 3.0511286385854084
- 2.7745995775858563
- 2.574241148630778
- 2.438522176742554
- 2.3335174338022866
- 2.2639495277404786
- 2.2106021865208945
- 2.1687162574132284
- 2.146200728416443
- 2.0845141728719074
- 2.0867557191848753
- 3.7108956972757974
- 1.8966007439295451
- 1.9226698970794678
- 1.9112780300776164
- 1.8969842688242595
- 1.8937576071421305
- 1.8876975059509278
- 1.87828719774882
- 1.8712764422098795
- 2.4068648370107013
- 1.6265401204427083
- 1.6709864950180053
- 1.7150332276026408
- 1.7165058294932047
- 1.704880723953247
- 1.7080161078770955
- 1.704014220237732
- 1.6766838836669922
- 1.671645131111145
- 1.7000977484385174
- 1.6846857770284016
- 1.720409574508667
- 1.7117849206924438
- 1.910202725728353
- 1.5055091381072998
- 1.5668573427200316
- 1.59408394018809
- 1.5606835889816284
- 1.5417829608917237
- 1.9188021723429363
- 1.3936596743265788
- 1.453908208211263
- 1.4957389799753824
- 1.507074678738912
- 1.495456771850586
- 1.4930578883488972
- 1.4976667674382527
- 1.5366347694396973
- 1.5275600655873616
- 1.5315199104944865
- 1.5249672667185465
- 1.5435274664560954
- 1.5417157634099325
- 1.5488954083124797
- 1.544625924428304
- 1.5556987444559733
- 1.5689673217137654
- 1.5646139748891195
- 1.5378599484761557
- 1.54112912495931
- 1.5319254875183106
- 1.5231214920679728
- 1.5599033339818318
- 1.3598728736241659
- 1.3202688487370808
- 1.3416987339655557
- 1.3905683612823487
- 1.4139342323939006
- 1.4186052179336548
- 1.420986722310384
- 1.4248022588094076
- 1.4056257661183675
- 1.249428428808848
- 1.311348299185435
- 1.321010136604309
- 1.3374427270889282
- 1.3259015846252442
- 1.3632831207911174
- 1.3788720337549845
- 1.3616788578033447
- 1.3988836606343586
- 1.3912355550130209
- 1.3990125878651938
- 1.430134727160136
- 1.4200945154825846
- 1.3970565128326415
- 1.4120983600616455
- 1.3945990784962972
- 1.4285610580444337
- 1.4319559637705486
- 1.4193114805221558
- 1.331005965868632
- 1.1936508933703105
- 1.259608874320984
train_accuracy:
- 0.002
- 0.027
- 0.0
- 0.121
- 0.0
- 0.373
- 0.442
- 0.483
- 0.0
- 0.562
- 0.594
- 0.619
- 0.0
- 0.648
- 0.627
- 0.0
- 0.983
- 0.648
- 0.658
- 0.713
- 0.713
- 0.0
- 0.0
- 0.0
- 0.0
- 0.806
- 0.746
- 0.0
- 0.715
- 0.0
- 0.74
- 0.763
- 0.0
- 0.0
- 0.0
- 0.719
- 0.0
- 0.719
- 0.777
- 0.944
- 0.0
- 0.0
- 0.781
- 0.787
- 0.0
- 0.985
- 0.0
- 0.012
- 0.779
- 0.792
- 0.79
- 0.006
- 0.0
- 0.0
- 0.787
- 0.794
- 0.0
- 0.781
- 0.0
- 0.0
- 0.0
- 0.806
- 0.804
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.958
- 0.0
- 0.74
- 0.8
- 0.817
- 0.0
- 0.815
- 0.75
- 0.983
- 0.808
- 0.0
- 0.0
- 0.792
- 0.0
- 0.0
- 0.812
- 0.0
- 0.821
- 0.817
- 0.81
- 0.81
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.827
- 0.808
- 0.981
- 0.0
- 0.821
train_loss:
- 0.281
- 2.656
- 2.681
- 2.592
- 2.472
- 2.289
- 2.08
- 1.079
- 0.999
- 1.718
- 1.617
- 1.543
- 0.853
- 0.862
- 0.842
- 1.381
- 0.277
- 1.478
- 1.283
- 1.282
- 1.287
- 1.245
- 0.71
- 0.744
- 0.693
- 0.237
- 1.221
- 1.182
- 1.117
- 0.674
- 1.093
- 1.076
- 1.1
- 0.642
- 0.637
- 1.046
- 0.631
- 1.02
- 1.443
- 0.227
- 1.068
- 0.574
- 1.388
- 0.613
- 0.616
- 0.168
- 1.03
- 0.573
- 1.332
- 0.533
- 0.982
- 0.544
- 0.543
- 0.537
- 0.53
- 0.908
- 0.543
- 0.523
- 0.934
- 0.541
- 0.566
- 0.882
- 0.875
- 0.522
- 0.571
- 0.552
- 0.911
- 0.555
- 0.867
- 0.221
- 0.495
- 0.52
- 1.195
- 0.824
- 0.876
- 0.501
- 0.509
- 0.169
- 0.55
- 0.465
- 0.531
- 0.506
- 0.501
- 0.494
- 1.168
- 0.514
- 1.152
- 0.813
- 0.507
- 1.15
- 0.491
- 0.522
- 0.508
- 0.535
- 0.803
- 1.116
- 0.512
- 0.2
- 0.8
- 0.762
unequal: 0
verbose: 1
