avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03053191489361702
- 0.05680851063829787
- 0.08569148936170212
- 0.13388297872340427
- 0.18914893617021278
- 0.28393617021276596
- 0.36196808510638295
- 0.41675531914893615
- 0.4504787234042553
- 0.4825531914893617
- 0.5150531914893617
- 0.5273936170212766
- 0.5388829787234043
- 0.5499468085106383
- 0.5624468085106383
- 0.5794680851063829
- 0.5766489361702127
- 0.5902127659574468
- 0.601063829787234
- 0.5968617021276595
- 0.6054255319148936
- 0.6177659574468085
- 0.6275
- 0.6331382978723404
- 0.6353723404255319
- 0.6411702127659574
- 0.6450531914893617
- 0.6442553191489362
- 0.30909574468085105
- 0.6452659574468085
- 0.19601063829787235
- 0.6477127659574468
- 0.6581382978723405
- 0.6570212765957447
- 0.6614361702127659
- 0.6647340425531915
- 0.6627659574468086
- 0.6673936170212766
- 0.6748404255319149
- 0.6746808510638298
- 0.22372340425531914
- 0.6746276595744681
- 0.42101063829787233
- 0.6801595744680851
- 0.6790425531914893
- 0.6799468085106383
- 0.6855851063829788
- 0.6817021276595745
- 0.69
- 0.689627659574468
- 0.6892021276595744
- 0.691063829787234
- 0.6902127659574468
- 0.6959574468085107
- 0.6951595744680851
- 0.6911170212765958
- 0.6979255319148936
- 0.6918617021276596
- 0.6981382978723404
- 0.6952659574468085
- 0.7024468085106383
- 0.7009042553191489
- 0.7045744680851064
- 0.6984574468085106
- 0.7082446808510638
- 0.7049468085106383
- 0.7039893617021277
- 0.7082978723404255
- 0.44632978723404254
- 0.7076063829787234
- 0.7027659574468085
- 0.5034042553191489
- 0.7018617021276595
- 0.7014361702127659
- 0.7082978723404255
- 0.7071808510638298
- 0.7092021276595745
- 0.7082446808510638
- 0.7136702127659574
- 0.5045744680851064
- 0.7130319148936171
- 0.7128191489361703
- 0.7157446808510638
- 0.7118085106382979
- 0.7112234042553192
- 0.7110106382978724
- 0.714095744680851
- 0.4977659574468085
- 0.7128723404255319
- 0.7141489361702128
- 0.5703191489361702
- 0.7126595744680851
- 0.7151595744680851
- 0.7138297872340426
- 0.7082978723404255
- 0.7210106382978724
- 0.7173936170212766
- 0.7174468085106382
- 0.7178191489361702
- 0.7172872340425532
test_loss_list:
- 3.792072073618571
- 3.7718423430124917
- 3.7212670771280925
- 3.611769682566325
- 3.3839927768707274
- 3.074519542058309
- 2.855299523671468
- 2.6649965635935464
- 2.5264456431070963
- 2.43007022857666
- 2.346605157852173
- 2.30519419670105
- 2.210700961748759
- 2.1907747681935628
- 2.161351319948832
- 2.1445405928293866
- 2.1229390970865887
- 2.0856622838974
- 2.0966931565602622
- 2.090489158630371
- 2.0465386056900026
- 2.031867432594299
- 2.0008737818400064
- 2.036537833213806
- 1.9791518004735311
- 1.9538935550053915
- 1.9707105159759521
- 1.9628718566894532
- 2.5620289993286134
- 1.6545585521062216
- 3.8188547388712566
- 1.5800105365117392
- 1.7008543348312377
- 1.7091446447372436
- 1.7069739770889283
- 1.745161894162496
- 1.7288429148991902
- 1.755594892501831
- 1.6956343126296998
- 1.7484591325124106
- 3.068860060373942
- 1.494581093788147
- 2.094428758621216
- 1.3841959381103515
- 1.4464038324356079
- 1.4611494461695353
- 1.488139591217041
- 1.5046580425898235
- 1.4700503047307332
- 1.512795360883077
- 1.4985023943583171
- 1.542558733622233
- 1.5254278453191121
- 1.5080868927637736
- 1.525722459157308
- 1.5573636356989542
- 1.5392711925506593
- 1.5451703770955403
- 1.5778526576360066
- 1.5814848200480143
- 1.5475716479619344
- 1.5704014174143472
- 1.5532221142450968
- 1.5576568110783895
- 1.533925511042277
- 1.5376399310429891
- 1.5528243684768677
- 1.4995732577641805
- 1.9824496475855509
- 1.296096323331197
- 1.3663452863693237
- 1.8253369140625
- 1.2310212103525797
- 1.236928243637085
- 1.299436208407084
- 1.3118640486399333
- 1.3237241013844807
- 1.3371162525812785
- 1.3533715152740478
- 1.7838116010030112
- 1.1799813652038573
- 1.2350832827885945
- 1.2465363454818725
- 1.2622471936543782
- 1.2988988161087036
- 1.3187392044067383
- 1.3016793982187906
- 1.8930311441421508
- 1.1601423120498657
- 1.1936764558156332
- 1.5546409130096435
- 1.074011664390564
- 1.1319205649693806
- 1.1832551089922587
- 1.2027467528978983
- 1.1898086818059286
- 1.185217624505361
- 1.208925759792328
- 1.2357252979278563
- 1.2140792536735534
train_accuracy:
- 0.04
- 0.0
- 0.069
- 0.154
- 0.0
- 0.312
- 0.371
- 0.0
- 0.0
- 0.521
- 0.0
- 0.577
- 0.602
- 0.0
- 0.612
- 0.631
- 0.648
- 0.66
- 0.662
- 0.0
- 0.0
- 0.0
- 0.0
- 0.698
- 0.704
- 0.0
- 0.721
- 0.0
- 0.935
- 0.0
- 0.99
- 0.0
- 0.723
- 0.733
- 0.0
- 0.746
- 0.0
- 0.75
- 0.0
- 0.742
- 0.981
- 0.0
- 0.971
- 0.0
- 0.0
- 0.0
- 0.75
- 0.752
- 0.0
- 0.773
- 0.773
- 0.0
- 0.744
- 0.0
- 0.771
- 0.0
- 0.773
- 0.765
- 0.781
- 0.767
- 0.0
- 0.779
- 0.781
- 0.0
- 0.771
- 0.777
- 0.0
- 0.796
- 0.96
- 0.0
- 0.0
- 0.99
- 0.0
- 0.0
- 0.775
- 0.787
- 0.785
- 0.783
- 0.785
- 0.965
- 0.787
- 0.8
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.979
- 0.0
- 0.0
- 0.994
- 0.794
- 0.802
- 0.79
- 0.787
- 0.804
- 0.798
- 0.798
- 0.0
- 0.0
train_loss:
- 2.715
- 1.651
- 1.563
- 1.444
- 1.371
- 1.27
- 1.157
- 1.072
- 0.989
- 1.72
- 1.602
- 0.871
- 0.844
- 0.787
- 0.824
- 1.354
- 0.83
- 0.73
- 1.274
- 0.762
- 0.753
- 0.719
- 1.241
- 1.645
- 0.735
- 0.715
- 1.137
- 0.664
- 0.264
- 0.638
- 0.16
- 0.655
- 1.53
- 1.029
- 0.61
- 1.007
- 0.606
- 0.992
- 0.627
- 0.989
- 0.265
- 0.532
- 0.172
- 0.976
- 0.517
- 0.549
- 1.354
- 0.954
- 0.606
- 0.961
- 0.58
- 0.931
- 0.563
- 0.574
- 0.92
- 0.537
- 0.924
- 0.539
- 1.248
- 0.522
- 0.927
- 1.247
- 0.89
- 0.548
- 0.903
- 0.539
- 0.857
- 0.577
- 0.198
- 0.951
- 0.502
- 0.161
- 0.475
- 0.492
- 0.82
- 0.814
- 0.851
- 0.492
- 1.186
- 0.196
- 0.85
- 0.82
- 0.488
- 0.485
- 0.804
- 0.481
- 0.827
- 0.156
- 0.447
- 0.469
- 0.133
- 0.457
- 0.785
- 0.751
- 0.435
- 0.829
- 0.504
- 0.461
- 0.776
- 0.469
unequal: 0
verbose: 1
