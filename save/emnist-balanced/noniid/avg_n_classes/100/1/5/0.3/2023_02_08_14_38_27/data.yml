avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.032021276595744684
- 0.03718085106382979
- 0.05122340425531915
- 0.12691489361702127
- 0.24085106382978724
- 0.34595744680851065
- 0.40835106382978725
- 0.45468085106382977
- 0.485531914893617
- 0.5055851063829787
- 0.1396808510638298
- 0.5049468085106383
- 0.5297872340425532
- 0.5457446808510639
- 0.08404255319148936
- 0.5580851063829787
- 0.5638297872340425
- 0.5682978723404255
- 0.5806914893617021
- 0.5920212765957447
- 0.3083510638297872
- 0.5940425531914894
- 0.6053723404255319
- 0.6078191489361702
- 0.6157978723404255
- 0.609468085106383
- 0.6227659574468085
- 0.6288829787234043
- 0.6353723404255319
- 0.30409574468085104
- 0.635531914893617
- 0.6404255319148936
- 0.6423404255319148
- 0.6430851063829788
- 0.6461170212765958
- 0.6536702127659575
- 0.6569680851063829
- 0.655
- 0.6622340425531915
- 0.6651595744680852
- 0.6662765957446809
- 0.6689893617021276
- 0.6688829787234043
- 0.671063829787234
- 0.6746276595744681
- 0.6744148936170212
- 0.6773404255319149
- 0.6756914893617021
- 0.6789893617021276
- 0.6852659574468085
- 0.6813829787234043
- 0.6838829787234042
- 0.6883510638297873
- 0.6890957446808511
- 0.5820744680851064
- 0.6871808510638298
- 0.6907446808510638
- 0.5859574468085106
- 0.6927127659574468
- 0.6931382978723404
- 0.6951595744680851
- 0.6970744680851064
- 0.6937765957446809
- 0.695531914893617
- 0.6977127659574468
- 0.6985638297872341
- 0.5707978723404256
- 0.6972872340425532
- 0.7023936170212766
- 0.7045212765957447
- 0.5763297872340426
- 0.7048936170212766
- 0.7048936170212766
- 0.7086702127659574
- 0.7105851063829787
- 0.7030851063829787
- 0.7015425531914894
- 0.7048936170212766
- 0.7096808510638298
- 0.7029787234042553
- 0.7108510638297872
- 0.7097340425531915
- 0.711436170212766
- 0.5428191489361702
- 0.44861702127659575
- 0.7117021276595744
- 0.7106382978723405
- 0.7145744680851064
- 0.7134574468085106
- 0.7118085106382979
- 0.7159574468085106
- 0.7140425531914893
- 0.7170744680851063
- 0.6692021276595744
- 0.7153723404255319
- 0.7137234042553191
- 0.7129787234042553
- 0.7155851063829787
- 0.7183510638297872
- 0.7180319148936171
test_loss_list:
- 3.785461403528849
- 3.7448703638712564
- 6.119996980031331
- 3.5677994283040366
- 3.2790995184580485
- 2.9694566980997723
- 2.726177314122518
- 2.5532692750295003
- 2.454427194595337
- 2.38340584119161
- 3.546037400563558
- 2.154864257176717
- 2.112030825614929
- 2.096158838272095
- 5.08452989578247
- 1.9926435804367066
- 1.977422916094462
- 1.9619572846094768
- 1.9615315930048625
- 1.9396394650141398
- 2.560840644836426
- 1.8012622165679932
- 1.8196980015436808
- 1.8142470089594522
- 1.8151822010676066
- 1.8298336426417032
- 1.8385193204879762
- 1.8277274306615194
- 1.858185388247172
- 2.6377301088968914
- 1.6603808975219727
- 1.6842209196090698
- 1.7113285303115844
- 1.728596741358439
- 1.709496906598409
- 1.7273183759053548
- 1.7533235041300457
- 1.7597925329208375
- 1.7588676754633585
- 1.765869197845459
- 1.7643619314829508
- 1.7766306479771932
- 1.7509773778915405
- 1.7546030139923097
- 1.7843385601043702
- 1.7342840274175009
- 1.781468776067098
- 1.8060535383224487
- 1.7296035035451254
- 1.7627184708913168
- 1.8057691446940105
- 1.7258762613932292
- 1.7544146966934204
- 1.7549868138631184
- 1.6573583443959554
- 1.4200131320953369
- 1.4560220813751221
- 1.5516598320007324
- 1.3441928577423097
- 1.3869791762034098
- 1.429315447807312
- 1.4745598649978637
- 1.4765381320317585
- 1.4720355240503946
- 1.4944478019078573
- 1.503068528175354
- 1.630922482808431
- 1.280911266009013
- 1.3300764767328899
- 1.3506565348307291
- 1.525485011736552
- 1.202157605489095
- 1.2604856077829998
- 1.3161340252558391
- 1.343951285680135
- 1.3239667018254597
- 1.3583969004948935
- 1.3634619156519572
- 1.3878098440170288
- 1.3940538215637206
- 1.3828064250946044
- 1.4072898546854655
- 1.4327913904190064
- 1.7052705399195354
- 1.8969591013590494
- 1.0699023262659708
- 1.1449528773625692
- 1.2044791269302368
- 1.2458648586273193
- 1.2463544734319052
- 1.2476594829559327
- 1.2585492658615112
- 1.2915955336888632
- 1.2388936392466228
- 1.1426956208546957
- 1.16712549050649
- 1.200555953979492
- 1.1993525632222493
- 1.230558598836263
- 1.2563803243637084
train_accuracy:
- 0.0
- 0.0
- 0.69
- 0.179
- 0.288
- 0.398
- 0.0
- 0.519
- 0.0
- 0.0
- 0.688
- 0.0
- 0.567
- 0.631
- 0.99
- 0.0
- 0.644
- 0.0
- 0.0
- 0.638
- 0.975
- 0.0
- 0.0
- 0.0
- 0.669
- 0.698
- 0.0
- 0.729
- 0.731
- 0.863
- 0.723
- 0.731
- 0.729
- 0.0
- 0.713
- 0.0
- 0.725
- 0.0
- 0.748
- 0.727
- 0.76
- 0.752
- 0.758
- 0.767
- 0.0
- 0.0
- 0.0
- 0.0
- 0.769
- 0.763
- 0.0
- 0.76
- 0.794
- 0.775
- 0.56
- 0.773
- 0.773
- 0.963
- 0.792
- 0.76
- 0.0
- 0.806
- 0.787
- 0.787
- 0.8
- 0.0
- 0.973
- 0.0
- 0.0
- 0.771
- 0.883
- 0.037
- 0.0
- 0.812
- 0.781
- 0.0
- 0.0
- 0.819
- 0.775
- 0.0
- 0.798
- 0.817
- 0.808
- 0.963
- 0.988
- 0.775
- 0.777
- 0.812
- 0.0
- 0.802
- 0.787
- 0.8
- 0.779
- 0.973
- 0.798
- 0.0
- 0.0
- 0.792
- 0.838
- 0.0
train_loss:
- 1.59
- 1.634
- 0.353
- 2.596
- 2.393
- 2.215
- 2.01
- 1.868
- 1.758
- 0.988
- 0.23
- 0.874
- 0.909
- 0.842
- 0.227
- 1.617
- 0.818
- 0.796
- 0.766
- 1.35
- 0.202
- 1.367
- 1.26
- 1.27
- 1.236
- 0.693
- 1.214
- 1.208
- 1.65
- 0.229
- 1.177
- 1.126
- 1.122
- 0.655
- 0.639
- 1.101
- 1.529
- 0.631
- 1.063
- 1.049
- 1.034
- 1.032
- 1.062
- 1.031
- 1.003
- 0.656
- 0.6
- 0.6
- 0.64
- 1.375
- 0.598
- 1.012
- 0.948
- 1.346
- 0.255
- 1.03
- 0.938
- 0.175
- 0.921
- 0.945
- 0.959
- 0.901
- 0.545
- 0.537
- 0.914
- 0.549
- 0.175
- 0.556
- 0.9
- 0.878
- 0.164
- 0.473
- 0.519
- 1.214
- 0.861
- 0.522
- 0.529
- 0.868
- 0.504
- 0.522
- 0.871
- 0.837
- 0.825
- 0.202
- 0.146
- 0.873
- 0.818
- 1.162
- 0.477
- 0.49
- 0.487
- 0.483
- 0.815
- 0.155
- 0.42
- 0.481
- 0.451
- 0.486
- 0.806
- 0.482
unequal: 0
verbose: 1
