avg_train_accuracy: 0.996
avg_train_loss: 0.001
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.019414893617021277
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02122340425531915
- 0.02127659574468085
- 0.02127659574468085
- 0.02526595744680851
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.039095744680851065
- 0.02127659574468085
- 0.02127659574468085
- 0.030904255319148935
- 0.03335106382978723
- 0.03489361702127659
- 0.02127659574468085
- 0.04781914893617021
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.04031914893617021
- 0.02127659574468085
- 0.04303191489361702
- 0.03648936170212766
- 0.05952127659574468
- 0.022872340425531913
- 0.02127659574468085
- 0.02127659574468085
- 0.058351063829787234
- 0.09047872340425532
- 0.02127659574468085
- 0.02127659574468085
- 0.028191489361702127
- 0.02675531914893617
- 0.06425531914893617
- 0.032872340425531915
- 0.13489361702127659
- 0.17797872340425533
- 0.22952127659574467
- 0.0451063829787234
- 0.2765957446808511
- 0.3222340425531915
- 0.021329787234042552
- 0.36531914893617023
- 0.40393617021276595
- 0.02127659574468085
- 0.023670212765957446
- 0.41382978723404257
- 0.45218085106382977
- 0.02127659574468085
- 0.47335106382978726
- 0.021914893617021276
- 0.49829787234042555
- 0.527127659574468
- 0.20893617021276595
- 0.5382446808510638
- 0.1823404255319149
- 0.12143617021276595
- 0.08335106382978723
- 0.5500531914893617
- 0.3075
- 0.5772340425531914
- 0.5867553191489362
- 0.041648936170212765
- 0.6
- 0.6036170212765958
- 0.6093085106382978
- 0.03308510638297872
- 0.6188829787234043
- 0.6273404255319149
- 0.6271808510638298
- 0.6292021276595745
- 0.10414893617021277
- 0.048563829787234045
- 0.04904255319148936
- 0.6519680851063829
- 0.1529255319148936
- 0.21382978723404256
- 0.6446808510638298
- 0.3822872340425532
- 0.14861702127659573
- 0.19170212765957448
- 0.15308510638297873
- 0.6495744680851064
- 0.6543617021276595
- 0.65
- 0.6486702127659575
- 0.41382978723404257
- 0.15569148936170213
- 0.20574468085106384
- 0.6607978723404255
- 0.28127659574468084
- 0.10037234042553192
- 0.679468085106383
- 0.21670212765957447
test_loss_list:
- 26.437094548543293
- 3.79891432762146
- 24.418120371500653
- 22.510537389119467
- 22.148836059570314
- 18.13044194539388
- 21.29255172729492
- 3.801896123886108
- 3.7996114031473796
- 3.7982204437255858
- 3.7972902139027913
- 23.301018931070963
- 3.8062321090698243
- 17.48541872660319
- 3.7923453521728514
- 10.850795199076334
- 20.23020533243815
- 3.7837793159484865
- 3.775118989944458
- 3.7603654225667316
- 8.289208761850993
- 3.715261704126994
- 27.784798736572267
- 37.85383845011393
- 25.43456741333008
- 3.740947971343994
- 14.54298454284668
- 3.689235973358154
- 7.6677216593424475
- 3.611171681086222
- 11.776660499572754
- 15.336068738301595
- 20.786158955891928
- 3.5958025868733725
- 3.48811261177063
- 17.040760650634766
- 18.84152842203776
- 7.61918509165446
- 17.19084213256836
- 3.5400504620869953
- 6.0430154037475585
- 3.3801489543914793
- 3.204904079437256
- 3.0783292770385744
- 8.822156842549642
- 2.9414618396759034
- 2.79001966158549
- 11.609084676106772
- 2.6407893594106038
- 2.5147786140441895
- 15.16923085530599
- 9.321615575154622
- 2.401303688685099
- 2.2882541529337566
- 15.21334592183431
- 2.163055124282837
- 11.404688936869304
- 2.0567275142669676
- 1.961097625096639
- 6.679795227050781
- 1.879053945541382
- 5.375342051188151
- 7.173237444559733
- 8.126615873972575
- 1.732651416460673
- 4.478086026509603
- 1.6790879329045614
- 1.6603260660171508
- 10.72406187693278
- 1.6055697441101073
- 1.5890269215901693
- 1.5929950284957886
- 12.684808209737142
- 1.5230334393183391
- 1.509752303759257
- 1.5206047503153484
- 1.528380002975464
- 8.461455097198487
- 10.017250366210938
- 9.920021603902182
- 1.352720367113749
- 6.603228836059571
- 4.6957826296488445
- 1.2716240787506103
- 4.551470801035563
- 7.392458432515462
- 5.176413720448812
- 6.010879046122233
- 1.2159917577107748
- 1.208630716005961
- 1.2336118920644124
- 1.262887487411499
- 3.453825438817342
- 6.319974536895752
- 5.875814456939697
- 1.163350482781728
- 4.570195007324219
- 7.999385643005371
- 1.0934364024798076
- 5.352693074544271
train_accuracy:
- 1.0
- 0.025
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.002
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.017
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.002
- 1.0
- 0.017
- 1.0
- 1.0
- 1.0
- 0.029
- 0.052
- 1.0
- 1.0
- 1.0
- 1.0
- 0.006
- 1.0
- 0.1
- 0.202
- 0.237
- 1.0
- 0.275
- 0.329
- 1.0
- 0.381
- 0.406
- 1.0
- 1.0
- 0.438
- 0.517
- 1.0
- 0.531
- 1.0
- 0.558
- 0.51
- 1.0
- 0.629
- 1.0
- 1.0
- 1.0
- 0.625
- 1.0
- 0.588
- 0.606
- 1.0
- 0.652
- 0.66
- 0.681
- 1.0
- 0.66
- 0.646
- 0.665
- 0.719
- 1.0
- 1.0
- 0.998
- 0.723
- 0.996
- 1.0
- 0.719
- 1.0
- 1.0
- 1.0
- 1.0
- 0.688
- 0.685
- 0.75
- 0.742
- 1.0
- 0.998
- 1.0
- 0.715
- 1.0
- 1.0
- 0.735
- 0.996
train_loss:
- 0.306
- 4.167
- 0.933
- 0.596
- 0.862
- 0.324
- 0.011
- 4.162
- 3.866
- 3.857
- 3.851
- 1.929
- 4.145
- 0.935
- 4.11
- 0.297
- 0.716
- 4.191
- 3.866
- 3.843
- 0.308
- 3.942
- 0.958
- 0.035
- 1.307
- 4.213
- 0.873
- 4.052
- 0.228
- 3.909
- 0.264
- 0.021
- 0.378
- 4.07
- 3.658
- 0.872
- 0.456
- 0.46
- 0.208
- 4.027
- 0.166
- 3.754
- 3.441
- 3.335
- 0.272
- 3.409
- 3.064
- 0.255
- 3.143
- 2.816
- 0.457
- 0.357
- 3.064
- 2.629
- 0.337
- 2.805
- 0.154
- 2.614
- 2.311
- 0.176
- 2.422
- 0.252
- 0.018
- 0.134
- 2.461
- 0.124
- 2.207
- 1.952
- 0.234
- 2.166
- 1.908
- 1.846
- 0.345
- 2.068
- 1.742
- 1.678
- 1.721
- 0.293
- 0.342
- 0.31
- 2.175
- 0.12
- 0.368
- 1.981
- 0.241
- 0.207
- 0.219
- 0.15
- 2.092
- 1.671
- 1.665
- 1.596
- 0.152
- 0.216
- 0.211
- 1.963
- 0.159
- 0.264
- 1.857
- 0.126
unequal: 0
verbose: 1
