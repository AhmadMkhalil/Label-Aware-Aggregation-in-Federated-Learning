avg_train_accuracy: 0.742
avg_train_loss: 0.018
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.025319148936170214
- 0.02127659574468085
- 0.03861702127659575
- 0.02127659574468085
- 0.02127659574468085
- 0.021968085106382977
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.03053191489361702
- 0.05202127659574468
- 0.02127659574468085
- 0.02127659574468085
- 0.02143617021276596
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.04707446808510638
- 0.09840425531914894
- 0.02127659574468085
- 0.18015957446808512
- 0.03861702127659575
- 0.02127659574468085
- 0.26867021276595743
- 0.04159574468085107
- 0.36069148936170214
- 0.023617021276595745
- 0.02127659574468085
- 0.4049468085106383
- 0.4571808510638298
- 0.4894148936170213
- 0.09446808510638298
- 0.5141489361702127
- 0.5423404255319149
- 0.02468085106382979
- 0.5598936170212766
- 0.18515957446808512
- 0.0375
- 0.5685638297872341
- 0.5760106382978724
- 0.08867021276595745
- 0.5905851063829787
- 0.06468085106382979
- 0.03824468085106383
- 0.031223404255319148
- 0.6044148936170213
- 0.11239361702127659
- 0.07367021276595745
- 0.1497872340425532
- 0.6032446808510639
- 0.11728723404255319
- 0.6158510638297873
- 0.6220744680851064
- 0.32882978723404255
- 0.24095744680851064
- 0.6232978723404256
- 0.1502659574468085
- 0.6360638297872341
- 0.2696276595744681
- 0.12829787234042553
- 0.6368085106382979
- 0.3467021276595745
- 0.6407978723404255
- 0.6463829787234042
- 0.38218085106382976
- 0.6473404255319148
- 0.36117021276595745
- 0.2822340425531915
- 0.6512765957446809
- 0.2651595744680851
- 0.6641489361702128
- 0.3389893617021277
- 0.1173936170212766
- 0.2403191489361702
- 0.17127659574468085
- 0.07547872340425532
- 0.6735638297872341
- 0.6687765957446808
- 0.21180851063829786
- 0.666595744680851
- 0.6711702127659575
- 0.6714361702127659
- 0.6735106382978724
- 0.4487765957446809
- 0.6712234042553191
- 0.3840425531914894
- 0.2900531914893617
- 0.6818085106382978
- 0.6767553191489362
- 0.6790425531914893
- 0.6764893617021277
- 0.4076063829787234
- 0.33861702127659576
- 0.6961702127659575
- 0.4653191489361702
- 0.1598936170212766
- 0.20303191489361702
- 0.11074468085106383
- 0.7074468085106383
test_loss_list:
- 3.786400737762451
- 29.495352274576824
- 3.794439868927002
- 20.353369420369464
- 3.781265474955241
- 3.7558597246805827
- 23.79882553100586
- 30.24802406311035
- 23.53658378601074
- 3.7727780691782633
- 3.738311087290446
- 20.774824142456055
- 16.05375425974528
- 3.7316787179311115
- 13.863099276224773
- 18.228615468343097
- 11.768071937561036
- 16.950596822102863
- 3.670058091481527
- 3.547716236114502
- 12.373654225667318
- 3.3336982758839926
- 10.297914950052897
- 9.356223691304525
- 3.0813128916422525
- 6.351182270050049
- 2.7527441692352297
- 9.865005963643393
- 16.583939463297526
- 2.5189839299519856
- 2.2898939355214436
- 2.1477120033899944
- 10.237415364583333
- 1.9861889092127483
- 1.9054512182871501
- 12.554529113769531
- 1.8102988322575888
- 8.062708085378011
- 11.53158307393392
- 1.7157441425323485
- 1.669963043530782
- 7.53442798614502
- 1.63399373849233
- 9.379654858907063
- 12.696595840454101
- 14.690793431599936
- 1.5950075499216716
- 6.471275246938069
- 8.6790779876709
- 5.4823975690205895
- 1.4997255007425945
- 6.845921262105306
- 1.4707697900136312
- 1.4817475175857544
- 4.358093115488688
- 6.131099376678467
- 1.474499446551005
- 6.76760576248169
- 1.4401791063944498
- 6.826555557250977
- 6.4161539586385095
- 1.3954644266764322
- 5.474123376210531
- 1.4017882124582925
- 1.4168147150675456
- 4.106092557907105
- 1.3741984764734905
- 5.024463456471761
- 7.189242909749349
- 1.3747705030441284
- 5.830279547373454
- 1.245233039855957
- 4.3166358820597335
- 6.878605092366536
- 5.4134803326924645
- 6.40642728805542
- 7.529273103078206
- 1.1519507805506388
- 1.163607579867045
- 5.322275587717692
- 1.1730842471122742
- 1.1889535760879517
- 1.212268311182658
- 1.2217413838704427
- 3.405734469095866
- 1.1794336342811584
- 4.672736857732137
- 5.227876014709473
- 1.0997697885831197
- 1.1265456827481588
- 1.1555045962333679
- 1.2020273431142172
- 3.6895417086283366
- 4.975369402567545
- 1.1471796528498333
- 3.1992023181915283
- 6.047686462402344
- 5.290843181610107
- 6.52413911819458
- 0.9949742825826009
train_accuracy:
- 0.023
- 1.0
- 0.017
- 1.0
- 0.0
- 0.002
- 1.0
- 1.0
- 1.0
- 0.0
- 0.021
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.05
- 1.0
- 0.133
- 1.0
- 1.0
- 0.24
- 1.0
- 0.402
- 1.0
- 1.0
- 0.45
- 0.537
- 0.615
- 1.0
- 0.581
- 0.577
- 1.0
- 0.602
- 1.0
- 1.0
- 0.61
- 0.621
- 0.998
- 0.627
- 1.0
- 1.0
- 1.0
- 0.648
- 0.998
- 0.998
- 1.0
- 0.679
- 0.994
- 0.698
- 0.681
- 1.0
- 1.0
- 0.685
- 0.994
- 0.706
- 1.0
- 0.998
- 0.717
- 1.0
- 0.704
- 0.735
- 1.0
- 0.737
- 1.0
- 1.0
- 0.717
- 1.0
- 0.723
- 1.0
- 0.996
- 1.0
- 1.0
- 1.0
- 0.725
- 0.71
- 0.996
- 0.719
- 0.721
- 0.763
- 0.763
- 1.0
- 0.754
- 1.0
- 1.0
- 0.748
- 0.746
- 0.775
- 0.787
- 1.0
- 1.0
- 0.756
- 1.0
- 0.996
- 1.0
- 1.0
- 0.742
train_loss:
- 3.838
- 0.597
- 4.162
- 0.79
- 4.052
- 3.817
- 0.628
- 0.015
- 1.034
- 4.154
- 3.817
- 1.2
- 0.496
- 4.056
- 0.578
- 0.018
- 0.299
- 0.444
- 4.046
- 3.725
- 0.227
- 3.753
- 0.226
- 0.174
- 3.565
- 0.095
- 3.24
- 0.163
- 0.49
- 3.284
- 2.726
- 2.506
- 0.35
- 2.643
- 2.285
- 0.253
- 2.42
- 0.195
- 0.327
- 2.432
- 2.029
- 0.13
- 2.064
- 0.197
- 0.009
- 0.005
- 2.19
- 0.126
- 0.008
- 0.333
- 2.141
- 0.151
- 1.94
- 1.771
- 0.14
- 0.014
- 1.871
- 0.144
- 1.864
- 0.224
- 0.183
- 1.893
- 0.116
- 1.747
- 1.625
- 0.166
- 1.723
- 0.143
- 0.018
- 1.748
- 0.305
- 1.768
- 0.086
- 0.221
- 0.222
- 0.065
- 0.443
- 2.002
- 1.607
- 0.133
- 1.643
- 1.491
- 1.461
- 1.487
- 0.191
- 1.548
- 0.158
- 0.169
- 1.617
- 1.424
- 1.411
- 1.341
- 0.124
- 0.009
- 1.535
- 0.162
- 0.21
- 0.133
- 0.347
- 1.771
unequal: 0
verbose: 1
