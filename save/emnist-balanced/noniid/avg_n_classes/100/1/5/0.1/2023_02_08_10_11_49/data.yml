avg_train_accuracy: 0.748
avg_train_loss: 0.015
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02622340425531915
- 0.08686170212765958
- 0.15164893617021277
- 0.24377659574468086
- 0.34867021276595744
- 0.423031914893617
- 0.02127659574468085
- 0.4067021276595745
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.046914893617021274
- 0.39739361702127657
- 0.4584042553191489
- 0.4901595744680851
- 0.5192553191489362
- 0.5332978723404256
- 0.550159574468085
- 0.5607978723404256
- 0.03648936170212766
- 0.037127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.5322872340425532
- 0.05324468085106383
- 0.5633510638297873
- 0.5752127659574469
- 0.588936170212766
- 0.07462765957446808
- 0.1295212765957447
- 0.0848404255319149
- 0.5861170212765957
- 0.2823404255319149
- 0.05345744680851064
- 0.6037765957446809
- 0.5967021276595744
- 0.6018085106382979
- 0.29723404255319147
- 0.6113829787234043
- 0.14797872340425533
- 0.6231382978723404
- 0.6220212765957447
- 0.6292021276595745
- 0.6317021276595745
- 0.6358510638297873
- 0.6402127659574468
- 0.3449468085106383
- 0.6468617021276596
- 0.6454255319148936
- 0.6448936170212766
- 0.6506382978723404
- 0.07973404255319148
- 0.6603191489361702
- 0.6634042553191489
- 0.15888297872340426
- 0.16659574468085106
- 0.6681382978723405
- 0.6651595744680852
- 0.35867021276595745
- 0.6619148936170213
- 0.21430851063829787
- 0.6743085106382979
- 0.6782978723404255
- 0.6755851063829788
- 0.6732446808510638
- 0.675372340425532
- 0.6789893617021276
- 0.10526595744680851
- 0.17186170212765958
- 0.6904787234042553
- 0.3399468085106383
- 0.315
- 0.6925
- 0.45143617021276594
- 0.25851063829787235
- 0.17085106382978724
- 0.6909574468085107
- 0.6856382978723404
- 0.6823936170212765
- 0.44882978723404254
- 0.29638297872340424
- 0.22946808510638297
- 0.6971808510638298
- 0.483031914893617
- 0.693936170212766
- 0.21675531914893617
- 0.698936170212766
- 0.2657978723404255
- 0.6971276595744681
- 0.5049468085106383
- 0.1946808510638298
- 0.20851063829787234
- 0.14920212765957447
- 0.7045744680851064
- 0.5169680851063829
- 0.698404255319149
- 0.39409574468085107
- 0.7105851063829787
test_loss_list:
- 3.7716736062367757
- 3.7164611848195395
- 3.5615293248494466
- 3.2344144280751546
- 2.9407540861765544
- 2.7000032234191895
- 34.42182866414388
- 2.785335947672526
- 25.004058990478516
- 24.34963882446289
- 23.267140553792316
- 18.993816909790038
- 3.4978419240315755
- 2.6219398466746013
- 2.427236483891805
- 2.3109317588806153
- 2.239138733545939
- 2.167836071650187
- 2.122770449320475
- 2.08082040309906
- 11.322500940958658
- 18.124481048583984
- 17.66865130106608
- 23.11539759318034
- 31.57636131286621
- 1.9308416144053142
- 11.492858034769695
- 1.7161016909281412
- 1.7027334403991699
- 1.6939745330810547
- 14.211137186686198
- 9.216527233123779
- 11.916645317077636
- 1.6137974532445272
- 4.804785137176514
- 10.350012613932291
- 1.4626597992579142
- 1.482562417984009
- 1.4947239049275716
- 6.707008851369222
- 1.4642533349990845
- 9.424263242085775
- 1.4287396351496378
- 1.4591146485010782
- 1.4644561115900676
- 1.467295316060384
- 1.471621166865031
- 1.4753483788172403
- 4.77458792368571
- 1.39120223681132
- 1.4131798712412516
- 1.4292664082845052
- 1.4453901545206707
- 10.561736348470053
- 1.3491896772384644
- 1.372962293624878
- 8.027005926767986
- 5.977725957234701
- 1.2653812233606974
- 1.2850497229894002
- 5.848299268086751
- 1.237783392270406
- 6.53295124689738
- 1.1611872617403667
- 1.1812638235092163
- 1.1950053453445435
- 1.2262900829315186
- 1.2377729940414428
- 1.2710565582911173
- 9.259192746480306
- 6.363013928731283
- 1.1833054757118224
- 4.724841041564941
- 4.435816135406494
- 1.1190485843022664
- 3.2121667734781902
- 6.406998589833577
- 7.086019547780355
- 1.0503667815526327
- 1.0930009659131368
- 1.1199031511942545
- 3.3005591424306235
- 4.685011568069458
- 6.373749656677246
- 1.0641744701067606
- 2.9874743366241456
- 1.0910496576627096
- 6.512852783203125
- 1.037696386973063
- 5.339338410695394
- 1.0657697081565858
- 2.755741472244263
- 6.26822764078776
- 7.0466747411092125
- 6.3589420382181805
- 0.9620442771911621
- 2.509576352437337
- 0.9960861905415853
- 4.043367897669475
- 0.9689501245816549
train_accuracy:
- 0.025
- 0.1
- 0.167
- 0.275
- 0.396
- 0.475
- 1.0
- 0.465
- 1.0
- 1.0
- 1.0
- 1.0
- 0.025
- 0.452
- 0.533
- 0.55
- 0.592
- 0.604
- 0.623
- 0.658
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.596
- 1.0
- 0.652
- 0.648
- 0.65
- 0.998
- 1.0
- 0.996
- 0.617
- 1.0
- 1.0
- 0.667
- 0.698
- 0.708
- 1.0
- 0.704
- 0.996
- 0.725
- 0.713
- 0.69
- 0.704
- 0.733
- 0.713
- 1.0
- 0.76
- 0.752
- 0.75
- 0.765
- 1.0
- 0.744
- 0.704
- 0.998
- 1.0
- 0.717
- 0.723
- 1.0
- 0.74
- 1.0
- 0.752
- 0.767
- 0.74
- 0.769
- 0.79
- 0.723
- 1.0
- 1.0
- 0.727
- 1.0
- 1.0
- 0.769
- 1.0
- 1.0
- 1.0
- 0.769
- 0.737
- 0.735
- 1.0
- 1.0
- 1.0
- 0.742
- 1.0
- 0.781
- 0.998
- 0.796
- 0.998
- 0.76
- 1.0
- 0.998
- 1.0
- 0.996
- 0.775
- 1.0
- 0.752
- 1.0
- 0.748
train_loss:
- 3.835
- 3.778
- 3.681
- 3.427
- 3.099
- 2.795
- 0.271
- 3.603
- 0.259
- 1.503
- 0.79
- 0.407
- 3.999
- 3.151
- 2.696
- 2.551
- 2.394
- 2.281
- 2.159
- 2.087
- 0.217
- 0.456
- 0.41
- 0.791
- 0.032
- 3.315
- 0.174
- 2.422
- 2.073
- 2.031
- 0.312
- 0.364
- 0.2
- 2.4
- 0.192
- 0.298
- 2.254
- 1.857
- 1.767
- 0.184
- 1.988
- 0.196
- 2.011
- 1.711
- 1.658
- 1.662
- 1.625
- 1.594
- 0.203
- 1.809
- 1.569
- 1.569
- 1.503
- 0.296
- 1.846
- 1.485
- 0.234
- 0.191
- 1.714
- 1.512
- 0.261
- 1.619
- 0.256
- 1.669
- 1.487
- 1.412
- 1.392
- 1.452
- 1.35
- 0.254
- 0.279
- 1.624
- 0.088
- 0.25
- 1.636
- 0.096
- 0.203
- 0.238
- 1.696
- 1.368
- 1.373
- 0.115
- 0.16
- 0.012
- 1.567
- 0.09
- 1.498
- 0.247
- 1.6
- 0.109
- 1.424
- 0.119
- 0.235
- 0.261
- 0.2
- 1.756
- 0.082
- 1.393
- 0.141
- 1.454
unequal: 0
verbose: 1
