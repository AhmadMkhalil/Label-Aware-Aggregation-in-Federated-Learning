avg_train_accuracy: 1.0
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02627659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.021861702127659574
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02468085106382979
- 0.03026595744680851
- 0.03696808510638298
- 0.02127659574468085
- 0.05398936170212766
- 0.062287234042553194
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.09
- 0.14292553191489363
- 0.20670212765957446
- 0.02127659574468085
- 0.023563829787234043
- 0.021808510638297873
- 0.04085106382978723
- 0.2077127659574468
- 0.051542553191489364
- 0.2754255319148936
- 0.08223404255319149
- 0.3523404255319149
- 0.4403191489361702
- 0.4728723404255319
- 0.03851063829787234
- 0.4925
- 0.526595744680851
- 0.11090425531914894
- 0.07117021276595745
- 0.5377127659574468
- 0.09420212765957447
- 0.5691489361702128
- 0.5763829787234043
- 0.14675531914893616
- 0.5943617021276596
- 0.2148936170212766
- 0.07053191489361701
- 0.07632978723404256
- 0.5979255319148936
- 0.23563829787234042
- 0.6138297872340426
- 0.09154255319148936
- 0.6230851063829788
- 0.32148936170212766
- 0.6222340425531915
- 0.13446808510638297
- 0.08978723404255319
- 0.07893617021276596
- 0.6507446808510639
- 0.637340425531915
- 0.33680851063829786
- 0.6379255319148937
- 0.6406914893617022
- 0.3527659574468085
- 0.13797872340425532
- 0.10021276595744681
- 0.6627127659574468
- 0.6547340425531915
- 0.6544148936170213
- 0.6558510638297872
- 0.6586702127659575
- 0.6576063829787234
- 0.1647872340425532
- 0.6720744680851064
- 0.18909574468085105
- 0.12723404255319148
- 0.055904255319148936
- 0.056914893617021275
- 0.6921276595744681
- 0.6809574468085107
- 0.24377659574468086
- 0.16351063829787235
- 0.1549468085106383
- 0.6939893617021277
- 0.6786702127659574
- 0.6786170212765957
- 0.6786702127659574
- 0.23797872340425533
- 0.19808510638297872
test_loss_list:
- 25.623292668660483
- 28.279714736938477
- 3.7987309392293294
- 18.336448186238606
- 20.681950352986654
- 24.645062433878582
- 22.244397735595705
- 3.8039569282531738
- 15.909828364054363
- 17.27787930806478
- 15.756908721923828
- 18.77760663350423
- 3.800307143529256
- 14.257440872192383
- 17.17843900044759
- 3.8055845483144126
- 3.7982524045308432
- 3.794127343495687
- 13.425893465677897
- 3.7958522478739423
- 9.330955352783203
- 3.8125602054595946
- 3.794001563390096
- 3.7765804958343505
- 17.2825425974528
- 3.7483621788024903
- 3.710012559890747
- 10.024637819925944
- 16.080575726826986
- 10.808904317220053
- 14.267215410868326
- 3.617379757563273
- 3.5154666646321613
- 3.336723928451538
- 13.595449905395508
- 8.669343948364258
- 11.62588675181071
- 12.699912350972493
- 3.231063795089722
- 6.966133537292481
- 2.9884027194976808
- 7.944284985860189
- 2.7167414665222167
- 2.477780901590983
- 2.3013279978434245
- 10.31778163909912
- 2.1369179328282675
- 2.0232344341278075
- 6.875959320068359
- 8.991014862060547
- 1.8778560956319172
- 8.064666442871093
- 1.7739786291122437
- 1.709976355234782
- 7.179674498240153
- 1.661410772005717
- 5.7663314882914225
- 9.503161938985189
- 10.438536326090494
- 1.5556357701619465
- 5.351009553273519
- 1.547946941057841
- 6.999010206858317
- 1.446921901702881
- 5.256423467000325
- 1.4170957501729329
- 7.10737953821818
- 7.053183937072754
- 6.690100167592367
- 1.2970573981602986
- 1.3160547399520874
- 4.353977794647217
- 1.308239482243856
- 1.306759425799052
- 4.673560196558634
- 7.485835552215576
- 7.048864771525065
- 1.2231338930130005
- 1.2489186922709148
- 1.2657162189483642
- 1.2863662036259969
- 1.2920420503616332
- 1.313779927889506
- 5.922672430674235
- 1.2320381514231364
- 7.357064997355144
- 10.195353418986002
- 7.117556966145833
- 8.442229512532553
- 1.16791632493337
- 1.1869091518719992
- 5.97424877166748
- 8.64963545481364
- 5.934546667734782
- 1.1713913544019063
- 1.2121288712819418
- 1.2212837012608846
- 1.2346887763341268
- 6.229326508839925
- 5.773332920074463
train_accuracy:
- 1.0
- 1.0
- 0.008
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 1.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 0.006
- 1.0
- 1.0
- 1.0
- 1.0
- 0.01
- 0.125
- 0.188
- 1.0
- 0.998
- 1.0
- 1.0
- 0.212
- 0.998
- 0.265
- 1.0
- 0.365
- 0.465
- 0.51
- 1.0
- 0.535
- 0.565
- 1.0
- 1.0
- 0.556
- 1.0
- 0.656
- 0.669
- 1.0
- 0.677
- 1.0
- 0.998
- 1.0
- 0.688
- 1.0
- 0.635
- 0.998
- 0.652
- 1.0
- 0.654
- 0.996
- 1.0
- 1.0
- 0.665
- 0.667
- 1.0
- 0.665
- 0.727
- 1.0
- 0.996
- 1.0
- 0.683
- 0.698
- 0.715
- 0.708
- 0.748
- 0.706
- 0.998
- 0.773
- 0.996
- 1.0
- 0.996
- 1.0
- 0.7
- 0.729
- 0.996
- 1.0
- 1.0
- 0.727
- 0.704
- 0.74
- 0.787
- 0.996
- 1.0
train_loss:
- 0.474
- 0.482
- 4.18
- 1.437
- 0.355
- 0.012
- 0.735
- 4.206
- 0.578
- 0.34
- 0.243
- 0.008
- 4.173
- 1.97
- 0.352
- 4.184
- 3.898
- 3.884
- 0.922
- 4.106
- 2.058
- 4.098
- 3.915
- 3.885
- 1.361
- 4.129
- 3.845
- 0.439
- 0.333
- 0.187
- 0.276
- 4.044
- 3.741
- 3.616
- 0.288
- 0.327
- 0.153
- 0.167
- 3.807
- 0.203
- 3.501
- 0.161
- 3.276
- 2.918
- 2.661
- 0.294
- 2.794
- 2.37
- 0.193
- 0.008
- 2.51
- 0.241
- 2.382
- 2.059
- 0.133
- 2.108
- 0.096
- 0.237
- 0.319
- 2.278
- 0.092
- 2.14
- 0.241
- 2.103
- 0.166
- 2.05
- 0.197
- 0.238
- 0.245
- 2.171
- 1.807
- 0.124
- 1.865
- 1.645
- 0.168
- 0.221
- 0.158
- 1.996
- 1.679
- 1.645
- 1.581
- 1.529
- 1.548
- 0.244
- 1.643
- 0.187
- 0.012
- 0.192
- 0.234
- 1.891
- 1.544
- 0.12
- 0.013
- 0.135
- 1.724
- 1.495
- 1.458
- 1.413
- 0.146
- 0.235
unequal: 0
verbose: 1
