avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.028297872340425533
- 0.03765957446808511
- 0.06329787234042553
- 0.19122340425531914
- 0.3084574468085106
- 0.4054255319148936
- 0.45632978723404255
- 0.4946276595744681
- 0.5198936170212766
- 0.5390957446808511
- 0.5628723404255319
- 0.5772872340425532
- 0.5856914893617021
- 0.5922872340425532
- 0.6095744680851064
- 0.618031914893617
- 0.628563829787234
- 0.6315957446808511
- 0.6389361702127659
- 0.6478191489361702
- 0.6488297872340425
- 0.6461702127659574
- 0.6580851063829787
- 0.6597340425531915
- 0.6632978723404256
- 0.6675
- 0.6675
- 0.6728723404255319
- 0.6736170212765957
- 0.6748936170212766
- 0.6773404255319149
- 0.6829255319148936
- 0.679468085106383
- 0.6798404255319149
- 0.6819148936170213
- 0.6858510638297872
- 0.6856382978723404
- 0.6906382978723404
- 0.6884574468085106
- 0.6933510638297873
- 0.6953723404255319
- 0.6941489361702128
- 0.6963297872340426
- 0.6975531914893617
- 0.6991489361702128
- 0.6980851063829787
- 0.7007978723404256
- 0.7016489361702127
- 0.7049468085106383
- 0.7024468085106383
- 0.705
- 0.7026595744680851
- 0.7052659574468085
- 0.706436170212766
- 0.7071276595744681
- 0.7076595744680851
- 0.7067021276595745
- 0.7076595744680851
- 0.7120212765957447
- 0.7093085106382979
- 0.708936170212766
- 0.7097872340425532
- 0.7132446808510639
- 0.7126063829787234
- 0.7131382978723404
- 0.7113297872340425
- 0.7148936170212766
- 0.7154255319148937
- 0.7143617021276596
- 0.7151595744680851
- 0.7161170212765957
- 0.7158510638297872
- 0.7160106382978724
- 0.7165957446808511
- 0.7178723404255319
- 0.7208510638297873
- 0.7193085106382979
- 0.7188297872340426
- 0.7185106382978723
- 0.7166489361702127
- 0.7194680851063829
- 0.7202659574468085
- 0.7237234042553191
- 0.7209042553191489
- 0.7203191489361702
- 0.7213829787234043
- 0.721063829787234
- 0.7227127659574468
- 0.7211170212765957
- 0.7246276595744681
- 0.7224468085106382
- 0.7249468085106383
- 0.7252127659574468
- 0.7255851063829787
- 0.7265425531914894
- 0.7265957446808511
- 0.7275
- 0.727872340425532
- 0.7253191489361702
- 0.7273936170212766
test_loss_list:
- 3.7856017335255943
- 3.7545203081766765
- 3.6752692381540935
- 3.4676099109649656
- 3.117228905359904
- 2.8174237855275472
- 2.5908992036183673
- 2.4037099838256837
- 2.311229060490926
- 2.2114011494318646
- 2.1560693184534707
- 2.114825717608134
- 2.039249142011007
- 1.9988763332366943
- 1.9720861005783081
- 1.9697343174616495
- 1.932544191678365
- 1.913590547243754
- 1.8550591341654459
- 1.8589846165974935
- 1.8387739690144858
- 1.8096081336339316
- 1.7813547738393147
- 1.7735194921493531
- 1.7435251347223917
- 1.7826406304041544
- 1.7381634585062662
- 1.7593137470881144
- 1.7544289461771647
- 1.6936655410130819
- 1.699895315170288
- 1.6989212052027385
- 1.6615988381703695
- 1.6532471100489299
- 1.6715433231989543
- 1.6574800380071004
- 1.6525266647338868
- 1.6567239157358806
- 1.606081051826477
- 1.6302546675999958
- 1.6028580077489216
- 1.5946789216995239
- 1.5495534070332846
- 1.5796219730377197
- 1.5689977153142294
- 1.5671538511912029
- 1.5556959676742554
- 1.5805514129002889
- 1.5389496151606241
- 1.5516293414433797
- 1.5219119453430177
- 1.531001524925232
- 1.5215295807520548
- 1.5248571395874024
- 1.4906728760401409
- 1.5335609038670859
- 1.4780575243632
- 1.4386668968200684
- 1.4922068436940512
- 1.4618636178970337
- 1.4808760070800782
- 1.4710318120320638
- 1.4638224363327026
- 1.4646071688334148
- 1.4420991547902424
- 1.4286871115366617
- 1.4695655155181884
- 1.457561484972636
- 1.429236585299174
- 1.4033589045206705
- 1.4146690305074057
- 1.4220704491933187
- 1.4318198188145956
- 1.4274327532450357
- 1.3995422395070394
- 1.4077596394220988
- 1.4213703362147014
- 1.4260894250869751
- 1.377183615366618
- 1.3462786817550658
- 1.3648222955067952
- 1.3419185447692872
- 1.3512074279785156
- 1.3448327732086183
- 1.3470132939020794
- 1.3573694769541422
- 1.3351771291097005
- 1.3418376270929973
- 1.3047392082214355
- 1.3466751607259115
- 1.3219143184026083
- 1.296074504852295
- 1.3406539630889893
- 1.3114167181650798
- 1.2915412219365439
- 1.308318190574646
- 1.3153737020492553
- 1.298510840733846
- 1.2917464097340903
- 1.2895830901463827
train_accuracy:
- 0.0
- 0.042
- 0.067
- 0.0
- 0.35
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.606
- 0.0
- 0.656
- 0.0
- 0.0
- 0.0
- 0.706
- 0.713
- 0.7
- 0.0
- 0.0
- 0.0
- 0.717
- 0.723
- 0.0
- 0.767
- 0.767
- 0.725
- 0.0
- 0.0
- 0.0
- 0.779
- 0.785
- 0.0
- 0.735
- 0.0
- 0.0
- 0.815
- 0.737
- 0.0
- 0.0
- 0.0
- 0.756
- 0.0
- 0.0
- 0.825
- 0.0
- 0.0
- 0.0
- 0.802
- 0.75
- 0.0
- 0.758
- 0.769
- 0.767
- 0.76
- 0.765
- 0.812
- 0.775
- 0.0
- 0.76
- 0.781
- 0.0
- 0.833
- 0.0
- 0.767
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.758
- 0.0
- 0.838
- 0.0
- 0.781
- 0.835
- 0.773
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.84
- 0.798
- 0.0
- 0.0
- 0.779
- 0.0
- 0.829
- 0.0
- 0.0
- 0.794
- 0.827
- 0.796
- 0.0
- 0.777
- 0.829
- 0.0
- 0.0
train_loss:
- 2.368
- 1.877
- 2.291
- 2.193
- 1.565
- 2.235
- 1.302
- 0.872
- 1.457
- 1.076
- 1.041
- 1.262
- 0.728
- 0.694
- 0.912
- 1.356
- 1.095
- 1.073
- 0.638
- 1.043
- 0.805
- 0.602
- 0.798
- 0.787
- 0.783
- 1.122
- 0.764
- 1.107
- 0.915
- 0.558
- 0.734
- 0.893
- 0.542
- 0.705
- 0.869
- 0.684
- 0.855
- 0.839
- 0.688
- 0.834
- 0.672
- 0.659
- 0.508
- 0.802
- 0.642
- 0.641
- 0.649
- 0.947
- 0.642
- 0.788
- 0.635
- 0.626
- 0.774
- 0.772
- 0.629
- 0.902
- 0.612
- 0.476
- 0.756
- 0.61
- 0.735
- 0.737
- 0.747
- 0.736
- 0.598
- 0.589
- 0.87
- 0.729
- 0.579
- 0.588
- 0.584
- 0.707
- 0.714
- 0.703
- 0.574
- 0.71
- 0.84
- 0.694
- 0.567
- 0.426
- 0.563
- 0.567
- 0.693
- 0.56
- 0.558
- 0.685
- 0.548
- 0.684
- 0.42
- 0.672
- 0.55
- 0.547
- 0.799
- 0.536
- 0.545
- 0.683
- 0.654
- 0.683
- 0.536
- 0.535
unequal: 0
verbose: 1
