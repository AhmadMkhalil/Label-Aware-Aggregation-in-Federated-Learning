avg_train_accuracy: 0.787
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03888297872340426
- 0.08063829787234042
- 0.12117021276595745
- 0.18265957446808512
- 0.28797872340425534
- 0.3705851063829787
- 0.43377659574468086
- 0.4689893617021277
- 0.5043617021276596
- 0.5282446808510638
- 0.5390957446808511
- 0.5581382978723404
- 0.5704787234042553
- 0.5786170212765958
- 0.5893085106382979
- 0.5992021276595745
- 0.601063829787234
- 0.6097872340425532
- 0.6161170212765957
- 0.6194148936170213
- 0.628031914893617
- 0.6306382978723404
- 0.6370212765957447
- 0.6368617021276596
- 0.6412765957446809
- 0.6467553191489361
- 0.6484042553191489
- 0.6532978723404256
- 0.6551595744680851
- 0.6589893617021276
- 0.6584042553191489
- 0.6621808510638297
- 0.6668085106382978
- 0.6686170212765957
- 0.671595744680851
- 0.6742553191489362
- 0.6701063829787234
- 0.6743617021276596
- 0.6763829787234042
- 0.68
- 0.6792553191489362
- 0.6825
- 0.6843617021276596
- 0.6852127659574468
- 0.6842553191489362
- 0.686063829787234
- 0.6896808510638298
- 0.6923404255319149
- 0.6921276595744681
- 0.6944148936170212
- 0.6951063829787234
- 0.6949468085106383
- 0.6953191489361702
- 0.6948404255319149
- 0.698031914893617
- 0.6976063829787233
- 0.6973404255319149
- 0.699840425531915
- 0.6988297872340425
- 0.6988297872340425
- 0.7012765957446808
- 0.7015957446808511
- 0.7020744680851064
- 0.7029255319148936
- 0.7044148936170213
- 0.7053723404255319
- 0.7054255319148937
- 0.7045744680851064
- 0.7059574468085107
- 0.7072872340425532
- 0.7072340425531914
- 0.708404255319149
- 0.7073936170212766
- 0.7110106382978724
- 0.7107446808510638
- 0.7118617021276595
- 0.7135106382978723
- 0.7137234042553191
- 0.7131382978723404
- 0.7144680851063829
- 0.7131914893617022
- 0.7156382978723405
- 0.7151063829787234
- 0.7152127659574468
- 0.7138829787234042
- 0.7179787234042553
- 0.7178191489361702
- 0.7172340425531915
- 0.716063829787234
- 0.7166489361702127
- 0.7189893617021277
- 0.7177659574468085
- 0.7200531914893618
- 0.7200531914893618
- 0.7219148936170213
- 0.7200531914893618
- 0.7212234042553192
- 0.7207978723404256
- 0.7196276595744681
- 0.7222872340425532
test_loss_list:
- 3.784686260223389
- 3.750885009765625
- 3.638834457397461
- 3.387400986353556
- 3.063451649347941
- 2.7992823950449623
- 2.568184741338094
- 2.429545110066732
- 2.310842078526815
- 2.1981666549046834
- 2.117185271581014
- 2.0708460235595703
- 2.014350096384684
- 1.975209856033325
- 1.9603075297673542
- 1.9110452874501547
- 1.8816874853769938
- 1.8755817047754924
- 1.8483461650212605
- 1.8339619207382203
- 1.849088223775228
- 1.8219069465001425
- 1.7943077516555785
- 1.7733878072102864
- 1.7684311532974244
- 1.7372205289204916
- 1.717522824605306
- 1.737208029429118
- 1.7006216780344645
- 1.7222678263982136
- 1.6651987648010254
- 1.6465194495519002
- 1.6373690191904704
- 1.6234484672546388
- 1.619105084737142
- 1.6543769947687785
- 1.5974653704961141
- 1.594741390546163
- 1.5931369225184122
- 1.6260390440622965
- 1.5745515028635662
- 1.5672951984405517
- 1.5614557536443074
- 1.5503827842076618
- 1.5279807360967
- 1.5028563372294108
- 1.5201142962773642
- 1.5271987406412761
- 1.5080761830012004
- 1.4947518491744995
- 1.4708231512705485
- 1.454469428062439
- 1.4544982957839965
- 1.4539406220118205
- 1.4315652720133463
- 1.4384777895609537
- 1.4324091704686484
- 1.4437557617823282
- 1.4562144406636557
- 1.4359424018859863
- 1.420304718017578
- 1.4245716762542724
- 1.402538342475891
- 1.416305357615153
- 1.4118109083175658
- 1.4138535912831625
- 1.406923656463623
- 1.375506771405538
- 1.3828580570220947
- 1.3923252375920614
- 1.362992804845174
- 1.3789413102467856
- 1.3724320205052694
- 1.3689179420471191
- 1.355201473236084
- 1.353045605023702
- 1.3589685408274332
- 1.3472901582717896
- 1.3276907364527384
- 1.3406088638305664
- 1.3459989086786905
- 1.316239776611328
- 1.316875794728597
- 1.3341090949376424
- 1.2959573062260945
- 1.3362650267283123
- 1.3296447086334229
- 1.339470542271932
- 1.3120777972539266
- 1.315085884730021
- 1.3120818408330281
- 1.2630822340647379
- 1.2920277293523152
- 1.2864970191319784
- 1.2886999519666036
- 1.2627500979105633
- 1.2804032770792644
- 1.2659447129567465
- 1.2513018250465393
- 1.254753204981486
train_accuracy:
- 0.0
- 0.09
- 0.0
- 0.198
- 0.0
- 0.0
- 0.517
- 0.0
- 0.56
- 0.0
- 0.612
- 0.0
- 0.0
- 0.7
- 0.0
- 0.662
- 0.0
- 0.0
- 0.0
- 0.0
- 0.723
- 0.0
- 0.723
- 0.0
- 0.0
- 0.748
- 0.0
- 0.746
- 0.735
- 0.723
- 0.752
- 0.0
- 0.0
- 0.0
- 0.765
- 0.754
- 0.0
- 0.729
- 0.0
- 0.794
- 0.0
- 0.754
- 0.746
- 0.0
- 0.796
- 0.0
- 0.0
- 0.754
- 0.0
- 0.0
- 0.806
- 0.796
- 0.0
- 0.763
- 0.796
- 0.812
- 0.777
- 0.771
- 0.779
- 0.808
- 0.823
- 0.769
- 0.812
- 0.0
- 0.792
- 0.783
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.825
- 0.798
- 0.806
- 0.825
- 0.823
- 0.0
- 0.821
- 0.831
- 0.0
- 0.821
- 0.808
- 0.84
- 0.821
- 0.0
- 0.827
- 0.0
- 0.0
- 0.0
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.0
- 0.785
- 0.831
- 0.0
- 0.0
- 0.787
train_loss:
- 2.384
- 2.856
- 1.819
- 2.163
- 1.099
- 1.831
- 1.309
- 1.238
- 1.49
- 1.112
- 0.773
- 1.035
- 1.005
- 0.713
- 1.201
- 1.176
- 0.907
- 0.898
- 0.876
- 0.852
- 1.283
- 1.056
- 1.037
- 0.82
- 1.014
- 0.79
- 0.792
- 0.961
- 0.766
- 1.145
- 0.575
- 0.744
- 0.742
- 0.732
- 0.729
- 1.072
- 0.715
- 0.712
- 0.871
- 1.04
- 0.697
- 0.683
- 0.858
- 0.683
- 0.683
- 0.505
- 0.828
- 0.827
- 0.661
- 0.817
- 0.655
- 0.485
- 0.637
- 0.798
- 0.64
- 0.634
- 0.632
- 0.785
- 0.938
- 0.77
- 0.616
- 0.767
- 0.62
- 0.765
- 0.761
- 0.757
- 0.6
- 0.606
- 0.595
- 0.741
- 0.598
- 0.733
- 0.735
- 0.725
- 0.723
- 0.724
- 0.718
- 0.713
- 0.579
- 0.709
- 0.712
- 0.57
- 0.706
- 0.839
- 0.576
- 0.838
- 0.703
- 0.843
- 0.57
- 0.691
- 0.691
- 0.423
- 0.696
- 0.682
- 0.683
- 0.554
- 0.688
- 0.682
- 0.549
- 0.684
unequal: 0
verbose: 1
