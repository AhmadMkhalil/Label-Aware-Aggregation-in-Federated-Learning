avg_train_accuracy: 0.812
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03053191489361702
- 0.0673936170212766
- 0.14909574468085107
- 0.2528723404255319
- 0.35090425531914893
- 0.4192021276595745
- 0.46867021276595744
- 0.5002659574468085
- 0.5236702127659575
- 0.5457446808510639
- 0.5534574468085106
- 0.5726063829787233
- 0.5828723404255319
- 0.5895212765957447
- 0.604468085106383
- 0.6075
- 0.6153723404255319
- 0.6208510638297873
- 0.6244148936170213
- 0.6289893617021277
- 0.6360638297872341
- 0.6400531914893617
- 0.6436170212765957
- 0.6495212765957447
- 0.6496808510638298
- 0.6556382978723404
- 0.6584042553191489
- 0.6605319148936171
- 0.6622872340425532
- 0.6639893617021276
- 0.6677127659574468
- 0.6698936170212766
- 0.6742021276595744
- 0.6748404255319149
- 0.6751063829787234
- 0.6790425531914893
- 0.6779787234042554
- 0.6815425531914894
- 0.6835638297872341
- 0.6845744680851064
- 0.6867021276595745
- 0.6884574468085106
- 0.6888297872340425
- 0.689468085106383
- 0.6902127659574468
- 0.6903723404255319
- 0.694468085106383
- 0.6963297872340426
- 0.696968085106383
- 0.6981382978723404
- 0.698031914893617
- 0.7005851063829788
- 0.7010106382978724
- 0.7013829787234043
- 0.7031914893617022
- 0.7035106382978723
- 0.7035106382978723
- 0.7055851063829788
- 0.7037765957446809
- 0.7053723404255319
- 0.7060106382978724
- 0.7081382978723404
- 0.708031914893617
- 0.7072340425531914
- 0.7087234042553191
- 0.7077127659574468
- 0.7086170212765958
- 0.7104787234042553
- 0.7106382978723405
- 0.7106914893617021
- 0.7068617021276595
- 0.7129787234042553
- 0.7095744680851064
- 0.7156382978723405
- 0.7121276595744681
- 0.7146808510638298
- 0.713936170212766
- 0.7139893617021277
- 0.7167021276595744
- 0.7140425531914893
- 0.7174468085106382
- 0.7187765957446809
- 0.7168617021276595
- 0.7175531914893617
- 0.7161170212765957
- 0.7165957446808511
- 0.7186170212765958
- 0.7201063829787234
- 0.7202127659574468
- 0.7190425531914894
- 0.7213829787234043
- 0.7225
- 0.7224468085106382
- 0.7219148936170213
- 0.7220744680851063
- 0.7212765957446808
- 0.7211170212765957
- 0.7222872340425532
- 0.7225
- 0.7238829787234042
test_loss_list:
- 3.7720948378245036
- 3.6961297289530437
- 3.4873125457763674
- 3.1592937469482423
- 2.860519914627075
- 2.6190190887451172
- 2.455397990544637
- 2.3373473199208576
- 2.249289698600769
- 2.178086287180583
- 2.1149213250478107
- 2.0782901493708295
- 2.0358956257502236
- 1.9926733160018921
- 1.99224960009257
- 1.9174709876378377
- 1.9029141982396445
- 1.8659506956736247
- 1.8538770786921184
- 1.8259677998224895
- 1.834550822575887
- 1.8274976682662964
- 1.8011867411931355
- 1.8202217690149942
- 1.7886353127161663
- 1.7813664960861206
- 1.7796922397613526
- 1.7267976299921672
- 1.6926937850316366
- 1.6913139295578004
- 1.6860471026102701
- 1.676583259900411
- 1.6758488321304321
- 1.649033759435018
- 1.6334466520945232
- 1.6485898717244467
- 1.6172305583953857
- 1.632739601135254
- 1.6003191884358723
- 1.591472544670105
- 1.5659040339787802
- 1.6066761366526285
- 1.5718171532948813
- 1.565487356185913
- 1.5459240913391112
- 1.5471688095728557
- 1.555616799990336
- 1.5402862024307251
- 1.5328718169530233
- 1.5383701817194622
- 1.5196928485234578
- 1.5482223145167033
- 1.5127673308054606
- 1.4980557600657145
- 1.514241582552592
- 1.486710124015808
- 1.4854947964350382
- 1.464408672650655
- 1.4545608059565227
- 1.4682270240783692
- 1.4675682926177978
- 1.4716782426834107
- 1.462231806119283
- 1.439016925493876
- 1.4445207850138346
- 1.4109774573644003
- 1.4338263877232869
- 1.4652559916178385
- 1.4383730618158976
- 1.4024124240875244
- 1.3840505615870158
- 1.3963919766743977
- 1.3654083935419719
- 1.4332951927185058
- 1.4015486590067545
- 1.3949383894602458
- 1.3693502473831176
- 1.3332477140426635
- 1.3141508642832438
- 1.3124491945902506
- 1.3371713336308797
- 1.3495492537816365
- 1.330890653928121
- 1.329659603436788
- 1.3097855138778687
- 1.317213961283366
- 1.3006558227539062
- 1.2893661626180013
- 1.2994362529118855
- 1.2981214062372843
- 1.318384656906128
- 1.3170987685521445
- 1.3048695294062296
- 1.3111452849706013
- 1.2946803506215414
- 1.2604004923502605
- 1.2757673041025797
- 1.3132257064183552
- 1.2674185307820638
- 1.2940276638666788
train_accuracy:
- 0.04
- 0.077
- 0.188
- 0.0
- 0.0
- 0.0
- 0.552
- 0.548
- 0.0
- 0.629
- 0.0
- 0.0
- 0.0
- 0.0
- 0.704
- 0.0
- 0.0
- 0.729
- 0.677
- 0.0
- 0.737
- 0.746
- 0.0
- 0.0
- 0.719
- 0.763
- 0.0
- 0.781
- 0.0
- 0.756
- 0.771
- 0.771
- 0.752
- 0.777
- 0.0
- 0.79
- 0.0
- 0.804
- 0.0
- 0.76
- 0.812
- 0.79
- 0.0
- 0.0
- 0.792
- 0.0
- 0.781
- 0.802
- 0.812
- 0.0
- 0.808
- 0.777
- 0.0
- 0.787
- 0.0
- 0.796
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.812
- 0.0
- 0.817
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.817
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.821
- 0.815
- 0.0
- 0.0
- 0.823
- 0.0
- 0.0
- 0.815
- 0.0
- 0.0
- 0.0
- 0.825
- 0.812
train_loss:
- 1.865
- 1.828
- 2.21
- 1.6
- 1.445
- 1.328
- 1.246
- 1.492
- 1.112
- 1.366
- 0.776
- 1.278
- 0.98
- 0.966
- 1.422
- 0.703
- 0.904
- 0.893
- 0.874
- 0.853
- 1.052
- 1.044
- 0.826
- 1.207
- 1.002
- 1.175
- 0.983
- 0.788
- 0.585
- 0.764
- 0.937
- 0.748
- 0.927
- 0.73
- 0.722
- 0.898
- 0.727
- 0.883
- 0.701
- 0.698
- 0.702
- 1.016
- 0.698
- 0.693
- 0.685
- 0.675
- 0.835
- 0.665
- 0.821
- 0.821
- 0.809
- 0.966
- 0.807
- 0.804
- 0.801
- 0.641
- 0.784
- 0.631
- 0.634
- 0.776
- 0.78
- 0.778
- 0.773
- 0.619
- 0.764
- 0.612
- 0.76
- 0.898
- 0.761
- 0.606
- 0.612
- 0.741
- 0.456
- 0.881
- 0.739
- 0.735
- 0.454
- 0.447
- 0.442
- 0.434
- 0.582
- 0.716
- 0.58
- 0.57
- 0.433
- 0.568
- 0.562
- 0.564
- 0.564
- 0.56
- 0.704
- 0.702
- 0.698
- 0.699
- 0.689
- 0.427
- 0.416
- 0.689
- 0.548
- 0.681
unequal: 0
verbose: 1
