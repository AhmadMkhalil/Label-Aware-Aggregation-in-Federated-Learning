avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0374468085106383
- 0.09053191489361702
- 0.13398936170212766
- 0.21936170212765957
- 0.3631382978723404
- 0.45
- 0.4978191489361702
- 0.5259574468085106
- 0.5497340425531915
- 0.5680851063829787
- 0.5818085106382979
- 0.5881914893617022
- 0.5980851063829787
- 0.6071276595744681
- 0.6114893617021276
- 0.6207978723404255
- 0.6295744680851064
- 0.6293617021276596
- 0.6388297872340426
- 0.6428723404255319
- 0.6456914893617022
- 0.6527659574468085
- 0.6542021276595744
- 0.6579255319148937
- 0.6611170212765958
- 0.6654787234042553
- 0.6693085106382979
- 0.6687765957446808
- 0.6743617021276596
- 0.676063829787234
- 0.6761170212765958
- 0.6802659574468085
- 0.6811170212765958
- 0.6842021276595744
- 0.6887234042553192
- 0.689627659574468
- 0.6901595744680851
- 0.6903723404255319
- 0.6898404255319149
- 0.6923936170212766
- 0.694627659574468
- 0.6972872340425532
- 0.6990425531914893
- 0.6986170212765958
- 0.6985638297872341
- 0.7005851063829788
- 0.7018085106382979
- 0.7022340425531914
- 0.7048404255319148
- 0.7038829787234042
- 0.7045744680851064
- 0.7069148936170213
- 0.7078723404255319
- 0.7087234042553191
- 0.7098936170212766
- 0.7100531914893617
- 0.7107446808510638
- 0.7112234042553192
- 0.7110106382978724
- 0.7098404255319148
- 0.7095744680851064
- 0.7112234042553192
- 0.7120744680851064
- 0.711436170212766
- 0.7133510638297872
- 0.7129787234042553
- 0.7160106382978724
- 0.716968085106383
- 0.7159574468085106
- 0.7152127659574468
- 0.714627659574468
- 0.7174468085106382
- 0.7161170212765957
- 0.7169148936170213
- 0.7179255319148936
- 0.7171276595744681
- 0.718404255319149
- 0.7207446808510638
- 0.7195744680851064
- 0.7197872340425532
- 0.7206914893617021
- 0.7197340425531915
- 0.7209042553191489
- 0.7201063829787234
- 0.7213297872340425
- 0.7222340425531915
- 0.7203723404255319
- 0.7195212765957447
- 0.7207446808510638
- 0.7209042553191489
- 0.7224468085106382
- 0.7221276595744681
- 0.7230851063829787
- 0.7217021276595744
- 0.7224468085106382
- 0.725
- 0.7226595744680852
- 0.7232446808510639
- 0.7238829787234042
- 0.7242553191489361
test_loss_list:
- 3.78204340616862
- 3.741145051320394
- 3.605975735982259
- 3.289264554977417
- 2.905542958577474
- 2.6117221895853677
- 2.4000714174906412
- 2.267765022913615
- 2.1669043413798015
- 2.0663663005828856
- 2.0247858285903932
- 1.974603861172994
- 1.9333507823944092
- 1.902550713221232
- 1.8538576745986939
- 1.8285229714711506
- 1.8191907596588135
- 1.7840466769536336
- 1.7953254954020181
- 1.7686412652333579
- 1.735220063527425
- 1.751481827100118
- 1.7282477378845216
- 1.6984044806162517
- 1.6994703483581544
- 1.6851071087519327
- 1.6589679718017578
- 1.6492436854044596
- 1.6232433859507243
- 1.620145149230957
- 1.582746459643046
- 1.598223622639974
- 1.5903853257497151
- 1.579750984509786
- 1.5755609639485677
- 1.5750752639770509
- 1.5791393486658731
- 1.5700150314966839
- 1.5274986871083578
- 1.5165017000834147
- 1.5353229014078775
- 1.5032911666234334
- 1.5184851090113323
- 1.525452602704366
- 1.5065029096603393
- 1.497259292602539
- 1.4921012671788534
- 1.4986616357167561
- 1.5061926285425822
- 1.4753587992986044
- 1.4751559352874757
- 1.4761546357472737
- 1.472256965637207
- 1.4730008522669473
- 1.4416902542114258
- 1.4443632634480794
- 1.4441971174875896
- 1.4395420249303181
- 1.4401685158411661
- 1.4267651844024658
- 1.4117330582936605
- 1.4287197669347127
- 1.4181547927856446
- 1.41378866036733
- 1.4192630736033123
- 1.3783794021606446
- 1.413147161801656
- 1.3654901790618896
- 1.368334272702535
- 1.3394812218348184
- 1.3620986795425416
- 1.3741782395044964
- 1.3487696393330892
- 1.3777660783131918
- 1.3478581857681275
- 1.345564759572347
- 1.3387457911173504
- 1.322855315208435
- 1.3667076031366985
- 1.3516290696461994
- 1.3470951048533122
- 1.334609891573588
- 1.3243909708658854
- 1.3378246561686198
- 1.3205559635162354
- 1.3336088069279988
- 1.3183101574579874
- 1.3046639490127563
- 1.305165189107259
- 1.2888191294670106
- 1.2926890134811402
- 1.3157390880584716
- 1.301345477104187
- 1.291203236579895
- 1.2741158453623453
- 1.2752328634262085
- 1.258948454062144
- 1.2758799203236897
- 1.2638568727175394
- 1.26477756579717
train_accuracy:
- 0.033
- 0.0
- 0.129
- 0.0
- 0.0
- 0.0
- 0.525
- 0.612
- 0.646
- 0.0
- 0.679
- 0.0
- 0.0
- 0.683
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.731
- 0.0
- 0.754
- 0.756
- 0.76
- 0.0
- 0.725
- 0.0
- 0.785
- 0.748
- 0.758
- 0.0
- 0.0
- 0.0
- 0.804
- 0.771
- 0.808
- 0.792
- 0.754
- 0.0
- 0.79
- 0.0
- 0.806
- 0.0
- 0.0
- 0.806
- 0.0
- 0.798
- 0.823
- 0.796
- 0.0
- 0.79
- 0.804
- 0.821
- 0.0
- 0.802
- 0.0
- 0.81
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.829
- 0.783
- 0.804
- 0.0
- 0.812
- 0.0
- 0.0
- 0.8
- 0.0
- 0.0
- 0.842
- 0.0
- 0.0
- 0.823
- 0.815
- 0.0
- 0.81
- 0.0
- 0.823
- 0.79
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.817
- 0.796
- 0.787
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 2.436
- 1.943
- 2.291
- 1.204
- 1.487
- 1.734
- 1.237
- 1.146
- 1.393
- 1.048
- 1.282
- 0.981
- 0.687
- 1.152
- 0.673
- 0.876
- 1.098
- 0.633
- 1.032
- 1.037
- 0.809
- 1.205
- 0.981
- 0.767
- 0.955
- 0.941
- 0.749
- 0.733
- 0.744
- 0.732
- 0.554
- 0.888
- 0.878
- 0.7
- 0.862
- 0.864
- 0.848
- 0.842
- 0.511
- 0.673
- 0.813
- 0.66
- 0.813
- 0.811
- 0.823
- 0.651
- 0.649
- 0.783
- 0.939
- 0.637
- 0.625
- 0.792
- 0.773
- 0.765
- 0.615
- 0.764
- 0.761
- 0.756
- 0.761
- 0.616
- 0.599
- 0.742
- 0.597
- 0.593
- 0.73
- 0.466
- 0.865
- 0.592
- 0.44
- 0.585
- 0.578
- 0.718
- 0.579
- 0.707
- 0.72
- 0.58
- 0.579
- 0.572
- 0.841
- 0.708
- 0.704
- 0.562
- 0.564
- 0.693
- 0.567
- 0.693
- 0.553
- 0.561
- 0.423
- 0.42
- 0.68
- 0.807
- 0.681
- 0.539
- 0.556
- 0.541
- 0.545
- 0.662
- 0.545
- 0.537
unequal: 0
verbose: 1
