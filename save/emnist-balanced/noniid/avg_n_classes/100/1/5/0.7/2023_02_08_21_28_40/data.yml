avg_train_accuracy: 0.815
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0400531914893617
- 0.07606382978723404
- 0.1250531914893617
- 0.2544148936170213
- 0.35132978723404257
- 0.4327659574468085
- 0.48436170212765955
- 0.5126595744680851
- 0.5355319148936171
- 0.5461170212765958
- 0.5661702127659575
- 0.5776063829787234
- 0.5887765957446809
- 0.5938829787234042
- 0.5977127659574468
- 0.6091489361702128
- 0.6195212765957446
- 0.620904255319149
- 0.6293617021276596
- 0.6325
- 0.6409574468085106
- 0.6453723404255319
- 0.6436702127659575
- 0.6513829787234042
- 0.6569680851063829
- 0.6636702127659575
- 0.6620744680851064
- 0.6646276595744681
- 0.670372340425532
- 0.6739893617021276
- 0.6742021276595744
- 0.6782446808510638
- 0.679468085106383
- 0.680372340425532
- 0.6826063829787234
- 0.6848404255319149
- 0.6845212765957447
- 0.688936170212766
- 0.6914361702127659
- 0.6920744680851064
- 0.6942553191489361
- 0.6942553191489361
- 0.695
- 0.6992021276595745
- 0.696968085106383
- 0.7010106382978724
- 0.7023404255319149
- 0.7018617021276595
- 0.7052659574468085
- 0.7030851063829787
- 0.7047872340425532
- 0.7049468085106383
- 0.7094148936170213
- 0.7116489361702127
- 0.7086702127659574
- 0.7102127659574468
- 0.7116489361702127
- 0.7125
- 0.7130319148936171
- 0.7158510638297872
- 0.7136702127659574
- 0.7163297872340425
- 0.7182978723404255
- 0.7194148936170213
- 0.721063829787234
- 0.719095744680851
- 0.7209574468085106
- 0.7217021276595744
- 0.7202127659574468
- 0.7217553191489362
- 0.7220212765957447
- 0.7246808510638297
- 0.7255851063829787
- 0.7199468085106383
- 0.7239893617021277
- 0.7251063829787234
- 0.7251595744680851
- 0.7284574468085107
- 0.7279787234042553
- 0.7258510638297873
- 0.7295744680851064
- 0.7259042553191489
- 0.7302659574468086
- 0.7311702127659574
- 0.731063829787234
- 0.7297872340425532
- 0.7295744680851064
- 0.7305851063829787
- 0.7324468085106383
- 0.7310106382978724
- 0.7323936170212766
- 0.7326595744680852
- 0.7337765957446809
- 0.7310106382978724
- 0.7316489361702128
- 0.7311170212765957
- 0.7306382978723405
- 0.7327127659574468
- 0.7304787234042553
- 0.7332446808510639
test_loss_list:
- 3.7798094018300374
- 3.7267993895212808
- 3.586000630060832
- 3.294667921066284
- 2.9470139439900715
- 2.662449607849121
- 2.4803791650136313
- 2.363384739557902
- 2.2552773269017536
- 2.179587092399597
- 2.1310740677515665
- 2.0909328635533653
- 2.045542311668396
- 1.9927469825744628
- 1.9649112733205158
- 1.95770179271698
- 1.9370865694681803
- 1.896521315574646
- 1.857879826227824
- 1.8412047449747722
- 1.8201840941111247
- 1.8310936212539672
- 1.7923212194442748
- 1.7726038376490274
- 1.7646964979171753
- 1.7682698806126913
- 1.734089862505595
- 1.7098290236790974
- 1.7191261625289918
- 1.7214372237523397
- 1.7135942697525024
- 1.7170178031921386
- 1.6786459334691366
- 1.653402338027954
- 1.6567560307184854
- 1.6217765029271443
- 1.5701131184895833
- 1.6185065253575643
- 1.6262971719106039
- 1.5956121587753296
- 1.5930567185084026
- 1.5452950366338094
- 1.512554570833842
- 1.5316976817448933
- 1.5221845610936482
- 1.5085196161270142
- 1.514524073600769
- 1.4611052910486857
- 1.5021223322550457
- 1.463766295115153
- 1.4407774432500204
- 1.4227004226048787
- 1.449688466389974
- 1.4430249945322673
- 1.4313329537709554
- 1.4298753039042156
- 1.4190234883626303
- 1.394718950589498
- 1.410244294802348
- 1.4320200792948405
- 1.3524388885498047
- 1.4043011411031088
- 1.3706486638387043
- 1.4099774758021038
- 1.4052053467432657
- 1.3777260017395019
- 1.3597671540578207
- 1.398883620897929
- 1.3805734300613404
- 1.3554949045181275
- 1.3590942923227947
- 1.3749074745178222
- 1.3709633620580037
- 1.335512351989746
- 1.3494059530893963
- 1.3321198256810507
- 1.3534256474177042
- 1.3160482295354208
- 1.34955913066864
- 1.3048579454421998
- 1.330923598607381
- 1.3007075436909994
- 1.314381848971049
- 1.3022396119435629
- 1.3215273348490397
- 1.3087564500172932
- 1.3224945259094238
- 1.3106931098302206
- 1.3105736287434895
- 1.2894870456059773
- 1.2654064957300821
- 1.2627153905232746
- 1.2907933775583904
- 1.2510522866249085
- 1.2851417303085326
- 1.2320452451705932
- 1.2372460714975992
- 1.2546730518341065
- 1.2162376546859741
- 1.248366334438324
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.56
- 0.581
- 0.619
- 0.0
- 0.635
- 0.648
- 0.665
- 0.677
- 0.667
- 0.0
- 0.0
- 0.704
- 0.681
- 0.0
- 0.713
- 0.0
- 0.0
- 0.733
- 0.735
- 0.0
- 0.0
- 0.0
- 0.756
- 0.769
- 0.0
- 0.0
- 0.748
- 0.0
- 0.765
- 0.758
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.0
- 0.804
- 0.0
- 0.787
- 0.0
- 0.0
- 0.767
- 0.781
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.812
- 0.792
- 0.0
- 0.815
- 0.787
- 0.0
- 0.0
- 0.0
- 0.802
- 0.0
- 0.804
- 0.792
- 0.0
- 0.808
- 0.804
- 0.0
- 0.0
- 0.802
- 0.812
- 0.0
- 0.821
- 0.0
- 0.808
- 0.794
- 0.0
- 0.838
- 0.796
- 0.0
- 0.806
- 0.821
- 0.806
- 0.0
- 0.804
- 0.0
- 0.0
- 0.0
- 0.802
- 0.0
- 0.0
- 0.819
- 0.796
- 0.815
train_loss:
- 1.926
- 2.833
- 2.286
- 2.116
- 1.917
- 1.73
- 1.582
- 1.474
- 1.4
- 1.061
- 1.291
- 1.243
- 1.203
- 0.924
- 0.673
- 1.121
- 1.098
- 0.852
- 0.849
- 0.613
- 0.821
- 1.0
- 0.59
- 0.773
- 0.977
- 0.946
- 0.754
- 0.729
- 0.903
- 1.08
- 0.893
- 1.053
- 0.875
- 0.683
- 0.866
- 0.682
- 0.508
- 0.837
- 0.816
- 0.811
- 0.82
- 0.502
- 0.495
- 0.8
- 0.628
- 0.641
- 0.774
- 0.48
- 0.758
- 0.61
- 0.462
- 0.462
- 0.753
- 0.745
- 0.594
- 0.585
- 0.721
- 0.584
- 0.709
- 0.862
- 0.448
- 0.71
- 0.581
- 0.708
- 0.708
- 0.558
- 0.556
- 0.836
- 0.691
- 0.565
- 0.682
- 0.814
- 0.686
- 0.412
- 0.681
- 0.536
- 0.812
- 0.545
- 0.8
- 0.545
- 0.675
- 0.534
- 0.678
- 0.672
- 0.784
- 0.657
- 0.663
- 0.649
- 0.656
- 0.658
- 0.535
- 0.521
- 0.639
- 0.529
- 0.642
- 0.522
- 0.518
- 0.638
- 0.518
- 0.752
unequal: 0
verbose: 1
