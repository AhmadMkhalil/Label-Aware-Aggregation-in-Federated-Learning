avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03627659574468085
- 0.0973936170212766
- 0.20941489361702129
- 0.3338829787234043
- 0.4050531914893617
- 0.4572340425531915
- 0.4875531914893617
- 0.5174468085106383
- 0.5343085106382979
- 0.5498936170212766
- 0.5641489361702128
- 0.5744148936170212
- 0.5847872340425532
- 0.5947340425531915
- 0.6038297872340426
- 0.611436170212766
- 0.619095744680851
- 0.6213829787234042
- 0.628031914893617
- 0.6343085106382979
- 0.6398404255319149
- 0.6457446808510638
- 0.6488297872340425
- 0.6522872340425532
- 0.6601595744680852
- 0.6622872340425532
- 0.6647340425531915
- 0.6651595744680852
- 0.6696276595744681
- 0.6759042553191489
- 0.6751063829787234
- 0.6776595744680851
- 0.6793617021276596
- 0.6796808510638298
- 0.6825531914893617
- 0.6839893617021277
- 0.6862234042553191
- 0.6876595744680851
- 0.6880851063829787
- 0.6916489361702127
- 0.6926595744680851
- 0.694627659574468
- 0.6963297872340426
- 0.6951063829787234
- 0.6958510638297872
- 0.6992021276595745
- 0.6981382978723404
- 0.6992553191489361
- 0.7013829787234043
- 0.7023936170212766
- 0.7016489361702127
- 0.7042021276595745
- 0.7043617021276596
- 0.7053191489361702
- 0.7087234042553191
- 0.7075
- 0.711063829787234
- 0.7087765957446809
- 0.7106914893617021
- 0.7098404255319148
- 0.7093085106382979
- 0.7114893617021276
- 0.7129787234042553
- 0.7156914893617021
- 0.7124468085106384
- 0.7128723404255319
- 0.7131382978723404
- 0.7156382978723405
- 0.7124468085106384
- 0.7172872340425532
- 0.7173936170212766
- 0.7158510638297872
- 0.7170212765957447
- 0.7172340425531915
- 0.7193617021276596
- 0.7167021276595744
- 0.7182978723404255
- 0.7200531914893618
- 0.7220212765957447
- 0.7204255319148937
- 0.7184574468085106
- 0.7198936170212766
- 0.7224468085106382
- 0.7220212765957447
- 0.7228191489361702
- 0.7241489361702128
- 0.7211170212765957
- 0.7215425531914894
- 0.7247872340425532
- 0.7230319148936171
- 0.7218617021276595
- 0.7249468085106383
- 0.7230319148936171
- 0.7253191489361702
- 0.7256382978723405
- 0.7268085106382979
- 0.7261170212765957
- 0.7252659574468086
- 0.7238829787234042
- 0.7236702127659574
test_loss_list:
- 3.7722237396240232
- 3.6781492296854656
- 3.4576817671457927
- 3.1282157421112062
- 2.8342555300394694
- 2.591708183288574
- 2.4350919087727863
- 2.308359375
- 2.2575960540771485
- 2.1907224400838214
- 2.1342009607950847
- 2.0757120736440022
- 2.0506861114501955
- 2.011849045753479
- 1.975653034845988
- 1.9891933345794677
- 1.9843471097946166
- 1.9253818209966023
- 1.9370463943481446
- 1.8917299254735311
- 1.8649459457397461
- 1.823644406000773
- 1.8450488313039144
- 1.8256517028808594
- 1.8092053508758545
- 1.812561092376709
- 1.7874218034744263
- 1.7619987201690674
- 1.7307080189387003
- 1.7464055760701498
- 1.7220881350835164
- 1.7127462275822958
- 1.6777194658915202
- 1.661339627901713
- 1.6514489682515463
- 1.6730238358179728
- 1.6476842419306437
- 1.6539505275090536
- 1.6298597129185994
- 1.6306436014175416
- 1.6611783329645793
- 1.6152331097920736
- 1.5883710527420043
- 1.5747816483179728
- 1.5742969083786011
- 1.5332156483332315
- 1.5532369756698607
- 1.5673913939793904
- 1.5640737660725912
- 1.54343474706014
- 1.4986040544509889
- 1.5207053407033284
- 1.5012223052978515
- 1.5020795726776124
- 1.5160899273554485
- 1.4989977884292602
- 1.4872269137700398
- 1.4994274123509725
- 1.4677314758300781
- 1.4725056219100952
- 1.4319519297281902
- 1.4276030508677164
- 1.456008342107137
- 1.4422118663787842
- 1.4335568316777547
- 1.4239468161265056
- 1.4054009501139324
- 1.4292255099614461
- 1.4031652514139812
- 1.394334135055542
- 1.4105132246017456
- 1.388651089668274
- 1.432876771291097
- 1.4040250015258788
- 1.438301526705424
- 1.4003178628285726
- 1.4064147265752156
- 1.3824084107081096
- 1.367064398129781
- 1.3807528320948284
- 1.3461714283625286
- 1.3675928147633871
- 1.3353785387674968
- 1.344661421775818
- 1.3143038336435955
- 1.3777432537078858
- 1.337293513615926
- 1.3227107954025268
- 1.346862621307373
- 1.3124055512746176
- 1.318100283940633
- 1.2999768924713135
- 1.3171470228830973
- 1.3009975496927897
- 1.3083035341898601
- 1.3040471156438191
- 1.2813385581970216
- 1.2693429787953694
- 1.256827668348948
- 1.2504604832331339
train_accuracy:
- 0.0
- 0.121
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.571
- 0.0
- 0.598
- 0.619
- 0.646
- 0.0
- 0.0
- 0.0
- 0.696
- 0.0
- 0.0
- 0.688
- 0.681
- 0.0
- 0.729
- 0.729
- 0.692
- 0.71
- 0.0
- 0.0
- 0.708
- 0.719
- 0.0
- 0.781
- 0.0
- 0.0
- 0.0
- 0.75
- 0.744
- 0.0
- 0.0
- 0.796
- 0.0
- 0.0
- 0.75
- 0.0
- 0.75
- 0.76
- 0.0
- 0.798
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.804
- 0.0
- 0.817
- 0.0
- 0.827
- 0.0
- 0.781
- 0.0
- 0.0
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.773
- 0.0
- 0.0
- 0.806
- 0.0
- 0.808
- 0.769
- 0.0
- 0.831
- 0.81
- 0.0
- 0.771
- 0.0
- 0.0
- 0.0
- 0.0
- 0.758
- 0.773
- 0.773
- 0.785
- 0.0
- 0.829
- 0.812
- 0.81
- 0.0
- 0.779
- 0.0
- 0.0
- 0.787
- 0.823
- 0.777
- 0.0
- 0.0
train_loss:
- 1.841
- 1.813
- 1.715
- 1.567
- 2.236
- 1.305
- 1.212
- 0.824
- 1.401
- 1.349
- 1.29
- 0.989
- 1.219
- 1.192
- 0.915
- 1.369
- 1.335
- 0.658
- 1.066
- 0.844
- 0.826
- 0.816
- 1.006
- 0.993
- 0.971
- 0.958
- 0.948
- 0.755
- 0.753
- 0.924
- 0.732
- 0.721
- 0.731
- 0.539
- 0.705
- 0.865
- 0.686
- 0.681
- 0.695
- 0.842
- 1.002
- 0.672
- 0.668
- 0.653
- 0.651
- 0.503
- 0.639
- 0.8
- 0.789
- 0.805
- 0.492
- 0.627
- 0.628
- 0.63
- 0.772
- 0.621
- 0.628
- 0.766
- 0.615
- 0.751
- 0.463
- 0.46
- 0.592
- 0.754
- 0.594
- 0.593
- 0.588
- 0.733
- 0.592
- 0.592
- 0.72
- 0.588
- 0.865
- 0.585
- 0.852
- 0.582
- 0.579
- 0.44
- 0.573
- 0.571
- 0.576
- 0.701
- 0.57
- 0.698
- 0.426
- 0.834
- 0.568
- 0.552
- 0.699
- 0.555
- 0.555
- 0.552
- 0.691
- 0.552
- 0.676
- 0.687
- 0.552
- 0.547
- 0.416
- 0.415
unequal: 0
verbose: 1
