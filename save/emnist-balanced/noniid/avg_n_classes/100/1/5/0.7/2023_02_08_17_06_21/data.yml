avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03877659574468085
- 0.0499468085106383
- 0.09675531914893618
- 0.2049468085106383
- 0.33063829787234045
- 0.4054255319148936
- 0.4427659574468085
- 0.4818085106382979
- 0.5043085106382978
- 0.5201063829787234
- 0.5401063829787234
- 0.5587765957446809
- 0.5658510638297872
- 0.5761170212765957
- 0.5848936170212766
- 0.5937234042553191
- 0.6016489361702128
- 0.6033510638297872
- 0.6088297872340426
- 0.6168085106382979
- 0.6247340425531915
- 0.6287234042553191
- 0.6356382978723404
- 0.6356382978723404
- 0.6396808510638298
- 0.6418085106382979
- 0.6498404255319149
- 0.6524468085106383
- 0.6560106382978723
- 0.6579787234042553
- 0.6632446808510638
- 0.6672872340425532
- 0.6673404255319149
- 0.6722340425531915
- 0.671968085106383
- 0.6724468085106383
- 0.6801063829787234
- 0.6776595744680851
- 0.6816489361702127
- 0.6819148936170213
- 0.6828191489361702
- 0.684468085106383
- 0.6851595744680851
- 0.6863297872340426
- 0.6856382978723404
- 0.689627659574468
- 0.6904787234042553
- 0.6936702127659574
- 0.6891489361702128
- 0.6908510638297872
- 0.6952659574468085
- 0.6988297872340425
- 0.6975531914893617
- 0.699468085106383
- 0.6993085106382979
- 0.7012234042553191
- 0.7012234042553191
- 0.703031914893617
- 0.7038829787234042
- 0.7066489361702127
- 0.7047872340425532
- 0.7080851063829787
- 0.7052659574468085
- 0.7073404255319149
- 0.7103191489361702
- 0.7089893617021277
- 0.7104255319148937
- 0.711968085106383
- 0.711968085106383
- 0.7110106382978724
- 0.7111170212765957
- 0.7128191489361703
- 0.7107978723404256
- 0.7132446808510639
- 0.7141489361702128
- 0.7152659574468085
- 0.7154787234042553
- 0.7168085106382979
- 0.7155851063829787
- 0.7160106382978724
- 0.7145744680851064
- 0.7165957446808511
- 0.7144680851063829
- 0.7185106382978723
- 0.7204787234042553
- 0.719095744680851
- 0.7166489361702127
- 0.7196276595744681
- 0.7176063829787234
- 0.7201063829787234
- 0.7202659574468085
- 0.720531914893617
- 0.7203723404255319
- 0.7206382978723405
- 0.721063829787234
- 0.7213297872340425
- 0.7228191489361702
- 0.7235106382978723
- 0.721968085106383
- 0.7230319148936171
test_loss_list:
- 3.7762645880381265
- 3.730048866271973
- 3.617413501739502
- 3.3684794235229494
- 3.0469574228922527
- 2.7798841508229573
- 2.593788356781006
- 2.4741063117980957
- 2.385273329416911
- 2.3079464435577393
- 2.251668054262797
- 2.2199261379241944
- 2.1772109985351564
- 2.155178074836731
- 2.1379617087046303
- 2.10392440478007
- 2.074525434176127
- 2.062201968828837
- 2.0197498989105225
- 2.0048801501592
- 2.005250894228617
- 2.000613643328349
- 1.985307420094808
- 1.9716669607162476
- 1.947929442723592
- 1.9461332654953003
- 1.922956649462382
- 1.911449942588806
- 1.9062658325831094
- 1.865326099395752
- 1.833353164990743
- 1.840251653989156
- 1.843236362139384
- 1.8411892080307006
- 1.7938822491963704
- 1.7651559686660767
- 1.7769589392344156
- 1.7542506154378255
- 1.7544969050089518
- 1.7190195353825888
- 1.7226450697580973
- 1.7087296183904013
- 1.6946617841720581
- 1.6988558292388916
- 1.6738866662979126
- 1.6856870778401694
- 1.6677550236384073
- 1.6808233944574993
- 1.6219217205047607
- 1.6254308557510375
- 1.639783306121826
- 1.6090835587183634
- 1.592777574857076
- 1.5749671999613444
- 1.6016118224461873
- 1.5969835058848063
- 1.5948943010965984
- 1.5682571268081664
- 1.5901625061035156
- 1.5813086573282877
- 1.5835542408625285
- 1.5226881488164266
- 1.4926465686162314
- 1.4953181330362957
- 1.496200343767802
- 1.4778631480534872
- 1.4701428174972535
- 1.475604232152303
- 1.4537243286768595
- 1.4257649437586466
- 1.4665278053283692
- 1.4676946814854939
- 1.427232756614685
- 1.419019536972046
- 1.4407390880584716
- 1.429041830698649
- 1.4300926764806112
- 1.419444783528646
- 1.3960385672251383
- 1.4066787115732828
- 1.3784718910853069
- 1.3762249485651652
- 1.3913040574391682
- 1.4022878726323447
- 1.3966943168640136
- 1.4274869505564372
- 1.3961298513412475
- 1.39346479733785
- 1.3611413017908731
- 1.3863189935684204
- 1.364810169537862
- 1.3823456112543742
- 1.3818995062510173
- 1.4078016392389934
- 1.385021554629008
- 1.3909204896291096
- 1.4167806990941365
- 1.4246206172307332
- 1.3800665696461996
- 1.3494946479797363
train_accuracy:
- 0.044
- 0.06
- 0.127
- 0.254
- 0.344
- 0.0
- 0.0
- 0.531
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.652
- 0.0
- 0.0
- 0.725
- 0.69
- 0.731
- 0.0
- 0.698
- 0.0
- 0.0
- 0.725
- 0.0
- 0.0
- 0.0
- 0.729
- 0.0
- 0.719
- 0.758
- 0.731
- 0.792
- 0.737
- 0.0
- 0.765
- 0.806
- 0.0
- 0.775
- 0.0
- 0.0
- 0.775
- 0.777
- 0.0
- 0.775
- 0.0
- 0.771
- 0.821
- 0.0
- 0.0
- 0.802
- 0.825
- 0.0
- 0.0
- 0.806
- 0.796
- 0.0
- 0.0
- 0.0
- 0.804
- 0.0
- 0.792
- 0.0
- 0.808
- 0.79
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.0
- 0.806
- 0.0
- 0.817
- 0.0
- 0.8
- 0.794
- 0.827
- 0.0
- 0.815
- 0.0
- 0.0
- 0.815
- 0.821
- 0.0
- 0.812
- 0.823
- 0.81
- 0.0
- 0.0
- 0.0
- 0.827
- 0.835
- 0.825
- 0.0
- 0.815
- 0.0
- 0.835
- 0.0
- 0.0
train_loss:
- 2.336
- 2.333
- 2.285
- 2.143
- 1.54
- 1.399
- 1.297
- 1.565
- 1.167
- 0.823
- 1.37
- 1.332
- 1.024
- 1.25
- 1.224
- 1.205
- 0.944
- 1.141
- 0.918
- 0.907
- 1.094
- 1.092
- 1.273
- 1.056
- 0.83
- 0.811
- 1.021
- 0.991
- 0.978
- 0.786
- 0.781
- 0.952
- 0.95
- 0.936
- 0.773
- 0.572
- 0.909
- 0.73
- 0.714
- 0.722
- 0.71
- 0.703
- 0.697
- 0.857
- 0.679
- 0.852
- 0.857
- 0.831
- 0.523
- 0.67
- 0.822
- 0.671
- 0.661
- 0.671
- 0.809
- 0.801
- 0.81
- 0.642
- 0.799
- 0.792
- 0.782
- 0.634
- 0.485
- 0.624
- 0.627
- 0.621
- 0.623
- 0.612
- 0.608
- 0.454
- 0.753
- 0.743
- 0.456
- 0.602
- 0.746
- 0.739
- 0.739
- 0.596
- 0.603
- 0.587
- 0.451
- 0.582
- 0.726
- 0.719
- 0.709
- 0.855
- 0.57
- 0.718
- 0.584
- 0.706
- 0.565
- 0.699
- 0.712
- 0.836
- 0.694
- 0.692
- 0.83
- 0.821
- 0.706
- 0.56
unequal: 0
verbose: 1
