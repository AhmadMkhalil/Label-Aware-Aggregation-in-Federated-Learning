avg_train_accuracy: 0.252
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04537234042553191
- 0.15308510638297873
- 0.2073404255319149
- 0.23335106382978724
- 0.2503723404255319
- 0.26728723404255317
- 0.25930851063829785
- 0.2776063829787234
- 0.2746276595744681
- 0.28835106382978726
- 0.2875531914893617
- 0.2860106382978723
- 0.2976063829787234
- 0.3053723404255319
- 0.3081382978723404
- 0.31718085106382976
- 0.32622340425531915
- 0.31893617021276593
- 0.32611702127659575
- 0.3322340425531915
- 0.3313829787234043
- 0.3170212765957447
- 0.32648936170212767
- 0.3251063829787234
- 0.34414893617021275
- 0.32101063829787235
- 0.3414893617021277
- 0.33601063829787237
- 0.34117021276595744
- 0.3659574468085106
- 0.34845744680851065
- 0.35771276595744683
- 0.36436170212765956
- 0.37329787234042555
- 0.35340425531914893
- 0.34
- 0.36579787234042555
- 0.2731914893617021
- 0.35377659574468084
- 0.3475531914893617
- 0.3721276595744681
- 0.3756914893617021
- 0.2693617021276596
- 0.34829787234042553
- 0.355531914893617
- 0.35345744680851066
- 0.39797872340425533
- 0.39909574468085107
- 0.40356382978723404
- 0.38111702127659575
- 0.4048404255319149
- 0.3964893617021277
- 0.36664893617021277
- 0.3827127659574468
- 0.3893617021276596
- 0.3829255319148936
- 0.38601063829787235
- 0.3871276595744681
- 0.425
- 0.41771276595744683
- 0.43186170212765956
- 0.37553191489361704
- 0.3745212765957447
- 0.4355851063829787
- 0.3997340425531915
- 0.4200531914893617
- 0.3946276595744681
- 0.43457446808510636
- 0.40180851063829787
- 0.40095744680851064
- 0.4178723404255319
- 0.4156382978723404
- 0.41127659574468084
- 0.40606382978723404
- 0.45617021276595743
- 0.38680851063829785
- 0.4047340425531915
- 0.4006382978723404
- 0.39574468085106385
- 0.41308510638297874
- 0.4218085106382979
- 0.44824468085106384
- 0.4486702127659574
- 0.4178723404255319
- 0.3638297872340426
- 0.4102127659574468
- 0.43042553191489363
- 0.3846276595744681
- 0.43670212765957445
- 0.43159574468085105
- 0.45
- 0.4128191489361702
- 0.38420212765957445
- 0.4779255319148936
- 0.4470212765957447
- 0.46452127659574466
- 0.4198404255319149
- 0.4220744680851064
- 0.4296808510638298
- 0.3795212765957447
test_loss_list:
- 4.040707031885783
- 4.170107259750366
- 4.209490483601888
- 3.9441505527496337
- 3.60787189801534
- 3.638906291325887
- 3.5575793615976967
- 4.0429014968872075
- 3.5359733072916666
- 3.3675967915852865
- 3.5322561009724933
- 3.142148504257202
- 3.5436395994822183
- 3.204832077026367
- 3.6403049786885577
- 3.0397453689575196
- 3.1429036299387616
- 3.4080864270528157
- 3.359975226720174
- 3.396775884628296
- 3.444957892100016
- 3.5467353884379067
- 3.8046181138356525
- 3.736071786880493
- 3.148316583633423
- 3.1897427304585775
- 3.7864892578125
- 2.911040360132853
- 3.273679132461548
- 2.9199156824747723
- 3.2379269790649414
- 2.7691550636291504
- 2.7913988812764488
- 2.7912882550557456
- 3.101637331644694
- 3.511471455891927
- 2.9233504486083985
- 2.728010444641113
- 2.830825446446737
- 3.015204248428345
- 2.9658164151509605
- 2.8534898471832277
- 3.1900689442952475
- 3.4841882864634197
- 2.895097335179647
- 3.4873804982503254
- 2.45193102200826
- 2.5977793089548746
- 2.5836465708414713
- 2.81372789700826
- 2.504983828862508
- 2.5197444279988606
- 3.3407938575744627
- 2.6958178265889488
- 2.5733423296610516
- 2.80235045115153
- 2.775281165440877
- 2.900310920079549
- 2.4063337898254393
- 2.4673612626393635
- 2.4173396333058674
- 2.7865471522013348
- 2.738332624435425
- 2.430767911275228
- 2.6400447591145833
- 2.3340693680445352
- 2.7924183432261147
- 2.261622764269511
- 2.7726068909962973
- 2.653042125701904
- 2.6853829701741536
- 2.354997671445211
- 2.6943602498372394
- 2.681364091237386
- 2.2131412982940675
- 2.6900969250996907
- 2.527832374572754
- 2.763845478693644
- 2.5552540524800618
- 2.5493085384368896
- 2.399848362604777
- 2.169888841311137
- 2.1333693710962933
- 2.5268204498291014
- 2.375126609802246
- 2.2926755650838215
- 2.411734790802002
- 3.182027063369751
- 2.201489887237549
- 2.4202356974283856
- 2.24164075533549
- 2.553595390319824
- 2.8594076283772787
- 2.014815150896708
- 2.3002956517537436
- 2.0293118572235107
- 2.4250814135869345
- 2.3884413035710654
- 2.454387655258179
- 2.4991357199350994
train_accuracy:
- 0.0
- 0.404
- 0.0
- 0.0
- 0.65
- 0.0
- 0.654
- 0.673
- 0.679
- 0.006
- 0.0
- 0.717
- 0.754
- 0.01
- 0.0
- 0.002
- 0.0
- 0.0
- 0.1
- 0.0
- 0.779
- 0.0
- 0.815
- 0.0
- 0.783
- 0.769
- 0.0
- 0.0
- 0.008
- 0.083
- 0.0
- 0.0
- 0.0
- 0.01
- 0.0
- 0.833
- 0.004
- 0.0
- 0.827
- 0.0
- 0.819
- 0.002
- 0.54
- 0.004
- 0.0
- 0.848
- 0.062
- 0.0
- 0.075
- 0.012
- 0.004
- 0.8
- 0.002
- 0.0
- 0.0
- 0.852
- 0.854
- 0.002
- 0.008
- 0.806
- 0.142
- 0.092
- 0.0
- 0.002
- 0.0
- 0.006
- 0.86
- 0.09
- 0.846
- 0.85
- 0.05
- 0.0
- 0.0
- 0.856
- 0.515
- 0.0
- 0.0
- 0.869
- 0.856
- 0.844
- 0.852
- 0.248
- 0.002
- 0.858
- 0.24
- 0.006
- 0.004
- 0.867
- 0.0
- 0.0
- 0.0
- 0.042
- 0.029
- 0.006
- 0.004
- 0.844
- 0.0
- 0.0
- 0.865
- 0.252
train_loss:
- 1.883
- 1.48
- 1.525
- 1.327
- 1.345
- 1.207
- 1.192
- 1.256
- 1.073
- 0.9
- 1.051
- 0.872
- 0.94
- 0.833
- 0.899
- 0.786
- 0.756
- 0.89
- 0.864
- 0.848
- 0.829
- 0.918
- 0.86
- 0.836
- 0.801
- 0.757
- 0.808
- 0.63
- 0.692
- 0.632
- 0.76
- 0.602
- 0.645
- 0.608
- 0.637
- 0.738
- 0.643
- 0.515
- 0.545
- 0.625
- 0.601
- 0.619
- 0.436
- 0.756
- 0.582
- 0.66
- 0.625
- 0.495
- 0.559
- 0.565
- 0.465
- 0.488
- 0.628
- 0.637
- 0.47
- 0.544
- 0.528
- 0.531
- 0.543
- 0.528
- 0.454
- 0.604
- 0.51
- 0.429
- 0.623
- 0.443
- 0.5
- 0.53
- 0.501
- 0.525
- 0.518
- 0.521
- 0.569
- 0.509
- 0.442
- 0.5
- 0.491
- 0.573
- 0.497
- 0.568
- 0.484
- 0.494
- 0.44
- 0.56
- 0.416
- 0.419
- 0.565
- 0.601
- 0.417
- 0.443
- 0.465
- 0.468
- 0.556
- 0.439
- 0.459
- 0.421
- 0.528
- 0.451
- 0.453
- 0.396
unequal: 0
verbose: 1
