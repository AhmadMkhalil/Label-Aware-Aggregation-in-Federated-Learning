avg_train_accuracy: 0.006
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06670212765957446
- 0.08984042553191489
- 0.17563829787234042
- 0.22803191489361702
- 0.20574468085106384
- 0.25042553191489364
- 0.27095744680851064
- 0.26654255319148934
- 0.27409574468085107
- 0.29271276595744683
- 0.18202127659574469
- 0.2951063829787234
- 0.31505319148936173
- 0.3246276595744681
- 0.32441489361702125
- 0.3207978723404255
- 0.3144148936170213
- 0.31696808510638297
- 0.3254787234042553
- 0.32638297872340427
- 0.3223404255319149
- 0.33654255319148935
- 0.3346808510638298
- 0.3472340425531915
- 0.33095744680851064
- 0.36361702127659573
- 0.35936170212765955
- 0.3459042553191489
- 0.36
- 0.35132978723404257
- 0.346968085106383
- 0.3671808510638298
- 0.35877659574468085
- 0.3646808510638298
- 0.3773936170212766
- 0.37127659574468086
- 0.38643617021276594
- 0.3690425531914894
- 0.4056382978723404
- 0.37632978723404253
- 0.3759574468085106
- 0.40861702127659577
- 0.39398936170212767
- 0.3548936170212766
- 0.35090425531914893
- 0.3628723404255319
- 0.39287234042553193
- 0.3627127659574468
- 0.4172872340425532
- 0.40324468085106385
- 0.3898404255319149
- 0.3454255319148936
- 0.37824468085106383
- 0.3826063829787234
- 0.3989893617021277
- 0.41154255319148936
- 0.37627659574468086
- 0.41069148936170213
- 0.4007978723404255
- 0.37957446808510636
- 0.4272340425531915
- 0.43696808510638296
- 0.39787234042553193
- 0.4200531914893617
- 0.42186170212765955
- 0.46308510638297873
- 0.3897340425531915
- 0.4170744680851064
- 0.41297872340425534
- 0.42351063829787233
- 0.4262234042553191
- 0.42425531914893616
- 0.46106382978723404
- 0.44132978723404254
- 0.40037234042553194
- 0.4748404255319149
- 0.44898936170212767
- 0.42909574468085104
- 0.46819148936170213
- 0.42781914893617023
- 0.41771276595744683
- 0.4461702127659574
- 0.375
- 0.4031382978723404
- 0.45563829787234045
- 0.4725531914893617
- 0.3873936170212766
- 0.4656914893617021
- 0.4302659574468085
- 0.4318085106382979
- 0.39601063829787236
- 0.4779255319148936
- 0.4313297872340425
- 0.4077659574468085
- 0.4441489361702128
- 0.3906914893617021
- 0.4301595744680851
- 0.46
- 0.4520744680851064
- 0.4729255319148936
test_loss_list:
- 3.8432172266642253
- 4.271815026601155
- 3.79793111483256
- 3.660715602238973
- 3.358877363204956
- 3.6342565472920736
- 3.4613218784332274
- 3.5901758925120038
- 3.2647714042663574
- 3.2966934299468993
- 3.494569876988729
- 3.4893398412068684
- 3.312401940027873
- 3.192067492802938
- 3.067272504170736
- 3.360090668996175
- 3.3410387070973715
- 3.3976696332295737
- 3.180166524251302
- 2.884403095245361
- 3.170414606730143
- 3.248338041305542
- 3.135925016403198
- 2.8133130582173664
- 3.9450992997487386
- 2.8304377015431723
- 2.8831992149353027
- 3.6933838303883872
- 2.70528582572937
- 2.742396586736043
- 3.075132595698039
- 2.668167463938395
- 2.8932114187876383
- 2.9766275278727212
- 2.581296609242757
- 3.03852814356486
- 2.6773437881469726
- 3.0006668090820314
- 2.4808059056599934
- 2.8014114093780518
- 2.980712251663208
- 2.407537349065145
- 2.443697945276896
- 3.2405786418914797
- 3.2956515471140544
- 3.0944675413767495
- 2.4606336386998495
- 2.850905090967814
- 2.3290127913157144
- 2.3950379419326784
- 2.56677672068278
- 2.3943746185302732
- 2.475329189300537
- 2.6622201220194497
- 2.4642448647816977
- 2.284274476369222
- 2.6664532597859703
- 2.3420386854807536
- 2.3571238708496094
- 3.0857876904805503
- 2.184920935630798
- 2.0869317070643105
- 2.582259635925293
- 2.3155823008219403
- 2.4358180316289264
- 2.1277142477035524
- 2.6656834093729653
- 2.501708505948385
- 2.480342224438985
- 2.461230500539144
- 2.4459406836827595
- 2.413707922299703
- 2.194001331329346
- 2.493652679125468
- 3.033973913192749
- 2.199009386698405
- 2.323447782198588
- 2.5521293036142985
- 2.1262513828277587
- 2.4387862316767372
- 2.749790817896525
- 2.1760788790384926
- 2.4467523829142253
- 2.3607829205195108
- 1.9972023455301922
- 1.893898852666219
- 2.7128789138793947
- 1.9897878185908
- 2.414675801595052
- 2.2791065152486167
- 2.78240790049235
- 2.061329976717631
- 2.3455743106206257
- 2.635718158086141
- 2.2567646312713623
- 2.775459718704224
- 2.1641146532694497
- 1.9822767925262452
- 2.131554431915283
- 1.9790840609868368
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.558
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.0
- 0.025
- 0.0
- 0.0
- 0.0
- 0.785
- 0.006
- 0.81
- 0.044
- 0.0
- 0.0
- 0.0
- 0.004
- 0.829
- 0.023
- 0.004
- 0.035
- 0.004
- 0.85
- 0.004
- 0.848
- 0.006
- 0.017
- 0.844
- 0.0
- 0.04
- 0.854
- 0.858
- 0.856
- 0.002
- 0.84
- 0.004
- 0.008
- 0.002
- 0.169
- 0.019
- 0.869
- 0.002
- 0.002
- 0.006
- 0.01
- 0.031
- 0.004
- 0.0
- 0.021
- 0.89
- 0.84
- 0.015
- 0.01
- 0.0
- 0.844
- 0.0
- 0.0
- 0.0
- 0.015
- 0.002
- 0.0
- 0.85
- 0.065
- 0.029
- 0.044
- 0.0
- 0.885
- 0.037
- 0.0
- 0.175
- 0.0
- 0.006
- 0.108
- 0.902
- 0.0
- 0.021
- 0.012
- 0.86
- 0.006
- 0.004
- 0.89
- 0.887
- 0.883
- 0.11
- 0.0
- 0.019
- 0.006
train_loss:
- 1.778
- 0.913
- 1.536
- 1.375
- 1.017
- 1.107
- 1.035
- 0.992
- 0.825
- 0.719
- 0.519
- 0.882
- 0.851
- 0.656
- 0.639
- 0.779
- 0.865
- 0.753
- 0.827
- 0.666
- 0.772
- 0.715
- 0.714
- 0.567
- 0.792
- 0.623
- 0.546
- 0.767
- 0.602
- 0.581
- 0.642
- 0.567
- 0.664
- 0.661
- 0.527
- 0.614
- 0.592
- 0.564
- 0.485
- 0.606
- 0.584
- 0.47
- 0.504
- 0.692
- 0.699
- 0.652
- 0.514
- 0.583
- 0.482
- 0.441
- 0.506
- 0.387
- 0.599
- 0.569
- 0.539
- 0.471
- 0.531
- 0.536
- 0.366
- 0.626
- 0.434
- 0.427
- 0.494
- 0.533
- 0.503
- 0.406
- 0.527
- 0.526
- 0.485
- 0.469
- 0.496
- 0.48
- 0.38
- 0.485
- 0.55
- 0.387
- 0.392
- 0.456
- 0.358
- 0.443
- 0.523
- 0.422
- 0.282
- 0.531
- 0.392
- 0.376
- 0.565
- 0.422
- 0.428
- 0.458
- 0.553
- 0.399
- 0.453
- 0.516
- 0.479
- 0.502
- 0.328
- 0.362
- 0.419
- 0.362
unequal: 0
verbose: 1
