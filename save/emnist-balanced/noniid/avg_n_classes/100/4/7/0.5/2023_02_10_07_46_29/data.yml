avg_train_accuracy: 0.248
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03574468085106383
- 0.09659574468085107
- 0.13026595744680852
- 0.16537234042553192
- 0.20420212765957446
- 0.23452127659574468
- 0.2595212765957447
- 0.2843617021276596
- 0.2851595744680851
- 0.29186170212765955
- 0.2895744680851064
- 0.286968085106383
- 0.2948936170212766
- 0.29659574468085104
- 0.29861702127659573
- 0.3081382978723404
- 0.3103723404255319
- 0.31622340425531914
- 0.33904255319148935
- 0.31813829787234044
- 0.3316489361702128
- 0.3384042553191489
- 0.3248404255319149
- 0.3324468085106383
- 0.33882978723404256
- 0.2522872340425532
- 0.344468085106383
- 0.32941489361702125
- 0.3267553191489362
- 0.3448404255319149
- 0.35601063829787233
- 0.37659574468085105
- 0.35606382978723405
- 0.35845744680851066
- 0.3567021276595745
- 0.3417021276595745
- 0.36606382978723406
- 0.34132978723404256
- 0.3607446808510638
- 0.3651595744680851
- 0.35085106382978726
- 0.3819148936170213
- 0.3674468085106383
- 0.38340425531914896
- 0.3801595744680851
- 0.3381914893617021
- 0.39845744680851064
- 0.37946808510638297
- 0.39159574468085107
- 0.363936170212766
- 0.378563829787234
- 0.35164893617021276
- 0.3844148936170213
- 0.3730851063829787
- 0.3875
- 0.3832978723404255
- 0.37824468085106383
- 0.4173936170212766
- 0.3921276595744681
- 0.37882978723404254
- 0.4078191489361702
- 0.3797340425531915
- 0.4275
- 0.3544148936170213
- 0.41638297872340424
- 0.35877659574468085
- 0.4149468085106383
- 0.37356382978723407
- 0.4123936170212766
- 0.39132978723404255
- 0.3906914893617021
- 0.428936170212766
- 0.44835106382978723
- 0.39361702127659576
- 0.3906914893617021
- 0.39797872340425533
- 0.4303723404255319
- 0.40622340425531916
- 0.37303191489361703
- 0.42446808510638295
- 0.41962765957446807
- 0.3971276595744681
- 0.3803723404255319
- 0.38553191489361704
- 0.42388297872340425
- 0.39441489361702126
- 0.43356382978723407
- 0.44840425531914896
- 0.4048936170212766
- 0.4379787234042553
- 0.4487765957446809
- 0.4478191489361702
- 0.4165957446808511
- 0.4
- 0.4290425531914894
- 0.44882978723404254
- 0.42611702127659573
- 0.4399468085106383
- 0.43111702127659574
- 0.48329787234042554
test_loss_list:
- 3.892854159673055
- 4.342825520833333
- 4.474148610432943
- 3.775007562637329
- 3.440026419957479
- 3.4323215738932293
- 3.4560615666707357
- 3.5718861293792723
- 3.265604419708252
- 3.844222625096639
- 3.122514019012451
- 3.2059581025441486
- 3.0032320499420164
- 3.6055810038248697
- 3.181430966059367
- 3.098817672729492
- 3.0554960060119627
- 3.2009259859720864
- 2.9833927090962726
- 3.3870253054300945
- 2.9673559951782225
- 2.8441274611155194
- 3.447880744934082
- 3.6621056238810223
- 2.9660292275746665
- 3.0351644865671794
- 2.903025566736857
- 3.367188164393107
- 3.092132705052694
- 3.0863266086578367
- 3.0410829544067384
- 2.7205051390329995
- 2.8481094868977865
- 3.0730430984497072
- 2.8992043368021645
- 3.1260893058776857
- 2.858681011199951
- 3.047761017481486
- 2.9908311653137205
- 2.6102952194213866
- 3.59236146291097
- 2.5932391103108725
- 3.2334397315979
- 2.5529577509562174
- 3.060124390920003
- 2.541987867355347
- 2.540737279256185
- 2.9062947432200112
- 2.7730704243977864
- 3.1899136098225913
- 2.50362509727478
- 2.9021477603912356
- 2.6008485317230225
- 2.896006415685018
- 2.4095335642496747
- 2.6925266361236573
- 2.190286095937093
- 2.2465009609858195
- 2.70643967628479
- 3.142913341522217
- 2.7328766632080077
- 2.8963250096639
- 2.374048703511556
- 3.3463524754842124
- 2.26793759504954
- 3.361087325414022
- 2.4513457266489667
- 2.8551028029123944
- 2.303930638631185
- 2.439968023300171
- 2.638506018320719
- 1.9915195671717325
- 2.1913974984486897
- 2.625927127202352
- 2.56866418838501
- 2.585419413248698
- 2.212577511469523
- 2.5079184563954673
- 2.966098197301229
- 2.342087279955546
- 2.4611771281560264
- 2.5867481581370035
- 3.0797255516052244
- 3.215538984934489
- 2.3639257955551147
- 2.652045710881551
- 2.269626471201579
- 2.338104999860128
- 2.6437114397684733
- 2.243650204340617
- 2.1732767152786256
- 2.213840961456299
- 2.295442644755046
- 2.512565631866455
- 2.3473817984263103
- 2.3671086120605467
- 2.3222255166371664
- 2.2140690676371255
- 2.1528029807408653
- 1.8178538417816161
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.513
- 0.0
- 0.642
- 0.681
- 0.0
- 0.74
- 0.0
- 0.0
- 0.006
- 0.0
- 0.004
- 0.004
- 0.008
- 0.006
- 0.0
- 0.029
- 0.004
- 0.133
- 0.792
- 0.004
- 0.002
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.821
- 0.831
- 0.002
- 0.802
- 0.0
- 0.0
- 0.01
- 0.0
- 0.835
- 0.844
- 0.002
- 0.0
- 0.081
- 0.0
- 0.846
- 0.0
- 0.842
- 0.002
- 0.002
- 0.002
- 0.004
- 0.842
- 0.0
- 0.004
- 0.854
- 0.002
- 0.856
- 0.863
- 0.0
- 0.0
- 0.856
- 0.0
- 0.852
- 0.0
- 0.85
- 0.856
- 0.0
- 0.015
- 0.002
- 0.846
- 0.002
- 0.0
- 0.004
- 0.021
- 0.0
- 0.865
- 0.0
- 0.002
- 0.86
- 0.023
- 0.865
- 0.002
- 0.025
- 0.215
- 0.0
- 0.0
- 0.004
- 0.0
- 0.0
- 0.052
- 0.844
- 0.848
- 0.0
- 0.858
- 0.023
- 0.0
- 0.248
train_loss:
- 2.023
- 1.845
- 1.585
- 1.117
- 1.067
- 0.986
- 1.068
- 1.063
- 1.1
- 1.196
- 0.829
- 0.797
- 0.734
- 0.904
- 0.893
- 0.722
- 0.679
- 0.803
- 0.673
- 0.784
- 0.824
- 0.63
- 0.777
- 0.866
- 0.644
- 0.5
- 0.618
- 0.826
- 0.737
- 0.709
- 0.681
- 0.571
- 0.681
- 0.656
- 0.667
- 0.666
- 0.646
- 0.658
- 0.623
- 0.575
- 0.743
- 0.639
- 0.614
- 0.532
- 0.591
- 0.411
- 0.485
- 0.606
- 0.565
- 0.676
- 0.531
- 0.6
- 0.501
- 0.577
- 0.485
- 0.554
- 0.373
- 0.469
- 0.554
- 0.626
- 0.522
- 0.56
- 0.451
- 0.653
- 0.455
- 0.609
- 0.475
- 0.531
- 0.447
- 0.439
- 0.513
- 0.382
- 0.429
- 0.522
- 0.542
- 0.521
- 0.446
- 0.518
- 0.592
- 0.446
- 0.433
- 0.5
- 0.581
- 0.566
- 0.456
- 0.49
- 0.427
- 0.408
- 0.476
- 0.416
- 0.409
- 0.398
- 0.427
- 0.482
- 0.491
- 0.395
- 0.473
- 0.396
- 0.382
- 0.315
unequal: 0
verbose: 1
