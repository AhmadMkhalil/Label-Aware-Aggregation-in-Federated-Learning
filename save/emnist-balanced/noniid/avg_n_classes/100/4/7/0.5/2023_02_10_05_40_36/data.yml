avg_train_accuracy: 0.012
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06521276595744681
- 0.1676063829787234
- 0.22638297872340427
- 0.2377127659574468
- 0.25765957446808513
- 0.27617021276595743
- 0.28462765957446806
- 0.2782978723404255
- 0.3046276595744681
- 0.1327659574468085
- 0.3052659574468085
- 0.31196808510638296
- 0.3255851063829787
- 0.30659574468085105
- 0.328031914893617
- 0.1773404255319149
- 0.3198936170212766
- 0.333031914893617
- 0.31930851063829785
- 0.3414893617021277
- 0.3586170212765957
- 0.33191489361702126
- 0.32904255319148934
- 0.34117021276595744
- 0.19196808510638297
- 0.33787234042553194
- 0.34622340425531917
- 0.3595744680851064
- 0.3672340425531915
- 0.3604787234042553
- 0.3632446808510638
- 0.37292553191489364
- 0.3576063829787234
- 0.35260638297872343
- 0.37
- 0.3558510638297872
- 0.3127659574468085
- 0.38122340425531914
- 0.39106382978723403
- 0.3638297872340426
- 0.3718085106382979
- 0.3975
- 0.35914893617021276
- 0.31436170212765957
- 0.3773404255319149
- 0.38643617021276594
- 0.3968617021276596
- 0.4032978723404255
- 0.37696808510638297
- 0.3815425531914894
- 0.3658510638297872
- 0.373936170212766
- 0.4003191489361702
- 0.3903723404255319
- 0.38590425531914896
- 0.39952127659574466
- 0.38680851063829785
- 0.41452127659574467
- 0.37893617021276593
- 0.3646808510638298
- 0.4106382978723404
- 0.3943617021276596
- 0.38978723404255317
- 0.420531914893617
- 0.39872340425531916
- 0.39180851063829786
- 0.4093617021276596
- 0.426436170212766
- 0.3951063829787234
- 0.4125531914893617
- 0.34606382978723405
- 0.37377659574468086
- 0.4325
- 0.3971276595744681
- 0.43164893617021277
- 0.44101063829787235
- 0.415531914893617
- 0.41095744680851065
- 0.4150531914893617
- 0.43292553191489364
- 0.4143085106382979
- 0.42377659574468085
- 0.4301595744680851
- 0.4198936170212766
- 0.4548936170212766
- 0.4002127659574468
- 0.40414893617021275
- 0.3937765957446808
- 0.4757446808510638
- 0.451968085106383
- 0.43446808510638296
- 0.42617021276595746
- 0.45606382978723403
- 0.3917553191489362
- 0.4321276595744681
- 0.3876063829787234
- 0.4169148936170213
- 0.4226595744680851
- 0.39659574468085107
- 0.45340425531914896
test_loss_list:
- 3.9708008511861164
- 4.082464536031087
- 3.8833249251047772
- 3.6370582803090414
- 3.617421900431315
- 3.2398688920338947
- 3.2295170911153157
- 3.2217982482910155
- 3.244380235671997
- 3.388982359568278
- 3.032542746861776
- 3.0346055444081625
- 3.0568412208557127
- 3.2915701770782473
- 3.4985421562194823
- 3.3199449729919435
- 3.059848461151123
- 2.7370854028066
- 3.263354450861613
- 2.819709078470866
- 2.7667329279581705
- 2.8618622779846192
- 3.0460048357645673
- 3.1071360079447428
- 3.667175614039103
- 2.9481765460968017
- 3.0594855086008708
- 2.6232372283935548
- 2.6381839752197265
- 2.6633487860361735
- 2.678660961786906
- 2.4969563579559324
- 2.839658120473226
- 2.909716707865397
- 2.7269457562764488
- 3.4305924479166667
- 2.575647258758545
- 2.5271250438690185
- 2.508384943008423
- 2.7801072851816815
- 2.723658192952474
- 2.4576123587290444
- 3.5030075200398763
- 2.5896834246317546
- 2.504808594385783
- 2.7375728289286294
- 2.3561076513926187
- 2.4081256357828775
- 2.6081018384297687
- 2.423890857696533
- 3.094184675216675
- 2.6841766103108724
- 2.3005180740356446
- 2.647529598871867
- 2.783350772857666
- 2.613624016443888
- 2.6110245482126873
- 2.2985026597976685
- 2.7650490379333497
- 2.886903527577718
- 2.2557358280817668
- 2.601223570505778
- 2.496274538040161
- 2.293090376853943
- 2.5729488945007324
- 2.6378955682118734
- 2.5325807348887124
- 2.2811199855804443
- 2.478445660273234
- 2.4143588876724245
- 2.341207701365153
- 3.0863879489898682
- 2.1839854272206622
- 2.4416477060317994
- 2.197297690709432
- 2.139088570276896
- 2.4066520516077676
- 2.485168520609538
- 2.451149541536967
- 2.0823688586552938
- 2.597239538828532
- 2.265203760464986
- 2.140280145009359
- 2.3783432610829673
- 2.0140644884109498
- 2.284238141377767
- 2.292493569056193
- 2.9420288022359213
- 1.8701236216227213
- 2.063782493273417
- 2.3152442502975465
- 2.188643569946289
- 1.9734541273117066
- 2.915594873428345
- 2.287213756243388
- 2.2162124729156494
- 2.290952083269755
- 2.312621374130249
- 2.271376640001933
- 1.9151122283935547
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.594
- 0.0
- 0.002
- 0.002
- 0.0
- 0.715
- 0.0
- 0.719
- 0.0
- 0.019
- 0.0
- 0.0
- 0.11
- 0.0
- 0.0
- 0.0
- 0.16
- 0.037
- 0.0
- 0.802
- 0.023
- 0.337
- 0.0
- 0.0
- 0.035
- 0.023
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.823
- 0.008
- 0.0
- 0.002
- 0.0
- 0.867
- 0.838
- 0.0
- 0.858
- 0.033
- 0.033
- 0.838
- 0.0
- 0.0
- 0.019
- 0.844
- 0.89
- 0.881
- 0.015
- 0.006
- 0.892
- 0.004
- 0.0
- 0.848
- 0.879
- 0.002
- 0.863
- 0.004
- 0.894
- 0.0
- 0.004
- 0.008
- 0.01
- 0.875
- 0.0
- 0.873
- 0.365
- 0.863
- 0.002
- 0.008
- 0.019
- 0.012
- 0.871
- 0.004
- 0.052
- 0.017
- 0.867
- 0.006
- 0.048
- 0.0
- 0.0
- 0.025
- 0.0
- 0.91
- 0.092
- 0.081
- 0.021
- 0.908
- 0.008
- 0.002
- 0.048
- 0.752
- 0.008
- 0.881
- 0.725
- 0.012
train_loss:
- 2.299
- 1.767
- 1.555
- 1.325
- 1.191
- 0.928
- 0.884
- 0.886
- 0.947
- 0.682
- 0.719
- 0.705
- 0.857
- 0.869
- 0.934
- 0.582
- 0.898
- 0.716
- 0.817
- 0.646
- 0.634
- 0.612
- 0.772
- 0.679
- 0.49
- 0.798
- 0.701
- 0.585
- 0.59
- 0.533
- 0.553
- 0.585
- 0.646
- 0.66
- 0.661
- 0.709
- 0.462
- 0.517
- 0.505
- 0.608
- 0.595
- 0.491
- 0.659
- 0.399
- 0.52
- 0.572
- 0.512
- 0.478
- 0.589
- 0.491
- 0.607
- 0.562
- 0.497
- 0.529
- 0.528
- 0.52
- 0.55
- 0.468
- 0.541
- 0.613
- 0.422
- 0.541
- 0.541
- 0.415
- 0.5
- 0.502
- 0.478
- 0.427
- 0.503
- 0.52
- 0.354
- 0.587
- 0.425
- 0.514
- 0.43
- 0.391
- 0.501
- 0.482
- 0.47
- 0.435
- 0.468
- 0.495
- 0.394
- 0.447
- 0.397
- 0.349
- 0.289
- 0.545
- 0.41
- 0.397
- 0.435
- 0.486
- 0.402
- 0.483
- 0.448
- 0.345
- 0.459
- 0.427
- 0.292
- 0.402
unequal: 0
verbose: 1
