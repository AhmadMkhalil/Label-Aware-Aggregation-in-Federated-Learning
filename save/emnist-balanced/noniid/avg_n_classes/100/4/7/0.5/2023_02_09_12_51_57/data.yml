avg_train_accuracy: 0.035
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04978723404255319
- 0.07111702127659575
- 0.1302127659574468
- 0.1923936170212766
- 0.23659574468085107
- 0.2429255319148936
- 0.2573936170212766
- 0.2720744680851064
- 0.26563829787234045
- 0.275531914893617
- 0.18058510638297873
- 0.28638297872340424
- 0.3050531914893617
- 0.2973404255319149
- 0.30569148936170215
- 0.30329787234042555
- 0.3252127659574468
- 0.3330851063829787
- 0.3231914893617021
- 0.32526595744680853
- 0.32122340425531914
- 0.3322340425531915
- 0.36031914893617023
- 0.31670212765957445
- 0.37207446808510636
- 0.34356382978723404
- 0.3390957446808511
- 0.3346276595744681
- 0.355
- 0.3623936170212766
- 0.35867021276595745
- 0.3457978723404255
- 0.36627659574468086
- 0.36
- 0.37553191489361704
- 0.350531914893617
- 0.351968085106383
- 0.3803191489361702
- 0.36877659574468086
- 0.39
- 0.36819148936170215
- 0.37122340425531913
- 0.39122340425531915
- 0.40095744680851064
- 0.36425531914893616
- 0.41893617021276597
- 0.3620212765957447
- 0.36308510638297875
- 0.4206382978723404
- 0.3827127659574468
- 0.39574468085106385
- 0.418031914893617
- 0.3558510638297872
- 0.3973404255319149
- 0.3815425531914894
- 0.39622340425531916
- 0.37638297872340426
- 0.41925531914893616
- 0.36106382978723406
- 0.4243085106382979
- 0.3956914893617021
- 0.4208510638297872
- 0.3656382978723404
- 0.42648936170212765
- 0.4128723404255319
- 0.4203723404255319
- 0.4056382978723404
- 0.4165957446808511
- 0.4154255319148936
- 0.44393617021276593
- 0.3818617021276596
- 0.4132446808510638
- 0.4609042553191489
- 0.4593617021276596
- 0.3945744680851064
- 0.38574468085106384
- 0.3821276595744681
- 0.45872340425531916
- 0.3612234042553191
- 0.4486702127659574
- 0.4252127659574468
- 0.45670212765957446
- 0.4117021276595745
- 0.45893617021276595
- 0.46159574468085107
- 0.47132978723404256
- 0.4229787234042553
- 0.4381914893617021
- 0.4671276595744681
- 0.4315425531914894
- 0.45159574468085106
- 0.4646276595744681
- 0.4587765957446808
- 0.4752127659574468
- 0.4913297872340426
- 0.4703191489361702
- 0.4444148936170213
- 0.4965425531914894
- 0.4315425531914894
- 0.46122340425531916
test_loss_list:
- 4.020546487172445
- 4.1976211102803545
- 4.2291769027709964
- 3.9674194558461506
- 3.7228213787078857
- 3.223452367782593
- 3.409300521214803
- 3.200224033991496
- 3.2700031089782713
- 3.383606595993042
- 3.2132878430684406
- 3.5380281098683675
- 3.139072093963623
- 3.1742455768585205
- 3.7531040477752686
- 2.955612710316976
- 3.0754435030619303
- 2.9278552691141764
- 3.120360864003499
- 3.05195961634318
- 3.3074904346466063
- 3.7747102228800458
- 2.7464550654093425
- 3.3631142489115398
- 2.606844800313314
- 2.9254928557078044
- 3.406912129720052
- 2.8224882570902508
- 2.6278044033050536
- 2.8132434463500977
- 2.8138323402404786
- 2.9818234920501707
- 2.7588160133361814
- 3.0033542188008626
- 2.770358190536499
- 3.041594502131144
- 3.24198392868042
- 2.735413459142049
- 2.923156290054321
- 2.44487016359965
- 2.5951450570424397
- 2.64697359085083
- 2.397141949335734
- 2.4537253093719484
- 2.8518824036916097
- 2.293900467554728
- 2.5941538333892824
- 2.8096485805511473
- 2.4139085737864177
- 2.7362300237019856
- 2.5003624025980633
- 2.2303246879577636
- 3.2135026454925537
- 2.4740064652760823
- 2.5062860361735027
- 2.550728069941203
- 3.145658877690633
- 2.491378107070923
- 2.8128916962941486
- 2.271178027788798
- 2.340552358627319
- 2.3645164076487224
- 3.247276242574056
- 2.0778784386316933
- 2.5126878134409587
- 2.3617677942911786
- 2.2407142241795857
- 2.4487826093037923
- 2.4488865407307943
- 2.0797376362482707
- 2.6064796924591063
- 2.280699388186137
- 2.0774030749003094
- 2.0987037579218546
- 2.5539454714457195
- 2.736303030649821
- 2.5965705744425454
- 2.0243987051645913
- 2.2529208771387736
- 2.148640087445577
- 2.3111734755833946
- 1.9541677888234457
- 2.39871124903361
- 1.9480449072519939
- 1.9856066226959228
- 1.8633946307500204
- 2.268391695022583
- 2.27530886332194
- 2.0112777868906657
- 2.40029322942098
- 2.2140695381164552
- 1.950109496116638
- 2.087214738527934
- 2.019898273150126
- 1.9746981382369995
- 1.9782592916488648
- 1.8192147699991863
- 1.7580580886205037
- 2.2987272850672404
- 1.7379083490371705
train_accuracy:
- 0.0
- 0.0
- 0.315
- 0.463
- 0.579
- 0.594
- 0.0
- 0.65
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.731
- 0.0
- 0.0
- 0.0
- 0.731
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.794
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.798
- 0.002
- 0.815
- 0.833
- 0.808
- 0.0
- 0.006
- 0.0
- 0.842
- 0.008
- 0.04
- 0.031
- 0.344
- 0.181
- 0.0
- 0.058
- 0.0
- 0.002
- 0.002
- 0.0
- 0.008
- 0.0
- 0.848
- 0.002
- 0.0
- 0.85
- 0.86
- 0.0
- 0.096
- 0.0
- 0.85
- 0.867
- 0.056
- 0.0
- 0.0
- 0.006
- 0.054
- 0.0
- 0.871
- 0.104
- 0.017
- 0.883
- 0.044
- 0.871
- 0.85
- 0.0
- 0.056
- 0.869
- 0.231
- 0.885
- 0.875
- 0.046
- 0.004
- 0.879
- 0.029
- 0.071
- 0.877
- 0.887
- 0.008
- 0.0
- 0.019
- 0.156
- 0.115
- 0.41
- 0.873
- 0.885
- 0.035
train_loss:
- 2.279
- 1.134
- 1.621
- 1.453
- 1.299
- 1.005
- 0.884
- 0.839
- 0.834
- 1.025
- 0.604
- 0.913
- 0.858
- 0.896
- 1.004
- 0.918
- 0.687
- 0.662
- 0.848
- 0.841
- 0.775
- 0.848
- 0.614
- 0.815
- 0.644
- 0.603
- 0.854
- 0.749
- 0.613
- 0.571
- 0.71
- 0.689
- 0.672
- 0.667
- 0.674
- 0.635
- 0.755
- 0.647
- 0.619
- 0.558
- 0.537
- 0.597
- 0.517
- 0.491
- 0.578
- 0.512
- 0.407
- 0.598
- 0.579
- 0.597
- 0.57
- 0.484
- 0.652
- 0.55
- 0.57
- 0.571
- 0.639
- 0.545
- 0.548
- 0.565
- 0.45
- 0.535
- 0.6
- 0.47
- 0.533
- 0.531
- 0.446
- 0.51
- 0.522
- 0.436
- 0.508
- 0.509
- 0.425
- 0.43
- 0.489
- 0.57
- 0.599
- 0.431
- 0.33
- 0.388
- 0.476
- 0.435
- 0.474
- 0.408
- 0.374
- 0.424
- 0.463
- 0.481
- 0.41
- 0.478
- 0.469
- 0.39
- 0.4
- 0.37
- 0.398
- 0.4
- 0.305
- 0.408
- 0.441
- 0.32
unequal: 0
verbose: 1
