avg_train_accuracy: 0.846
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04851063829787234
- 0.1273936170212766
- 0.19085106382978723
- 0.2026595744680851
- 0.22170212765957448
- 0.23042553191489362
- 0.25813829787234044
- 0.2827659574468085
- 0.2770744680851064
- 0.2777127659574468
- 0.2773404255319149
- 0.2898404255319149
- 0.30569148936170215
- 0.31351063829787235
- 0.3068085106382979
- 0.3479255319148936
- 0.3298404255319149
- 0.3596276595744681
- 0.35260638297872343
- 0.3474468085106383
- 0.3637234042553191
- 0.35925531914893616
- 0.3716489361702128
- 0.3928191489361702
- 0.3778191489361702
- 0.42138297872340424
- 0.4001063829787234
- 0.39813829787234045
- 0.3882978723404255
- 0.4195212765957447
- 0.4110106382978723
- 0.44361702127659575
- 0.4277127659574468
- 0.42388297872340425
- 0.44063829787234043
- 0.4101063829787234
- 0.42648936170212765
- 0.44638297872340427
- 0.4482978723404255
- 0.4401595744680851
- 0.42340425531914894
- 0.4373936170212766
- 0.46691489361702126
- 0.40962765957446806
- 0.43329787234042555
- 0.46585106382978725
- 0.4525531914893617
- 0.4477127659574468
- 0.4639893617021277
- 0.4568617021276596
- 0.45351063829787236
- 0.466968085106383
- 0.4973404255319149
- 0.4449468085106383
- 0.4734042553191489
- 0.46143617021276595
- 0.48654255319148937
- 0.4768085106382979
- 0.45643617021276595
- 0.47856382978723405
- 0.47356382978723405
- 0.4983510638297872
- 0.4653191489361702
- 0.5078723404255319
- 0.5022872340425532
- 0.5202127659574468
- 0.46914893617021275
- 0.4878723404255319
- 0.48404255319148937
- 0.4927659574468085
- 0.4881382978723404
- 0.48659574468085104
- 0.48090425531914893
- 0.5107446808510638
- 0.5109574468085106
- 0.5212234042553191
- 0.5012234042553192
- 0.5392021276595744
- 0.49148936170212765
- 0.5363829787234042
- 0.5447340425531915
- 0.47388297872340424
- 0.5216489361702128
- 0.46845744680851065
- 0.5202127659574468
- 0.5371808510638297
- 0.5173404255319148
- 0.4984574468085106
- 0.5161702127659574
- 0.5349468085106382
- 0.5217021276595745
- 0.5268085106382979
- 0.5357446808510639
- 0.5236170212765957
- 0.5471808510638297
- 0.5117021276595745
- 0.5128723404255319
- 0.558936170212766
- 0.4769148936170213
- 0.5417553191489362
test_loss_list:
- 3.9538815148671467
- 3.9058746465047203
- 3.587255983352661
- 3.459160010019938
- 3.2660905933380127
- 3.045616547266642
- 3.049095360438029
- 2.8902494780222576
- 3.0356979179382324
- 2.85378186861674
- 3.1268503952026365
- 2.82971381187439
- 2.9910727246602375
- 2.73606543858846
- 3.0280126508076988
- 2.6198143513997394
- 2.7523845863342284
- 2.4830006186167397
- 2.579660120010376
- 2.7435557238260904
- 2.5412729517618815
- 2.5825279903411866
- 2.572893835703532
- 2.4796679751078288
- 2.421827074686686
- 2.339472843805949
- 2.345230751037598
- 2.3177914873758954
- 2.3845792388916016
- 2.2400006230672203
- 2.231981716156006
- 2.122643934885661
- 2.1182418727874754
- 2.1474068784713745
- 2.1411156368255617
- 2.2816549507776895
- 2.128952617645264
- 2.038387500445048
- 2.0797990957895913
- 2.0770165141423544
- 2.192608893712362
- 2.0349235041936238
- 1.9050843445460002
- 2.245803581873576
- 2.100224733352661
- 1.9660380188624065
- 1.9647314262390136
- 2.162611756324768
- 1.9047121000289917
- 1.9334494145711263
- 2.05509165763855
- 1.9031903505325318
- 1.7583982340494793
- 2.171128894488017
- 1.7992175213495891
- 1.980609777768453
- 1.7944858996073405
- 1.8827020994822183
- 1.9915682156880696
- 1.785215088526408
- 1.867212184270223
- 1.7578938436508178
- 1.9507431030273437
- 1.7485644880930582
- 1.8538221708933513
- 1.7972024869918823
- 2.164974513053894
- 1.9043932135899861
- 1.9308857599894205
- 1.819097375869751
- 1.7961321624120077
- 1.768703343073527
- 1.8808509302139282
- 1.6240231800079346
- 1.643623433113098
- 1.7060296567281088
- 1.7403665129343668
- 1.519931936264038
- 1.7341169341405234
- 1.5498059288660686
- 1.5979500261942545
- 1.8029803323745728
- 1.6503630081812541
- 1.939125631650289
- 1.618749769528707
- 1.5281807772318523
- 1.6285076093673707
- 1.7719417794545491
- 1.7379052114486695
- 1.5422550996144613
- 1.6251090669631958
- 1.5806779861450195
- 1.6567507855097452
- 1.6069561751683552
- 1.5727810637156168
- 1.6797616068522137
- 1.5870298767089843
- 1.4664959287643433
- 1.8725231631596884
- 1.5305146312713622
train_accuracy:
- 0.121
- 0.335
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.642
- 0.002
- 0.0
- 0.0
- 0.0
- 0.713
- 0.0
- 0.671
- 0.0
- 0.717
- 0.021
- 0.742
- 0.01
- 0.76
- 0.773
- 0.71
- 0.027
- 0.737
- 0.0
- 0.021
- 0.008
- 0.74
- 0.006
- 0.027
- 0.004
- 0.031
- 0.081
- 0.01
- 0.785
- 0.0
- 0.01
- 0.052
- 0.827
- 0.802
- 0.05
- 0.829
- 0.002
- 0.023
- 0.004
- 0.823
- 0.81
- 0.01
- 0.052
- 0.06
- 0.771
- 0.037
- 0.094
- 0.815
- 0.006
- 0.04
- 0.037
- 0.106
- 0.079
- 0.812
- 0.04
- 0.023
- 0.023
- 0.035
- 0.012
- 0.0
- 0.842
- 0.835
- 0.827
- 0.844
- 0.008
- 0.012
- 0.833
- 0.021
- 0.048
- 0.15
- 0.023
- 0.017
- 0.819
- 0.85
- 0.019
- 0.067
- 0.048
- 0.096
- 0.054
- 0.077
- 0.844
- 0.146
- 0.188
- 0.052
- 0.848
- 0.854
- 0.242
- 0.054
- 0.092
- 0.019
- 0.883
- 0.846
train_loss:
- 1.753
- 1.525
- 1.255
- 1.128
- 1.03
- 0.821
- 0.777
- 0.766
- 0.881
- 0.846
- 0.923
- 0.931
- 0.874
- 0.861
- 0.814
- 0.712
- 0.686
- 0.697
- 0.707
- 0.753
- 0.771
- 0.747
- 0.734
- 0.606
- 0.642
- 0.613
- 0.503
- 0.59
- 0.676
- 0.593
- 0.589
- 0.481
- 0.466
- 0.546
- 0.55
- 0.606
- 0.535
- 0.45
- 0.514
- 0.533
- 0.614
- 0.522
- 0.417
- 0.566
- 0.583
- 0.501
- 0.495
- 0.568
- 0.506
- 0.519
- 0.549
- 0.513
- 0.42
- 0.553
- 0.503
- 0.483
- 0.491
- 0.472
- 0.536
- 0.468
- 0.466
- 0.46
- 0.462
- 0.475
- 0.464
- 0.464
- 0.532
- 0.522
- 0.454
- 0.446
- 0.428
- 0.441
- 0.525
- 0.434
- 0.362
- 0.443
- 0.45
- 0.358
- 0.423
- 0.371
- 0.361
- 0.477
- 0.414
- 0.473
- 0.404
- 0.37
- 0.434
- 0.481
- 0.495
- 0.342
- 0.402
- 0.423
- 0.406
- 0.412
- 0.414
- 0.385
- 0.48
- 0.353
- 0.456
- 0.393
unequal: 0
verbose: 1
