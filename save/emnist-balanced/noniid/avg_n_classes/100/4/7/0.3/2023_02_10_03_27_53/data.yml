avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.09925531914893616
- 0.049840425531914895
- 0.08106382978723405
- 0.09
- 0.20430851063829789
- 0.22898936170212766
- 0.23813829787234042
- 0.2695744680851064
- 0.26340425531914896
- 0.25601063829787235
- 0.14718085106382978
- 0.2848404255319149
- 0.1453191489361702
- 0.28797872340425534
- 0.29579787234042554
- 0.29845744680851066
- 0.29186170212765955
- 0.29531914893617023
- 0.3026063829787234
- 0.30707446808510636
- 0.3057446808510638
- 0.30659574468085105
- 0.316063829787234
- 0.3175
- 0.31888297872340426
- 0.22622340425531914
- 0.31446808510638297
- 0.3191489361702128
- 0.20095744680851063
- 0.3450531914893617
- 0.32904255319148934
- 0.3203191489361702
- 0.3322340425531915
- 0.3321808510638298
- 0.3372340425531915
- 0.3373404255319149
- 0.3490957446808511
- 0.3351595744680851
- 0.3347872340425532
- 0.1803191489361702
- 0.33414893617021274
- 0.3377659574468085
- 0.33547872340425533
- 0.3448404255319149
- 0.34191489361702126
- 0.3421808510638298
- 0.21101063829787234
- 0.3489893617021277
- 0.24627659574468086
- 0.22148936170212766
- 0.35143617021276596
- 0.26632978723404255
- 0.34606382978723405
- 0.36425531914893616
- 0.36196808510638295
- 0.35606382978723405
- 0.3425
- 0.3420744680851064
- 0.30154255319148937
- 0.26324468085106384
- 0.36398936170212765
- 0.2531914893617021
- 0.3598404255319149
- 0.3298936170212766
- 0.3618085106382979
- 0.2937234042553192
- 0.3723936170212766
- 0.3575
- 0.3579787234042553
- 0.35893617021276597
- 0.3561170212765957
- 0.37111702127659574
- 0.36319148936170215
- 0.3608510638297872
- 0.385
- 0.3618085106382979
- 0.3652659574468085
- 0.3743085106382979
- 0.36877659574468086
- 0.33893617021276595
- 0.36340425531914894
- 0.355531914893617
- 0.38978723404255317
- 0.3847340425531915
- 0.37106382978723407
- 0.3730851063829787
- 0.3749468085106383
- 0.3586170212765957
- 0.3645744680851064
- 0.41377659574468084
- 0.3421276595744681
- 0.32851063829787236
- 0.4025531914893617
- 0.39132978723404255
- 0.39335106382978724
- 0.36803191489361703
- 0.38930851063829786
- 0.38393617021276594
- 0.36308510638297875
- 0.3776063829787234
test_loss_list:
- 4.265143400828044
- 4.577782726287841
- 4.569571762084961
- 5.017273559570312
- 4.559290110270182
- 4.6378750928243
- 4.0444321568806965
- 4.524687105814616
- 4.143181187311808
- 3.757885665893555
- 3.445437100728353
- 3.6549905713399253
- 4.08871109644572
- 3.8026669279734295
- 4.504071400960286
- 4.01099702835083
- 3.771375624338786
- 3.5958314673105876
- 3.7189856497446696
- 3.865477202733358
- 3.782190949122111
- 3.940263353983561
- 4.117834974924723
- 4.251848862965901
- 3.868423401514689
- 3.336201206843058
- 3.7799498462677
- 3.5427151997884114
- 3.484656867980957
- 3.5246253299713133
- 3.368160966237386
- 3.722131652832031
- 4.609909985860189
- 4.729097951253255
- 4.808993867238363
- 4.649295488993327
- 4.9519807116190595
- 4.984314575195312
- 4.053509127298991
- 3.3575494543711346
- 3.4182322057088217
- 3.461441977818807
- 4.421930303573609
- 3.4554052511850992
- 4.562204189300537
- 3.6834507751464844
- 3.9054960091908772
- 4.222069047292074
- 3.482652324040731
- 3.3650205167134604
- 3.2640941905975343
- 2.956838013331095
- 3.7412422211964924
- 3.551507962544759
- 4.556377633412679
- 4.258775885899862
- 3.5823918024698895
- 3.545230747858683
- 2.8708704058329264
- 3.025215730667114
- 3.0118218294779457
- 3.0585582129160565
- 3.875669355392456
- 2.6616955852508544
- 3.582714840571086
- 3.2247590510050457
- 3.0712361685434977
- 3.1474690024058023
- 3.159988063176473
- 3.1587090237935382
- 3.92641139348348
- 3.274859873453776
- 4.244983927408854
- 2.677138214111328
- 3.3185409545898437
- 3.2995125579833986
- 3.2274876976013185
- 3.372773936589559
- 3.2914016977945963
- 2.83298152923584
- 3.565226132074992
- 3.8584505335489907
- 2.211035606066386
- 2.824550568262736
- 3.1426325257619223
- 3.2359073988596596
- 3.1146905612945557
- 3.699965753555298
- 3.097687753041585
- 2.0965353616078697
- 2.7881847540537517
- 2.6860902563730877
- 2.8794421990712484
- 2.251394220987956
- 2.5380821895599364
- 2.484975954691569
- 2.7920152695973712
- 2.250835911432902
- 3.110941613515218
- 2.824159278869629
train_accuracy:
- 0.237
- 0.0
- 0.037
- 0.004
- 0.498
- 0.546
- 0.0
- 0.64
- 0.679
- 0.0
- 0.0
- 0.0
- 0.16
- 0.0
- 0.723
- 0.0
- 0.0
- 0.708
- 0.0
- 0.0
- 0.0
- 0.748
- 0.0
- 0.0
- 0.0
- 0.256
- 0.0
- 0.0
- 0.575
- 0.0
- 0.0
- 0.748
- 0.0
- 0.8
- 0.0
- 0.0
- 0.817
- 0.821
- 0.806
- 0.073
- 0.004
- 0.0
- 0.781
- 0.808
- 0.812
- 0.808
- 0.573
- 0.831
- 0.133
- 0.802
- 0.0
- 0.448
- 0.0
- 0.0
- 0.844
- 0.825
- 0.833
- 0.858
- 0.429
- 0.617
- 0.846
- 0.231
- 0.0
- 0.487
- 0.858
- 0.546
- 0.848
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.863
- 0.163
- 0.006
- 0.0
- 0.0
- 0.812
- 0.0
- 0.608
- 0.0
- 0.835
- 0.354
- 0.035
- 0.0
- 0.0
- 0.863
- 0.0
- 0.892
- 0.358
- 0.892
- 0.89
- 0.0
- 0.206
- 0.85
- 0.531
- 0.029
- 0.869
- 0.0
- 0.0
train_loss:
- 2.787
- 1.325
- 1.088
- 0.925
- 2.077
- 1.774
- 1.22
- 1.444
- 1.465
- 1.185
- 0.911
- 1.131
- 0.669
- 0.9
- 1.306
- 1.021
- 0.939
- 1.041
- 0.896
- 0.863
- 0.918
- 0.92
- 0.901
- 1.094
- 0.837
- 0.661
- 0.833
- 0.821
- 0.642
- 0.759
- 0.792
- 0.889
- 0.893
- 0.983
- 0.865
- 0.838
- 0.825
- 0.934
- 0.814
- 0.634
- 0.796
- 0.756
- 0.85
- 0.7
- 0.832
- 0.773
- 0.613
- 0.984
- 0.575
- 0.53
- 0.705
- 0.462
- 0.873
- 0.602
- 0.719
- 0.714
- 0.662
- 0.712
- 0.478
- 0.548
- 0.79
- 0.595
- 0.802
- 0.517
- 0.81
- 0.507
- 0.58
- 0.643
- 0.594
- 0.617
- 0.673
- 0.558
- 0.665
- 0.458
- 0.546
- 0.684
- 0.572
- 0.578
- 0.666
- 0.428
- 0.753
- 0.66
- 0.497
- 0.665
- 0.532
- 0.535
- 0.621
- 0.632
- 0.53
- 0.424
- 0.374
- 0.319
- 0.506
- 0.418
- 0.662
- 0.47
- 0.488
- 0.413
- 0.809
- 0.578
unequal: 0
verbose: 1
