avg_train_accuracy: 0.073
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03425531914893617
- 0.11372340425531915
- 0.06569148936170213
- 0.21345744680851064
- 0.11085106382978724
- 0.25803191489361704
- 0.2793617021276596
- 0.2691489361702128
- 0.2975531914893617
- 0.1372340425531915
- 0.3012234042553191
- 0.13414893617021276
- 0.2923936170212766
- 0.3046276595744681
- 0.3142553191489362
- 0.30781914893617024
- 0.31851063829787235
- 0.13117021276595744
- 0.32468085106382977
- 0.3202659574468085
- 0.3250531914893617
- 0.32638297872340427
- 0.22542553191489362
- 0.18718085106382978
- 0.18127659574468086
- 0.19042553191489361
- 0.32845744680851063
- 0.24303191489361703
- 0.3338829787234043
- 0.3274468085106383
- 0.32968085106382977
- 0.3337765957446808
- 0.3374468085106383
- 0.2606914893617021
- 0.23398936170212767
- 0.3625531914893617
- 0.3519148936170213
- 0.22829787234042553
- 0.34888297872340424
- 0.33111702127659576
- 0.35808510638297875
- 0.354468085106383
- 0.35132978723404257
- 0.3562234042553192
- 0.3576063829787234
- 0.343031914893617
- 0.2631914893617021
- 0.3468617021276596
- 0.35627659574468085
- 0.3600531914893617
- 0.36196808510638295
- 0.3525531914893617
- 0.3716489361702128
- 0.35058510638297874
- 0.3475
- 0.366436170212766
- 0.3638297872340426
- 0.36351063829787233
- 0.35117021276595745
- 0.3550531914893617
- 0.38377659574468087
- 0.36414893617021277
- 0.33441489361702126
- 0.37957446808510636
- 0.3648936170212766
- 0.37090425531914895
- 0.36542553191489363
- 0.3667021276595745
- 0.3456382978723404
- 0.39313829787234045
- 0.36367021276595746
- 0.37106382978723407
- 0.29904255319148937
- 0.28962765957446807
- 0.3021276595744681
- 0.3847872340425532
- 0.41877659574468085
- 0.39739361702127657
- 0.39
- 0.3875
- 0.3981914893617021
- 0.3594148936170213
- 0.39893617021276595
- 0.3929787234042553
- 0.4283510638297872
- 0.4002127659574468
- 0.42484042553191487
- 0.35664893617021276
- 0.4076063829787234
- 0.39617021276595743
- 0.39787234042553193
- 0.40430851063829787
- 0.3853191489361702
- 0.3964893617021277
- 0.3924468085106383
- 0.3978191489361702
- 0.39537234042553193
- 0.3918617021276596
- 0.3903191489361702
- 0.4252127659574468
test_loss_list:
- 3.8302118523915607
- 4.166276111602783
- 4.466608079274495
- 3.977819786071777
- 4.13768951733907
- 4.52420867284139
- 4.515745035807291
- 3.5403385734558106
- 4.398513126373291
- 3.7980504480997723
- 3.7190622997283938
- 4.444733581542969
- 3.4276018142700195
- 3.786173521677653
- 3.8711475308736167
- 3.80698353767395
- 4.698000933329264
- 3.7492428843180337
- 3.465347684224447
- 3.645363051096598
- 4.561543337504069
- 4.341106675465902
- 3.628546641667684
- 3.896283941268921
- 3.6542010084788004
- 3.9421314493815105
- 3.912016496658325
- 3.1348437945048016
- 2.9156282138824463
- 3.3609184233347573
- 3.4869349002838135
- 4.156772708892822
- 3.4130128701527913
- 2.9649874687194826
- 3.2230201975504555
- 3.0263680013020835
- 3.208821258544922
- 3.2100339285532633
- 3.128505840301514
- 2.4618482875823973
- 2.981120179494222
- 3.182080685297648
- 3.056353209813436
- 3.3547741889953615
- 3.1705897839864097
- 4.002689469655355
- 3.1460361607869465
- 3.8078888765970866
- 2.4720402590433754
- 2.960194396972656
- 3.781997340520223
- 3.720298636754354
- 3.2605991331736246
- 3.963045441309611
- 3.856877406438192
- 2.5155318355560303
- 2.996531842549642
- 3.251567506790161
- 3.8223462518056235
- 3.1666646067301434
- 2.243153082529704
- 2.9509369277954103
- 3.276614357630412
- 2.9067946529388426
- 3.7609530671437583
- 2.951780554453532
- 2.9577220567067464
- 2.5165625921885173
- 2.600464963912964
- 2.7111916383107504
- 3.456366949081421
- 2.5341618696848554
- 2.8466457239786784
- 3.306464993158976
- 2.628592007954915
- 2.144227032661438
- 2.3525711345672606
- 2.588443854649862
- 2.828885014851888
- 2.885565814971924
- 2.8615061028798423
- 2.6093914254506427
- 2.723538014094035
- 2.959826962153117
- 2.065429598490397
- 2.60043044090271
- 2.138822019894918
- 4.297144994735718
- 3.057182410558065
- 2.1607527987162274
- 2.632596623102824
- 2.940503231684367
- 2.747189172108968
- 2.7534002176920573
- 2.823558514912923
- 2.8917853927612303
- 2.3350378926595052
- 3.2069708728790283
- 2.4396909999847414
- 2.828406629562378
train_accuracy:
- 0.0
- 0.3
- 0.079
- 0.0
- 0.0
- 0.0
- 0.694
- 0.673
- 0.729
- 0.008
- 0.729
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.781
- 0.394
- 0.787
- 0.0
- 0.0
- 0.8
- 0.119
- 0.092
- 0.312
- 0.135
- 0.81
- 0.0
- 0.796
- 0.783
- 0.819
- 0.821
- 0.0
- 0.094
- 0.3
- 0.0
- 0.002
- 0.288
- 0.833
- 0.227
- 0.838
- 0.012
- 0.838
- 0.027
- 0.0
- 0.852
- 0.31
- 0.856
- 0.027
- 0.838
- 0.848
- 0.0
- 0.023
- 0.875
- 0.0
- 0.423
- 0.0
- 0.86
- 0.858
- 0.0
- 0.231
- 0.025
- 0.658
- 0.023
- 0.848
- 0.856
- 0.002
- 0.848
- 0.485
- 0.871
- 0.869
- 0.048
- 0.062
- 0.577
- 0.035
- 0.219
- 0.092
- 0.1
- 0.019
- 0.079
- 0.004
- 0.646
- 0.867
- 0.0
- 0.485
- 0.846
- 0.49
- 0.877
- 0.0
- 0.706
- 0.0
- 0.867
- 0.012
- 0.017
- 0.006
- 0.069
- 0.698
- 0.09
- 0.537
- 0.073
train_loss:
- 2.369
- 1.927
- 0.995
- 1.287
- 0.691
- 1.597
- 1.357
- 1.241
- 1.282
- 0.761
- 0.904
- 0.648
- 0.979
- 0.877
- 0.855
- 0.793
- 0.957
- 0.822
- 0.86
- 0.767
- 0.97
- 0.999
- 0.612
- 0.526
- 0.548
- 0.426
- 1.058
- 0.539
- 0.762
- 0.661
- 0.66
- 0.847
- 0.705
- 0.456
- 0.435
- 0.665
- 0.664
- 0.462
- 0.621
- 0.362
- 0.584
- 0.559
- 0.638
- 0.558
- 0.561
- 0.768
- 0.423
- 0.783
- 0.496
- 0.566
- 0.732
- 0.726
- 0.586
- 0.686
- 0.715
- 0.45
- 0.555
- 0.509
- 0.67
- 0.53
- 0.35
- 0.51
- 0.302
- 0.501
- 0.605
- 0.538
- 0.58
- 0.403
- 0.353
- 0.487
- 0.62
- 0.402
- 0.308
- 0.27
- 0.336
- 0.293
- 0.491
- 0.474
- 0.429
- 0.447
- 0.523
- 0.352
- 0.512
- 0.442
- 0.286
- 0.47
- 0.255
- 0.821
- 0.424
- 0.364
- 0.435
- 0.403
- 0.502
- 0.501
- 0.459
- 0.435
- 0.378
- 0.636
- 0.322
- 0.391
unequal: 0
verbose: 1
