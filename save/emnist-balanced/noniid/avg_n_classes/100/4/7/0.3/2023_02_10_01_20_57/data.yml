avg_train_accuracy: 0.002
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06617021276595744
- 0.040372340425531915
- 0.20079787234042554
- 0.20792553191489363
- 0.2375
- 0.27393617021276595
- 0.11936170212765958
- 0.2739893617021277
- 0.29308510638297874
- 0.30148936170212765
- 0.18111702127659574
- 0.14553191489361703
- 0.3071808510638298
- 0.3104787234042553
- 0.1550531914893617
- 0.3076063829787234
- 0.31563829787234043
- 0.3153723404255319
- 0.3173404255319149
- 0.3175531914893617
- 0.31622340425531914
- 0.32170212765957445
- 0.32303191489361704
- 0.32728723404255317
- 0.3277127659574468
- 0.3288829787234043
- 0.3253723404255319
- 0.32835106382978724
- 0.33345744680851064
- 0.3329255319148936
- 0.33574468085106385
- 0.1822872340425532
- 0.21819148936170213
- 0.34143617021276595
- 0.2326063829787234
- 0.3424468085106383
- 0.2526063829787234
- 0.33574468085106385
- 0.32585106382978724
- 0.3504255319148936
- 0.280531914893617
- 0.34585106382978725
- 0.32515957446808513
- 0.26670212765957446
- 0.3472872340425532
- 0.3429255319148936
- 0.3619148936170213
- 0.3532446808510638
- 0.3558510638297872
- 0.30127659574468085
- 0.39430851063829786
- 0.3876063829787234
- 0.35058510638297874
- 0.35606382978723405
- 0.3925
- 0.3548936170212766
- 0.3203191489361702
- 0.36909574468085105
- 0.39739361702127657
- 0.3948404255319149
- 0.39313829787234045
- 0.3796276595744681
- 0.3829255319148936
- 0.3879255319148936
- 0.38079787234042556
- 0.35085106382978726
- 0.37382978723404253
- 0.3604787234042553
- 0.36840425531914894
- 0.3793617021276596
- 0.395
- 0.30856382978723407
- 0.42617021276595746
- 0.4296808510638298
- 0.3843617021276596
- 0.39095744680851063
- 0.3622872340425532
- 0.43069148936170215
- 0.41079787234042553
- 0.3695212765957447
- 0.39835106382978724
- 0.3399468085106383
- 0.39
- 0.3906914893617021
- 0.42436170212765956
- 0.40143617021276595
- 0.3791489361702128
- 0.3924468085106383
- 0.44377659574468087
- 0.42425531914893616
- 0.39026595744680853
- 0.45441489361702125
- 0.4231382978723404
- 0.4580851063829787
- 0.40702127659574466
- 0.3997340425531915
- 0.38920212765957446
- 0.3976063829787234
- 0.46095744680851064
- 0.4263297872340426
test_loss_list:
- 4.079025274912516
- 6.031867033640544
- 4.566392059326172
- 4.363396511077881
- 4.184720379511515
- 4.9179369099934895
- 3.873492873509725
- 3.458886270523071
- 3.9393011379241942
- 4.21687208811442
- 3.362422596613566
- 3.610423692067464
- 3.4741787910461426
- 3.8287089602152506
- 4.540205516815186
- 3.704630241394043
- 4.439216734568278
- 4.1828750928243
- 3.948442440032959
- 4.148254880905151
- 3.5750340048472085
- 3.8369589328765867
- 3.7397784773508707
- 4.561237885157268
- 3.6478476238250734
- 3.9097748947143556
- 3.7366889731089272
- 3.6397858174641926
- 3.824903450012207
- 4.738063252766927
- 4.609400513966878
- 3.6215417448679608
- 4.471603247324626
- 3.3087414010365803
- 3.3928020413716635
- 3.38593474706014
- 3.541822945276896
- 4.041299692789713
- 2.512514657974243
- 3.047733793258667
- 2.993338689804077
- 3.541863412857056
- 2.9441755867004393
- 3.2843536535898843
- 3.461032123565674
- 2.480379727681478
- 3.033253151575724
- 4.016540145874023
- 2.685232973098755
- 2.977182912826538
- 3.0606868934631346
- 2.154328670501709
- 3.4099324417114256
- 2.3978470738728843
- 2.754702243804932
- 3.484127337137858
- 2.8784071667989095
- 2.737273168563843
- 2.3856135177612305
- 3.0896917152404786
- 3.0159724807739257
- 3.234073117574056
- 2.8592751820882163
- 2.798076187769572
- 2.9574869378407795
- 4.965394426981608
- 3.4223546028137206
- 3.071059090296427
- 3.0395086860656737
- 2.25241513411204
- 2.31953173160553
- 2.9124231179555258
- 2.651317237218221
- 2.079032092094421
- 2.7594569555918373
- 2.8621240425109864
- 2.490533955891927
- 2.002884111404419
- 2.510469665527344
- 3.394395128885905
- 2.8475639247894287
- 2.62635560353597
- 2.6618287563323975
- 2.833790022532145
- 2.2330381615956623
- 2.7610288206736247
- 2.775611553192139
- 2.29096284866333
- 1.8894104401270548
- 2.286295075416565
- 2.71851123491923
- 1.9048047637939454
- 2.3092139180501303
- 1.8899478197097779
- 2.566736799875895
- 2.9479928970336915
- 2.8891415945688883
- 2.7321207014719646
- 1.864880469640096
- 2.585528424580892
train_accuracy:
- 0.152
- 0.0
- 0.483
- 0.0
- 0.579
- 0.713
- 0.267
- 0.0
- 0.0
- 0.729
- 0.0
- 0.158
- 0.723
- 0.0
- 0.002
- 0.727
- 0.777
- 0.0
- 0.742
- 0.0
- 0.0
- 0.76
- 0.0
- 0.8
- 0.0
- 0.802
- 0.0
- 0.802
- 0.0
- 0.0
- 0.817
- 0.019
- 0.204
- 0.0
- 0.019
- 0.002
- 0.698
- 0.0
- 0.14
- 0.0
- 0.071
- 0.865
- 0.635
- 0.092
- 0.852
- 0.265
- 0.008
- 0.002
- 0.146
- 0.917
- 0.84
- 0.506
- 0.846
- 0.369
- 0.898
- 0.008
- 0.246
- 0.0
- 0.727
- 0.104
- 0.0
- 0.002
- 0.825
- 0.002
- 0.252
- 0.892
- 0.0
- 0.848
- 0.004
- 0.144
- 0.787
- 0.94
- 0.106
- 0.085
- 0.879
- 0.0
- 0.671
- 0.694
- 0.0
- 0.898
- 0.002
- 0.354
- 0.025
- 0.125
- 0.435
- 0.887
- 0.896
- 0.727
- 0.835
- 0.912
- 0.033
- 0.419
- 0.102
- 0.75
- 0.021
- 0.002
- 0.035
- 0.0
- 0.729
- 0.002
train_loss:
- 2.305
- 1.244
- 2.341
- 1.427
- 1.196
- 1.436
- 0.841
- 1.204
- 1.267
- 1.26
- 0.685
- 0.729
- 0.914
- 0.96
- 0.634
- 0.805
- 1.048
- 1.025
- 0.756
- 0.787
- 0.996
- 0.836
- 0.78
- 0.876
- 0.823
- 0.697
- 0.887
- 0.711
- 0.651
- 0.823
- 0.781
- 0.584
- 0.446
- 0.817
- 0.476
- 0.649
- 0.565
- 0.85
- 0.637
- 0.584
- 0.428
- 0.85
- 0.405
- 0.339
- 0.974
- 0.554
- 0.561
- 0.707
- 0.499
- 0.355
- 0.621
- 0.5
- 0.836
- 0.397
- 0.516
- 0.66
- 0.48
- 0.7
- 0.523
- 0.608
- 0.501
- 0.507
- 0.448
- 0.648
- 0.511
- 0.752
- 0.514
- 0.606
- 0.572
- 0.381
- 0.321
- 0.379
- 0.457
- 0.341
- 0.593
- 0.586
- 0.424
- 0.335
- 0.558
- 0.651
- 0.5
- 0.476
- 0.464
- 0.445
- 0.32
- 0.447
- 0.571
- 0.388
- 0.4
- 0.499
- 0.404
- 0.342
- 0.643
- 0.423
- 0.421
- 0.415
- 0.421
- 0.484
- 0.408
- 0.453
unequal: 0
verbose: 1
