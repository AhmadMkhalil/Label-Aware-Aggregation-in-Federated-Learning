avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.01973404255319149
- 0.13425531914893618
- 0.2251595744680851
- 0.24436170212765956
- 0.26111702127659575
- 0.09590425531914894
- 0.10117021276595745
- 0.14063829787234042
- 0.14659574468085107
- 0.28638297872340424
- 0.13569148936170214
- 0.3023936170212766
- 0.30377659574468086
- 0.1375
- 0.31436170212765957
- 0.3123936170212766
- 0.31340425531914895
- 0.31707446808510636
- 0.19031914893617022
- 0.32840425531914896
- 0.331968085106383
- 0.33430851063829786
- 0.321968085106383
- 0.32590425531914896
- 0.24148936170212765
- 0.3321276595744681
- 0.34037234042553194
- 0.20829787234042554
- 0.3498404255319149
- 0.33643617021276595
- 0.344468085106383
- 0.3409042553191489
- 0.3353191489361702
- 0.34037234042553194
- 0.3443617021276596
- 0.3495744680851064
- 0.34675531914893615
- 0.3447872340425532
- 0.21111702127659573
- 0.2026063829787234
- 0.36601063829787234
- 0.23920212765957446
- 0.22069148936170213
- 0.34595744680851065
- 0.35106382978723405
- 0.36281914893617023
- 0.3473936170212766
- 0.34393617021276596
- 0.37707446808510636
- 0.37542553191489364
- 0.3501595744680851
- 0.3769148936170213
- 0.3525
- 0.37946808510638297
- 0.36569148936170215
- 0.36611702127659573
- 0.3076063829787234
- 0.3840425531914894
- 0.37446808510638296
- 0.35904255319148937
- 0.3723936170212766
- 0.3409042553191489
- 0.37579787234042555
- 0.36079787234042554
- 0.3997872340425532
- 0.3816489361702128
- 0.3456382978723404
- 0.4161170212765957
- 0.30531914893617024
- 0.36590425531914894
- 0.39085106382978724
- 0.38143617021276593
- 0.3706382978723404
- 0.40595744680851065
- 0.40643617021276596
- 0.4054255319148936
- 0.3932978723404255
- 0.3318617021276596
- 0.3721808510638298
- 0.3912765957446809
- 0.38904255319148934
- 0.39159574468085107
- 0.38170212765957445
- 0.3907978723404255
- 0.38590425531914896
- 0.39191489361702125
- 0.38207446808510637
- 0.38888297872340427
- 0.3861702127659574
- 0.39861702127659576
- 0.4057978723404255
- 0.39154255319148934
- 0.4071808510638298
- 0.3521808510638298
- 0.43803191489361704
- 0.41335106382978726
- 0.411968085106383
- 0.34164893617021275
- 0.3822340425531915
- 0.410531914893617
test_loss_list:
- 3.9569667307535807
- 4.383108107248942
- 4.613279113769531
- 4.372165807088217
- 4.085208075841268
- 4.755488154093425
- 5.471254444122314
- 4.013225202560425
- 4.113589922587077
- 3.9383576933542885
- 3.445612980524699
- 3.278325030008952
- 3.4653312174479165
- 3.606699603398641
- 3.4342329502105713
- 4.110952879587809
- 3.4717898750305176
- 3.6585255177815754
- 3.645493081410726
- 3.3520226669311524
- 3.7948959986368815
- 3.8407670052846274
- 3.6825608094533284
- 3.6707739384969074
- 3.1920188999176027
- 3.9604950459798176
- 3.432641617457072
- 3.4870287418365478
- 3.4377714443206786
- 3.5910556920369467
- 3.6516817792256675
- 4.307156229019165
- 3.5834872913360596
- 4.4598585255940755
- 3.6236018498738605
- 3.5074610964457196
- 4.314595441818238
- 4.194125477472941
- 3.4802564493815105
- 4.89423064549764
- 3.2166075706481934
- 3.6492287890116373
- 3.7726024754842125
- 3.4756384468078614
- 3.212371377944946
- 3.1779314708709716
- 5.458118095397949
- 2.63832820892334
- 3.535879198710124
- 3.3425871658325197
- 2.708408857981364
- 2.886313041051229
- 3.784494349161784
- 3.1305696137746177
- 3.1703495820363363
- 4.069174076716105
- 2.9739943313598634
- 2.951676918665568
- 3.023453400929769
- 3.1895901934305826
- 3.1904289023081462
- 2.4653120708465575
- 3.7056943448384603
- 2.4315298239390057
- 2.899964329401652
- 2.4165452988942464
- 2.572515961329142
- 2.572319081624349
- 3.3436215686798096
- 3.0676869996388754
- 2.6719346618652344
- 2.8992829195658367
- 2.3884980201721193
- 2.505896609624227
- 2.1760217571258544
- 2.565844554901123
- 2.5943696943918866
- 2.6066160011291504
- 3.1048279285430906
- 2.8327614466349282
- 2.786133610407511
- 2.6310175450642905
- 2.701226828893026
- 2.810781955718994
- 2.750926179885864
- 2.9409100596110025
- 2.848580799102783
- 2.749407122929891
- 2.841966501871745
- 2.9566190083821615
- 3.1913702233632404
- 2.5229905954996745
- 2.12707529703776
- 2.525689271291097
- 2.3105454508463543
- 2.4615763409932456
- 2.5404493904113767
- 2.5096111806233723
- 3.1649484475453695
- 2.6746896076202393
train_accuracy:
- 0.0
- 0.317
- 0.0
- 0.0
- 0.0
- 0.0
- 0.035
- 0.35
- 0.0
- 0.0
- 0.2
- 0.0
- 0.0
- 0.358
- 0.0
- 0.785
- 0.777
- 0.0
- 0.021
- 0.802
- 0.817
- 0.0
- 0.0
- 0.008
- 0.456
- 0.0
- 0.002
- 0.412
- 0.0
- 0.0
- 0.01
- 0.846
- 0.0
- 0.0
- 0.0
- 0.848
- 0.858
- 0.0
- 0.612
- 0.106
- 0.0
- 0.158
- 0.583
- 0.858
- 0.0
- 0.86
- 0.869
- 0.335
- 0.0
- 0.0
- 0.027
- 0.0
- 0.0
- 0.0
- 0.871
- 0.875
- 0.062
- 0.877
- 0.875
- 0.0
- 0.0
- 0.225
- 0.89
- 0.067
- 0.0
- 0.454
- 0.24
- 0.198
- 0.767
- 0.0
- 0.0
- 0.0
- 0.706
- 0.883
- 0.285
- 0.89
- 0.0
- 0.619
- 0.883
- 0.0
- 0.0
- 0.054
- 0.877
- 0.885
- 0.883
- 0.0
- 0.0
- 0.89
- 0.017
- 0.0
- 0.0
- 0.896
- 0.883
- 0.752
- 0.0
- 0.892
- 0.0
- 0.804
- 0.89
- 0.0
train_loss:
- 2.312
- 1.941
- 1.481
- 1.273
- 1.19
- 0.765
- 0.757
- 0.71
- 0.571
- 0.959
- 0.778
- 0.961
- 0.959
- 0.66
- 0.865
- 1.17
- 0.859
- 0.834
- 0.59
- 0.814
- 0.705
- 0.706
- 0.784
- 0.748
- 0.512
- 1.013
- 0.774
- 0.536
- 0.656
- 0.676
- 0.654
- 0.794
- 0.754
- 0.76
- 0.627
- 0.662
- 0.727
- 0.743
- 0.487
- 0.419
- 0.644
- 0.435
- 0.459
- 0.883
- 0.599
- 0.571
- 0.833
- 0.467
- 0.71
- 0.544
- 0.418
- 0.598
- 0.686
- 0.511
- 0.55
- 0.598
- 0.431
- 0.551
- 0.537
- 0.509
- 0.498
- 0.339
- 0.631
- 0.442
- 0.462
- 0.387
- 0.29
- 0.516
- 0.311
- 0.754
- 0.528
- 0.493
- 0.391
- 0.496
- 0.379
- 0.485
- 0.498
- 0.364
- 0.648
- 0.466
- 0.485
- 0.472
- 0.489
- 0.466
- 0.476
- 0.436
- 0.468
- 0.483
- 0.461
- 0.435
- 0.413
- 0.346
- 0.366
- 0.282
- 0.47
- 0.462
- 0.425
- 0.344
- 0.579
- 0.425
unequal: 0
verbose: 1
