avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.1225
- 0.19324468085106383
- 0.09664893617021277
- 0.09175531914893617
- 0.25957446808510637
- 0.25611702127659575
- 0.10595744680851064
- 0.12212765957446808
- 0.12654255319148935
- 0.2851063829787234
- 0.12159574468085106
- 0.27585106382978725
- 0.28095744680851065
- 0.14085106382978724
- 0.1630851063829787
- 0.2987234042553191
- 0.3025531914893617
- 0.3042021276595745
- 0.31111702127659574
- 0.30638297872340425
- 0.3105851063829787
- 0.31840425531914895
- 0.3273404255319149
- 0.3266489361702128
- 0.3261702127659574
- 0.20617021276595746
- 0.1595212765957447
- 0.3262765957446809
- 0.339468085106383
- 0.3498404255319149
- 0.3318617021276596
- 0.33287234042553193
- 0.23680851063829786
- 0.18888297872340426
- 0.1976595744680851
- 0.35627659574468085
- 0.22143617021276596
- 0.3398404255319149
- 0.34356382978723404
- 0.27654255319148935
- 0.3626595744680851
- 0.3504255319148936
- 0.3481382978723404
- 0.31813829787234044
- 0.3448936170212766
- 0.3475
- 0.25372340425531914
- 0.23180851063829788
- 0.3853191489361702
- 0.2531914893617021
- 0.35382978723404257
- 0.3665425531914894
- 0.36446808510638296
- 0.2861170212765957
- 0.38111702127659575
- 0.3601595744680851
- 0.35925531914893616
- 0.35781914893617023
- 0.34856382978723405
- 0.35335106382978726
- 0.34835106382978726
- 0.35095744680851065
- 0.3625
- 0.3621808510638298
- 0.35829787234042554
- 0.3579255319148936
- 0.37361702127659574
- 0.3727659574468085
- 0.37590425531914895
- 0.36734042553191487
- 0.3701063829787234
- 0.3776063829787234
- 0.3903723404255319
- 0.3638297872340426
- 0.3570744680851064
- 0.3672872340425532
- 0.35840425531914893
- 0.36648936170212765
- 0.33930851063829787
- 0.3879787234042553
- 0.3645212765957447
- 0.36127659574468085
- 0.386968085106383
- 0.37707446808510636
- 0.37186170212765957
- 0.37303191489361703
- 0.3904255319148936
- 0.375
- 0.3743085106382979
- 0.3557446808510638
- 0.37659574468085105
- 0.3925531914893617
- 0.37542553191489364
- 0.3695212765957447
- 0.3068085106382979
- 0.40904255319148936
- 0.37159574468085105
- 0.38691489361702125
- 0.39547872340425533
test_loss_list:
- 5.503715311686198
- 3.935053208669027
- 4.458247750600179
- 3.685957336425781
- 4.682661571502686
- 3.9356722609202066
- 4.313962697982788
- 3.9398346741994223
- 6.220747477213542
- 4.696443036397298
- 4.9067518997192385
- 4.1082808272043865
- 3.5938376903533937
- 3.7600865364074707
- 4.132781531016032
- 3.5648400084177654
- 3.909265702565511
- 4.3081509971618654
- 3.75489821434021
- 3.857329765955607
- 3.8497947311401366
- 4.124124698638916
- 4.108863611221313
- 5.99647247950236
- 3.607778838475545
- 3.938487869898478
- 3.578616040547689
- 4.3314365228017175
- 3.898755865097046
- 3.7457862854003907
- 3.6219440714518227
- 5.762345339457194
- 3.8091695340474447
- 3.094759241739909
- 3.6793034712473554
- 3.429846134185791
- 3.0985259024302163
- 3.4942265192667645
- 3.909936517079671
- 4.013267084757487
- 2.5932595411936443
- 3.2178194586435955
- 3.3726157029469808
- 3.092685899734497
- 2.5871725273132324
- 3.5352325121561687
- 2.739644988377889
- 4.312556629180908
- 3.390291395187378
- 3.0324484507242837
- 3.051724424362183
- 3.255241552988688
- 2.955060876210531
- 3.2233912118275962
- 2.6184053961435954
- 2.845665626525879
- 3.6648383458455402
- 3.1378372859954835
- 3.7763593037923178
- 3.290314064025879
- 3.1885667037963867
- 4.021825202306112
- 3.2914766470591226
- 3.4053151702880857
- 3.1492100938161216
- 3.3092808024088542
- 3.9424630069732665
- 3.184483108520508
- 3.0827775160471598
- 3.1811626307169596
- 3.3001463349660236
- 3.3278340752919515
- 3.1367679087320965
- 3.2525630092620847
- 3.808702964782715
- 4.219213558832805
- 3.959257844289144
- 4.03388944307963
- 3.1282841237386068
- 2.458714551925659
- 2.9070885435740155
- 3.389410651524862
- 3.885792338053385
- 3.0124462858835854
- 3.1285540294647216
- 3.1567765204111735
- 2.299199539820353
- 2.725732224782308
- 2.319971914291382
- 3.4631982612609864
- 2.3899376074473064
- 3.2114815521240234
- 2.709673611323039
- 3.6309056218465168
- 2.4815381654103597
- 3.1833441480000815
- 2.67037166595459
- 3.3781198596954347
- 3.597156902949015
- 2.7221357154846193
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.002
- 0.423
- 0.627
- 0.0
- 0.0
- 0.121
- 0.0
- 0.708
- 0.485
- 0.0
- 0.76
- 0.0
- 0.492
- 0.0
- 0.775
- 0.002
- 0.0
- 0.0
- 0.787
- 0.0
- 0.825
- 0.0
- 0.0
- 0.192
- 0.217
- 0.0
- 0.0
- 0.0
- 0.827
- 0.0
- 0.008
- 0.425
- 0.427
- 0.067
- 0.192
- 0.831
- 0.823
- 0.177
- 0.012
- 0.825
- 0.002
- 0.481
- 0.831
- 0.731
- 0.583
- 0.352
- 0.846
- 0.34
- 0.86
- 0.0
- 0.0
- 0.769
- 0.042
- 0.875
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.898
- 0.0
- 0.002
- 0.894
- 0.86
- 0.0
- 0.0
- 0.004
- 0.002
- 0.871
- 0.896
- 0.892
- 0.902
- 0.0
- 0.0
- 0.867
- 0.64
- 0.89
- 0.0
- 0.002
- 0.0
- 0.012
- 0.0
- 0.475
- 0.894
- 0.89
- 0.0
- 0.685
- 0.912
- 0.89
- 0.002
- 0.475
- 0.81
- 0.006
- 0.879
- 0.015
- 0.0
train_loss:
- 1.568
- 1.78
- 1.4
- 0.944
- 0.806
- 1.114
- 0.968
- 0.682
- 0.479
- 0.634
- 2.07
- 0.669
- 1.152
- 1.03
- 0.693
- 0.704
- 1.299
- 1.182
- 0.842
- 0.832
- 0.759
- 1.145
- 0.776
- 1.168
- 0.929
- 0.712
- 0.617
- 0.606
- 1.162
- 0.712
- 0.645
- 1.04
- 0.717
- 0.755
- 0.444
- 0.486
- 0.713
- 0.479
- 0.924
- 0.844
- 0.631
- 0.723
- 0.617
- 0.777
- 0.473
- 0.852
- 0.437
- 0.303
- 0.463
- 0.596
- 0.423
- 0.861
- 0.716
- 0.569
- 0.552
- 0.566
- 0.843
- 0.589
- 0.838
- 0.572
- 0.557
- 0.662
- 0.582
- 0.562
- 0.69
- 0.676
- 0.664
- 0.697
- 0.555
- 0.524
- 0.562
- 0.532
- 0.667
- 0.496
- 0.766
- 0.67
- 0.751
- 0.642
- 0.585
- 0.415
- 0.535
- 0.663
- 0.608
- 0.537
- 0.509
- 0.641
- 0.524
- 0.531
- 0.373
- 0.646
- 0.525
- 0.674
- 0.618
- 0.695
- 0.494
- 0.396
- 0.531
- 0.631
- 0.584
- 0.637
unequal: 0
verbose: 1
