avg_train_accuracy: 0.046
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027925531914893616
- 0.11409574468085107
- 0.23670212765957446
- 0.28414893617021275
- 0.3223936170212766
- 0.3385106382978723
- 0.34117021276595744
- 0.3719148936170213
- 0.3638297872340426
- 0.36781914893617024
- 0.3898936170212766
- 0.4002127659574468
- 0.3855851063829787
- 0.4051063829787234
- 0.40867021276595744
- 0.40962765957446806
- 0.43053191489361703
- 0.41297872340425534
- 0.43920212765957445
- 0.42154255319148937
- 0.43686170212765957
- 0.44
- 0.44930851063829785
- 0.44893617021276594
- 0.45
- 0.44430851063829785
- 0.451063829787234
- 0.4557978723404255
- 0.4597872340425532
- 0.460531914893617
- 0.4668617021276596
- 0.4660106382978723
- 0.4724468085106383
- 0.46867021276595744
- 0.4722872340425532
- 0.47585106382978726
- 0.47877659574468084
- 0.46861702127659577
- 0.4801063829787234
- 0.47638297872340424
- 0.48021276595744683
- 0.48212765957446807
- 0.4745744680851064
- 0.4765957446808511
- 0.4863297872340426
- 0.49164893617021277
- 0.479468085106383
- 0.48090425531914893
- 0.48909574468085104
- 0.4888297872340426
- 0.49356382978723407
- 0.4923936170212766
- 0.4972872340425532
- 0.49803191489361703
- 0.4991489361702128
- 0.49861702127659574
- 0.4897872340425532
- 0.5003191489361702
- 0.49909574468085105
- 0.49196808510638296
- 0.49792553191489364
- 0.5137765957446808
- 0.5131914893617021
- 0.5043085106382978
- 0.5171808510638298
- 0.5155851063829787
- 0.49882978723404253
- 0.5013297872340425
- 0.5101063829787233
- 0.5143617021276595
- 0.516595744680851
- 0.5081382978723404
- 0.5186702127659575
- 0.5081914893617021
- 0.526595744680851
- 0.5204255319148936
- 0.5232446808510638
- 0.5266489361702128
- 0.5212765957446809
- 0.5238297872340425
- 0.5192021276595745
- 0.5288829787234043
- 0.5215425531914893
- 0.5134042553191489
- 0.5162234042553191
- 0.535
- 0.5228723404255319
- 0.5091489361702127
- 0.5067553191489361
- 0.515531914893617
- 0.5341489361702128
- 0.5279255319148937
- 0.5059574468085106
- 0.5456914893617021
- 0.527127659574468
- 0.5405319148936171
- 0.524468085106383
- 0.5262765957446809
- 0.5232978723404256
- 0.5248404255319149
test_loss_list:
- 3.8131538359324137
- 3.711346991856893
- 3.550366923014323
- 3.349346497853597
- 3.272218325932821
- 3.1994090048472086
- 2.9471509710947674
- 3.048009443283081
- 2.91941686630249
- 2.896651268005371
- 2.885947825113932
- 3.100704666773478
- 2.8166320006052654
- 2.8073085753122964
- 2.7451722971598307
- 2.721636654535929
- 3.2463627020517984
- 2.4903835391998292
- 3.2530405362447103
- 2.7337828890482583
- 2.878327569961548
- 2.5752232678731284
- 2.8481003602345782
- 2.903304713567098
- 2.870178658167521
- 2.6282492955525716
- 2.4936378447214764
- 2.7353912003835044
- 2.754036537806193
- 2.4617743174235027
- 2.6767211087544758
- 2.44323450088501
- 2.7235812536875406
- 2.690360933939616
- 2.7365169779459637
- 2.705550731023153
- 2.65285169283549
- 2.580298449198405
- 2.625226306915283
- 2.8161382834116617
- 2.584003044764201
- 3.0495809586842855
- 2.5085812187194825
- 2.558104960123698
- 2.5580286502838137
- 2.2751995277404786
- 2.9040870730082196
- 2.4325399367014566
- 2.2962440808614093
- 2.557987804412842
- 2.4060381094614667
- 2.48466578801473
- 2.138775946299235
- 2.469725039800008
- 2.1148136949539182
- 2.480330743789673
- 2.2937274519602457
- 2.0729369862874347
- 2.4182014910380047
- 2.2408385213216144
- 2.68639541943868
- 1.8546806605656943
- 2.055023152033488
- 2.323816426595052
- 2.0173197841644286
- 2.017371335029602
- 2.2280080366134642
- 2.2490073299407958
- 2.2256468470891315
- 2.2173775100708006
- 2.296675591468811
- 1.9453983545303344
- 2.266764767964681
- 2.1858753045399983
- 1.7813763904571533
- 2.2666592756907145
- 1.9094886191685994
- 1.8634835386276245
- 2.1440023056666058
- 2.139669359525045
- 2.63386757850647
- 2.178726995786031
- 2.2130412912368773
- 2.145114491780599
- 1.838565870920817
- 1.6616787147521972
- 1.794575277964274
- 2.4019742997487388
- 2.377908484141032
- 2.065223019917806
- 1.8523816140492757
- 2.1560586516062417
- 2.3719396495819094
- 1.603812918663025
- 1.7971174732844035
- 1.8290280564626058
- 1.9313829708099366
- 2.0112346347173053
- 1.9493550666173298
- 1.939434601465861
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.446
- 0.527
- 0.0
- 0.0
- 0.621
- 0.638
- 0.0
- 0.698
- 0.677
- 0.0
- 0.681
- 0.733
- 0.733
- 0.74
- 0.742
- 0.0
- 0.008
- 0.0
- 0.006
- 0.771
- 0.0
- 0.002
- 0.0
- 0.002
- 0.777
- 0.0
- 0.019
- 0.002
- 0.017
- 0.812
- 0.008
- 0.817
- 0.819
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.829
- 0.838
- 0.004
- 0.0
- 0.0
- 0.842
- 0.817
- 0.829
- 0.006
- 0.0
- 0.856
- 0.842
- 0.0
- 0.838
- 0.844
- 0.829
- 0.002
- 0.002
- 0.854
- 0.846
- 0.002
- 0.844
- 0.84
- 0.0
- 0.033
- 0.844
- 0.863
- 0.871
- 0.844
- 0.863
- 0.852
- 0.021
- 0.019
- 0.846
- 0.873
- 0.019
- 0.008
- 0.873
- 0.004
- 0.875
- 0.86
- 0.852
- 0.846
- 0.846
- 0.854
- 0.037
- 0.875
- 0.865
- 0.017
- 0.002
- 0.0
- 0.04
- 0.021
- 0.008
- 0.883
- 0.865
- 0.892
- 0.865
- 0.046
train_loss:
- 2.443
- 2.416
- 2.424
- 1.837
- 1.651
- 1.561
- 1.11
- 1.22
- 1.209
- 1.152
- 1.098
- 1.181
- 1.068
- 0.996
- 0.964
- 0.99
- 1.229
- 0.842
- 1.161
- 1.066
- 1.0
- 0.897
- 0.963
- 0.933
- 0.921
- 0.842
- 0.841
- 0.905
- 0.894
- 0.781
- 0.863
- 0.761
- 0.852
- 0.828
- 0.867
- 0.809
- 0.829
- 0.859
- 0.81
- 0.903
- 0.79
- 0.86
- 0.849
- 0.812
- 0.766
- 0.673
- 0.878
- 0.788
- 0.704
- 0.766
- 0.741
- 0.743
- 0.643
- 0.761
- 0.662
- 0.73
- 0.747
- 0.628
- 0.723
- 0.731
- 0.765
- 0.563
- 0.629
- 0.676
- 0.603
- 0.588
- 0.721
- 0.702
- 0.709
- 0.673
- 0.663
- 0.621
- 0.661
- 0.689
- 0.521
- 0.675
- 0.591
- 0.566
- 0.633
- 0.637
- 0.719
- 0.633
- 0.632
- 0.677
- 0.583
- 0.495
- 0.566
- 0.736
- 0.726
- 0.622
- 0.574
- 0.615
- 0.689
- 0.496
- 0.562
- 0.553
- 0.634
- 0.634
- 0.61
- 0.632
unequal: 0
verbose: 1
