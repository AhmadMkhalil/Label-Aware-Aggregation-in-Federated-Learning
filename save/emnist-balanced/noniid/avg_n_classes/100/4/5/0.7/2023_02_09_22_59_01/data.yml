avg_train_accuracy: 0.102
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02526595744680851
- 0.09351063829787234
- 0.21840425531914895
- 0.2785106382978723
- 0.30553191489361703
- 0.3249468085106383
- 0.3465957446808511
- 0.35404255319148936
- 0.3658510638297872
- 0.3780851063829787
- 0.39882978723404255
- 0.394468085106383
- 0.39111702127659576
- 0.4023936170212766
- 0.411968085106383
- 0.4109042553191489
- 0.4192021276595745
- 0.42590425531914894
- 0.4220212765957447
- 0.4402659574468085
- 0.4325531914893617
- 0.43117021276595746
- 0.43898936170212766
- 0.43617021276595747
- 0.43861702127659574
- 0.44861702127659575
- 0.454468085106383
- 0.4505851063829787
- 0.46
- 0.4652659574468085
- 0.4672872340425532
- 0.46441489361702126
- 0.47106382978723405
- 0.46324468085106385
- 0.48095744680851066
- 0.47840425531914893
- 0.4776595744680851
- 0.4704255319148936
- 0.48409574468085104
- 0.48106382978723405
- 0.48090425531914893
- 0.48829787234042554
- 0.49106382978723406
- 0.4930851063829787
- 0.5001063829787235
- 0.4929787234042553
- 0.5030851063829788
- 0.4971276595744681
- 0.4991489361702128
- 0.49340425531914894
- 0.5034042553191489
- 0.49420212765957444
- 0.5126063829787234
- 0.5213297872340426
- 0.4996808510638298
- 0.49590425531914895
- 0.4948936170212766
- 0.516436170212766
- 0.5049468085106383
- 0.4938297872340425
- 0.4949468085106383
- 0.49898936170212765
- 0.5131382978723404
- 0.5075
- 0.5007446808510638
- 0.5080851063829788
- 0.5179787234042553
- 0.5021808510638298
- 0.5503191489361702
- 0.5065425531914893
- 0.5003723404255319
- 0.5208510638297872
- 0.5102659574468085
- 0.5267021276595745
- 0.5169148936170213
- 0.5138829787234043
- 0.5494148936170212
- 0.5467021276595745
- 0.5654255319148936
- 0.5236702127659575
- 0.5562234042553191
- 0.5178191489361702
- 0.5739893617021277
- 0.5676595744680851
- 0.5328723404255319
- 0.5335106382978724
- 0.5498936170212766
- 0.515904255319149
- 0.5304787234042553
- 0.5230851063829787
- 0.5490425531914893
- 0.5069148936170212
- 0.5579787234042554
- 0.5259574468085106
- 0.5570212765957446
- 0.528031914893617
- 0.5319148936170213
- 0.5438829787234043
- 0.530904255319149
- 0.5428191489361702
test_loss_list:
- 3.8439789040883383
- 3.8201655260721843
- 3.572484261194865
- 3.346288382212321
- 3.3317731602986655
- 3.0813745244344077
- 3.0304911454518635
- 2.991458708445231
- 2.9505089982350667
- 2.8672911802927654
- 3.3355728912353517
- 3.277767082850138
- 2.9522478644053143
- 3.018104874293009
- 2.942016611099243
- 2.947081832885742
- 2.67793776512146
- 2.9143778610229494
- 2.4756749629974366
- 3.278208627700806
- 2.8039987246195475
- 2.611144749323527
- 2.834455690383911
- 2.536361296971639
- 2.5376848475138347
- 2.7481361961364748
- 2.4510747973124185
- 2.5145417976379396
- 2.4354445521036783
- 2.2416555722554525
- 2.632483358383179
- 2.55682515780131
- 2.610778388977051
- 2.641570421854655
- 2.1231535132726034
- 2.3162560208638507
- 2.4897986761728923
- 2.491219924290975
- 2.2357485818862917
- 2.536349713007609
- 2.198626068433126
- 2.4706356143951416
- 2.1605500920613605
- 2.1956957324345905
- 2.1471505959828696
- 2.47334542910258
- 2.1311790211995443
- 2.1957216517130536
- 2.119867502848307
- 2.104806342124939
- 2.083767272631327
- 2.4185968399047852
- 2.0275063721338906
- 1.890972367922465
- 2.317469007174174
- 2.248578871091207
- 2.346719512939453
- 2.030447926521301
- 2.2942862764994305
- 2.747251443862915
- 2.1997466866175333
- 2.3171504322687784
- 1.981900725364685
- 2.301572192509969
- 2.1654986270268757
- 2.180218097368876
- 1.9636309083302816
- 2.2155662457148235
- 1.6888391145070394
- 2.195144993464152
- 2.512582680384318
- 2.1119454288482666
- 2.167316427230835
- 2.1552245791753135
- 2.178102757136027
- 2.1152265516916913
- 1.8245237064361572
- 1.8663022597630818
- 1.6456898625691732
- 2.148628797531128
- 1.7584655857086182
- 2.171957564353943
- 1.5625057872136434
- 1.6468646558125815
- 2.0215026632944744
- 2.0284176874160766
- 1.7941887172063191
- 2.40794376373291
- 2.0612752119700115
- 2.089319038391113
- 1.7409048954645792
- 2.5018139044443766
- 1.719407664934794
- 2.0292146762212115
- 1.7423464425404867
- 1.9920420932769776
- 2.016319955190023
- 1.9492568079630535
- 2.033124944368998
- 1.95981907526652
train_accuracy:
- 0.035
- 0.0
- 0.0
- 0.46
- 0.0
- 0.571
- 0.617
- 0.0
- 0.644
- 0.671
- 0.721
- 0.688
- 0.646
- 0.702
- 0.0
- 0.727
- 0.002
- 0.721
- 0.0
- 0.758
- 0.0
- 0.0
- 0.0
- 0.76
- 0.727
- 0.796
- 0.0
- 0.76
- 0.802
- 0.0
- 0.798
- 0.773
- 0.0
- 0.783
- 0.0
- 0.792
- 0.794
- 0.0
- 0.029
- 0.0
- 0.04
- 0.794
- 0.0
- 0.0
- 0.825
- 0.0
- 0.0
- 0.0
- 0.815
- 0.825
- 0.0
- 0.825
- 0.815
- 0.0
- 0.0
- 0.84
- 0.006
- 0.0
- 0.856
- 0.831
- 0.012
- 0.0
- 0.0
- 0.0
- 0.002
- 0.842
- 0.031
- 0.844
- 0.829
- 0.84
- 0.838
- 0.0
- 0.877
- 0.842
- 0.008
- 0.01
- 0.0
- 0.044
- 0.867
- 0.0
- 0.867
- 0.877
- 0.838
- 0.833
- 0.877
- 0.885
- 0.835
- 0.844
- 0.0
- 0.848
- 0.854
- 0.879
- 0.852
- 0.0
- 0.01
- 0.844
- 0.033
- 0.004
- 0.858
- 0.102
train_loss:
- 2.826
- 2.168
- 2.152
- 1.873
- 1.645
- 1.364
- 1.303
- 1.2
- 1.156
- 1.14
- 1.438
- 1.403
- 1.187
- 1.171
- 1.179
- 1.107
- 0.979
- 1.065
- 0.789
- 1.181
- 1.029
- 0.862
- 0.959
- 0.828
- 0.812
- 0.954
- 0.807
- 0.783
- 0.787
- 0.662
- 0.901
- 0.875
- 0.864
- 0.863
- 0.631
- 0.731
- 0.841
- 0.823
- 0.714
- 0.81
- 0.693
- 0.809
- 0.69
- 0.683
- 0.674
- 0.765
- 0.663
- 0.678
- 0.666
- 0.652
- 0.649
- 0.74
- 0.643
- 0.545
- 0.728
- 0.726
- 0.711
- 0.624
- 0.73
- 0.795
- 0.712
- 0.693
- 0.606
- 0.703
- 0.695
- 0.707
- 0.605
- 0.673
- 0.514
- 0.678
- 0.756
- 0.685
- 0.661
- 0.677
- 0.667
- 0.653
- 0.58
- 0.566
- 0.483
- 0.653
- 0.571
- 0.642
- 0.483
- 0.461
- 0.645
- 0.642
- 0.555
- 0.72
- 0.63
- 0.627
- 0.553
- 0.695
- 0.548
- 0.627
- 0.542
- 0.609
- 0.605
- 0.625
- 0.615
- 0.623
unequal: 0
verbose: 1
