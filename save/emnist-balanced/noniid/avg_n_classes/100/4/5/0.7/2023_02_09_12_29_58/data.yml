avg_train_accuracy: 0.023
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.039521276595744684
- 0.1301595744680851
- 0.24143617021276595
- 0.274468085106383
- 0.3026063829787234
- 0.3076063829787234
- 0.3209574468085106
- 0.3459042553191489
- 0.3525531914893617
- 0.3671808510638298
- 0.38968085106382977
- 0.39111702127659576
- 0.39101063829787236
- 0.4
- 0.41058510638297874
- 0.4081382978723404
- 0.4179787234042553
- 0.42186170212765955
- 0.4282446808510638
- 0.43367021276595746
- 0.4406914893617021
- 0.4398404255319149
- 0.43707446808510636
- 0.44670212765957445
- 0.45101063829787236
- 0.448563829787234
- 0.4632978723404255
- 0.46239361702127657
- 0.46867021276595744
- 0.4671276595744681
- 0.48696808510638295
- 0.46702127659574466
- 0.4852659574468085
- 0.475531914893617
- 0.4948404255319149
- 0.4826063829787234
- 0.47664893617021276
- 0.4948936170212766
- 0.49111702127659573
- 0.511968085106383
- 0.4902659574468085
- 0.5021808510638298
- 0.4899468085106383
- 0.5005851063829787
- 0.4971276595744681
- 0.49234042553191487
- 0.4997340425531915
- 0.5065425531914893
- 0.5042553191489362
- 0.5037234042553191
- 0.5106914893617022
- 0.5197872340425532
- 0.5066489361702128
- 0.5087234042553191
- 0.5172340425531915
- 0.5288829787234043
- 0.5106382978723404
- 0.5207446808510638
- 0.5181382978723404
- 0.5018085106382979
- 0.5039361702127659
- 0.5268617021276596
- 0.5109574468085106
- 0.4996276595744681
- 0.5117553191489361
- 0.5326595744680851
- 0.5163297872340425
- 0.5360106382978723
- 0.5051595744680851
- 0.505
- 0.5323404255319149
- 0.5177127659574469
- 0.5274468085106383
- 0.5223404255319148
- 0.531595744680851
- 0.5488829787234043
- 0.5282446808510638
- 0.5771276595744681
- 0.5273404255319148
- 0.5406382978723404
- 0.5596276595744681
- 0.5527127659574468
- 0.5249468085106384
- 0.5372872340425532
- 0.5599468085106383
- 0.5326063829787234
- 0.5302659574468085
- 0.5677127659574468
- 0.5912234042553192
- 0.5736702127659574
- 0.5182978723404256
- 0.5644148936170212
- 0.5347872340425532
- 0.5656914893617021
- 0.5454255319148936
- 0.5732446808510638
- 0.5398404255319149
- 0.5522340425531915
- 0.5534042553191489
- 0.5754787234042553
test_loss_list:
- 3.7879167779286704
- 3.7324755668640135
- 3.5660792541503907
- 3.18843466758728
- 3.178195603688558
- 2.9811774508158364
- 2.930060895284017
- 2.977080103556315
- 2.7766029167175295
- 2.740363416671753
- 2.889103940327962
- 3.107048648198446
- 2.875933542251587
- 2.5932043266296385
- 2.8377444076538088
- 2.7702509371439614
- 2.5228645992279053
- 2.5363487720489504
- 2.3914961846669516
- 2.669897362391154
- 2.581823155085246
- 2.3724230257670085
- 2.5369305070241293
- 2.5378700796763103
- 2.36214075088501
- 2.960848331451416
- 2.263318190574646
- 2.3410727691650393
- 2.152346731821696
- 2.1996174176534016
- 1.953990600903829
- 2.505689884821574
- 2.0449576791127524
- 2.4948650232950844
- 1.9932635021209717
- 2.0882244062423707
- 2.216760188738505
- 1.976788821220398
- 2.035720739364624
- 1.8847547149658204
- 2.175746768315633
- 1.944779052734375
- 2.2031708558400473
- 1.9633051919937134
- 2.105521674156189
- 2.1725982268651327
- 2.077673637072245
- 1.8901903947194418
- 1.9001142358779908
- 2.0442648188273114
- 1.8718488279978434
- 1.8534192085266112
- 2.143391687075297
- 2.051629408200582
- 1.8489268906911214
- 1.76795338789622
- 2.111313261985779
- 1.9525415976842244
- 2.059434537887573
- 2.495565849939982
- 2.00988218943278
- 1.7223582855860393
- 2.046057875951131
- 2.3647881650924685
- 1.9653989823659261
- 1.7375790325800577
- 2.03565069993337
- 1.7151542584101358
- 2.3506407896677652
- 2.2066225385665894
- 1.7528461488087972
- 2.029029752413432
- 1.875577311515808
- 1.9978216393788655
- 1.875018048286438
- 1.7059290313720703
- 1.8715076923370362
- 1.4424309428532918
- 1.9580549017588298
- 1.8682918373743693
- 1.6070478455225627
- 1.6322104628880818
- 1.904130260149638
- 1.823483584721883
- 1.5908353249231975
- 1.8577379163106282
- 1.8954927587509156
- 1.6125226179758707
- 1.4090092913309733
- 1.5935839303334554
- 2.2411599922180176
- 1.5611087735493978
- 1.8519684060414632
- 1.558416771888733
- 1.8395013221104939
- 1.520164187749227
- 1.848711298306783
- 1.7753451379140217
- 1.863728591601054
- 1.5356046597162882
train_accuracy:
- 0.0
- 0.198
- 0.0
- 0.525
- 0.0
- 0.0
- 0.0
- 0.608
- 0.002
- 0.633
- 0.683
- 0.0
- 0.0
- 0.679
- 0.0
- 0.715
- 0.0
- 0.731
- 0.733
- 0.785
- 0.746
- 0.733
- 0.763
- 0.0
- 0.76
- 0.775
- 0.765
- 0.052
- 0.077
- 0.0
- 0.0
- 0.796
- 0.8
- 0.0
- 0.765
- 0.002
- 0.002
- 0.808
- 0.0
- 0.798
- 0.006
- 0.0
- 0.825
- 0.806
- 0.0
- 0.829
- 0.004
- 0.004
- 0.004
- 0.088
- 0.0
- 0.838
- 0.829
- 0.865
- 0.0
- 0.0
- 0.821
- 0.852
- 0.852
- 0.831
- 0.844
- 0.825
- 0.854
- 0.073
- 0.006
- 0.031
- 0.819
- 0.0
- 0.0
- 0.854
- 0.0
- 0.858
- 0.844
- 0.0
- 0.848
- 0.85
- 0.871
- 0.798
- 0.873
- 0.863
- 0.002
- 0.0
- 0.0
- 0.838
- 0.175
- 0.856
- 0.0
- 0.133
- 0.846
- 0.856
- 0.873
- 0.033
- 0.848
- 0.029
- 0.002
- 0.881
- 0.877
- 0.879
- 0.885
- 0.023
train_loss:
- 2.89
- 2.481
- 2.544
- 1.629
- 1.678
- 1.316
- 1.23
- 1.384
- 1.161
- 1.099
- 1.269
- 1.377
- 1.164
- 1.004
- 1.125
- 1.084
- 0.946
- 0.908
- 0.874
- 1.019
- 0.984
- 0.866
- 0.967
- 0.958
- 0.829
- 1.031
- 0.811
- 0.781
- 0.776
- 0.748
- 0.625
- 0.847
- 0.735
- 0.838
- 0.717
- 0.695
- 0.811
- 0.707
- 0.675
- 0.674
- 0.788
- 0.681
- 0.757
- 0.65
- 0.764
- 0.768
- 0.75
- 0.641
- 0.63
- 0.73
- 0.617
- 0.61
- 0.718
- 0.72
- 0.612
- 0.605
- 0.68
- 0.684
- 0.673
- 0.781
- 0.697
- 0.605
- 0.675
- 0.782
- 0.677
- 0.578
- 0.644
- 0.565
- 0.769
- 0.744
- 0.568
- 0.658
- 0.648
- 0.653
- 0.635
- 0.576
- 0.65
- 0.474
- 0.634
- 0.64
- 0.537
- 0.539
- 0.631
- 0.615
- 0.536
- 0.632
- 0.615
- 0.555
- 0.445
- 0.541
- 0.709
- 0.535
- 0.613
- 0.529
- 0.608
- 0.517
- 0.593
- 0.606
- 0.597
- 0.533
unequal: 0
verbose: 1
