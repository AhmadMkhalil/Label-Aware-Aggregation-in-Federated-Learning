avg_train_accuracy: 0.879
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.050425531914893615
- 0.14303191489361702
- 0.22228723404255318
- 0.2677127659574468
- 0.2870744680851064
- 0.345
- 0.33904255319148935
- 0.3548936170212766
- 0.37138297872340426
- 0.36861702127659574
- 0.3928191489361702
- 0.394468085106383
- 0.40037234042553194
- 0.4078191489361702
- 0.40547872340425534
- 0.41356382978723405
- 0.41771276595744683
- 0.42595744680851066
- 0.42329787234042554
- 0.4327659574468085
- 0.4319148936170213
- 0.43803191489361704
- 0.44398936170212766
- 0.44117021276595747
- 0.4427127659574468
- 0.45143617021276594
- 0.45632978723404255
- 0.4520744680851064
- 0.45824468085106385
- 0.46106382978723404
- 0.45861702127659576
- 0.4620744680851064
- 0.47382978723404257
- 0.4631914893617021
- 0.4651063829787234
- 0.46877659574468084
- 0.4714893617021277
- 0.47074468085106386
- 0.4747340425531915
- 0.47132978723404256
- 0.49090425531914894
- 0.4958510638297872
- 0.4908510638297872
- 0.4826063829787234
- 0.49606382978723407
- 0.4829787234042553
- 0.5036702127659575
- 0.48531914893617023
- 0.49872340425531914
- 0.5006382978723404
- 0.5030851063829788
- 0.4958510638297872
- 0.485
- 0.518936170212766
- 0.49175531914893617
- 0.508031914893617
- 0.5272872340425532
- 0.5314893617021277
- 0.4901063829787234
- 0.5089893617021276
- 0.5044148936170213
- 0.5003723404255319
- 0.5138297872340426
- 0.5098936170212766
- 0.523936170212766
- 0.5110638297872341
- 0.5354787234042553
- 0.5452659574468085
- 0.5145744680851064
- 0.5030851063829788
- 0.5148936170212766
- 0.5282978723404256
- 0.5073404255319149
- 0.5087234042553191
- 0.5177127659574469
- 0.5166489361702128
- 0.544468085106383
- 0.5364361702127659
- 0.5334574468085106
- 0.5154255319148936
- 0.5472340425531915
- 0.5044148936170213
- 0.546595744680851
- 0.5364361702127659
- 0.5253191489361703
- 0.5661170212765958
- 0.5658510638297872
- 0.5255319148936171
- 0.5545744680851064
- 0.5441489361702128
- 0.5526063829787234
- 0.5299468085106382
- 0.5506382978723404
- 0.5372340425531915
- 0.5245212765957447
- 0.5396276595744681
- 0.5609042553191489
- 0.5485106382978724
- 0.5290425531914894
- 0.5312765957446809
test_loss_list:
- 3.8193612194061277
- 3.7052186234792073
- 3.545897518793742
- 3.329840847651164
- 3.2172405687967935
- 3.2323187446594237
- 3.0173011525472004
- 3.1604367097218833
- 2.9454324531555174
- 2.901288293202718
- 3.1387109375
- 2.98006023089091
- 3.023667364120483
- 3.0652811018625896
- 2.701833403905233
- 2.7642557112375896
- 2.65152645111084
- 2.5757776260375977
- 2.7622091356913248
- 2.8163463179270427
- 2.5234938557942708
- 2.7352117125193276
- 2.7100668811798094
- 2.442503499984741
- 2.6030199019114177
- 2.9799500433603923
- 2.3577178128560385
- 2.3242142550150553
- 2.2566352478663125
- 2.3399867026011147
- 2.476923211415609
- 2.5007179991404214
- 2.251700092951457
- 2.7561551475524904
- 2.456658706665039
- 2.4267070293426514
- 2.341987330118815
- 2.430452995300293
- 2.2196368932724
- 2.5062597529093424
- 2.0637081384658815
- 2.079772605895996
- 2.1202536980311075
- 2.4601193841298423
- 2.064217758178711
- 2.3832464536031086
- 2.0063608328501386
- 2.4038285986582437
- 2.080990621248881
- 2.030978619257609
- 1.9847768513361612
- 2.236226151784261
- 2.6311061223347982
- 1.9194497569402058
- 2.3316518545150755
- 1.9858416652679443
- 1.7845097955067952
- 1.7759401194254558
- 2.7452411142985027
- 2.0802336724599204
- 2.118757232030233
- 2.239591833750407
- 1.9922794644037882
- 2.21618235429128
- 1.8833023961385091
- 2.2267253541946412
- 1.7842991240819295
- 1.6938375282287597
- 2.1851323874791464
- 2.571398572921753
- 2.139572122891744
- 1.9426471853256226
- 2.1641944440205894
- 2.164378670056661
- 2.0572763442993165
- 2.1859074703852337
- 1.7695303376515705
- 1.8602323087056478
- 1.8602016671498616
- 2.1563446442286174
- 1.7300334612528483
- 2.4886529223124185
- 1.7325249417622883
- 1.8502441867192587
- 2.0471424070994058
- 1.5825912777582805
- 1.5725766658782958
- 1.9889696041742961
- 1.6887868547439575
- 1.7682581106821695
- 1.706597482363383
- 1.9562326574325561
- 1.7244800758361816
- 1.9530061292648315
- 2.049346359570821
- 1.9209713045756023
- 1.6829342126846314
- 1.744787998199463
- 2.0406205813090006
- 2.083687391281128
train_accuracy:
- 0.0
- 0.298
- 0.0
- 0.469
- 0.0
- 0.0
- 0.552
- 0.0
- 0.662
- 0.017
- 0.0
- 0.66
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.006
- 0.752
- 0.727
- 0.027
- 0.76
- 0.763
- 0.0
- 0.0
- 0.773
- 0.019
- 0.0
- 0.777
- 0.0
- 0.773
- 0.0
- 0.781
- 0.821
- 0.8
- 0.0
- 0.794
- 0.825
- 0.0
- 0.815
- 0.81
- 0.792
- 0.0
- 0.806
- 0.0
- 0.821
- 0.0
- 0.815
- 0.802
- 0.831
- 0.823
- 0.0
- 0.84
- 0.835
- 0.835
- 0.0
- 0.794
- 0.817
- 0.0
- 0.842
- 0.844
- 0.825
- 0.84
- 0.825
- 0.831
- 0.0
- 0.0
- 0.0
- 0.823
- 0.86
- 0.858
- 0.035
- 0.854
- 0.0
- 0.017
- 0.015
- 0.835
- 0.827
- 0.025
- 0.871
- 0.033
- 0.006
- 0.827
- 0.031
- 0.84
- 0.0
- 0.027
- 0.008
- 0.027
- 0.85
- 0.002
- 0.0
- 0.008
- 0.104
- 0.86
- 0.002
- 0.077
- 0.848
- 0.01
- 0.879
train_loss:
- 2.757
- 2.426
- 2.04
- 1.559
- 1.478
- 1.536
- 1.247
- 1.392
- 1.145
- 1.09
- 1.221
- 1.159
- 1.16
- 1.146
- 0.972
- 0.944
- 0.905
- 0.904
- 1.0
- 1.005
- 0.857
- 0.987
- 0.956
- 0.811
- 0.891
- 1.025
- 0.78
- 0.759
- 0.758
- 0.76
- 0.845
- 0.863
- 0.734
- 0.949
- 0.834
- 0.8
- 0.805
- 0.792
- 0.711
- 0.796
- 0.669
- 0.65
- 0.654
- 0.756
- 0.683
- 0.763
- 0.661
- 0.746
- 0.651
- 0.656
- 0.633
- 0.716
- 0.81
- 0.615
- 0.723
- 0.625
- 0.522
- 0.507
- 0.794
- 0.683
- 0.683
- 0.697
- 0.596
- 0.678
- 0.587
- 0.667
- 0.571
- 0.48
- 0.659
- 0.728
- 0.667
- 0.556
- 0.667
- 0.657
- 0.665
- 0.644
- 0.579
- 0.549
- 0.566
- 0.629
- 0.567
- 0.725
- 0.574
- 0.537
- 0.599
- 0.47
- 0.461
- 0.631
- 0.545
- 0.549
- 0.539
- 0.604
- 0.524
- 0.612
- 0.606
- 0.61
- 0.518
- 0.529
- 0.606
- 0.595
unequal: 0
verbose: 1
