avg_train_accuracy: 0.006
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03228723404255319
- 0.12925531914893618
- 0.20117021276595745
- 0.28180851063829787
- 0.33861702127659576
- 0.33622340425531916
- 0.3649468085106383
- 0.3565957446808511
- 0.3829255319148936
- 0.3784574468085106
- 0.38409574468085106
- 0.405
- 0.40058510638297873
- 0.40377659574468083
- 0.40893617021276596
- 0.4186170212765957
- 0.4107446808510638
- 0.43420212765957444
- 0.42127659574468085
- 0.441063829787234
- 0.43356382978723407
- 0.4351595744680851
- 0.4542553191489362
- 0.4599468085106383
- 0.45122340425531915
- 0.4532978723404255
- 0.4650531914893617
- 0.46382978723404256
- 0.459468085106383
- 0.4602127659574468
- 0.46239361702127657
- 0.46111702127659576
- 0.4675531914893617
- 0.4775531914893617
- 0.4725531914893617
- 0.469468085106383
- 0.473031914893617
- 0.47425531914893615
- 0.4812234042553192
- 0.47382978723404257
- 0.4725
- 0.48148936170212764
- 0.47877659574468084
- 0.4823936170212766
- 0.4776595744680851
- 0.47723404255319146
- 0.4953723404255319
- 0.485531914893617
- 0.5007446808510638
- 0.4876063829787234
- 0.5021808510638298
- 0.4778191489361702
- 0.5045744680851064
- 0.49042553191489363
- 0.4975531914893617
- 0.5005851063829787
- 0.49414893617021277
- 0.48904255319148937
- 0.5010106382978723
- 0.4893085106382979
- 0.4980851063829787
- 0.503031914893617
- 0.505
- 0.49234042553191487
- 0.5138297872340426
- 0.5044148936170213
- 0.4915425531914894
- 0.5053191489361702
- 0.5020744680851064
- 0.4946808510638298
- 0.5126063829787234
- 0.4953723404255319
- 0.5154787234042553
- 0.4975531914893617
- 0.520531914893617
- 0.49829787234042555
- 0.4977659574468085
- 0.5083510638297872
- 0.5062765957446809
- 0.5196808510638298
- 0.49946808510638296
- 0.5099468085106383
- 0.5128191489361702
- 0.5003191489361702
- 0.5047872340425532
- 0.5027127659574468
- 0.5027659574468085
- 0.5118617021276596
- 0.5057978723404255
- 0.5323404255319149
- 0.5206382978723404
- 0.5052127659574468
- 0.5172340425531915
- 0.5226063829787234
- 0.5319148936170213
- 0.508031914893617
- 0.5264893617021277
- 0.5114893617021277
- 0.5279787234042553
- 0.5195744680851064
test_loss_list:
- 3.8423256429036456
- 3.7985896396636964
- 3.4999475797017414
- 3.362270482381185
- 3.3673714351654054
- 3.1429229513804118
- 3.15059489885966
- 2.8984778626759846
- 3.0560084279378255
- 2.9859186744689943
- 2.974617983500163
- 2.9730429617563883
- 3.1801519775390625
- 3.2345646826426186
- 2.858542814254761
- 3.2311462211608886
- 2.7714099788665774
- 3.270405782063802
- 2.7704503854115803
- 3.8138081582387287
- 2.516424051920573
- 2.5792196559906007
- 3.7647089703877765
- 2.6945694001515705
- 2.9079663308461505
- 2.727663065592448
- 3.2749132347106933
- 3.844693552652995
- 3.1329287624359132
- 2.6892155043284096
- 2.779214967091878
- 3.6138447602589925
- 2.9654752254486083
- 2.8477840932210285
- 2.6650336265563963
- 3.087955280939738
- 3.0850161266326905
- 3.068741579055786
- 3.925889485677083
- 2.883525848388672
- 2.980385805765788
- 2.42678027788798
- 2.6666267681121827
- 2.576908232371012
- 2.917652339935303
- 2.8973897139231366
- 2.2695103677113853
- 3.0332197761535644
- 2.525449364980062
- 2.9106724707285565
- 2.518692760467529
- 2.7561190350850424
- 2.4331243069966635
- 2.8127610588073733
- 2.395542933146159
- 2.5233530044555663
- 2.945160598754883
- 2.336994717915853
- 2.9567665576934816
- 2.7260850111643475
- 2.3691437530517576
- 2.3635947481791177
- 2.917504479090373
- 3.3654605611165365
- 2.3365265973409017
- 2.3729283173878986
- 2.708893019358317
- 2.381046330134074
- 2.976762628555298
- 2.638359759648641
- 2.509341068267822
- 2.701254758834839
- 2.0228663444519044
- 3.487600015004476
- 1.9169642464319865
- 3.3485764535268148
- 3.293980423609416
- 2.1681460682551066
- 2.360030771891276
- 2.322321898142497
- 2.6041045316060383
- 2.7590147399902345
- 2.2418630568186444
- 2.614634081522624
- 2.5079897340138753
- 2.452019872665405
- 2.577778116861979
- 2.268762404123942
- 2.5269507694244386
- 1.89516326268514
- 2.2255390803019206
- 2.4969324016571046
- 2.0598252487182616
- 2.1979691791534424
- 2.1613433249791463
- 2.5586885325113933
- 2.117432888348897
- 2.540260601043701
- 2.1051454067230226
- 2.4522935803731283
train_accuracy:
- 0.067
- 0.202
- 0.0
- 0.0
- 0.556
- 0.61
- 0.681
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.669
- 0.0
- 0.769
- 0.69
- 0.0
- 0.737
- 0.0
- 0.733
- 0.0
- 0.733
- 0.783
- 0.0
- 0.0
- 0.775
- 0.787
- 0.823
- 0.8
- 0.798
- 0.815
- 0.81
- 0.794
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.804
- 0.775
- 0.0
- 0.008
- 0.0
- 0.0
- 0.79
- 0.852
- 0.0
- 0.006
- 0.052
- 0.802
- 0.0
- 0.002
- 0.817
- 0.0
- 0.827
- 0.844
- 0.023
- 0.838
- 0.0
- 0.85
- 0.848
- 0.002
- 0.0
- 0.875
- 0.869
- 0.873
- 0.006
- 0.0
- 0.012
- 0.0
- 0.033
- 0.856
- 0.838
- 0.877
- 0.106
- 0.881
- 0.829
- 0.0
- 0.0
- 0.887
- 0.89
- 0.875
- 0.0
- 0.0
- 0.0
- 0.877
- 0.825
- 0.865
- 0.0
- 0.0
- 0.838
- 0.035
- 0.858
- 0.008
- 0.858
- 0.873
- 0.062
- 0.883
- 0.84
- 0.006
train_loss:
- 2.827
- 2.091
- 1.42
- 1.531
- 1.73
- 1.275
- 1.224
- 0.938
- 1.117
- 1.102
- 1.053
- 1.053
- 1.206
- 1.155
- 0.949
- 1.147
- 0.924
- 1.111
- 0.901
- 1.203
- 0.764
- 0.689
- 1.153
- 0.86
- 0.822
- 0.847
- 0.967
- 1.075
- 0.956
- 0.793
- 0.75
- 1.031
- 0.932
- 0.754
- 0.735
- 0.856
- 0.84
- 0.832
- 0.949
- 0.901
- 0.831
- 0.633
- 0.725
- 0.713
- 0.813
- 0.836
- 0.573
- 0.82
- 0.703
- 0.795
- 0.681
- 0.792
- 0.684
- 0.789
- 0.659
- 0.661
- 0.752
- 0.656
- 0.757
- 0.761
- 0.657
- 0.642
- 0.737
- 0.848
- 0.656
- 0.632
- 0.714
- 0.635
- 0.715
- 0.714
- 0.615
- 0.708
- 0.515
- 0.795
- 0.555
- 0.799
- 0.788
- 0.642
- 0.595
- 0.599
- 0.687
- 0.686
- 0.585
- 0.659
- 0.666
- 0.68
- 0.671
- 0.567
- 0.66
- 0.495
- 0.544
- 0.646
- 0.597
- 0.56
- 0.554
- 0.677
- 0.547
- 0.629
- 0.538
- 0.66
unequal: 0
verbose: 1
