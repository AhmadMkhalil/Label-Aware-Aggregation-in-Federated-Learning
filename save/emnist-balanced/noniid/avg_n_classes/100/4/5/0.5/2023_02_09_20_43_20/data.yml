avg_train_accuracy: 0.871
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03212765957446809
- 0.08611702127659575
- 0.21664893617021277
- 0.2763829787234043
- 0.32340425531914896
- 0.3363829787234043
- 0.3601063829787234
- 0.38393617021276594
- 0.3842553191489362
- 0.3964893617021277
- 0.3903191489361702
- 0.3948936170212766
- 0.40632978723404256
- 0.42117021276595745
- 0.4077659574468085
- 0.4279787234042553
- 0.42898936170212765
- 0.4263297872340426
- 0.4426063829787234
- 0.43686170212765957
- 0.4426063829787234
- 0.44659574468085106
- 0.446968085106383
- 0.44590425531914896
- 0.4517553191489362
- 0.44872340425531915
- 0.45622340425531915
- 0.4451063829787234
- 0.4548936170212766
- 0.45574468085106384
- 0.4673404255319149
- 0.4682978723404255
- 0.46606382978723404
- 0.46691489361702126
- 0.4698936170212766
- 0.4725531914893617
- 0.47452127659574467
- 0.4742021276595745
- 0.47297872340425534
- 0.4775
- 0.47297872340425534
- 0.48021276595744683
- 0.4793085106382979
- 0.4735106382978723
- 0.47898936170212764
- 0.47882978723404257
- 0.4820744680851064
- 0.4823936170212766
- 0.4818085106382979
- 0.48819148936170215
- 0.485
- 0.48271276595744683
- 0.4869148936170213
- 0.49
- 0.48654255319148937
- 0.4879787234042553
- 0.48648936170212764
- 0.4896276595744681
- 0.4869148936170213
- 0.4950531914893617
- 0.4922872340425532
- 0.49377659574468086
- 0.4997872340425532
- 0.5067553191489361
- 0.4980851063829787
- 0.495
- 0.49101063829787234
- 0.4952659574468085
- 0.4945212765957447
- 0.48861702127659573
- 0.4926595744680851
- 0.4959574468085106
- 0.5002127659574468
- 0.5095744680851064
- 0.5010638297872341
- 0.5102659574468085
- 0.4932446808510638
- 0.4959574468085106
- 0.5028723404255319
- 0.5157978723404255
- 0.5034574468085107
- 0.4973936170212766
- 0.5050531914893617
- 0.5034042553191489
- 0.5025
- 0.49840425531914895
- 0.500904255319149
- 0.5013829787234042
- 0.5129255319148937
- 0.5049468085106383
- 0.5118617021276596
- 0.5042021276595745
- 0.5096276595744681
- 0.5277127659574468
- 0.5010106382978723
- 0.5104255319148936
- 0.5268085106382979
- 0.5113829787234042
- 0.505
- 0.5074468085106383
test_loss_list:
- 3.807177438735962
- 3.831568489074707
- 3.6223082033793133
- 3.3258036835988363
- 3.2218794345855715
- 3.0671400260925292
- 3.0649112764994304
- 3.239084227879842
- 3.294965372085571
- 3.053487154642741
- 2.9930169709523518
- 2.9799659697214764
- 2.991203145980835
- 3.3438443088531495
- 2.716949666341146
- 3.2221737702687583
- 3.244639037450155
- 2.9746089013417563
- 3.583310931523641
- 3.0084636370340982
- 2.9484898853302
- 3.8449985281626384
- 3.20045485496521
- 3.0870030975341796
- 2.925327959060669
- 2.759019021987915
- 2.7582125663757324
- 2.6604963747660317
- 2.6683556842803955
- 2.646879644393921
- 3.356951503753662
- 3.612862097422282
- 2.654188175201416
- 3.1852465724945067
- 3.0350738398234047
- 2.690524517695109
- 3.6177576955159507
- 2.7251154518127443
- 2.4505903720855713
- 2.731283105214437
- 2.6172452608744305
- 2.4871168677012125
- 2.5219125906626383
- 2.234995527267456
- 2.5869252904256186
- 2.8275236320495605
- 2.5714725971221926
- 2.4117079385121665
- 2.4479867935180666
- 2.3336478169759114
- 2.7043968296051024
- 2.7359163570404053
- 2.390909433364868
- 2.7657738463083903
- 2.7121797211964926
- 2.3262848154703777
- 2.8482015800476073
- 2.27966438293457
- 2.654181210199992
- 2.0201460027694704
- 2.550576438903809
- 2.465297613143921
- 2.295539566675822
- 2.3211835130055745
- 2.2795795822143554
- 2.267123861312866
- 2.575927438735962
- 2.6825749015808107
- 3.906177994410197
- 2.588450152079264
- 2.710559720993042
- 3.2232659594217936
- 3.2551571051279704
- 2.0630608367919923
- 2.842504940032959
- 2.271589806874593
- 2.6748115158081056
- 2.6531482632954915
- 2.227420121828715
- 1.9596108388900757
- 2.203084815343221
- 2.9642177867889403
- 2.1249806118011474
- 2.1958334414164224
- 2.5074467563629153
- 2.4307323424021403
- 2.5068602625528973
- 2.491791229248047
- 2.2237337032953897
- 2.235908114115397
- 2.072981355985006
- 2.5072347863515216
- 2.3856271012624104
- 1.8496883058547973
- 2.867238779067993
- 2.0513586966196695
- 1.8583748213450113
- 2.1462051598231
- 2.429943866729736
- 2.3923338635762534
train_accuracy:
- 0.046
- 0.0
- 0.0
- 0.477
- 0.0
- 0.0
- 0.642
- 0.642
- 0.0
- 0.0
- 0.0
- 0.715
- 0.0
- 0.735
- 0.0
- 0.775
- 0.0
- 0.775
- 0.812
- 0.0
- 0.0
- 0.773
- 0.808
- 0.767
- 0.0
- 0.8
- 0.0
- 0.0
- 0.802
- 0.0
- 0.815
- 0.0
- 0.0
- 0.0
- 0.796
- 0.815
- 0.817
- 0.0
- 0.0
- 0.838
- 0.0
- 0.831
- 0.0
- 0.0
- 0.0
- 0.002
- 0.015
- 0.0
- 0.002
- 0.827
- 0.846
- 0.0
- 0.0
- 0.0
- 0.838
- 0.848
- 0.854
- 0.0
- 0.838
- 0.0
- 0.844
- 0.844
- 0.0
- 0.0
- 0.85
- 0.854
- 0.856
- 0.838
- 0.86
- 0.854
- 0.89
- 0.0
- 0.854
- 0.073
- 0.01
- 0.856
- 0.0
- 0.852
- 0.015
- 0.0
- 0.017
- 0.86
- 0.031
- 0.863
- 0.879
- 0.86
- 0.0
- 0.006
- 0.85
- 0.0
- 0.0
- 0.867
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.019
- 0.869
- 0.871
train_loss:
- 2.958
- 2.189
- 1.846
- 1.509
- 1.413
- 1.024
- 1.198
- 1.4
- 1.28
- 1.123
- 0.985
- 0.928
- 0.956
- 1.146
- 0.813
- 1.132
- 1.08
- 0.85
- 1.201
- 1.051
- 0.878
- 1.119
- 0.978
- 0.932
- 0.826
- 0.784
- 0.819
- 0.726
- 0.732
- 0.746
- 1.0
- 1.016
- 0.77
- 0.853
- 0.846
- 0.745
- 0.951
- 0.683
- 0.567
- 0.686
- 0.659
- 0.674
- 0.692
- 0.526
- 0.623
- 0.723
- 0.616
- 0.687
- 0.637
- 0.64
- 0.756
- 0.708
- 0.655
- 0.724
- 0.749
- 0.586
- 0.709
- 0.656
- 0.688
- 0.52
- 0.713
- 0.687
- 0.596
- 0.589
- 0.611
- 0.584
- 0.696
- 0.723
- 0.894
- 0.686
- 0.654
- 0.774
- 0.75
- 0.495
- 0.639
- 0.584
- 0.689
- 0.671
- 0.595
- 0.475
- 0.557
- 0.774
- 0.551
- 0.543
- 0.673
- 0.627
- 0.69
- 0.631
- 0.54
- 0.558
- 0.577
- 0.624
- 0.634
- 0.434
- 0.734
- 0.564
- 0.467
- 0.531
- 0.599
- 0.648
unequal: 0
verbose: 1
