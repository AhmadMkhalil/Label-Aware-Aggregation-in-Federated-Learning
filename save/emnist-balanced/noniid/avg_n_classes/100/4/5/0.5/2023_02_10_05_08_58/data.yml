avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.052127659574468084
- 0.13335106382978723
- 0.21382978723404256
- 0.28180851063829787
- 0.31042553191489364
- 0.34845744680851065
- 0.34
- 0.33563829787234045
- 0.38718085106382977
- 0.36069148936170214
- 0.39606382978723403
- 0.3973404255319149
- 0.3943617021276596
- 0.3972340425531915
- 0.39313829787234045
- 0.40191489361702126
- 0.4267021276595745
- 0.42106382978723406
- 0.4344148936170213
- 0.4178723404255319
- 0.4377659574468085
- 0.43686170212765957
- 0.4375
- 0.44468085106382976
- 0.45601063829787236
- 0.45632978723404255
- 0.45218085106382977
- 0.45617021276595743
- 0.46180851063829786
- 0.45851063829787236
- 0.46361702127659576
- 0.46627659574468083
- 0.46047872340425533
- 0.46872340425531916
- 0.47414893617021275
- 0.4726063829787234
- 0.4773404255319149
- 0.4731382978723404
- 0.4754255319148936
- 0.47308510638297874
- 0.47856382978723405
- 0.48021276595744683
- 0.48377659574468085
- 0.478031914893617
- 0.49
- 0.48154255319148936
- 0.4844148936170213
- 0.4872872340425532
- 0.4849468085106383
- 0.4875
- 0.49829787234042555
- 0.4876063829787234
- 0.48473404255319147
- 0.4924468085106383
- 0.48569148936170214
- 0.5042553191489362
- 0.4969148936170213
- 0.48829787234042554
- 0.4920212765957447
- 0.4895744680851064
- 0.5004787234042554
- 0.5070212765957447
- 0.49861702127659574
- 0.49553191489361703
- 0.5072340425531915
- 0.5174468085106383
- 0.5004255319148936
- 0.5147340425531914
- 0.4955851063829787
- 0.53
- 0.4970212765957447
- 0.5115425531914893
- 0.508031914893617
- 0.5179255319148937
- 0.5042553191489362
- 0.5077127659574469
- 0.49829787234042555
- 0.5186170212765957
- 0.49670212765957444
- 0.5095744680851064
- 0.5080851063829788
- 0.5102127659574468
- 0.5262765957446809
- 0.5146276595744681
- 0.5027127659574468
- 0.5217021276595745
- 0.5139893617021276
- 0.5160106382978723
- 0.5082446808510638
- 0.5452127659574468
- 0.5265425531914893
- 0.5304787234042553
- 0.51
- 0.5430851063829787
- 0.5424468085106383
- 0.5462234042553191
- 0.5237234042553192
- 0.5287765957446808
- 0.5260106382978723
- 0.5442021276595744
test_loss_list:
- 3.7841088644663494
- 3.8155623563130696
- 3.644666862487793
- 3.390416580835978
- 3.221440486907959
- 3.3763662656148274
- 2.9556848335266115
- 2.974836975733439
- 3.752281274795532
- 2.9820208104451496
- 3.448142474492391
- 3.238650643030802
- 3.005912424723307
- 2.9414245001475017
- 2.957941795984904
- 2.644071102142334
- 3.236000607808431
- 2.7067737007141113
- 3.2211410204569497
- 2.746581350962321
- 2.7542431418100994
- 3.134412228266398
- 3.0808077335357664
- 2.694002129236857
- 3.6740591812133787
- 3.7449728552500408
- 2.9378007507324218
- 2.700293092727661
- 3.074191328684489
- 2.92602697690328
- 2.998938268025716
- 3.650636609395345
- 2.619317506154378
- 3.170373913447062
- 2.5296073532104493
- 3.03201917330424
- 2.8791469510396324
- 2.8038760979970294
- 2.8762127621968587
- 2.5369921429951985
- 2.2864371967315673
- 2.482878376642863
- 2.392558790842692
- 2.494583082199097
- 2.3272793451944986
- 2.7348104159037274
- 2.4031822363535564
- 2.416345796585083
- 2.380262161890666
- 2.700331064860026
- 2.3109099944432576
- 2.703810930252075
- 2.7324190107981363
- 2.258255508740743
- 2.7712172921498617
- 2.0043851645787556
- 2.27633629322052
- 2.6936768531799316
- 2.537700777053833
- 2.6652710564931232
- 2.293249947230021
- 2.0136410427093505
- 2.2584737380345663
- 2.6612230714162193
- 2.1281456836064656
- 1.9528463745117188
- 2.2237860059738157
- 2.0778466097513832
- 2.6249623616536457
- 1.821903150876363
- 2.62223201751709
- 2.0753686221440635
- 2.1966444301605224
- 2.0169013865788776
- 2.4900241724650063
- 2.4199835713704427
- 3.1165288416544596
- 2.133234108289083
- 2.6050705337524414
- 2.145077338218689
- 2.4522407817840577
- 2.496692565282186
- 2.11348269144694
- 2.2007147057851157
- 2.4568545468648275
- 2.0503950357437133
- 2.184317700068156
- 2.103245851198832
- 2.4990434296925863
- 1.7448503653208414
- 2.1080419858296713
- 2.0904587427775065
- 2.3497684971491495
- 1.8705625025431316
- 1.793334666887919
- 1.7659693749745686
- 2.0381721607844034
- 2.029903225898743
- 2.073731843630473
- 1.8902214193344116
train_accuracy:
- 0.0
- 0.24
- 0.0
- 0.0
- 0.0
- 0.604
- 0.585
- 0.0
- 0.677
- 0.0
- 0.0
- 0.0
- 0.671
- 0.665
- 0.0
- 0.677
- 0.0
- 0.681
- 0.779
- 0.0
- 0.771
- 0.0
- 0.785
- 0.017
- 0.815
- 0.806
- 0.842
- 0.767
- 0.819
- 0.815
- 0.869
- 0.81
- 0.819
- 0.0
- 0.029
- 0.0
- 0.84
- 0.808
- 0.0
- 0.0
- 0.838
- 0.004
- 0.835
- 0.006
- 0.01
- 0.86
- 0.85
- 0.858
- 0.848
- 0.0
- 0.012
- 0.85
- 0.0
- 0.842
- 0.879
- 0.048
- 0.856
- 0.846
- 0.002
- 0.86
- 0.844
- 0.0
- 0.865
- 0.015
- 0.852
- 0.0
- 0.885
- 0.021
- 0.0
- 0.835
- 0.0
- 0.848
- 0.89
- 0.015
- 0.873
- 0.873
- 0.854
- 0.0
- 0.879
- 0.019
- 0.0
- 0.852
- 0.875
- 0.896
- 0.002
- 0.902
- 0.0
- 0.848
- 0.0
- 0.037
- 0.875
- 0.0
- 0.004
- 0.0
- 0.0
- 0.0
- 0.021
- 0.015
- 0.017
- 0.0
train_loss:
- 2.28
- 2.455
- 1.765
- 1.515
- 1.351
- 1.562
- 1.022
- 1.019
- 1.614
- 1.143
- 1.279
- 1.276
- 1.095
- 1.02
- 1.003
- 0.82
- 1.119
- 0.984
- 1.065
- 0.924
- 0.921
- 1.029
- 0.983
- 0.861
- 1.115
- 1.094
- 1.055
- 0.835
- 0.971
- 0.935
- 0.92
- 1.031
- 0.779
- 0.834
- 0.767
- 0.815
- 0.867
- 0.862
- 0.838
- 0.7
- 0.607
- 0.674
- 0.667
- 0.724
- 0.715
- 0.772
- 0.683
- 0.637
- 0.658
- 0.771
- 0.679
- 0.748
- 0.745
- 0.682
- 0.774
- 0.549
- 0.62
- 0.715
- 0.736
- 0.756
- 0.645
- 0.512
- 0.568
- 0.679
- 0.612
- 0.506
- 0.635
- 0.62
- 0.666
- 0.526
- 0.664
- 0.56
- 0.595
- 0.63
- 0.667
- 0.663
- 0.748
- 0.595
- 0.675
- 0.591
- 0.693
- 0.68
- 0.569
- 0.579
- 0.668
- 0.588
- 0.542
- 0.583
- 0.629
- 0.46
- 0.563
- 0.541
- 0.646
- 0.567
- 0.422
- 0.444
- 0.53
- 0.509
- 0.512
- 0.516
unequal: 0
verbose: 1
