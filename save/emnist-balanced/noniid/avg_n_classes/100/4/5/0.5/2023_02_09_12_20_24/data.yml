avg_train_accuracy: 0.858
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04542553191489362
- 0.1474468085106383
- 0.26861702127659576
- 0.3090425531914894
- 0.3470744680851064
- 0.368936170212766
- 0.3752127659574468
- 0.38585106382978723
- 0.40127659574468083
- 0.39776595744680854
- 0.42484042553191487
- 0.4073404255319149
- 0.4148404255319149
- 0.4227659574468085
- 0.4245212765957447
- 0.4346808510638298
- 0.4325531914893617
- 0.4373404255319149
- 0.4348936170212766
- 0.4377127659574468
- 0.44707446808510637
- 0.44707446808510637
- 0.27585106382978725
- 0.4582978723404255
- 0.4537765957446809
- 0.4552127659574468
- 0.46101063829787237
- 0.46159574468085107
- 0.46680851063829787
- 0.47085106382978725
- 0.4631382978723404
- 0.4743617021276596
- 0.4721808510638298
- 0.47393617021276596
- 0.47590425531914893
- 0.476968085106383
- 0.4743617021276596
- 0.47643617021276596
- 0.4773936170212766
- 0.48058510638297874
- 0.4837234042553191
- 0.47952127659574467
- 0.4848936170212766
- 0.4843085106382979
- 0.4826595744680851
- 0.48595744680851066
- 0.48409574468085104
- 0.48723404255319147
- 0.4913297872340426
- 0.488031914893617
- 0.49611702127659574
- 0.48617021276595745
- 0.49436170212765956
- 0.49414893617021277
- 0.4896808510638298
- 0.49361702127659574
- 0.49409574468085105
- 0.5025
- 0.5022340425531915
- 0.49531914893617024
- 0.4998936170212766
- 0.4958510638297872
- 0.5006914893617022
- 0.49840425531914895
- 0.49569148936170215
- 0.496436170212766
- 0.4984574468085106
- 0.504095744680851
- 0.5044148936170213
- 0.4981914893617021
- 0.504468085106383
- 0.5013829787234042
- 0.5076063829787234
- 0.5058510638297873
- 0.5085106382978724
- 0.5008510638297873
- 0.5068617021276596
- 0.4978191489361702
- 0.5050531914893617
- 0.5131914893617021
- 0.504095744680851
- 0.5032446808510638
- 0.5068617021276596
- 0.5034042553191489
- 0.5082978723404256
- 0.5063297872340425
- 0.5118085106382979
- 0.5062765957446809
- 0.5139893617021276
- 0.510904255319149
- 0.5101063829787233
- 0.5097872340425532
- 0.5026063829787234
- 0.5061170212765957
- 0.5104787234042554
- 0.5134042553191489
- 0.5068617021276596
- 0.510904255319149
- 0.5111170212765958
- 0.5135106382978724
test_loss_list:
- 3.8320110352834065
- 3.797174259821574
- 3.6027481396993
- 3.4149839814503986
- 3.426526845296224
- 3.7956893475850424
- 3.4189185078938804
- 3.585296869277954
- 4.042386805216472
- 3.2959839153289794
- 4.65027650197347
- 3.32049077351888
- 3.529745543797811
- 3.321764087677002
- 3.501376667022705
- 3.796557881037394
- 3.5249841276804608
- 3.2557995637257893
- 2.990091470082601
- 2.868175671895345
- 3.218056879043579
- 3.2846160093943277
- 2.653643503189087
- 2.6430168183644613
- 2.412148847579956
- 2.4432245826721193
- 2.6302146085103355
- 3.532334950764974
- 3.446660083134969
- 3.564175370534261
- 2.709113556543986
- 3.5821842670440676
- 3.0994114971160887
- 2.9487536430358885
- 2.613053000768026
- 3.0147712993621827
- 2.407899630864461
- 2.3653984769185383
- 2.3549588521321616
- 3.235496384302775
- 2.76131716410319
- 2.9619823551177977
- 2.262726982434591
- 2.8973957920074462
- 2.5381647904713946
- 3.5354256725311277
- 2.5248686504364013
- 2.9001371606190998
- 2.616412556966146
- 2.988622522354126
- 2.4909801483154297
- 3.4312746874491373
- 2.5782717577616374
- 2.92806476910909
- 3.2572804228464762
- 2.9049637571970623
- 2.925834445953369
- 2.451774361928304
- 2.566897850036621
- 2.389685195287069
- 2.2190053415298463
- 2.7665116945902506
- 2.331846513748169
- 2.2842244275410972
- 2.756056718826294
- 2.3551537799835205
- 2.3743838326136273
- 2.3983909130096435
- 2.2208102560043335
- 2.7306953207651774
- 2.2053072357177737
- 2.1510123856862386
- 2.0447819948196413
- 2.349798968633016
- 1.9694039758046469
- 2.580012480417887
- 2.386815989812215
- 2.663885285059611
- 2.2425385602315266
- 2.017921013832092
- 2.232872716585795
- 2.4793017292022705
- 2.2857237482070922
- 2.561835848490397
- 2.20013209660848
- 2.6175682830810545
- 2.1130887047449747
- 2.6671912542978924
- 2.2902463483810425
- 2.124608184496562
- 2.261989638010661
- 2.627741921742757
- 2.50644905090332
- 2.532940184275309
- 2.2873878622055055
- 2.270108714103699
- 2.498338311513265
- 2.5976554997762045
- 2.4975680033365886
- 2.6787236754099526
train_accuracy:
- 0.079
- 0.0
- 0.475
- 0.0
- 0.0
- 0.671
- 0.0
- 0.648
- 0.717
- 0.0
- 0.744
- 0.0
- 0.748
- 0.0
- 0.0
- 0.765
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.785
- 0.55
- 0.01
- 0.0
- 0.827
- 0.0
- 0.0
- 0.825
- 0.848
- 0.806
- 0.0
- 0.821
- 0.819
- 0.821
- 0.812
- 0.002
- 0.002
- 0.0
- 0.0
- 0.0
- 0.838
- 0.004
- 0.84
- 0.829
- 0.865
- 0.0
- 0.0
- 0.0
- 0.85
- 0.0
- 0.852
- 0.0
- 0.842
- 0.858
- 0.0
- 0.846
- 0.84
- 0.004
- 0.856
- 0.002
- 0.852
- 0.85
- 0.0
- 0.85
- 0.002
- 0.002
- 0.0
- 0.894
- 0.885
- 0.004
- 0.002
- 0.0
- 0.858
- 0.0
- 0.873
- 0.848
- 0.869
- 0.0
- 0.0
- 0.0
- 0.002
- 0.863
- 0.892
- 0.0
- 0.0
- 0.01
- 0.86
- 0.904
- 0.865
- 0.892
- 0.852
- 0.863
- 0.896
- 0.0
- 0.0
- 0.871
- 0.867
- 0.902
- 0.858
train_loss:
- 2.314
- 2.507
- 2.223
- 1.593
- 1.686
- 1.825
- 1.478
- 1.408
- 1.535
- 1.109
- 1.602
- 1.077
- 1.232
- 1.241
- 1.13
- 1.307
- 1.092
- 0.972
- 0.811
- 0.936
- 0.999
- 1.001
- 0.624
- 0.861
- 0.666
- 0.685
- 0.809
- 1.112
- 1.071
- 1.028
- 0.795
- 1.006
- 0.881
- 0.882
- 0.736
- 0.812
- 0.63
- 0.624
- 0.581
- 0.978
- 0.825
- 0.826
- 0.607
- 0.754
- 0.689
- 0.884
- 0.745
- 0.774
- 0.674
- 0.742
- 0.684
- 0.897
- 0.715
- 0.738
- 0.824
- 0.725
- 0.74
- 0.633
- 0.612
- 0.678
- 0.58
- 0.775
- 0.664
- 0.627
- 0.693
- 0.612
- 0.598
- 0.668
- 0.601
- 0.68
- 0.594
- 0.536
- 0.487
- 0.589
- 0.51
- 0.629
- 0.708
- 0.682
- 0.622
- 0.523
- 0.562
- 0.625
- 0.639
- 0.712
- 0.617
- 0.679
- 0.513
- 0.672
- 0.579
- 0.56
- 0.585
- 0.62
- 0.648
- 0.699
- 0.578
- 0.558
- 0.642
- 0.646
- 0.642
- 0.623
unequal: 0
verbose: 1
