avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03446808510638298
- 0.12569148936170213
- 0.23803191489361702
- 0.2825
- 0.32303191489361704
- 0.3668085106382979
- 0.37611702127659574
- 0.3765425531914894
- 0.3976063829787234
- 0.4049468085106383
- 0.39276595744680853
- 0.41595744680851066
- 0.4175531914893617
- 0.42319148936170214
- 0.41069148936170213
- 0.42606382978723406
- 0.41404255319148936
- 0.4372340425531915
- 0.4172872340425532
- 0.4425
- 0.4376595744680851
- 0.4380851063829787
- 0.41893617021276597
- 0.43638297872340426
- 0.4396276595744681
- 0.4465425531914894
- 0.451968085106383
- 0.4521276595744681
- 0.44335106382978723
- 0.45420212765957446
- 0.4572340425531915
- 0.45643617021276595
- 0.46441489361702126
- 0.4656382978723404
- 0.45595744680851064
- 0.4576595744680851
- 0.46170212765957447
- 0.46558510638297873
- 0.47085106382978725
- 0.46170212765957447
- 0.4745744680851064
- 0.471968085106383
- 0.4726063829787234
- 0.4775
- 0.479468085106383
- 0.47712765957446807
- 0.47877659574468084
- 0.47893617021276597
- 0.48223404255319147
- 0.48409574468085104
- 0.48792553191489363
- 0.4831382978723404
- 0.4896808510638298
- 0.4902127659574468
- 0.49590425531914895
- 0.48377659574468085
- 0.48851063829787233
- 0.4915425531914894
- 0.501436170212766
- 0.49946808510638296
- 0.49946808510638296
- 0.4968085106382979
- 0.49803191489361703
- 0.48936170212765956
- 0.49090425531914894
- 0.49888297872340426
- 0.5015957446808511
- 0.4976063829787234
- 0.49175531914893617
- 0.5006382978723404
- 0.5025
- 0.5202659574468085
- 0.503563829787234
- 0.5019148936170212
- 0.5176595744680851
- 0.5077659574468085
- 0.4946808510638298
- 0.5175531914893617
- 0.5034042553191489
- 0.49611702127659574
- 0.4976063829787234
- 0.5012765957446809
- 0.5237765957446808
- 0.49803191489361703
- 0.5034574468085107
- 0.5207978723404255
- 0.5200531914893617
- 0.5257978723404255
- 0.5149468085106383
- 0.500531914893617
- 0.5115425531914893
- 0.5162234042553191
- 0.5097340425531914
- 0.5011170212765957
- 0.5282446808510638
- 0.5167553191489361
- 0.525
- 0.5095744680851064
- 0.5264893617021277
- 0.5052127659574468
test_loss_list:
- 3.8256999111175536
- 3.777558552424113
- 3.505033082962036
- 3.2503426933288573
- 3.3231025568644204
- 3.645319029490153
- 3.317257995605469
- 3.1088310209910075
- 3.265980494817098
- 3.84842711130778
- 3.074089183807373
- 3.322584466934204
- 3.7379556115468344
- 3.3447848097483317
- 3.0941182549794517
- 3.2033564790089923
- 3.2382953929901124
- 3.5002311134338377
- 2.7514630126953126
- 3.8002803834279377
- 3.1222914695739745
- 2.9575061003367105
- 2.83213703473409
- 2.6793609619140626
- 2.7799032433827717
- 2.782550992965698
- 2.8846445592244465
- 2.797164414723714
- 2.683418353398641
- 2.5197070121765135
- 2.72595388730367
- 3.0439327653249104
- 3.672660779953003
- 2.7733154328664145
- 3.078690166473389
- 2.9861329714457194
- 2.6629180494944253
- 2.7006318378448486
- 3.062504456837972
- 2.612232036590576
- 2.752707141240438
- 3.3667000357309975
- 2.3029833984375
- 2.6882887204488117
- 3.0451845709482828
- 3.513164437611898
- 3.614471035003662
- 2.5609748776753745
- 2.7309768358866373
- 3.000648635228475
- 2.62381934483846
- 3.4690781847635903
- 2.4274630705515543
- 2.3241365178426108
- 2.2607131083806355
- 2.4380276807149253
- 2.3316331100463867
- 2.4228030236562095
- 2.3497820695241294
- 2.4556893920898437
- 2.4269438393910727
- 2.2452080345153806
- 2.3620808347066244
- 3.3698640982309978
- 2.695894174575806
- 2.4110413519541423
- 2.458936513264974
- 2.326875842412313
- 3.350965417226156
- 2.7205470339457194
- 2.4906891695658366
- 2.059364589055379
- 2.8948096656799316
- 2.233055974642436
- 2.025266064008077
- 2.287630484898885
- 3.221606772740682
- 2.028109548886617
- 2.7438113276163736
- 3.167466192245483
- 3.143780202865601
- 2.6665980497996014
- 1.9896967697143555
- 3.361478408177694
- 2.4265672079722087
- 2.3837979952494304
- 2.1632480017344156
- 1.9750373554229737
- 2.188191196123759
- 3.1956218592325847
- 2.186127961476644
- 2.2549722973505655
- 2.3913951969146727
- 3.2077810668945315
- 2.1035088030497233
- 2.2614434003829955
- 2.239729013442993
- 2.5537351671854656
- 2.133333282470703
- 2.7490647633870444
train_accuracy:
- 0.0
- 0.235
- 0.0
- 0.0
- 0.548
- 0.635
- 0.0
- 0.0
- 0.0
- 0.719
- 0.66
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.763
- 0.0
- 0.756
- 0.754
- 0.0
- 0.002
- 0.0
- 0.754
- 0.0
- 0.0
- 0.0
- 0.004
- 0.79
- 0.0
- 0.81
- 0.815
- 0.0
- 0.804
- 0.785
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.804
- 0.0
- 0.002
- 0.823
- 0.0
- 0.827
- 0.0
- 0.0
- 0.0
- 0.0
- 0.842
- 0.0
- 0.0
- 0.002
- 0.825
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.006
- 0.867
- 0.85
- 0.827
- 0.0
- 0.006
- 0.871
- 0.0
- 0.0
- 0.827
- 0.86
- 0.844
- 0.0
- 0.0
- 0.856
- 0.0
- 0.877
- 0.865
- 0.863
- 0.85
- 0.823
- 0.86
- 0.856
- 0.846
- 0.877
- 0.002
- 0.887
- 0.887
- 0.002
- 0.004
- 0.854
- 0.856
- 0.846
- 0.887
- 0.015
- 0.873
- 0.017
- 0.0
train_loss:
- 2.442
- 2.571
- 1.796
- 1.247
- 1.757
- 1.883
- 1.503
- 1.191
- 1.376
- 1.561
- 1.107
- 1.251
- 1.417
- 1.199
- 1.042
- 1.152
- 1.167
- 1.116
- 0.797
- 1.239
- 1.067
- 0.898
- 0.921
- 0.729
- 0.846
- 0.867
- 0.83
- 0.817
- 0.838
- 0.656
- 0.806
- 0.922
- 1.029
- 0.785
- 0.929
- 0.904
- 0.767
- 0.738
- 0.912
- 0.749
- 0.746
- 0.988
- 0.616
- 0.733
- 0.832
- 0.934
- 0.921
- 0.752
- 0.711
- 0.804
- 0.705
- 0.922
- 0.717
- 0.576
- 0.552
- 0.689
- 0.668
- 0.67
- 0.659
- 0.65
- 0.624
- 0.655
- 0.656
- 0.873
- 0.762
- 0.662
- 0.634
- 0.637
- 0.829
- 0.738
- 0.63
- 0.521
- 0.733
- 0.638
- 0.528
- 0.618
- 0.815
- 0.524
- 0.727
- 0.816
- 0.811
- 0.722
- 0.513
- 0.788
- 0.715
- 0.593
- 0.61
- 0.51
- 0.587
- 0.778
- 0.616
- 0.595
- 0.69
- 0.757
- 0.622
- 0.568
- 0.583
- 0.679
- 0.573
- 0.661
unequal: 0
verbose: 1
