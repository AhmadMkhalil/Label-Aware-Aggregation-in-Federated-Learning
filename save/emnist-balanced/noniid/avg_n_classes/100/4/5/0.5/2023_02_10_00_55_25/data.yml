avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03
- 0.04936170212765958
- 0.20882978723404255
- 0.2796808510638298
- 0.29590425531914893
- 0.31372340425531914
- 0.36617021276595746
- 0.34287234042553194
- 0.36569148936170215
- 0.3802127659574468
- 0.3804787234042553
- 0.38968085106382977
- 0.3929787234042553
- 0.4100531914893617
- 0.41867021276595745
- 0.4151595744680851
- 0.41925531914893616
- 0.4270212765957447
- 0.4309574468085106
- 0.43122340425531913
- 0.4313297872340425
- 0.4357446808510638
- 0.4384574468085106
- 0.44382978723404254
- 0.44670212765957445
- 0.448563829787234
- 0.4478723404255319
- 0.4491489361702128
- 0.4567553191489362
- 0.4573936170212766
- 0.45941489361702126
- 0.4597872340425532
- 0.4631914893617021
- 0.4804787234042553
- 0.47069148936170213
- 0.4793085106382979
- 0.46664893617021275
- 0.46867021276595744
- 0.4684042553191489
- 0.47829787234042553
- 0.4726063829787234
- 0.47590425531914893
- 0.47723404255319146
- 0.47127659574468084
- 0.47069148936170213
- 0.468031914893617
- 0.4703191489361702
- 0.47648936170212763
- 0.47835106382978726
- 0.48414893617021276
- 0.4953723404255319
- 0.49069148936170215
- 0.49388297872340425
- 0.4950531914893617
- 0.49877659574468086
- 0.4825531914893617
- 0.49457446808510636
- 0.483031914893617
- 0.493936170212766
- 0.4920744680851064
- 0.4882446808510638
- 0.4995212765957447
- 0.5057978723404255
- 0.5112765957446809
- 0.4983510638297872
- 0.5034574468085107
- 0.5156382978723404
- 0.5062765957446809
- 0.49319148936170215
- 0.49340425531914894
- 0.4921276595744681
- 0.5011170212765957
- 0.49446808510638296
- 0.4904787234042553
- 0.5030851063829788
- 0.5207978723404255
- 0.49617021276595746
- 0.5001063829787235
- 0.5075
- 0.4997340425531915
- 0.5217021276595745
- 0.5109574468085106
- 0.5104787234042554
- 0.5073936170212766
- 0.5252659574468085
- 0.5169680851063829
- 0.520904255319149
- 0.5216489361702128
- 0.5248936170212766
- 0.5045744680851064
- 0.5046276595744681
- 0.518936170212766
- 0.5314893617021277
- 0.49579787234042555
- 0.5117553191489361
- 0.5038297872340426
- 0.506436170212766
- 0.507127659574468
- 0.521595744680851
- 0.5061170212765957
test_loss_list:
- 3.819854825337728
- 3.8489214356740318
- 3.9363918908437094
- 4.085875237782796
- 3.295650863647461
- 3.219094336827596
- 4.307879031499227
- 3.1464999135335288
- 3.1920679092407225
- 3.3272512404123944
- 3.033153778711955
- 2.9535282897949218
- 2.8012930234273274
- 3.1882034301757813
- 3.6705255635579426
- 3.202827116648356
- 2.8982665475209552
- 3.1695646635691324
- 3.1277929242451985
- 2.8022728888193766
- 2.6823147328694663
- 2.6844556776682538
- 2.7516374270121258
- 2.6891666348775227
- 3.0169082482655845
- 2.8749390570322673
- 2.934472462336222
- 2.8720547930399576
- 3.5840006669362388
- 2.6188425699869793
- 2.9825582917531333
- 2.864691130320231
- 2.5532519181569415
- 2.274782150586446
- 2.4968624846140544
- 2.5264183457692466
- 2.771821931203206
- 2.80814071337382
- 2.3988196150461834
- 2.3871004517873127
- 2.406145830154419
- 2.7962216186523436
- 2.302766655286153
- 3.3483941650390623
- 2.328865559895833
- 2.4045569547017416
- 2.394657516479492
- 2.382041794459025
- 2.288234084447225
- 2.33260511080424
- 2.303635234832764
- 2.6778228028615314
- 2.2487501303354898
- 2.29708975315094
- 2.318873564402262
- 3.2101422055562336
- 2.6240241877237955
- 2.626755126317342
- 2.588288599650065
- 2.2141910934448243
- 2.7323748683929443
- 2.171644563674927
- 1.9333847284317016
- 2.2289835961659747
- 2.6179878425598146
- 2.08333677927653
- 1.9390512021382649
- 2.143213610649109
- 2.5074731286366783
- 2.463959312438965
- 3.1035356871287028
- 2.5918832429250083
- 2.509061352411906
- 3.2256238714853924
- 2.630387404759725
- 1.9832435846328735
- 2.5006348260243736
- 2.084926013946533
- 2.1849694951375325
- 2.5205781110127767
- 2.107150780359904
- 2.0358873144785563
- 2.128662560780843
- 2.4053054745992024
- 2.051714865366618
- 2.046589345932007
- 2.083400093714396
- 2.160226500829061
- 2.1459055296579996
- 2.4487413628896078
- 2.427498270670573
- 2.03317417939504
- 1.8412891578674317
- 2.8468280124664305
- 2.3740035041173297
- 2.963761355082194
- 2.3145110114415486
- 2.4720668347676593
- 2.039184341430664
- 2.0511438417434693
train_accuracy:
- 0.05
- 0.083
- 0.373
- 0.471
- 0.0
- 0.0
- 0.627
- 0.642
- 0.0
- 0.66
- 0.0
- 0.669
- 0.688
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.792
- 0.819
- 0.0
- 0.0
- 0.821
- 0.0
- 0.006
- 0.831
- 0.825
- 0.783
- 0.0
- 0.0
- 0.002
- 0.823
- 0.815
- 0.0
- 0.835
- 0.825
- 0.004
- 0.792
- 0.844
- 0.002
- 0.0
- 0.0
- 0.854
- 0.844
- 0.004
- 0.008
- 0.863
- 0.0
- 0.856
- 0.842
- 0.0
- 0.002
- 0.858
- 0.0
- 0.0
- 0.004
- 0.829
- 0.004
- 0.0
- 0.0
- 0.873
- 0.86
- 0.008
- 0.0
- 0.873
- 0.867
- 0.006
- 0.865
- 0.863
- 0.0
- 0.858
- 0.0
- 0.0
- 0.0
- 0.004
- 0.865
- 0.037
- 0.002
- 0.01
- 0.031
- 0.004
- 0.002
- 0.871
- 0.019
- 0.881
- 0.86
- 0.89
- 0.002
- 0.86
- 0.031
- 0.0
train_loss:
- 2.915
- 2.364
- 2.874
- 2.411
- 1.3
- 1.461
- 2.156
- 1.339
- 1.264
- 1.439
- 1.171
- 1.148
- 0.919
- 1.227
- 1.391
- 1.164
- 1.038
- 1.167
- 1.134
- 0.929
- 0.978
- 0.92
- 0.921
- 0.914
- 1.005
- 1.026
- 1.006
- 1.034
- 1.103
- 0.805
- 0.948
- 0.932
- 0.765
- 0.681
- 0.819
- 0.736
- 0.924
- 0.856
- 0.806
- 0.768
- 0.796
- 0.817
- 0.785
- 0.975
- 0.774
- 0.743
- 0.725
- 0.738
- 0.752
- 0.674
- 0.673
- 0.776
- 0.736
- 0.695
- 0.689
- 0.882
- 0.75
- 0.779
- 0.76
- 0.715
- 0.737
- 0.635
- 0.561
- 0.617
- 0.716
- 0.694
- 0.542
- 0.664
- 0.76
- 0.771
- 0.814
- 0.694
- 0.753
- 0.802
- 0.704
- 0.499
- 0.769
- 0.669
- 0.634
- 0.682
- 0.642
- 0.63
- 0.573
- 0.682
- 0.64
- 0.572
- 0.55
- 0.548
- 0.528
- 0.73
- 0.727
- 0.578
- 0.511
- 0.772
- 0.663
- 0.748
- 0.669
- 0.65
- 0.631
- 0.61
unequal: 0
verbose: 1
