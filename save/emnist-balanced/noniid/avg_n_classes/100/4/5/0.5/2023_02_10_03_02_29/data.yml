avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04074468085106383
- 0.06797872340425531
- 0.18601063829787234
- 0.2351595744680851
- 0.25898936170212766
- 0.29340425531914893
- 0.32590425531914896
- 0.3422340425531915
- 0.35840425531914893
- 0.35138297872340424
- 0.37148936170212765
- 0.38824468085106384
- 0.3946808510638298
- 0.3825531914893617
- 0.3815425531914894
- 0.3927127659574468
- 0.4079255319148936
- 0.4212234042553191
- 0.41771276595744683
- 0.4095744680851064
- 0.42138297872340424
- 0.43
- 0.4196808510638298
- 0.44207446808510636
- 0.43617021276595747
- 0.4454255319148936
- 0.4347340425531915
- 0.436436170212766
- 0.44904255319148934
- 0.4550531914893617
- 0.45691489361702126
- 0.45893617021276595
- 0.45468085106382977
- 0.46675531914893614
- 0.4628191489361702
- 0.46914893617021275
- 0.4657978723404255
- 0.4772872340425532
- 0.47164893617021275
- 0.4792021276595745
- 0.47877659574468084
- 0.4726063829787234
- 0.46845744680851065
- 0.485531914893617
- 0.48319148936170214
- 0.48425531914893616
- 0.48946808510638296
- 0.4827659574468085
- 0.49079787234042555
- 0.49138297872340425
- 0.49627659574468086
- 0.4842021276595745
- 0.48904255319148937
- 0.4901063829787234
- 0.5006382978723404
- 0.48377659574468085
- 0.48569148936170214
- 0.4862234042553191
- 0.486436170212766
- 0.4949468085106383
- 0.49079787234042555
- 0.4979787234042553
- 0.49840425531914895
- 0.49638297872340426
- 0.508031914893617
- 0.5187234042553192
- 0.5042553191489362
- 0.5174468085106383
- 0.5134042553191489
- 0.4972872340425532
- 0.5088829787234043
- 0.5143085106382979
- 0.5278723404255319
- 0.4931382978723404
- 0.4973936170212766
- 0.4978191489361702
- 0.4993085106382979
- 0.5080851063829788
- 0.5070212765957447
- 0.5237765957446808
- 0.5011702127659574
- 0.5223936170212766
- 0.5173936170212766
- 0.4136170212765957
- 0.5412765957446809
- 0.5106914893617022
- 0.5220212765957447
- 0.5020744680851064
- 0.5163829787234042
- 0.5349468085106382
- 0.5132446808510638
- 0.5180851063829788
- 0.5129787234042553
- 0.5047872340425532
- 0.5052659574468085
- 0.5127659574468085
- 0.5107446808510638
- 0.5109574468085106
- 0.5089361702127659
- 0.5329787234042553
test_loss_list:
- 3.7900539112091063
- 3.8109259923299152
- 3.794622300465902
- 3.5960681692759198
- 3.6470402526855468
- 3.411748208999634
- 3.43727068901062
- 3.363231789271037
- 3.3623122342427574
- 3.097392962773641
- 3.1307477855682375
- 3.2359029261271157
- 2.976868190765381
- 3.3104061285654702
- 2.882977695465088
- 2.9582031377156577
- 2.84025221824646
- 3.619203945795695
- 2.790334396362305
- 2.6533206939697265
- 3.1848761304219564
- 2.9830029233296713
- 3.02756365776062
- 3.5739172331492104
- 2.648984743754069
- 3.078905267715454
- 2.490574150085449
- 2.702443555196126
- 2.433864459991455
- 2.9735927200317382
- 2.874468517303467
- 2.5996897506713865
- 2.945197547276815
- 3.4712322394053143
- 2.5012731679280598
- 2.946873896916707
- 2.58762500445048
- 2.298961788813273
- 2.55310453414917
- 2.4894405110677083
- 2.28632417678833
- 2.8269255956014
- 2.4550049686431885
- 2.454848384857178
- 2.1729056358337404
- 2.843082930246989
- 2.3788805341720582
- 2.4526288318634033
- 2.437518409093221
- 2.409002798398336
- 2.3483270613352456
- 3.2267482884724936
- 2.234503323237101
- 3.293694060643514
- 2.3423378976186116
- 2.391132485071818
- 2.6761072953542073
- 3.3049484380086263
- 3.2679320907592775
- 2.4044586658477782
- 2.435508991877238
- 2.365763915379842
- 2.699016278584798
- 2.7731455516815187
- 2.0377634636561077
- 2.1062386258443198
- 2.7009568564097086
- 2.2314127349853514
- 2.0523336998621624
- 2.581653127670288
- 2.2452146673202513
- 2.2102213271458946
- 1.9610783990224203
- 3.120750751495361
- 2.4426237201690673
- 3.1627206707000735
- 2.4996587880452474
- 2.2775015751520793
- 2.6154498863220215
- 1.996774706840515
- 3.063576796849569
- 2.240184466044108
- 2.256874787012736
- 2.088662846883138
- 1.8696300586064656
- 2.4060600328445436
- 2.0808332188924155
- 2.932806345621745
- 2.53100705464681
- 1.9628667163848876
- 2.578439671198527
- 2.5412506008148195
- 2.55812814394633
- 3.0243060048421224
- 2.4576195939381917
- 2.5658035119374594
- 2.4851873111724854
- 2.513997885386149
- 3.1504901440938315
- 2.0950005944569905
train_accuracy:
- 0.027
- 0.113
- 0.315
- 0.0
- 0.417
- 0.0
- 0.544
- 0.621
- 0.604
- 0.0
- 0.662
- 0.025
- 0.694
- 0.0
- 0.0
- 0.0
- 0.031
- 0.735
- 0.744
- 0.0
- 0.731
- 0.0
- 0.731
- 0.756
- 0.746
- 0.0
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.785
- 0.777
- 0.006
- 0.004
- 0.804
- 0.0
- 0.006
- 0.823
- 0.01
- 0.0
- 0.0
- 0.0
- 0.802
- 0.0
- 0.0
- 0.0
- 0.015
- 0.012
- 0.827
- 0.825
- 0.833
- 0.825
- 0.84
- 0.031
- 0.0
- 0.0
- 0.848
- 0.848
- 0.027
- 0.0
- 0.015
- 0.021
- 0.006
- 0.0
- 0.167
- 0.84
- 0.0
- 0.0
- 0.0
- 0.85
- 0.846
- 0.0
- 0.858
- 0.854
- 0.86
- 0.0
- 0.017
- 0.0
- 0.852
- 0.879
- 0.0
- 0.86
- 0.833
- 0.133
- 0.86
- 0.058
- 0.858
- 0.863
- 0.0
- 0.854
- 0.0
- 0.879
- 0.854
- 0.863
- 0.877
- 0.885
- 0.873
- 0.892
- 0.0
train_loss:
- 2.985
- 3.225
- 2.617
- 1.811
- 1.903
- 1.523
- 1.654
- 1.545
- 1.505
- 1.234
- 1.195
- 1.324
- 1.14
- 1.339
- 1.119
- 1.161
- 1.018
- 1.347
- 1.054
- 0.904
- 1.118
- 1.119
- 1.143
- 1.202
- 0.965
- 1.057
- 0.817
- 0.888
- 0.728
- 0.979
- 0.943
- 0.859
- 1.016
- 1.036
- 0.876
- 0.926
- 0.76
- 0.659
- 0.806
- 0.78
- 0.637
- 0.862
- 0.764
- 0.718
- 0.669
- 0.838
- 0.688
- 0.761
- 0.734
- 0.672
- 0.699
- 0.941
- 0.782
- 0.932
- 0.699
- 0.728
- 0.825
- 0.918
- 0.908
- 0.749
- 0.671
- 0.681
- 0.789
- 0.744
- 0.617
- 0.534
- 0.731
- 0.652
- 0.547
- 0.72
- 0.668
- 0.598
- 0.556
- 0.861
- 0.749
- 0.841
- 0.731
- 0.588
- 0.682
- 0.531
- 0.834
- 0.623
- 0.644
- 0.446
- 0.535
- 0.672
- 0.587
- 0.791
- 0.667
- 0.512
- 0.683
- 0.673
- 0.689
- 0.785
- 0.725
- 0.65
- 0.672
- 0.69
- 0.725
- 0.614
unequal: 0
verbose: 1
