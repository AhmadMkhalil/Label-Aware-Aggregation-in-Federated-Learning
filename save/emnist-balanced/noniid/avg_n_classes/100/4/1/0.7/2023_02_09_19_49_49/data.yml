avg_train_accuracy: 0.806
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.058351063829787234
- 0.10388297872340425
- 0.25324468085106383
- 0.3551595744680851
- 0.4403723404255319
- 0.4955851063829787
- 0.5170212765957447
- 0.5450531914893617
- 0.5656914893617021
- 0.5707978723404256
- 0.591436170212766
- 0.5962765957446808
- 0.6073404255319149
- 0.6160638297872341
- 0.6267553191489361
- 0.637340425531915
- 0.6431382978723404
- 0.6406914893617022
- 0.6542553191489362
- 0.6504255319148936
- 0.6619680851063829
- 0.6586702127659575
- 0.6690957446808511
- 0.6679787234042553
- 0.6723936170212766
- 0.6744148936170212
- 0.6762765957446808
- 0.6796808510638298
- 0.6855851063829788
- 0.6857446808510639
- 0.6894148936170212
- 0.6922872340425532
- 0.6925
- 0.6943085106382979
- 0.693031914893617
- 0.6982978723404255
- 0.7002659574468085
- 0.7004787234042553
- 0.7015425531914894
- 0.7013297872340426
- 0.7063829787234043
- 0.7073404255319149
- 0.7088297872340426
- 0.7076595744680851
- 0.7105851063829787
- 0.7112234042553192
- 0.7144680851063829
- 0.7139893617021277
- 0.7152659574468085
- 0.7175
- 0.7180851063829787
- 0.7170744680851063
- 0.719095744680851
- 0.7171808510638298
- 0.7197340425531915
- 0.7225
- 0.7232446808510639
- 0.7226595744680852
- 0.7237234042553191
- 0.7253723404255319
- 0.7246808510638297
- 0.7254787234042553
- 0.7272872340425532
- 0.7271808510638298
- 0.7284574468085107
- 0.7279255319148936
- 0.7285106382978723
- 0.7280319148936171
- 0.728563829787234
- 0.729095744680851
- 0.7305851063829787
- 0.7320744680851063
- 0.7333510638297872
- 0.732872340425532
- 0.7334574468085107
- 0.7333510638297872
- 0.7343085106382978
- 0.735
- 0.7336170212765958
- 0.7343085106382978
- 0.7345744680851064
- 0.7365425531914893
- 0.7357978723404255
- 0.7363829787234043
- 0.7383510638297872
- 0.7378191489361702
- 0.7388829787234042
- 0.7395744680851064
- 0.7393617021276596
- 0.7397340425531915
- 0.7383510638297872
- 0.7411702127659574
- 0.7421808510638298
- 0.7395744680851064
- 0.7404255319148936
- 0.7411170212765957
- 0.7409574468085106
- 0.7426063829787234
- 0.7415957446808511
- 0.7418617021276596
test_loss_list:
- 3.752578051884969
- 3.6087574577331543
- 3.3277845033009847
- 2.9319072564442954
- 2.621824932098389
- 2.4013452275594074
- 2.2164307181040446
- 2.115141685803731
- 2.0553349320093792
- 1.9349453433354695
- 1.9186504713694255
- 1.8111673593521118
- 1.747645559310913
- 1.684042501449585
- 1.6375466759999593
- 1.678105125427246
- 1.6859222650527954
- 1.575540115038554
- 1.6376256656646728
- 1.524222092628479
- 1.5914384269714354
- 1.491893900235494
- 1.5692770512898764
- 1.4487776358922322
- 1.4129396104812622
- 1.3916137250264486
- 1.359649839401245
- 1.336230025291443
- 1.4451823790868124
- 1.4682042010625203
- 1.469870998064677
- 1.4836452404658
- 1.4827943881352743
- 1.4930802949269613
- 1.3526622358957927
- 1.4575141096115112
- 1.4663645394643148
- 1.3263745339711508
- 1.2951102654139202
- 1.2638931735356649
- 1.3821482721964518
- 1.2457859214146931
- 1.3693666823705037
- 1.2333494345347087
- 1.3598037830988565
- 1.225847540696462
- 1.2004752945899964
- 1.1813778527577719
- 1.1813933459917705
- 1.3042261854807535
- 1.3418603324890137
- 1.196785387992859
- 1.1766770148277284
- 1.1623445351918538
- 1.1445971862475077
- 1.1309552041689555
- 1.1226027743021647
- 1.1063742383321127
- 1.1171700763702392
- 1.248309419155121
- 1.2841832828521729
- 1.1541539947191874
- 1.2775885033607484
- 1.1452224429448445
- 1.1201737197240194
- 1.2520758668581644
- 1.1213918034235637
- 1.103727126121521
- 1.0923335138956707
- 1.0824518712361653
- 1.074277118841807
- 1.0680357829729716
- 1.0671684042612712
- 1.2028993670145671
- 1.2405779457092285
- 1.1086653025945028
- 1.08535826365153
- 1.0717503809928894
- 1.0578379821777344
- 1.0529075241088868
- 1.0387449304262797
- 1.1816309928894042
- 1.0612486290931702
- 1.0454624493916829
- 1.0391999991734822
- 1.035425820350647
- 1.0274657424290974
- 1.0215830739339193
- 1.0139263248443604
- 1.0150938288370768
- 1.1613959050178528
- 1.0325730093320211
- 1.019072659810384
- 1.0123558696111044
- 1.0078759558995565
- 0.995608541170756
- 0.9930526296297709
- 0.9986816994349161
- 1.1270449217160543
- 1.0123521955808004
train_accuracy:
- 0.079
- 0.119
- 0.26
- 0.415
- 0.506
- 0.592
- 0.571
- 0.577
- 0.604
- 0.61
- 0.671
- 0.662
- 0.633
- 0.677
- 0.0
- 0.673
- 0.688
- 0.721
- 0.7
- 0.706
- 0.706
- 0.76
- 0.729
- 0.721
- 0.725
- 0.746
- 0.731
- 0.721
- 0.744
- 0.787
- 0.744
- 0.787
- 0.74
- 0.752
- 0.744
- 0.796
- 0.767
- 0.765
- 0.8
- 0.76
- 0.779
- 0.802
- 0.779
- 0.765
- 0.785
- 0.0
- 0.0
- 0.81
- 0.771
- 0.767
- 0.765
- 0.0
- 0.79
- 0.812
- 0.794
- 0.781
- 0.792
- 0.79
- 0.798
- 0.8
- 0.775
- 0.829
- 0.823
- 0.796
- 0.8
- 0.785
- 0.0
- 0.0
- 0.802
- 0.796
- 0.833
- 0.804
- 0.0
- 0.769
- 0.798
- 0.802
- 0.783
- 0.0
- 0.0
- 0.8
- 0.794
- 0.79
- 0.785
- 0.808
- 0.79
- 0.81
- 0.798
- 0.792
- 0.802
- 0.808
- 0.806
- 0.821
- 0.0
- 0.0
- 0.779
- 0.81
- 0.819
- 0.804
- 0.804
- 0.806
train_loss:
- 3.828
- 3.433
- 3.564
- 2.943
- 2.681
- 2.751
- 2.293
- 2.401
- 2.282
- 1.981
- 2.103
- 1.842
- 1.781
- 1.73
- 1.691
- 1.842
- 1.794
- 1.59
- 1.728
- 1.534
- 1.68
- 1.502
- 1.636
- 1.449
- 1.42
- 1.401
- 1.389
- 1.368
- 1.516
- 1.506
- 1.487
- 1.47
- 1.449
- 1.436
- 1.29
- 1.415
- 1.41
- 1.271
- 1.25
- 1.236
- 1.373
- 1.234
- 1.352
- 1.204
- 1.323
- 1.187
- 1.18
- 1.163
- 1.167
- 1.295
- 1.283
- 1.157
- 1.141
- 1.138
- 1.138
- 1.126
- 1.115
- 1.111
- 1.103
- 1.233
- 1.227
- 1.097
- 1.219
- 1.091
- 1.079
- 1.21
- 1.09
- 1.077
- 1.074
- 1.071
- 1.065
- 1.067
- 1.059
- 1.18
- 1.17
- 1.058
- 1.045
- 1.038
- 1.051
- 1.035
- 1.04
- 1.151
- 1.042
- 1.027
- 1.023
- 1.03
- 1.02
- 1.018
- 1.011
- 1.014
- 1.132
- 1.013
- 1.009
- 1.012
- 1.006
- 1.006
- 0.998
- 0.997
- 1.113
- 1.004
unequal: 0
verbose: 1
