avg_train_accuracy: 0.817
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.025372340425531915
- 0.053085106382978725
- 0.11680851063829788
- 0.27606382978723404
- 0.3818617021276596
- 0.43867021276595747
- 0.4896808510638298
- 0.5221808510638298
- 0.5493085106382979
- 0.565
- 0.5815425531914894
- 0.5973936170212766
- 0.6096276595744681
- 0.616436170212766
- 0.6312234042553192
- 0.6340425531914894
- 0.6463297872340426
- 0.6473936170212766
- 0.648936170212766
- 0.6593085106382979
- 0.6653191489361702
- 0.6696276595744681
- 0.6703191489361702
- 0.6722872340425532
- 0.6765425531914894
- 0.6850531914893617
- 0.685372340425532
- 0.6886702127659574
- 0.6882978723404255
- 0.6947340425531915
- 0.6918085106382978
- 0.695531914893617
- 0.6956382978723404
- 0.6987765957446809
- 0.7004255319148937
- 0.7044148936170213
- 0.7029787234042553
- 0.7081382978723404
- 0.7084574468085106
- 0.7071808510638298
- 0.7076063829787234
- 0.710531914893617
- 0.7115957446808511
- 0.7116489361702127
- 0.7157978723404256
- 0.715
- 0.7194148936170213
- 0.7167553191489362
- 0.7166489361702127
- 0.7226063829787234
- 0.7196808510638298
- 0.7246808510638297
- 0.7193085106382979
- 0.7227659574468085
- 0.7227659574468085
- 0.7222340425531915
- 0.7237765957446809
- 0.7234574468085107
- 0.723563829787234
- 0.7263297872340425
- 0.7253723404255319
- 0.7276063829787234
- 0.7250531914893616
- 0.7260106382978724
- 0.7296808510638297
- 0.7311702127659574
- 0.7295212765957447
- 0.7303191489361702
- 0.7313297872340425
- 0.7305851063829787
- 0.7302659574468086
- 0.7330319148936171
- 0.7340425531914894
- 0.7351063829787234
- 0.7373936170212766
- 0.7346276595744681
- 0.7325
- 0.7332978723404255
- 0.7374468085106383
- 0.7345744680851064
- 0.7357978723404255
- 0.7346276595744681
- 0.7393085106382978
- 0.7371808510638298
- 0.7354787234042554
- 0.7370744680851063
- 0.7386702127659575
- 0.7365425531914893
- 0.7387234042553191
- 0.7418617021276596
- 0.7377659574468085
- 0.7419148936170212
- 0.7397340425531915
- 0.7404787234042554
- 0.7434574468085107
- 0.7404787234042554
- 0.7411170212765957
- 0.7417021276595744
- 0.7430851063829788
- 0.7459574468085106
test_loss_list:
- 3.7729039001464844
- 3.721994997660319
- 3.571964661280314
- 3.264808702468872
- 2.918136361440023
- 2.5974145857493083
- 2.3637107753753663
- 2.1844974168141684
- 2.0421619542439777
- 1.9238664690653484
- 1.8409151681264242
- 1.768456999460856
- 1.7121758000055949
- 1.6622471777598062
- 1.7141446685791015
- 1.6020316155751546
- 1.670834444363912
- 1.5424936866760255
- 1.5130450296401978
- 1.6010863574345906
- 1.6095877615610759
- 1.6164511060714721
- 1.477043940226237
- 1.4435276222229003
- 1.417318148612976
- 1.527277388572693
- 1.5483487224578858
- 1.5587334871292113
- 1.4149980290730795
- 1.5274421803156535
- 1.3852934662501017
- 1.3599467182159424
- 1.3343429438273111
- 1.31572536945343
- 1.44610630830129
- 1.4683635568618774
- 1.3226032702128092
- 1.453473890622457
- 1.471703012784322
- 1.316647006670634
- 1.3017586930592855
- 1.2733510796229044
- 1.2467791763941447
- 1.225342214902242
- 1.3683875830968222
- 1.2353024832407633
- 1.359991087913513
- 1.2253890419006348
- 1.2042473737398784
- 1.3438551568984984
- 1.3746499808629353
- 1.3980489730834962
- 1.2355050937334697
- 1.362882563273112
- 1.2317831158638
- 1.1958580295244852
- 1.3319134871164957
- 1.182893545627594
- 1.1591072702407836
- 1.1461736679077148
- 1.1268884491920472
- 1.277054983774821
- 1.1437993121147156
- 1.134909196694692
- 1.272269407113393
- 1.2896556480725607
- 1.151620454788208
- 1.1291501824061076
- 1.109787216981252
- 1.1091813286145529
- 1.0928750030199688
- 1.0864175009727477
- 1.2349395402272543
- 1.256335190931956
- 1.2903972506523131
- 1.131776044368744
- 1.109294618765513
- 1.0883713682492575
- 1.0813520948092143
- 1.060161633491516
- 1.2193580603599548
- 1.0831244119008383
- 1.2275086069107055
- 1.0936561965942382
- 1.0670761688550314
- 1.056744483311971
- 1.202846015294393
- 1.0625062958399454
- 1.040397625764211
- 1.1952725378672282
- 1.052168530623118
- 1.2054782128334045
- 1.0618323397636413
- 1.0459329922993978
- 1.180674254099528
- 1.0607461007436116
- 1.0321604776382447
- 1.020123701095581
- 1.014239784081777
- 1.1565129550298054
train_accuracy:
- 0.048
- 0.075
- 0.146
- 0.321
- 0.44
- 0.429
- 0.542
- 0.531
- 0.0
- 0.608
- 0.654
- 0.646
- 0.633
- 0.646
- 0.708
- 0.715
- 0.725
- 0.0
- 0.696
- 0.737
- 0.74
- 0.735
- 0.733
- 0.742
- 0.767
- 0.779
- 0.775
- 0.777
- 0.742
- 0.779
- 0.0
- 0.777
- 0.763
- 0.767
- 0.767
- 0.779
- 0.0
- 0.752
- 0.773
- 0.779
- 0.763
- 0.0
- 0.787
- 0.777
- 0.794
- 0.8
- 0.775
- 0.765
- 0.783
- 0.796
- 0.787
- 0.798
- 0.792
- 0.783
- 0.815
- 0.775
- 0.798
- 0.781
- 0.0
- 0.8
- 0.812
- 0.802
- 0.781
- 0.794
- 0.798
- 0.812
- 0.798
- 0.792
- 0.785
- 0.796
- 0.0
- 0.817
- 0.798
- 0.827
- 0.81
- 0.835
- 0.0
- 0.792
- 0.806
- 0.796
- 0.792
- 0.817
- 0.804
- 0.8
- 0.821
- 0.821
- 0.806
- 0.794
- 0.796
- 0.806
- 0.81
- 0.817
- 0.804
- 0.815
- 0.827
- 0.812
- 0.815
- 0.798
- 0.817
- 0.817
train_loss:
- 3.492
- 3.797
- 3.704
- 3.499
- 3.2
- 2.64
- 2.416
- 2.249
- 2.11
- 1.991
- 1.907
- 1.832
- 1.772
- 1.722
- 1.863
- 1.633
- 1.771
- 1.567
- 1.52
- 1.672
- 1.626
- 1.607
- 1.438
- 1.412
- 1.393
- 1.52
- 1.5
- 1.486
- 1.346
- 1.446
- 1.3
- 1.285
- 1.282
- 1.274
- 1.388
- 1.382
- 1.251
- 1.358
- 1.348
- 1.231
- 1.21
- 1.201
- 1.192
- 1.176
- 1.305
- 1.172
- 1.286
- 1.173
- 1.153
- 1.269
- 1.261
- 1.25
- 1.139
- 1.246
- 1.125
- 1.115
- 1.228
- 1.113
- 1.111
- 1.097
- 1.098
- 1.212
- 1.096
- 1.082
- 1.196
- 1.19
- 1.072
- 1.078
- 1.072
- 1.058
- 1.066
- 1.06
- 1.162
- 1.17
- 1.152
- 1.057
- 1.043
- 1.046
- 1.032
- 1.039
- 1.146
- 1.043
- 1.14
- 1.032
- 1.024
- 1.028
- 1.128
- 1.024
- 1.011
- 1.122
- 1.016
- 1.119
- 1.012
- 1.006
- 1.111
- 0.996
- 0.995
- 0.99
- 0.991
- 1.101
unequal: 0
verbose: 1
