avg_train_accuracy: 0.838
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0274468085106383
- 0.05813829787234043
- 0.10090425531914894
- 0.20803191489361703
- 0.3272340425531915
- 0.3649468085106383
- 0.4295212765957447
- 0.4777127659574468
- 0.48946808510638296
- 0.5147872340425532
- 0.5463829787234042
- 0.5627659574468085
- 0.5756914893617021
- 0.5894148936170213
- 0.5991489361702128
- 0.6138297872340426
- 0.6204787234042554
- 0.6265425531914893
- 0.6297340425531915
- 0.6326595744680851
- 0.6400531914893617
- 0.6447872340425532
- 0.6395744680851064
- 0.6531382978723405
- 0.6589893617021276
- 0.6612234042553191
- 0.6621276595744681
- 0.6677127659574468
- 0.6748404255319149
- 0.67
- 0.6773404255319149
- 0.6814361702127659
- 0.6828723404255319
- 0.6850531914893617
- 0.6872340425531915
- 0.6866489361702127
- 0.6940425531914893
- 0.693031914893617
- 0.6988829787234042
- 0.6972340425531914
- 0.7007446808510638
- 0.7035638297872341
- 0.7052659574468085
- 0.7060106382978724
- 0.7045212765957447
- 0.7025531914893617
- 0.708936170212766
- 0.7078191489361703
- 0.7074468085106383
- 0.7107446808510638
- 0.7148404255319148
- 0.7143617021276596
- 0.7138829787234042
- 0.7116489361702127
- 0.7165957446808511
- 0.7204255319148937
- 0.7170744680851063
- 0.7189893617021277
- 0.7186170212765958
- 0.7203191489361702
- 0.7197872340425532
- 0.7215425531914894
- 0.7189893617021277
- 0.7214893617021276
- 0.721436170212766
- 0.7247872340425532
- 0.7252659574468086
- 0.7182978723404255
- 0.7306382978723405
- 0.7225
- 0.725
- 0.7278191489361702
- 0.7252127659574468
- 0.7301595744680851
- 0.7296276595744681
- 0.7315957446808511
- 0.7315425531914893
- 0.7322340425531915
- 0.7305851063829787
- 0.7278191489361702
- 0.7356382978723405
- 0.7320212765957447
- 0.7296276595744681
- 0.7337765957446809
- 0.7311702127659574
- 0.7359042553191489
- 0.734468085106383
- 0.7364893617021276
- 0.7369148936170212
- 0.7384042553191489
- 0.7378191489361702
- 0.7361170212765957
- 0.7392021276595745
- 0.7377659574468085
- 0.7377659574468085
- 0.7396276595744681
- 0.7373404255319149
- 0.7392553191489362
- 0.7377659574468085
- 0.7406382978723405
test_loss_list:
- 3.7853826522827148
- 3.752735481262207
- 3.669642260869344
- 3.4019266668955486
- 3.0416025829315188
- 2.7540380160013833
- 2.5247323449452717
- 2.402107760111491
- 2.2258241812388104
- 2.1170515489578245
- 2.0976925039291383
- 2.0613745737075804
- 2.038395520846049
- 1.9965997695922852
- 1.980543402036031
- 1.9273345454533894
- 1.9284400447209675
- 1.9141437482833863
- 1.915093100865682
- 1.9041626342137654
- 1.9002958567937216
- 1.8973943996429443
- 1.7529748741785685
- 1.8296226040522257
- 1.8450462452570597
- 1.8478025070826212
- 1.8456343825658161
- 1.805152366956075
- 1.8143985684712727
- 1.6294878149032592
- 1.7499208068847656
- 1.769202535947164
- 1.750352398554484
- 1.7525200462341308
- 1.7593445857365926
- 1.5881317154566448
- 1.6814995845158895
- 1.7219704294204712
- 1.6987291971842449
- 1.723880999883016
- 1.720072143872579
- 1.7197172212600709
- 1.7354558277130128
- 1.7137082386016846
- 1.7248740895589192
- 1.5214936447143554
- 1.666028470993042
- 1.4581314500172933
- 1.4044511477152506
- 1.5632778803507488
- 1.5803431940078736
- 1.5740546417236327
- 1.5918683608373005
- 1.609926980336507
- 1.5994031524658203
- 1.5911626768112184
- 1.620042839050293
- 1.6044562180836996
- 1.4221539862950643
- 1.3761310005187988
- 1.5312133073806762
- 1.5330991458892822
- 1.3277756643295289
- 1.4880867528915405
- 1.2991374762852987
- 1.450136006673177
- 1.461607977549235
- 1.2928184056282044
- 1.4512637042999268
- 1.259761913617452
- 1.4029566526412964
- 1.4196983623504638
- 1.2519298116366069
- 1.200181527932485
- 1.3566984303792318
- 1.400885518391927
- 1.2450997614860535
- 1.3621649106343587
- 1.205569605032603
- 1.1585307677586874
- 1.34123881260554
- 1.357372883160909
- 1.1851699392000834
- 1.3455525890986124
- 1.164111734231313
- 1.3154192749659221
- 1.1712245122591654
- 1.309579356511434
- 1.3288022287686665
- 1.3619087727864583
- 1.1809047357241313
- 1.14706916252772
- 1.3112975056966145
- 1.337654430071513
- 1.1802071539560954
- 1.2983636768658955
- 1.3152176721890767
- 1.1726041730244954
- 1.1336887510617575
- 1.1137544353803
train_accuracy:
- 0.029
- 0.077
- 0.104
- 0.233
- 0.0
- 0.415
- 0.527
- 0.51
- 0.0
- 0.0
- 0.596
- 0.625
- 0.6
- 0.667
- 0.675
- 0.656
- 0.681
- 0.708
- 0.679
- 0.694
- 0.723
- 0.698
- 0.683
- 0.731
- 0.7
- 0.748
- 0.692
- 0.742
- 0.742
- 0.758
- 0.76
- 0.733
- 0.723
- 0.752
- 0.729
- 0.0
- 0.769
- 0.754
- 0.758
- 0.79
- 0.777
- 0.783
- 0.767
- 0.779
- 0.758
- 0.0
- 0.756
- 0.0
- 0.777
- 0.781
- 0.783
- 0.769
- 0.781
- 0.802
- 0.79
- 0.79
- 0.733
- 0.783
- 0.787
- 0.798
- 0.783
- 0.769
- 0.0
- 0.796
- 0.798
- 0.823
- 0.8
- 0.0
- 0.787
- 0.0
- 0.802
- 0.798
- 0.0
- 0.0
- 0.804
- 0.808
- 0.0
- 0.833
- 0.796
- 0.781
- 0.821
- 0.806
- 0.792
- 0.838
- 0.765
- 0.796
- 0.775
- 0.8
- 0.792
- 0.8
- 0.819
- 0.0
- 0.838
- 0.817
- 0.827
- 0.817
- 0.808
- 0.819
- 0.0
- 0.838
train_loss:
- 3.006
- 3.817
- 3.763
- 2.803
- 2.523
- 2.298
- 2.125
- 2.635
- 1.861
- 1.785
- 2.259
- 2.157
- 2.059
- 2.031
- 1.953
- 1.906
- 1.87
- 1.81
- 1.783
- 1.748
- 1.706
- 1.701
- 1.347
- 1.657
- 1.596
- 1.563
- 1.534
- 1.591
- 1.548
- 1.261
- 1.508
- 1.496
- 1.468
- 1.46
- 1.423
- 1.196
- 1.43
- 1.419
- 1.384
- 1.385
- 1.367
- 1.363
- 1.332
- 1.389
- 1.355
- 1.144
- 1.322
- 1.1
- 1.063
- 1.31
- 1.274
- 1.307
- 1.304
- 1.274
- 1.251
- 1.281
- 1.248
- 1.283
- 1.039
- 0.977
- 1.238
- 1.233
- 1.028
- 1.233
- 0.993
- 1.205
- 1.229
- 0.971
- 1.21
- 0.979
- 1.217
- 1.204
- 0.97
- 0.932
- 1.188
- 1.176
- 0.915
- 1.176
- 0.946
- 0.923
- 1.136
- 1.163
- 0.924
- 1.119
- 0.917
- 1.152
- 0.896
- 1.146
- 1.163
- 1.149
- 0.893
- 0.907
- 1.138
- 1.108
- 0.88
- 1.129
- 1.12
- 0.865
- 0.839
- 0.842
unequal: 0
verbose: 1
