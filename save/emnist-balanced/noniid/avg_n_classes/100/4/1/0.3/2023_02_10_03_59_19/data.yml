avg_train_accuracy: 0.804
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.028138297872340425
- 0.05531914893617021
- 0.15159574468085107
- 0.27574468085106385
- 0.3415957446808511
- 0.4110106382978723
- 0.47558510638297874
- 0.5061702127659574
- 0.5334574468085106
- 0.5399468085106383
- 0.5657446808510638
- 0.5813297872340426
- 0.5921276595744681
- 0.6007446808510638
- 0.6151063829787234
- 0.6237765957446808
- 0.63
- 0.6334574468085107
- 0.6451063829787234
- 0.6505851063829787
- 0.6549468085106382
- 0.6606382978723404
- 0.6625
- 0.6646276595744681
- 0.6711702127659575
- 0.6725531914893617
- 0.6754255319148936
- 0.6762234042553191
- 0.6825531914893617
- 0.6831382978723404
- 0.6842021276595744
- 0.6897340425531915
- 0.6878191489361702
- 0.6937765957446809
- 0.6942021276595745
- 0.6977127659574468
- 0.7
- 0.6985106382978723
- 0.7022872340425532
- 0.703936170212766
- 0.7070744680851064
- 0.7063829787234043
- 0.7014361702127659
- 0.7065425531914894
- 0.7105851063829787
- 0.7067021276595745
- 0.7096808510638298
- 0.7103191489361702
- 0.7145744680851064
- 0.7148936170212766
- 0.7117553191489362
- 0.7147872340425532
- 0.7154787234042553
- 0.7200531914893618
- 0.7178723404255319
- 0.7197872340425532
- 0.718404255319149
- 0.7214893617021276
- 0.7232978723404255
- 0.7167021276595744
- 0.7241489361702128
- 0.7246808510638297
- 0.7220744680851063
- 0.7192553191489361
- 0.7247340425531915
- 0.725
- 0.7281382978723404
- 0.725531914893617
- 0.7254787234042553
- 0.7276595744680852
- 0.7262765957446808
- 0.7267021276595744
- 0.729468085106383
- 0.7301595744680851
- 0.7320744680851063
- 0.7319148936170212
- 0.732872340425532
- 0.730531914893617
- 0.7315425531914893
- 0.7311170212765957
- 0.7335106382978723
- 0.734095744680851
- 0.7372872340425531
- 0.7351063829787234
- 0.7330851063829787
- 0.7363829787234043
- 0.7352127659574468
- 0.7345744680851064
- 0.7372340425531915
- 0.7345744680851064
- 0.7398404255319149
- 0.7415425531914893
- 0.7335106382978723
- 0.7405851063829787
- 0.7360106382978724
- 0.7410106382978724
- 0.7434042553191489
- 0.7377659574468085
- 0.7423404255319149
- 0.7401595744680851
test_loss_list:
- 3.772191677093506
- 3.7198111152648927
- 3.55390744527181
- 3.2194062010447184
- 2.864134422938029
- 2.591695884068807
- 2.4123608334859212
- 2.3115411122639973
- 2.2322547515233357
- 2.1099782466888426
- 2.1244435834884645
- 2.087456390062968
- 2.0536920849482216
- 1.916385882695516
- 1.9699814128875732
- 1.9749414348602294
- 1.9565083233515421
- 1.9551668882369995
- 1.9319376643498738
- 1.9134746090571086
- 1.9043472210566204
- 1.900897658665975
- 1.8808808994293214
- 1.894340607325236
- 1.884953603744507
- 1.8829426018397013
- 1.7044377660751342
- 1.664247760772705
- 1.7935003328323365
- 1.7871525971094768
- 1.80301992893219
- 1.8088113355636597
- 1.6082425053914389
- 1.7592622550328572
- 1.7518386793136598
- 1.7447265879313152
- 1.779717141787211
- 1.7838605880737304
- 1.5737059958775839
- 1.725690213839213
- 1.7148608525594076
- 1.7486334133148194
- 1.5348122723897297
- 1.693410579363505
- 1.695494402249654
- 1.5071985832850139
- 1.654260598818461
- 1.676343274116516
- 1.6869049962361653
- 1.7005614344278972
- 1.482357349395752
- 1.649066990216573
- 1.4234926764170328
- 1.6203598658243814
- 1.6113252147038777
- 1.6284084065755209
- 1.4260845263799031
- 1.6006359195709228
- 1.6066267983118694
- 1.391286958058675
- 1.5849817673365274
- 1.5742086760203045
- 1.3640357971191406
- 1.3573655351003011
- 1.5307578865687053
- 1.3445876550674438
- 1.4913232771555582
- 1.3292374960581461
- 1.3062191724777221
- 1.4736820284525554
- 1.5024062792460124
- 1.3125685230890909
- 1.4776640335718791
- 1.4980125951766967
- 1.524449847539266
- 1.526962251663208
- 1.3235394207636515
- 1.3054098431269328
- 1.2754283253351848
- 1.4294263903299969
- 1.4651313734054565
- 1.2871801733970643
- 1.4268051942189535
- 1.2705034788449605
- 1.2306965430577597
- 1.2215718507766724
- 1.2137251234054565
- 1.1974386342366536
- 1.1797945626576742
- 1.1642043010393779
- 1.334700468381246
- 1.3911367734273274
- 1.205198372999827
- 1.371015159289042
- 1.1991600966453553
- 1.3613066148757935
- 1.3756803290049235
- 1.2171485408147176
- 1.3605354245503742
- 1.3746887652079265
train_accuracy:
- 0.044
- 0.067
- 0.169
- 0.306
- 0.394
- 0.483
- 0.523
- 0.571
- 0.604
- 0.0
- 0.638
- 0.621
- 0.608
- 0.0
- 0.675
- 0.685
- 0.698
- 0.685
- 0.698
- 0.7
- 0.744
- 0.704
- 0.7
- 0.725
- 0.721
- 0.752
- 0.773
- 0.0
- 0.733
- 0.75
- 0.748
- 0.746
- 0.771
- 0.773
- 0.765
- 0.754
- 0.769
- 0.769
- 0.0
- 0.787
- 0.773
- 0.771
- 0.758
- 0.783
- 0.783
- 0.767
- 0.76
- 0.777
- 0.779
- 0.812
- 0.769
- 0.779
- 0.765
- 0.806
- 0.781
- 0.81
- 0.779
- 0.775
- 0.798
- 0.812
- 0.8
- 0.802
- 0.785
- 0.779
- 0.823
- 0.812
- 0.787
- 0.0
- 0.8
- 0.808
- 0.8
- 0.773
- 0.817
- 0.8
- 0.79
- 0.796
- 0.79
- 0.785
- 0.825
- 0.785
- 0.812
- 0.794
- 0.812
- 0.798
- 0.796
- 0.796
- 0.0
- 0.785
- 0.825
- 0.804
- 0.833
- 0.808
- 0.0
- 0.819
- 0.0
- 0.815
- 0.81
- 0.815
- 0.844
- 0.804
train_loss:
- 3.052
- 3.796
- 3.689
- 3.452
- 2.472
- 2.184
- 2.672
- 2.479
- 2.343
- 1.811
- 2.134
- 2.082
- 1.993
- 1.61
- 1.927
- 1.862
- 1.807
- 1.762
- 1.722
- 1.709
- 1.662
- 1.659
- 1.616
- 1.582
- 1.564
- 1.546
- 1.351
- 1.27
- 1.504
- 1.473
- 1.458
- 1.489
- 1.261
- 1.438
- 1.424
- 1.403
- 1.402
- 1.4
- 1.207
- 1.365
- 1.358
- 1.344
- 1.151
- 1.334
- 1.311
- 1.112
- 1.322
- 1.329
- 1.325
- 1.301
- 1.096
- 1.27
- 1.076
- 1.299
- 1.285
- 1.263
- 1.04
- 1.262
- 1.236
- 1.027
- 1.251
- 1.255
- 1.016
- 0.975
- 1.245
- 0.99
- 1.226
- 0.987
- 0.959
- 1.202
- 1.194
- 0.977
- 1.191
- 1.176
- 1.213
- 1.168
- 0.986
- 0.922
- 0.935
- 1.181
- 1.17
- 0.942
- 1.171
- 0.937
- 0.929
- 0.902
- 0.905
- 0.902
- 0.895
- 0.888
- 1.146
- 1.139
- 0.888
- 1.109
- 0.884
- 1.133
- 1.133
- 0.913
- 1.112
- 1.133
unequal: 0
verbose: 1
