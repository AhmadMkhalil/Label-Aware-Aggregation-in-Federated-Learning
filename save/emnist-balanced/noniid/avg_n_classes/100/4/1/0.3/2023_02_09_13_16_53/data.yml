avg_train_accuracy: 0.85
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06436170212765957
- 0.11888297872340425
- 0.18893617021276596
- 0.2875
- 0.3316489361702128
- 0.42271276595744683
- 0.4671276595744681
- 0.4940425531914894
- 0.5302127659574468
- 0.545
- 0.5681382978723404
- 0.5787234042553191
- 0.5832446808510638
- 0.6027127659574468
- 0.6129255319148936
- 0.6225531914893617
- 0.6296808510638298
- 0.6335106382978724
- 0.6395744680851064
- 0.6463829787234042
- 0.6451595744680851
- 0.6506382978723404
- 0.6620744680851064
- 0.6631914893617021
- 0.6661170212765958
- 0.6735106382978724
- 0.6695212765957447
- 0.6756382978723404
- 0.6825
- 0.6828723404255319
- 0.6879255319148936
- 0.6873404255319149
- 0.6917021276595745
- 0.6945744680851064
- 0.6915425531914894
- 0.6981382978723404
- 0.6987234042553192
- 0.6986702127659574
- 0.7003191489361702
- 0.7011170212765957
- 0.7075531914893617
- 0.7075
- 0.7059042553191489
- 0.7083510638297872
- 0.7135638297872341
- 0.7126063829787234
- 0.7148404255319148
- 0.7143085106382979
- 0.7149468085106383
- 0.7158510638297872
- 0.7151063829787234
- 0.7192021276595745
- 0.7170744680851063
- 0.7162234042553192
- 0.7186170212765958
- 0.7197340425531915
- 0.7208510638297873
- 0.7245212765957447
- 0.721968085106383
- 0.723404255319149
- 0.7226595744680852
- 0.7253191489361702
- 0.7265957446808511
- 0.7260106382978724
- 0.7297340425531915
- 0.7302127659574468
- 0.7297872340425532
- 0.7302659574468086
- 0.7295212765957447
- 0.7331382978723404
- 0.7321808510638298
- 0.7313297872340425
- 0.7334574468085107
- 0.7346276595744681
- 0.7356382978723405
- 0.7330319148936171
- 0.731063829787234
- 0.7344148936170213
- 0.7363829787234043
- 0.7354255319148936
- 0.7338829787234042
- 0.7381382978723404
- 0.737659574468085
- 0.7372340425531915
- 0.7349468085106383
- 0.7425531914893617
- 0.7390425531914894
- 0.7390425531914894
- 0.7392553191489362
- 0.740531914893617
- 0.7413829787234043
- 0.7421276595744681
- 0.7394148936170213
- 0.7409042553191489
- 0.7423404255319149
- 0.7407978723404255
- 0.7432978723404255
- 0.7431914893617021
- 0.7445212765957446
- 0.7411170212765957
test_loss_list:
- 3.77274214108785
- 3.7096968841552735
- 3.5244192282358804
- 3.1895531845092773
- 2.876916478474935
- 2.6526254844665527
- 2.466792214711507
- 2.341157064437866
- 2.2413771184285483
- 2.1183224010467527
- 2.0933884636561078
- 2.0621332136789956
- 1.9512308899561563
- 1.9680209843317669
- 1.943877420425415
- 1.9151784054438272
- 1.904953776995341
- 1.8866946951548258
- 1.883890126546224
- 1.88954648176829
- 1.722618989944458
- 1.69097065448761
- 1.7589066219329834
- 1.7848538827896119
- 1.623885752360026
- 1.7022614192962646
- 1.579962156613668
- 1.6855152940750122
- 1.698339540163676
- 1.696958883603414
- 1.7073753261566162
- 1.714033652941386
- 1.6993185806274413
- 1.7197451035181681
- 1.5440416860580444
- 1.6428648471832275
- 1.6544861300786335
- 1.6751330439249674
- 1.680495122273763
- 1.5034776735305786
- 1.6164036289850872
- 1.6247764778137208
- 1.4572880283991496
- 1.436784054438273
- 1.3871461137135823
- 1.5276309617360433
- 1.5372647142410278
- 1.5584961446126302
- 1.5768197170893352
- 1.586921378771464
- 1.4133642037709555
- 1.5411155780156454
- 1.3893845240275065
- 1.5285571320851643
- 1.5173249594370524
- 1.550877602895101
- 1.5727981885274251
- 1.5615966383616129
- 1.572243636449178
- 1.3889613739649456
- 1.360213311513265
- 1.4788669776916503
- 1.4944317611058553
- 1.3281627798080444
- 1.4634345149993897
- 1.4705222368240356
- 1.498834408124288
- 1.5023588434855144
- 1.5226497411727906
- 1.5533313767115275
- 1.52493505636851
- 1.519673908551534
- 1.543102216720581
- 1.551087555885315
- 1.5586859305699667
- 1.3758213567733764
- 1.327324802875519
- 1.2948117200533549
- 1.43505859375
- 1.2668499302864076
- 1.2184230788548787
- 1.3624292198816936
- 1.4070172119140625
- 1.40552170753479
- 1.247696487903595
- 1.3834356737136841
- 1.4121755329767862
- 1.4178664859135945
- 1.2431596438090007
- 1.3835328531265259
- 1.4249976046880086
- 1.2406937098503112
- 1.3657455126444498
- 1.2036030594507854
- 1.3334356172879538
- 1.3839382235209148
- 1.2109058197339375
- 1.1782666905721029
- 1.3205200489362081
- 1.3626427698135375
train_accuracy:
- 0.037
- 0.131
- 0.21
- 0.323
- 0.373
- 0.465
- 0.51
- 0.55
- 0.546
- 0.577
- 0.604
- 0.667
- 0.654
- 0.688
- 0.702
- 0.683
- 0.681
- 0.696
- 0.725
- 0.74
- 0.735
- 0.0
- 0.692
- 0.746
- 0.0
- 0.754
- 0.0
- 0.756
- 0.75
- 0.775
- 0.752
- 0.758
- 0.758
- 0.735
- 0.777
- 0.723
- 0.769
- 0.765
- 0.781
- 0.0
- 0.775
- 0.769
- 0.0
- 0.802
- 0.0
- 0.802
- 0.787
- 0.81
- 0.815
- 0.787
- 0.0
- 0.787
- 0.815
- 0.781
- 0.771
- 0.8
- 0.785
- 0.798
- 0.808
- 0.796
- 0.812
- 0.804
- 0.8
- 0.0
- 0.829
- 0.812
- 0.819
- 0.787
- 0.808
- 0.806
- 0.775
- 0.794
- 0.804
- 0.806
- 0.779
- 0.0
- 0.825
- 0.827
- 0.838
- 0.0
- 0.0
- 0.81
- 0.808
- 0.835
- 0.823
- 0.817
- 0.802
- 0.821
- 0.785
- 0.833
- 0.827
- 0.821
- 0.827
- 0.0
- 0.848
- 0.829
- 0.0
- 0.838
- 0.835
- 0.85
train_loss:
- 3.846
- 3.797
- 3.686
- 2.706
- 2.423
- 2.964
- 2.72
- 2.54
- 2.407
- 1.838
- 2.221
- 2.102
- 1.64
- 1.985
- 1.952
- 1.88
- 1.874
- 1.819
- 1.738
- 1.722
- 1.413
- 1.352
- 1.674
- 1.599
- 1.307
- 1.602
- 1.278
- 1.558
- 1.503
- 1.545
- 1.481
- 1.468
- 1.486
- 1.445
- 1.187
- 1.456
- 1.428
- 1.403
- 1.392
- 1.161
- 1.393
- 1.365
- 1.146
- 1.087
- 1.085
- 1.341
- 1.315
- 1.308
- 1.313
- 1.287
- 1.053
- 1.313
- 1.04
- 1.264
- 1.249
- 1.25
- 1.234
- 1.244
- 1.221
- 1.049
- 0.991
- 1.239
- 1.239
- 1.007
- 1.23
- 1.206
- 1.211
- 1.2
- 1.194
- 1.172
- 1.195
- 1.211
- 1.169
- 1.168
- 1.198
- 1.008
- 0.978
- 0.949
- 1.178
- 0.971
- 0.937
- 1.168
- 1.138
- 1.153
- 0.952
- 1.167
- 1.135
- 1.144
- 0.951
- 1.132
- 1.124
- 0.928
- 1.128
- 0.92
- 1.129
- 1.108
- 0.929
- 0.872
- 1.123
- 1.085
unequal: 0
verbose: 1
