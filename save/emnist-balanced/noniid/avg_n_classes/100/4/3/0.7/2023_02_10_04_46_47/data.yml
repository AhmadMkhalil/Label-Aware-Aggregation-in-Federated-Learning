avg_train_accuracy: 0.852
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.061861702127659575
- 0.17680851063829786
- 0.3175531914893617
- 0.3809574468085106
- 0.4167021276595745
- 0.44680851063829785
- 0.45398936170212767
- 0.4761170212765957
- 0.4794148936170213
- 0.49042553191489363
- 0.4997340425531915
- 0.5075
- 0.5111702127659574
- 0.5169148936170213
- 0.5205851063829787
- 0.5256914893617022
- 0.533936170212766
- 0.5405851063829787
- 0.5461170212765958
- 0.5521276595744681
- 0.5554787234042553
- 0.5529255319148936
- 0.5602127659574468
- 0.5612765957446808
- 0.5640957446808511
- 0.5699468085106383
- 0.5700531914893617
- 0.5732978723404255
- 0.5754255319148937
- 0.5798936170212766
- 0.5772340425531914
- 0.5829787234042553
- 0.5814893617021276
- 0.585531914893617
- 0.5863297872340425
- 0.5866489361702127
- 0.5887765957446809
- 0.5912765957446808
- 0.5909574468085106
- 0.593563829787234
- 0.5936702127659574
- 0.5952127659574468
- 0.5959574468085106
- 0.5957978723404256
- 0.5980319148936171
- 0.5991489361702128
- 0.5979255319148936
- 0.6018085106382979
- 0.6012765957446808
- 0.6030319148936171
- 0.6046808510638297
- 0.6051595744680851
- 0.6053191489361702
- 0.6060106382978724
- 0.6096276595744681
- 0.6104255319148936
- 0.6093617021276596
- 0.6074468085106383
- 0.6070744680851063
- 0.61
- 0.6112765957446809
- 0.6150531914893617
- 0.6129255319148936
- 0.6100531914893617
- 0.6115425531914893
- 0.6111702127659574
- 0.6132446808510639
- 0.6125
- 0.6134042553191489
- 0.615
- 0.6126063829787234
- 0.6153723404255319
- 0.6146276595744681
- 0.6177659574468085
- 0.6202659574468085
- 0.6216489361702128
- 0.6218085106382979
- 0.6267021276595744
- 0.6175
- 0.6245212765957446
- 0.6255851063829787
- 0.6189893617021277
- 0.6261170212765957
- 0.6280851063829788
- 0.6279787234042553
- 0.6172872340425531
- 0.6272872340425532
- 0.6213829787234042
- 0.6175
- 0.6304787234042554
- 0.6254787234042554
- 0.6311170212765957
- 0.6193085106382978
- 0.6277127659574468
- 0.6322340425531915
- 0.6306382978723404
- 0.6220212765957447
- 0.6287234042553191
- 0.6237765957446808
- 0.6355851063829787
test_loss_list:
- 3.71204376856486
- 3.47327078183492
- 3.09846791267395
- 2.924702558517456
- 2.7559998575846354
- 2.701231050491333
- 2.53932669321696
- 2.5869532998402915
- 2.4177812004089354
- 2.3794530232747397
- 2.467550443013509
- 2.459095624287923
- 2.44008802096049
- 2.4261954847971596
- 2.389729248682658
- 2.3895697911580402
- 2.237567714055379
- 2.3638373025258383
- 2.326561460494995
- 2.2941615931193033
- 2.339974446296692
- 2.2939801534016926
- 2.257921036084493
- 2.2649054606755574
- 2.271927229563395
- 2.4834092744191487
- 2.0556248887379964
- 2.248453048070272
- 2.2242262077331545
- 2.490390933354696
- 2.5232268714904786
- 2.5404435475667317
- 2.2563761981328327
- 2.2622741429011026
- 2.0313739522298175
- 2.1942941395441693
- 2.180861487388611
- 2.4436909596125287
- 2.1754912678400675
- 2.1994522269566854
- 2.1534176111221313
- 1.9431947946548462
- 2.117637561162313
- 2.0988971439997357
- 2.067679821650187
- 2.3969402599334715
- 2.1404243993759153
- 1.8819492324193319
- 2.0593944851557415
- 2.0526576677958173
- 2.037262682914734
- 1.8562108993530273
- 2.018157238960266
- 2.02715190410614
- 1.8182154925664267
- 2.020995864868164
- 2.0230988295873007
- 2.0408677784601847
- 2.3140633805592854
- 1.7906979529062907
- 1.7955797974268595
- 1.7407442077000936
- 1.7456145016352336
- 2.2430095545450848
- 2.3031807788213094
- 2.043692324956258
- 2.671288874944051
- 1.7836745723088583
- 2.0458892806371054
- 2.658221426010132
- 1.7931565777460734
- 1.9931558195749919
- 1.959040493965149
- 1.957544331550598
- 1.7418787924448649
- 1.9027596600850423
- 1.9167603937784832
- 1.690301186243693
- 2.20679896513621
- 1.9222708479563395
- 1.689303207397461
- 2.1306468216578165
- 1.8926023197174073
- 1.7135324716567992
- 1.8946759303410847
- 2.187963145573934
- 1.8459833367665608
- 2.1231593561172484
- 1.905992579460144
- 1.6608969831466676
- 1.8407130209604898
- 1.8443915875752768
- 2.1038855584462484
- 1.6464687871932984
- 1.6221096817652385
- 1.7912994368871054
- 1.8410688734054566
- 1.774907202720642
- 1.8156668694814047
- 1.5868660910924275
train_accuracy:
- 0.108
- 0.0
- 0.458
- 0.542
- 0.554
- 0.585
- 0.633
- 0.65
- 0.0
- 0.0
- 0.0
- 0.669
- 0.713
- 0.0
- 0.0
- 0.731
- 0.754
- 0.721
- 0.758
- 0.0
- 0.729
- 0.781
- 0.0
- 0.0
- 0.729
- 0.75
- 0.81
- 0.783
- 0.0
- 0.787
- 0.806
- 0.806
- 0.758
- 0.806
- 0.771
- 0.827
- 0.798
- 0.817
- 0.821
- 0.812
- 0.81
- 0.804
- 0.0
- 0.81
- 0.8
- 0.819
- 0.8
- 0.0
- 0.819
- 0.835
- 0.815
- 0.802
- 0.0
- 0.821
- 0.827
- 0.796
- 0.821
- 0.794
- 0.827
- 0.794
- 0.831
- 0.827
- 0.835
- 0.838
- 0.833
- 0.84
- 0.854
- 0.842
- 0.0
- 0.856
- 0.844
- 0.0
- 0.825
- 0.0
- 0.819
- 0.863
- 0.831
- 0.0
- 0.867
- 0.0
- 0.0
- 0.867
- 0.835
- 0.825
- 0.867
- 0.84
- 0.844
- 0.0
- 0.0
- 0.819
- 0.835
- 0.0
- 0.844
- 0.812
- 0.0
- 0.865
- 0.869
- 0.865
- 0.844
- 0.852
train_loss:
- 2.707
- 2.843
- 2.512
- 2.513
- 1.978
- 1.83
- 1.564
- 1.623
- 1.415
- 1.359
- 1.507
- 1.471
- 1.425
- 1.389
- 1.352
- 1.319
- 1.143
- 1.282
- 1.241
- 1.246
- 1.196
- 1.191
- 1.196
- 1.159
- 1.141
- 1.273
- 1.002
- 1.094
- 1.085
- 1.213
- 1.196
- 1.16
- 1.047
- 1.033
- 0.918
- 1.026
- 1.034
- 1.121
- 1.001
- 0.979
- 0.998
- 0.873
- 0.96
- 0.954
- 0.973
- 1.054
- 0.936
- 0.836
- 0.951
- 0.934
- 0.938
- 0.812
- 0.933
- 0.926
- 0.81
- 0.9
- 0.916
- 0.888
- 0.988
- 0.807
- 0.778
- 0.781
- 0.778
- 0.961
- 0.957
- 0.861
- 1.053
- 0.791
- 0.839
- 1.047
- 0.784
- 0.855
- 0.856
- 0.862
- 0.749
- 0.834
- 0.845
- 0.74
- 0.908
- 0.83
- 0.746
- 0.937
- 0.835
- 0.74
- 0.828
- 0.912
- 0.829
- 0.916
- 0.808
- 0.718
- 0.814
- 0.813
- 0.897
- 0.723
- 0.699
- 0.806
- 0.778
- 0.805
- 0.775
- 0.708
unequal: 0
verbose: 1
