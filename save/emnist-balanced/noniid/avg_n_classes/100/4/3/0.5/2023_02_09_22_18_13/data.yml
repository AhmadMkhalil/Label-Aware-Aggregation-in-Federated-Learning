avg_train_accuracy: 0.829
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02324468085106383
- 0.0698936170212766
- 0.23335106382978724
- 0.2823404255319149
- 0.35143617021276596
- 0.38127659574468087
- 0.4271276595744681
- 0.4313297872340425
- 0.4581914893617021
- 0.4715957446808511
- 0.4807446808510638
- 0.4826595744680851
- 0.4999468085106383
- 0.5080851063829788
- 0.5184574468085107
- 0.5088297872340426
- 0.5175
- 0.5304787234042553
- 0.5277127659574468
- 0.5370744680851064
- 0.5340425531914894
- 0.5450531914893617
- 0.5497872340425531
- 0.5527127659574468
- 0.555531914893617
- 0.5570744680851064
- 0.564627659574468
- 0.564468085106383
- 0.5707978723404256
- 0.5743617021276596
- 0.5701063829787234
- 0.5728191489361703
- 0.5763297872340426
- 0.5815425531914894
- 0.5781914893617022
- 0.5788829787234042
- 0.5846808510638298
- 0.5886702127659574
- 0.5892021276595745
- 0.5851063829787234
- 0.5856382978723405
- 0.5874468085106384
- 0.5912234042553192
- 0.5947340425531915
- 0.5938297872340426
- 0.5918617021276595
- 0.5942021276595745
- 0.5997340425531915
- 0.5946808510638298
- 0.5980851063829787
- 0.6
- 0.5994680851063829
- 0.5992021276595745
- 0.6038829787234042
- 0.6070212765957447
- 0.6089361702127659
- 0.6028191489361702
- 0.6102127659574468
- 0.6023936170212766
- 0.603404255319149
- 0.6052127659574468
- 0.6046808510638297
- 0.6064893617021276
- 0.6055851063829787
- 0.6111170212765957
- 0.6107446808510638
- 0.6090425531914894
- 0.6109574468085106
- 0.6103723404255319
- 0.613563829787234
- 0.612872340425532
- 0.6104255319148936
- 0.6151063829787234
- 0.6123936170212766
- 0.6162765957446809
- 0.6159574468085106
- 0.6152127659574468
- 0.6200531914893617
- 0.6192021276595745
- 0.616968085106383
- 0.6154255319148936
- 0.620531914893617
- 0.6174468085106383
- 0.6174468085106383
- 0.6180851063829788
- 0.6184574468085107
- 0.6235106382978723
- 0.6248404255319149
- 0.6283510638297872
- 0.6222872340425532
- 0.6254255319148936
- 0.6227659574468085
- 0.6179255319148936
- 0.6242021276595745
- 0.6211170212765957
- 0.6207446808510638
- 0.6213829787234042
- 0.6224468085106383
- 0.6251595744680851
- 0.6235106382978723
test_loss_list:
- 3.7931575775146484
- 3.7538142077128094
- 3.5528242270151775
- 3.290537691116333
- 3.044317865371704
- 2.8884220027923586
- 2.9667130088806153
- 2.7399949773152668
- 2.8658838717142743
- 2.8696387322743733
- 2.789947684605916
- 2.579542636871338
- 2.7818244870503746
- 2.7851732762654624
- 3.164180164337158
- 2.5566374746958416
- 2.353453276952108
- 2.743341194788615
- 2.4244399642944336
- 2.6897723801930744
- 2.1888098907470703
- 2.664921236038208
- 2.6445435365041097
- 2.6268609364827475
- 2.594847396214803
- 2.600268809000651
- 2.6087310473124186
- 2.3453196175893147
- 2.575481112798055
- 2.5794219080607097
- 2.077609114646912
- 2.267268803914388
- 2.069535284042358
- 2.206656009356181
- 2.1496469418207806
- 2.4235965092976888
- 2.1416857369740803
- 2.449617261886597
- 2.155000654856364
- 2.378216109275818
- 1.9308689181009928
- 2.3436371803283693
- 2.1001259167989095
- 2.0946713797251384
- 2.0414198637008667
- 1.80498064994812
- 1.9941366338729858
- 2.27907949924469
- 1.9699645725886028
- 2.587098274230957
- 2.3206765683492026
- 2.322841204007467
- 2.075724875132243
- 1.826298778851827
- 1.9960400772094726
- 1.9717287556330363
- 1.9301001532872517
- 2.261804469426473
- 1.9088078912099202
- 2.2436072715123494
- 1.9351885906855266
- 2.266805089314779
- 2.5591959126790367
- 2.0062346490224203
- 1.9572019942601522
- 1.9380996243158977
- 2.2029356082280476
- 2.1211914173762003
- 2.178695553143819
- 1.9406754477818806
- 2.213647796312968
- 2.1470739157994587
- 2.1904017321268716
- 2.216806182861328
- 1.8863827991485596
- 2.1349147256215413
- 1.9185469245910645
- 1.8551468896865844
- 1.867910590171814
- 2.107413945198059
- 1.8309958394368488
- 2.121489307085673
- 2.16962278842926
- 2.115287052790324
- 2.1307861757278443
- 1.6837241236368816
- 2.092156825065613
- 1.859310720761617
- 1.7927189445495606
- 1.769780036608378
- 1.799696963628133
- 2.3474345270792645
- 2.118726994196574
- 1.8938128312428792
- 2.3936338090896605
- 2.151991279919942
- 1.8540193192164103
- 2.095608347256978
- 2.107769161860148
- 1.8462333345413209
train_accuracy:
- 0.025
- 0.075
- 0.304
- 0.0
- 0.483
- 0.0
- 0.0
- 0.569
- 0.619
- 0.642
- 0.665
- 0.631
- 0.673
- 0.0
- 0.737
- 0.0
- 0.0
- 0.752
- 0.0
- 0.76
- 0.0
- 0.721
- 0.723
- 0.737
- 0.748
- 0.783
- 0.785
- 0.758
- 0.787
- 0.76
- 0.783
- 0.777
- 0.785
- 0.0
- 0.796
- 0.804
- 0.748
- 0.783
- 0.0
- 0.804
- 0.754
- 0.0
- 0.798
- 0.758
- 0.806
- 0.794
- 0.777
- 0.765
- 0.823
- 0.792
- 0.773
- 0.787
- 0.783
- 0.0
- 0.825
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.781
- 0.8
- 0.0
- 0.0
- 0.806
- 0.835
- 0.846
- 0.0
- 0.0
- 0.825
- 0.844
- 0.0
- 0.806
- 0.0
- 0.835
- 0.838
- 0.804
- 0.002
- 0.846
- 0.815
- 0.815
- 0.804
- 0.812
- 0.835
- 0.842
- 0.0
- 0.823
- 0.0
- 0.0
- 0.827
- 0.844
- 0.852
- 0.825
- 0.838
- 0.0
- 0.002
- 0.835
- 0.827
- 0.829
train_loss:
- 3.413
- 3.316
- 2.636
- 2.383
- 2.095
- 1.932
- 2.14
- 1.682
- 1.931
- 1.84
- 1.73
- 1.449
- 1.592
- 1.627
- 1.753
- 1.321
- 1.113
- 1.477
- 1.25
- 1.413
- 1.033
- 1.311
- 1.332
- 1.347
- 1.268
- 1.22
- 1.217
- 1.042
- 1.17
- 1.167
- 0.93
- 0.983
- 0.878
- 1.005
- 0.961
- 1.131
- 0.988
- 1.087
- 0.968
- 1.132
- 0.815
- 1.097
- 0.951
- 0.928
- 0.897
- 0.782
- 0.954
- 1.016
- 0.965
- 1.189
- 0.996
- 1.074
- 0.855
- 0.741
- 0.836
- 0.822
- 0.904
- 0.948
- 0.914
- 0.972
- 0.821
- 0.965
- 1.119
- 0.898
- 0.857
- 0.844
- 0.958
- 1.007
- 1.006
- 0.797
- 0.933
- 1.006
- 0.914
- 0.934
- 0.83
- 0.963
- 0.783
- 0.819
- 0.768
- 0.928
- 0.84
- 0.885
- 0.894
- 0.961
- 0.94
- 0.682
- 0.882
- 0.749
- 0.794
- 0.814
- 0.779
- 1.011
- 0.897
- 0.736
- 1.007
- 0.882
- 0.809
- 0.928
- 0.855
- 0.807
unequal: 0
verbose: 1
