avg_train_accuracy: 0.856
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02154255319148936
- 0.07047872340425532
- 0.19994680851063829
- 0.3032446808510638
- 0.33563829787234045
- 0.390531914893617
- 0.42154255319148937
- 0.4549468085106383
- 0.4595744680851064
- 0.4495212765957447
- 0.4473936170212766
- 0.4808510638297872
- 0.4796808510638298
- 0.4858510638297872
- 0.49351063829787234
- 0.5154787234042553
- 0.5013829787234042
- 0.511968085106383
- 0.521436170212766
- 0.5252127659574468
- 0.5121808510638298
- 0.5373936170212766
- 0.5424468085106383
- 0.5443617021276596
- 0.5428723404255319
- 0.5486170212765957
- 0.5507446808510639
- 0.5541489361702128
- 0.5568085106382978
- 0.560372340425532
- 0.5552659574468085
- 0.5587234042553192
- 0.5661170212765958
- 0.5624468085106383
- 0.5712234042553191
- 0.5735106382978723
- 0.566595744680851
- 0.5765957446808511
- 0.5792553191489361
- 0.5787765957446809
- 0.5795744680851064
- 0.5834574468085106
- 0.5785106382978723
- 0.5814893617021276
- 0.5817553191489362
- 0.5837765957446809
- 0.581436170212766
- 0.5903191489361702
- 0.5923404255319149
- 0.5906914893617021
- 0.5938297872340426
- 0.5872872340425532
- 0.5952659574468085
- 0.591063829787234
- 0.5945212765957447
- 0.5934574468085106
- 0.5985106382978723
- 0.5957446808510638
- 0.5942021276595745
- 0.5992021276595745
- 0.6010106382978724
- 0.6011702127659575
- 0.6027659574468085
- 0.6009042553191489
- 0.601063829787234
- 0.6009574468085106
- 0.6004787234042553
- 0.6016489361702128
- 0.6044148936170213
- 0.6039361702127659
- 0.6053191489361702
- 0.6032978723404255
- 0.6075
- 0.606063829787234
- 0.6075531914893617
- 0.6092021276595745
- 0.608404255319149
- 0.6111702127659574
- 0.6117021276595744
- 0.6101063829787234
- 0.6113297872340425
- 0.6134574468085107
- 0.6141489361702127
- 0.6110106382978724
- 0.6134042553191489
- 0.6163297872340425
- 0.6123936170212766
- 0.6159574468085106
- 0.6145212765957446
- 0.6156382978723405
- 0.6180851063829788
- 0.6215957446808511
- 0.6181382978723404
- 0.6227127659574468
- 0.6161170212765957
- 0.6162234042553192
- 0.6165425531914893
- 0.6182446808510639
- 0.6177127659574468
- 0.6165957446808511
test_loss_list:
- 3.7732175985972085
- 3.657277952829997
- 3.4210649331410727
- 3.1970432567596436
- 2.94779444694519
- 2.9225481859842937
- 2.9148863220214842
- 3.075452035268148
- 2.897751487096151
- 2.6846449406941733
- 2.593236608505249
- 2.8411836942036945
- 2.5994987964630125
- 2.5537500445048016
- 2.568440990447998
- 3.030918509165446
- 2.5010195446014403
- 2.514710661570231
- 2.677693913777669
- 2.744231408437093
- 2.2872041034698487
- 2.6669455178578696
- 2.6615468311309813
- 2.689142344792684
- 2.57881947517395
- 2.726542126337687
- 2.687986707687378
- 2.6945391337076825
- 2.6175634320576986
- 2.673959827423096
- 2.382368008295695
- 2.346929588317871
- 2.6143873182932538
- 2.3330782159169514
- 2.5180838521321616
- 2.566037588119507
- 2.077476414044698
- 2.555750258763631
- 2.5683629099527994
- 2.5397843805948894
- 2.3129392766952517
- 2.60465674718221
- 2.2883663829167684
- 2.2778651523590088
- 2.3314481019973754
- 2.423115094502767
- 1.971526606877645
- 2.456090348561605
- 2.492480573654175
- 2.509397350947062
- 2.4825505193074546
- 2.1104033327102663
- 2.2276790142059326
- 1.9311620855331422
- 2.367513823509216
- 2.093531805674235
- 2.4049327754974366
- 2.3062978839874266
- 2.086412426630656
- 2.3977967214584353
- 2.0751467084884645
- 1.854261884689331
- 2.312627870241801
- 2.2378260310490927
- 2.271437465349833
- 2.0146038881937662
- 2.0094714180628457
- 2.0002682717641194
- 2.2486597013473513
- 1.983384402592977
- 2.259113825162252
- 1.737525021235148
- 1.9726242860158285
- 2.141577517191569
- 1.921492156982422
- 1.7093375889460245
- 1.8753254795074463
- 2.1281313292185464
- 2.1779873259862264
- 2.2047544066111247
- 2.2144858741760256
- 2.2341764688491823
- 2.6151213963826496
- 1.9256420834859211
- 2.263477012316386
- 1.9980558586120605
- 2.180143149693807
- 2.2241978740692137
- 2.2686020072301227
- 2.658604787190755
- 2.346580828030904
- 2.0768771171569824
- 1.9374386183420818
- 1.6996981128056845
- 1.8481220690409343
- 1.7928535509109498
- 2.0755870787302655
- 2.0955847533543905
- 1.8681717570622762
- 1.8766292031606038
train_accuracy:
- 0.033
- 0.104
- 0.254
- 0.398
- 0.0
- 0.567
- 0.579
- 0.625
- 0.623
- 0.0
- 0.594
- 0.656
- 0.0
- 0.0
- 0.681
- 0.7
- 0.69
- 0.679
- 0.715
- 0.0
- 0.0
- 0.0
- 0.75
- 0.752
- 0.733
- 0.742
- 0.0
- 0.765
- 0.767
- 0.763
- 0.0
- 0.756
- 0.787
- 0.771
- 0.787
- 0.0
- 0.771
- 0.808
- 0.798
- 0.806
- 0.0
- 0.0
- 0.781
- 0.0
- 0.0
- 0.0
- 0.806
- 0.798
- 0.794
- 0.81
- 0.0
- 0.794
- 0.827
- 0.0
- 0.827
- 0.0
- 0.825
- 0.829
- 0.806
- 0.829
- 0.831
- 0.0
- 0.831
- 0.831
- 0.817
- 0.0
- 0.823
- 0.842
- 0.0
- 0.846
- 0.825
- 0.0
- 0.846
- 0.848
- 0.827
- 0.0
- 0.833
- 0.835
- 0.0
- 0.842
- 0.829
- 0.842
- 0.835
- 0.0
- 0.85
- 0.0
- 0.835
- 0.831
- 0.84
- 0.835
- 0.842
- 0.848
- 0.838
- 0.846
- 0.0
- 0.852
- 0.844
- 0.854
- 0.854
- 0.856
train_loss:
- 3.298
- 2.672
- 2.944
- 2.704
- 1.615
- 2.153
- 2.05
- 2.198
- 1.819
- 1.503
- 1.223
- 1.678
- 1.396
- 1.361
- 1.316
- 1.743
- 1.308
- 1.26
- 1.443
- 1.413
- 1.028
- 1.376
- 1.38
- 1.345
- 1.355
- 1.321
- 1.323
- 1.296
- 1.303
- 1.252
- 1.082
- 1.057
- 1.256
- 1.034
- 1.214
- 1.194
- 0.849
- 1.166
- 1.149
- 1.164
- 0.981
- 1.104
- 0.958
- 0.942
- 0.916
- 1.15
- 0.806
- 1.092
- 1.09
- 1.064
- 1.079
- 0.946
- 0.896
- 0.75
- 1.055
- 0.88
- 1.025
- 1.037
- 0.904
- 1.037
- 0.883
- 0.71
- 1.021
- 1.006
- 1.008
- 0.86
- 0.83
- 0.846
- 0.976
- 0.849
- 0.958
- 0.691
- 0.806
- 0.964
- 0.825
- 0.67
- 0.785
- 0.969
- 0.936
- 0.92
- 0.952
- 0.927
- 1.065
- 0.817
- 0.932
- 0.773
- 0.921
- 0.92
- 0.905
- 1.034
- 0.918
- 0.768
- 0.789
- 0.64
- 0.755
- 0.742
- 0.872
- 0.883
- 0.745
- 0.752
unequal: 0
verbose: 1
