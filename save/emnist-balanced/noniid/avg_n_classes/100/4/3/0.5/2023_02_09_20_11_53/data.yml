avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0275531914893617
- 0.034840425531914895
- 0.15340425531914895
- 0.2753191489361702
- 0.33563829787234045
- 0.3929787234042553
- 0.4175
- 0.4420212765957447
- 0.4710106382978723
- 0.47308510638297874
- 0.4863297872340426
- 0.46377659574468083
- 0.4980851063829787
- 0.49648936170212765
- 0.5126595744680851
- 0.4991489361702128
- 0.5222872340425532
- 0.5168617021276596
- 0.516595744680851
- 0.5351063829787234
- 0.5397340425531915
- 0.5338297872340425
- 0.5309574468085106
- 0.5442553191489362
- 0.546063829787234
- 0.5514893617021277
- 0.5535106382978724
- 0.5507978723404255
- 0.5627659574468085
- 0.5593617021276596
- 0.5625
- 0.5702659574468085
- 0.5713829787234043
- 0.5628723404255319
- 0.5726063829787233
- 0.5739893617021277
- 0.5786170212765958
- 0.5817553191489362
- 0.5766489361702127
- 0.584627659574468
- 0.583404255319149
- 0.5827127659574468
- 0.5861702127659575
- 0.5843617021276596
- 0.588404255319149
- 0.5871276595744681
- 0.5929255319148936
- 0.5915425531914894
- 0.5864893617021276
- 0.5944148936170213
- 0.5981382978723404
- 0.5992021276595745
- 0.5957978723404256
- 0.5973936170212766
- 0.6011170212765957
- 0.6032446808510639
- 0.6001063829787234
- 0.6025531914893617
- 0.6028191489361702
- 0.6010106382978724
- 0.6036702127659574
- 0.6054255319148936
- 0.6063297872340425
- 0.6051595744680851
- 0.6075
- 0.6086702127659575
- 0.6083510638297872
- 0.6063297872340425
- 0.606063829787234
- 0.6100531914893617
- 0.611968085106383
- 0.6112765957446809
- 0.6124468085106383
- 0.610531914893617
- 0.6094148936170213
- 0.613563829787234
- 0.6097340425531915
- 0.6141489361702127
- 0.6106382978723405
- 0.6139361702127659
- 0.6137765957446808
- 0.6138829787234042
- 0.6161702127659574
- 0.6167553191489362
- 0.6172872340425531
- 0.6186702127659575
- 0.6202659574468085
- 0.6211702127659574
- 0.6289361702127659
- 0.6163297872340425
- 0.6190425531914894
- 0.6186702127659575
- 0.6188829787234043
- 0.625
- 0.6202659574468085
- 0.6172340425531915
- 0.6212765957446809
- 0.6172340425531915
- 0.620531914893617
- 0.6193617021276596
test_loss_list:
- 3.7916630935668945
- 3.7495720100402834
- 3.553129364649455
- 3.265045499801636
- 3.0109326712290447
- 2.8370635414123537
- 2.704321098327637
- 2.632424208323161
- 2.972816530863444
- 2.740923318862915
- 2.6853028869628908
- 2.4069135252634686
- 2.6326498572031656
- 2.423072474797567
- 2.6247538566589355
- 2.224812788963318
- 2.5732698090871176
- 2.319690588315328
- 2.1544659487406412
- 2.2394850301742553
- 2.4182984320322674
- 2.188681534131368
- 2.048762044906616
- 2.1309030485153198
- 2.138767302831014
- 2.120567674636841
- 2.1120109446843465
- 1.9392569287618002
- 2.333570663134257
- 2.1006528679529826
- 2.289868806203206
- 2.3128756856918335
- 2.368071002960205
- 1.8805415328343709
- 2.2924781958262126
- 2.2528029378255208
- 2.351537535985311
- 2.291883274714152
- 2.3444287077585857
- 2.2955142800013224
- 2.3029362312952677
- 2.052038617134094
- 2.0581094360351564
- 2.0248891878128052
- 2.0026340309778847
- 1.8234774955113728
- 2.235793007214864
- 1.9606213792165121
- 1.7099989414215089
- 2.1780383427937826
- 1.8838603814442954
- 2.521446002324422
- 2.160463155110677
- 1.9771982765197753
- 2.2133921639124554
- 1.9098884312311808
- 1.900736624399821
- 1.8768375142415366
- 2.0939091618855796
- 2.086642475128174
- 2.136480371157328
- 2.181137530008952
- 2.158411204020182
- 2.164702272415161
- 1.9461023314793904
- 2.175120406150818
- 1.9250256093343099
- 2.1465491580963136
- 1.8521690368652344
- 1.8758629624048868
- 2.5150771236419676
- 2.156910923322042
- 2.5583083534240725
- 1.7080409256617228
- 1.8756120268503824
- 2.5043809096018474
- 1.8799791558583578
- 2.520436566670736
- 2.1360860379536946
- 1.9039714749654133
- 1.8687940692901612
- 2.0948274580637616
- 2.1253930505116783
- 1.8298682546615601
- 2.4383696349461874
- 2.1691053915023804
- 1.8616603326797485
- 2.1559400018056234
- 1.6059698279698689
- 1.7661152982711792
- 1.827440889676412
- 1.6897337675094604
- 2.024863265355428
- 1.8023699394861856
- 2.0243987099329632
- 1.7129281346003216
- 2.0281371307373046
- 1.721827441851298
- 2.0486154333750406
- 1.707930850982666
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.381
- 0.435
- 0.0
- 0.0
- 0.633
- 0.625
- 0.642
- 0.0
- 0.0
- 0.69
- 0.0
- 0.665
- 0.0
- 0.0
- 0.0
- 0.677
- 0.713
- 0.708
- 0.708
- 0.0
- 0.733
- 0.696
- 0.0
- 0.735
- 0.002
- 0.79
- 0.779
- 0.742
- 0.794
- 0.735
- 0.735
- 0.756
- 0.0
- 0.777
- 0.754
- 0.777
- 0.8
- 0.0
- 0.0
- 0.779
- 0.783
- 0.787
- 0.765
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.8
- 0.0
- 0.81
- 0.827
- 0.783
- 0.835
- 0.0
- 0.819
- 0.79
- 0.831
- 0.0
- 0.0
- 0.825
- 0.831
- 0.79
- 0.785
- 0.781
- 0.0
- 0.0
- 0.869
- 0.0
- 0.792
- 0.81
- 0.817
- 0.831
- 0.819
- 0.823
- 0.812
- 0.84
- 0.796
- 0.0
- 0.829
- 0.831
- 0.819
- 0.829
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.887
- 0.821
- 0.838
- 0.0
- 0.84
- 0.0
- 0.823
- 0.0
train_loss:
- 3.437
- 2.457
- 2.577
- 2.285
- 2.111
- 1.854
- 1.725
- 1.653
- 2.134
- 1.738
- 1.7
- 1.184
- 1.604
- 1.36
- 1.514
- 1.076
- 1.458
- 1.241
- 0.99
- 1.153
- 1.401
- 1.159
- 0.92
- 1.138
- 1.115
- 1.098
- 1.078
- 0.869
- 1.241
- 1.024
- 1.242
- 1.201
- 1.187
- 0.834
- 1.19
- 1.173
- 1.135
- 1.148
- 1.146
- 1.135
- 1.128
- 0.962
- 0.94
- 0.936
- 0.928
- 0.764
- 1.073
- 0.897
- 0.738
- 1.032
- 0.867
- 1.196
- 1.061
- 0.857
- 1.004
- 0.848
- 0.866
- 0.858
- 0.995
- 1.022
- 0.981
- 0.966
- 0.983
- 0.971
- 0.807
- 0.956
- 0.804
- 0.952
- 0.849
- 0.78
- 1.082
- 0.934
- 1.07
- 0.695
- 0.816
- 1.061
- 0.816
- 1.052
- 0.951
- 0.776
- 0.789
- 0.915
- 0.895
- 0.771
- 1.043
- 0.884
- 0.784
- 0.864
- 0.655
- 0.778
- 0.736
- 0.782
- 0.867
- 0.727
- 0.867
- 0.768
- 0.862
- 0.77
- 0.857
- 0.753
unequal: 0
verbose: 1
