avg_train_accuracy: 0.0
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03234042553191489
- 0.04989361702127659
- 0.09686170212765957
- 0.24335106382978725
- 0.3280851063829787
- 0.3755851063829787
- 0.40452127659574466
- 0.4402659574468085
- 0.4562765957446808
- 0.4588829787234043
- 0.4781382978723404
- 0.4882446808510638
- 0.48340425531914893
- 0.49670212765957444
- 0.5093085106382979
- 0.5177659574468085
- 0.5162765957446809
- 0.5183510638297872
- 0.5338829787234043
- 0.5325
- 0.5371808510638297
- 0.5386170212765957
- 0.541063829787234
- 0.5451063829787234
- 0.5535106382978724
- 0.5585106382978723
- 0.5467553191489362
- 0.5650531914893617
- 0.5559042553191489
- 0.566968085106383
- 0.5697872340425532
- 0.5690957446808511
- 0.5689893617021277
- 0.5697872340425532
- 0.5741489361702128
- 0.5752127659574469
- 0.5765957446808511
- 0.5759574468085107
- 0.5808510638297872
- 0.5761702127659575
- 0.5870212765957447
- 0.5876063829787234
- 0.5773404255319149
- 0.5832978723404255
- 0.5870212765957447
- 0.5889893617021277
- 0.5929787234042553
- 0.5911170212765957
- 0.5904255319148937
- 0.5957978723404256
- 0.5929787234042553
- 0.6011702127659575
- 0.6004255319148936
- 0.5962234042553192
- 0.5979255319148936
- 0.6
- 0.6019148936170213
- 0.6003191489361702
- 0.6002127659574468
- 0.6051063829787234
- 0.6087765957446809
- 0.6026595744680852
- 0.6055851063829787
- 0.6077127659574468
- 0.6039361702127659
- 0.6086170212765958
- 0.6065957446808511
- 0.6087765957446809
- 0.6093617021276596
- 0.6135106382978723
- 0.6110638297872341
- 0.6113297872340425
- 0.6156382978723405
- 0.6182446808510639
- 0.6122872340425531
- 0.6157978723404255
- 0.6189893617021277
- 0.62
- 0.6143617021276596
- 0.6168617021276596
- 0.6139361702127659
- 0.6112234042553192
- 0.6171276595744681
- 0.6142553191489362
- 0.6198404255319149
- 0.6157446808510638
- 0.6194148936170213
- 0.6203191489361702
- 0.6177659574468085
- 0.6193617021276596
- 0.6238297872340426
- 0.6263297872340425
- 0.6189361702127659
- 0.6167553191489362
- 0.624468085106383
- 0.6225531914893617
- 0.621968085106383
- 0.6288829787234043
- 0.6272872340425532
- 0.6249468085106383
test_loss_list:
- 3.7896098550160726
- 3.7516898345947265
- 3.6121443271636964
- 3.288837652206421
- 2.991108121871948
- 2.7990473651885988
- 2.737942186991374
- 2.760068778991699
- 2.769154183069865
- 2.615009346008301
- 2.5424185689290364
- 2.499763453801473
- 2.357085383733114
- 2.4043071269989014
- 2.386298888524373
- 2.634692424138387
- 2.4093151823679606
- 2.3921339162190756
- 2.948504788080851
- 2.610396588643392
- 2.40026985168457
- 2.3334175237019856
- 2.324411702156067
- 2.2961682430903116
- 2.4835464636484783
- 2.8951740296681723
- 2.0607113377253214
- 2.8798069890340168
- 2.255233201980591
- 2.53281808535258
- 2.539439697265625
- 2.5111205259958904
- 2.5149075571695962
- 2.552651513417562
- 2.213757160504659
- 2.43413636525472
- 2.4306388743718466
- 2.1555670992533367
- 2.4680263423919677
- 2.1756228319803874
- 2.8673798847198486
- 2.8983076667785643
- 1.9990046501159668
- 2.1257414388656617
- 2.0893634351094565
- 2.3769070053100587
- 2.762744042078654
- 2.4704870827992758
- 2.1367515341440835
- 2.0890772120157877
- 2.359666175842285
- 2.0976569668451943
- 2.1052719799677533
- 2.270468112627665
- 1.8198249451319377
- 2.257525086402893
- 2.0106577412287394
- 2.226398410797119
- 2.333644464810689
- 2.330823316574097
- 2.339293181101481
- 2.2582237243652346
- 2.7128775946299233
- 2.756400130589803
- 2.111805985768636
- 2.381411550839742
- 2.309130317370097
- 2.112562936147054
- 2.3076024150848387
- 2.018270386060079
- 2.270100433031718
- 2.3226317024230956
- 2.366550827026367
- 2.047403828303019
- 2.3053020079930624
- 2.040911404291789
- 2.0331532255808513
- 2.2763073221842447
- 2.264825317064921
- 2.2819292052586873
- 2.6992448806762694
- 1.967243358294169
- 2.2581007273991904
- 1.9170841360092163
- 2.2274645280838015
- 2.1529146416982017
- 1.6782812643051148
- 2.172733659744263
- 2.0685608704884846
- 2.139349850018819
- 1.8880395269393921
- 1.858863854408264
- 2.1169328832626344
- 2.088289985656738
- 1.8364695930480956
- 2.130137049357096
- 1.7528756125768026
- 1.7514783430099488
- 1.7145103152592978
- 2.0354863850275677
train_accuracy:
- 0.046
- 0.0
- 0.137
- 0.321
- 0.0
- 0.0
- 0.577
- 0.6
- 0.654
- 0.633
- 0.0
- 0.685
- 0.0
- 0.0
- 0.696
- 0.719
- 0.0
- 0.679
- 0.717
- 0.721
- 0.0
- 0.0
- 0.0
- 0.752
- 0.74
- 0.767
- 0.0
- 0.777
- 0.76
- 0.771
- 0.785
- 0.785
- 0.742
- 0.781
- 0.79
- 0.777
- 0.779
- 0.773
- 0.771
- 0.0
- 0.806
- 0.808
- 0.777
- 0.79
- 0.0
- 0.815
- 0.819
- 0.773
- 0.0
- 0.806
- 0.798
- 0.0
- 0.808
- 0.825
- 0.0
- 0.812
- 0.0
- 0.817
- 0.844
- 0.0
- 0.827
- 0.806
- 0.833
- 0.806
- 0.833
- 0.808
- 0.0
- 0.833
- 0.806
- 0.0
- 0.821
- 0.838
- 0.823
- 0.0
- 0.823
- 0.825
- 0.802
- 0.817
- 0.827
- 0.0
- 0.812
- 0.0
- 0.842
- 0.819
- 0.831
- 0.846
- 0.0
- 0.823
- 0.821
- 0.835
- 0.84
- 0.0
- 0.854
- 0.0
- 0.846
- 0.85
- 0.84
- 0.84
- 0.844
- 0.0
train_loss:
- 3.37
- 2.863
- 3.129
- 2.375
- 2.128
- 1.864
- 1.774
- 1.967
- 1.843
- 1.508
- 1.436
- 1.38
- 1.117
- 1.3
- 1.271
- 1.442
- 1.229
- 1.231
- 1.603
- 1.394
- 1.17
- 1.143
- 1.137
- 1.092
- 1.316
- 1.439
- 0.941
- 1.421
- 1.07
- 1.215
- 1.204
- 1.195
- 1.194
- 1.147
- 1.013
- 1.15
- 1.141
- 0.992
- 1.1
- 0.934
- 1.236
- 1.231
- 0.82
- 0.94
- 0.937
- 1.068
- 1.208
- 1.045
- 0.894
- 0.875
- 1.02
- 0.897
- 0.853
- 1.041
- 0.725
- 0.988
- 0.856
- 0.993
- 0.976
- 0.979
- 0.96
- 1.008
- 1.1
- 1.101
- 0.839
- 0.937
- 0.966
- 0.806
- 0.944
- 0.811
- 0.943
- 0.959
- 0.909
- 0.797
- 0.907
- 0.784
- 0.77
- 0.913
- 0.899
- 0.917
- 1.026
- 0.836
- 0.897
- 0.808
- 0.894
- 0.904
- 0.671
- 0.889
- 0.915
- 0.898
- 0.755
- 0.761
- 0.878
- 0.864
- 0.759
- 0.854
- 0.755
- 0.746
- 0.755
- 0.856
unequal: 0
verbose: 1
