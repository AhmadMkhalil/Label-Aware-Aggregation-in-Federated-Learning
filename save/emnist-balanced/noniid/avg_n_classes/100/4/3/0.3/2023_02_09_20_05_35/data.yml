avg_train_accuracy: 0.844
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04797872340425532
- 0.1270212765957447
- 0.23643617021276594
- 0.3281914893617021
- 0.37
- 0.41723404255319146
- 0.41143617021276596
- 0.4377127659574468
- 0.465531914893617
- 0.4858510638297872
- 0.48675531914893616
- 0.503031914893617
- 0.4984574468085106
- 0.5163829787234042
- 0.512127659574468
- 0.5173936170212766
- 0.5159574468085106
- 0.5234042553191489
- 0.5166489361702128
- 0.5347340425531915
- 0.5442021276595744
- 0.5442553191489362
- 0.5406382978723404
- 0.5543617021276596
- 0.5468085106382978
- 0.5520212765957446
- 0.5588297872340425
- 0.5634574468085106
- 0.5586170212765957
- 0.5726595744680851
- 0.573404255319149
- 0.5604255319148936
- 0.5771276595744681
- 0.5776595744680851
- 0.5775
- 0.5754787234042553
- 0.5835106382978723
- 0.5821808510638298
- 0.5885106382978723
- 0.5883510638297872
- 0.591968085106383
- 0.5877127659574468
- 0.5899468085106383
- 0.5943617021276596
- 0.5938829787234042
- 0.5959042553191489
- 0.5930319148936171
- 0.5972340425531915
- 0.5997340425531915
- 0.5962234042553192
- 0.5938297872340426
- 0.595
- 0.5976063829787234
- 0.6
- 0.6023404255319149
- 0.5989361702127659
- 0.6028191489361702
- 0.5989893617021277
- 0.6018085106382979
- 0.6024468085106383
- 0.6047340425531915
- 0.6027659574468085
- 0.6049468085106383
- 0.6036702127659574
- 0.6014893617021276
- 0.6082446808510639
- 0.6065425531914893
- 0.6072340425531915
- 0.611436170212766
- 0.6122340425531915
- 0.6107446808510638
- 0.6068617021276596
- 0.6112765957446809
- 0.610531914893617
- 0.6132446808510639
- 0.613031914893617
- 0.613563829787234
- 0.6132978723404255
- 0.6108510638297873
- 0.612659574468085
- 0.6144148936170213
- 0.6163829787234043
- 0.6128191489361702
- 0.6118617021276596
- 0.6160638297872341
- 0.6190425531914894
- 0.6157978723404255
- 0.6161170212765957
- 0.6142553191489362
- 0.6192021276595745
- 0.6181382978723404
- 0.6169148936170212
- 0.6188829787234043
- 0.616968085106383
- 0.6201063829787234
- 0.6179787234042553
- 0.6213829787234042
- 0.6189893617021277
- 0.621968085106383
- 0.6179255319148936
test_loss_list:
- 3.7789137522379557
- 3.6825157038370766
- 3.4360289255777996
- 3.2051955954233806
- 3.1033636061350505
- 2.9756429290771482
- 2.8258840243021646
- 2.7238488006591797
- 2.909185724258423
- 3.1838987350463865
- 2.8474581654866538
- 3.210526812871297
- 2.9497137800852458
- 3.2757970809936525
- 2.919395278294881
- 2.9096404774983724
- 2.7034061113993326
- 2.865539919535319
- 2.540990804036458
- 2.829278974533081
- 3.1997257614135743
- 2.794892479578654
- 2.8803800551096597
- 3.3046193663279215
- 2.540923172632853
- 2.495285488764445
- 2.7552014605204262
- 2.7767468070983887
- 2.7193298816680906
- 3.2364038022359214
- 3.2844105497996012
- 2.4520678997039793
- 3.214982369740804
- 2.765483862559001
- 2.706858116785685
- 2.715021696090698
- 3.199727249145508
- 2.7206320730845133
- 3.222318099339803
- 2.682882995605469
- 2.7068332958221437
- 2.6744145361582436
- 2.6607917722066246
- 2.680716047286987
- 2.7144956684112547
- 3.1365152422587075
- 2.615805778503418
- 3.117238359451294
- 3.196129674911499
- 2.7355074977874754
- 2.6957817395528156
- 2.3608648522694904
- 2.2901180362701417
- 2.6093384329477947
- 3.004276367823283
- 2.2014981667200724
- 2.4554880634943643
- 2.520642639795939
- 2.5282099564870197
- 2.510888942082723
- 2.4606382497151693
- 2.4877036317189534
- 2.4532952817281086
- 2.5092072772979734
- 2.1670530033111572
- 2.884550593694051
- 2.4948494752248127
- 2.414304469426473
- 2.875030838648478
- 2.982352803548177
- 3.005089823404948
- 2.166501620610555
- 2.4551308949788413
- 2.513058595657349
- 2.433775831858317
- 2.461127068201701
- 2.4417029428482055
- 2.440824030240377
- 2.379336946805318
- 2.4517350403467812
- 2.8583676528930666
- 2.409621369043986
- 2.442535940806071
- 2.381757044792175
- 2.350806573232015
- 2.794368397394816
- 2.398002921740214
- 2.049331393241882
- 2.0253234084447227
- 2.7560363324483235
- 2.3580577691396076
- 2.393571031888326
- 2.3211584170659383
- 2.3235256401697795
- 2.738066374460856
- 2.3224870761235556
- 2.7864763832092283
- 2.3834653997421267
- 2.321150310834249
- 2.302318325042725
train_accuracy:
- 0.077
- 0.0
- 0.304
- 0.446
- 0.508
- 0.575
- 0.0
- 0.61
- 0.646
- 0.629
- 0.654
- 0.7
- 0.681
- 0.694
- 0.696
- 0.723
- 0.71
- 0.723
- 0.694
- 0.723
- 0.756
- 0.752
- 0.748
- 0.752
- 0.717
- 0.0
- 0.792
- 0.767
- 0.779
- 0.798
- 0.794
- 0.0
- 0.808
- 0.0
- 0.773
- 0.781
- 0.785
- 0.804
- 0.783
- 0.79
- 0.802
- 0.0
- 0.819
- 0.0
- 0.808
- 0.773
- 0.0
- 0.779
- 0.825
- 0.81
- 0.821
- 0.0
- 0.0
- 0.767
- 0.827
- 0.821
- 0.815
- 0.779
- 0.0
- 0.806
- 0.823
- 0.833
- 0.819
- 0.79
- 0.781
- 0.821
- 0.819
- 0.842
- 0.804
- 0.802
- 0.8
- 0.002
- 0.0
- 0.835
- 0.0
- 0.0
- 0.838
- 0.0
- 0.84
- 0.815
- 0.848
- 0.829
- 0.0
- 0.827
- 0.0
- 0.806
- 0.806
- 0.0
- 0.0
- 0.835
- 0.827
- 0.86
- 0.0
- 0.835
- 0.846
- 0.0
- 0.846
- 0.0
- 0.0
- 0.844
train_loss:
- 2.227
- 2.84
- 2.541
- 2.222
- 2.091
- 1.956
- 1.3
- 1.272
- 1.591
- 1.985
- 1.541
- 1.841
- 1.447
- 1.744
- 1.391
- 1.454
- 1.038
- 1.294
- 1.044
- 1.304
- 1.523
- 1.274
- 1.187
- 1.464
- 0.942
- 0.973
- 1.151
- 1.188
- 1.104
- 1.375
- 1.335
- 0.857
- 1.352
- 1.146
- 1.073
- 1.042
- 1.277
- 1.043
- 1.245
- 1.049
- 1.007
- 1.091
- 1.014
- 0.996
- 0.964
- 1.208
- 1.042
- 1.189
- 1.178
- 1.021
- 0.985
- 0.783
- 0.745
- 0.95
- 1.142
- 0.762
- 0.915
- 0.921
- 0.894
- 0.889
- 0.908
- 0.867
- 0.899
- 0.887
- 0.716
- 1.096
- 0.934
- 0.89
- 1.083
- 1.071
- 1.061
- 0.743
- 0.842
- 0.886
- 0.849
- 0.893
- 0.868
- 0.833
- 0.849
- 0.856
- 1.039
- 0.849
- 0.852
- 0.814
- 0.833
- 1.043
- 0.824
- 0.649
- 0.629
- 1.032
- 0.851
- 0.821
- 0.827
- 0.831
- 0.989
- 0.822
- 0.967
- 0.799
- 0.784
- 0.807
unequal: 0
verbose: 1
