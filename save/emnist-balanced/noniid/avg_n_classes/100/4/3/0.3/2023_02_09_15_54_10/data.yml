avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026968085106382978
- 0.07617021276595745
- 0.1671276595744681
- 0.295531914893617
- 0.3784574468085106
- 0.39351063829787236
- 0.40297872340425533
- 0.4340425531914894
- 0.4581914893617021
- 0.4650531914893617
- 0.4672872340425532
- 0.4824468085106383
- 0.49106382978723406
- 0.5007446808510638
- 0.5132446808510638
- 0.5080851063829788
- 0.4997872340425532
- 0.5192553191489362
- 0.5325531914893618
- 0.5247340425531914
- 0.5424468085106383
- 0.5386702127659575
- 0.5407446808510639
- 0.5462765957446809
- 0.5506914893617021
- 0.5481382978723405
- 0.5441489361702128
- 0.5575
- 0.561063829787234
- 0.5629255319148936
- 0.5662234042553191
- 0.5647340425531915
- 0.5642021276595744
- 0.5754787234042553
- 0.5682978723404255
- 0.5738829787234042
- 0.5785638297872341
- 0.5730851063829787
- 0.581436170212766
- 0.5802659574468085
- 0.5817021276595745
- 0.5844148936170213
- 0.5842553191489361
- 0.5856382978723405
- 0.5902659574468085
- 0.5807978723404256
- 0.5857978723404256
- 0.5909042553191489
- 0.5856382978723405
- 0.5896808510638298
- 0.5865957446808511
- 0.5958510638297873
- 0.5975
- 0.5937234042553191
- 0.586063829787234
- 0.3501595744680851
- 0.5976063829787234
- 0.5956914893617021
- 0.5991489361702128
- 0.5986702127659574
- 0.5996276595744681
- 0.6022340425531915
- 0.5979787234042553
- 0.6000531914893616
- 0.6008510638297873
- 0.6033510638297872
- 0.6018085106382979
- 0.6056914893617021
- 0.6055851063829787
- 0.6052659574468086
- 0.6054255319148936
- 0.6008510638297873
- 0.6029787234042553
- 0.6042021276595745
- 0.6092553191489362
- 0.6025
- 0.6082978723404255
- 0.6077127659574468
- 0.6088297872340426
- 0.6077659574468085
- 0.6123404255319149
- 0.6112234042553192
- 0.6137765957446808
- 0.6122872340425531
- 0.6170212765957447
- 0.6192021276595745
- 0.6193617021276596
- 0.6149468085106383
- 0.6172340425531915
- 0.6132978723404255
- 0.6165425531914893
- 0.617872340425532
- 0.6167553191489362
- 0.6131914893617021
- 0.6155851063829787
- 0.6173936170212766
- 0.6109574468085106
- 0.6113829787234043
- 0.6188297872340426
- 0.6150531914893617
test_loss_list:
- 3.7951721509297687
- 3.739176355997721
- 3.4986613464355467
- 3.252946875890096
- 3.25221422513326
- 3.0377733198801677
- 2.8503433736165364
- 2.9855752595265708
- 3.223454615275065
- 2.9337932364145916
- 2.9359237639109295
- 2.91333168665568
- 2.9224354934692385
- 2.8570281314849852
- 3.3126459248860676
- 2.9411238193511964
- 2.611838337580363
- 2.8077102088928223
- 3.2571959018707277
- 2.5492135111490883
- 3.2051945718129478
- 2.8321436627705894
- 2.7990984185536703
- 2.750580145517985
- 2.6855414708455405
- 2.535061168670654
- 2.37840891679128
- 2.703804915746053
- 2.638040100733439
- 2.702941281000773
- 2.6792754173278808
- 2.6824408785502114
- 2.33340468565623
- 3.069733912150065
- 2.689601100285848
- 2.729415365854899
- 3.1038417847951254
- 2.651896111170451
- 3.202831319173177
- 2.6898650964101156
- 2.6606528027852376
- 2.6793824354807536
- 2.6391127904256186
- 2.684207108815511
- 3.091228853861491
- 2.258780380884806
- 2.635517120361328
- 2.510404249827067
- 2.2331045643488565
- 2.5017058722178143
- 2.483028990427653
- 3.036629737218221
- 2.977373348871867
- 2.5637761529286704
- 2.1842780351638793
- 2.431560920079549
- 1.8495533307393393
- 2.7319521935780844
- 2.348123819033305
- 2.3719958130518597
- 2.343866958618164
- 2.8659113756815593
- 2.4684984413782756
- 2.4774092690149945
- 2.4449032306671143
- 2.4942887369791666
- 2.4437849696477256
- 2.924347578684489
- 2.534519936243693
- 2.9540330664316814
- 2.458905660311381
- 2.1092385816574097
- 2.407583243052165
- 2.366002836227417
- 2.9236429850260417
- 2.0319226106007893
- 2.376293840408325
- 2.3870556847254436
- 2.2937528387705486
- 1.9995659399032593
- 2.8388340187072756
- 2.322663065592448
- 2.4045611238479614
- 2.062918767929077
- 2.3550609143575034
- 2.4213442516326906
- 2.4069467878341673
- 2.8841450436909994
- 2.467121427853902
- 2.383452041943868
- 2.8498427549997967
- 2.994461816151937
- 3.003102184931437
- 2.459926985104879
- 2.5169799884160358
- 2.9552370230356853
- 2.0580841557184857
- 2.042609178225199
- 2.809622383117676
- 2.3871958096822103
train_accuracy:
- 0.031
- 0.144
- 0.0
- 0.456
- 0.515
- 0.548
- 0.0
- 0.0
- 0.596
- 0.0
- 0.0
- 0.0
- 0.683
- 0.0
- 0.685
- 0.646
- 0.0
- 0.708
- 0.706
- 0.0
- 0.746
- 0.0
- 0.0
- 0.735
- 0.735
- 0.0
- 0.74
- 0.0
- 0.717
- 0.752
- 0.0
- 0.752
- 0.785
- 0.767
- 0.802
- 0.802
- 0.808
- 0.0
- 0.802
- 0.785
- 0.804
- 0.0
- 0.796
- 0.812
- 0.8
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.825
- 0.819
- 0.0
- 0.0
- 0.012
- 0.792
- 0.802
- 0.8
- 0.79
- 0.848
- 0.79
- 0.0
- 0.0
- 0.0
- 0.825
- 0.825
- 0.844
- 0.808
- 0.81
- 0.0
- 0.0
- 0.819
- 0.842
- 0.808
- 0.0
- 0.819
- 0.827
- 0.0
- 0.846
- 0.831
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.835
- 0.825
- 0.81
- 0.0
- 0.85
- 0.86
- 0.806
- 0.0
- 0.0
- 0.827
- 0.0
- 0.819
- 0.827
- 0.0
train_loss:
- 3.809
- 2.951
- 1.959
- 2.338
- 2.749
- 1.984
- 1.422
- 1.807
- 2.137
- 1.621
- 1.654
- 1.533
- 1.449
- 1.427
- 1.773
- 1.362
- 1.175
- 1.352
- 1.658
- 0.984
- 1.612
- 1.239
- 1.356
- 1.223
- 1.314
- 0.932
- 0.938
- 1.183
- 1.142
- 1.146
- 1.11
- 1.169
- 0.853
- 1.37
- 1.11
- 1.062
- 1.306
- 1.098
- 1.297
- 1.071
- 1.01
- 1.032
- 1.014
- 0.993
- 1.236
- 0.833
- 1.018
- 0.988
- 0.781
- 0.952
- 1.008
- 1.179
- 1.189
- 0.955
- 0.731
- 0.487
- 0.706
- 1.17
- 0.928
- 0.941
- 0.907
- 1.129
- 0.9
- 0.851
- 0.916
- 0.909
- 0.881
- 1.105
- 0.852
- 1.089
- 0.859
- 0.646
- 0.943
- 0.915
- 1.066
- 0.676
- 0.912
- 0.864
- 0.856
- 0.617
- 1.06
- 0.874
- 0.835
- 0.631
- 0.843
- 0.82
- 0.821
- 1.043
- 0.828
- 0.826
- 1.039
- 1.011
- 1.016
- 0.915
- 0.818
- 1.008
- 0.704
- 0.636
- 1.014
- 0.806
unequal: 0
verbose: 1
