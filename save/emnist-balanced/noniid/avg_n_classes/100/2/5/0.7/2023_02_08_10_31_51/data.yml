avg_train_accuracy: 0.831
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02281914893617021
- 0.12537234042553191
- 0.21361702127659574
- 0.32638297872340427
- 0.3675
- 0.4052127659574468
- 0.4330851063829787
- 0.45617021276595743
- 0.4760106382978723
- 0.47829787234042553
- 0.49675531914893617
- 0.5011702127659574
- 0.5176595744680851
- 0.5311702127659574
- 0.5374468085106383
- 0.5437765957446808
- 0.546595744680851
- 0.5471276595744681
- 0.5516489361702127
- 0.5655851063829788
- 0.57
- 0.5657446808510638
- 0.5758510638297872
- 0.5806914893617021
- 0.5824468085106383
- 0.5863297872340425
- 0.5899468085106383
- 0.5961170212765957
- 0.5977127659574468
- 0.5943617021276596
- 0.5962765957446808
- 0.597872340425532
- 0.6067021276595744
- 0.6072340425531915
- 0.6077659574468085
- 0.6101063829787234
- 0.6117553191489362
- 0.6163297872340425
- 0.6182978723404255
- 0.6160106382978724
- 0.6167021276595744
- 0.620531914893617
- 0.6176063829787234
- 0.6234042553191489
- 0.6196808510638298
- 0.6272872340425532
- 0.6272872340425532
- 0.6262234042553192
- 0.623563829787234
- 0.630531914893617
- 0.6311702127659574
- 0.6303723404255319
- 0.6345212765957446
- 0.6340425531914894
- 0.6341489361702127
- 0.6354255319148936
- 0.6352659574468085
- 0.6387234042553191
- 0.6379787234042553
- 0.6387765957446808
- 0.6378723404255319
- 0.6390957446808511
- 0.6388829787234043
- 0.6373936170212766
- 0.6412765957446809
- 0.6404255319148936
- 0.642127659574468
- 0.6424468085106383
- 0.6423404255319148
- 0.6451063829787234
- 0.6446276595744681
- 0.6422872340425532
- 0.644468085106383
- 0.645904255319149
- 0.6460106382978723
- 0.6473404255319148
- 0.647127659574468
- 0.6478191489361702
- 0.6471808510638298
- 0.6496276595744681
- 0.648563829787234
- 0.6485106382978724
- 0.65
- 0.6513829787234042
- 0.6493085106382979
- 0.650904255319149
- 0.65
- 0.6519680851063829
- 0.6512765957446809
- 0.6529787234042553
- 0.6537234042553192
- 0.6531914893617021
- 0.652127659574468
- 0.6531382978723405
- 0.6540957446808511
- 0.653936170212766
- 0.6542553191489362
- 0.6560106382978723
- 0.6542021276595744
- 0.6543617021276595
test_loss_list:
- 3.762122392654419
- 3.6476007239023844
- 3.3763353411356607
- 3.1455474694569907
- 2.9743654696146646
- 2.8774870872497558
- 2.758451716105143
- 2.746058785120646
- 2.7323032919565837
- 2.6045216655731203
- 2.621429942448934
- 2.522798458735148
- 2.6213909721374513
- 2.6143886343638103
- 2.511846647262573
- 2.510644957224528
- 2.525986700057983
- 2.3699537563323974
- 2.385731159845988
- 2.5544048722585044
- 2.4611935424804687
- 2.2911468267440798
- 2.2951356983184814
- 2.3473762289683022
- 2.351806127230326
- 2.370492383639018
- 2.3772077846527098
- 2.3654618406295778
- 2.341297418276469
- 2.24405535697937
- 2.195510570208232
- 2.2405840587615966
- 2.396223030090332
- 2.2736385838190714
- 2.3006380780537925
- 2.187168307304382
- 2.2731577412287396
- 2.281418712933858
- 2.2649982007344565
- 2.2475592199961345
- 2.2415768639246623
- 2.2351463158925373
- 2.129205355644226
- 2.1871299107869464
- 2.0628969208399455
- 2.246386389732361
- 2.168310974438985
- 2.081356455485026
- 1.9892313305536906
- 2.2131851736704506
- 2.060983527501424
- 2.0135660568873086
- 2.178198088010152
- 2.0957598129908246
- 2.0546620384852092
- 2.0287409591674805
- 2.0925741545359293
- 2.1643539396921794
- 2.0649842341740925
- 2.0579967816670734
- 1.979823528925578
- 1.9351411294937133
- 1.9387227773666382
- 1.8707810338338215
- 1.9164438358942668
- 1.9089599863688151
- 2.05193608601888
- 1.9178439791997273
- 1.8306931702295939
- 2.0300415563583374
- 1.9527227783203125
- 1.8904283809661866
- 1.956654634475708
- 1.868491128285726
- 1.850165031750997
- 1.9408120171229044
- 1.9085641288757325
- 1.9122487179438272
- 1.8337994241714477
- 1.9006708288192748
- 1.8326423486073813
- 1.7482506465911865
- 1.8704117425282796
- 1.9626512289047242
- 1.7534939193725585
- 1.8667742935816447
- 1.8114858102798461
- 1.8891603597005209
- 1.7966584984461467
- 1.8278024832407633
- 1.9154305458068848
- 1.8843051846822103
- 1.7910393476486206
- 1.7829312785466511
- 1.6717424885431926
- 1.7871824630101523
- 1.7819446754455566
- 1.790991415977478
- 1.7229619693756104
- 1.7364877287546794
train_accuracy:
- 0.027
- 0.137
- 0.0
- 0.431
- 0.49
- 0.513
- 0.0
- 0.579
- 0.619
- 0.615
- 0.642
- 0.0
- 0.675
- 0.0
- 0.667
- 0.0
- 0.692
- 0.0
- 0.721
- 0.731
- 0.746
- 0.0
- 0.0
- 0.748
- 0.752
- 0.758
- 0.735
- 0.0
- 0.0
- 0.731
- 0.744
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.781
- 0.785
- 0.787
- 0.8
- 0.771
- 0.0
- 0.783
- 0.781
- 0.0
- 0.0
- 0.771
- 0.812
- 0.0
- 0.0
- 0.0
- 0.777
- 0.806
- 0.817
- 0.0
- 0.796
- 0.819
- 0.815
- 0.792
- 0.808
- 0.817
- 0.787
- 0.0
- 0.817
- 0.825
- 0.785
- 0.827
- 0.827
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.825
- 0.833
- 0.833
- 0.804
- 0.846
- 0.0
- 0.0
- 0.831
- 0.0
- 0.0
- 0.802
- 0.0
- 0.833
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.804
- 0.833
- 0.81
- 0.0
- 0.833
- 0.831
train_loss:
- 2.991
- 2.919
- 1.846
- 2.379
- 1.497
- 1.666
- 1.026
- 1.497
- 1.456
- 0.916
- 1.348
- 0.858
- 1.265
- 1.456
- 1.193
- 1.157
- 1.172
- 0.75
- 0.926
- 1.279
- 1.07
- 0.703
- 0.853
- 1.017
- 1.014
- 0.992
- 0.981
- 0.974
- 0.965
- 0.799
- 0.788
- 0.773
- 1.075
- 0.907
- 0.9
- 0.754
- 0.885
- 0.884
- 0.871
- 0.878
- 0.86
- 0.861
- 0.721
- 0.84
- 0.69
- 0.962
- 0.824
- 0.698
- 0.544
- 0.937
- 0.675
- 0.664
- 0.921
- 0.782
- 0.779
- 0.654
- 0.783
- 0.896
- 0.774
- 0.76
- 0.628
- 0.638
- 0.636
- 0.501
- 0.62
- 0.625
- 0.873
- 0.621
- 0.498
- 0.845
- 0.738
- 0.612
- 0.734
- 0.606
- 0.602
- 0.709
- 0.726
- 0.71
- 0.587
- 0.7
- 0.59
- 0.471
- 0.697
- 0.82
- 0.468
- 0.7
- 0.573
- 0.684
- 0.576
- 0.681
- 0.801
- 0.682
- 0.573
- 0.563
- 0.448
- 0.661
- 0.667
- 0.659
- 0.562
- 0.546
unequal: 0
verbose: 1
