avg_train_accuracy: 0.867
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06037234042553191
- 0.10537234042553191
- 0.16792553191489362
- 0.2709042553191489
- 0.3470744680851064
- 0.39335106382978724
- 0.4218085106382979
- 0.46085106382978724
- 0.46632978723404256
- 0.4873936170212766
- 0.4971808510638298
- 0.5095212765957446
- 0.5185106382978724
- 0.5336702127659575
- 0.5262765957446809
- 0.5351063829787234
- 0.5443085106382979
- 0.5518617021276596
- 0.5517021276595745
- 0.5576595744680851
- 0.5718617021276595
- 0.5683510638297873
- 0.5711702127659575
- 0.5775
- 0.5756914893617021
- 0.5835638297872341
- 0.5879255319148936
- 0.591968085106383
- 0.5920212765957447
- 0.5917553191489362
- 0.5979255319148936
- 0.5948936170212766
- 0.6042021276595745
- 0.6030851063829787
- 0.6060106382978724
- 0.6094148936170213
- 0.6134574468085107
- 0.6149468085106383
- 0.6112234042553192
- 0.6125
- 0.6187234042553191
- 0.6152659574468086
- 0.6225531914893617
- 0.6217021276595744
- 0.6260638297872341
- 0.624468085106383
- 0.6261170212765957
- 0.6264893617021277
- 0.6309574468085106
- 0.6311702127659574
- 0.6297872340425532
- 0.6327659574468085
- 0.6303723404255319
- 0.6365425531914893
- 0.6362234042553192
- 0.6375
- 0.6375
- 0.6384574468085107
- 0.6366489361702128
- 0.64
- 0.6363829787234042
- 0.6410638297872341
- 0.6422872340425532
- 0.6417553191489361
- 0.6414893617021277
- 0.6440957446808511
- 0.6468085106382979
- 0.6437765957446808
- 0.6475
- 0.6474468085106383
- 0.6455851063829787
- 0.6463297872340426
- 0.6504255319148936
- 0.6493617021276595
- 0.6412234042553191
- 0.6482978723404256
- 0.6452659574468085
- 0.6505851063829787
- 0.6501063829787234
- 0.6547872340425532
- 0.6557446808510639
- 0.6496276595744681
- 0.6512234042553191
- 0.6537765957446808
- 0.6557446808510639
- 0.6489893617021276
- 0.6570744680851064
- 0.6518617021276596
- 0.6546276595744681
- 0.6525531914893618
- 0.6565425531914894
- 0.6570744680851064
- 0.6553191489361702
- 0.6571808510638298
- 0.6588297872340425
- 0.6584574468085106
- 0.6555851063829787
- 0.6588829787234043
- 0.6605319148936171
- 0.6597340425531915
test_loss_list:
- 3.782862742741903
- 3.697363640467326
- 3.494032834370931
- 3.2073230806986492
- 3.0093596458435057
- 2.818171847661336
- 2.6987933127085366
- 2.6982906246185303
- 2.5604658857981364
- 2.5782574780782066
- 2.5180186239878335
- 2.503768758773804
- 2.4657454776763914
- 2.5491394742329914
- 2.3690918509165444
- 2.3570141410827636
- 2.369291149775187
- 2.37482115427653
- 2.3243527698516844
- 2.362867137591044
- 2.474131892522176
- 2.3335556904474895
- 2.2660311222076417
- 2.340480372111003
- 2.204112105369568
- 2.196880127588908
- 2.2838952589035033
- 2.3454617245992027
- 2.268900615374247
- 2.0726659886042276
- 2.1081794420878093
- 2.0726454623540245
- 2.16826487382253
- 2.085358649889628
- 2.055941004753113
- 2.134852819442749
- 2.1656273142496745
- 2.1459576749801634
- 2.0032658433914183
- 1.9668920564651489
- 2.088466920852661
- 1.9411207373936972
- 2.074004693031311
- 2.057737504641215
- 2.0724534463882445
- 2.0057189162572224
- 1.9370998509724935
- 1.8680013513565064
- 2.1285282389322915
- 2.12025111357371
- 1.889137593905131
- 1.8855445051193238
- 1.7821814425786335
- 1.9492271534601848
- 1.9444222450256348
- 2.087437971433004
- 1.8582123645146689
- 1.9495405117670694
- 1.8255898761749267
- 1.8175045267740886
- 1.6836287419001261
- 1.7662502320607503
- 1.8611482715606689
- 1.7360667641957601
- 1.7597157255808513
- 1.7472257359822592
- 1.8066504351298014
- 1.6991780471801758
- 1.8054519955317179
- 1.78477801322937
- 1.7003422753016153
- 1.7901188373565673
- 1.7874315770467122
- 1.7539329640070598
- 1.5739222876230876
- 1.7370264196395875
- 1.5941592709223429
- 1.6247259998321533
- 1.7356606674194337
- 1.816122539838155
- 1.731327470143636
- 1.6377724170684815
- 1.7181762154897053
- 1.8442578919728596
- 1.758975346883138
- 1.5658392588297525
- 1.7169945176442465
- 1.6204568274815878
- 1.5940025965372722
- 1.599074748357137
- 1.6707924397786458
- 1.693933842976888
- 1.5025098927815754
- 1.6567892376581828
- 1.570937835375468
- 1.6524343093236287
- 1.5716193119684856
- 1.7349003760019939
- 1.7350778261820474
- 1.6813079897562664
train_accuracy:
- 0.0
- 0.146
- 0.223
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.6
- 0.617
- 0.0
- 0.656
- 0.652
- 0.633
- 0.696
- 0.0
- 0.688
- 0.0
- 0.0
- 0.721
- 0.0
- 0.71
- 0.0
- 0.719
- 0.74
- 0.74
- 0.723
- 0.735
- 0.0
- 0.0
- 0.763
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.775
- 0.792
- 0.0
- 0.0
- 0.0
- 0.798
- 0.787
- 0.0
- 0.802
- 0.0
- 0.79
- 0.808
- 0.0
- 0.0
- 0.787
- 0.0
- 0.002
- 0.8
- 0.802
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.819
- 0.0
- 0.002
- 0.0
- 0.821
- 0.81
- 0.84
- 0.0
- 0.0
- 0.002
- 0.817
- 0.0
- 0.821
- 0.838
- 0.0
- 0.002
- 0.0
- 0.0
- 0.004
- 0.0
- 0.0
- 0.835
- 0.0
- 0.823
- 0.848
- 0.0
- 0.006
- 0.86
- 0.0
- 0.825
- 0.85
- 0.854
- 0.867
train_loss:
- 2.486
- 2.458
- 2.263
- 2.042
- 1.858
- 1.371
- 1.269
- 1.506
- 0.891
- 1.113
- 1.306
- 1.055
- 1.223
- 1.428
- 0.97
- 0.954
- 0.954
- 1.108
- 0.912
- 1.059
- 1.273
- 1.038
- 0.854
- 1.024
- 0.807
- 0.811
- 0.983
- 1.134
- 0.947
- 0.598
- 0.751
- 0.747
- 0.9
- 0.747
- 0.729
- 0.904
- 0.889
- 0.873
- 0.711
- 0.697
- 0.852
- 0.704
- 0.834
- 0.839
- 0.825
- 0.828
- 0.669
- 0.66
- 0.953
- 0.949
- 0.672
- 0.645
- 0.493
- 0.77
- 0.773
- 0.917
- 0.63
- 0.765
- 0.619
- 0.609
- 0.49
- 0.607
- 0.752
- 0.613
- 0.601
- 0.594
- 0.728
- 0.593
- 0.742
- 0.73
- 0.585
- 0.726
- 0.723
- 0.725
- 0.464
- 0.709
- 0.455
- 0.575
- 0.708
- 0.834
- 0.698
- 0.569
- 0.697
- 0.826
- 0.687
- 0.453
- 0.684
- 0.571
- 0.56
- 0.564
- 0.674
- 0.673
- 0.43
- 0.678
- 0.539
- 0.663
- 0.549
- 0.799
- 0.789
- 0.659
unequal: 0
verbose: 1
