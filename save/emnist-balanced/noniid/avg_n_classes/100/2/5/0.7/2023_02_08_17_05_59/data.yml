avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03893617021276596
- 0.09521276595744681
- 0.20659574468085107
- 0.2871808510638298
- 0.36308510638297875
- 0.4072340425531915
- 0.44904255319148934
- 0.4693617021276596
- 0.4848936170212766
- 0.501436170212766
- 0.5021808510638298
- 0.5217021276595745
- 0.5331382978723405
- 0.5332978723404256
- 0.5472340425531915
- 0.5525531914893617
- 0.5559574468085107
- 0.5577659574468085
- 0.5642553191489361
- 0.5609042553191489
- 0.5775
- 0.5718617021276595
- 0.5753723404255319
- 0.579627659574468
- 0.5894680851063829
- 0.5901063829787234
- 0.5885638297872341
- 0.5921276595744681
- 0.5955851063829787
- 0.599095744680851
- 0.5973404255319149
- 0.6036702127659574
- 0.6076063829787234
- 0.6047872340425532
- 0.6053723404255319
- 0.6109042553191489
- 0.6115425531914893
- 0.6081382978723404
- 0.6139361702127659
- 0.6146808510638297
- 0.6188297872340426
- 0.6132446808510639
- 0.617872340425532
- 0.6217021276595744
- 0.6204787234042554
- 0.6245744680851064
- 0.6182978723404255
- 0.6253723404255319
- 0.6254255319148936
- 0.6232978723404256
- 0.6268085106382979
- 0.623563829787234
- 0.6295212765957446
- 0.6307446808510638
- 0.6326063829787234
- 0.6320744680851064
- 0.6280851063829788
- 0.6278191489361702
- 0.6339361702127659
- 0.6332446808510638
- 0.637127659574468
- 0.6338297872340426
- 0.635
- 0.6361170212765958
- 0.6332978723404256
- 0.6389893617021276
- 0.6362765957446809
- 0.6344148936170213
- 0.6388297872340426
- 0.6381914893617021
- 0.6421808510638298
- 0.6398936170212766
- 0.6395744680851064
- 0.6370212765957447
- 0.6387765957446808
- 0.6394148936170213
- 0.6402659574468085
- 0.6401595744680851
- 0.6448404255319149
- 0.6412234042553191
- 0.6437765957446808
- 0.6434042553191489
- 0.6481382978723405
- 0.6440957446808511
- 0.6461702127659574
- 0.6413297872340425
- 0.6446808510638298
- 0.6458510638297872
- 0.6468617021276596
- 0.6468617021276596
- 0.6493085106382979
- 0.6483510638297872
- 0.6490425531914894
- 0.6457978723404255
- 0.651436170212766
- 0.6501063829787234
- 0.6506382978723404
- 0.6513297872340426
- 0.6495212765957447
- 0.6498936170212766
test_loss_list:
- 3.7792495695749917
- 3.701036122639974
- 3.4524747149149575
- 3.128543866475423
- 2.928054043451945
- 2.815897808074951
- 2.796948013305664
- 2.662881193161011
- 2.628954305648804
- 2.6253105958302814
- 2.485363136927287
- 2.5731956736246744
- 2.5236183706919353
- 2.4124850463867187
- 2.443015454610189
- 2.4474721177419028
- 2.445043528874715
- 2.304744997024536
- 2.3889100392659506
- 2.2418233156204224
- 2.3971233558654785
- 2.2642954476674397
- 2.232810587882996
- 2.2412434593836466
- 2.2850951878229777
- 2.241103173891703
- 2.1561620457967123
- 2.1945295190811156
- 2.207398285865784
- 2.2509358088175455
- 2.0482373142242434
- 2.181302545865377
- 2.199164721171061
- 2.0220030562082925
- 2.037411427497864
- 2.1470235188802085
- 2.187894385655721
- 1.9793194246292114
- 2.1415007495880127
- 2.137732369105021
- 2.2363344367345173
- 1.966082469622294
- 2.02259442170461
- 2.1370802704493204
- 2.0303216473261516
- 2.10237863222758
- 1.9660959720611573
- 2.109789136250814
- 2.099262274106344
- 1.9825284242630006
- 2.0421535857518514
- 1.950221602121989
- 2.047511701583862
- 2.055205632845561
- 2.152551147143046
- 2.084219725926717
- 1.8404207849502563
- 1.830513868331909
- 1.8592656008402506
- 1.9700187253952026
- 1.9831464910507202
- 1.9818203115463258
- 1.8931887769699096
- 1.9744722493489584
- 1.877750546137492
- 2.1181635951995847
- 1.8373061800003052
- 1.726467498143514
- 1.825116025606791
- 1.794678339958191
- 2.012091541290283
- 1.8275713809331258
- 1.796419275601705
- 1.7638055499394734
- 1.7813493998845418
- 1.7923001035054524
- 1.7755780251820883
- 1.6836337963740031
- 1.8897587649027507
- 1.6986155064900716
- 1.8789664936065673
- 1.7345716094970702
- 1.9045780245463053
- 1.8123434114456176
- 1.8439029518763224
- 1.682561297416687
- 1.695673770904541
- 1.6989396969477335
- 1.7628246370951335
- 1.6822601747512818
- 1.905134539604187
- 1.700135825475057
- 1.817815982500712
- 1.6322219308217367
- 1.7818389717737835
- 1.9201522461573284
- 1.8396218554178874
- 1.797343381245931
- 1.7451876544952392
- 1.689408950805664
train_accuracy:
- 0.0
- 0.154
- 0.0
- 0.358
- 0.429
- 0.0
- 0.573
- 0.627
- 0.0
- 0.648
- 0.0
- 0.662
- 0.688
- 0.0
- 0.706
- 0.708
- 0.708
- 0.698
- 0.765
- 0.696
- 0.0
- 0.0
- 0.731
- 0.79
- 0.754
- 0.748
- 0.756
- 0.744
- 0.0
- 0.771
- 0.0
- 0.765
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.79
- 0.0
- 0.79
- 0.792
- 0.81
- 0.0
- 0.0
- 0.804
- 0.0
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.804
- 0.0
- 0.0
- 0.808
- 0.0
- 0.0
- 0.0
- 0.812
- 0.812
- 0.815
- 0.825
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.815
- 0.817
- 0.867
- 0.819
- 0.0
- 0.002
- 0.877
- 0.827
- 0.829
- 0.823
- 0.0
- 0.0
- 0.0
- 0.877
- 0.0
- 0.831
- 0.825
- 0.0
- 0.0
- 0.0
- 0.817
- 0.819
- 0.84
- 0.831
- 0.825
- 0.0
- 0.0
- 0.817
- 0.823
- 0.829
- 0.0
- 0.0
train_loss:
- 2.554
- 2.522
- 1.867
- 1.665
- 1.834
- 1.654
- 1.817
- 1.471
- 1.424
- 1.328
- 1.103
- 1.27
- 1.222
- 0.994
- 1.182
- 1.145
- 1.14
- 0.946
- 1.093
- 0.726
- 1.031
- 0.882
- 0.863
- 0.827
- 0.988
- 0.803
- 0.795
- 0.782
- 0.954
- 0.923
- 0.628
- 0.911
- 0.913
- 0.609
- 0.753
- 0.902
- 0.874
- 0.593
- 0.878
- 0.861
- 0.998
- 0.59
- 0.707
- 0.843
- 0.686
- 0.82
- 0.702
- 0.807
- 0.812
- 0.676
- 0.813
- 0.667
- 0.787
- 0.796
- 0.919
- 0.771
- 0.54
- 0.523
- 0.647
- 0.775
- 0.757
- 0.775
- 0.633
- 0.772
- 0.648
- 0.861
- 0.645
- 0.505
- 0.621
- 0.614
- 0.874
- 0.634
- 0.625
- 0.615
- 0.624
- 0.603
- 0.61
- 0.486
- 0.706
- 0.495
- 0.699
- 0.62
- 0.687
- 0.736
- 0.716
- 0.485
- 0.602
- 0.596
- 0.584
- 0.595
- 0.814
- 0.594
- 0.685
- 0.472
- 0.702
- 0.795
- 0.679
- 0.693
- 0.569
- 0.577
unequal: 0
verbose: 1
