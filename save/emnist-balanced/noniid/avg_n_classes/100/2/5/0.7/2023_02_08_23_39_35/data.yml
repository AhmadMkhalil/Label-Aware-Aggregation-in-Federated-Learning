avg_train_accuracy: 0.86
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.031329787234042554
- 0.07281914893617021
- 0.22335106382978723
- 0.3472872340425532
- 0.4110106382978723
- 0.44909574468085106
- 0.4668617021276596
- 0.48404255319148937
- 0.5042553191489362
- 0.513031914893617
- 0.5235106382978724
- 0.5256914893617022
- 0.5407978723404255
- 0.5403191489361702
- 0.5542553191489362
- 0.5601063829787234
- 0.5678723404255319
- 0.5711702127659575
- 0.5732446808510638
- 0.5777127659574468
- 0.5764361702127659
- 0.5858510638297872
- 0.5921808510638298
- 0.5938297872340426
- 0.5899468085106383
- 0.5957978723404256
- 0.5997872340425532
- 0.6001063829787234
- 0.6051063829787234
- 0.6043085106382978
- 0.6063829787234043
- 0.6044148936170213
- 0.6067553191489362
- 0.6103191489361702
- 0.6147872340425532
- 0.6150531914893617
- 0.6152659574468086
- 0.6184042553191489
- 0.619468085106383
- 0.6201595744680851
- 0.6189893617021277
- 0.6252659574468085
- 0.6238297872340426
- 0.6279787234042553
- 0.6238829787234043
- 0.6287234042553191
- 0.6249468085106383
- 0.6281382978723404
- 0.628031914893617
- 0.625
- 0.630531914893617
- 0.6292021276595745
- 0.6292021276595745
- 0.6308510638297873
- 0.6335106382978724
- 0.6327127659574469
- 0.6349468085106383
- 0.6337234042553191
- 0.6313297872340425
- 0.6339893617021276
- 0.6341489361702127
- 0.6348936170212766
- 0.6382446808510638
- 0.6396276595744681
- 0.6416489361702128
- 0.6374468085106383
- 0.6382978723404256
- 0.6403191489361703
- 0.6402659574468085
- 0.6422872340425532
- 0.6411702127659574
- 0.6407978723404255
- 0.6419148936170213
- 0.6418617021276596
- 0.6437234042553192
- 0.6418085106382979
- 0.643936170212766
- 0.6427127659574469
- 0.6453191489361703
- 0.6459574468085106
- 0.645531914893617
- 0.6458510638297872
- 0.6456382978723404
- 0.6488829787234043
- 0.6461170212765958
- 0.6478191489361702
- 0.6473936170212766
- 0.6469148936170213
- 0.6470212765957447
- 0.6478723404255319
- 0.6497872340425532
- 0.6498936170212766
- 0.6484042553191489
- 0.6490425531914894
- 0.6497340425531914
- 0.6499468085106384
- 0.6501063829787234
- 0.6509574468085106
- 0.6515425531914893
- 0.6522340425531915
test_loss_list:
- 3.777444715499878
- 3.6842866675059
- 3.442899249394735
- 3.099436922073364
- 2.8658517678578694
- 2.7238214079538983
- 2.627535807291667
- 2.5237151845296224
- 2.5819184589385986
- 2.463387610117594
- 2.4217950852711994
- 2.3360067558288575
- 2.3592095311482746
- 2.272490318616231
- 2.392739715576172
- 2.382449696858724
- 2.3981071376800536
- 2.3601166184743247
- 2.328681461016337
- 2.3514533980687458
- 2.1761633761723838
- 2.3179487975438438
- 2.3994632879892985
- 2.2923992999394733
- 2.1150277042388916
- 2.1611429341634114
- 2.158269392649333
- 2.139826733271281
- 2.1129292980829875
- 2.0895309845606485
- 2.181007801691691
- 1.9779746182759603
- 2.0325805600484212
- 2.0614363861083986
- 2.16406707127889
- 2.15807337919871
- 2.1221541213989257
- 2.251112939516703
- 2.275860514640808
- 2.2591400480270387
- 2.0887966283162434
- 2.2769095373153685
- 2.27800182501475
- 2.321773111025492
- 2.0818991533915203
- 2.16579789797465
- 2.0160477447509764
- 2.0282768233617148
- 2.0750568040211994
- 1.8717614046732585
- 1.9566329447428386
- 1.915159363746643
- 1.9121977885564168
- 1.9009552669525147
- 2.1313968563079833
- 1.9058933194478354
- 1.9909827311833699
- 1.913974715868632
- 1.7831946023305256
- 1.8742383575439454
- 1.8615236298243205
- 1.8630514319737752
- 1.9397085920969646
- 2.095928235054016
- 2.0904307158788047
- 1.9580697202682495
- 1.8802549266815185
- 1.9552457125981648
- 1.7765462668736776
- 2.037044816017151
- 1.9149765650431314
- 1.8113841772079469
- 1.9039911635716755
- 1.8255669943491617
- 1.802352663675944
- 1.7873531421025595
- 1.85609872341156
- 1.6924319664637248
- 1.9710486078262328
- 1.7893443981806436
- 1.9439881626764934
- 1.8743637196222942
- 1.7692608944574992
- 1.8746846278508504
- 1.7379913457234701
- 1.825359477996826
- 1.733558824857076
- 1.8195382420221964
- 1.7359814914067586
- 1.8389075501759846
- 1.82917285601298
- 1.8261640357971192
- 1.7112433004379273
- 1.6990817419687907
- 1.6921555805206299
- 1.6760804398854574
- 1.6740814749399822
- 1.767540381749471
- 1.7808997456232707
- 1.8024651511510212
train_accuracy:
- 0.037
- 0.0
- 0.283
- 0.0
- 0.0
- 0.529
- 0.0
- 0.0
- 0.669
- 0.0
- 0.0
- 0.688
- 0.0
- 0.0
- 0.0
- 0.713
- 0.0
- 0.0
- 0.0
- 0.74
- 0.0
- 0.0
- 0.723
- 0.758
- 0.0
- 0.763
- 0.0
- 0.0
- 0.777
- 0.773
- 0.775
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.777
- 0.787
- 0.79
- 0.8
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.802
- 0.0
- 0.79
- 0.771
- 0.0
- 0.0
- 0.831
- 0.817
- 0.804
- 0.831
- 0.804
- 0.815
- 0.808
- 0.829
- 0.81
- 0.0
- 0.819
- 0.829
- 0.806
- 0.804
- 0.827
- 0.0
- 0.808
- 0.002
- 0.0
- 0.84
- 0.817
- 0.0
- 0.0
- 0.0
- 0.0
- 0.815
- 0.8
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.838
- 0.002
- 0.0
- 0.812
- 0.0
- 0.835
- 0.0
- 0.821
- 0.819
- 0.0
- 0.812
- 0.86
train_loss:
- 2.144
- 1.55
- 2.232
- 2.005
- 1.791
- 1.604
- 1.242
- 0.895
- 1.368
- 1.062
- 1.03
- 0.773
- 0.959
- 0.737
- 1.139
- 1.107
- 1.085
- 1.069
- 1.05
- 1.034
- 0.663
- 0.99
- 1.172
- 0.977
- 0.625
- 0.782
- 0.775
- 0.766
- 0.749
- 0.752
- 0.9
- 0.575
- 0.73
- 0.716
- 0.864
- 0.853
- 0.87
- 1.002
- 0.996
- 1.001
- 0.714
- 0.977
- 0.974
- 0.964
- 0.695
- 0.81
- 0.679
- 0.656
- 0.807
- 0.519
- 0.651
- 0.646
- 0.653
- 0.637
- 0.905
- 0.648
- 0.763
- 0.639
- 0.5
- 0.612
- 0.626
- 0.623
- 0.748
- 0.876
- 0.877
- 0.748
- 0.608
- 0.727
- 0.48
- 0.859
- 0.731
- 0.61
- 0.717
- 0.596
- 0.592
- 0.595
- 0.713
- 0.465
- 0.824
- 0.59
- 0.828
- 0.7
- 0.584
- 0.695
- 0.581
- 0.69
- 0.568
- 0.694
- 0.571
- 0.688
- 0.678
- 0.678
- 0.565
- 0.56
- 0.55
- 0.554
- 0.553
- 0.667
- 0.671
- 0.669
unequal: 0
verbose: 1
