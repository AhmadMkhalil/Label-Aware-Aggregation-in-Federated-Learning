avg_train_accuracy: 0.844
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03787234042553191
- 0.09856382978723405
- 0.1981382978723404
- 0.30829787234042555
- 0.38638297872340427
- 0.42143617021276597
- 0.4366489361702128
- 0.4545744680851064
- 0.47579787234042553
- 0.4848404255319149
- 0.504468085106383
- 0.5094148936170213
- 0.5128191489361702
- 0.5235106382978724
- 0.5321276595744681
- 0.5391489361702128
- 0.5422340425531915
- 0.5516489361702127
- 0.5575531914893617
- 0.5576063829787234
- 0.565531914893617
- 0.5679787234042554
- 0.5687765957446809
- 0.5752127659574469
- 0.5777659574468085
- 0.5794148936170213
- 0.5873936170212766
- 0.5893085106382979
- 0.5925531914893617
- 0.5929787234042553
- 0.5977127659574468
- 0.6011170212765957
- 0.5992021276595745
- 0.6039893617021277
- 0.6046276595744681
- 0.6112765957446809
- 0.6086170212765958
- 0.6084574468085107
- 0.6079787234042553
- 0.6148404255319149
- 0.6193617021276596
- 0.6176595744680851
- 0.6182978723404255
- 0.6199468085106383
- 0.6225531914893617
- 0.6251595744680851
- 0.6275531914893617
- 0.6234042553191489
- 0.6301595744680851
- 0.628563829787234
- 0.6288829787234043
- 0.6274468085106383
- 0.6294148936170213
- 0.6315957446808511
- 0.6299468085106383
- 0.6332978723404256
- 0.6350531914893617
- 0.6383510638297872
- 0.6368085106382979
- 0.6379787234042553
- 0.6368085106382979
- 0.6409574468085106
- 0.6384574468085107
- 0.6395212765957446
- 0.6400531914893617
- 0.6371808510638298
- 0.6399468085106383
- 0.6390425531914894
- 0.642127659574468
- 0.643563829787234
- 0.6440957446808511
- 0.6443085106382979
- 0.6425
- 0.6442021276595745
- 0.6402127659574468
- 0.6451595744680851
- 0.6469148936170213
- 0.6489893617021276
- 0.6513297872340426
- 0.6525531914893618
- 0.6479255319148937
- 0.6504255319148936
- 0.6529255319148937
- 0.6526595744680851
- 0.6514893617021277
- 0.6509574468085106
- 0.6504787234042553
- 0.6508510638297872
- 0.6504255319148936
- 0.6487765957446808
- 0.6486170212765957
- 0.6502127659574468
- 0.6518085106382979
- 0.6521808510638298
- 0.6537234042553192
- 0.6565425531914894
- 0.6544148936170213
- 0.6579255319148937
- 0.654468085106383
- 0.6551063829787234
test_loss_list:
- 3.789946269989014
- 3.68815762201945
- 3.4402638117472333
- 3.1467267100016274
- 2.9387488396962484
- 2.819211031595866
- 2.6809886010487873
- 2.6231390889485677
- 2.5994092845916748
- 2.4987325700124106
- 2.588366371790568
- 2.557382335662842
- 2.4284439373016355
- 2.458944772084554
- 2.4180191135406495
- 2.496539347966512
- 2.41157990137736
- 2.4705627218882245
- 2.4625617090861
- 2.4196647230784096
- 2.401455637613932
- 2.4098863140741984
- 2.2957542912165323
- 2.3692361084620157
- 2.26760680993398
- 2.239729962348938
- 2.3165523703893025
- 2.234988910357157
- 2.198933401107788
- 2.1697120602925617
- 2.251614980697632
- 2.236565408706665
- 2.1131972789764406
- 2.22688845316569
- 2.13071616490682
- 2.3315562852223715
- 2.115072380701701
- 2.107057592074076
- 2.0832124662399294
- 2.2797871685028075
- 2.167029299736023
- 2.0650418472290037
- 2.054071763356527
- 2.0214588038126626
- 2.131506005922953
- 2.1306618356704714
- 2.2512036037445067
- 2.008900901476542
- 2.111234927177429
- 1.9707642475763956
- 2.0866291507085166
- 1.9923089456558227
- 1.8599193731943766
- 2.0541021060943603
- 1.9489622545242309
- 1.9336621491114299
- 1.8724304850896198
- 1.991420865058899
- 1.901256430943807
- 2.117723140716553
- 1.9080238803227743
- 2.083419804573059
- 1.994823702176412
- 1.8879568020502726
- 1.9027536090215047
- 1.825905000368754
- 1.8633667087554933
- 1.738922308286031
- 1.8051297346750894
- 1.906939156850179
- 1.9111866188049316
- 1.7555770508448283
- 1.9569490480422973
- 1.8137885745366413
- 1.684683885574341
- 1.7610192839304606
- 1.958897695541382
- 1.893194662729899
- 1.9096487951278687
- 2.025846980412801
- 1.77074169476827
- 1.8664039198557536
- 1.8739515272776286
- 1.8892436552047729
- 1.7659581359227499
- 1.868221386273702
- 1.8541153367360432
- 1.7628950436909994
- 1.751214796702067
- 1.7207276471455892
- 1.817478396097819
- 1.8493025509516399
- 1.9082431713740031
- 1.7458361641565958
- 1.8022874307632446
- 1.8171840842564901
- 1.8301892534891764
- 1.8118452564875285
- 1.820510794321696
- 1.7854290040334067
train_accuracy:
- 0.0
- 0.0
- 0.246
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.594
- 0.623
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.733
- 0.719
- 0.737
- 0.727
- 0.0
- 0.746
- 0.0
- 0.0
- 0.0
- 0.758
- 0.0
- 0.0
- 0.777
- 0.0
- 0.779
- 0.0
- 0.0
- 0.756
- 0.812
- 0.0
- 0.0
- 0.806
- 0.79
- 0.792
- 0.794
- 0.0
- 0.817
- 0.804
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.8
- 0.802
- 0.84
- 0.8
- 0.0
- 0.821
- 0.0
- 0.825
- 0.815
- 0.81
- 0.833
- 0.002
- 0.0
- 0.838
- 0.002
- 0.842
- 0.0
- 0.0
- 0.838
- 0.846
- 0.004
- 0.796
- 0.0
- 0.0
- 0.846
- 0.0
- 0.806
- 0.0
- 0.844
- 0.829
- 0.815
- 0.0
- 0.0
- 0.852
- 0.0
- 0.848
- 0.848
- 0.002
- 0.823
- 0.002
- 0.819
- 0.865
- 0.006
- 0.817
- 0.842
- 0.0
- 0.0
- 0.838
- 0.844
train_loss:
- 2.012
- 1.956
- 1.79
- 1.97
- 1.802
- 1.652
- 1.244
- 1.195
- 1.137
- 0.869
- 1.301
- 1.26
- 0.81
- 0.983
- 0.98
- 1.15
- 0.942
- 1.114
- 1.086
- 1.078
- 1.06
- 1.042
- 0.84
- 1.006
- 0.837
- 0.818
- 0.966
- 0.796
- 0.79
- 0.778
- 0.919
- 0.946
- 0.77
- 0.902
- 0.751
- 1.041
- 0.751
- 0.71
- 0.722
- 0.999
- 0.861
- 0.71
- 0.687
- 0.694
- 0.812
- 0.844
- 0.956
- 0.672
- 0.804
- 0.68
- 0.805
- 0.652
- 0.524
- 0.792
- 0.633
- 0.66
- 0.657
- 0.772
- 0.636
- 0.887
- 0.645
- 0.883
- 0.758
- 0.642
- 0.61
- 0.62
- 0.599
- 0.483
- 0.591
- 0.73
- 0.726
- 0.473
- 0.842
- 0.61
- 0.471
- 0.581
- 0.827
- 0.716
- 0.72
- 0.814
- 0.599
- 0.697
- 0.701
- 0.71
- 0.582
- 0.706
- 0.687
- 0.584
- 0.551
- 0.568
- 0.662
- 0.663
- 0.807
- 0.552
- 0.694
- 0.677
- 0.672
- 0.669
- 0.669
- 0.684
unequal: 0
verbose: 1
