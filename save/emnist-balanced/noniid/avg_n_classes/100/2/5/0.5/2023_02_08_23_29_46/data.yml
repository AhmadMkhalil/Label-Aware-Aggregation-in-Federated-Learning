avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029361702127659574
- 0.07202127659574468
- 0.1696276595744681
- 0.2773404255319149
- 0.36920212765957444
- 0.4178191489361702
- 0.4475
- 0.46335106382978725
- 0.49111702127659573
- 0.49829787234042555
- 0.5074468085106383
- 0.515
- 0.5297340425531915
- 0.5286702127659575
- 0.5256914893617022
- 0.5420744680851064
- 0.551063829787234
- 0.5586170212765957
- 0.564468085106383
- 0.5682978723404255
- 0.5724468085106383
- 0.5757446808510638
- 0.5821808510638298
- 0.585531914893617
- 0.5852127659574468
- 0.5898404255319148
- 0.5944148936170213
- 0.5871276595744681
- 0.5926595744680851
- 0.601063829787234
- 0.6041489361702128
- 0.6026595744680852
- 0.6029255319148936
- 0.6105851063829787
- 0.608563829787234
- 0.6036702127659574
- 0.6107446808510638
- 0.6137234042553191
- 0.6194148936170213
- 0.6188829787234043
- 0.6217021276595744
- 0.616436170212766
- 0.6183510638297872
- 0.6196276595744681
- 0.6199468085106383
- 0.6204787234042554
- 0.6242021276595745
- 0.6202127659574468
- 0.6197340425531915
- 0.6275531914893617
- 0.6265957446808511
- 0.6323404255319149
- 0.6306914893617022
- 0.6317553191489361
- 0.6352659574468085
- 0.6308510638297873
- 0.6362765957446809
- 0.6368617021276596
- 0.6383510638297872
- 0.6362765957446809
- 0.6400531914893617
- 0.6404255319148936
- 0.6417553191489361
- 0.6390425531914894
- 0.641436170212766
- 0.6398404255319149
- 0.6410106382978723
- 0.639468085106383
- 0.6377659574468085
- 0.6409574468085106
- 0.6406382978723404
- 0.6396808510638298
- 0.6431382978723404
- 0.6466489361702128
- 0.6410638297872341
- 0.6476595744680851
- 0.6420744680851064
- 0.6476063829787234
- 0.6467553191489361
- 0.6471808510638298
- 0.6474468085106383
- 0.6503191489361703
- 0.6506914893617022
- 0.65
- 0.6510638297872341
- 0.6507446808510639
- 0.65
- 0.6526063829787234
- 0.6523404255319148
- 0.6479787234042553
- 0.6517553191489361
- 0.6531382978723405
- 0.6523936170212766
- 0.6545744680851063
- 0.655
- 0.6568085106382979
- 0.6529255319148937
- 0.6556382978723404
- 0.6575
- 0.654468085106383
test_loss_list:
- 3.7865271282196047
- 3.7195267836252848
- 3.511827589670817
- 3.2730598322550457
- 3.0402522532145184
- 2.919647766749064
- 2.8316477171579995
- 2.79985626856486
- 2.891968062718709
- 2.785333366394043
- 2.720670744578044
- 2.7482533486684164
- 2.7713965606689452
- 2.6661516666412353
- 2.5940251636505125
- 2.658343102137248
- 2.690273583730062
- 2.6923546504974367
- 2.607305405934652
- 2.6841375986735025
- 2.6647782452901203
- 2.714021946589152
- 2.7231678676605227
- 2.8446680323282876
- 2.71247891108195
- 2.750369873046875
- 2.8962222003936766
- 2.5031904125213624
- 2.5130141989390054
- 2.675709206263224
- 2.7872392654418947
- 2.5723859818776447
- 2.4820493030548096
- 2.6513503265380858
- 2.5252135817209878
- 2.506486948331197
- 2.50313188234965
- 2.4870929304758707
- 2.6537447134653727
- 2.7596052487691245
- 2.608521890640259
- 2.557217461268107
- 2.4988213968276978
- 2.343506614367167
- 2.383183493614197
- 2.365356478691101
- 2.3969894440968833
- 2.3153996801376344
- 2.230245410601298
- 2.4708951059977213
- 2.261860400835673
- 2.5398029963175457
- 2.4680354245503744
- 2.395931846300761
- 2.4136677757898966
- 2.218630401293437
- 2.4050476932525635
- 2.467139199574788
- 2.4724029811223347
- 2.2952356354395547
- 2.4723439423243203
- 2.4040194193522137
- 2.6044676876068116
- 2.212292056083679
- 2.410920465787252
- 2.3009000889460247
- 2.2356497462590537
- 2.1384719530741374
- 2.1191117000579833
- 2.2172945022583006
- 2.180558870633443
- 2.151829177538554
- 2.1405760860443115
- 2.3999960819880166
- 2.05552570660909
- 2.434647733370463
- 2.0551135206222533
- 2.1470525964101155
- 2.191433703104655
- 2.3253613710403442
- 2.2534871355692547
- 2.291763860384623
- 2.28756738503774
- 2.3830905803044637
- 2.4432184998194377
- 2.2580843130747477
- 2.4104107443491616
- 2.238139066696167
- 2.3309707419077554
- 2.091099354426066
- 2.110476851463318
- 2.2283451890945436
- 2.1168054072062175
- 2.214754068056742
- 2.245526024500529
- 2.0833756812413533
- 1.9340668312708538
- 2.2142070547739663
- 2.2250829188028973
- 1.9880282322565714
train_accuracy:
- 0.04
- 0.079
- 0.219
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.656
- 0.0
- 0.0
- 0.0
- 0.658
- 0.0
- 0.0
- 0.0
- 0.733
- 0.0
- 0.0
- 0.719
- 0.771
- 0.744
- 0.0
- 0.777
- 0.76
- 0.0
- 0.71
- 0.0
- 0.0
- 0.71
- 0.765
- 0.0
- 0.756
- 0.74
- 0.0
- 0.0
- 0.79
- 0.8
- 0.79
- 0.808
- 0.0
- 0.758
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.765
- 0.798
- 0.781
- 0.829
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.831
- 0.838
- 0.0
- 0.0
- 0.0
- 0.792
- 0.787
- 0.827
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.842
- 0.0
- 0.0
- 0.0
- 0.0
- 0.831
- 0.808
- 0.0
- 0.842
- 0.846
- 0.844
- 0.81
- 0.0
- 0.852
- 0.0
- 0.0
- 0.829
- 0.838
- 0.0
- 0.0
- 0.848
- 0.852
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
train_loss:
- 2.667
- 1.981
- 2.367
- 2.144
- 1.461
- 1.324
- 1.247
- 1.19
- 1.808
- 1.424
- 1.1
- 1.355
- 1.302
- 1.007
- 0.697
- 0.95
- 1.192
- 1.188
- 0.938
- 1.161
- 1.161
- 1.134
- 1.106
- 1.307
- 1.069
- 1.047
- 1.264
- 0.615
- 0.567
- 1.032
- 1.212
- 0.799
- 0.795
- 0.966
- 0.774
- 0.781
- 0.737
- 0.753
- 0.899
- 1.121
- 0.913
- 0.949
- 0.728
- 0.514
- 0.713
- 0.505
- 0.699
- 0.497
- 0.5
- 0.879
- 0.483
- 1.059
- 0.866
- 0.659
- 0.853
- 0.517
- 0.861
- 0.82
- 0.814
- 0.667
- 0.786
- 0.827
- 0.972
- 0.493
- 0.803
- 0.656
- 0.652
- 0.489
- 0.447
- 0.61
- 0.61
- 0.653
- 0.62
- 0.927
- 0.473
- 0.923
- 0.481
- 0.586
- 0.789
- 0.924
- 0.767
- 0.76
- 0.758
- 0.903
- 0.899
- 0.585
- 0.897
- 0.756
- 0.75
- 0.444
- 0.581
- 0.731
- 0.577
- 0.72
- 0.729
- 0.59
- 0.435
- 0.693
- 0.687
- 0.596
unequal: 0
verbose: 1
