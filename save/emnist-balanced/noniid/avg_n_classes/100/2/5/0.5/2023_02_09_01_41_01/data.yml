avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.01351063829787234
- 0.03207446808510638
- 0.13069148936170213
- 0.24319148936170212
- 0.324468085106383
- 0.356968085106383
- 0.4000531914893617
- 0.3998404255319149
- 0.4304787234042553
- 0.4707978723404255
- 0.47867021276595745
- 0.5006382978723404
- 0.4955851063829787
- 0.5113829787234042
- 0.5127127659574469
- 0.5023936170212766
- 0.5371808510638297
- 0.5349468085106382
- 0.5407978723404255
- 0.5463297872340426
- 0.5502659574468085
- 0.5484574468085106
- 0.5510106382978723
- 0.5513829787234042
- 0.5670744680851064
- 0.5676595744680851
- 0.5714361702127659
- 0.576968085106383
- 0.5790425531914893
- 0.5768617021276595
- 0.5847340425531915
- 0.5806914893617021
- 0.5854255319148937
- 0.5844148936170213
- 0.5962765957446808
- 0.5956914893617021
- 0.6007446808510638
- 0.6001595744680851
- 0.6079787234042553
- 0.6046808510638297
- 0.6051063829787234
- 0.6063297872340425
- 0.6077127659574468
- 0.606063829787234
- 0.6124468085106383
- 0.6162765957446809
- 0.6161702127659574
- 0.6173404255319149
- 0.6131382978723404
- 0.6181914893617021
- 0.6189893617021277
- 0.6115425531914893
- 0.6227659574468085
- 0.6213297872340425
- 0.6211702127659574
- 0.6270212765957447
- 0.623563829787234
- 0.628563829787234
- 0.6301063829787235
- 0.6294148936170213
- 0.6298404255319149
- 0.6276595744680851
- 0.6307446808510638
- 0.635531914893617
- 0.633031914893617
- 0.6351063829787233
- 0.6354255319148936
- 0.6354787234042554
- 0.6381914893617021
- 0.6387234042553191
- 0.6377659574468085
- 0.6358510638297873
- 0.6400531914893617
- 0.635904255319149
- 0.6390425531914894
- 0.6411170212765958
- 0.6400531914893617
- 0.641436170212766
- 0.6401595744680851
- 0.6436702127659575
- 0.6445744680851064
- 0.6443617021276595
- 0.6417021276595745
- 0.6377659574468085
- 0.640531914893617
- 0.6406382978723404
- 0.6454787234042553
- 0.645904255319149
- 0.6462234042553191
- 0.6461702127659574
- 0.6489893617021276
- 0.6479255319148937
- 0.6494148936170213
- 0.6497872340425532
- 0.6514893617021277
- 0.6479787234042553
- 0.6509574468085106
- 0.6496808510638298
- 0.6514893617021277
- 0.6505319148936171
test_loss_list:
- 3.7953109804789227
- 3.7661218007405597
- 3.615667505264282
- 3.2854539362589517
- 3.0451047611236572
- 2.8984740924835206
- 2.8911159960428874
- 2.7492620023091634
- 2.746932589213053
- 2.845284538269043
- 2.7688372866312663
- 2.8580383682250976
- 2.695876658757528
- 2.7490097586313884
- 2.7037691179911296
- 2.547320226033529
- 2.7377789338429768
- 2.6854667822519938
- 2.7348005962371826
- 2.5967666244506837
- 2.5708083947499594
- 2.611692632039388
- 2.559690361022949
- 2.495845225652059
- 2.6666585191090904
- 2.62987548828125
- 2.5317151991526288
- 2.7372828324635825
- 2.6418481731414794
- 2.5909038384755454
- 2.6247259108225505
- 2.519201062520345
- 2.581529982884725
- 2.4506093724568685
- 2.7103754043579102
- 2.5916373125712076
- 2.7319091161092124
- 2.6201363213857016
- 2.722398697535197
- 2.5638603242238363
- 2.5498068364461264
- 2.490289947191874
- 2.428196937243144
- 2.3803952344258628
- 2.5167214918136596
- 2.6411241753896078
- 2.6407621701558432
- 2.377830924987793
- 2.357172654469808
- 2.4167799186706542
- 2.2879935932159423
- 2.1844176944096882
- 2.4025729846954347
- 2.2410080353418986
- 2.3801741154988605
- 2.3890041812260945
- 2.2816932996114097
- 2.3339352575937906
- 2.3354394388198854
- 2.396195567448934
- 2.2722993326187133
- 2.2866486152013143
- 2.160824723243713
- 2.4351940981547036
- 2.238566943804423
- 2.3479344908396405
- 2.2845521688461305
- 2.331332859992981
- 2.3032551527023317
- 2.319337148666382
- 2.147372299830119
- 2.1972762854894
- 2.3954460636774697
- 2.067344214121501
- 2.2152912187576295
- 2.357118134498596
- 2.093561358451843
- 2.0091932169596354
- 2.2008028491338094
- 2.2084989500045777
- 2.17886670589447
- 2.231586414972941
- 1.99142236550649
- 1.934876306851705
- 1.91615726629893
- 1.8841009680430094
- 2.1326416683197023
- 2.249781977335612
- 2.1298214832941693
- 2.023963278134664
- 2.1205363670984902
- 2.0015614652633666
- 2.2048807255427043
- 2.1070563650131224
- 2.260667796134949
- 2.03229172706604
- 2.236246034304301
- 2.2619648536046344
- 2.290866003036499
- 2.1691423877080283
train_accuracy:
- 0.023
- 0.065
- 0.169
- 0.0
- 0.0
- 0.481
- 0.492
- 0.0
- 0.0
- 0.583
- 0.612
- 0.642
- 0.0
- 0.673
- 0.654
- 0.0
- 0.648
- 0.0
- 0.685
- 0.708
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.717
- 0.729
- 0.758
- 0.754
- 0.0
- 0.771
- 0.0
- 0.783
- 0.756
- 0.742
- 0.0
- 0.0
- 0.758
- 0.767
- 0.8
- 0.79
- 0.0
- 0.0
- 0.767
- 0.76
- 0.763
- 0.808
- 0.819
- 0.0
- 0.777
- 0.0
- 0.0
- 0.812
- 0.802
- 0.0
- 0.821
- 0.804
- 0.827
- 0.0
- 0.817
- 0.0
- 0.787
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.817
- 0.0
- 0.833
- 0.85
- 0.0
- 0.004
- 0.002
- 0.812
- 0.835
- 0.0
- 0.004
- 0.0
- 0.0
- 0.84
- 0.842
- 0.856
- 0.0
- 0.0
- 0.006
- 0.006
- 0.842
- 0.842
- 0.819
- 0.01
- 0.863
- 0.869
- 0.852
- 0.0
train_loss:
- 2.599
- 2.589
- 2.466
- 1.073
- 1.428
- 0.879
- 1.725
- 0.787
- 1.121
- 1.872
- 1.396
- 1.724
- 1.03
- 1.303
- 1.294
- 0.693
- 1.209
- 1.259
- 1.192
- 0.892
- 0.879
- 0.853
- 0.837
- 0.619
- 1.096
- 1.093
- 0.822
- 1.293
- 1.042
- 1.07
- 1.021
- 0.821
- 0.998
- 0.783
- 1.186
- 0.94
- 1.151
- 0.921
- 1.146
- 0.989
- 0.984
- 0.759
- 0.704
- 0.744
- 0.901
- 1.113
- 1.098
- 0.739
- 0.716
- 0.888
- 0.733
- 0.498
- 0.863
- 0.704
- 0.852
- 0.84
- 0.674
- 0.825
- 0.851
- 0.802
- 0.614
- 0.855
- 0.681
- 0.981
- 0.645
- 0.79
- 0.833
- 0.795
- 0.786
- 0.791
- 0.641
- 0.623
- 0.943
- 0.485
- 0.796
- 0.946
- 0.617
- 0.453
- 0.759
- 0.746
- 0.771
- 0.747
- 0.44
- 0.42
- 0.392
- 0.422
- 0.715
- 0.881
- 0.755
- 0.578
- 0.756
- 0.576
- 0.901
- 0.749
- 0.883
- 0.595
- 0.891
- 0.886
- 0.872
- 0.728
unequal: 0
verbose: 1
