avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.01957446808510638
- 0.03835106382978724
- 0.13813829787234042
- 0.26053191489361704
- 0.3447340425531915
- 0.4072872340425532
- 0.43117021276595746
- 0.42606382978723406
- 0.4523404255319149
- 0.4795744680851064
- 0.48904255319148937
- 0.5055851063829787
- 0.5104787234042554
- 0.53
- 0.5325531914893618
- 0.5417553191489362
- 0.5408510638297872
- 0.5470212765957447
- 0.5518617021276596
- 0.5554787234042553
- 0.5662234042553191
- 0.5685638297872341
- 0.5774468085106383
- 0.5796808510638298
- 0.5770744680851064
- 0.5778723404255319
- 0.5782978723404255
- 0.5838829787234042
- 0.5820212765957447
- 0.5939893617021277
- 0.5970212765957447
- 0.5994680851063829
- 0.5999468085106383
- 0.5982446808510639
- 0.6015957446808511
- 0.5981382978723404
- 0.6097872340425532
- 0.614468085106383
- 0.6079255319148936
- 0.6129787234042553
- 0.6182446808510639
- 0.6197340425531915
- 0.6202127659574468
- 0.6215957446808511
- 0.6243617021276596
- 0.6251595744680851
- 0.6270744680851064
- 0.6250531914893617
- 0.629095744680851
- 0.6322872340425532
- 0.633031914893617
- 0.6300531914893617
- 0.6330851063829788
- 0.6336702127659575
- 0.6347872340425532
- 0.6332978723404256
- 0.6362234042553192
- 0.6365425531914893
- 0.6366489361702128
- 0.6429787234042553
- 0.641595744680851
- 0.6405851063829787
- 0.6398936170212766
- 0.6414893617021277
- 0.6422340425531915
- 0.6389361702127659
- 0.6469148936170213
- 0.6469148936170213
- 0.6443617021276595
- 0.6436170212765957
- 0.6476063829787234
- 0.6500531914893617
- 0.6496808510638298
- 0.6504787234042553
- 0.6492021276595744
- 0.6520212765957447
- 0.6502127659574468
- 0.6493085106382979
- 0.6523404255319148
- 0.6514893617021277
- 0.653563829787234
- 0.6535106382978724
- 0.6505851063829787
- 0.6545744680851063
- 0.655
- 0.6535106382978724
- 0.6535106382978724
- 0.6522872340425532
- 0.6536170212765957
- 0.6571276595744681
- 0.6586170212765957
- 0.6570212765957447
- 0.6573404255319149
- 0.6598936170212766
- 0.6572340425531915
- 0.6566489361702128
- 0.6582978723404256
- 0.6553191489361702
- 0.6575
- 0.6588297872340425
test_loss_list:
- 3.7866395632425944
- 3.7683573087056477
- 3.6882780265808104
- 3.4353520393371584
- 3.15830979347229
- 3.0005987866719566
- 2.864594456354777
- 2.7854424699147544
- 2.7211676915486653
- 2.718426291147868
- 2.708137772878011
- 2.8026241302490233
- 2.723809626897176
- 2.8673264948527017
- 2.8032051277160646
- 2.8051750818888346
- 2.7113734817504884
- 2.6598664855957033
- 2.6735657787323
- 2.6370116519927977
- 2.7750496610005695
- 2.733098471959432
- 2.8474922688802082
- 2.779522943496704
- 2.663373524347941
- 2.6429994360605877
- 2.590852692921956
- 2.5766340780258177
- 2.4909471893310546
- 2.6703937594095866
- 2.649900925954183
- 2.6880445194244387
- 2.6461275752385456
- 2.539298659960429
- 2.5229463243484496
- 2.394428574244181
- 2.5865598328908286
- 2.4999215539296467
- 2.4043806393941245
- 2.4793984842300416
- 2.5746367232004803
- 2.5641001224517823
- 2.529497044881185
- 2.56434952100118
- 2.5783884127934775
- 2.449171109199524
- 2.5798124917348226
- 2.3495736010869344
- 2.522304964065552
- 2.5144340817133584
- 2.5758491881688435
- 2.2933801952997843
- 2.37455827554067
- 2.3618998034795124
- 2.3534774208068847
- 2.3538861083984375
- 2.4316450214385985
- 2.4335393937428793
- 2.4130846500396728
- 2.407959497769674
- 2.686493844985962
- 2.4010817607243857
- 2.3181207752227784
- 2.390403202374776
- 2.35919243812561
- 2.2349196529388426
- 2.3726690657933553
- 2.3864814329147337
- 2.3184802023569744
- 2.1568267790476483
- 2.3500142590204876
- 2.2826153802871705
- 2.262034200032552
- 2.278363356590271
- 2.2565232944488525
- 2.3898926623662313
- 2.1982568645477296
- 2.1599426142374676
- 2.215435234705607
- 2.1940854008992514
- 2.2622407484054565
- 2.2609192180633544
- 2.1184448941548664
- 2.1077597761154174
- 2.169525637626648
- 2.0930153449376423
- 2.052012645403544
- 2.042267648379008
- 2.058563755353292
- 2.135629328091939
- 2.260464434623718
- 2.079175200462341
- 2.0632634099324543
- 2.2661101071039838
- 2.0501381810506185
- 2.039922782580058
- 2.086432917912801
- 1.9169414933522542
- 1.935206166903178
- 2.0657551860809327
train_accuracy:
- 0.0
- 0.046
- 0.131
- 0.312
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.617
- 0.0
- 0.0
- 0.679
- 0.0
- 0.0
- 0.713
- 0.71
- 0.0
- 0.0
- 0.0
- 0.0
- 0.69
- 0.758
- 0.0
- 0.763
- 0.773
- 0.0
- 0.0
- 0.0
- 0.785
- 0.777
- 0.748
- 0.0
- 0.781
- 0.0
- 0.763
- 0.804
- 0.806
- 0.0
- 0.0
- 0.812
- 0.808
- 0.0
- 0.0
- 0.81
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.81
- 0.823
- 0.0
- 0.0
- 0.0
- 0.829
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.827
- 0.0
- 0.848
- 0.0
- 0.0
- 0.838
- 0.0
- 0.0
- 0.0
- 0.821
- 0.833
- 0.0
- 0.823
- 0.0
- 0.842
- 0.0
- 0.0
- 0.0
- 0.825
- 0.829
- 0.84
- 0.856
- 0.833
- 0.0
- 0.0
- 0.846
- 0.86
- 0.0
- 0.0
- 0.819
- 0.0
- 0.0
train_loss:
- 2.152
- 2.6
- 3.664
- 2.297
- 2.046
- 2.286
- 1.251
- 0.854
- 0.785
- 1.102
- 1.03
- 1.306
- 0.955
- 1.51
- 1.19
- 1.229
- 0.902
- 0.955
- 0.935
- 0.892
- 1.117
- 1.055
- 1.28
- 1.042
- 0.871
- 0.786
- 0.848
- 0.799
- 0.574
- 0.975
- 0.964
- 0.915
- 0.718
- 0.773
- 0.768
- 0.577
- 0.901
- 0.759
- 0.532
- 0.716
- 0.885
- 0.864
- 0.933
- 0.857
- 0.854
- 0.702
- 0.843
- 0.545
- 0.83
- 0.889
- 0.843
- 0.508
- 0.702
- 0.642
- 0.639
- 0.623
- 0.804
- 0.846
- 0.82
- 0.813
- 1.108
- 0.642
- 0.661
- 0.785
- 0.621
- 0.497
- 0.783
- 0.748
- 0.799
- 0.501
- 0.753
- 0.783
- 0.595
- 0.802
- 0.772
- 0.887
- 0.624
- 0.629
- 0.588
- 0.769
- 0.751
- 0.73
- 0.626
- 0.582
- 0.758
- 0.595
- 0.591
- 0.611
- 0.585
- 0.712
- 0.865
- 0.609
- 0.579
- 0.861
- 0.586
- 0.578
- 0.69
- 0.449
- 0.555
- 0.709
unequal: 0
verbose: 1
