avg_train_accuracy: 0.852
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03845744680851064
- 0.06946808510638298
- 0.1523404255319149
- 0.2567553191489362
- 0.35808510638297875
- 0.4098404255319149
- 0.44143617021276593
- 0.45643617021276595
- 0.47547872340425534
- 0.48351063829787233
- 0.5039893617021277
- 0.5091489361702127
- 0.522127659574468
- 0.5204787234042553
- 0.5362765957446809
- 0.5376063829787234
- 0.5490957446808511
- 0.5496808510638298
- 0.5568085106382978
- 0.5621808510638298
- 0.5581914893617022
- 0.5625531914893617
- 0.5684574468085106
- 0.5671808510638298
- 0.5782978723404255
- 0.5795212765957447
- 0.5825
- 0.5901063829787234
- 0.5897340425531915
- 0.2351595744680851
- 0.5949468085106383
- 0.5928191489361702
- 0.5980319148936171
- 0.5993085106382978
- 0.5997872340425532
- 0.6055851063829787
- 0.6064893617021276
- 0.6138297872340426
- 0.6110106382978724
- 0.6149468085106383
- 0.6139893617021277
- 0.6207978723404255
- 0.6197872340425532
- 0.620904255319149
- 0.623563829787234
- 0.6227127659574468
- 0.6268085106382979
- 0.6302659574468085
- 0.6275
- 0.6295744680851064
- 0.6297872340425532
- 0.6260106382978723
- 0.6325
- 0.6354255319148936
- 0.6318085106382979
- 0.6367021276595745
- 0.6354255319148936
- 0.6361170212765958
- 0.6378191489361702
- 0.6383510638297872
- 0.641436170212766
- 0.6417021276595745
- 0.6416489361702128
- 0.6427659574468085
- 0.6419680851063829
- 0.6442021276595745
- 0.6443085106382979
- 0.6437765957446808
- 0.6451063829787234
- 0.6455851063829787
- 0.6468085106382979
- 0.6464893617021277
- 0.6454787234042553
- 0.6476063829787234
- 0.6494148936170213
- 0.6485106382978724
- 0.6508510638297872
- 0.6500531914893617
- 0.6513829787234042
- 0.6518085106382979
- 0.6497340425531914
- 0.6506914893617022
- 0.6525
- 0.651436170212766
- 0.6534574468085106
- 0.6523404255319148
- 0.6512765957446809
- 0.6540425531914894
- 0.649468085106383
- 0.6557446808510639
- 0.6534574468085106
- 0.6554255319148936
- 0.6563829787234042
- 0.6540425531914894
- 0.6540425531914894
- 0.6499468085106384
- 0.6502127659574468
- 0.659468085106383
- 0.6588297872340425
- 0.6582978723404256
test_loss_list:
- 3.783673063913981
- 3.7353486315409343
- 3.569464661280314
- 3.2565645440419515
- 3.029881998697917
- 2.8561873245239258
- 2.741530129114787
- 2.7371969032287597
- 2.633515475591024
- 2.615997683207194
- 2.6429755942026776
- 2.6091401863098143
- 2.6500722535451255
- 2.573536704381307
- 2.6419553407033285
- 2.567976973851522
- 2.721721617380778
- 2.621188751856486
- 2.6078268114725747
- 2.6215546258290607
- 2.5952921772003172
- 2.547269163131714
- 2.4601771020889283
- 2.466831987698873
- 2.437668654123942
- 2.4586946980158486
- 2.422550574938456
- 2.6124175643920897
- 2.4435537735621136
- 3.1057798194885256
- 2.3199227539698284
- 2.2323399209976196
- 2.2221583922704062
- 2.218750066757202
- 2.2199847237269084
- 2.278685024579366
- 2.3019694725672406
- 2.4065014553070068
- 2.3447740681966147
- 2.4717045338948567
- 2.312520950635274
- 2.346869656244914
- 2.3165423838297525
- 2.3732827218373616
- 2.4412994956970215
- 2.345340385437012
- 2.3494237645467124
- 2.308304662704468
- 2.224615805943807
- 2.2035395336151122
- 2.309118150075277
- 2.091201278368632
- 2.3558493836720786
- 2.2763529602686563
- 2.167146201133728
- 2.314482035636902
- 2.1613279898961384
- 2.1231155172983804
- 2.1416907771428426
- 2.1676833041508994
- 2.134989242553711
- 2.228069920539856
- 2.085045445760091
- 2.0856576204299926
- 2.151356134414673
- 2.072705438931783
- 2.263450492223104
- 1.9540991608301799
- 2.1349793434143067
- 2.1650972747802735
- 2.1241312805811563
- 2.148743634223938
- 2.0206313943862915
- 1.9917208528518677
- 2.081451802253723
- 2.127819193204244
- 2.083593209584554
- 2.2442436043421425
- 2.2365136194229125
- 2.088019464810689
- 2.0432046778996784
- 2.0963279581069947
- 1.9992418781916301
- 1.978567705154419
- 2.0696265125274658
- 1.9494410705566407
- 1.92826056321462
- 2.0021509885787965
- 1.8599886035919189
- 2.1371596654256186
- 1.8847345495224
- 1.9612776231765747
- 1.896315050125122
- 1.8938421058654784
- 1.866847874323527
- 1.7729735056559244
- 1.7546591885884604
- 2.0177983538309734
- 1.9751761388778686
- 1.968798559506734
train_accuracy:
- 0.056
- 0.0
- 0.198
- 0.327
- 0.458
- 0.0
- 0.0
- 0.608
- 0.0
- 0.0
- 0.0
- 0.0
- 0.646
- 0.0
- 0.0
- 0.679
- 0.706
- 0.74
- 0.0
- 0.0
- 0.752
- 0.0
- 0.0
- 0.721
- 0.0
- 0.0
- 0.0
- 0.74
- 0.748
- 0.583
- 0.787
- 0.0
- 0.0
- 0.781
- 0.0
- 0.779
- 0.0
- 0.81
- 0.0
- 0.79
- 0.775
- 0.804
- 0.0
- 0.0
- 0.806
- 0.796
- 0.81
- 0.821
- 0.0
- 0.817
- 0.785
- 0.0
- 0.802
- 0.819
- 0.0
- 0.8
- 0.817
- 0.825
- 0.002
- 0.835
- 0.002
- 0.0
- 0.0
- 0.825
- 0.842
- 0.835
- 0.831
- 0.0
- 0.0
- 0.0
- 0.81
- 0.0
- 0.827
- 0.0
- 0.0
- 0.84
- 0.844
- 0.819
- 0.842
- 0.848
- 0.0
- 0.0
- 0.0
- 0.0
- 0.833
- 0.0
- 0.852
- 0.0
- 0.833
- 0.848
- 0.844
- 0.848
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.863
- 0.856
- 0.852
train_loss:
- 1.985
- 2.579
- 2.426
- 1.133
- 1.959
- 1.347
- 1.253
- 1.593
- 1.139
- 1.125
- 1.392
- 1.345
- 1.301
- 0.991
- 1.3
- 0.987
- 1.507
- 1.189
- 1.168
- 1.122
- 1.149
- 0.891
- 0.876
- 0.847
- 0.853
- 0.82
- 0.82
- 1.248
- 0.826
- 0.36
- 1.297
- 0.76
- 0.746
- 0.738
- 0.761
- 0.952
- 0.931
- 1.143
- 0.921
- 1.111
- 0.716
- 0.902
- 0.912
- 0.872
- 1.063
- 0.857
- 0.884
- 0.894
- 0.687
- 0.668
- 0.845
- 0.491
- 1.017
- 0.832
- 0.643
- 0.999
- 0.629
- 0.643
- 0.643
- 0.823
- 0.627
- 0.801
- 0.65
- 0.613
- 0.784
- 0.614
- 0.94
- 0.484
- 0.774
- 0.771
- 0.769
- 0.764
- 0.599
- 0.604
- 0.759
- 0.752
- 0.77
- 0.894
- 0.904
- 0.77
- 0.579
- 0.752
- 0.587
- 0.577
- 0.721
- 0.572
- 0.575
- 0.746
- 0.418
- 0.869
- 0.415
- 0.755
- 0.569
- 0.549
- 0.572
- 0.408
- 0.393
- 0.875
- 0.706
- 0.689
unequal: 0
verbose: 1
