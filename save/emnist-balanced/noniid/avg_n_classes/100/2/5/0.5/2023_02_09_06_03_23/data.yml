avg_train_accuracy: 0.002
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.055212765957446806
- 0.1352659574468085
- 0.23053191489361702
- 0.30909574468085105
- 0.39122340425531915
- 0.4149468085106383
- 0.44138297872340426
- 0.46558510638297873
- 0.4724468085106383
- 0.47914893617021276
- 0.5053723404255319
- 0.5168617021276596
- 0.5083510638297872
- 0.5305319148936171
- 0.5497872340425531
- 0.5502659574468085
- 0.5562765957446808
- 0.5558510638297872
- 0.568404255319149
- 0.5590425531914893
- 0.5729255319148936
- 0.5738297872340425
- 0.5801595744680851
- 0.5865957446808511
- 0.5912234042553192
- 0.5921276595744681
- 0.5990425531914894
- 0.5992021276595745
- 0.6002659574468086
- 0.6037765957446809
- 0.6052127659574468
- 0.6116489361702128
- 0.6140425531914894
- 0.6111702127659574
- 0.6142553191489362
- 0.6172340425531915
- 0.617872340425532
- 0.6192021276595745
- 0.6176595744680851
- 0.6201595744680851
- 0.6197340425531915
- 0.6166489361702128
- 0.6228191489361702
- 0.6235106382978723
- 0.6248936170212765
- 0.625
- 0.6301595744680851
- 0.6265957446808511
- 0.6298936170212766
- 0.6328723404255319
- 0.6321808510638298
- 0.629095744680851
- 0.631436170212766
- 0.6317021276595745
- 0.6329255319148936
- 0.6364893617021277
- 0.6360638297872341
- 0.6347872340425532
- 0.6335106382978724
- 0.6403723404255319
- 0.640531914893617
- 0.6397872340425532
- 0.639468085106383
- 0.6407446808510638
- 0.640904255319149
- 0.6382978723404256
- 0.6399468085106383
- 0.6420744680851064
- 0.6413297872340425
- 0.6406914893617022
- 0.6411702127659574
- 0.6427659574468085
- 0.6461170212765958
- 0.635904255319149
- 0.6435106382978724
- 0.6440425531914894
- 0.6445744680851064
- 0.6473404255319148
- 0.6442553191489362
- 0.6462765957446809
- 0.648563829787234
- 0.6473936170212766
- 0.6471808510638298
- 0.6473936170212766
- 0.647127659574468
- 0.6487765957446808
- 0.6500531914893617
- 0.6492553191489362
- 0.6490425531914894
- 0.6498404255319149
- 0.6524468085106383
- 0.6487765957446808
- 0.6499468085106384
- 0.6523404255319148
- 0.6489893617021276
- 0.6506914893617022
- 0.6518085106382979
- 0.6458510638297872
- 0.6519680851063829
- 0.6520744680851064
test_loss_list:
- 3.784782355626424
- 3.694681749343872
- 3.4383176453908284
- 3.208497021993001
- 3.0436134847005207
- 2.8980668512980143
- 2.791860631306966
- 2.7708136940002444
- 2.6666248861948647
- 2.6186863358815513
- 2.7539382648468016
- 2.7088129774729413
- 2.5536684513092043
- 2.540487518310547
- 2.7900812276204427
- 2.6753774547576903
- 2.6747223631540935
- 2.559131434758504
- 2.665762027104696
- 2.4128450298309327
- 2.507829205195109
- 2.480674149195353
- 2.474611577987671
- 2.503636693954468
- 2.4486036332448324
- 2.4123936398824055
- 2.5204740635553997
- 2.544608640670776
- 2.4356428543726603
- 2.498281234105428
- 2.5519071769714357
- 2.5462663332621256
- 2.6842914231618247
- 2.3669632546106976
- 2.496946179072062
- 2.4089676904678345
- 2.5206702295939127
- 2.555043420791626
- 2.352756191889445
- 2.3331713167826336
- 2.3419044748942057
- 2.2128394158681233
- 2.320063576698303
- 2.2549634091059367
- 2.203998877207438
- 2.2486261781056722
- 2.5384248940149945
- 2.274341932932536
- 2.262562257448832
- 2.23514466603597
- 2.2533539390563964
- 2.2702083158493043
- 2.1890500434239706
- 2.240343427658081
- 2.326892374356588
- 2.0742555046081543
- 2.2032249482472737
- 2.3178165674209597
- 2.1785967842737834
- 2.2794967699050903
- 2.2597709608078005
- 2.4472051000595094
- 2.2827619171142577
- 2.243832804361979
- 2.262340958913167
- 2.045822671254476
- 2.112428585688273
- 2.2421622896194457
- 2.162846399943034
- 2.0531035375595095
- 2.0033461395899455
- 2.006570302645365
- 2.2071039549509686
- 1.9343019151687622
- 2.096488979657491
- 2.197995672225952
- 2.1604362392425536
- 2.20428968111674
- 2.1136843172709145
- 2.139579192797343
- 2.023020790417989
- 2.07372145652771
- 2.0557700554529825
- 2.0924661207199096
- 2.0417889022827147
- 2.118234713872274
- 2.2079836257298786
- 2.171629236539205
- 2.182158834139506
- 2.1581049823760985
- 2.036070402463277
- 2.1463574155171714
- 2.051671182314555
- 2.0753429301579795
- 1.9249615542093912
- 2.1093195470174155
- 2.0904718605677286
- 1.849933125178019
- 2.1744743013381957
- 2.0675881322224936
train_accuracy:
- 0.067
- 0.2
- 0.35
- 0.0
- 0.508
- 0.575
- 0.0
- 0.581
- 0.619
- 0.0
- 0.694
- 0.0
- 0.652
- 0.0
- 0.733
- 0.0
- 0.0
- 0.0
- 0.679
- 0.0
- 0.0
- 0.746
- 0.729
- 0.767
- 0.0
- 0.0
- 0.777
- 0.79
- 0.0
- 0.781
- 0.783
- 0.756
- 0.8
- 0.0
- 0.0
- 0.781
- 0.802
- 0.796
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.829
- 0.81
- 0.0
- 0.0
- 0.817
- 0.0
- 0.819
- 0.0
- 0.827
- 0.0
- 0.829
- 0.0
- 0.8
- 0.0
- 0.835
- 0.823
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.0
- 0.815
- 0.804
- 0.0
- 0.819
- 0.0
- 0.002
- 0.848
- 0.844
- 0.002
- 0.852
- 0.858
- 0.835
- 0.875
- 0.802
- 0.846
- 0.852
- 0.0
- 0.817
- 0.819
- 0.0
- 0.0
- 0.842
- 0.867
- 0.002
- 0.815
- 0.002
train_loss:
- 2.676
- 2.572
- 2.328
- 2.065
- 2.304
- 1.34
- 1.239
- 1.592
- 1.152
- 0.769
- 1.339
- 1.337
- 0.73
- 0.992
- 1.483
- 1.251
- 1.207
- 0.889
- 1.119
- 0.676
- 0.887
- 0.873
- 0.826
- 0.814
- 0.785
- 0.787
- 1.014
- 0.989
- 0.764
- 1.02
- 0.978
- 0.959
- 1.138
- 0.788
- 0.931
- 0.736
- 0.93
- 0.89
- 0.739
- 0.726
- 0.692
- 0.485
- 0.682
- 0.664
- 0.501
- 0.689
- 1.027
- 0.691
- 0.688
- 0.674
- 0.66
- 0.647
- 0.65
- 0.654
- 0.82
- 0.478
- 0.611
- 0.779
- 0.641
- 0.802
- 0.802
- 0.96
- 0.803
- 0.602
- 0.809
- 0.466
- 0.629
- 0.762
- 0.615
- 0.639
- 0.449
- 0.634
- 0.73
- 0.458
- 0.566
- 0.723
- 0.738
- 0.731
- 0.565
- 0.759
- 0.621
- 0.586
- 0.586
- 0.56
- 0.56
- 0.733
- 0.884
- 0.721
- 0.728
- 0.711
- 0.569
- 0.746
- 0.553
- 0.726
- 0.607
- 0.71
- 0.703
- 0.45
- 0.889
- 0.714
unequal: 0
verbose: 1
