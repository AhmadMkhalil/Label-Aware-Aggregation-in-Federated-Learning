avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.042925531914893615
- 0.07478723404255319
- 0.1675
- 0.25601063829787235
- 0.30819148936170215
- 0.3670212765957447
- 0.41122340425531917
- 0.44622340425531914
- 0.4576063829787234
- 0.4854255319148936
- 0.4854255319148936
- 0.5080851063829788
- 0.5163297872340425
- 0.5247340425531914
- 0.5187234042553192
- 0.5363829787234042
- 0.5480851063829787
- 0.5523936170212767
- 0.5556914893617021
- 0.5622340425531915
- 0.5679255319148936
- 0.5757978723404256
- 0.5717021276595745
- 0.5808510638297872
- 0.5801063829787234
- 0.5860106382978724
- 0.5907978723404256
- 0.5959574468085106
- 0.5987234042553191
- 0.5954255319148937
- 0.6032446808510639
- 0.6072872340425531
- 0.6081914893617021
- 0.6038297872340426
- 0.6137765957446808
- 0.6059574468085106
- 0.6175531914893617
- 0.621436170212766
- 0.6160638297872341
- 0.6175531914893617
- 0.6260106382978723
- 0.6276595744680851
- 0.6294148936170213
- 0.6291489361702127
- 0.6289893617021277
- 0.6305851063829787
- 0.6287765957446808
- 0.6365425531914893
- 0.634468085106383
- 0.6367553191489361
- 0.6342553191489362
- 0.6410106382978723
- 0.6385106382978724
- 0.6403191489361703
- 0.6359574468085106
- 0.6393085106382979
- 0.64
- 0.6353191489361703
- 0.6406382978723404
- 0.6457446808510638
- 0.6461702127659574
- 0.6460638297872341
- 0.6477127659574468
- 0.6472340425531915
- 0.6447872340425532
- 0.6400531914893617
- 0.6451063829787234
- 0.6460106382978723
- 0.6471808510638298
- 0.6485106382978724
- 0.6509574468085106
- 0.6489893617021276
- 0.6537765957446808
- 0.6510638297872341
- 0.6528191489361702
- 0.6552659574468085
- 0.6501063829787234
- 0.6499468085106384
- 0.6555851063829787
- 0.6454255319148936
- 0.6532978723404256
- 0.653563829787234
- 0.6571276595744681
- 0.6518085106382979
- 0.6559574468085106
- 0.6535106382978724
- 0.6552127659574468
- 0.6525531914893618
- 0.6566489361702128
- 0.6531382978723405
- 0.6549468085106382
- 0.6586702127659575
- 0.6554787234042553
- 0.6588297872340425
- 0.6596276595744681
- 0.6563829787234042
- 0.6542553191489362
- 0.6595212765957447
- 0.6567553191489361
- 0.6571808510638298
test_loss_list:
- 3.7829025840759276
- 3.7336127789815268
- 3.5677011585235596
- 3.2741981506347657
- 3.0713528378804527
- 2.985434611638387
- 2.91988650004069
- 2.8748768361409507
- 2.769222914377848
- 2.9031568241119383
- 2.7058998839060466
- 2.757701161702474
- 2.7328837235768635
- 2.7285673809051514
- 2.5463646125793455
- 2.693791882197062
- 2.9542481168111165
- 2.818708620071411
- 2.6763129552205402
- 2.712761329015096
- 2.7162247721354165
- 2.844040543238322
- 2.6240640036265055
- 2.533364423116048
- 2.5393668874104818
- 2.48346053759257
- 2.557570428848267
- 2.531988363265991
- 2.5425567309061687
- 2.437334254582723
- 2.38131826877594
- 2.524480142593384
- 2.5208141867319744
- 2.322463363011678
- 2.35444137096405
- 2.351351709365845
- 2.5806871477762856
- 2.6295319112141926
- 2.245926712354024
- 2.3400911394755046
- 2.3815118900934853
- 2.265068168640137
- 2.3773148997624713
- 2.266784756978353
- 2.523416193326314
- 2.248839732805888
- 2.263438407580058
- 2.3765729411443073
- 2.2125347089767455
- 2.2235427141189574
- 2.323905013402303
- 2.1906842295328777
- 2.156548981666565
- 2.305936794281006
- 2.194262849489848
- 2.191575954755147
- 2.296224152247111
- 2.061981752713521
- 2.230508476893107
- 2.094714722633362
- 2.338449419339498
- 2.146200448671977
- 2.1320944960912067
- 2.3832389068603517
- 2.2085930188496907
- 2.0823299884796143
- 2.2165805530548095
- 2.2045064465204876
- 2.0042078844706217
- 2.081203370094299
- 2.0558349068959556
- 2.03510285059611
- 2.1158213408788047
- 2.1492686382929485
- 2.020988311767578
- 2.1001897271474204
- 2.131177242596944
- 1.9983225282033283
- 2.0849970038731893
- 1.9006008418401081
- 1.9553598308563231
- 2.0482225100199383
- 1.9808657884597778
- 1.9717144346237183
- 1.983537343343099
- 2.017589594523112
- 2.0328770891825356
- 1.9042769368489583
- 2.033905030886332
- 1.9132885122299195
- 1.9640018860499064
- 1.986130191485087
- 1.9003004423777263
- 1.9948596858978271
- 2.018914222717285
- 1.869420189857483
- 1.8977753337224323
- 1.9973968919118246
- 1.9722385597229004
- 1.9835417318344115
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.483
- 0.556
- 0.0
- 0.596
- 0.0
- 0.0
- 0.667
- 0.0
- 0.69
- 0.0
- 0.0
- 0.706
- 0.708
- 0.0
- 0.729
- 0.0
- 0.746
- 0.0
- 0.0
- 0.744
- 0.744
- 0.754
- 0.0
- 0.0
- 0.775
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.81
- 0.798
- 0.0
- 0.802
- 0.796
- 0.785
- 0.819
- 0.796
- 0.817
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.823
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.833
- 0.0
- 0.827
- 0.823
- 0.823
- 0.0
- 0.823
- 0.0
- 0.0
- 0.825
- 0.0
- 0.0
- 0.0
- 0.831
- 0.0
- 0.833
- 0.0
- 0.0
- 0.833
- 0.833
- 0.0
- 0.0
- 0.0
- 0.004
- 0.831
- 0.0
- 0.0
- 0.0
- 0.833
- 0.835
- 0.0
- 0.84
- 0.0
- 0.0
- 0.833
- 0.0
- 0.844
- 0.84
- 0.0
- 0.84
- 0.0
- 0.844
- 0.0
train_loss:
- 1.446
- 3.145
- 3.054
- 1.664
- 1.46
- 1.79
- 1.716
- 1.624
- 1.182
- 1.851
- 1.117
- 1.413
- 1.367
- 1.301
- 0.709
- 1.257
- 1.793
- 1.469
- 1.222
- 1.143
- 1.165
- 1.358
- 0.867
- 0.836
- 0.883
- 0.831
- 1.046
- 1.07
- 1.005
- 0.801
- 0.835
- 1.005
- 0.957
- 0.548
- 0.735
- 0.765
- 1.168
- 1.124
- 0.547
- 0.755
- 0.918
- 0.726
- 0.909
- 0.716
- 1.082
- 0.707
- 0.667
- 0.855
- 0.677
- 0.674
- 0.844
- 0.653
- 0.641
- 0.836
- 0.639
- 0.653
- 0.801
- 0.478
- 0.818
- 0.658
- 0.997
- 0.653
- 0.628
- 0.96
- 0.819
- 0.451
- 0.772
- 0.804
- 0.47
- 0.59
- 0.619
- 0.585
- 0.771
- 0.746
- 0.614
- 0.773
- 0.763
- 0.607
- 0.771
- 0.439
- 0.59
- 0.758
- 0.586
- 0.57
- 0.572
- 0.746
- 0.731
- 0.563
- 0.745
- 0.562
- 0.539
- 0.747
- 0.563
- 0.713
- 0.703
- 0.574
- 0.534
- 0.684
- 0.739
- 0.716
unequal: 0
verbose: 1
