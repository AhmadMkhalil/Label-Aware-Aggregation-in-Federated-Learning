avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.025159574468085106
- 0.07468085106382978
- 0.23542553191489363
- 0.31175531914893617
- 0.3901595744680851
- 0.41154255319148936
- 0.44680851063829785
- 0.4598404255319149
- 0.4818085106382979
- 0.49356382978723407
- 0.5077659574468085
- 0.5241489361702127
- 0.5300531914893617
- 0.5390425531914894
- 0.533031914893617
- 0.5534042553191489
- 0.5486170212765957
- 0.5570744680851064
- 0.5684574468085106
- 0.5567553191489362
- 0.5706382978723404
- 0.5792021276595745
- 0.5738829787234042
- 0.5755851063829788
- 0.5759574468085107
- 0.5902659574468085
- 0.5916489361702127
- 0.5871276595744681
- 0.5979255319148936
- 0.6013829787234043
- 0.6005851063829787
- 0.6002659574468086
- 0.6065425531914893
- 0.6029787234042553
- 0.6110106382978724
- 0.6115957446808511
- 0.6112234042553192
- 0.6056382978723405
- 0.6104255319148936
- 0.6197872340425532
- 0.6153723404255319
- 0.6214893617021277
- 0.6243085106382978
- 0.6212234042553192
- 0.6212234042553192
- 0.6218085106382979
- 0.6284042553191489
- 0.628563829787234
- 0.6315425531914893
- 0.6295744680851064
- 0.626436170212766
- 0.6326595744680851
- 0.6306382978723404
- 0.6331382978723404
- 0.6327127659574469
- 0.6313297872340425
- 0.6306382978723404
- 0.6307978723404255
- 0.6373936170212766
- 0.6386170212765957
- 0.6388297872340426
- 0.6386702127659575
- 0.6374468085106383
- 0.6408510638297872
- 0.6412765957446809
- 0.6406382978723404
- 0.6410106382978723
- 0.6418617021276596
- 0.6442553191489362
- 0.6423404255319148
- 0.6403723404255319
- 0.6431382978723404
- 0.6463297872340426
- 0.6484574468085106
- 0.6476595744680851
- 0.6455851063829787
- 0.6488297872340425
- 0.6454787234042553
- 0.6441489361702127
- 0.6488297872340425
- 0.6500531914893617
- 0.6489893617021276
- 0.6502659574468085
- 0.6490425531914894
- 0.6499468085106384
- 0.6483510638297872
- 0.6495212765957447
- 0.6506914893617022
- 0.651436170212766
- 0.6507446808510639
- 0.6510106382978723
- 0.6523936170212766
- 0.6536702127659575
- 0.6542021276595744
- 0.6518085106382979
- 0.6527659574468085
- 0.6519680851063829
- 0.6539893617021276
- 0.6529255319148937
- 0.6557978723404255
test_loss_list:
- 3.7676150544484455
- 3.6624067656199135
- 3.380027411778768
- 3.099369401931763
- 2.9106016222635906
- 2.8014699681599935
- 2.7341628901163735
- 2.651799100240072
- 2.633037265141805
- 2.638631738026937
- 2.5829861640930174
- 2.6471771399180093
- 2.629281005859375
- 2.7739778677622478
- 2.499672705332438
- 2.667965440750122
- 2.535913419723511
- 2.5574736754099527
- 2.7797088050842285
- 2.410222682952881
- 2.5833354949951173
- 2.661737273534139
- 2.4584245618184406
- 2.5043441327412923
- 2.3461710373560587
- 2.6778745651245117
- 2.607398872375488
- 2.4183364073435465
- 2.5680647214253742
- 2.489784154891968
- 2.446964203516642
- 2.5003942012786866
- 2.502786644299825
- 2.390838484764099
- 2.524124722480774
- 2.3670869795481364
- 2.3477260303497314
- 2.2473103348414103
- 2.293047358194987
- 2.459245753288269
- 2.266157283782959
- 2.41913915793101
- 2.4652516412734986
- 2.3029396200180052
- 2.1786309766769407
- 2.2682129621505736
- 2.5052914158503214
- 2.4154198662439983
- 2.2972585328420005
- 2.2963398424784343
- 2.1875899267196655
- 2.373722205162048
- 2.217211298942566
- 2.2905761273701986
- 2.1934020868937174
- 2.15262965520223
- 2.0560933526357017
- 2.070784657796224
- 2.2168040831883746
- 2.1151581160227457
- 2.0928063599268594
- 2.1974703884124756
- 2.1028626585006713
- 2.3964706563949587
- 2.131311492919922
- 2.1845573488871257
- 2.1889036146799725
- 2.121611533164978
- 2.20926718711853
- 2.218999719619751
- 2.098892404238383
- 2.1789218187332153
- 2.363468928337097
- 2.1887313238779704
- 2.245204385121663
- 2.22500199953715
- 2.144558529853821
- 2.197625141143799
- 2.050825565656026
- 2.1974311749140423
- 2.220831955273946
- 2.095399595896403
- 2.1146665891011556
- 2.121904222170512
- 2.151740894317627
- 2.02388508160909
- 1.9690625667572021
- 2.0710949261983234
- 2.0695776605606078
- 2.1070546690622964
- 2.006648476918538
- 1.994363481203715
- 2.1055600039164224
- 2.230021777153015
- 2.004846954345703
- 1.9718156321843465
- 1.95945631980896
- 2.0292045338948568
- 2.071019384066264
- 2.0690306425094604
train_accuracy:
- 0.037
- 0.0
- 0.248
- 0.0
- 0.469
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.646
- 0.0
- 0.681
- 0.0
- 0.0
- 0.0
- 0.0
- 0.717
- 0.0
- 0.719
- 0.742
- 0.0
- 0.715
- 0.0
- 0.0
- 0.756
- 0.0
- 0.767
- 0.75
- 0.765
- 0.737
- 0.792
- 0.0
- 0.781
- 0.769
- 0.777
- 0.0
- 0.787
- 0.802
- 0.0
- 0.783
- 0.779
- 0.0
- 0.0
- 0.0
- 0.796
- 0.812
- 0.0
- 0.785
- 0.0
- 0.812
- 0.806
- 0.821
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.825
- 0.827
- 0.806
- 0.802
- 0.0
- 0.0
- 0.833
- 0.821
- 0.0
- 0.831
- 0.835
- 0.838
- 0.0
- 0.002
- 0.812
- 0.812
- 0.0
- 0.812
- 0.835
- 0.0
- 0.0
- 0.842
- 0.84
- 0.0
- 0.802
- 0.0
- 0.829
- 0.81
- 0.806
- 0.0
- 0.842
- 0.833
- 0.0
- 0.838
- 0.0
- 0.831
- 0.844
- 0.0
train_loss:
- 2.585
- 1.95
- 2.273
- 1.51
- 1.407
- 1.263
- 1.165
- 0.765
- 1.08
- 1.067
- 1.066
- 1.269
- 1.234
- 1.463
- 0.686
- 1.164
- 0.904
- 0.867
- 1.321
- 0.678
- 1.078
- 1.065
- 0.599
- 0.823
- 0.601
- 1.19
- 0.996
- 0.551
- 0.99
- 0.992
- 0.768
- 0.952
- 0.937
- 0.549
- 0.91
- 0.711
- 0.715
- 0.522
- 0.51
- 0.854
- 0.731
- 0.864
- 0.862
- 0.706
- 0.502
- 0.662
- 1.001
- 0.826
- 0.656
- 0.648
- 0.66
- 0.827
- 0.627
- 0.791
- 0.668
- 0.663
- 0.462
- 0.458
- 0.796
- 0.628
- 0.626
- 0.776
- 0.627
- 0.92
- 0.644
- 0.783
- 0.776
- 0.605
- 0.77
- 0.762
- 0.616
- 0.794
- 0.898
- 0.763
- 0.744
- 0.73
- 0.753
- 0.771
- 0.597
- 0.743
- 0.712
- 0.563
- 0.714
- 0.738
- 0.703
- 0.568
- 0.556
- 0.686
- 0.735
- 0.705
- 0.594
- 0.56
- 0.674
- 0.852
- 0.573
- 0.56
- 0.572
- 0.711
- 0.706
- 0.728
unequal: 0
verbose: 1
