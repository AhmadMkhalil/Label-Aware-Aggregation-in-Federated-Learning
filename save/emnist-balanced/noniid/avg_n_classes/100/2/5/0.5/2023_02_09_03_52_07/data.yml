avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03531914893617021
- 0.059042553191489364
- 0.14398936170212767
- 0.27047872340425533
- 0.324468085106383
- 0.3892553191489362
- 0.3963829787234043
- 0.44138297872340426
- 0.45920212765957447
- 0.48414893617021276
- 0.48861702127659573
- 0.5106914893617022
- 0.5169148936170213
- 0.5109574468085106
- 0.5224468085106383
- 0.5351595744680852
- 0.5422872340425532
- 0.5468085106382978
- 0.5542553191489362
- 0.5497340425531915
- 0.5587765957446809
- 0.5623936170212765
- 0.5669148936170213
- 0.5651063829787234
- 0.5708510638297872
- 0.5740425531914893
- 0.578936170212766
- 0.58
- 0.5805851063829788
- 0.585531914893617
- 0.583404255319149
- 0.5919148936170213
- 0.5892553191489361
- 0.5916489361702127
- 0.5942021276595745
- 0.5974468085106382
- 0.6016489361702128
- 0.6063829787234043
- 0.6031382978723404
- 0.6056382978723405
- 0.6103723404255319
- 0.6087765957446809
- 0.6087765957446809
- 0.6127127659574468
- 0.6123936170212766
- 0.6135106382978723
- 0.6148936170212767
- 0.616968085106383
- 0.6162234042553192
- 0.6187765957446808
- 0.615531914893617
- 0.6215957446808511
- 0.6207978723404255
- 0.6237234042553191
- 0.6286170212765958
- 0.6265957446808511
- 0.6231382978723404
- 0.6287765957446808
- 0.6326063829787234
- 0.6327659574468085
- 0.6323936170212766
- 0.6329787234042553
- 0.6315957446808511
- 0.6310106382978723
- 0.6353723404255319
- 0.6358510638297873
- 0.6327659574468085
- 0.6354255319148936
- 0.6403723404255319
- 0.6344148936170213
- 0.6384574468085107
- 0.6370212765957447
- 0.6336170212765957
- 0.6395744680851064
- 0.6323404255319149
- 0.640904255319149
- 0.6381914893617021
- 0.6377659574468085
- 0.6353723404255319
- 0.642127659574468
- 0.6418617021276596
- 0.6422872340425532
- 0.6438297872340426
- 0.645904255319149
- 0.6427127659574469
- 0.6436702127659575
- 0.6462234042553191
- 0.6440957446808511
- 0.6449468085106383
- 0.6452127659574468
- 0.643936170212766
- 0.6468085106382979
- 0.6462234042553191
- 0.646436170212766
- 0.6469148936170213
- 0.6403191489361703
- 0.6449468085106383
- 0.6404787234042553
- 0.6465425531914893
- 0.6448404255319149
test_loss_list:
- 3.7911288293202716
- 3.757015708287557
- 3.6290795962015787
- 3.3090070311228432
- 3.07987416267395
- 2.9825494289398193
- 2.802995220820109
- 2.787686758041382
- 2.7081828435262043
- 2.763195234934489
- 2.6824723529815673
- 2.93602068901062
- 2.651274620691935
- 2.6226013851165773
- 2.5282955519358317
- 2.5938109302520753
- 2.6569580046335854
- 2.801430803934733
- 2.8761792119344074
- 2.5926559448242186
- 2.729585771560669
- 2.6909299087524414
- 2.7124256801605227
- 2.6307871468861896
- 2.54600710550944
- 2.6599617195129395
- 2.6036181449890137
- 2.6150043042500815
- 2.474538402557373
- 2.496005385716756
- 2.4112605539957683
- 2.5576553249359133
- 2.40263987382253
- 2.3799658489227293
- 2.499308409690857
- 2.5441943836212157
- 2.526718600591024
- 2.674150482813517
- 2.463834931055705
- 2.5107844845453897
- 2.5134540096918743
- 2.3997543732325237
- 2.3398261992136637
- 2.4907685279846192
- 2.2784583457310994
- 2.303149291674296
- 2.290673923492432
- 2.4016380008061726
- 2.218179562886556
- 2.381298000017802
- 2.1410523811976114
- 2.307341963450114
- 2.253799508412679
- 2.3202728033065796
- 2.439337582588196
- 2.284223175048828
- 2.11805871963501
- 2.3033237504959105
- 2.336980187098185
- 2.3645369466145834
- 2.2947021118799844
- 2.434200825691223
- 2.3093593454360963
- 2.3267603000005086
- 2.4275521596272784
- 2.3090469662348427
- 2.1619569555918376
- 2.2915582911173504
- 2.302947432200114
- 2.1118634525934854
- 2.2357857751846315
- 2.1322941827774047
- 2.132959090868632
- 2.2039090967178345
- 1.9805979824066162
- 2.1809748601913452
- 2.0838489659627277
- 2.0609855953852336
- 2.0968416277567545
- 2.188133953412374
- 2.069910569190979
- 2.115013068517049
- 2.147759025891622
- 2.140630949338277
- 2.1664465920130414
- 2.0332741753260293
- 2.128024608294169
- 2.106372283299764
- 2.1237166213989256
- 2.15929869333903
- 2.1375275643666587
- 2.159460269610087
- 2.015672343571981
- 2.0408376232783
- 2.05585603872935
- 1.917197324434916
- 1.9635319725672404
- 1.9531335719426473
- 2.0447683397928875
- 1.9883071962992351
train_accuracy:
- 0.05
- 0.09
- 0.0
- 0.0
- 0.435
- 0.533
- 0.0
- 0.0
- 0.0
- 0.0
- 0.615
- 0.658
- 0.0
- 0.0
- 0.0
- 0.675
- 0.0
- 0.0
- 0.7
- 0.0
- 0.0
- 0.731
- 0.737
- 0.0
- 0.0
- 0.0
- 0.0
- 0.752
- 0.76
- 0.0
- 0.0
- 0.0
- 0.758
- 0.771
- 0.0
- 0.796
- 0.777
- 0.75
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.769
- 0.831
- 0.758
- 0.0
- 0.0
- 0.771
- 0.0
- 0.794
- 0.0
- 0.769
- 0.781
- 0.8
- 0.0
- 0.0
- 0.0
- 0.779
- 0.0
- 0.785
- 0.0
- 0.808
- 0.796
- 0.827
- 0.0
- 0.0
- 0.819
- 0.0
- 0.796
- 0.0
- 0.833
- 0.785
- 0.792
- 0.785
- 0.835
- 0.0
- 0.817
- 0.0
- 0.796
- 0.858
- 0.804
- 0.0
- 0.0
- 0.0
- 0.829
- 0.0
- 0.825
- 0.0
- 0.84
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.865
- 0.0
train_loss:
- 2.111
- 2.584
- 3.055
- 1.73
- 1.001
- 1.843
- 0.89
- 1.246
- 0.827
- 1.486
- 1.096
- 2.019
- 1.054
- 0.753
- 0.726
- 0.991
- 1.219
- 1.475
- 1.45
- 0.916
- 1.128
- 1.108
- 1.147
- 0.893
- 0.874
- 1.097
- 1.086
- 1.083
- 0.832
- 0.828
- 0.848
- 0.998
- 0.814
- 0.779
- 0.993
- 0.982
- 0.979
- 1.161
- 0.967
- 0.941
- 0.925
- 0.74
- 0.748
- 0.942
- 0.746
- 0.708
- 0.739
- 0.888
- 0.707
- 0.877
- 0.527
- 0.899
- 0.694
- 0.897
- 1.055
- 0.871
- 0.522
- 0.858
- 0.867
- 0.858
- 0.856
- 1.006
- 0.843
- 0.836
- 1.02
- 0.838
- 0.676
- 0.83
- 0.828
- 0.674
- 0.812
- 0.662
- 0.642
- 0.798
- 0.493
- 0.794
- 0.637
- 0.612
- 0.622
- 0.791
- 0.636
- 0.785
- 0.797
- 0.791
- 0.78
- 0.641
- 0.776
- 0.771
- 0.758
- 0.785
- 0.758
- 0.755
- 0.606
- 0.608
- 0.597
- 0.468
- 0.618
- 0.595
- 0.738
- 0.577
unequal: 0
verbose: 1
