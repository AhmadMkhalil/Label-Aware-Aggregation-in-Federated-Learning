avg_train_accuracy: 0.84
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06845744680851064
- 0.07787234042553191
- 0.17914893617021277
- 0.27574468085106385
- 0.3355851063829787
- 0.38563829787234044
- 0.4200531914893617
- 0.44627659574468087
- 0.47047872340425534
- 0.4828723404255319
- 0.49632978723404253
- 0.4927659574468085
- 0.5006382978723404
- 0.5126063829787234
- 0.11143617021276596
- 0.5156382978723404
- 0.5313829787234042
- 0.5402659574468085
- 0.535372340425532
- 0.5462234042553191
- 0.5477127659574468
- 0.165
- 0.12329787234042554
- 0.5533510638297873
- 0.5672340425531915
- 0.5696808510638298
- 0.5723936170212766
- 0.5772340425531914
- 0.5803723404255319
- 0.5813829787234043
- 0.5872872340425532
- 0.5924468085106382
- 0.32382978723404254
- 0.5930851063829787
- 0.5968617021276595
- 0.3600531914893617
- 0.5997872340425532
- 0.6004787234042553
- 0.6030319148936171
- 0.4007978723404255
- 0.6026595744680852
- 0.6059574468085106
- 0.6028191489361702
- 0.6109042553191489
- 0.33430851063829786
- 0.6082446808510639
- 0.6145744680851064
- 0.35840425531914893
- 0.6171808510638298
- 0.6179787234042553
- 0.6146808510638297
- 0.6224468085106383
- 0.6223936170212766
- 0.6247872340425532
- 0.5031914893617021
- 0.6261702127659574
- 0.6262234042553192
- 0.6286702127659575
- 0.6281382978723404
- 0.6260638297872341
- 0.3997872340425532
- 0.6323404255319149
- 0.6317553191489361
- 0.630531914893617
- 0.6330851063829788
- 0.6339893617021276
- 0.6374468085106383
- 0.635531914893617
- 0.635531914893617
- 0.6360106382978723
- 0.6385106382978724
- 0.6350531914893617
- 0.6405851063829787
- 0.6347340425531914
- 0.638563829787234
- 0.6428723404255319
- 0.6398404255319149
- 0.6435106382978724
- 0.6435106382978724
- 0.6427659574468085
- 0.6441489361702127
- 0.6423404255319148
- 0.6425
- 0.6454787234042553
- 0.6452127659574468
- 0.6484574468085106
- 0.6448936170212766
- 0.6413297872340425
- 0.645531914893617
- 0.6442021276595745
- 0.6482978723404256
- 0.6487234042553192
- 0.649468085106383
- 0.648936170212766
- 0.6503191489361703
- 0.6514893617021277
- 0.6524468085106383
- 0.6517021276595745
- 0.6476063829787234
- 0.6515425531914893
test_loss_list:
- 6.49566296895345
- 3.71512401898702
- 3.5234104569753013
- 3.240989859898885
- 3.0830557537078858
- 3.00022406578064
- 2.970860726038615
- 2.968015613555908
- 3.0390074602762858
- 2.8523908869425454
- 2.95687318166097
- 2.8316594568888345
- 2.832395486831665
- 2.8771839237213133
- 4.092211910883585
- 2.5358792209625243
- 2.657780564626058
- 2.677290439605713
- 2.651652119954427
- 2.6930641333262124
- 2.731952015558879
- 4.02421301205953
- 5.5971609942118326
- 2.358807363510132
- 2.4728807767232257
- 2.494322633743286
- 2.42600266456604
- 2.512650626500448
- 2.5435776774088543
- 2.4858512465159097
- 2.4713236649831134
- 2.554018351236979
- 2.340047852198283
- 2.1861866537729897
- 2.355192928314209
- 2.225223633448283
- 2.126477386156718
- 2.207276357014974
- 2.292036142349243
- 2.1027497259775796
- 2.032639805475871
- 2.1663805135091145
- 2.1509399875005086
- 2.1845611826578777
- 2.3458545716603596
- 1.9239018265406291
- 2.0462391630808514
- 2.1945153951644896
- 1.8519640175501506
- 1.883074968655904
- 1.92742506980896
- 2.041909112930298
- 2.106073196729024
- 2.1404629071553547
- 1.7329062159856161
- 1.8197506539026895
- 1.8095520242055256
- 1.9583112510045368
- 1.9142743380864462
- 1.9790276829401652
- 2.171817790667216
- 1.7463196992874146
- 1.8501698112487792
- 1.8775282875696817
- 2.035580749511719
- 1.9367780303955078
- 1.9244282960891723
- 1.9983595609664917
- 1.9168505223592123
- 1.9547217814127604
- 1.9608156029383341
- 1.9226090240478515
- 1.908755931854248
- 1.9360728947321575
- 1.9220555814107259
- 2.0080954122543333
- 1.9864237292607625
- 2.000619190533956
- 1.9840025186538697
- 1.9494164435068766
- 2.004879724184672
- 1.8952393309275308
- 1.950683143933614
- 1.9952845017115275
- 1.8764326906204223
- 1.9664505290985108
- 1.9142736101150513
- 1.9080490064620972
- 1.883550729751587
- 1.8932792234420777
- 1.8649362198511759
- 1.8213283268610636
- 1.8591412417093913
- 1.8408789777755736
- 1.8841340414683023
- 2.0386038796106973
- 1.9742317247390746
- 1.9947909100850423
- 1.9439734792709351
- 1.9615797996520996
train_accuracy:
- 0.0
- 0.098
- 0.206
- 0.358
- 0.0
- 0.0
- 0.0
- 0.579
- 0.598
- 0.0
- 0.65
- 0.0
- 0.0
- 0.0
- 0.21
- 0.679
- 0.721
- 0.715
- 0.0
- 0.696
- 0.729
- 0.177
- 0.565
- 0.002
- 0.735
- 0.0
- 0.758
- 0.781
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.056
- 0.0
- 0.0
- 0.0
- 0.362
- 0.748
- 0.798
- 0.0
- 0.0
- 0.956
- 0.0
- 0.79
- 0.838
- 0.817
- 0.0
- 0.804
- 0.825
- 0.802
- 0.815
- 0.954
- 0.0
- 0.0
- 0.817
- 0.781
- 0.796
- 0.963
- 0.8
- 0.792
- 0.0
- 0.842
- 0.0
- 0.0
- 0.8
- 0.829
- 0.815
- 0.0
- 0.827
- 0.844
- 0.831
- 0.0
- 0.0
- 0.0
- 0.821
- 0.846
- 0.856
- 0.838
- 0.0
- 0.0
- 0.833
- 0.0
- 0.806
- 0.0
- 0.0
- 0.0
- 0.831
- 0.85
- 0.0
- 0.0
- 0.0
- 0.842
- 0.84
- 0.854
- 0.0
- 0.0
- 0.84
train_loss:
- 0.813
- 2.641
- 3.625
- 2.341
- 2.101
- 1.911
- 1.75
- 1.669
- 2.207
- 1.048
- 1.515
- 0.915
- 1.035
- 0.945
- 0.409
- 0.931
- 1.354
- 1.332
- 0.79
- 0.804
- 0.822
- 0.391
- 0.237
- 0.716
- 1.232
- 1.221
- 0.75
- 1.144
- 1.157
- 0.744
- 0.703
- 1.127
- 0.3
- 1.128
- 1.001
- 0.234
- 1.028
- 1.027
- 0.977
- 0.223
- 1.094
- 1.034
- 0.655
- 0.582
- 0.294
- 0.554
- 0.936
- 0.304
- 0.996
- 0.604
- 0.622
- 0.945
- 0.884
- 0.914
- 0.25
- 0.96
- 0.656
- 0.904
- 0.624
- 0.529
- 0.293
- 0.892
- 0.893
- 0.521
- 1.163
- 0.538
- 0.528
- 0.822
- 0.576
- 0.571
- 0.538
- 0.575
- 0.553
- 0.55
- 0.583
- 0.838
- 0.544
- 0.812
- 0.852
- 0.542
- 0.806
- 0.546
- 0.54
- 0.78
- 0.573
- 0.786
- 0.513
- 0.549
- 0.518
- 0.526
- 0.496
- 0.519
- 0.485
- 0.516
- 0.82
- 1.019
- 0.773
- 0.793
- 0.511
- 0.802
unequal: 0
verbose: 1
