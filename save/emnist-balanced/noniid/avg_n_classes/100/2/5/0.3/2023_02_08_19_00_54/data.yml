avg_train_accuracy: 0.835
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05622340425531915
- 0.08132978723404255
- 0.1798936170212766
- 0.3326063829787234
- 0.39867021276595743
- 0.4176595744680851
- 0.45053191489361705
- 0.4654255319148936
- 0.4800531914893617
- 0.49117021276595746
- 0.5111702127659574
- 0.518563829787234
- 0.5236702127659575
- 0.5304787234042553
- 0.5192021276595745
- 0.534468085106383
- 0.5477659574468086
- 0.550159574468085
- 0.5638829787234042
- 0.16367021276595745
- 0.5609574468085107
- 0.5712765957446808
- 0.394468085106383
- 0.5753723404255319
- 0.5717021276595745
- 0.581968085106383
- 0.5825531914893617
- 0.586968085106383
- 0.5830851063829787
- 0.26111702127659575
- 0.5927659574468085
- 0.29819148936170214
- 0.5906914893617021
- 0.5986170212765958
- 0.6003191489361702
- 0.6027127659574468
- 0.6054255319148936
- 0.6102659574468086
- 0.6097872340425532
- 0.6100531914893617
- 0.6124468085106383
- 0.6132446808510639
- 0.6159574468085106
- 0.621436170212766
- 0.6187234042553191
- 0.6211170212765957
- 0.6207446808510638
- 0.6246808510638298
- 0.6272340425531915
- 0.6245212765957446
- 0.6242021276595745
- 0.6303723404255319
- 0.6230851063829788
- 0.6256382978723404
- 0.6303723404255319
- 0.6274468085106383
- 0.6286702127659575
- 0.6317021276595745
- 0.46430851063829787
- 0.6321808510638298
- 0.635904255319149
- 0.5150531914893617
- 0.6371808510638298
- 0.6352659574468085
- 0.6348404255319149
- 0.4804787234042553
- 0.6363297872340425
- 0.6311170212765957
- 0.6378191489361702
- 0.6386170212765957
- 0.6393617021276595
- 0.4973936170212766
- 0.6385106382978724
- 0.64
- 0.6427127659574469
- 0.6388829787234043
- 0.6459574468085106
- 0.6418085106382979
- 0.6427659574468085
- 0.6456914893617022
- 0.6448936170212766
- 0.6458510638297872
- 0.6445212765957447
- 0.5118085106382979
- 0.6509574468085106
- 0.6427127659574469
- 0.6479255319148937
- 0.6488829787234043
- 0.6498936170212766
- 0.6518085106382979
- 0.5335106382978724
- 0.6464893617021277
- 0.6476595744680851
- 0.6482446808510638
- 0.650904255319149
- 0.6486170212765957
- 0.6511170212765958
- 0.6514893617021277
- 0.6531914893617021
- 0.6476063829787234
test_loss_list:
- 6.127884241739909
- 3.649657726287842
- 3.3583703517913817
- 3.027837206522624
- 2.8457464536031085
- 2.780713653564453
- 2.734147392908732
- 2.6861701265970868
- 2.7353082720438637
- 2.6820244630177816
- 2.702179931004842
- 2.731934092839559
- 2.782111399968465
- 2.853231627146403
- 2.6923311805725096
- 2.6756743431091308
- 2.731593246459961
- 2.658057320912679
- 2.921042175292969
- 3.5217222340901695
- 2.314501361846924
- 2.539649658203125
- 2.3304709752400714
- 2.3558862686157225
- 2.3137296279271444
- 2.4319961229960123
- 2.3350822989145916
- 2.4624821297327677
- 2.381187949180603
- 2.903834931055705
- 2.240845683415731
- 2.868482675552368
- 1.988058271408081
- 2.123985137939453
- 2.22391624768575
- 2.2956680170694987
- 2.199689426422119
- 2.2863851435979208
- 2.213307174046834
- 2.205149073600769
- 2.3536038891474407
- 2.362315068244934
- 2.4065416351954143
- 2.4745504983266193
- 2.351933719317118
- 2.453231264750163
- 2.4534277009963987
- 2.4002717463175456
- 2.5376299540201823
- 2.3992898829778038
- 2.4022652832667033
- 2.4390485207239787
- 2.341374645233154
- 2.3276442448298136
- 2.38401029586792
- 2.3675599082310996
- 2.354197173118591
- 2.2162170298894246
- 1.9841571203867594
- 2.012568496068319
- 2.094244804382324
- 1.7845076322555542
- 1.7490222120285035
- 1.9360995531082152
- 1.9354874674479168
- 1.823510570526123
- 1.6515082613627117
- 1.7809821812311808
- 1.9859024858474732
- 2.0939938116073606
- 1.9849797550837198
- 1.6976775391896566
- 1.7362033859888713
- 1.84168816725413
- 1.9068245760599771
- 1.8897673161824544
- 1.9674805132548014
- 1.9053197081883748
- 1.9164107974370321
- 1.883479339281718
- 1.9757935730616252
- 2.0127661148707072
- 1.9540427096684774
- 1.7919819450378418
- 1.673550133705139
- 1.8405006074905395
- 1.8586957359313965
- 2.0440920130411784
- 1.9274795118967691
- 2.088201683362325
- 1.6134042819341023
- 1.5952844921747844
- 1.8326112016042073
- 1.8835292991002401
- 1.788244547843933
- 1.8055764754613242
- 1.8945574140548707
- 1.9406730365753173
- 1.9296280749638874
- 1.8649260838826498
train_accuracy:
- 0.802
- 0.0
- 0.0
- 0.415
- 0.523
- 0.0
- 0.0
- 0.619
- 0.588
- 0.652
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.713
- 0.0
- 0.731
- 0.719
- 0.727
- 0.737
- 0.815
- 0.0
- 0.733
- 0.0
- 0.0
- 0.75
- 0.748
- 0.465
- 0.758
- 0.715
- 0.0
- 0.767
- 0.0
- 0.773
- 0.0
- 0.79
- 0.0
- 0.781
- 0.794
- 0.785
- 0.808
- 0.785
- 0.794
- 0.779
- 0.0
- 0.0
- 0.792
- 0.0
- 0.781
- 0.817
- 0.0
- 0.785
- 0.802
- 0.0
- 0.825
- 0.827
- 0.923
- 0.815
- 0.823
- 0.942
- 0.821
- 0.819
- 0.819
- 0.892
- 0.831
- 0.0
- 0.81
- 0.823
- 0.002
- 0.677
- 0.0
- 0.819
- 0.838
- 0.0
- 0.0
- 0.0
- 0.0
- 0.838
- 0.823
- 0.0
- 0.0
- 0.942
- 0.0
- 0.802
- 0.829
- 0.84
- 0.0
- 0.84
- 0.838
- 0.023
- 0.802
- 0.81
- 0.842
- 0.0
- 0.846
- 0.0
- 0.0
- 0.835
train_loss:
- 0.686
- 1.484
- 2.505
- 1.275
- 2.048
- 1.131
- 1.05
- 0.996
- 0.986
- 1.006
- 1.493
- 1.433
- 1.399
- 1.338
- 0.906
- 0.842
- 1.295
- 0.853
- 1.654
- 0.452
- 0.741
- 1.173
- 0.361
- 1.16
- 0.749
- 1.118
- 0.745
- 1.058
- 0.743
- 0.335
- 1.602
- 0.286
- 0.587
- 1.001
- 1.02
- 0.985
- 0.658
- 1.042
- 0.625
- 0.639
- 1.008
- 0.973
- 0.975
- 1.29
- 0.662
- 0.942
- 0.921
- 0.938
- 1.235
- 0.645
- 0.927
- 0.917
- 0.631
- 0.62
- 0.894
- 0.594
- 0.601
- 0.612
- 0.287
- 0.877
- 0.91
- 0.257
- 0.893
- 0.822
- 0.522
- 0.25
- 0.529
- 0.508
- 1.141
- 1.117
- 0.571
- 0.275
- 0.837
- 0.851
- 0.835
- 0.537
- 0.822
- 0.533
- 0.539
- 0.509
- 0.779
- 0.81
- 0.491
- 0.234
- 0.439
- 0.513
- 0.824
- 1.041
- 0.796
- 1.053
- 0.294
- 0.491
- 1.04
- 0.758
- 0.504
- 0.527
- 0.754
- 0.745
- 0.738
- 0.529
unequal: 0
verbose: 1
