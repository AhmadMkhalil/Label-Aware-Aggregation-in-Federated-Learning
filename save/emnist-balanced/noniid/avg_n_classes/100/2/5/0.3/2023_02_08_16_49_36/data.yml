avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027127659574468086
- 0.07691489361702128
- 0.20664893617021277
- 0.33143617021276595
- 0.37622340425531914
- 0.43319148936170215
- 0.44351063829787235
- 0.4457978723404255
- 0.47867021276595745
- 0.4792021276595745
- 0.49872340425531914
- 0.5082446808510638
- 0.5253191489361703
- 0.5271808510638298
- 0.13882978723404255
- 0.5254787234042553
- 0.23170212765957446
- 0.5370212765957447
- 0.541063829787234
- 0.5485106382978724
- 0.14117021276595745
- 0.5450531914893617
- 0.5462234042553191
- 0.5484574468085106
- 0.5523404255319149
- 0.5617553191489362
- 0.5638297872340425
- 0.5738829787234042
- 0.5775531914893617
- 0.5809574468085107
- 0.5819148936170213
- 0.58
- 0.5879787234042553
- 0.5906382978723405
- 0.5897340425531915
- 0.5909042553191489
- 0.5930319148936171
- 0.5908510638297872
- 0.1749468085106383
- 0.595531914893617
- 0.6021276595744681
- 0.5984574468085107
- 0.6061702127659574
- 0.6095212765957447
- 0.6080319148936171
- 0.6091489361702128
- 0.6124468085106383
- 0.6139361702127659
- 0.6094148936170213
- 0.6151063829787234
- 0.6152659574468086
- 0.6156914893617021
- 0.6170744680851064
- 0.6158510638297873
- 0.6145212765957446
- 0.6193085106382978
- 0.620904255319149
- 0.6250531914893617
- 0.6326063829787234
- 0.6271808510638298
- 0.6310106382978723
- 0.6318085106382979
- 0.6263829787234042
- 0.6329255319148936
- 0.6331914893617021
- 0.6384574468085107
- 0.3027127659574468
- 0.6351595744680851
- 0.6381382978723404
- 0.6320744680851064
- 0.3561170212765957
- 0.636968085106383
- 0.640531914893617
- 0.6347872340425532
- 0.6372872340425532
- 0.6382978723404256
- 0.6419148936170213
- 0.6407978723404255
- 0.640531914893617
- 0.6417021276595745
- 0.6437234042553192
- 0.6456382978723404
- 0.6447340425531914
- 0.6437765957446808
- 0.6448936170212766
- 0.6446808510638298
- 0.4767021276595745
- 0.645904255319149
- 0.6451063829787234
- 0.646436170212766
- 0.6476063829787234
- 0.6454787234042553
- 0.6476063829787234
- 0.6432446808510638
- 0.6476063829787234
- 0.6502659574468085
- 0.6477659574468085
- 0.4997340425531915
- 0.6460106382978723
- 0.653031914893617
test_loss_list:
- 3.7719029649098714
- 3.681485112508138
- 3.4382327524820964
- 3.1911731974283852
- 3.004044443766276
- 3.0098188972473143
- 2.95237387975057
- 2.9423647499084473
- 2.925194253921509
- 2.859902400970459
- 2.77013910929362
- 2.9027459398905435
- 2.861619024276733
- 2.8141434542338053
- 3.558688933054606
- 2.4640023803710935
- 2.858510373433431
- 2.4127007134755454
- 2.564202782313029
- 2.4682136376698813
- 3.423242638905843
- 2.2668033345540364
- 2.4012153212229412
- 2.5115584977467855
- 2.4965116024017333
- 2.525391902923584
- 2.408329833348592
- 2.5491301759084064
- 2.4379987049102785
- 2.5293503983815513
- 2.573261270523071
- 2.525124839146932
- 2.446575164794922
- 2.5461079406738283
- 2.472967077891032
- 2.4929509735107422
- 2.447239287694295
- 2.4141874329249062
- 3.718598794937134
- 2.03433696269989
- 2.2604552539189657
- 2.196538530985514
- 2.3185469500223794
- 2.3577036174138386
- 2.294987826347351
- 2.387507519721985
- 2.411590266227722
- 2.454096097946167
- 2.3456129026412964
- 2.2875841522216795
- 2.3061778704325357
- 2.3035593620936075
- 2.3165034008026124
- 2.2029446681340534
- 2.1475026845932006
- 2.2774992497762043
- 2.1948742151260374
- 2.448460499445597
- 2.4616440836588542
- 2.400424599647522
- 2.5076939392089845
- 2.3441787433624266
- 2.2742467562357587
- 2.415416890780131
- 2.4375693639119467
- 2.4891493701934815
- 2.442043835322062
- 2.026005392074585
- 2.132005165417989
- 2.074454874992371
- 2.5387716913223266
- 1.8581058152516683
- 1.9959096590677896
- 1.9641608095169067
- 2.087281238238017
- 2.1209511613845824
- 2.1088639640808107
- 2.175761154492696
- 2.1195249557495117
- 2.170343532562256
- 2.2043190145492555
- 2.170306921005249
- 2.207513248125712
- 2.2062100982666015
- 2.2316839679082237
- 2.093738169670105
- 1.984265201886495
- 1.9589962148666382
- 1.9956510337193807
- 1.924410212834676
- 1.906689829826355
- 1.9559839614232382
- 2.0020474990208945
- 1.974762150446574
- 1.9150305398305256
- 2.0705953518549602
- 2.119545504252116
- 1.8602206977208455
- 1.7533019018173217
- 1.887686293919881
train_accuracy:
- 0.033
- 0.1
- 0.271
- 0.392
- 0.485
- 0.567
- 0.0
- 0.0
- 0.606
- 0.0
- 0.0
- 0.0
- 0.69
- 0.0
- 0.758
- 0.0
- 0.246
- 0.696
- 0.0
- 0.0
- 0.523
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.775
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.729
- 0.996
- 0.0
- 0.0
- 0.794
- 0.785
- 0.781
- 0.0
- 0.0
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.783
- 0.0
- 0.0
- 0.773
- 0.0
- 0.796
- 0.804
- 0.815
- 0.0
- 0.81
- 0.802
- 0.79
- 0.827
- 0.0
- 0.815
- 0.9
- 0.8
- 0.815
- 0.8
- 0.752
- 0.0
- 0.819
- 0.0
- 0.0
- 0.815
- 0.829
- 0.819
- 0.817
- 0.85
- 0.825
- 0.0
- 0.823
- 0.833
- 0.846
- 0.821
- 0.467
- 0.829
- 0.0
- 0.833
- 0.0
- 0.838
- 0.844
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
train_loss:
- 2.767
- 2.745
- 2.534
- 2.256
- 1.299
- 2.538
- 1.118
- 1.151
- 1.606
- 1.016
- 1.012
- 1.388
- 1.399
- 1.037
- 0.482
- 0.936
- 0.34
- 1.43
- 0.762
- 0.966
- 0.381
- 0.706
- 0.807
- 0.775
- 0.774
- 0.682
- 0.695
- 1.183
- 0.82
- 1.087
- 1.062
- 0.675
- 0.771
- 1.027
- 0.696
- 0.741
- 0.665
- 0.627
- 0.422
- 0.67
- 1.009
- 0.636
- 0.967
- 0.989
- 0.69
- 0.954
- 0.979
- 0.909
- 0.63
- 0.62
- 0.611
- 0.603
- 0.573
- 0.65
- 0.596
- 0.625
- 0.626
- 1.175
- 1.223
- 0.899
- 1.186
- 0.942
- 0.59
- 0.912
- 0.88
- 1.181
- 0.398
- 0.939
- 0.837
- 0.551
- 0.283
- 0.88
- 0.878
- 0.566
- 0.826
- 0.805
- 0.882
- 0.814
- 0.822
- 0.845
- 0.821
- 0.814
- 0.82
- 0.795
- 0.825
- 0.529
- 0.287
- 1.147
- 0.792
- 0.501
- 0.539
- 0.532
- 0.835
- 0.576
- 0.558
- 0.8
- 0.782
- 0.255
- 0.442
- 0.801
unequal: 0
verbose: 1
