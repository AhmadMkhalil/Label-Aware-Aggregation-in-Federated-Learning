avg_train_accuracy: 0.004
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037393617021276596
- 0.04952127659574468
- 0.09037234042553191
- 0.22361702127659575
- 0.32728723404255317
- 0.3751063829787234
- 0.4263297872340426
- 0.4478191489361702
- 0.4777127659574468
- 0.49234042553191487
- 0.5063297872340425
- 0.17712765957446808
- 0.5143085106382979
- 0.5246276595744681
- 0.5207446808510638
- 0.54
- 0.5346808510638298
- 0.5472340425531915
- 0.5475
- 0.5512234042553191
- 0.5609042553191489
- 0.5586702127659574
- 0.5670212765957446
- 0.5717021276595745
- 0.21861702127659574
- 0.5751063829787234
- 0.576968085106383
- 0.5826063829787234
- 0.5781914893617022
- 0.5852127659574468
- 0.5952659574468085
- 0.594095744680851
- 0.5959574468085106
- 0.5957446808510638
- 0.600531914893617
- 0.5990425531914894
- 0.6055851063829787
- 0.6063829787234043
- 0.6081382978723404
- 0.6097340425531915
- 0.6075531914893617
- 0.6106914893617021
- 0.618563829787234
- 0.6197340425531915
- 0.1322872340425532
- 0.6166489361702128
- 0.6210106382978723
- 0.6218617021276596
- 0.6194148936170213
- 0.6233510638297872
- 0.619468085106383
- 0.6216489361702128
- 0.6252127659574468
- 0.6278723404255319
- 0.6253723404255319
- 0.6315957446808511
- 0.628563829787234
- 0.6323936170212766
- 0.6354255319148936
- 0.6328723404255319
- 0.6292021276595745
- 0.6299468085106383
- 0.6377659574468085
- 0.631968085106383
- 0.6339893617021276
- 0.6333510638297872
- 0.6365957446808511
- 0.6380851063829788
- 0.6387234042553191
- 0.6384574468085107
- 0.6394148936170213
- 0.64
- 0.6389893617021276
- 0.6430851063829788
- 0.6393617021276595
- 0.6445744680851064
- 0.5440425531914893
- 0.6448404255319149
- 0.6447872340425532
- 0.645531914893617
- 0.6432978723404256
- 0.6444148936170213
- 0.6462765957446809
- 0.6453191489361703
- 0.6489893617021276
- 0.6466489361702128
- 0.6462765957446809
- 0.6487234042553192
- 0.6457446808510638
- 0.6500531914893617
- 0.6477127659574468
- 0.6507446808510639
- 0.6495212765957447
- 0.6501595744680851
- 0.6507978723404255
- 0.6510106382978723
- 0.6522340425531915
- 0.6478723404255319
- 0.47202127659574467
- 0.6487234042553192
test_loss_list:
- 3.794663492838542
- 3.782612886428833
- 3.7328867212931316
- 3.49871337890625
- 3.168550885518392
- 2.9673870754241944
- 2.8646075280507404
- 2.8812794081370035
- 2.8320586109161376
- 2.8105984210968016
- 2.851694253285726
- 3.5038002077738444
- 2.6352718671162925
- 2.734428803126017
- 2.6655684661865235
- 2.8456647109985354
- 2.728147128423055
- 2.7523312981923422
- 2.7112301127115885
- 2.693642686208089
- 2.892669048309326
- 2.7615556430816652
- 2.7105489571889243
- 2.8655492051442466
- 3.1701712608337402
- 2.3908839082717894
- 2.5853215503692626
- 2.590115763346354
- 2.552506351470947
- 2.5323363176981606
- 2.7543361155192057
- 2.7307061322530113
- 2.754262367884318
- 2.6502789306640624
- 2.668116677602132
- 2.594628267288208
- 2.650152489344279
- 2.684768854777018
- 2.6705029328664143
- 2.760602051417033
- 2.636164077123006
- 2.6559178320566814
- 2.8258832931518554
- 2.911996138890584
- 4.239554554621378
- 2.3017807006835938
- 2.4233486970265705
- 2.525476379394531
- 2.5595027732849123
- 2.550863593419393
- 2.3553857024510703
- 2.482137959798177
- 2.55267497698466
- 2.523994992574056
- 2.4415536085764566
- 2.522441711425781
- 2.4567418416341145
- 2.5176160748799643
- 2.6595576254526776
- 2.571930707295736
- 2.5286890188852946
- 2.484833132425944
- 2.50971826394399
- 2.442531975110372
- 2.5029974047342938
- 2.3727890634536744
- 2.4484024715423582
- 2.489875456492106
- 2.532201452255249
- 2.473789437611898
- 2.3907092952728273
- 2.3376099967956545
- 2.3055381774902344
- 2.3984012174606324
- 2.3587499888737997
- 2.5594963232676187
- 1.6958517583211263
- 2.1735160128275552
- 2.1501920302708943
- 2.206789412498474
- 2.13736519018809
- 2.2440538024902343
- 2.2634785747528077
- 2.1939324458440144
- 2.2623475344975787
- 2.2952528778711954
- 2.2169826459884643
- 2.319256978034973
- 2.2757538334528604
- 2.408660976092021
- 2.3355256764094037
- 2.3380754788716636
- 2.3397795470555622
- 2.284025829633077
- 2.381016376813253
- 2.3564175097147624
- 2.343299026489258
- 2.25565362294515
- 1.8021544059117636
- 1.840896725654602
train_accuracy:
- 0.04
- 0.06
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.583
- 0.633
- 0.638
- 0.656
- 0.0
- 0.683
- 0.662
- 0.0
- 0.708
- 0.0
- 0.0
- 0.0
- 0.713
- 0.0
- 0.0
- 0.0
- 0.754
- 0.325
- 0.0
- 0.754
- 0.756
- 0.708
- 0.773
- 0.775
- 0.781
- 0.783
- 0.0
- 0.0
- 0.785
- 0.781
- 0.75
- 0.79
- 0.8
- 0.0
- 0.0
- 0.804
- 0.81
- 0.198
- 0.808
- 0.0
- 0.0
- 0.827
- 0.808
- 0.0
- 0.773
- 0.798
- 0.819
- 0.779
- 0.815
- 0.0
- 0.773
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.817
- 0.79
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.8
- 0.0
- 0.0
- 0.838
- 0.848
- 0.842
- 0.117
- 0.846
- 0.0
- 0.846
- 0.0
- 0.835
- 0.852
- 0.0
- 0.0
- 0.821
- 0.0
- 0.833
- 0.821
- 0.848
- 0.831
- 0.844
- 0.812
- 0.0
- 0.0
- 0.831
- 0.846
- 0.0
- 0.894
- 0.004
train_loss:
- 2.899
- 3.783
- 1.803
- 1.637
- 1.356
- 1.24
- 1.173
- 1.079
- 1.648
- 1.569
- 1.491
- 0.469
- 1.61
- 1.353
- 0.839
- 1.797
- 0.854
- 1.296
- 0.786
- 0.785
- 1.239
- 0.909
- 0.784
- 1.142
- 0.445
- 1.192
- 1.113
- 1.246
- 0.733
- 0.811
- 1.461
- 1.06
- 1.069
- 0.706
- 0.673
- 0.702
- 1.159
- 1.02
- 1.104
- 0.987
- 0.748
- 0.675
- 1.313
- 1.268
- 0.466
- 1.053
- 0.981
- 0.952
- 0.924
- 0.9
- 0.686
- 0.593
- 0.89
- 0.923
- 0.633
- 0.901
- 0.641
- 0.864
- 1.15
- 0.888
- 0.6
- 0.62
- 0.909
- 0.634
- 0.567
- 0.613
- 0.879
- 0.889
- 0.831
- 0.552
- 0.545
- 0.611
- 0.603
- 0.846
- 0.611
- 1.08
- 0.329
- 1.196
- 0.882
- 0.824
- 0.584
- 0.788
- 0.816
- 0.548
- 0.848
- 0.799
- 0.54
- 0.832
- 0.558
- 1.045
- 0.787
- 0.822
- 0.779
- 0.564
- 0.767
- 0.769
- 0.787
- 0.535
- 0.286
- 0.479
unequal: 0
verbose: 1
