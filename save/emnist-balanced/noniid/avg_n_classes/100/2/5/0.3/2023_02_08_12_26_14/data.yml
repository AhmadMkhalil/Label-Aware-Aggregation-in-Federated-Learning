avg_train_accuracy: 0.958
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.050691489361702126
- 0.08542553191489362
- 0.20914893617021277
- 0.32090425531914896
- 0.3549468085106383
- 0.4035106382978723
- 0.4511702127659574
- 0.4701063829787234
- 0.4751595744680851
- 0.4883510638297872
- 0.5070212765957447
- 0.5135106382978724
- 0.5240425531914894
- 0.5245212765957447
- 0.5394148936170213
- 0.5456382978723404
- 0.5488297872340425
- 0.5527127659574468
- 0.5540425531914893
- 0.13920212765957446
- 0.5642553191489361
- 0.5640957446808511
- 0.5757978723404256
- 0.5686702127659574
- 0.2374468085106383
- 0.5828723404255319
- 0.5822872340425532
- 0.5889893617021277
- 0.5909574468085106
- 0.5941489361702128
- 0.5968617021276595
- 0.5987765957446809
- 0.6026063829787234
- 0.6082446808510639
- 0.4167021276595745
- 0.6059574468085106
- 0.6077127659574468
- 0.6077659574468085
- 0.6078191489361702
- 0.6128191489361702
- 0.4097872340425532
- 0.6131914893617021
- 0.6090425531914894
- 0.27180851063829786
- 0.6150531914893617
- 0.6162765957446809
- 0.6152127659574468
- 0.6160638297872341
- 0.6215957446808511
- 0.6179787234042553
- 0.6241489361702127
- 0.6223936170212766
- 0.6252127659574468
- 0.35845744680851066
- 0.6283510638297872
- 0.6304787234042554
- 0.6236170212765958
- 0.6301063829787235
- 0.6273936170212766
- 0.6298404255319149
- 0.632127659574468
- 0.6263829787234042
- 0.635904255319149
- 0.633563829787234
- 0.38170212765957445
- 0.6356914893617022
- 0.6381382978723404
- 0.6374468085106383
- 0.6384574468085107
- 0.6389893617021276
- 0.6397872340425532
- 0.6380851063829788
- 0.6353723404255319
- 0.6409574468085106
- 0.6440957446808511
- 0.6403191489361703
- 0.6395212765957446
- 0.6472872340425532
- 0.6452127659574468
- 0.6431914893617021
- 0.6417021276595745
- 0.6478191489361702
- 0.645531914893617
- 0.6410638297872341
- 0.648031914893617
- 0.643563829787234
- 0.6501595744680851
- 0.6481382978723405
- 0.6484042553191489
- 0.6503723404255319
- 0.6477659574468085
- 0.6505851063829787
- 0.646595744680851
- 0.6511702127659574
- 0.6494148936170213
- 0.6519680851063829
- 0.6522340425531915
- 0.6493085106382979
- 0.6519680851063829
- 0.5085106382978724
test_loss_list:
- 6.4610112762451175
- 3.698450288772583
- 3.470146360397339
- 3.168431526819865
- 2.9635080401102702
- 2.8650010140736897
- 2.842837559382121
- 2.818500229517619
- 2.785704835255941
- 2.7721621799468994
- 2.7747034200032554
- 2.8222707303365073
- 2.8250813070933023
- 2.7420962270100913
- 2.863555711110433
- 2.7965262571970624
- 2.8763719272613524
- 2.7487633419036865
- 2.7085421752929686
- 3.680316635767619
- 2.4649692376454673
- 2.529082562128703
- 2.6021595064798992
- 2.612801151275635
- 3.057904806137085
- 2.3116556946436564
- 2.3181685479482015
- 2.4443705908457436
- 2.433974962234497
- 2.495434169769287
- 2.5331122398376467
- 2.5022823731104533
- 2.5071064456303915
- 2.6636197757720947
- 2.246326894760132
- 2.184426636695862
- 2.3215891234079997
- 2.346959431966146
- 2.323167599042257
- 2.357885616620382
- 2.145187726020813
- 2.11121302763621
- 2.093590195973714
- 2.6561047299702962
- 1.8707539304097494
- 1.9516191498438518
- 2.0719067684809365
- 2.001426216761271
- 2.109512969652812
- 2.120437812805176
- 2.1028317467371624
- 2.1429101848602294
- 2.1385641431808473
- 2.3285602060953776
- 1.8570735422770182
- 2.058019706408183
- 2.0120581833521527
- 2.2013373136520387
- 2.0902747678756715
- 2.1384050861994424
- 2.2066867049535115
- 2.044986968040466
- 2.1832123772303262
- 2.1152381038665773
- 2.201703208287557
- 1.9682728306452433
- 1.996030577023824
- 1.9965876817703248
- 2.0732404661178587
- 2.0567555475234984
- 2.195673875808716
- 2.093253788948059
- 2.064553839365641
- 2.113542211850484
- 2.228762912750244
- 2.1391749382019043
- 2.1078952741622925
- 2.2476250886917115
- 2.3011972284317017
- 2.225784508387248
- 2.1639650662740073
- 2.205923811594645
- 2.2312620147069295
- 2.148044474919637
- 2.175126045544942
- 2.1341837151845295
- 2.238232135772705
- 2.1875449291865032
- 2.1654742399851483
- 2.2057990423838296
- 2.192096552848816
- 2.219548711776733
- 2.1082639519373574
- 2.1847478771209716
- 2.1925154892603556
- 2.1072449350357054
- 2.099182833035787
- 1.9929958534240724
- 1.9904886706670126
- 1.9296164480845133
train_accuracy:
- 0.558
- 0.104
- 0.275
- 0.398
- 0.0
- 0.0
- 0.0
- 0.625
- 0.0
- 0.0
- 0.0
- 0.623
- 0.0
- 0.0
- 0.0
- 0.729
- 0.685
- 0.0
- 0.0
- 0.123
- 0.0
- 0.0
- 0.0
- 0.744
- 0.137
- 0.0
- 0.717
- 0.729
- 0.735
- 0.767
- 0.0
- 0.74
- 0.0
- 0.785
- 0.773
- 0.748
- 0.785
- 0.794
- 0.0
- 0.771
- 0.717
- 0.763
- 0.0
- 0.735
- 0.0
- 0.0
- 0.0
- 0.0
- 0.781
- 0.0
- 0.0
- 0.815
- 0.0
- 0.802
- 0.8
- 0.794
- 0.0
- 0.817
- 0.792
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.771
- 0.796
- 0.825
- 0.0
- 0.0
- 0.0
- 0.785
- 0.0
- 0.0
- 0.0
- 0.819
- 0.0
- 0.798
- 0.829
- 0.81
- 0.815
- 0.0
- 0.835
- 0.0
- 0.858
- 0.0
- 0.838
- 0.829
- 0.0
- 0.0
- 0.794
- 0.842
- 0.798
- 0.0
- 0.808
- 0.838
- 0.798
- 0.0
- 0.823
- 0.0
- 0.958
train_loss:
- 0.763
- 2.731
- 1.525
- 3.246
- 1.24
- 1.11
- 1.846
- 1.722
- 1.013
- 0.983
- 1.511
- 1.441
- 1.414
- 0.893
- 1.321
- 1.345
- 1.322
- 0.842
- 0.831
- 0.46
- 1.345
- 0.773
- 1.18
- 0.788
- 0.339
- 1.29
- 0.758
- 1.092
- 1.145
- 1.069
- 1.124
- 1.104
- 1.072
- 1.401
- 0.376
- 1.108
- 1.025
- 0.993
- 0.632
- 1.027
- 0.324
- 1.006
- 0.654
- 0.287
- 0.613
- 0.632
- 0.584
- 0.614
- 0.964
- 0.621
- 0.619
- 0.581
- 0.951
- 0.269
- 0.587
- 1.251
- 0.596
- 1.201
- 0.565
- 0.886
- 0.874
- 0.609
- 0.878
- 0.599
- 0.304
- 1.28
- 0.869
- 0.566
- 0.858
- 0.849
- 1.139
- 0.578
- 0.574
- 0.851
- 1.107
- 0.578
- 0.559
- 1.103
- 1.096
- 0.829
- 0.572
- 0.824
- 0.83
- 0.546
- 0.845
- 0.541
- 1.102
- 0.819
- 0.589
- 0.807
- 0.804
- 0.803
- 0.545
- 0.803
- 0.788
- 0.575
- 0.555
- 0.541
- 0.522
- 0.287
unequal: 0
verbose: 1
