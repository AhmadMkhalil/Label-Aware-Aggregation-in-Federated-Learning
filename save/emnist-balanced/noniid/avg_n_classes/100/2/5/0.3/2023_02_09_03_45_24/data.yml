avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022925531914893618
- 0.06345744680851063
- 0.06398936170212766
- 0.220531914893617
- 0.3357978723404255
- 0.38968085106382977
- 0.44132978723404254
- 0.45478723404255317
- 0.4827659574468085
- 0.4909574468085106
- 0.5012234042553192
- 0.5101595744680851
- 0.5128191489361702
- 0.534468085106383
- 0.5406382978723404
- 0.548031914893617
- 0.5497340425531915
- 0.5537234042553192
- 0.5647872340425532
- 0.5581914893617022
- 0.5715425531914894
- 0.5677659574468085
- 0.5773404255319149
- 0.5773936170212766
- 0.2666489361702128
- 0.5857978723404256
- 0.5837234042553191
- 0.5939893617021277
- 0.5912765957446808
- 0.5997340425531915
- 0.44351063829787235
- 0.6009574468085106
- 0.6037234042553191
- 0.605531914893617
- 0.6016489361702128
- 0.6057446808510638
- 0.6050531914893617
- 0.610531914893617
- 0.6143085106382978
- 0.6143617021276596
- 0.6135106382978723
- 0.6155851063829787
- 0.6229255319148936
- 0.6258510638297873
- 0.6272340425531915
- 0.6236170212765958
- 0.629095744680851
- 0.6284042553191489
- 0.6306382978723404
- 0.46170212765957447
- 0.6348404255319149
- 0.6274468085106383
- 0.6285106382978723
- 0.6323936170212766
- 0.6302659574468085
- 0.6340957446808511
- 0.6348936170212766
- 0.6377127659574469
- 0.6372340425531915
- 0.2903191489361702
- 0.6463297872340426
- 0.6364893617021277
- 0.6358510638297873
- 0.39191489361702125
- 0.2759042553191489
- 0.6506914893617022
- 0.6436702127659575
- 0.6373936170212766
- 0.6412234042553191
- 0.5142553191489362
- 0.6473936170212766
- 0.6443085106382979
- 0.642127659574468
- 0.6440425531914894
- 0.5118617021276596
- 0.648936170212766
- 0.6519148936170213
- 0.6522872340425532
- 0.6476595744680851
- 0.6493085106382979
- 0.651436170212766
- 0.5861170212765957
- 0.647127659574468
- 0.6492553191489362
- 0.645904255319149
- 0.6467021276595745
- 0.6476595744680851
- 0.6475
- 0.6469148936170213
- 0.6494148936170213
- 0.6509574468085106
- 0.6507446808510639
- 0.6494148936170213
- 0.6483510638297872
- 0.6529787234042553
- 0.6510106382978723
- 0.6507978723404255
- 0.5529787234042554
- 0.6534042553191489
- 0.6522872340425532
test_loss_list:
- 3.7934650707244875
- 3.736637280782064
- 6.474756590525309
- 3.3818081760406495
- 3.092838141123454
- 2.9506428146362307
- 2.9366138044993084
- 2.8574477354685466
- 2.9072650051116944
- 2.862635278701782
- 2.858669293721517
- 2.8114842828114828
- 2.812551606496175
- 2.9436037572224936
- 2.83387965520223
- 2.9184633986155193
- 2.7857499090830484
- 2.8335556983947754
- 2.8594290351867677
- 2.86204088528951
- 2.9946405919392904
- 2.8178875160217287
- 2.8469049231211345
- 2.768965549468994
- 2.9190684223175047
- 2.4260752105712893
- 2.5478607018788657
- 2.564309145609538
- 2.5785372734069822
- 2.6648674043019613
- 2.231347401936849
- 2.3119489192962646
- 2.5539213848114013
- 2.5082874933878583
- 2.4387806622187296
- 2.5260250854492186
- 2.513947744369507
- 2.479941625595093
- 2.5855200894673667
- 2.560026149749756
- 2.5171340688069663
- 2.523024574915568
- 2.490087947845459
- 2.560081116358439
- 2.7272791481018066
- 2.4809940179189045
- 2.551267371177673
- 2.472688652674357
- 2.747239910761515
- 2.0456165981292727
- 2.2153695662816366
- 2.2563062429428102
- 2.3192417669296264
- 2.3621111663182575
- 2.4159553114573162
- 2.5706823380788166
- 2.3497314993540446
- 2.443091006278992
- 2.2949554936091103
- 3.0282843017578127
- 1.9894031079610188
- 2.055581660270691
- 2.0932287820180258
- 2.3984911092122396
- 3.2399279753367107
- 1.6321926228205363
- 1.8767024596532187
- 1.8608305486043295
- 2.0152194134394326
- 1.774124779701233
- 1.6980568154652913
- 1.8031053447723389
- 1.902503368059794
- 1.9734259621302286
- 1.6745363823572794
- 1.5746269035339355
- 1.7552473735809326
- 1.7789385827382405
- 1.869896273612976
- 1.9224924977620443
- 1.970149213473002
- 1.464631168047587
- 1.7251987091700236
- 1.8812444814046223
- 1.8449132013320924
- 1.8739333152770996
- 1.8751499160130818
- 1.9364651425679524
- 1.8785931046803792
- 2.024367537498474
- 1.9238791799545287
- 2.020915649731954
- 1.9806392669677735
- 2.059143484433492
- 2.04061061223348
- 1.9473746331532795
- 1.9847958898544311
- 1.6920285081863404
- 1.781021205584208
- 1.8453062613805136
train_accuracy:
- 0.0
- 0.092
- 0.004
- 0.0
- 0.45
- 0.487
- 0.606
- 0.606
- 0.606
- 0.646
- 0.662
- 0.0
- 0.0
- 0.692
- 0.0
- 0.706
- 0.681
- 0.0
- 0.0
- 0.731
- 0.748
- 0.0
- 0.769
- 0.735
- 0.002
- 0.717
- 0.0
- 0.7
- 0.0
- 0.0
- 0.719
- 0.0
- 0.0
- 0.806
- 0.004
- 0.004
- 0.0
- 0.004
- 0.8
- 0.0
- 0.783
- 0.746
- 0.0
- 0.79
- 0.802
- 0.0
- 0.842
- 0.829
- 0.783
- 0.45
- 0.0
- 0.012
- 0.012
- 0.0
- 0.0
- 0.787
- 0.0
- 0.0
- 0.85
- 0.35
- 0.0
- 0.0
- 0.0
- 0.504
- 0.881
- 0.006
- 0.0
- 0.0
- 0.0
- 0.646
- 0.0
- 0.0
- 0.85
- 0.0
- 0.469
- 0.0
- 0.865
- 0.008
- 0.812
- 0.804
- 0.0
- 0.831
- 0.81
- 0.808
- 0.0
- 0.0
- 0.817
- 0.0
- 0.819
- 0.865
- 0.81
- 0.0
- 0.869
- 0.833
- 0.0
- 0.0
- 0.0
- 0.935
- 0.835
- 0.0
train_loss:
- 2.807
- 1.91
- 0.652
- 2.53
- 2.275
- 1.174
- 2.524
- 1.674
- 2.198
- 1.593
- 1.529
- 0.978
- 0.927
- 1.876
- 1.335
- 1.334
- 0.915
- 0.871
- 1.263
- 0.812
- 1.604
- 0.857
- 1.2
- 0.802
- 0.464
- 1.205
- 0.742
- 1.117
- 0.7
- 1.068
- 0.333
- 0.617
- 0.969
- 1.074
- 0.705
- 0.631
- 0.678
- 0.649
- 0.992
- 0.997
- 0.66
- 1.02
- 0.662
- 0.991
- 1.249
- 0.718
- 0.958
- 0.671
- 1.206
- 0.372
- 0.967
- 0.625
- 0.573
- 0.908
- 0.552
- 1.166
- 0.666
- 0.894
- 0.625
- 0.318
- 0.926
- 0.535
- 0.566
- 0.28
- 0.15
- 0.515
- 0.817
- 0.525
- 0.835
- 0.226
- 0.49
- 0.535
- 0.792
- 0.783
- 0.293
- 0.525
- 0.824
- 0.517
- 0.814
- 0.836
- 0.807
- 0.269
- 1.148
- 1.086
- 0.507
- 0.488
- 0.827
- 0.763
- 0.505
- 1.051
- 0.513
- 0.737
- 0.789
- 0.74
- 0.753
- 0.543
- 0.487
- 0.218
- 1.096
- 0.712
unequal: 0
verbose: 1
