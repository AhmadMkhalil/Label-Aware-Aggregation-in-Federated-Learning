avg_train_accuracy: 0.002
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.046595744680851064
- 0.1273936170212766
- 0.2530851063829787
- 0.31398936170212766
- 0.3651063829787234
- 0.4074468085106383
- 0.44670212765957445
- 0.47
- 0.4901595744680851
- 0.5006914893617022
- 0.49638297872340426
- 0.5101063829787233
- 0.5255319148936171
- 0.5272340425531915
- 0.5410106382978723
- 0.5456914893617021
- 0.5568085106382978
- 0.5622340425531915
- 0.5593617021276596
- 0.09585106382978724
- 0.08957446808510638
- 0.5714361702127659
- 0.5663829787234043
- 0.5800531914893617
- 0.589627659574468
- 0.5897872340425532
- 0.5927127659574468
- 0.5953191489361702
- 0.593563829787234
- 0.6029787234042553
- 0.6038297872340426
- 0.5986702127659574
- 0.6026595744680852
- 0.6117553191489362
- 0.611436170212766
- 0.6138297872340426
- 0.6162765957446809
- 0.6090425531914894
- 0.6213829787234042
- 0.6208510638297873
- 0.6201063829787234
- 0.6253191489361702
- 0.62
- 0.6261702127659574
- 0.6189361702127659
- 0.6302127659574468
- 0.19622340425531914
- 0.6258510638297873
- 0.6260638297872341
- 0.6262234042553192
- 0.2821808510638298
- 0.6313829787234042
- 0.6320744680851064
- 0.6317021276595745
- 0.3042021276595745
- 0.629095744680851
- 0.6329255319148936
- 0.6336170212765957
- 0.6359574468085106
- 0.635904255319149
- 0.6371808510638298
- 0.6382446808510638
- 0.636968085106383
- 0.6376595744680851
- 0.6401595744680851
- 0.399468085106383
- 0.639468085106383
- 0.6390425531914894
- 0.638031914893617
- 0.6419148936170213
- 0.6406382978723404
- 0.6429787234042553
- 0.6440425531914894
- 0.6463297872340426
- 0.6460106382978723
- 0.6443617021276595
- 0.6480851063829787
- 0.6506382978723404
- 0.6469148936170213
- 0.6490957446808511
- 0.6466489361702128
- 0.6484574468085106
- 0.6516489361702128
- 0.6495212765957447
- 0.6503723404255319
- 0.6464893617021277
- 0.6468617021276596
- 0.6511702127659574
- 0.6498404255319149
- 0.6539893617021276
- 0.6484574468085106
- 0.6502659574468085
- 0.6500531914893617
- 0.6523404255319148
- 0.6539893617021276
- 0.6530851063829787
- 0.6569680851063829
- 0.6509574468085106
- 0.4226063829787234
- 0.6544148936170213
test_loss_list:
- 3.7809056599934894
- 3.709707956314087
- 3.4930739720662434
- 3.2645002873738607
- 3.1476977602640788
- 3.049114844004313
- 3.0573732026418052
- 3.0565296522776286
- 3.160622355143229
- 3.109928251902262
- 2.975169817606608
- 2.9445584138234455
- 3.032774937947591
- 2.951912520726522
- 2.935441430409749
- 2.9501985454559327
- 3.0482482306162515
- 3.1528542264302573
- 2.968161172866821
- 4.1817619927724206
- 6.271349379221598
- 2.5709124342600504
- 2.558148466746012
- 2.7334304078420004
- 3.031105613708496
- 2.9040578397115073
- 2.892523539861043
- 2.913673931757609
- 2.775881443023682
- 2.8982321961720783
- 2.9422541936238606
- 2.7914995670318605
- 2.7446316464742027
- 2.9858254051208495
- 2.8101646105448403
- 2.8061301072438556
- 2.9786905606587726
- 2.782059488296509
- 2.941136569976807
- 2.9709755579630532
- 2.931258929570516
- 2.9655802822113038
- 2.7926185003916424
- 2.9381842454274496
- 2.7890191141764324
- 3.1762219715118407
- 3.296806999842326
- 2.390913028717041
- 2.5421131801605226
- 2.4799367666244505
- 2.702833283742269
- 2.275715479850769
- 2.5023828887939454
- 2.5472321685155235
- 2.5907888221740722
- 2.109799526532491
- 2.3197655789057414
- 2.392898041407267
- 2.425927235285441
- 2.419299956957499
- 2.464328393936157
- 2.5765537865956625
- 2.412548279762268
- 2.4641147883733114
- 2.530181582768758
- 2.2274708064397175
- 2.076699913342794
- 2.2572683540980023
- 2.279184039433797
- 2.32691175142924
- 2.320105587641398
- 2.3809760204950967
- 2.426503133773804
- 2.415866249402364
- 2.557328921953837
- 2.3738948678970337
- 2.4355496756235757
- 2.3468534247080486
- 2.450136909484863
- 2.3722822125752767
- 2.301683174769084
- 2.507220547993978
- 2.472256762186686
- 2.445408061345418
- 2.4148423194885256
- 2.317703808148702
- 2.357115109761556
- 2.5392046038309735
- 2.443978950182597
- 2.5808251412709553
- 2.3493336486816405
- 2.4140386168162027
- 2.334534862836202
- 2.3938343127568564
- 2.3008823935190836
- 2.393673760096232
- 2.5195069694519043
- 2.3155323394139606
- 2.5322948455810548
- 1.8833641560872396
train_accuracy:
- 0.037
- 0.0
- 0.0
- 0.0
- 0.483
- 0.0
- 0.567
- 0.588
- 0.617
- 0.648
- 0.0
- 0.0
- 0.0
- 0.702
- 0.683
- 0.0
- 0.708
- 0.0
- 0.744
- 0.015
- 0.654
- 0.708
- 0.0
- 0.0
- 0.76
- 0.765
- 0.769
- 0.771
- 0.0
- 0.794
- 0.775
- 0.0
- 0.769
- 0.794
- 0.0
- 0.775
- 0.785
- 0.0
- 0.802
- 0.802
- 0.817
- 0.798
- 0.0
- 0.796
- 0.8
- 0.8
- 0.09
- 0.802
- 0.0
- 0.0
- 0.529
- 0.812
- 0.812
- 0.829
- 0.933
- 0.0
- 0.823
- 0.81
- 0.81
- 0.0
- 0.829
- 0.829
- 0.0
- 0.0
- 0.806
- 0.904
- 0.804
- 0.8
- 0.0
- 0.819
- 0.0
- 0.835
- 0.823
- 0.842
- 0.842
- 0.0
- 0.844
- 0.833
- 0.817
- 0.838
- 0.0
- 0.85
- 0.819
- 0.846
- 0.0
- 0.817
- 0.0
- 0.827
- 0.844
- 0.823
- 0.0
- 0.856
- 0.0
- 0.84
- 0.844
- 0.0
- 0.838
- 0.0
- 0.921
- 0.002
train_loss:
- 3.812
- 2.8
- 2.545
- 1.378
- 1.223
- 1.327
- 1.741
- 1.764
- 2.148
- 1.648
- 0.994
- 1.086
- 1.41
- 1.009
- 0.964
- 0.89
- 1.276
- 1.254
- 0.991
- 0.568
- 0.303
- 1.403
- 0.797
- 1.173
- 1.499
- 1.094
- 1.124
- 1.105
- 0.776
- 1.037
- 1.076
- 0.733
- 0.722
- 1.04
- 0.722
- 0.742
- 1.012
- 0.718
- 1.032
- 0.972
- 0.989
- 0.987
- 0.698
- 0.97
- 0.678
- 1.206
- 0.486
- 1.061
- 0.645
- 0.665
- 0.383
- 1.012
- 0.898
- 0.898
- 0.333
- 0.559
- 0.855
- 0.879
- 0.868
- 0.561
- 0.852
- 1.13
- 0.634
- 0.567
- 0.829
- 0.355
- 0.866
- 0.82
- 0.585
- 0.817
- 0.573
- 0.799
- 0.777
- 0.839
- 1.048
- 0.536
- 0.831
- 0.857
- 0.783
- 0.847
- 0.568
- 1.053
- 0.779
- 0.797
- 0.774
- 0.559
- 0.58
- 1.031
- 0.788
- 1.006
- 0.548
- 0.796
- 0.574
- 0.82
- 0.608
- 0.788
- 0.973
- 0.568
- 0.321
- 0.479
unequal: 0
verbose: 1
