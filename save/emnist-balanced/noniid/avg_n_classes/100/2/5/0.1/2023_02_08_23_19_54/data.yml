avg_train_accuracy: 0.794
avg_train_loss: 0.017
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04196808510638298
- 0.033829787234042556
- 0.04154255319148936
- 0.05515957446808511
- 0.040106382978723404
- 0.04239361702127659
- 0.031595744680851065
- 0.04143617021276596
- 0.047180851063829785
- 0.04228723404255319
- 0.10558510638297873
- 0.04186170212765957
- 0.04186170212765957
- 0.12117021276595745
- 0.04186170212765957
- 0.04281914893617021
- 0.04808510638297872
- 0.16574468085106384
- 0.23132978723404254
- 0.04398936170212766
- 0.047287234042553195
- 0.28898936170212763
- 0.3542021276595745
- 0.04414893617021277
- 0.039095744680851065
- 0.37643617021276593
- 0.04111702127659574
- 0.411968085106383
- 0.061861702127659575
- 0.4743085106382979
- 0.0524468085106383
- 0.49851063829787234
- 0.5100531914893617
- 0.5190425531914894
- 0.10340425531914893
- 0.06675531914893618
- 0.5300531914893617
- 0.21090425531914894
- 0.5320212765957447
- 0.16388297872340427
- 0.07585106382978724
- 0.044468085106382976
- 0.5590957446808511
- 0.21313829787234043
- 0.560531914893617
- 0.08611702127659575
- 0.5783510638297872
- 0.5672340425531915
- 0.163031914893617
- 0.5894148936170213
- 0.2501063829787234
- 0.5980319148936171
- 0.5895212765957447
- 0.5924468085106382
- 0.5805851063829788
- 0.5878191489361703
- 0.5871808510638298
- 0.06468085106382979
- 0.05558510638297872
- 0.10281914893617021
- 0.10797872340425532
- 0.6077127659574468
- 0.5999468085106383
- 0.6033510638297872
- 0.2653191489361702
- 0.6168085106382979
- 0.6162234042553192
- 0.608404255319149
- 0.6045212765957447
- 0.6076595744680852
- 0.6064893617021276
- 0.31563829787234043
- 0.6260638297872341
- 0.6288829787234043
- 0.3334042553191489
- 0.6164893617021276
- 0.09904255319148936
- 0.6226063829787234
- 0.12170212765957447
- 0.2127659574468085
- 0.14122340425531915
- 0.14170212765957446
- 0.06361702127659574
- 0.1576063829787234
- 0.6547340425531915
- 0.44196808510638297
- 0.12292553191489362
- 0.6364893617021277
- 0.1920744680851064
- 0.6360106382978723
- 0.6304255319148936
- 0.6260106382978723
- 0.6247340425531915
- 0.3079787234042553
- 0.2027659574468085
- 0.07718085106382978
- 0.0952659574468085
- 0.11409574468085107
- 0.20175531914893616
- 0.6688297872340425
test_loss_list:
- 23.79404307047526
- 3.790670353571574
- 23.331640345255533
- 3.7739658832550047
- 21.845482025146485
- 23.84684804280599
- 20.587386830647787
- 18.96446309407552
- 3.7292246596018472
- 13.50411558787028
- 3.618327407836914
- 14.750667165120444
- 12.71139030456543
- 3.5128381951649983
- 10.40675895690918
- 13.226355934143067
- 11.384478874206543
- 3.4211247030893963
- 3.163970883687337
- 10.191408780415854
- 9.495304985046387
- 2.952799835205078
- 2.7503465366363526
- 8.312567138671875
- 17.50626304626465
- 2.6242597198486326
- 11.986928151448568
- 2.4705980110168455
- 8.189440027872722
- 2.3255827109018963
- 7.3298459752400715
- 2.2310800727208457
- 2.214210295677185
- 2.2197788921991983
- 7.942259254455567
- 8.3859055074056
- 1.9143877696990967
- 5.637167943318685
- 1.9038324213027955
- 6.07939338684082
- 7.49271650950114
- 13.536280873616537
- 1.703498182296753
- 5.127904561360677
- 1.7475478045145671
- 6.447670567830404
- 1.6741801929473876
- 1.746113255818685
- 5.204605623881022
- 1.7028387149175008
- 4.768275737762451
- 1.6715041573842366
- 1.7407787545522053
- 1.7866223335266114
- 1.8509847243626913
- 1.867967241605123
- 1.9552764336268107
- 11.24698434193929
- 13.70853126525879
- 6.310758959452311
- 6.862474880218506
- 1.5298068602879842
- 1.6597104581197102
- 1.7026972881952922
- 4.988036874135335
- 1.7274415175120035
- 1.8010231081644694
- 1.8490762567520143
- 1.893452107111613
- 1.9169144376118978
- 1.9690368890762329
- 4.705164852142334
- 1.845393198331197
- 1.9388183403015136
- 4.715960677464803
- 1.7293519163131714
- 9.307810478210449
- 1.6437234735488893
- 8.260486005147298
- 5.058212871551514
- 5.476275380452474
- 6.3926195017496745
- 8.249996115366617
- 5.35465134938558
- 1.1654474131266277
- 3.604776070912679
- 7.282590109507243
- 1.2472404273351034
- 5.952575600941976
- 1.3259830872217815
- 1.398221108118693
- 1.4873032585779826
- 1.5452999067306519
- 3.650143709182739
- 5.1484312884012855
- 9.050210647583008
- 7.81011589050293
- 6.2912681070963545
- 4.6877651786804195
- 1.2149517520268758
train_accuracy:
- 0.977
- 0.004
- 0.994
- 0.0
- 0.935
- 0.998
- 0.515
- 0.956
- 0.0
- 0.994
- 0.042
- 0.975
- 0.994
- 0.06
- 0.983
- 1.0
- 0.988
- 0.102
- 0.227
- 1.0
- 0.979
- 0.285
- 0.396
- 0.992
- 0.856
- 0.475
- 0.971
- 0.475
- 1.0
- 0.606
- 0.992
- 0.635
- 0.592
- 0.617
- 0.998
- 0.99
- 0.608
- 0.992
- 0.631
- 0.998
- 1.0
- 0.977
- 0.638
- 0.998
- 0.64
- 0.992
- 0.681
- 0.696
- 1.0
- 0.702
- 0.998
- 0.706
- 0.725
- 0.725
- 0.727
- 0.754
- 0.746
- 0.979
- 0.981
- 0.996
- 0.985
- 0.752
- 0.76
- 0.754
- 0.998
- 0.765
- 0.771
- 0.781
- 0.76
- 0.775
- 0.773
- 0.996
- 0.8
- 0.779
- 0.992
- 0.76
- 0.983
- 0.775
- 0.983
- 0.998
- 1.0
- 0.998
- 0.985
- 0.99
- 0.765
- 0.988
- 0.983
- 0.752
- 0.983
- 0.787
- 0.775
- 0.802
- 0.794
- 1.0
- 1.0
- 0.99
- 0.983
- 1.0
- 1.0
- 0.794
train_loss:
- 0.799
- 4.153
- 1.298
- 4.131
- 1.569
- 1.014
- 1.576
- 0.869
- 4.129
- 0.745
- 4.003
- 0.896
- 0.52
- 3.95
- 0.537
- 0.417
- 1.08
- 3.951
- 3.473
- 0.307
- 0.478
- 3.566
- 3.007
- 0.308
- 0.983
- 3.362
- 0.503
- 2.953
- 0.289
- 2.795
- 0.33
- 2.631
- 2.352
- 2.204
- 0.447
- 0.493
- 2.508
- 0.257
- 2.206
- 0.249
- 0.349
- 0.723
- 2.408
- 0.222
- 2.031
- 0.419
- 2.139
- 1.841
- 0.229
- 1.946
- 0.257
- 1.947
- 1.692
- 1.649
- 1.598
- 1.615
- 1.524
- 0.547
- 0.168
- 0.445
- 0.451
- 2.02
- 1.572
- 1.567
- 0.203
- 1.648
- 1.437
- 1.41
- 1.43
- 1.364
- 1.369
- 0.234
- 1.556
- 1.325
- 0.387
- 1.538
- 0.491
- 1.604
- 0.291
- 0.32
- 0.396
- 0.135
- 0.67
- 0.417
- 1.951
- 0.184
- 0.39
- 1.656
- 0.261
- 1.583
- 1.388
- 1.309
- 1.264
- 0.236
- 0.023
- 0.375
- 0.472
- 0.337
- 0.149
- 1.745
unequal: 0
verbose: 1
