avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024361702127659573
- 0.031063829787234043
- 0.13425531914893618
- 0.21265957446808512
- 0.2668617021276596
- 0.2885106382978723
- 0.33787234042553194
- 0.35840425531914893
- 0.3964893617021277
- 0.41143617021276596
- 0.43957446808510636
- 0.4444148936170213
- 0.4353723404255319
- 0.4551595744680851
- 0.4622872340425532
- 0.4717021276595745
- 0.4761170212765957
- 0.4728723404255319
- 0.47808510638297874
- 0.18010638297872342
- 0.48409574468085104
- 0.49388297872340425
- 0.49319148936170215
- 0.49882978723404253
- 0.502127659574468
- 0.5024468085106383
- 0.18973404255319148
- 0.5080851063829788
- 0.5093617021276595
- 0.5193617021276595
- 0.5179255319148937
- 0.5268617021276596
- 0.5228191489361702
- 0.5253723404255319
- 0.5290957446808511
- 0.5311170212765958
- 0.5338297872340425
- 0.5331914893617021
- 0.5279787234042553
- 0.5352659574468085
- 0.5380851063829787
- 0.5397340425531915
- 0.5422872340425532
- 0.5398404255319149
- 0.5382978723404256
- 0.5435106382978724
- 0.5490957446808511
- 0.5475
- 0.5495212765957447
- 0.5522872340425532
- 0.5514893617021277
- 0.5511702127659575
- 0.5545744680851064
- 0.5521276595744681
- 0.5567553191489362
- 0.5568617021276596
- 0.5593085106382979
- 0.5567021276595745
- 0.5613829787234043
- 0.5611702127659575
- 0.5631914893617022
- 0.5649468085106383
- 0.5637234042553192
- 0.563936170212766
- 0.5657446808510638
- 0.5659042553191489
- 0.5679787234042554
- 0.5672872340425532
- 0.5674468085106383
- 0.5664893617021277
- 0.5700531914893617
- 0.5690957446808511
- 0.5706382978723404
- 0.5714361702127659
- 0.5698936170212766
- 0.5713829787234043
- 0.5712234042553191
- 0.5732978723404255
- 0.5754787234042553
- 0.5744148936170212
- 0.5709042553191489
- 0.5728191489361703
- 0.5725
- 0.5714893617021276
- 0.5750531914893617
- 0.5764361702127659
- 0.5754787234042553
- 0.5752127659574469
- 0.5773936170212766
- 0.5757446808510638
- 0.578404255319149
- 0.5762234042553191
- 0.5771808510638298
- 0.5768085106382979
- 0.5776595744680851
- 0.5772340425531914
- 0.5768617021276595
- 0.5792021276595745
- 0.5795744680851064
- 0.5802127659574469
test_loss_list:
- 3.799025615056356
- 3.7796460405985512
- 3.6913459428151447
- 3.446057170232137
- 3.2754893016815188
- 3.1101129976908366
- 3.0633585325876873
- 3.030989742279053
- 3.0470162041982016
- 2.924325647354126
- 3.0384622478485106
- 2.9845921675364178
- 2.7520607407887776
- 2.8324918206532796
- 2.79684770266215
- 2.8692319266001385
- 2.7796726926167805
- 2.6394717439015705
- 2.7162341976165774
- 3.259996713002523
- 2.5438939189910887
- 2.701898619333903
- 2.5509258937835693
- 2.5637626520792645
- 2.569446687698364
- 2.550828463236491
- 3.1152432028452557
- 2.464362433751424
- 2.429898484547933
- 2.5530385716756183
- 2.512995443344116
- 2.5611387729644775
- 2.326601360638936
- 2.4367811775207517
- 2.553115167617798
- 2.500246003468831
- 2.5976952838897707
- 2.4388824685414634
- 2.308811601003011
- 2.410647341410319
- 2.4115300528208414
- 2.3493485403060914
- 2.3633518171310426
- 2.346265427271525
- 2.2874856408437094
- 2.349090099334717
- 2.460079310735067
- 2.2687692276636757
- 2.32706690788269
- 2.41483252843221
- 2.32100905418396
- 2.3093061208724976
- 2.327956183751424
- 2.223913197517395
- 2.3956626431147257
- 2.3548249133427936
- 2.4293172136942545
- 2.263889897664388
- 2.299610203107198
- 2.210615474383036
- 2.255922916730245
- 2.1713600095113117
- 2.108044047355652
- 2.171718365351359
- 2.338692037264506
- 2.180066965421041
- 2.350186643600464
- 2.158517977396647
- 2.2357310183842976
- 2.1179913806915285
- 2.1094987630844115
- 2.2277921279271444
- 2.216772503852844
- 2.1111087719599406
- 2.0306785519917807
- 2.1899323892593383
- 2.137248290379842
- 2.158828845024109
- 2.157011014620463
- 2.208754720687866
- 1.9640352789560953
- 2.0619263950983684
- 2.0611454582214357
- 1.9163694349924723
- 2.0395012712478637
- 2.135001311302185
- 2.096983118057251
- 2.111647434234619
- 2.0027229658762615
- 2.0948958285649617
- 2.105793293317159
- 2.0826395479838054
- 1.9948982906341552
- 1.9265890407562256
- 1.9643858528137208
- 2.051306266784668
- 1.902679149309794
- 1.9768079757690429
- 2.0485749419530235
- 2.0166122086842857
train_accuracy:
- 0.027
- 0.037
- 0.0
- 0.319
- 0.433
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.656
- 0.612
- 0.696
- 0.0
- 0.0
- 0.633
- 0.0
- 0.115
- 0.0
- 0.0
- 0.723
- 0.0
- 0.683
- 0.725
- 0.175
- 0.0
- 0.696
- 0.0
- 0.0
- 0.715
- 0.0
- 0.754
- 0.727
- 0.0
- 0.725
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.8
- 0.002
- 0.0
- 0.781
- 0.0
- 0.0
- 0.002
- 0.771
- 0.004
- 0.004
- 0.767
- 0.775
- 0.817
- 0.0
- 0.806
- 0.769
- 0.0
- 0.794
- 0.825
- 0.0
- 0.0
- 0.004
- 0.819
- 0.779
- 0.0
- 0.0
- 0.0
- 0.006
- 0.0
- 0.765
- 0.783
- 0.006
- 0.0
- 0.0
- 0.0
- 0.0
- 0.781
- 0.006
- 0.0
- 0.0
- 0.0
- 0.01
- 0.825
- 0.027
- 0.798
- 0.0
train_loss:
- 1.788
- 1.574
- 1.877
- 1.304
- 1.495
- 0.734
- 0.977
- 0.924
- 1.128
- 0.89
- 1.067
- 1.018
- 0.59
- 0.747
- 0.769
- 0.907
- 0.711
- 0.526
- 0.691
- 0.329
- 0.461
- 0.853
- 0.639
- 0.657
- 0.63
- 0.635
- 0.284
- 0.589
- 0.615
- 0.748
- 0.751
- 0.74
- 0.415
- 0.587
- 0.713
- 0.719
- 0.697
- 0.562
- 0.404
- 0.542
- 0.537
- 0.54
- 0.525
- 0.53
- 0.39
- 0.524
- 0.652
- 0.528
- 0.514
- 0.657
- 0.508
- 0.512
- 0.491
- 0.36
- 0.619
- 0.624
- 0.615
- 0.499
- 0.482
- 0.486
- 0.5
- 0.483
- 0.342
- 0.473
- 0.593
- 0.471
- 0.574
- 0.466
- 0.601
- 0.48
- 0.462
- 0.57
- 0.57
- 0.452
- 0.341
- 0.572
- 0.453
- 0.563
- 0.55
- 0.571
- 0.342
- 0.431
- 0.447
- 0.33
- 0.42
- 0.542
- 0.541
- 0.56
- 0.435
- 0.54
- 0.529
- 0.537
- 0.427
- 0.322
- 0.414
- 0.533
- 0.317
- 0.417
- 0.524
- 0.534
unequal: 0
verbose: 1
