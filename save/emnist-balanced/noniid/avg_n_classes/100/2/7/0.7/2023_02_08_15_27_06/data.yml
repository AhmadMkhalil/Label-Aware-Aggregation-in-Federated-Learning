avg_train_accuracy: 0.842
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03590425531914894
- 0.059468085106382976
- 0.14952127659574468
- 0.2746276595744681
- 0.32638297872340427
- 0.3749468085106383
- 0.39324468085106384
- 0.4201063829787234
- 0.42946808510638296
- 0.4525531914893617
- 0.4525531914893617
- 0.46393617021276595
- 0.46675531914893614
- 0.4725531914893617
- 0.48345744680851066
- 0.49031914893617023
- 0.4896808510638298
- 0.48654255319148937
- 0.4876063829787234
- 0.5037765957446808
- 0.5034042553191489
- 0.5018617021276596
- 0.5139361702127659
- 0.5171808510638298
- 0.5175
- 0.515531914893617
- 0.5242553191489362
- 0.5288829787234043
- 0.5317553191489361
- 0.5292553191489362
- 0.5358510638297872
- 0.5320744680851064
- 0.5357446808510639
- 0.5318085106382979
- 0.538563829787234
- 0.541595744680851
- 0.5384574468085106
- 0.5390425531914894
- 0.5432446808510638
- 0.5467021276595745
- 0.546063829787234
- 0.5481914893617021
- 0.5498404255319149
- 0.5476063829787234
- 0.5506914893617021
- 0.5522340425531915
- 0.5538297872340425
- 0.5554787234042553
- 0.5576063829787234
- 0.5589893617021277
- 0.5503191489361702
- 0.559468085106383
- 0.5604787234042553
- 0.5604787234042553
- 0.5610106382978723
- 0.56
- 0.5612234042553191
- 0.5629255319148936
- 0.5625531914893617
- 0.5685106382978723
- 0.5639893617021277
- 0.5687234042553192
- 0.5661170212765958
- 0.5674468085106383
- 0.5691489361702128
- 0.5693085106382979
- 0.5649468085106383
- 0.5723404255319149
- 0.5697340425531915
- 0.5729255319148936
- 0.571968085106383
- 0.5694148936170212
- 0.5679255319148936
- 0.5713829787234043
- 0.4465425531914894
- 0.573031914893617
- 0.5739893617021277
- 0.5733510638297873
- 0.5745212765957447
- 0.5757446808510638
- 0.5750531914893617
- 0.5751595744680851
- 0.5730851063829787
- 0.5759042553191489
- 0.5762765957446808
- 0.5754255319148937
- 0.5783510638297872
- 0.5731914893617022
- 0.5767021276595745
- 0.5776595744680851
- 0.5783510638297872
- 0.5770212765957446
- 0.574840425531915
- 0.5805851063829788
- 0.5822872340425532
- 0.5818085106382979
- 0.5799468085106383
- 0.5795744680851064
- 0.5804255319148937
- 0.5835106382978723
test_loss_list:
- 3.798508990605672
- 3.800410264333089
- 3.6880098978678384
- 3.462865425745646
- 3.229313424428304
- 3.131776959101359
- 3.0495729478200277
- 3.0297511450449623
- 2.9508655389149983
- 3.04427121480306
- 2.9222722625732422
- 2.903191095987956
- 2.960634288787842
- 2.903690980275472
- 2.8936648686726887
- 2.891255261103312
- 2.8061355686187746
- 2.724926373163859
- 2.708433717091878
- 2.741292740503947
- 2.7048140239715575
- 2.5834231758117676
- 2.7920038000742595
- 2.6327597840627033
- 2.592409652074178
- 2.5897492281595866
- 2.5772067070007325
- 2.5652847480773926
- 2.629658390680949
- 2.592033904393514
- 2.5920517603556315
- 2.5166529019673667
- 2.4642620499928793
- 2.4170811494191486
- 2.450881897608439
- 2.6144148890177408
- 2.382619244257609
- 2.3445817756652834
- 2.5835040124257405
- 2.411228278477987
- 2.504627126057943
- 2.373677886327108
- 2.3736466280619304
- 2.3991167227427166
- 2.4234523423512777
- 2.3965546226501466
- 2.601433734893799
- 2.386926806767782
- 2.545360492070516
- 2.505824886957804
- 2.214937389691671
- 2.451068630218506
- 2.455514103571574
- 2.316461386680603
- 2.434500726064046
- 2.3768241119384768
- 2.2867830419540405
- 2.3565427271525063
- 2.2891167894999187
- 2.4095458078384397
- 2.274065237045288
- 2.3443248383204143
- 2.2901195351282757
- 2.2936334307988484
- 2.4333965301513674
- 2.339003187815348
- 2.1440270551045737
- 2.382785741488139
- 2.233101658821106
- 2.3589214070638023
- 2.3854041353861493
- 2.1917778317133587
- 2.140035177866618
- 2.1820322545369466
- 1.9373086166381837
- 2.012598377863566
- 2.1102993504206338
- 2.118465805053711
- 2.218647295633952
- 2.2661524772644044
- 2.0479559024175007
- 2.1287649043401085
- 2.087768691380819
- 2.087368729909261
- 2.151301870346069
- 2.0664467191696168
- 2.075250593821208
- 1.9557540941238403
- 2.085494179725647
- 2.0181488545735675
- 2.1297446997960408
- 2.0801454337437946
- 1.9726520856221517
- 2.211564809481303
- 2.2189389657974243
- 2.078344044685364
- 2.079571919441223
- 1.9897472349802654
- 1.9920732084910076
- 2.011343272527059
train_accuracy:
- 0.048
- 0.0
- 0.0
- 0.45
- 0.0
- 0.0
- 0.0
- 0.0
- 0.64
- 0.0
- 0.65
- 0.65
- 0.0
- 0.677
- 0.0
- 0.0
- 0.7
- 0.0
- 0.0
- 0.725
- 0.0
- 0.0
- 0.748
- 0.0
- 0.0
- 0.0
- 0.765
- 0.775
- 0.0
- 0.763
- 0.0
- 0.76
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.792
- 0.773
- 0.792
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.812
- 0.821
- 0.817
- 0.825
- 0.0
- 0.817
- 0.0
- 0.0
- 0.823
- 0.0
- 0.0
- 0.0
- 0.0
- 0.821
- 0.848
- 0.0
- 0.0
- 0.0
- 0.583
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.846
- 0.0
- 0.827
- 0.0
- 0.84
- 0.002
- 0.0
- 0.0
- 0.0
- 0.84
- 0.0
- 0.006
- 0.858
- 0.0
- 0.831
- 0.838
- 0.0
- 0.004
- 0.842
train_loss:
- 1.743
- 1.983
- 1.044
- 1.712
- 1.15
- 1.363
- 0.941
- 1.187
- 0.893
- 1.101
- 1.054
- 0.842
- 1.01
- 0.77
- 0.961
- 0.769
- 0.725
- 0.547
- 0.56
- 0.672
- 0.699
- 0.532
- 0.84
- 0.629
- 0.496
- 0.492
- 0.615
- 0.611
- 0.752
- 0.63
- 0.585
- 0.618
- 0.415
- 0.457
- 0.591
- 0.707
- 0.453
- 0.457
- 0.708
- 0.436
- 0.559
- 0.564
- 0.552
- 0.547
- 0.536
- 0.546
- 0.657
- 0.522
- 0.644
- 0.629
- 0.411
- 0.52
- 0.596
- 0.485
- 0.653
- 0.652
- 0.535
- 0.505
- 0.525
- 0.585
- 0.515
- 0.448
- 0.503
- 0.503
- 0.573
- 0.58
- 0.387
- 0.555
- 0.482
- 0.546
- 0.588
- 0.511
- 0.377
- 0.478
- 0.261
- 0.452
- 0.584
- 0.588
- 0.56
- 0.575
- 0.327
- 0.415
- 0.468
- 0.435
- 0.582
- 0.463
- 0.464
- 0.362
- 0.456
- 0.462
- 0.569
- 0.447
- 0.345
- 0.545
- 0.507
- 0.444
- 0.444
- 0.348
- 0.404
- 0.4
unequal: 0
verbose: 1
