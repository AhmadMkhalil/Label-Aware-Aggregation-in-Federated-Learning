avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033829787234042556
- 0.09329787234042553
- 0.23303191489361702
- 0.2982446808510638
- 0.34106382978723404
- 0.3708510638297872
- 0.38909574468085106
- 0.4027127659574468
- 0.4326063829787234
- 0.43898936170212766
- 0.4423404255319149
- 0.46143617021276595
- 0.4642553191489362
- 0.4742021276595745
- 0.4727127659574468
- 0.48984042553191487
- 0.4826595744680851
- 0.4951063829787234
- 0.49138297872340425
- 0.49909574468085105
- 0.5037234042553191
- 0.5061702127659574
- 0.5136170212765957
- 0.5190425531914894
- 0.5138829787234043
- 0.5259574468085106
- 0.5295212765957447
- 0.5325531914893618
- 0.5267021276595745
- 0.5334042553191489
- 0.5389893617021276
- 0.5409574468085107
- 0.5374468085106383
- 0.5436702127659574
- 0.5448404255319149
- 0.5467553191489362
- 0.5485106382978724
- 0.5480851063829787
- 0.5523936170212767
- 0.5529787234042554
- 0.5511170212765958
- 0.5559042553191489
- 0.5546276595744681
- 0.556968085106383
- 0.555
- 0.5574468085106383
- 0.556595744680851
- 0.5574468085106383
- 0.5593085106382979
- 0.5632446808510638
- 0.5587234042553192
- 0.5624468085106383
- 0.5622340425531915
- 0.5663829787234043
- 0.5715957446808511
- 0.5679787234042554
- 0.5718617021276595
- 0.5672872340425532
- 0.5722872340425532
- 0.5720744680851064
- 0.5730851063829787
- 0.5714893617021276
- 0.5709574468085107
- 0.5763297872340426
- 0.574840425531915
- 0.5742553191489361
- 0.5766489361702127
- 0.5765957446808511
- 0.5765425531914894
- 0.5737234042553192
- 0.5776595744680851
- 0.5810106382978724
- 0.5793085106382979
- 0.5816489361702127
- 0.5793085106382979
- 0.5818617021276595
- 0.5827659574468085
- 0.578031914893617
- 0.5797340425531915
- 0.5775
- 0.5798936170212766
- 0.5834574468085106
- 0.5816489361702127
- 0.5832978723404255
- 0.5812765957446808
- 0.5854255319148937
- 0.5853191489361702
- 0.5826595744680851
- 0.5856914893617021
- 0.5829787234042553
- 0.5826063829787234
- 0.5876595744680851
- 0.5869148936170213
- 0.5831382978723404
- 0.5873404255319149
- 0.5862765957446808
- 0.5857446808510638
- 0.5856382978723405
- 0.5876063829787234
- 0.5868085106382979
test_loss_list:
- 3.7935546811421714
- 3.7243920516967775
- 3.5225900109608967
- 3.225335102081299
- 3.0901372464497885
- 2.979308993021647
- 2.9316642729441327
- 2.8541617806752524
- 2.898205416997274
- 2.8216544278462727
- 2.7770316632588705
- 2.8272671127319335
- 2.7998924541473387
- 2.7926950645446778
- 2.817074890136719
- 2.8452953338623046
- 2.5966277821858723
- 2.760234473546346
- 2.661015033721924
- 2.6831662368774416
- 2.649041004180908
- 2.6046122042338054
- 2.751754191716512
- 2.728715124130249
- 2.5697009245554607
- 2.5894677607218424
- 2.7212612438201904
- 2.721371749242147
- 2.465563424428304
- 2.491041088104248
- 2.546823740005493
- 2.6624143409729
- 2.363523448308309
- 2.4981176630655924
- 2.4906890137990314
- 2.4597175248463947
- 2.5818864250183107
- 2.3793016465504966
- 2.4236885833740236
- 2.411287523905436
- 2.369707711537679
- 2.493568538029989
- 2.378240706125895
- 2.3709461816151935
- 2.343167476654053
- 2.454931993484497
- 2.2196595589319865
- 2.2300192817052205
- 2.288828361829122
- 2.3123226022720336
- 2.171447900136312
- 2.208715443611145
- 2.161966584523519
- 2.09416684627533
- 2.3106640148162843
- 2.296492851575216
- 2.362528978983561
- 2.2211806917190553
- 2.1742123794555663
- 2.112677667935689
- 2.170200572013855
- 2.2491764799753824
- 2.040674859682719
- 2.1087826681137085
- 2.2717827351888022
- 2.1357116969426473
- 2.112237426439921
- 2.1587287521362306
- 2.020903887748718
- 1.946787780125936
- 2.0093123801549275
- 2.0614230553309123
- 2.162999350229899
- 2.2319716803232827
- 2.1461257934570312
- 2.103402040799459
- 2.216037537256877
- 2.038743158976237
- 2.1805268732706704
- 2.024178547859192
- 2.0330652872721355
- 2.062519515355428
- 2.0320022328694662
- 2.031045413017273
- 1.9545121415456137
- 2.013042411804199
- 2.1550741624832153
- 1.9709439706802367
- 2.010557157198588
- 1.9527584966023763
- 2.017643372217814
- 2.098800930976868
- 1.9841503286361695
- 1.8555563720067343
- 2.0829335006078082
- 1.945278253555298
- 1.9678138748804728
- 1.9542722876866658
- 1.8683248567581177
- 2.0398614311218264
train_accuracy:
- 0.058
- 0.115
- 0.0
- 0.0
- 0.0
- 0.0
- 0.56
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.667
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.01
- 0.0
- 0.0
- 0.0
- 0.0
- 0.733
- 0.0
- 0.004
- 0.779
- 0.0
- 0.785
- 0.002
- 0.0
- 0.002
- 0.0
- 0.76
- 0.812
- 0.0
- 0.792
- 0.76
- 0.808
- 0.0
- 0.812
- 0.787
- 0.0
- 0.0
- 0.023
- 0.0
- 0.021
- 0.0
- 0.029
- 0.802
- 0.023
- 0.012
- 0.002
- 0.0
- 0.812
- 0.002
- 0.0
- 0.002
- 0.002
- 0.81
- 0.8
- 0.806
- 0.792
- 0.002
- 0.002
- 0.0
- 0.8
- 0.0
- 0.815
- 0.802
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.002
- 0.0
- 0.0
- 0.0
- 0.833
- 0.0
- 0.0
- 0.827
- 0.823
- 0.0
- 0.037
- 0.0
- 0.0
- 0.054
- 0.821
- 0.006
- 0.808
- 0.006
- 0.81
- 0.0
train_loss:
- 2.065
- 1.155
- 1.772
- 0.84
- 1.056
- 1.016
- 0.943
- 0.643
- 0.879
- 0.84
- 0.581
- 0.785
- 0.782
- 0.767
- 0.932
- 0.915
- 0.526
- 0.692
- 0.677
- 0.669
- 0.636
- 0.662
- 0.767
- 0.798
- 0.624
- 0.615
- 0.743
- 0.721
- 0.441
- 0.578
- 0.585
- 0.716
- 0.448
- 0.57
- 0.542
- 0.544
- 0.68
- 0.555
- 0.536
- 0.549
- 0.529
- 0.52
- 0.53
- 0.518
- 0.514
- 0.643
- 0.401
- 0.384
- 0.374
- 0.499
- 0.364
- 0.512
- 0.356
- 0.355
- 0.586
- 0.622
- 0.588
- 0.465
- 0.471
- 0.339
- 0.466
- 0.46
- 0.359
- 0.452
- 0.541
- 0.455
- 0.478
- 0.433
- 0.346
- 0.331
- 0.443
- 0.451
- 0.56
- 0.539
- 0.571
- 0.448
- 0.528
- 0.449
- 0.535
- 0.456
- 0.43
- 0.439
- 0.425
- 0.439
- 0.441
- 0.428
- 0.51
- 0.408
- 0.423
- 0.406
- 0.399
- 0.521
- 0.401
- 0.328
- 0.496
- 0.419
- 0.414
- 0.395
- 0.424
- 0.514
unequal: 0
verbose: 1
