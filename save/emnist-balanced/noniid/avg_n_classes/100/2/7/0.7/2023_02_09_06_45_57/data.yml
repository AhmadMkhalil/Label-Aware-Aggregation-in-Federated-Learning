avg_train_accuracy: 0.513
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.032446808510638296
- 0.08643617021276596
- 0.18898936170212766
- 0.23898936170212767
- 0.29888297872340425
- 0.3618085106382979
- 0.3797340425531915
- 0.41143617021276596
- 0.4309574468085106
- 0.4425531914893617
- 0.45632978723404255
- 0.4635106382978723
- 0.47760638297872343
- 0.4848404255319149
- 0.48638297872340425
- 0.4922340425531915
- 0.49882978723404253
- 0.31851063829787235
- 0.500904255319149
- 0.5013829787234042
- 0.5119148936170212
- 0.5128191489361702
- 0.5184042553191489
- 0.518563829787234
- 0.524468085106383
- 0.5304255319148936
- 0.5327659574468085
- 0.5255319148936171
- 0.5368085106382978
- 0.5378191489361702
- 0.5370744680851064
- 0.5364893617021277
- 0.5414361702127659
- 0.5419148936170213
- 0.5384042553191489
- 0.5476063829787234
- 0.5436170212765957
- 0.5474468085106383
- 0.5512234042553191
- 0.5545212765957447
- 0.5534574468085106
- 0.5545744680851064
- 0.556063829787234
- 0.5595744680851064
- 0.5555851063829788
- 0.5588297872340425
- 0.559468085106383
- 0.5616489361702127
- 0.5618085106382978
- 0.5627659574468085
- 0.5632446808510638
- 0.5647340425531915
- 0.5597340425531915
- 0.5648404255319149
- 0.5672872340425532
- 0.5663829787234043
- 0.5686702127659574
- 0.5676063829787235
- 0.5695744680851064
- 0.5712234042553191
- 0.5683510638297873
- 0.5707978723404256
- 0.5722340425531914
- 0.5715957446808511
- 0.573404255319149
- 0.573031914893617
- 0.5713829787234043
- 0.5746808510638298
- 0.5749468085106383
- 0.5778723404255319
- 0.5765425531914894
- 0.5778191489361703
- 0.5804255319148937
- 0.5772872340425532
- 0.5789893617021277
- 0.5794148936170213
- 0.5765425531914894
- 0.5802127659574469
- 0.579627659574468
- 0.5802127659574469
- 0.5821808510638298
- 0.5835106382978723
- 0.5832978723404255
- 0.5839893617021277
- 0.5832446808510638
- 0.5818085106382979
- 0.5825
- 0.5831914893617022
- 0.5825
- 0.5853723404255319
- 0.5854787234042553
- 0.5870212765957447
- 0.5872872340425532
- 0.5877127659574468
- 0.5893617021276596
- 0.5851063829787234
- 0.5858510638297872
- 0.5853191489361702
- 0.5871276595744681
- 0.45835106382978724
test_loss_list:
- 3.8046811485290526
- 3.7913887151082357
- 3.600844268798828
- 3.331479527155558
- 3.1955783812205
- 3.1495144176483154
- 3.032785154978434
- 2.989890282948812
- 2.9099331124623617
- 2.9138303057352704
- 2.8827660497029624
- 2.8608119901021323
- 2.912710952758789
- 2.914779233932495
- 2.7813198661804197
- 2.8812914276123047
- 2.8953479766845702
- 2.5947627703348797
- 2.57434458732605
- 2.5327154223124184
- 2.6065912501017254
- 2.610434824625651
- 2.6589263470967612
- 2.61061318397522
- 2.686025791168213
- 2.737624928156535
- 2.5725710868835447
- 2.4818054898579915
- 2.591602045694987
- 2.6611268806457518
- 2.57955096244812
- 2.49848051071167
- 2.516169605255127
- 2.548680168787638
- 2.3839427344004314
- 2.462959124247233
- 2.380194142659505
- 2.4563043212890623
- 2.4880482800801595
- 2.4147044086456297
- 2.40912371635437
- 2.5183888912200927
- 2.4135736878712972
- 2.4495001204808555
- 2.2576619895299275
- 2.477368459701538
- 2.36489248752594
- 2.492781778971354
- 2.4050905529657998
- 2.361014200846354
- 2.356054449081421
- 2.3994583638509113
- 2.2228049182891847
- 2.4187498172124227
- 2.418487861951192
- 2.462378436724345
- 2.4849818404515585
- 2.252368106842041
- 2.2864206155141193
- 2.400261729558309
- 2.2981385660171507
- 2.3191774320602416
- 2.164527633984884
- 2.31152458190918
- 2.234895675977071
- 2.2687368106842043
- 2.1419067509969074
- 2.197454465230306
- 2.1021713177363077
- 2.265107258160909
- 2.130277468363444
- 2.1695092312494912
- 2.3240034262339275
- 2.1778509696324666
- 2.214829053878784
- 2.212929476102193
- 2.0385758797327678
- 2.2310234117507934
- 2.1165948136647543
- 2.2417949644724526
- 1.9879226239522299
- 2.197932318051656
- 2.2054359022776286
- 2.1235320234298705
- 2.2159377749760947
- 2.023941157658895
- 2.0727787669499715
- 2.1414448690414427
- 1.9826254971822104
- 2.1647201124827067
- 1.9967516660690308
- 2.0730047464370727
- 2.040610373814901
- 2.06648099899292
- 2.0034883721669514
- 2.0646215788523357
- 2.176602980295817
- 1.8913737773895263
- 2.1529167175292967
- 1.8395202000935873
train_accuracy:
- 0.0
- 0.14
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.644
- 0.0
- 0.0
- 0.633
- 0.0
- 0.675
- 0.0
- 0.725
- 0.0
- 0.31
- 0.713
- 0.708
- 0.75
- 0.742
- 0.0
- 0.0
- 0.0
- 0.771
- 0.0
- 0.75
- 0.781
- 0.763
- 0.0
- 0.0
- 0.8
- 0.779
- 0.0
- 0.787
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.796
- 0.802
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.808
- 0.823
- 0.0
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.0
- 0.81
- 0.002
- 0.0
- 0.0
- 0.802
- 0.821
- 0.0
- 0.796
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.8
- 0.0
- 0.8
- 0.0
- 0.002
- 0.812
- 0.002
- 0.808
- 0.002
- 0.0
- 0.812
- 0.0
- 0.812
- 0.002
- 0.0
- 0.821
- 0.808
- 0.833
- 0.002
- 0.0
- 0.835
- 0.002
- 0.513
train_loss:
- 2.219
- 1.584
- 0.993
- 0.859
- 1.085
- 1.335
- 0.973
- 0.915
- 0.86
- 1.057
- 0.795
- 0.789
- 0.965
- 0.959
- 0.736
- 0.895
- 0.884
- 0.35
- 0.892
- 0.481
- 0.653
- 0.644
- 0.812
- 0.636
- 0.622
- 0.764
- 0.622
- 0.436
- 0.595
- 0.74
- 0.584
- 0.584
- 0.574
- 0.554
- 0.427
- 0.538
- 0.407
- 0.536
- 0.685
- 0.532
- 0.524
- 0.652
- 0.527
- 0.521
- 0.385
- 0.505
- 0.513
- 0.621
- 0.504
- 0.5
- 0.489
- 0.484
- 0.346
- 0.614
- 0.598
- 0.588
- 0.576
- 0.495
- 0.459
- 0.58
- 0.478
- 0.448
- 0.48
- 0.587
- 0.454
- 0.46
- 0.349
- 0.459
- 0.347
- 0.573
- 0.339
- 0.451
- 0.548
- 0.442
- 0.545
- 0.445
- 0.332
- 0.553
- 0.443
- 0.537
- 0.334
- 0.43
- 0.545
- 0.429
- 0.524
- 0.32
- 0.414
- 0.545
- 0.32
- 0.533
- 0.327
- 0.408
- 0.422
- 0.421
- 0.412
- 0.422
- 0.512
- 0.321
- 0.522
- 0.209
unequal: 0
verbose: 1
