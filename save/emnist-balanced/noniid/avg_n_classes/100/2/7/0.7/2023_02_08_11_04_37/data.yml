avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033882978723404254
- 0.14446808510638298
- 0.2498404255319149
- 0.3267553191489362
- 0.3647872340425532
- 0.3901063829787234
- 0.4144148936170213
- 0.4358510638297872
- 0.4380851063829787
- 0.4507978723404255
- 0.46627659574468083
- 0.4740957446808511
- 0.4796808510638298
- 0.4871808510638298
- 0.4851595744680851
- 0.5013829787234042
- 0.5043617021276596
- 0.5046808510638298
- 0.5095744680851064
- 0.510531914893617
- 0.5163297872340425
- 0.5256914893617022
- 0.5224468085106383
- 0.5261702127659574
- 0.5292553191489362
- 0.5305851063829787
- 0.5242553191489362
- 0.5345744680851063
- 0.5327659574468085
- 0.5367021276595745
- 0.5404255319148936
- 0.5446808510638298
- 0.5404787234042553
- 0.5425
- 0.5478191489361702
- 0.5486170212765957
- 0.5457978723404255
- 0.5469148936170213
- 0.5507978723404255
- 0.5532446808510638
- 0.5532978723404255
- 0.5552127659574468
- 0.5548404255319149
- 0.558031914893617
- 0.5604787234042553
- 0.5598936170212766
- 0.559468085106383
- 0.5604255319148936
- 0.5596276595744681
- 0.5618617021276596
- 0.5602127659574468
- 0.5633510638297873
- 0.5612765957446808
- 0.56
- 0.5650531914893617
- 0.5657978723404256
- 0.5657978723404256
- 0.5662765957446808
- 0.5677127659574468
- 0.5661170212765958
- 0.5684574468085106
- 0.5703723404255319
- 0.568936170212766
- 0.569468085106383
- 0.565
- 0.5687765957446809
- 0.5695744680851064
- 0.5703723404255319
- 0.5712234042553191
- 0.5727127659574468
- 0.5707446808510638
- 0.5719148936170213
- 0.5747872340425532
- 0.5737234042553192
- 0.5776595744680851
- 0.5740425531914893
- 0.5761702127659575
- 0.5748936170212766
- 0.5742553191489361
- 0.5753723404255319
- 0.5771808510638298
- 0.5767021276595745
- 0.5795212765957447
- 0.5809574468085107
- 0.5802127659574469
- 0.579095744680851
- 0.5775531914893617
- 0.5792553191489361
- 0.5820212765957447
- 0.5801595744680851
- 0.579095744680851
- 0.5793085106382979
- 0.581063829787234
- 0.5802127659574469
- 0.5821808510638298
- 0.5832446808510638
- 0.5832978723404255
- 0.5826063829787234
- 0.5828723404255319
- 0.5818617021276595
test_loss_list:
- 3.7617833614349365
- 3.6299218463897707
- 3.3420499547322593
- 3.1041665077209473
- 3.0029812812805177
- 2.857918752034505
- 2.944341395696004
- 2.8634503173828123
- 2.758936513264974
- 2.819369099934896
- 2.822557741800944
- 2.8325090408325195
- 2.715450226465861
- 2.740283654530843
- 2.653570534388224
- 2.835651222864787
- 2.7653119405110678
- 2.7849661858876544
- 2.6846665128072105
- 2.6474067306518556
- 2.6573137919108074
- 2.755951150258382
- 2.599679288864136
- 2.608023821512858
- 2.653324632644653
- 2.7020500691731772
- 2.483972670237223
- 2.6304544512430827
- 2.5965671062469484
- 2.5021314175923663
- 2.46732905069987
- 2.5972275638580324
- 2.4785461107889812
- 2.3204863405227663
- 2.53747673034668
- 2.553715721766154
- 2.4118829441070555
- 2.4478807640075684
- 2.3848614645004274
- 2.384628791809082
- 2.3509893480936688
- 2.335468783378601
- 2.219324280420939
- 2.3400864092508953
- 2.412157713572184
- 2.3011372582117717
- 2.261434030532837
- 2.241214509010315
- 2.149964761734009
- 2.2014102013905843
- 2.1502781438827516
- 2.1692125018437705
- 2.195713858604431
- 2.1311388635635375
- 2.135820253690084
- 2.282497550646464
- 2.159838857650757
- 2.253919736544291
- 2.2332578563690184
- 2.1747460762659707
- 2.0934828027089436
- 2.1906653881072997
- 2.2272041336695354
- 2.1105275678634645
- 2.0012237803141275
- 2.090130713780721
- 2.123521253267924
- 2.0273258606592814
- 2.187946105003357
- 2.0480267365773517
- 2.03633620262146
- 2.13606902440389
- 2.0552194627126057
- 1.9900628185272218
- 2.0083408737182618
- 1.910710317293803
- 1.9129571501413982
- 1.9661720323562621
- 1.9637814696629843
- 2.0723380502065023
- 1.9549928124745686
- 2.0009427865346274
- 1.9658995151519776
- 1.9414157978693645
- 1.885324764251709
- 1.9336673561731974
- 1.9473973592122396
- 1.929587370554606
- 1.9219591108957927
- 1.9979461669921874
- 1.8899207480748494
- 1.9979687547683715
- 1.8148602437973023
- 1.835772787729899
- 1.8408414856592814
- 1.8991124391555787
- 1.840600102742513
- 1.8456503915786744
- 1.9675815121332805
- 1.8585236024856568
train_accuracy:
- 0.037
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.702
- 0.0
- 0.0
- 0.733
- 0.0
- 0.0
- 0.725
- 0.0
- 0.0
- 0.694
- 0.735
- 0.0
- 0.0
- 0.744
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.777
- 0.0
- 0.0
- 0.0
- 0.773
- 0.0
- 0.0
- 0.0
- 0.002
- 0.765
- 0.002
- 0.006
- 0.785
- 0.785
- 0.006
- 0.002
- 0.01
- 0.023
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.798
- 0.0
- 0.819
- 0.0
- 0.0
- 0.808
- 0.002
- 0.0
- 0.798
- 0.002
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.846
- 0.0
- 0.848
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.806
- 0.835
- 0.812
- 0.0
- 0.806
- 0.838
- 0.002
- 0.002
- 0.002
- 0.865
- 0.0
- 0.0
- 0.0
- 0.0
- 0.017
- 0.0
- 0.819
- 0.002
- 0.0
- 0.0
- 0.0
train_loss:
- 1.661
- 1.443
- 0.903
- 1.127
- 1.015
- 0.67
- 1.154
- 1.084
- 0.605
- 0.799
- 0.989
- 0.968
- 0.766
- 0.754
- 0.529
- 0.864
- 0.855
- 0.852
- 0.654
- 0.664
- 0.647
- 0.779
- 0.644
- 0.617
- 0.765
- 0.768
- 0.463
- 0.729
- 0.594
- 0.604
- 0.578
- 0.707
- 0.556
- 0.425
- 0.696
- 0.685
- 0.541
- 0.535
- 0.548
- 0.525
- 0.535
- 0.522
- 0.397
- 0.501
- 0.641
- 0.521
- 0.516
- 0.513
- 0.38
- 0.494
- 0.379
- 0.502
- 0.484
- 0.356
- 0.491
- 0.594
- 0.486
- 0.591
- 0.599
- 0.473
- 0.478
- 0.586
- 0.579
- 0.464
- 0.351
- 0.46
- 0.581
- 0.465
- 0.565
- 0.464
- 0.448
- 0.581
- 0.451
- 0.451
- 0.457
- 0.336
- 0.325
- 0.432
- 0.447
- 0.543
- 0.432
- 0.416
- 0.435
- 0.428
- 0.446
- 0.441
- 0.44
- 0.425
- 0.418
- 0.519
- 0.437
- 0.534
- 0.319
- 0.413
- 0.424
- 0.417
- 0.423
- 0.431
- 0.515
- 0.427
unequal: 0
verbose: 1
