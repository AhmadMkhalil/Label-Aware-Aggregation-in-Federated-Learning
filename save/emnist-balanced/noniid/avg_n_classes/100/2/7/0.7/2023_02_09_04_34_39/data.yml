avg_train_accuracy: 0.0
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03765957446808511
- 0.12888297872340426
- 0.23420212765957446
- 0.31111702127659574
- 0.36186170212765956
- 0.3798404255319149
- 0.4048936170212766
- 0.4173404255319149
- 0.4405851063829787
- 0.449468085106383
- 0.4468617021276596
- 0.46547872340425533
- 0.45909574468085107
- 0.47175531914893615
- 0.4777127659574468
- 0.48898936170212765
- 0.4844148936170213
- 0.4957446808510638
- 0.5031914893617021
- 0.5048404255319149
- 0.506968085106383
- 0.510531914893617
- 0.5061702127659574
- 0.517127659574468
- 0.5228191489361702
- 0.5230851063829787
- 0.5283510638297872
- 0.5282446808510638
- 0.531063829787234
- 0.5329255319148937
- 0.5386170212765957
- 0.5371276595744681
- 0.5404787234042553
- 0.5419148936170213
- 0.5452127659574468
- 0.5452127659574468
- 0.5471276595744681
- 0.5492021276595744
- 0.5483510638297873
- 0.5529787234042554
- 0.5520744680851064
- 0.5543617021276596
- 0.5561170212765958
- 0.5513829787234042
- 0.553936170212766
- 0.5581914893617022
- 0.5578723404255319
- 0.5586170212765957
- 0.5568617021276596
- 0.556063829787234
- 0.5605851063829788
- 0.5622872340425532
- 0.5613297872340426
- 0.5621808510638298
- 0.5648936170212766
- 0.563404255319149
- 0.5682978723404255
- 0.5688297872340425
- 0.5663297872340426
- 0.5678723404255319
- 0.5673936170212766
- 0.5674468085106383
- 0.5675531914893617
- 0.568936170212766
- 0.5687765957446809
- 0.5716489361702127
- 0.5685106382978723
- 0.5718617021276595
- 0.5689893617021277
- 0.5717021276595745
- 0.570531914893617
- 0.5718617021276595
- 0.5740425531914893
- 0.5727659574468085
- 0.5730851063829787
- 0.5774468085106383
- 0.5767553191489362
- 0.5759042553191489
- 0.5756382978723404
- 0.5742021276595745
- 0.5794680851063829
- 0.5746808510638298
- 0.5769148936170213
- 0.5782446808510638
- 0.5761170212765957
- 0.5779255319148936
- 0.5788829787234042
- 0.578936170212766
- 0.5816489361702127
- 0.5765425531914894
- 0.5796808510638298
- 0.583936170212766
- 0.5820744680851064
- 0.5827659574468085
- 0.5763829787234043
- 0.5823936170212766
- 0.5833510638297872
- 0.5794680851063829
- 0.5811170212765957
- 0.583404255319149
test_loss_list:
- 3.7811572647094724
- 3.6597921148935955
- 3.387823289235433
- 3.1408065605163573
- 2.994261744817098
- 2.9012374941507977
- 2.911902551651001
- 2.8243124198913576
- 2.830060370763143
- 2.823424987792969
- 2.6916906452178955
- 2.8170529270172118
- 2.6163104248046873
- 2.6623944250742593
- 2.673733456929525
- 2.737101043065389
- 2.530389413833618
- 2.7174633344014487
- 2.6874172337849935
- 2.6219521713256837
- 2.681534833908081
- 2.532941786448161
- 2.4796140988667807
- 2.5611648591359457
- 2.575407536824544
- 2.4537852414449057
- 2.5607069301605225
- 2.43223508199056
- 2.5357346216837566
- 2.3811788749694824
- 2.544527988433838
- 2.417358700434367
- 2.4909164619445803
- 2.3665586694081626
- 2.4021212450663247
- 2.3051878801981607
- 2.350910113652547
- 2.3162940724690757
- 2.2812509139378867
- 2.292913057009379
- 2.143808445930481
- 2.3801598167419433
- 2.3796441332499185
- 2.194234913190206
- 2.2251605304082234
- 2.3552765623728433
- 2.188815221786499
- 2.159850719769796
- 2.084609308242798
- 2.071617987950643
- 2.107559243837992
- 2.1839361937840778
- 2.157910834948222
- 2.1584865760803225
- 2.2273649390538535
- 2.21239022731781
- 2.1023125982284547
- 2.210969815254211
- 2.1815834029515586
- 2.2169503752390542
- 2.212156217892965
- 2.1033606068293254
- 2.054017415046692
- 2.2049427461624145
- 2.086785411834717
- 2.1844568173090617
- 2.0015683046976727
- 2.1578257687886557
- 1.9692860078811645
- 2.1157956965764364
- 2.0770766655604045
- 2.0111476151148477
- 1.997826805114746
- 2.117116314570109
- 2.035798128445943
- 1.9629890028635661
- 1.9891981856028238
- 1.9057395553588867
- 1.9153596099217733
- 1.9808862860997518
- 1.9119106992085775
- 1.8555745267868042
- 1.9357526048024496
- 2.065592567125956
- 1.9234642028808593
- 1.919954301516215
- 1.909522066116333
- 1.9852583471934
- 1.9105945571263632
- 1.8435122092564902
- 1.9876346810658774
- 1.7551405493418375
- 1.993744928042094
- 2.0067553520202637
- 1.8077417389551798
- 1.9938436396916708
- 1.8910663684209188
- 1.775509705543518
- 1.910748405456543
- 1.8701080385843913
train_accuracy:
- 0.054
- 0.19
- 0.321
- 0.0
- 0.529
- 0.0
- 0.0
- 0.0
- 0.0
- 0.631
- 0.0
- 0.0
- 0.644
- 0.0
- 0.0
- 0.0
- 0.0
- 0.704
- 0.756
- 0.0
- 0.694
- 0.76
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.735
- 0.0
- 0.002
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.815
- 0.812
- 0.0
- 0.004
- 0.785
- 0.792
- 0.831
- 0.763
- 0.002
- 0.002
- 0.002
- 0.004
- 0.002
- 0.806
- 0.0
- 0.0
- 0.01
- 0.798
- 0.002
- 0.794
- 0.004
- 0.006
- 0.0
- 0.008
- 0.01
- 0.0
- 0.004
- 0.01
- 0.0
- 0.846
- 0.004
- 0.002
- 0.0
- 0.0
- 0.0
- 0.037
- 0.0
- 0.002
- 0.002
- 0.806
- 0.037
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.825
- 0.0
- 0.0
- 0.81
- 0.16
- 0.008
- 0.0
- 0.0
- 0.812
- 0.821
- 0.0
- 0.808
- 0.0
train_loss:
- 1.625
- 1.429
- 1.268
- 1.107
- 1.014
- 0.635
- 0.861
- 0.844
- 1.052
- 1.031
- 0.553
- 0.938
- 0.528
- 0.719
- 0.699
- 0.871
- 0.496
- 0.841
- 0.813
- 0.636
- 0.789
- 0.623
- 0.449
- 0.769
- 0.751
- 0.598
- 0.73
- 0.569
- 0.727
- 0.547
- 0.678
- 0.561
- 0.698
- 0.546
- 0.526
- 0.522
- 0.509
- 0.51
- 0.509
- 0.512
- 0.361
- 0.617
- 0.62
- 0.361
- 0.495
- 0.6
- 0.48
- 0.487
- 0.359
- 0.354
- 0.486
- 0.456
- 0.467
- 0.459
- 0.577
- 0.599
- 0.455
- 0.559
- 0.595
- 0.572
- 0.564
- 0.446
- 0.467
- 0.548
- 0.449
- 0.558
- 0.458
- 0.56
- 0.339
- 0.553
- 0.433
- 0.426
- 0.415
- 0.543
- 0.412
- 0.436
- 0.427
- 0.436
- 0.417
- 0.405
- 0.407
- 0.305
- 0.414
- 0.519
- 0.413
- 0.417
- 0.416
- 0.512
- 0.4
- 0.305
- 0.503
- 0.297
- 0.514
- 0.51
- 0.303
- 0.505
- 0.397
- 0.294
- 0.398
- 0.392
unequal: 0
verbose: 1
