avg_train_accuracy: 0.846
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026382978723404255
- 0.13047872340425531
- 0.19425531914893618
- 0.26335106382978724
- 0.3147872340425532
- 0.3507446808510638
- 0.3698936170212766
- 0.38978723404255317
- 0.4117021276595745
- 0.414468085106383
- 0.4395212765957447
- 0.4356914893617021
- 0.455
- 0.4648404255319149
- 0.4665957446808511
- 0.4748936170212766
- 0.4740957446808511
- 0.4874468085106383
- 0.47925531914893615
- 0.5016489361702128
- 0.5032446808510638
- 0.5032446808510638
- 0.5066489361702128
- 0.5074468085106383
- 0.5147340425531914
- 0.5128723404255319
- 0.5196808510638298
- 0.5203191489361703
- 0.5229787234042553
- 0.5248404255319149
- 0.5288297872340425
- 0.5309574468085106
- 0.531063829787234
- 0.5296808510638298
- 0.5364893617021277
- 0.5357978723404255
- 0.541968085106383
- 0.5376595744680851
- 0.5438829787234043
- 0.5428723404255319
- 0.540904255319149
- 0.548936170212766
- 0.5473404255319149
- 0.5409574468085107
- 0.5514361702127659
- 0.5518085106382978
- 0.5475531914893617
- 0.5523404255319149
- 0.5537234042553192
- 0.5540425531914893
- 0.5575531914893617
- 0.5546808510638298
- 0.5556914893617021
- 0.5548404255319149
- 0.5580851063829787
- 0.5602127659574468
- 0.5585106382978723
- 0.5622340425531915
- 0.5622340425531915
- 0.5576063829787234
- 0.5626063829787235
- 0.5640957446808511
- 0.5631382978723404
- 0.563031914893617
- 0.5631914893617022
- 0.5686170212765957
- 0.5673936170212766
- 0.5652659574468085
- 0.5695744680851064
- 0.5690957446808511
- 0.5700531914893617
- 0.5674468085106383
- 0.5686170212765957
- 0.5701063829787234
- 0.5717021276595745
- 0.5710106382978724
- 0.5678723404255319
- 0.569468085106383
- 0.571063829787234
- 0.5702127659574469
- 0.5701063829787234
- 0.5759042553191489
- 0.5728191489361703
- 0.5740425531914893
- 0.578404255319149
- 0.5778191489361703
- 0.5748936170212766
- 0.573936170212766
- 0.5762234042553191
- 0.578404255319149
- 0.5777659574468085
- 0.5789893617021277
- 0.5777127659574468
- 0.5787765957446809
- 0.5752659574468085
- 0.5793085106382979
- 0.5793617021276596
- 0.5778723404255319
- 0.5809574468085107
- 0.5794148936170213
test_loss_list:
- 3.783050578435262
- 3.6801134554545083
- 3.444277276992798
- 3.217396189371745
- 3.0827128505706787
- 3.0193244075775145
- 2.9199296061197915
- 2.8526422278086345
- 2.8438275814056397
- 2.7790362644195556
- 2.829042148590088
- 2.687563339869181
- 2.769447822570801
- 2.783924328486125
- 2.7107658926645914
- 2.7083440844217934
- 2.580440212885539
- 2.66379487991333
- 2.5177814896901447
- 2.7023961702982584
- 2.6533246580759684
- 2.6823437213897705
- 2.661628710428874
- 2.5287562783559165
- 2.673962109883626
- 2.551479552586873
- 2.5993222173055015
- 2.4865469392140707
- 2.5297063700358073
- 2.503847672144572
- 2.5678692881266274
- 2.553537645339966
- 2.4353435643514
- 2.31176726659139
- 2.4088622919718423
- 2.3127451578776044
- 2.5034797096252444
- 2.2562375926971434
- 2.3851729011535645
- 2.3586590544382733
- 2.3031001567840574
- 2.3885906251271565
- 2.3329797919591266
- 2.1446656783421836
- 2.3733809343973795
- 2.298802056312561
- 2.197339833577474
- 2.228332460721334
- 2.3514208793640137
- 2.2535897811253864
- 2.3422964318593342
- 2.3450511344273886
- 2.1935675032933553
- 2.2361666425069173
- 2.28283761660258
- 2.3339245319366455
- 2.258340400060018
- 2.2835144090652464
- 2.115103645324707
- 2.0909076944986977
- 2.2883806848526
- 2.1444042332967124
- 2.3112176672617593
- 2.104464990297953
- 2.0441238705317177
- 2.2875580072402952
- 2.1349727741877236
- 2.0552008660634358
- 2.0850660022099814
- 2.1670192750295003
- 2.0865497239430746
- 2.0513549121220906
- 1.9646122948328655
- 2.0418820905685426
- 2.008421460787455
- 2.057252469062805
- 1.9661236095428467
- 2.0663711818059287
- 2.0510372591018675
- 1.9828430716196697
- 2.0297068405151366
- 1.9623223527272542
- 1.9310143311818442
- 2.1208752632141112
- 2.0798436212539673
- 2.0800108019510906
- 1.894698553085327
- 1.8948270654678345
- 1.8244527260462442
- 1.8475113519032795
- 1.927666850090027
- 1.797503965695699
- 2.0340113274256386
- 1.9020525868733724
- 1.8043467855453492
- 1.8318438450495402
- 2.026276111602783
- 1.8923608620961507
- 2.0107843351364134
- 1.9951903088887533
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.45
- 0.521
- 0.0
- 0.0
- 0.0
- 0.569
- 0.0
- 0.0
- 0.0
- 0.692
- 0.694
- 0.0
- 0.0
- 0.715
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.698
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.781
- 0.0
- 0.0
- 0.0
- 0.737
- 0.0
- 0.0
- 0.0
- 0.787
- 0.002
- 0.796
- 0.0
- 0.0
- 0.765
- 0.806
- 0.0
- 0.76
- 0.798
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.808
- 0.0
- 0.79
- 0.0
- 0.0
- 0.006
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.0
- 0.0
- 0.842
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.785
- 0.808
- 0.819
- 0.794
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.0
- 0.004
- 0.0
- 0.794
- 0.0
- 0.846
train_loss:
- 1.707
- 1.078
- 0.958
- 1.162
- 1.119
- 1.057
- 0.943
- 0.715
- 0.861
- 0.651
- 0.875
- 0.62
- 0.971
- 1.008
- 0.775
- 0.764
- 0.594
- 0.759
- 0.563
- 0.901
- 0.883
- 0.838
- 0.816
- 0.63
- 0.852
- 0.618
- 0.831
- 0.647
- 0.6
- 0.633
- 0.784
- 0.787
- 0.582
- 0.432
- 0.577
- 0.416
- 0.742
- 0.422
- 0.585
- 0.594
- 0.583
- 0.714
- 0.56
- 0.438
- 0.683
- 0.577
- 0.441
- 0.52
- 0.675
- 0.512
- 0.649
- 0.677
- 0.419
- 0.553
- 0.624
- 0.607
- 0.662
- 0.627
- 0.536
- 0.423
- 0.649
- 0.481
- 0.647
- 0.524
- 0.4
- 0.637
- 0.502
- 0.387
- 0.507
- 0.582
- 0.497
- 0.466
- 0.378
- 0.457
- 0.497
- 0.488
- 0.387
- 0.497
- 0.486
- 0.449
- 0.471
- 0.388
- 0.37
- 0.578
- 0.559
- 0.598
- 0.366
- 0.36
- 0.352
- 0.358
- 0.475
- 0.326
- 0.528
- 0.357
- 0.36
- 0.353
- 0.571
- 0.46
- 0.568
- 0.565
unequal: 0
verbose: 1
