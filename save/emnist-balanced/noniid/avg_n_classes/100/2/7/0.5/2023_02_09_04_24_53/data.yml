avg_train_accuracy: 0.823
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03553191489361702
- 0.1099468085106383
- 0.2298404255319149
- 0.30648936170212765
- 0.35154255319148936
- 0.37882978723404254
- 0.08882978723404256
- 0.09329787234042553
- 0.4097340425531915
- 0.4220744680851064
- 0.16042553191489362
- 0.44398936170212766
- 0.45324468085106384
- 0.460531914893617
- 0.46824468085106385
- 0.47962765957446807
- 0.4815957446808511
- 0.49361702127659574
- 0.5030851063829788
- 0.49425531914893617
- 0.5016489361702128
- 0.5115957446808511
- 0.5146808510638298
- 0.517127659574468
- 0.5254787234042553
- 0.526595744680851
- 0.5337234042553192
- 0.5273936170212766
- 0.5321276595744681
- 0.5342021276595744
- 0.5354787234042553
- 0.5405851063829787
- 0.5423936170212766
- 0.5395744680851063
- 0.5370212765957447
- 0.5486702127659574
- 0.5467021276595745
- 0.5483510638297873
- 0.5513829787234042
- 0.5481382978723405
- 0.5497340425531915
- 0.5528723404255319
- 0.5481382978723405
- 0.5551595744680851
- 0.5546808510638298
- 0.556063829787234
- 0.5561170212765958
- 0.5564361702127659
- 0.31446808510638297
- 0.5568617021276596
- 0.3741489361702128
- 0.5585638297872341
- 0.5597872340425532
- 0.5602659574468085
- 0.5618085106382978
- 0.5580851063829787
- 0.3410106382978723
- 0.563031914893617
- 0.5647872340425532
- 0.5622872340425532
- 0.5603191489361702
- 0.5583510638297873
- 0.5646808510638298
- 0.5650531914893617
- 0.5642021276595744
- 0.5700531914893617
- 0.5639893617021277
- 0.5685638297872341
- 0.5704255319148936
- 0.5703723404255319
- 0.4599468085106383
- 0.5688829787234042
- 0.5743617021276596
- 0.5726063829787233
- 0.5693617021276596
- 0.5716489361702127
- 0.5725
- 0.5761702127659575
- 0.5757978723404256
- 0.5725531914893617
- 0.5749468085106383
- 0.5756914893617021
- 0.5769148936170213
- 0.5776595744680851
- 0.5776063829787234
- 0.5774468085106383
- 0.5751595744680851
- 0.5769148936170213
- 0.5785638297872341
- 0.5781382978723404
- 0.4551063829787234
- 0.5784574468085106
- 0.5777127659574468
- 0.581436170212766
- 0.5125531914893617
- 0.5853723404255319
- 0.5845212765957447
- 0.5863829787234043
- 0.5808510638297872
- 0.5838297872340426
test_loss_list:
- 3.8027710501352945
- 3.7496662839253743
- 3.5065838273366294
- 3.2984888617197674
- 3.18034005800883
- 3.1379701137542724
- 3.6038087240854897
- 4.713068968454997
- 2.963105754852295
- 2.862190326054891
- 3.277598638534546
- 2.861668488184611
- 2.8788215986887615
- 2.8328398640950523
- 2.817652327219645
- 2.850937935511271
- 2.809169012705485
- 2.9204994169871012
- 2.9457245190938313
- 2.691610994338989
- 2.8354897753397625
- 2.814868513743083
- 2.832161973317464
- 2.6944162940979
- 3.055004618962606
- 2.824241803487142
- 2.8947116820017498
- 2.6979957548777262
- 2.7197140725453695
- 2.849176565806071
- 2.7357917149861652
- 2.9091299947102867
- 2.9232462501525878
- 2.673257964452108
- 2.6861936473846435
- 3.0066909472147625
- 2.7981800492604574
- 2.810631554921468
- 2.809766019185384
- 2.6519891293843587
- 2.7493385060628257
- 2.7581008593241374
- 2.6351422754923504
- 2.5882966327667236
- 2.6029468727111817
- 2.588644402821859
- 2.6193903350830077
- 2.533627077738444
- 2.705282392501831
- 2.2191628281275433
- 2.1998828220367432
- 2.1763561964035034
- 2.2966106923421226
- 2.260911127726237
- 2.341957289377848
- 2.296973829269409
- 2.3417094230651854
- 2.080914022127787
- 2.369958060582479
- 2.3336737076441447
- 2.2619203424453733
- 2.260304152170817
- 2.3879380416870117
- 2.4701057402292887
- 2.298946868578593
- 2.3453200387954714
- 2.2886792055765786
- 2.4353890450795492
- 2.4213184928894043
- 2.268026844660441
- 1.8779800446828205
- 1.9953288062413534
- 2.208460267384847
- 2.2759748856226603
- 2.16662859916687
- 2.1755159425735475
- 2.2128687413533528
- 2.365443967183431
- 2.29466556708018
- 2.166311920483907
- 2.325961152712504
- 2.3167175022761026
- 2.299010025660197
- 2.410365966161092
- 2.3708218479156495
- 2.3447367509206134
- 2.216537014643351
- 2.285931806564331
- 2.5497337500254313
- 2.2694230969746907
- 1.9225831572214762
- 1.9980186065038046
- 2.0022765032450356
- 2.210220956802368
- 1.678146727879842
- 1.9801321585973104
- 2.104720805486043
- 1.97280987739563
- 2.0736632331212363
- 2.2676259406407673
train_accuracy:
- 0.0
- 0.171
- 0.0
- 0.456
- 0.556
- 0.0
- 0.0
- 0.108
- 0.0
- 0.617
- 0.435
- 0.0
- 0.0
- 0.0
- 0.706
- 0.0
- 0.0
- 0.0
- 0.0
- 0.696
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.765
- 0.775
- 0.775
- 0.779
- 0.0
- 0.0
- 0.0
- 0.796
- 0.0
- 0.0
- 0.004
- 0.0
- 0.0
- 0.0
- 0.0
- 0.8
- 0.002
- 0.0
- 0.796
- 0.0
- 0.523
- 0.0
- 0.66
- 0.008
- 0.008
- 0.0
- 0.817
- 0.006
- 0.965
- 0.0
- 0.819
- 0.808
- 0.0
- 0.8
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.827
- 0.823
- 0.608
- 0.0
- 0.81
- 0.817
- 0.0
- 0.0
- 0.0
- 0.819
- 0.0
- 0.0
- 0.0
- 0.831
- 0.0
- 0.829
- 0.0
- 0.0
- 0.815
- 0.0
- 0.821
- 0.835
- 0.79
- 0.017
- 0.821
- 0.0
- 0.754
- 0.044
- 0.0
- 0.0
- 0.0
- 0.823
train_loss:
- 1.947
- 1.82
- 1.616
- 0.931
- 0.831
- 0.746
- 0.413
- 0.245
- 1.542
- 0.691
- 0.354
- 0.995
- 0.924
- 0.944
- 0.602
- 0.865
- 0.572
- 0.849
- 0.822
- 0.558
- 0.511
- 0.779
- 0.779
- 0.513
- 0.968
- 0.708
- 0.684
- 0.526
- 0.458
- 0.729
- 0.466
- 0.673
- 0.707
- 0.475
- 0.516
- 0.854
- 0.671
- 0.67
- 0.652
- 0.46
- 0.619
- 0.605
- 0.465
- 0.433
- 0.475
- 0.461
- 0.611
- 0.469
- 0.268
- 0.437
- 0.248
- 0.39
- 0.392
- 0.387
- 0.573
- 0.408
- 0.24
- 0.385
- 0.555
- 0.359
- 0.393
- 0.378
- 0.529
- 0.528
- 0.38
- 0.596
- 0.404
- 0.541
- 0.567
- 0.427
- 0.224
- 0.349
- 0.547
- 0.508
- 0.408
- 0.4
- 0.363
- 0.495
- 0.525
- 0.393
- 0.537
- 0.52
- 0.514
- 0.67
- 0.507
- 0.518
- 0.359
- 0.533
- 0.647
- 0.366
- 0.236
- 0.313
- 0.353
- 0.484
- 0.22
- 0.46
- 0.309
- 0.379
- 0.483
- 0.628
unequal: 0
verbose: 1
