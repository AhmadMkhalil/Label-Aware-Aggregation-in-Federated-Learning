avg_train_accuracy: 0.842
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029095744680851063
- 0.05824468085106383
- 0.19287234042553192
- 0.29723404255319147
- 0.35367021276595745
- 0.3903723404255319
- 0.3930851063829787
- 0.41398936170212763
- 0.4182446808510638
- 0.4390425531914894
- 0.4481914893617021
- 0.45335106382978724
- 0.46574468085106385
- 0.4642553191489362
- 0.4807446808510638
- 0.47840425531914893
- 0.47888297872340424
- 0.24627659574468086
- 0.48914893617021277
- 0.4954787234042553
- 0.49398936170212765
- 0.5057978723404255
- 0.5102659574468085
- 0.5109574468085106
- 0.5135106382978724
- 0.5201063829787234
- 0.5227659574468085
- 0.5210106382978723
- 0.35914893617021276
- 0.5234574468085106
- 0.5257978723404255
- 0.5248404255319149
- 0.5275531914893618
- 0.5313829787234042
- 0.5292553191489362
- 0.5343085106382979
- 0.5353191489361702
- 0.5390425531914894
- 0.538936170212766
- 0.5429787234042553
- 0.5456382978723404
- 0.538936170212766
- 0.5481914893617021
- 0.5408510638297872
- 0.5426063829787234
- 0.5464361702127659
- 0.4223936170212766
- 0.5511170212765958
- 0.5511170212765958
- 0.5495744680851063
- 0.5504787234042553
- 0.5501063829787234
- 0.5525531914893617
- 0.555372340425532
- 0.5145744680851064
- 0.4871276595744681
- 0.5543617021276596
- 0.5542553191489362
- 0.5588297872340425
- 0.5593617021276596
- 0.5604255319148936
- 0.5598936170212766
- 0.5630851063829787
- 0.5602659574468085
- 0.563936170212766
- 0.5664361702127659
- 0.5657978723404256
- 0.5656382978723404
- 0.5685638297872341
- 0.5681382978723404
- 0.5658510638297872
- 0.5677127659574468
- 0.5716489361702127
- 0.5704255319148936
- 0.5702659574468085
- 0.5415425531914894
- 0.5723404255319149
- 0.5692553191489361
- 0.5725
- 0.5683510638297873
- 0.5703723404255319
- 0.5728191489361703
- 0.5705851063829788
- 0.5736170212765958
- 0.5727127659574468
- 0.5654255319148936
- 0.5786702127659574
- 0.5473404255319149
- 0.49675531914893617
- 0.5826063829787234
- 0.5532446808510638
- 0.5812765957446808
- 0.5798404255319148
- 0.5779787234042553
- 0.5765425531914894
- 0.5788829787234042
- 0.5767021276595745
- 0.5775
- 0.5729255319148936
- 0.5747872340425532
test_loss_list:
- 3.806669209798177
- 3.773722972869873
- 3.6049027093251547
- 3.352514015833537
- 3.2205995019276936
- 3.1606500403086346
- 3.0192265033721926
- 3.0752748266855874
- 2.9714229170481365
- 3.1221935653686526
- 2.9713584327697755
- 3.0772607135772705
- 2.943764263788859
- 2.936047576268514
- 3.083990869522095
- 2.873643538157145
- 2.9263267358144125
- 2.9624882793426512
- 2.69551690419515
- 2.739777708053589
- 2.7086974970499673
- 2.921138286590576
- 3.0048154894510906
- 2.920074151357015
- 2.944845272699992
- 3.0617648792266845
- 2.968870897293091
- 2.8552706559499104
- 2.457795117696126
- 2.553210662206014
- 2.6654906177520754
- 2.611447671254476
- 2.7658710352579754
- 2.665921751658122
- 2.6967444705963133
- 2.7453293704986574
- 2.6638588333129882
- 2.623830474217733
- 2.5934523932139077
- 2.7809856700897218
- 2.8571288839975995
- 2.657122360865275
- 2.9430610688527423
- 2.676750268936157
- 2.5955840810139974
- 2.698071502049764
- 2.2106736787160237
- 2.412098379135132
- 2.4452989228566486
- 2.5944032923380536
- 2.4360014692942302
- 2.4492891057332358
- 2.487222496668498
- 2.5689741007486977
- 1.8529713090260824
- 1.7103155692418417
- 2.1399842071533204
- 2.205481948852539
- 2.3540096505482992
- 2.4135080273946126
- 2.4467784372965493
- 2.405826603571574
- 2.399817330042521
- 2.318534175554911
- 2.4375642426808675
- 2.487693157196045
- 2.3626084423065183
- 2.432569637298584
- 2.657950903574626
- 2.470091781616211
- 2.332495125134786
- 2.4093749872843424
- 2.463247454961141
- 2.4684621620178224
- 2.4721195761362713
- 1.6549139674504598
- 2.203280208905538
- 2.263704458872477
- 2.3823242791493735
- 2.2449703566233317
- 2.235251242319743
- 2.392260411580404
- 2.233481559753418
- 2.257145126660665
- 2.2124568208058677
- 1.6027575890223185
- 1.9488226318359374
- 1.623990052541097
- 1.6345466788609821
- 1.832782293955485
- 1.4282671817143757
- 1.7338766447703045
- 1.9665045611063638
- 1.864308099746704
- 2.06957258383433
- 2.192526399294535
- 2.0923297532399494
- 2.0593073638280233
- 2.005280179977417
- 2.0187810897827148
train_accuracy:
- 0.021
- 0.0
- 0.0
- 0.0
- 0.0
- 0.59
- 0.562
- 0.0
- 0.619
- 0.662
- 0.0
- 0.658
- 0.681
- 0.0
- 0.692
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.723
- 0.727
- 0.75
- 0.0
- 0.0
- 0.006
- 0.0
- 0.0
- 0.773
- 0.0
- 0.0
- 0.756
- 0.0
- 0.0
- 0.0
- 0.0
- 0.79
- 0.775
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.292
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.792
- 0.821
- 0.6
- 0.729
- 0.808
- 0.0
- 0.0
- 0.804
- 0.821
- 0.815
- 0.823
- 0.004
- 0.0
- 0.0
- 0.0
- 0.831
- 0.806
- 0.825
- 0.0
- 0.002
- 0.0
- 0.812
- 0.825
- 0.829
- 0.0
- 0.002
- 0.008
- 0.0
- 0.002
- 0.819
- 0.831
- 0.0
- 0.0
- 0.781
- 0.0
- 0.569
- 0.731
- 0.2
- 0.31
- 0.831
- 0.075
- 0.0
- 0.0
- 0.852
- 0.0
- 0.029
- 0.0
- 0.842
train_loss:
- 2.075
- 1.954
- 2.296
- 1.567
- 1.342
- 1.697
- 0.9
- 0.838
- 0.809
- 1.456
- 0.751
- 1.058
- 0.745
- 0.769
- 1.217
- 0.671
- 0.691
- 0.386
- 0.632
- 0.633
- 0.639
- 0.833
- 1.06
- 0.799
- 0.854
- 1.008
- 0.765
- 0.534
- 0.399
- 0.782
- 0.561
- 0.598
- 0.788
- 0.513
- 0.552
- 0.699
- 0.49
- 0.553
- 0.552
- 0.729
- 0.892
- 0.55
- 0.862
- 0.49
- 0.521
- 0.521
- 0.277
- 0.63
- 0.499
- 0.616
- 0.529
- 0.491
- 0.508
- 0.665
- 0.319
- 0.259
- 0.599
- 0.447
- 0.619
- 0.606
- 0.598
- 0.402
- 0.605
- 0.406
- 0.574
- 0.633
- 0.452
- 0.571
- 0.742
- 0.574
- 0.463
- 0.615
- 0.609
- 0.55
- 0.567
- 0.292
- 0.529
- 0.592
- 0.549
- 0.374
- 0.369
- 0.739
- 0.434
- 0.369
- 0.432
- 0.217
- 0.404
- 0.244
- 0.213
- 0.525
- 0.219
- 0.384
- 0.497
- 0.415
- 0.508
- 0.7
- 0.407
- 0.349
- 0.411
- 0.359
unequal: 0
verbose: 1
