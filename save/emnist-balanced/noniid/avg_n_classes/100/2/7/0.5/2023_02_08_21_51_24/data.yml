avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05063829787234043
- 0.11728723404255319
- 0.21622340425531916
- 0.3295212765957447
- 0.3793617021276596
- 0.40404255319148935
- 0.41893617021276597
- 0.42648936170212765
- 0.4537765957446809
- 0.1271808510638298
- 0.456968085106383
- 0.46122340425531916
- 0.4673936170212766
- 0.4806382978723404
- 0.4892021276595745
- 0.4928723404255319
- 0.496436170212766
- 0.49617021276595746
- 0.4994148936170213
- 0.5108510638297873
- 0.5092553191489362
- 0.5126063829787234
- 0.2275
- 0.5152127659574468
- 0.5133510638297872
- 0.5168085106382979
- 0.5225
- 0.5257446808510639
- 0.5326595744680851
- 0.5302127659574468
- 0.531595744680851
- 0.2559574468085106
- 0.5369148936170213
- 0.5398404255319149
- 0.540904255319149
- 0.5412234042553191
- 0.5425531914893617
- 0.5425
- 0.5423936170212766
- 0.5487234042553192
- 0.5456382978723404
- 0.5487234042553192
- 0.5485106382978724
- 0.5535638297872341
- 0.5512234042553191
- 0.5528723404255319
- 0.555531914893617
- 0.5580851063829787
- 0.5569148936170213
- 0.555372340425532
- 0.5568617021276596
- 0.5544148936170212
- 0.556595744680851
- 0.43170212765957444
- 0.5596276595744681
- 0.5594148936170212
- 0.5594148936170212
- 0.561063829787234
- 0.5614361702127659
- 0.5642553191489361
- 0.5614361702127659
- 0.5633510638297873
- 0.475531914893617
- 0.5645744680851064
- 0.5636702127659574
- 0.5642021276595744
- 0.568031914893617
- 0.42856382978723406
- 0.5693617021276596
- 0.5672340425531915
- 0.5662234042553191
- 0.5672340425531915
- 0.5685638297872341
- 0.5667021276595745
- 0.5655851063829788
- 0.5631382978723404
- 0.5667021276595745
- 0.5679787234042554
- 0.566063829787234
- 0.5659042553191489
- 0.5680851063829787
- 0.5661702127659575
- 0.5722340425531914
- 0.5702127659574469
- 0.5710106382978724
- 0.5724468085106383
- 0.5753723404255319
- 0.5717553191489362
- 0.5754255319148937
- 0.5756914893617021
- 0.573404255319149
- 0.4052127659574468
- 0.5795744680851064
- 0.5780851063829787
- 0.576063829787234
- 0.5765425531914894
- 0.5777127659574468
- 0.5738297872340425
- 0.5751063829787234
- 0.573936170212766
test_loss_list:
- 3.796876541773478
- 3.7478712717692058
- 3.5163681729634604
- 3.249962975184123
- 3.240251744588216
- 3.124686679840088
- 3.044038585027059
- 3.0271686935424804
- 3.155771156946818
- 3.7201601696014404
- 2.884904696146647
- 2.9394009081522623
- 2.8664367453257245
- 2.954361604054769
- 3.009780937830607
- 3.044716774622599
- 2.9622885767618814
- 2.8249278322855633
- 2.8143683815002443
- 2.9336763350168864
- 2.8118088976542155
- 2.8526865514119466
- 2.9618055566151935
- 2.6667176214853923
- 2.732583932876587
- 2.6754754702250163
- 2.6797752888997395
- 2.7841881624857585
- 2.8022234121958416
- 2.6736596711476643
- 2.701858501434326
- 2.8617033100128175
- 2.543630142211914
- 2.469611384073893
- 2.572274103164673
- 2.5009949684143065
- 2.5916791788736977
- 2.5468897755940754
- 2.5619249375661215
- 2.724686396916707
- 2.4873359616597495
- 2.5969959672292076
- 2.51297638575236
- 2.499855791727702
- 2.7301492500305176
- 2.523913157780965
- 2.4821868737538657
- 2.5984466552734373
- 2.5836864630381267
- 2.478864854176839
- 2.42445600827535
- 2.4459505875905356
- 2.507224127451579
- 1.9774830595652262
- 2.256916497548421
- 2.405098943710327
- 2.3670923868815104
- 2.4710221894582114
- 2.379888178507487
- 2.4403793716430666
- 2.473149162928263
- 2.365643301010132
- 1.7975529464085898
- 2.041666094462077
- 2.1831430912017824
- 2.248102169036865
- 2.273674335479736
- 1.8723214515050253
- 1.963179907798767
- 2.2503613138198855
- 2.3571883487701415
- 2.418139902750651
- 2.234922243754069
- 2.3268026224772136
- 2.2165712118148804
- 2.1802502854665122
- 2.2987023703257243
- 2.2920044326782225
- 2.2024468851089476
- 2.2870647144317626
- 2.235856369336446
- 2.070195023218791
- 2.1073955996831257
- 2.2472284253438315
- 2.1254252084096272
- 2.1846401850382486
- 2.259144722620646
- 2.2601414918899536
- 2.207603025436401
- 2.390972833633423
- 2.2197017812728883
- 2.029691039721171
- 1.904335954984029
- 2.023753523826599
- 1.9689315557479858
- 2.117033389409383
- 2.0451503451665243
- 1.9973450454076132
- 2.067816653251648
- 2.090911634763082
train_accuracy:
- 0.071
- 0.142
- 0.283
- 0.0
- 0.0
- 0.565
- 0.0
- 0.0
- 0.625
- 0.817
- 0.635
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.719
- 0.0
- 0.0
- 0.725
- 0.115
- 0.76
- 0.0
- 0.0
- 0.0
- 0.744
- 0.763
- 0.0
- 0.0
- 0.692
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.002
- 0.0
- 0.0
- 0.781
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.235
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.796
- 0.554
- 0.808
- 0.002
- 0.0
- 0.0
- 0.321
- 0.823
- 0.808
- 0.0
- 0.831
- 0.0
- 0.0
- 0.0
- 0.0
- 0.815
- 0.0
- 0.0
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.0
- 0.0
- 0.775
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
train_loss:
- 1.967
- 2.432
- 1.129
- 0.96
- 1.723
- 1.596
- 1.082
- 0.705
- 1.318
- 0.441
- 1.341
- 0.908
- 0.662
- 0.876
- 0.871
- 0.814
- 0.834
- 0.549
- 0.601
- 0.762
- 0.528
- 0.752
- 0.328
- 0.809
- 0.506
- 0.525
- 0.495
- 0.713
- 0.684
- 0.494
- 0.481
- 0.303
- 0.668
- 0.468
- 0.685
- 0.473
- 0.454
- 0.463
- 0.436
- 0.811
- 0.456
- 0.616
- 0.438
- 0.424
- 0.781
- 0.465
- 0.432
- 0.597
- 0.602
- 0.445
- 0.402
- 0.431
- 0.63
- 0.261
- 0.622
- 0.565
- 0.592
- 0.555
- 0.425
- 0.59
- 0.573
- 0.41
- 0.23
- 0.384
- 0.546
- 0.553
- 0.536
- 0.252
- 0.36
- 0.71
- 0.687
- 0.698
- 0.4
- 0.529
- 0.373
- 0.383
- 0.523
- 0.544
- 0.373
- 0.513
- 0.373
- 0.378
- 0.392
- 0.52
- 0.362
- 0.536
- 0.526
- 0.536
- 0.363
- 0.666
- 0.361
- 0.232
- 0.33
- 0.498
- 0.346
- 0.493
- 0.35
- 0.356
- 0.341
- 0.496
unequal: 0
verbose: 1
