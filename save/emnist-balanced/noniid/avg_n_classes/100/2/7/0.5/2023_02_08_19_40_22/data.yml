avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04042553191489362
- 0.10505319148936171
- 0.2176595744680851
- 0.31351063829787235
- 0.35867021276595745
- 0.3846276595744681
- 0.39930851063829786
- 0.4175531914893617
- 0.4366489361702128
- 0.4502127659574468
- 0.4614893617021277
- 0.451968085106383
- 0.46893617021276596
- 0.47585106382978726
- 0.476968085106383
- 0.48223404255319147
- 0.4873936170212766
- 0.5004255319148936
- 0.4915425531914894
- 0.5047340425531915
- 0.505904255319149
- 0.5075
- 0.5168617021276596
- 0.5153723404255319
- 0.5202127659574468
- 0.5190425531914894
- 0.5234042553191489
- 0.5292021276595744
- 0.5354255319148936
- 0.39335106382978724
- 0.34
- 0.5327659574468085
- 0.5354255319148936
- 0.5382978723404256
- 0.5422872340425532
- 0.5384042553191489
- 0.548031914893617
- 0.5485638297872341
- 0.5468085106382978
- 0.4403723404255319
- 0.55
- 0.5486702127659574
- 0.5545212765957447
- 0.5486170212765957
- 0.5562765957446808
- 0.5552127659574468
- 0.556968085106383
- 0.5557978723404255
- 0.5566489361702127
- 0.5579255319148936
- 0.558936170212766
- 0.5604787234042553
- 0.5579787234042554
- 0.558031914893617
- 0.5641489361702128
- 0.5652659574468085
- 0.5603191489361702
- 0.561595744680851
- 0.5647872340425532
- 0.5673404255319149
- 0.5685638297872341
- 0.5693617021276596
- 0.5671276595744681
- 0.5682978723404255
- 0.5667021276595745
- 0.5729787234042554
- 0.5705851063829788
- 0.5711702127659575
- 0.5687234042553192
- 0.57
- 0.5726595744680851
- 0.5696808510638298
- 0.5689893617021277
- 0.5737234042553192
- 0.5701595744680851
- 0.5752659574468085
- 0.5738297872340425
- 0.5779787234042553
- 0.5776595744680851
- 0.4547340425531915
- 0.39632978723404255
- 0.5772872340425532
- 0.5779787234042553
- 0.5778191489361703
- 0.5744148936170212
- 0.5786702127659574
- 0.5740957446808511
- 0.5807978723404256
- 0.5806382978723404
- 0.5796808510638298
- 0.5782446808510638
- 0.5144148936170213
- 0.38265957446808513
- 0.5802659574468085
- 0.5808510638297872
- 0.46893617021276596
- 0.5857978723404256
- 0.584627659574468
- 0.5825531914893617
- 0.5816489361702127
test_loss_list:
- 3.8206382369995118
- 3.77809731165568
- 3.5408529218037925
- 3.3641657797495523
- 3.36362673441569
- 3.2414879353841144
- 3.1374194939931233
- 3.066136496861776
- 3.146783062616984
- 3.151553208033244
- 3.250140994389852
- 3.019725481669108
- 2.961969321568807
- 3.0469919300079344
- 2.9522571086883547
- 2.9968240706125897
- 3.1752015082041423
- 3.1725314394632975
- 2.9244478352864585
- 3.010757204691569
- 3.004030539194743
- 2.8352126407623293
- 2.9534191449483234
- 2.8229550902048746
- 2.950607802073161
- 2.818974075317383
- 2.9110249042510987
- 2.8750975195566815
- 3.084355354309082
- 2.3155519644419353
- 2.5851812744140625
- 2.3666600863138836
- 2.4350291156768797
- 2.4902620188395184
- 2.6709522501627605
- 2.5409295622507733
- 2.720927416483561
- 2.7226449775695802
- 2.6024657344818114
- 2.1133578221003213
- 2.400796788533529
- 2.5164530436197916
- 2.6993871688842774
- 2.4253296597798664
- 2.552761999766032
- 2.6442376295725505
- 2.531733013788859
- 2.4624576981862387
- 2.6263095792134603
- 2.5859253501892088
- 2.6416975593566896
- 2.625504814783732
- 2.4536099020640054
- 2.4706780974070233
- 2.453949295679728
- 2.532625029881795
- 2.3754038937886555
- 2.4157164192199705
- 2.3954858048756917
- 2.511537173589071
- 2.4507088820139566
- 2.341775321960449
- 2.4138164202372234
- 2.5065355014801027
- 2.285268422762553
- 2.6224720255533853
- 2.353139667510986
- 2.3569098981221517
- 2.2703048165639244
- 2.2614884344736734
- 2.365770626068115
- 2.321724576950073
- 2.296528937021891
- 2.28785356203715
- 2.2919856977462767
- 2.388306852976481
- 2.264444286028544
- 2.3999516359965005
- 2.4169614060719806
- 1.862218704223633
- 2.206636349360148
- 1.8817253160476684
- 1.9617465273539225
- 2.035968912442525
- 2.04507030804952
- 2.2504755020141602
- 2.1334195868174235
- 2.1868931595484415
- 2.4080916118621825
- 2.2764562050501507
- 2.2736537567774455
- 1.6054557021458944
- 2.2105021905899047
- 1.8857378753026326
- 1.9242504914601644
- 1.867055926322937
- 1.8513486289978027
- 2.1105709743499754
- 2.064952090581258
- 2.0982489999135336
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.5
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.685
- 0.0
- 0.0
- 0.704
- 0.0
- 0.0
- 0.727
- 0.0
- 0.715
- 0.763
- 0.0
- 0.0
- 0.0
- 0.0
- 0.769
- 0.758
- 0.0
- 0.76
- 0.763
- 0.083
- 0.544
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.769
- 0.0
- 0.812
- 0.108
- 0.0
- 0.019
- 0.0
- 0.015
- 0.829
- 0.838
- 0.827
- 0.0
- 0.0
- 0.0
- 0.0
- 0.806
- 0.821
- 0.008
- 0.0
- 0.842
- 0.002
- 0.0
- 0.008
- 0.827
- 0.846
- 0.848
- 0.846
- 0.0
- 0.0
- 0.856
- 0.004
- 0.858
- 0.823
- 0.008
- 0.856
- 0.842
- 0.006
- 0.004
- 0.01
- 0.004
- 0.006
- 0.852
- 0.0
- 0.392
- 0.477
- 0.008
- 0.215
- 0.052
- 0.831
- 0.0
- 0.0
- 0.019
- 0.869
- 0.0
- 0.0
- 0.65
- 0.544
- 0.0
- 0.14
- 0.735
- 0.0
- 0.073
- 0.004
- 0.0
train_loss:
- 2.103
- 1.321
- 1.189
- 1.999
- 1.777
- 1.254
- 0.832
- 0.8
- 1.102
- 1.351
- 1.289
- 0.749
- 0.701
- 0.908
- 0.707
- 0.902
- 1.109
- 1.112
- 0.654
- 0.816
- 0.803
- 0.565
- 0.834
- 0.575
- 0.784
- 0.548
- 0.754
- 0.738
- 0.914
- 0.352
- 0.223
- 0.433
- 0.499
- 0.506
- 0.667
- 0.536
- 0.876
- 0.662
- 0.477
- 0.298
- 0.687
- 0.628
- 0.799
- 0.495
- 0.66
- 0.641
- 0.473
- 0.454
- 0.601
- 0.633
- 0.598
- 0.585
- 0.464
- 0.434
- 0.426
- 0.599
- 0.43
- 0.414
- 0.403
- 0.595
- 0.602
- 0.418
- 0.44
- 0.568
- 0.411
- 0.726
- 0.435
- 0.426
- 0.412
- 0.422
- 0.562
- 0.401
- 0.404
- 0.427
- 0.39
- 0.551
- 0.415
- 0.529
- 0.53
- 0.285
- 0.175
- 0.355
- 0.385
- 0.374
- 0.356
- 0.667
- 0.414
- 0.544
- 0.686
- 0.521
- 0.522
- 0.27
- 0.185
- 0.49
- 0.347
- 0.208
- 0.524
- 0.626
- 0.514
- 0.498
unequal: 0
verbose: 1
