avg_train_accuracy: 0.912
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04845744680851064
- 0.09441489361702128
- 0.17074468085106384
- 0.26845744680851064
- 0.3236702127659574
- 0.3719148936170213
- 0.4050531914893617
- 0.12042553191489362
- 0.42106382978723406
- 0.4173404255319149
- 0.42925531914893617
- 0.4545212765957447
- 0.46377659574468083
- 0.4772872340425532
- 0.46882978723404256
- 0.4727659574468085
- 0.488031914893617
- 0.4946276595744681
- 0.2529787234042553
- 0.49627659574468086
- 0.5020212765957447
- 0.5104787234042554
- 0.223031914893617
- 0.5153723404255319
- 0.5140957446808511
- 0.5156382978723404
- 0.5227127659574468
- 0.5240957446808511
- 0.5299468085106382
- 0.28547872340425534
- 0.22872340425531915
- 0.5293617021276595
- 0.5355319148936171
- 0.5318617021276596
- 0.5392021276595744
- 0.5366489361702128
- 0.5446808510638298
- 0.5456382978723404
- 0.5476595744680851
- 0.5470212765957447
- 0.5498404255319149
- 0.5521276595744681
- 0.5540957446808511
- 0.32063829787234044
- 0.5556914893617021
- 0.5556382978723404
- 0.5568085106382978
- 0.5597340425531915
- 0.559468085106383
- 0.5570744680851064
- 0.5595212765957447
- 0.560531914893617
- 0.3286702127659574
- 0.5620212765957446
- 0.5662765957446808
- 0.5646808510638298
- 0.561595744680851
- 0.5654787234042553
- 0.4027659574468085
- 0.5682446808510638
- 0.5670212765957446
- 0.5682978723404255
- 0.5656914893617021
- 0.5686170212765957
- 0.5686170212765957
- 0.5703723404255319
- 0.5725
- 0.5706914893617021
- 0.5696808510638298
- 0.5720744680851064
- 0.5727659574468085
- 0.5718085106382979
- 0.5757978723404256
- 0.5754255319148937
- 0.5758510638297872
- 0.5773404255319149
- 0.5773404255319149
- 0.5757978723404256
- 0.5736170212765958
- 0.40941489361702127
- 0.5792021276595745
- 0.578031914893617
- 0.5734574468085106
- 0.5782978723404255
- 0.5787765957446809
- 0.5773404255319149
- 0.574840425531915
- 0.578936170212766
- 0.578936170212766
- 0.5822872340425532
- 0.5813829787234043
- 0.5795212765957447
- 0.5825
- 0.581436170212766
- 0.5832446808510638
- 0.5825
- 0.5837765957446809
- 0.5848404255319148
- 0.5832446808510638
- 0.45563829787234045
test_loss_list:
- 3.784255485534668
- 3.7199121220906575
- 3.5044629923502604
- 3.2768906211853026
- 3.1721437772115073
- 3.0751749674479165
- 3.1175452041625977
- 3.7605779711405436
- 3.008633162180583
- 2.9579922358194985
- 2.8913755321502688
- 3.147703202565511
- 3.0269245274861656
- 3.0800569597880045
- 2.9646127796173096
- 2.9514941279093425
- 2.9536603673299155
- 3.013049955368042
- 2.9463646984100342
- 2.7808780225118
- 2.906582686106364
- 2.9082979106903077
- 3.278353004455566
- 2.5990610758463544
- 2.5924829483032226
- 2.6494999249776203
- 2.6373571141560874
- 2.6384635988871254
- 2.716663023630778
- 2.806973810195923
- 3.6565857474009196
- 2.3304896863301594
- 2.4440442593892415
- 2.467540636062622
- 2.3933099619547527
- 2.4632815233866374
- 2.5600306606292724
- 2.4870234298706055
- 2.6562829494476317
- 2.4906877740224203
- 2.572885694503784
- 2.5508213392893473
- 2.692752898534139
- 2.887400099436442
- 2.2958070866266884
- 2.4281630102793375
- 2.4814353052775067
- 2.494349177678426
- 2.458337656656901
- 2.4184728876749673
- 2.3811750094095867
- 2.4645782693227134
- 2.7819572480519614
- 2.2937966283162434
- 2.4938654994964597
- 2.362749145825704
- 2.285083866119385
- 2.4183497460683188
- 2.0667232020696003
- 2.156393632888794
- 2.281101287206014
- 2.2048549858729043
- 2.1598926973342896
- 2.2859430996576946
- 2.185811235109965
- 2.2856295601526897
- 2.2776978111267088
- 2.212586681048075
- 2.2405070050557456
- 2.172606650988261
- 2.3176642417907716
- 2.2384201081593833
- 2.2679166809717812
- 2.283831443786621
- 2.33492786248525
- 2.459715690612793
- 2.3717190710703533
- 2.211861809094747
- 2.17601904074351
- 2.241870250701904
- 2.0267231130599974
- 2.12314071337382
- 2.1192034101486206
- 2.2131827052434287
- 2.1252221568425496
- 2.1669831530253094
- 2.13246603012085
- 2.1730301491419475
- 2.0966909392674764
- 2.2275562349955242
- 2.111563975016276
- 2.09430543422699
- 2.1813433599472045
- 2.1511498355865477
- 2.3836633348464966
- 2.2520525296529135
- 2.252809445063273
- 2.2620419136683148
- 2.232238793373108
- 1.9097976684570312
train_accuracy:
- 0.071
- 0.125
- 0.26
- 0.0
- 0.435
- 0.0
- 0.0
- 0.021
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.715
- 0.0
- 0.0
- 0.731
- 0.681
- 0.0
- 0.0
- 0.0
- 0.0
- 0.021
- 0.0
- 0.723
- 0.0
- 0.0
- 0.0
- 0.758
- 0.154
- 0.0
- 0.0
- 0.771
- 0.0
- 0.0
- 0.0
- 0.812
- 0.0
- 0.0
- 0.781
- 0.785
- 0.81
- 0.779
- 0.327
- 0.779
- 0.84
- 0.004
- 0.0
- 0.002
- 0.0
- 0.0
- 0.79
- 0.904
- 0.0
- 0.806
- 0.0
- 0.0
- 0.81
- 0.248
- 0.0
- 0.0
- 0.042
- 0.802
- 0.015
- 0.002
- 0.0
- 0.85
- 0.0
- 0.798
- 0.823
- 0.844
- 0.012
- 0.0
- 0.0
- 0.823
- 0.858
- 0.0
- 0.833
- 0.81
- 0.79
- 0.0
- 0.806
- 0.004
- 0.819
- 0.002
- 0.0
- 0.0
- 0.852
- 0.0
- 0.823
- 0.027
- 0.0
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.0
- 0.912
train_loss:
- 1.992
- 1.295
- 1.047
- 0.97
- 0.906
- 0.825
- 1.514
- 0.425
- 1.078
- 0.718
- 0.72
- 1.284
- 1.007
- 0.937
- 0.631
- 0.579
- 0.882
- 0.866
- 0.356
- 0.876
- 0.834
- 0.772
- 0.282
- 0.453
- 0.562
- 0.546
- 0.52
- 0.47
- 0.743
- 0.275
- 0.237
- 0.429
- 0.69
- 0.47
- 0.484
- 0.45
- 0.659
- 0.442
- 0.865
- 0.497
- 0.61
- 0.637
- 0.79
- 0.283
- 0.651
- 0.583
- 0.599
- 0.621
- 0.606
- 0.437
- 0.436
- 0.577
- 0.242
- 0.59
- 0.713
- 0.595
- 0.416
- 0.568
- 0.271
- 0.547
- 0.541
- 0.381
- 0.388
- 0.534
- 0.424
- 0.552
- 0.568
- 0.428
- 0.389
- 0.375
- 0.532
- 0.361
- 0.549
- 0.561
- 0.526
- 0.674
- 0.544
- 0.385
- 0.386
- 0.228
- 0.33
- 0.351
- 0.384
- 0.509
- 0.376
- 0.532
- 0.368
- 0.527
- 0.359
- 0.52
- 0.369
- 0.354
- 0.501
- 0.518
- 0.633
- 0.504
- 0.532
- 0.514
- 0.495
- 0.226
unequal: 0
verbose: 1
