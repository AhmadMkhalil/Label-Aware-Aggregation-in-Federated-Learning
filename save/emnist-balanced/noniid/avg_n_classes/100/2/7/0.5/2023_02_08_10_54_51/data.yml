avg_train_accuracy: 0.856
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024361702127659573
- 0.09037234042553191
- 0.1879255319148936
- 0.3019148936170213
- 0.3445744680851064
- 0.3521808510638298
- 0.41436170212765955
- 0.4223936170212766
- 0.43398936170212765
- 0.4503191489361702
- 0.45606382978723403
- 0.4632978723404255
- 0.4621276595744681
- 0.47404255319148936
- 0.47877659574468084
- 0.47547872340425534
- 0.48404255319148937
- 0.18106382978723404
- 0.49234042553191487
- 0.4975531914893617
- 0.49042553191489363
- 0.2051063829787234
- 0.5011702127659574
- 0.5011170212765957
- 0.5119148936170212
- 0.515
- 0.5110106382978723
- 0.5234574468085106
- 0.5247340425531914
- 0.5211170212765958
- 0.5290425531914894
- 0.525904255319149
- 0.5318085106382979
- 0.5324468085106383
- 0.5304787234042553
- 0.5302127659574468
- 0.5398936170212766
- 0.540904255319149
- 0.5385106382978724
- 0.3729787234042553
- 0.5402127659574468
- 0.5460106382978723
- 0.5453191489361702
- 0.5471276595744681
- 0.5478723404255319
- 0.5537765957446809
- 0.5534042553191489
- 0.38265957446808513
- 0.5523404255319149
- 0.556063829787234
- 0.5515425531914894
- 0.5598936170212766
- 0.5532978723404255
- 0.5572872340425532
- 0.5598936170212766
- 0.5651595744680851
- 0.5625531914893617
- 0.5595212765957447
- 0.5601595744680851
- 0.5652659574468085
- 0.5618085106382978
- 0.5634574468085106
- 0.5653723404255319
- 0.47632978723404257
- 0.5656382978723404
- 0.5666489361702127
- 0.5684574468085106
- 0.5679787234042554
- 0.5662765957446808
- 0.5683510638297873
- 0.5718085106382979
- 0.5698936170212766
- 0.5709574468085107
- 0.5706914893617021
- 0.5729787234042554
- 0.5735106382978723
- 0.5716489361702127
- 0.573936170212766
- 0.5701595744680851
- 0.5768085106382979
- 0.5742553191489361
- 0.5718617021276595
- 0.571968085106383
- 0.5763829787234043
- 0.5737234042553192
- 0.5759574468085107
- 0.5751063829787234
- 0.5785638297872341
- 0.5744148936170212
- 0.5773404255319149
- 0.5804787234042553
- 0.5771808510638298
- 0.576063829787234
- 0.47797872340425535
- 0.5823936170212766
- 0.5809042553191489
- 0.5816489361702127
- 0.5772340425531914
- 0.47085106382978725
- 0.5852127659574468
test_loss_list:
- 3.804401766459147
- 3.7448044459025067
- 3.57366823832194
- 3.4212294514973958
- 3.3403077125549316
- 3.216208527882894
- 3.274667638142904
- 3.1684232266743977
- 3.218431625366211
- 3.21066707611084
- 3.2476277573903403
- 3.188989919026693
- 3.086501735051473
- 3.098415225346883
- 3.0863274923960367
- 3.0201487668355305
- 2.931245896021525
- 3.3052100372314452
- 2.6740093644460043
- 2.8067538007100423
- 2.7488989480336508
- 3.200876483917236
- 2.5028629684448243
- 2.6236257489522297
- 2.808222999572754
- 2.6644031238555907
- 2.6412132517496745
- 2.7680665111541747
- 2.9152437909444173
- 2.7222149340311685
- 2.802555611928304
- 2.7891367848714195
- 2.7775721327463785
- 2.7415374279022218
- 2.6806622727711997
- 2.658687448501587
- 2.7292985184987386
- 2.7454971917470297
- 2.711450357437134
- 2.2458515993754067
- 2.2780562178293864
- 2.5591951115926106
- 2.4739190101623536
- 2.6866145865122477
- 2.655804058710734
- 2.8339850902557373
- 2.8530271371205647
- 2.38319699605306
- 2.209644028345744
- 2.3736202335357666
- 2.2465964365005493
- 2.582241481145223
- 2.374164705276489
- 2.4734036095937095
- 2.536213445663452
- 2.6494940026601155
- 2.528351068496704
- 2.4881664911905923
- 2.454127197265625
- 2.5404503186543783
- 2.3000715827941893
- 2.3918849722544353
- 2.4448536602656046
- 1.8817425632476807
- 2.1231562948226927
- 2.343684434890747
- 2.3034633668263753
- 2.3807027022043865
- 2.2523638280232747
- 2.3165179316202797
- 2.3630097770690917
- 2.2836308908462524
- 2.2932228326797484
- 2.3404197454452516
- 2.412586110432943
- 2.320434931119283
- 2.3528443241119383
- 2.331326004664103
- 2.240092584292094
- 2.3498096100489296
- 2.2533279593785602
- 2.264636295636495
- 2.1262558460235597
- 2.4523250961303713
- 2.2404040543238324
- 2.281958731015523
- 2.286206520398458
- 2.4855751387278238
- 2.1924035946528115
- 2.2844255208969115
- 2.364477299054464
- 2.24478059609731
- 2.1524736324946088
- 1.7802130540211996
- 2.083041264216105
- 2.185766846338908
- 2.0924456230799358
- 2.0835545603434245
- 1.8952106555302939
- 2.133226693471273
train_accuracy:
- 0.021
- 0.0
- 0.0
- 0.0
- 0.517
- 0.0
- 0.604
- 0.633
- 0.625
- 0.675
- 0.0
- 0.0
- 0.692
- 0.704
- 0.0
- 0.0
- 0.0
- 0.0
- 0.713
- 0.719
- 0.0
- 0.388
- 0.0
- 0.0
- 0.0
- 0.763
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.794
- 0.0
- 0.0
- 0.0
- 0.771
- 0.767
- 0.806
- 0.39
- 0.0
- 0.815
- 0.0
- 0.0
- 0.796
- 0.0
- 0.827
- 0.04
- 0.806
- 0.0
- 0.823
- 0.806
- 0.0
- 0.0
- 0.827
- 0.827
- 0.806
- 0.0
- 0.829
- 0.84
- 0.0
- 0.0
- 0.0
- 0.406
- 0.835
- 0.0
- 0.0
- 0.008
- 0.019
- 0.0
- 0.0
- 0.0
- 0.838
- 0.0
- 0.838
- 0.019
- 0.846
- 0.825
- 0.002
- 0.0
- 0.84
- 0.017
- 0.84
- 0.835
- 0.85
- 0.0
- 0.0
- 0.0
- 0.0
- 0.835
- 0.0
- 0.0
- 0.833
- 0.833
- 0.0
- 0.0
- 0.019
- 0.015
- 0.852
- 0.856
train_loss:
- 1.416
- 1.929
- 1.163
- 2.003
- 1.359
- 0.88
- 1.534
- 1.17
- 1.08
- 1.03
- 0.999
- 0.97
- 0.965
- 0.667
- 0.676
- 0.663
- 0.66
- 0.377
- 0.844
- 0.813
- 0.618
- 0.323
- 0.597
- 0.57
- 0.811
- 0.548
- 0.58
- 0.776
- 0.76
- 0.542
- 0.74
- 0.554
- 0.749
- 0.518
- 0.562
- 0.533
- 0.723
- 0.687
- 0.684
- 0.328
- 0.46
- 0.678
- 0.502
- 0.677
- 0.649
- 0.813
- 0.835
- 0.297
- 0.487
- 0.452
- 0.473
- 0.795
- 0.458
- 0.465
- 0.601
- 0.774
- 0.646
- 0.627
- 0.599
- 0.617
- 0.449
- 0.424
- 0.591
- 0.265
- 0.577
- 0.594
- 0.598
- 0.595
- 0.408
- 0.377
- 0.55
- 0.421
- 0.578
- 0.396
- 0.558
- 0.404
- 0.527
- 0.553
- 0.411
- 0.56
- 0.398
- 0.393
- 0.405
- 0.688
- 0.561
- 0.55
- 0.551
- 0.671
- 0.378
- 0.552
- 0.54
- 0.412
- 0.424
- 0.252
- 0.519
- 0.51
- 0.37
- 0.386
- 0.229
- 0.681
unequal: 0
verbose: 1
