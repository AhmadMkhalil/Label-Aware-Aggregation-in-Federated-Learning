avg_train_accuracy: 0.99
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03835106382978724
- 0.04127659574468085
- 0.038404255319148935
- 0.040638297872340426
- 0.05686170212765958
- 0.07026595744680851
- 0.03234042553191489
- 0.04159574468085107
- 0.03803191489361702
- 0.04180851063829787
- 0.1626063829787234
- 0.041914893617021276
- 0.2476063829787234
- 0.3270212765957447
- 0.040106382978723404
- 0.04085106382978723
- 0.03930851063829787
- 0.3702659574468085
- 0.4027127659574468
- 0.42872340425531913
- 0.04851063829787234
- 0.04473404255319149
- 0.04441489361702128
- 0.06845744680851064
- 0.05058510638297872
- 0.05579787234042553
- 0.06537234042553192
- 0.06281914893617022
- 0.04069148936170213
- 0.04127659574468085
- 0.054946808510638295
- 0.05132978723404255
- 0.04638297872340426
- 0.04542553191489362
- 0.06122340425531915
- 0.07404255319148936
- 0.43303191489361703
- 0.09893617021276596
- 0.05404255319148936
- 0.46856382978723404
- 0.08813829787234043
- 0.10436170212765958
- 0.07792553191489361
- 0.46356382978723404
- 0.10170212765957447
- 0.055212765957446806
- 0.07606382978723404
- 0.04281914893617021
- 0.48914893617021277
- 0.25127659574468086
- 0.11936170212765958
- 0.0876595744680851
- 0.4823404255319149
- 0.24638297872340426
- 0.12303191489361702
- 0.5020212765957447
- 0.09595744680851064
- 0.51
- 0.3077127659574468
- 0.5201063829787234
- 0.22101063829787235
- 0.10601063829787234
- 0.12404255319148937
- 0.10361702127659575
- 0.5335106382978724
- 0.16404255319148936
- 0.22930851063829788
- 0.14138297872340425
- 0.5522340425531915
- 0.5445744680851063
- 0.5435106382978724
- 0.1751595744680851
- 0.11404255319148936
- 0.5590425531914893
- 0.28632978723404257
- 0.12877659574468084
- 0.5668085106382978
- 0.20585106382978724
- 0.5671808510638298
- 0.24606382978723404
- 0.5636170212765957
- 0.5540957446808511
- 0.3959042553191489
- 0.1922340425531915
- 0.14159574468085107
- 0.10478723404255319
- 0.0748936170212766
- 0.5920744680851063
- 0.5752127659574469
- 0.22329787234042553
- 0.1924468085106383
- 0.2756382978723404
- 0.12781914893617022
- 0.18808510638297873
- 0.1000531914893617
- 0.5824468085106383
- 0.5738297872340425
- 0.563936170212766
- 0.3228723404255319
- 0.17
test_loss_list:
- 18.290096435546875
- 17.202619145711264
- 19.97423792521159
- 17.86825050354004
- 3.7706301339467365
- 3.754236405690511
- 13.528931147257486
- 19.46770716349284
- 3.7055414708455405
- 12.859795405069987
- 3.5119979572296143
- 14.076088434855142
- 3.1957706133524577
- 3.0160236676534016
- 10.190614318847656
- 13.122556495666505
- 12.72801705678304
- 2.7755952898661294
- 2.7477926540374757
- 2.7877825768788655
- 10.97107504526774
- 13.898587455749512
- 7.882704327901204
- 9.134609400431316
- 11.246170756022135
- 9.33170342763265
- 7.385914630889893
- 9.073851216634115
- 16.45795960744222
- 21.015796737670897
- 9.843199297587077
- 10.190406634012858
- 12.740644200642903
- 12.498413124084472
- 11.264227956136068
- 9.267231661478679
- 2.3372310129801432
- 5.3205952390035
- 7.7798476409912105
- 2.1200046316782633
- 7.424018281300863
- 6.196974449157715
- 7.5949165026346845
- 2.0318223889668783
- 6.4031964747111
- 9.48254576365153
- 7.944227561950684
- 8.939898872375489
- 1.9026481628417968
- 4.339073311487834
- 6.551639868418376
- 8.224590937296549
- 1.897842928568522
- 4.019308099746704
- 6.192743326822916
- 1.8925964879989623
- 7.2578148333231605
- 1.9013779751459758
- 3.5654609203338623
- 1.9449460903803508
- 5.066693757375082
- 7.345395991007487
- 6.117852350870768
- 7.463391640981039
- 1.86276194413503
- 5.800473105112712
- 3.9074575074513755
- 6.322260367075602
- 1.8273355118433634
- 1.9372908544540406
- 2.031992783546448
- 5.851535650889079
- 6.3442643356323245
- 1.902531728744507
- 4.354218505223592
- 6.809188810984294
- 1.8064196062088014
- 5.054147981007894
- 1.8885377248128254
- 4.67401008605957
- 1.9442408434549967
- 2.014555117289225
- 3.297515137990316
- 5.309724661509196
- 6.888318080902099
- 7.1057537651062015
- 9.246615346272787
- 1.837977949778239
- 1.9616547091801961
- 5.281329091389974
- 5.34724661509196
- 3.8000352891286213
- 5.460875695546468
- 4.29056077003479
- 6.643089307149252
- 1.6201586612065633
- 1.7544462792078654
- 1.8726825284957886
- 3.9850593121846516
- 5.556047681172688
train_accuracy:
- 0.815
- 0.967
- 0.871
- 0.923
- 0.015
- 0.027
- 0.556
- 0.981
- 0.004
- 0.985
- 0.156
- 0.979
- 0.269
- 0.485
- 0.946
- 0.956
- 0.858
- 0.5
- 0.567
- 0.606
- 0.998
- 0.998
- 0.952
- 0.971
- 0.99
- 0.981
- 0.948
- 0.983
- 0.956
- 0.983
- 0.969
- 0.998
- 1.0
- 0.95
- 0.992
- 1.0
- 0.552
- 0.967
- 0.975
- 0.625
- 0.996
- 0.977
- 0.981
- 0.619
- 0.994
- 0.988
- 0.973
- 0.971
- 0.673
- 0.977
- 1.0
- 1.0
- 0.635
- 0.963
- 0.998
- 0.66
- 0.981
- 0.702
- 0.973
- 0.69
- 0.998
- 0.985
- 0.996
- 0.996
- 0.708
- 0.996
- 0.977
- 0.998
- 0.723
- 0.708
- 0.763
- 0.983
- 0.998
- 0.769
- 1.0
- 0.988
- 0.733
- 0.996
- 0.742
- 0.998
- 0.746
- 0.765
- 0.977
- 1.0
- 1.0
- 0.985
- 0.99
- 0.758
- 0.76
- 0.994
- 0.996
- 0.977
- 0.985
- 0.979
- 0.99
- 0.731
- 0.794
- 0.771
- 1.0
- 0.99
train_loss:
- 1.118
- 1.141
- 1.08
- 1.161
- 4.122
- 3.824
- 2.136
- 1.309
- 4.096
- 0.733
- 3.905
- 0.404
- 3.672
- 2.971
- 0.607
- 0.185
- 0.979
- 3.201
- 2.49
- 2.241
- 0.714
- 0.101
- 0.577
- 0.643
- 0.637
- 0.73
- 0.378
- 0.197
- 1.008
- 0.269
- 0.574
- 0.574
- 0.106
- 0.517
- 0.491
- 0.226
- 3.381
- 0.352
- 0.51
- 2.613
- 0.309
- 0.474
- 0.395
- 2.529
- 0.33
- 0.413
- 0.322
- 1.144
- 2.514
- 0.288
- 0.402
- 0.089
- 2.282
- 0.359
- 0.293
- 2.061
- 0.521
- 2.066
- 0.273
- 1.777
- 0.297
- 0.522
- 0.176
- 0.064
- 2.098
- 0.413
- 0.357
- 0.181
- 2.012
- 1.56
- 1.582
- 0.515
- 0.323
- 1.804
- 0.328
- 0.446
- 1.748
- 0.237
- 1.566
- 0.185
- 1.485
- 1.471
- 0.338
- 0.211
- 0.049
- 0.42
- 0.114
- 1.704
- 1.286
- 0.26
- 0.361
- 0.319
- 0.718
- 0.184
- 0.158
- 1.807
- 1.45
- 1.259
- 0.282
- 0.292
unequal: 0
verbose: 1
