avg_train_accuracy: 0.996
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.051382978723404256
- 0.1226595744680851
- 0.2578191489361702
- 0.04074468085106383
- 0.04154255319148936
- 0.24159574468085107
- 0.04180851063829787
- 0.3046808510638298
- 0.04186170212765957
- 0.04212765957446808
- 0.04090425531914894
- 0.041329787234042556
- 0.32127659574468087
- 0.04212765957446808
- 0.36425531914893616
- 0.041914893617021276
- 0.40132978723404256
- 0.42281914893617023
- 0.4340425531914894
- 0.04196808510638298
- 0.040797872340425534
- 0.04186170212765957
- 0.04202127659574468
- 0.04170212765957447
- 0.05585106382978723
- 0.04202127659574468
- 0.4471276595744681
- 0.4469148936170213
- 0.04154255319148936
- 0.0425
- 0.04212765957446808
- 0.4635106382978723
- 0.4652127659574468
- 0.05132978723404255
- 0.47510638297872343
- 0.1176063829787234
- 0.07340425531914893
- 0.06664893617021277
- 0.4801595744680851
- 0.1971276595744681
- 0.06026595744680851
- 0.08143617021276596
- 0.4998404255319149
- 0.05978723404255319
- 0.07345744680851064
- 0.11728723404255319
- 0.06430851063829787
- 0.07271276595744681
- 0.06382978723404255
- 0.5089893617021276
- 0.5006382978723404
- 0.5053191489361702
- 0.5042021276595745
- 0.5070744680851064
- 0.2049468085106383
- 0.06829787234042553
- 0.06281914893617022
- 0.5300531914893617
- 0.10079787234042553
- 0.06308510638297872
- 0.052074468085106386
- 0.04765957446808511
- 0.08861702127659575
- 0.5385106382978724
- 0.1447340425531915
- 0.5252659574468085
- 0.5263829787234042
- 0.2854255319148936
- 0.5354255319148936
- 0.1554255319148936
- 0.105
- 0.04893617021276596
- 0.5525531914893617
- 0.19452127659574467
- 0.5535638297872341
- 0.25920212765957445
- 0.5477659574468086
- 0.34361702127659577
- 0.10132978723404255
- 0.5586170212765957
- 0.13303191489361701
- 0.13691489361702128
- 0.14898936170212765
- 0.10835106382978724
- 0.1322340425531915
- 0.5836702127659574
- 0.3625531914893617
- 0.2023936170212766
- 0.5607978723404256
- 0.21090425531914894
- 0.09648936170212766
- 0.15143617021276595
- 0.2246276595744681
- 0.13101063829787235
- 0.14377659574468085
- 0.11829787234042553
- 0.16319148936170214
- 0.5843085106382979
- 0.5632978723404255
- 0.29648936170212764
test_loss_list:
- 3.7941800117492677
- 3.7459393088022868
- 3.610720933278402
- 21.016568222045898
- 26.728719202677407
- 3.5147756799062093
- 21.119784978230793
- 3.3526429398854574
- 14.061975746154785
- 17.934875361124675
- 17.846731338500977
- 22.39114756266276
- 3.1189417680104574
- 11.095576400756835
- 3.090364408493042
- 13.87130869547526
- 2.8809494813283285
- 2.922924585342407
- 3.0074048614501954
- 15.813503570556641
- 17.766525166829428
- 12.642367108662922
- 16.710732447306317
- 17.14720199584961
- 11.304948768615724
- 12.537024078369141
- 2.508138910929362
- 2.5853423341115316
- 10.949306411743164
- 10.201806373596192
- 11.97615946451823
- 2.415593786239624
- 2.567708495457967
- 9.470018564860027
- 2.577536112467448
- 6.90258020401001
- 8.098876857757569
- 9.721239026387533
- 2.166646841367086
- 5.800089028676351
- 8.103225631713867
- 7.80047030766805
- 2.1694962946573892
- 7.770938294728597
- 9.075696360270182
- 6.631906541188558
- 7.344865627288819
- 9.26190975189209
- 11.247674878438314
- 1.8791497580210368
- 2.024787311553955
- 2.1496682182947793
- 2.213119320869446
- 2.2916369915008543
- 5.490737489064535
- 7.884611854553222
- 8.172171281178793
- 1.9661194070180257
- 6.905342381795247
- 7.699906838734945
- 9.443715031941732
- 10.534809125264486
- 7.58761884689331
- 1.8423604122797648
- 5.993855304718018
- 1.9010324176152547
- 2.0173573891321817
- 4.19072229385376
- 1.929602214495341
- 5.799004205067953
- 8.088851585388184
- 8.182239627838134
- 1.835817821820577
- 5.661518923441569
- 1.9459700759251912
- 4.463580725987752
- 1.8595557419459026
- 3.834540459314982
- 7.002411022186279
- 1.7528793652852377
- 5.802830053965251
- 6.096301314036052
- 5.25988099416097
- 6.824257640838623
- 6.3875136566162105
- 1.65211710135142
- 3.6525002193450926
- 5.592085501352946
- 1.586595425605774
- 4.988055585225423
- 6.408354237874349
- 6.514895381927491
- 4.590136613845825
- 5.9498444938659665
- 5.760005874633789
- 5.96562952041626
- 5.128839047749837
- 1.4692928981781006
- 1.6450734170277914
- 4.0564479637146
train_accuracy:
- 0.077
- 0.142
- 0.367
- 0.925
- 0.965
- 0.35
- 0.99
- 0.404
- 0.985
- 0.996
- 0.944
- 0.967
- 0.448
- 0.998
- 0.494
- 0.971
- 0.54
- 0.619
- 0.633
- 0.981
- 0.983
- 0.971
- 0.971
- 0.977
- 0.996
- 0.981
- 0.623
- 0.654
- 0.954
- 0.985
- 0.975
- 0.646
- 0.662
- 0.985
- 0.665
- 0.973
- 0.996
- 0.988
- 0.681
- 0.971
- 0.983
- 0.992
- 0.658
- 0.979
- 0.971
- 0.977
- 0.985
- 0.983
- 0.983
- 0.706
- 0.667
- 0.69
- 0.717
- 0.721
- 0.996
- 0.99
- 0.979
- 0.717
- 0.99
- 0.992
- 0.992
- 0.992
- 0.996
- 0.706
- 0.998
- 0.742
- 0.723
- 0.977
- 0.75
- 0.981
- 0.981
- 0.994
- 0.748
- 0.981
- 0.729
- 0.996
- 0.746
- 0.979
- 0.992
- 0.754
- 0.992
- 0.996
- 1.0
- 1.0
- 0.981
- 0.725
- 0.981
- 0.996
- 0.767
- 0.996
- 0.992
- 0.996
- 0.981
- 0.996
- 0.979
- 0.992
- 0.979
- 0.752
- 0.758
- 0.996
train_loss:
- 3.792
- 3.601
- 3.241
- 0.656
- 1.123
- 3.825
- 0.835
- 3.407
- 0.747
- 0.129
- 1.093
- 0.175
- 3.527
- 0.356
- 2.919
- 1.023
- 2.765
- 2.308
- 2.147
- 0.787
- 1.296
- 0.803
- 0.126
- 0.556
- 0.631
- 0.602
- 3.012
- 2.124
- 0.611
- 0.462
- 0.588
- 2.551
- 1.986
- 0.375
- 2.142
- 0.414
- 0.429
- 0.846
- 2.406
- 0.264
- 0.428
- 0.388
- 2.252
- 0.566
- 0.607
- 0.407
- 1.164
- 0.385
- 0.121
- 2.542
- 1.794
- 1.685
- 1.675
- 1.602
- 0.4
- 0.452
- 0.548
- 2.052
- 0.428
- 0.361
- 0.092
- 0.073
- 0.527
- 2.106
- 0.463
- 1.795
- 1.526
- 0.399
- 1.653
- 0.461
- 0.123
- 0.396
- 1.8
- 0.28
- 1.642
- 0.405
- 1.621
- 0.302
- 0.481
- 1.706
- 0.359
- 0.323
- 0.36
- 0.073
- 0.4
- 1.862
- 0.251
- 0.552
- 1.724
- 0.329
- 0.33
- 0.293
- 0.33
- 0.488
- 0.118
- 0.338
- 0.176
- 2.007
- 1.391
- 0.333
unequal: 0
verbose: 1
