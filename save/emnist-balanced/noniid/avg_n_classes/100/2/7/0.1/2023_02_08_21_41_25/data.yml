avg_train_accuracy: 1.0
avg_train_loss: 0.0
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.039521276595744684
- 0.041648936170212765
- 0.0473936170212766
- 0.04186170212765957
- 0.041223404255319146
- 0.04143617021276596
- 0.04218085106382979
- 0.041914893617021276
- 0.042340425531914895
- 0.07287234042553191
- 0.09228723404255319
- 0.18388297872340426
- 0.04196808510638298
- 0.26191489361702125
- 0.04196808510638298
- 0.3204255319148936
- 0.3683510638297872
- 0.4097872340425532
- 0.04329787234042553
- 0.044042553191489364
- 0.0523404255319149
- 0.41164893617021275
- 0.43792553191489364
- 0.45170212765957446
- 0.04563829787234042
- 0.06420212765957446
- 0.04281914893617021
- 0.04569148936170213
- 0.04377659574468085
- 0.04218085106382979
- 0.05414893617021277
- 0.4650531914893617
- 0.08117021276595744
- 0.06893617021276596
- 0.046170212765957445
- 0.04324468085106383
- 0.07643617021276596
- 0.0678191489361702
- 0.46047872340425533
- 0.05047872340425532
- 0.051542553191489364
- 0.06377659574468085
- 0.05872340425531915
- 0.4981914893617021
- 0.053085106382978725
- 0.48127659574468085
- 0.48101063829787233
- 0.1223936170212766
- 0.05696808510638298
- 0.05303191489361702
- 0.04632978723404255
- 0.07058510638297873
- 0.0625531914893617
- 0.06335106382978724
- 0.09723404255319149
- 0.5111170212765958
- 0.18143617021276595
- 0.09893617021276596
- 0.10351063829787234
- 0.09962765957446809
- 0.5248404255319149
- 0.165
- 0.5126063829787234
- 0.5085106382978724
- 0.5125531914893617
- 0.12170212765957447
- 0.5194148936170213
- 0.13930851063829788
- 0.5261702127659574
- 0.1545212765957447
- 0.12345744680851063
- 0.09276595744680852
- 0.5305319148936171
- 0.530904255319149
- 0.5327127659574468
- 0.25420212765957445
- 0.08420212765957447
- 0.10563829787234043
- 0.5434574468085106
- 0.14037234042553193
- 0.12351063829787234
- 0.10930851063829787
- 0.1672872340425532
- 0.5583510638297873
- 0.5463829787234042
- 0.2672340425531915
- 0.5626595744680851
- 0.19356382978723405
- 0.5643617021276596
- 0.5546276595744681
- 0.31643617021276593
- 0.24207446808510638
- 0.15143617021276595
- 0.12723404255319148
- 0.5620212765957446
- 0.25627659574468087
- 0.13856382978723406
- 0.14845744680851064
- 0.19489361702127658
- 0.14553191489361703
test_loss_list:
- 17.076378606160482
- 19.522805608113607
- 3.7904188442230224
- 19.64047213236491
- 18.415274327596027
- 19.824137090047202
- 18.448812815348308
- 15.53893871307373
- 11.53707302093506
- 3.696944694519043
- 3.600708754857381
- 3.492763833999634
- 14.460360412597657
- 3.3909606456756594
- 13.733014106750488
- 3.216546777089437
- 3.2055518690745037
- 3.1957389799753826
- 10.09987606048584
- 14.154910329182943
- 10.613221244812012
- 2.815528252919515
- 2.9197401205698648
- 3.0422311464945477
- 11.440079981486003
- 7.971152693430582
- 10.969372749328613
- 8.974578348795573
- 9.210634574890136
- 13.14900520324707
- 11.059740867614746
- 2.280767936706543
- 6.826577154795329
- 9.664873059590658
- 11.414316584269205
- 13.39599131266276
- 8.91742655436198
- 11.04230349222819
- 2.147911178270976
- 9.349181569417318
- 7.212874221801758
- 9.854544067382813
- 8.465765240987142
- 2.1124409341812136
- 8.850621922810872
- 2.1186895529429117
- 2.228776551882426
- 6.621259625752767
- 9.651553446451823
- 9.087269458770752
- 9.525291913350424
- 7.234753665924072
- 11.743632214864094
- 10.75396401723226
- 8.248647034962971
- 1.8999154965082805
- 5.0083264605204265
- 6.6578265508015955
- 8.458428846995035
- 8.590353209177653
- 1.8292230113347372
- 5.371078968048096
- 1.96467920144399
- 2.133092940648397
- 2.159877281188965
- 6.860676129659017
- 2.080950204531352
- 6.58550106048584
- 2.1441578022638956
- 6.347326278686523
- 7.741843388875325
- 9.66536334991455
- 1.9957597144444783
- 2.1627596918741863
- 2.261952214241028
- 5.041073099772135
- 9.224475135803223
- 6.973388284047445
- 1.9117074696222942
- 6.965955231984457
- 5.255989761352539
- 6.203580888112386
- 5.662367413838704
- 1.7089537811279296
- 1.8843851884206135
- 4.268373886744182
- 1.917335073153178
- 6.351143169403076
- 1.9143242979049682
- 1.99983908812205
- 4.173176803588867
- 5.5959183184305825
- 6.346403687795004
- 6.525102443695069
- 1.607384910583496
- 4.733494714101155
- 5.811944026947021
- 6.055424969991048
- 5.000867722829183
- 6.513105487823486
train_accuracy:
- 0.946
- 0.963
- 0.002
- 0.983
- 0.925
- 0.942
- 0.983
- 0.992
- 0.998
- 0.037
- 0.094
- 0.258
- 0.969
- 0.373
- 0.977
- 0.435
- 0.523
- 0.569
- 0.99
- 0.96
- 0.996
- 0.585
- 0.619
- 0.669
- 0.975
- 0.994
- 0.981
- 0.996
- 0.998
- 0.99
- 0.965
- 0.633
- 0.998
- 0.967
- 0.992
- 0.992
- 0.967
- 0.969
- 0.631
- 0.981
- 0.983
- 0.975
- 0.975
- 0.623
- 0.988
- 0.658
- 0.66
- 0.975
- 0.992
- 0.977
- 0.992
- 0.998
- 0.992
- 0.994
- 0.969
- 0.704
- 0.983
- 0.998
- 0.996
- 0.971
- 0.715
- 0.973
- 0.696
- 0.733
- 0.748
- 0.994
- 0.756
- 0.994
- 0.717
- 0.994
- 0.996
- 0.996
- 0.76
- 0.719
- 0.779
- 0.996
- 0.977
- 0.998
- 0.763
- 0.985
- 0.988
- 0.994
- 0.994
- 0.771
- 0.773
- 0.99
- 0.756
- 0.99
- 0.744
- 0.742
- 0.996
- 0.996
- 0.994
- 1.0
- 0.79
- 1.0
- 0.998
- 0.988
- 1.0
- 1.0
train_loss:
- 0.86
- 0.889
- 4.085
- 1.651
- 1.312
- 1.24
- 0.984
- 0.641
- 0.768
- 4.027
- 3.682
- 3.437
- 0.513
- 3.469
- 0.64
- 3.215
- 2.614
- 2.436
- 0.439
- 0.701
- 0.458
- 2.842
- 2.201
- 2.015
- 0.433
- 0.523
- 0.649
- 0.261
- 0.388
- 1.335
- 0.771
- 2.889
- 0.27
- 0.337
- 0.672
- 0.465
- 0.331
- 0.1
- 2.797
- 0.388
- 0.519
- 0.201
- 0.502
- 2.507
- 0.526
- 2.209
- 1.825
- 0.324
- 0.317
- 0.473
- 0.281
- 0.5
- 0.452
- 0.242
- 0.317
- 2.494
- 0.427
- 0.293
- 0.309
- 0.249
- 2.291
- 0.245
- 1.938
- 1.684
- 1.635
- 0.355
- 1.773
- 0.222
- 1.732
- 0.207
- 0.356
- 0.061
- 1.875
- 1.483
- 1.459
- 0.27
- 0.281
- 0.385
- 1.801
- 0.453
- 0.495
- 0.473
- 0.274
- 1.823
- 1.391
- 0.296
- 1.482
- 0.301
- 1.567
- 1.331
- 0.287
- 0.049
- 0.351
- 0.689
- 1.789
- 0.234
- 0.409
- 0.409
- 0.274
- 0.049
unequal: 0
verbose: 1
