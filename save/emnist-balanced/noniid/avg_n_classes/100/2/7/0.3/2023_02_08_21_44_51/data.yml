avg_train_accuracy: 0.981
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05813829787234043
- 0.05702127659574468
- 0.09367021276595745
- 0.19281914893617022
- 0.2856382978723404
- 0.06079787234042553
- 0.3484042553191489
- 0.3823404255319149
- 0.047180851063829785
- 0.38398936170212766
- 0.10930851063829787
- 0.4095744680851064
- 0.42473404255319147
- 0.44303191489361704
- 0.455
- 0.4622340425531915
- 0.4623404255319149
- 0.16787234042553192
- 0.4697872340425532
- 0.1528191489361702
- 0.10707446808510639
- 0.4843085106382979
- 0.49611702127659574
- 0.49840425531914895
- 0.2630851063829787
- 0.1721808510638298
- 0.14877659574468086
- 0.500531914893617
- 0.18670212765957447
- 0.500904255319149
- 0.5054255319148936
- 0.5153723404255319
- 0.5137234042553191
- 0.522127659574468
- 0.5236702127659575
- 0.5214893617021277
- 0.5260106382978723
- 0.5229255319148937
- 0.38159574468085106
- 0.1996276595744681
- 0.5306914893617021
- 0.5326063829787234
- 0.5342021276595744
- 0.5398936170212766
- 0.3792553191489362
- 0.5414361702127659
- 0.5412234042553191
- 0.40819148936170213
- 0.5412765957446809
- 0.3601063829787234
- 0.545904255319149
- 0.5422872340425532
- 0.5430851063829787
- 0.5487765957446809
- 0.5507978723404255
- 0.35627659574468085
- 0.5497340425531915
- 0.5050531914893617
- 0.5492021276595744
- 0.5498404255319149
- 0.4743085106382979
- 0.5561170212765958
- 0.5612765957446808
- 0.44845744680851063
- 0.5573936170212765
- 0.48861702127659573
- 0.565531914893617
- 0.5580851063829787
- 0.4486702127659574
- 0.5637234042553192
- 0.47175531914893615
- 0.3670744680851064
- 0.20308510638297872
- 0.5706914893617021
- 0.5127127659574469
- 0.5779787234042553
- 0.4946808510638298
- 0.5742021276595745
- 0.5657446808510638
- 0.474468085106383
- 0.5671276595744681
- 0.5481914893617021
- 0.5765957446808511
- 0.5685638297872341
- 0.5673936170212766
- 0.5652127659574468
- 0.564468085106383
- 0.5682978723404255
- 0.5152127659574468
- 0.5712765957446808
- 0.5706914893617021
- 0.5667553191489362
- 0.5678723404255319
- 0.5666489361702127
- 0.44861702127659575
- 0.5722340425531914
- 0.5687234042553192
- 0.5712765957446808
- 0.5695212765957447
- 0.573404255319149
test_loss_list:
- 6.2851487159729
- 8.171284929911296
- 3.6838505999247233
- 3.5066234270731607
- 3.347503751118978
- 6.194593931833903
- 3.2422345733642577
- 3.275048573811849
- 5.222266801198324
- 2.9992349592844647
- 4.379095633824666
- 3.014922431310018
- 3.090564619700114
- 3.1609226926167806
- 3.05719048500061
- 3.1138425922393798
- 3.1715172322591147
- 3.817012087504069
- 2.952541087468465
- 3.7222209072113035
- 5.414735260009766
- 2.679313933054606
- 2.880017900466919
- 2.8999995962778726
- 3.1491764036814374
- 3.9414464696248372
- 4.900560525258382
- 2.5029968643188476
- 3.5580909792582194
- 2.443236894607544
- 2.631976776123047
- 2.7860454432169597
- 2.6300595378875733
- 2.8330398241678876
- 2.742285696665446
- 2.7677512804667157
- 2.7759470399220785
- 2.831641451517741
- 2.4188798809051515
- 3.4960810502370196
- 2.4132543341318766
- 2.529586216608683
- 2.5465558433532713
- 2.5125286865234373
- 2.3199399534861245
- 2.3776118246714275
- 2.4823524570465088
- 2.1842467641830443
- 2.2203890450795494
- 2.364749159812927
- 2.2749245421091717
- 2.3500186745325724
- 2.439247128168742
- 2.522712478637695
- 2.660329745610555
- 2.390547072092692
- 2.1934559377034506
- 1.8058453194300335
- 2.0006602668762206
- 2.242332688967387
- 1.7915736134847005
- 2.06923108736674
- 2.1372895654042563
- 1.9011258824666342
- 1.9780714400609334
- 1.7818386363983154
- 1.9964766089121502
- 2.0985785992940267
- 2.0273343960444135
- 2.0132501220703123
- 1.8573775068918863
- 2.2729376570383706
- 3.785491523742676
- 1.7730095688501994
- 1.7195299418767294
- 1.9311412541071573
- 1.9057097371419272
- 1.9385062583287558
- 2.074312369028727
- 1.9082066853841146
- 1.9168413925170897
- 1.643838357925415
- 1.7257950480779012
- 2.023812797864278
- 2.1382507499059042
- 2.0195658445358275
- 2.2045948791503904
- 2.1243073892593385
- 1.5983081197738647
- 1.9733345127105713
- 1.9764682610829671
- 2.119092982610067
- 2.22466960589091
- 2.199255688985189
- 2.2525534296035765
- 2.156728846232096
- 2.1996160570780434
- 2.1268018372853597
- 2.2424299716949463
- 1.6278087361653646
train_accuracy:
- 0.938
- 0.0
- 0.15
- 0.248
- 0.4
- 0.002
- 0.515
- 0.0
- 0.875
- 0.0
- 0.598
- 0.0
- 0.0
- 0.0
- 0.662
- 0.648
- 0.0
- 0.579
- 0.0
- 0.588
- 0.881
- 0.0
- 0.704
- 0.685
- 0.656
- 0.729
- 0.948
- 0.0
- 0.806
- 0.729
- 0.7
- 0.0
- 0.721
- 0.0
- 0.708
- 0.0
- 0.0
- 0.0
- 0.969
- 0.883
- 0.0
- 0.0
- 0.735
- 0.0
- 0.871
- 0.0
- 0.0
- 0.708
- 0.765
- 0.69
- 0.771
- 0.0
- 0.783
- 0.779
- 0.0
- 0.775
- 0.0
- 0.952
- 0.0
- 0.781
- 0.885
- 0.0
- 0.769
- 0.958
- 0.771
- 0.975
- 0.0
- 0.802
- 0.956
- 0.794
- 0.619
- 0.89
- 0.8
- 0.771
- 0.89
- 0.8
- 0.877
- 0.023
- 0.804
- 0.927
- 0.033
- 0.715
- 0.796
- 0.79
- 0.796
- 0.006
- 0.0
- 0.002
- 0.965
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.963
- 0.796
- 0.0
- 0.812
- 0.0
- 0.981
train_loss:
- 0.748
- 0.385
- 1.6
- 1.412
- 1.375
- 0.487
- 2.04
- 1.811
- 0.547
- 1.002
- 0.357
- 0.988
- 0.903
- 1.43
- 0.861
- 0.858
- 0.81
- 0.331
- 0.81
- 0.348
- 0.21
- 0.752
- 1.21
- 0.769
- 0.292
- 0.276
- 0.152
- 0.707
- 0.297
- 0.775
- 0.626
- 1.085
- 0.743
- 1.117
- 0.703
- 0.648
- 0.638
- 0.621
- 0.288
- 0.238
- 0.643
- 0.589
- 0.566
- 0.659
- 0.285
- 0.601
- 0.683
- 0.304
- 0.579
- 0.286
- 0.934
- 0.551
- 0.537
- 0.934
- 0.854
- 0.352
- 0.585
- 0.234
- 0.594
- 0.516
- 0.266
- 0.523
- 0.527
- 0.272
- 0.518
- 0.203
- 0.86
- 0.481
- 0.232
- 0.479
- 0.243
- 0.175
- 0.178
- 0.506
- 0.194
- 0.818
- 0.207
- 0.463
- 0.82
- 0.187
- 0.518
- 0.191
- 0.586
- 0.739
- 0.748
- 0.593
- 0.447
- 0.528
- 0.272
- 0.79
- 0.518
- 0.507
- 0.45
- 0.494
- 0.228
- 1.07
- 0.458
- 0.459
- 0.506
- 0.218
unequal: 0
verbose: 1
