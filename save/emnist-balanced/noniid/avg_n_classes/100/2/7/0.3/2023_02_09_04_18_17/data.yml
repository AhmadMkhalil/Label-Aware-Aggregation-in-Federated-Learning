avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03803191489361702
- 0.09069148936170213
- 0.24079787234042555
- 0.32382978723404254
- 0.062180851063829784
- 0.3778723404255319
- 0.13537234042553192
- 0.07670212765957447
- 0.3946276595744681
- 0.42696808510638296
- 0.19398936170212766
- 0.4273936170212766
- 0.449468085106383
- 0.4577127659574468
- 0.45776595744680854
- 0.47760638297872343
- 0.48569148936170214
- 0.48404255319148937
- 0.4923936170212766
- 0.5018085106382979
- 0.49888297872340426
- 0.5107978723404255
- 0.5060106382978723
- 0.15313829787234043
- 0.5090957446808511
- 0.5121808510638298
- 0.5188829787234043
- 0.528031914893617
- 0.5269680851063829
- 0.5306382978723404
- 0.535904255319149
- 0.5323404255319149
- 0.5388297872340425
- 0.5442553191489362
- 0.5407446808510639
- 0.2272872340425532
- 0.5379787234042553
- 0.5418617021276596
- 0.5461702127659575
- 0.5508510638297872
- 0.551595744680851
- 0.5509574468085107
- 0.29781914893617023
- 0.5478191489361702
- 0.5545212765957447
- 0.5526595744680851
- 0.32856382978723403
- 0.16446808510638297
- 0.5531382978723405
- 0.3429255319148936
- 0.5563829787234043
- 0.5586702127659574
- 0.5615425531914894
- 0.5595212765957447
- 0.5611702127659575
- 0.5621276595744681
- 0.5648404255319149
- 0.3612234042553191
- 0.5632446808510638
- 0.5657978723404256
- 0.5611702127659575
- 0.5674468085106383
- 0.5641489361702128
- 0.34111702127659577
- 0.24303191489361703
- 0.2722872340425532
- 0.1778723404255319
- 0.18212765957446808
- 0.1727659574468085
- 0.16632978723404254
- 0.565
- 0.5685106382978723
- 0.5711702127659575
- 0.5701063829787234
- 0.394468085106383
- 0.5714361702127659
- 0.39601063829787236
- 0.570531914893617
- 0.5723936170212766
- 0.5725531914893617
- 0.5752127659574469
- 0.574627659574468
- 0.573031914893617
- 0.5753191489361702
- 0.4774468085106383
- 0.5786170212765958
- 0.573936170212766
- 0.5761702127659575
- 0.4525
- 0.5770744680851064
- 0.5752659574468085
- 0.5808510638297872
- 0.5032446808510638
- 0.5832446808510638
- 0.47617021276595745
- 0.5854255319148937
- 0.5396276595744681
- 0.3398404255319149
- 0.5901063829787234
- 0.5834574468085106
test_loss_list:
- 3.7872622362772623
- 3.7487068780263266
- 3.566396408081055
- 3.3642813841501873
- 4.989705537160238
- 3.180496161778768
- 3.631609214146932
- 6.0689499473571775
- 2.9337874825795494
- 3.1395893541971844
- 3.0887310187021892
- 2.8814735635121664
- 3.2147893969217938
- 3.1902771250406903
- 3.225423914591471
- 3.5659860229492186
- 3.3285069052378335
- 3.274025535583496
- 3.24880139986674
- 3.455697234471639
- 3.3138866011301675
- 3.286190627415975
- 3.31162340482076
- 4.714885616302491
- 2.9708454449971518
- 3.1679513835906983
- 3.2644763946533204
- 3.21628843943278
- 3.115875221888224
- 3.2724007161458335
- 3.3860230445861816
- 3.3477129141489663
- 3.6041194915771486
- 3.527400248845418
- 3.3224125321706137
- 3.436433350245158
- 2.8144140656789145
- 3.0055344772338866
- 3.0819840749104817
- 3.1589882373809814
- 3.294664198557536
- 3.155932289759318
- 2.7415945625305174
- 2.6982545693715414
- 3.002851244608561
- 2.902832612991333
- 2.7847453339894614
- 4.541639302571615
- 2.4328418731689454
- 2.647154343922933
- 2.6171409765879314
- 2.913683150609334
- 2.9033533255259196
- 2.7724801858266193
- 2.8423967425028485
- 3.0009267552693686
- 2.8232312711079914
- 2.591638765335083
- 2.67659291267395
- 2.624565703074137
- 2.7212036863962807
- 2.854425862630208
- 2.884445193608602
- 2.7197517681121828
- 3.2053613535563152
- 2.6069830735524495
- 3.7595742988586425
- 4.077166191736857
- 4.229957367579142
- 4.30186429977417
- 1.8515000518163045
- 2.1542550150553383
- 2.3753486553827923
- 2.4432670656840005
- 2.1838287591934202
- 2.2932944536209106
- 2.22336612701416
- 2.1839901145299274
- 2.3794916613896686
- 2.3879428927103676
- 2.481885140736898
- 2.3966454871495566
- 2.4455143801371255
- 2.6367093658447267
- 1.765233899752299
- 2.2550157737731933
- 2.3812856260935464
- 2.5950219440460205
- 2.043940645853678
- 2.1177676932017007
- 2.2280053249994913
- 2.280287186304728
- 1.7884782902399698
- 2.159115824699402
- 2.1601522954305015
- 2.0359231408437095
- 1.6384120241800944
- 3.2638120619455973
- 1.9118068583806356
- 2.18333091100057
train_accuracy:
- 0.0
- 0.0
- 0.358
- 0.0
- 0.002
- 0.542
- 0.029
- 0.277
- 0.575
- 0.594
- 0.9
- 0.0
- 0.652
- 0.656
- 0.64
- 0.683
- 0.683
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.852
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.758
- 0.0
- 0.798
- 0.796
- 0.0
- 0.74
- 0.0
- 0.0
- 0.0
- 0.787
- 0.0
- 0.804
- 0.9
- 0.0
- 0.806
- 0.781
- 0.935
- 0.621
- 0.802
- 0.919
- 0.806
- 0.0
- 0.817
- 0.0
- 0.783
- 0.0
- 0.0
- 0.588
- 0.817
- 0.8
- 0.0
- 0.0
- 0.0
- 0.917
- 0.877
- 0.523
- 0.829
- 0.979
- 0.794
- 0.877
- 0.0
- 0.815
- 0.831
- 0.0
- 0.956
- 0.802
- 0.94
- 0.8
- 0.833
- 0.0
- 0.831
- 0.0
- 0.842
- 0.835
- 0.819
- 0.0
- 0.838
- 0.0
- 0.8
- 0.002
- 0.846
- 0.846
- 0.969
- 0.012
- 0.963
- 0.365
- 0.915
- 0.725
- 0.81
- 0.0
train_loss:
- 1.824
- 2.648
- 2.45
- 1.347
- 0.442
- 1.985
- 0.512
- 0.267
- 1.07
- 1.597
- 0.423
- 1.017
- 1.422
- 1.404
- 0.858
- 1.758
- 1.262
- 0.754
- 0.759
- 1.217
- 0.845
- 0.795
- 0.721
- 0.41
- 0.887
- 0.715
- 0.669
- 0.723
- 0.789
- 0.629
- 0.986
- 0.674
- 0.975
- 1.0
- 0.64
- 0.369
- 0.748
- 0.609
- 0.725
- 0.666
- 0.641
- 0.593
- 0.379
- 0.642
- 0.924
- 0.664
- 0.344
- 0.239
- 0.56
- 0.282
- 0.952
- 0.815
- 0.824
- 0.599
- 0.53
- 0.513
- 0.613
- 0.323
- 0.523
- 0.551
- 0.505
- 0.514
- 0.503
- 0.312
- 0.259
- 0.236
- 0.169
- 0.155
- 0.18
- 0.161
- 0.572
- 0.46
- 0.791
- 0.459
- 0.249
- 0.467
- 0.268
- 0.82
- 0.76
- 0.542
- 0.754
- 0.488
- 0.541
- 0.765
- 0.299
- 0.464
- 0.509
- 0.712
- 0.272
- 0.503
- 0.484
- 0.499
- 0.239
- 0.427
- 0.17
- 0.493
- 0.185
- 0.114
- 0.415
- 0.703
unequal: 0
verbose: 1
