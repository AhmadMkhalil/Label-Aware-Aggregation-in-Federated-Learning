avg_train_accuracy: 0.881
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02175531914893617
- 0.08319148936170213
- 0.18053191489361703
- 0.028244680851063828
- 0.27664893617021274
- 0.3299468085106383
- 0.35638297872340424
- 0.39026595744680853
- 0.044893617021276595
- 0.05553191489361702
- 0.40356382978723404
- 0.061010638297872344
- 0.4221808510638298
- 0.4297872340425532
- 0.4479255319148936
- 0.45526595744680853
- 0.468031914893617
- 0.4773936170212766
- 0.4850531914893617
- 0.1777659574468085
- 0.49
- 0.49148936170212765
- 0.1974468085106383
- 0.16430851063829788
- 0.5006914893617022
- 0.5039361702127659
- 0.5095744680851064
- 0.5093085106382979
- 0.24936170212765957
- 0.5173404255319148
- 0.20968085106382978
- 0.20558510638297872
- 0.1529255319148936
- 0.5236170212765957
- 0.28111702127659577
- 0.5272340425531915
- 0.3320744680851064
- 0.5319680851063829
- 0.5304255319148936
- 0.3252127659574468
- 0.5360106382978723
- 0.5406382978723404
- 0.5371276595744681
- 0.5373936170212766
- 0.5417021276595745
- 0.5396808510638298
- 0.5407446808510639
- 0.5427659574468086
- 0.5470212765957447
- 0.5484574468085106
- 0.35473404255319146
- 0.16888297872340424
- 0.1298936170212766
- 0.5567553191489362
- 0.5536702127659574
- 0.5502127659574468
- 0.5514361702127659
- 0.5557978723404255
- 0.4725531914893617
- 0.5530851063829787
- 0.4607978723404255
- 0.2620212765957447
- 0.5609042553191489
- 0.4679255319148936
- 0.5610106382978723
- 0.5600531914893617
- 0.5597872340425532
- 0.4129255319148936
- 0.2499468085106383
- 0.5647340425531915
- 0.563936170212766
- 0.4822872340425532
- 0.5758510638297872
- 0.5681382978723404
- 0.5677659574468085
- 0.566968085106383
- 0.5658510638297872
- 0.5665425531914894
- 0.3339893617021277
- 0.5704787234042553
- 0.5673404255319149
- 0.5681914893617022
- 0.4901063829787234
- 0.33904255319148935
- 0.573936170212766
- 0.45909574468085107
- 0.5757446808510638
- 0.5692021276595745
- 0.5708510638297872
- 0.5717553191489362
- 0.5676595744680851
- 0.42888297872340425
- 0.5777127659574468
- 0.5716489361702127
- 0.5712765957446808
- 0.3842553191489362
- 0.5818617021276595
- 0.5747340425531915
- 0.5768085106382979
- 0.5465425531914894
test_loss_list:
- 6.161761894226074
- 3.7096215724945067
- 3.5433895937601725
- 6.04679651260376
- 3.312066160837809
- 3.244551877975464
- 3.1623306401570637
- 3.110754617055257
- 5.984095656077067
- 4.4976783434549965
- 2.8935937817891437
- 4.915022640228272
- 2.8474681917826334
- 2.884845167795817
- 2.883655637105306
- 3.0064655049641926
- 2.9515141836802163
- 3.076638174057007
- 3.111373504002889
- 3.5129259141286213
- 2.674802694320679
- 2.8420521354675294
- 3.336736733118693
- 3.710657730102539
- 2.5737074565887452
- 2.561020164489746
- 2.658776299158732
- 2.663434298833211
- 3.0519563357035318
- 2.5392318471272786
- 3.14981759707133
- 3.3526957130432127
- 3.879573666254679
- 2.3355498917897544
- 3.270711835225423
- 2.3840448649724326
- 2.4044239648183185
- 2.2209952465693155
- 2.403819204966227
- 2.3591902764638264
- 2.225463447570801
- 2.461820748647054
- 2.425506509145101
- 2.474623540242513
- 2.4620895926157633
- 2.513411674499512
- 2.486772616704305
- 2.5670198726654054
- 2.5875531387329103
- 2.62185107866923
- 2.412483762105306
- 4.0008629671732585
- 5.4815818977355955
- 2.274207836786906
- 2.586106637318929
- 2.450398817062378
- 2.398364906311035
- 2.5959015146891278
- 1.9203976122538249
- 2.1652389653523763
- 2.0326619068781535
- 3.3811877377827964
- 2.0037792507807413
- 1.893545683224996
- 2.1393320258458455
- 2.221347907384237
- 2.2046447579065958
- 2.1418161964416504
- 3.1333849175771076
- 1.9607894484202066
- 2.072717162768046
- 1.8437571493784586
- 1.9543947474161785
- 2.1197196690241498
- 2.159601519902547
- 2.179384071032206
- 2.2603680817286174
- 2.228283535639445
- 2.698843781153361
- 2.058724652926127
- 2.1756193669637045
- 2.2380465761820476
- 1.8333380317687988
- 2.5126384766896566
- 1.8948527654012044
- 1.8511943912506104
- 1.895337371826172
- 2.0077809381484983
- 2.0554805246988934
- 2.209203503926595
- 2.189436403910319
- 2.2212460708618162
- 2.0887438297271728
- 2.2081295839945474
- 2.197204378445943
- 2.4700579198201496
- 1.896578605969747
- 2.0907216342290242
- 2.0602647749582927
- 1.6599887482325235
train_accuracy:
- 0.831
- 0.0
- 0.258
- 0.0
- 0.394
- 0.465
- 0.0
- 0.0
- 0.037
- 0.431
- 0.0
- 0.919
- 0.598
- 0.0
- 0.0
- 0.0
- 0.665
- 0.706
- 0.733
- 0.777
- 0.721
- 0.0
- 0.729
- 0.415
- 0.0
- 0.717
- 0.731
- 0.0
- 0.938
- 0.748
- 0.381
- 0.756
- 0.84
- 0.0
- 0.898
- 0.002
- 0.802
- 0.0
- 0.0
- 0.9
- 0.787
- 0.0
- 0.804
- 0.0
- 0.0
- 0.052
- 0.0
- 0.812
- 0.783
- 0.0
- 0.765
- 0.763
- 0.883
- 0.825
- 0.823
- 0.0
- 0.0
- 0.796
- 0.975
- 0.812
- 0.725
- 0.923
- 0.0
- 0.981
- 0.842
- 0.021
- 0.0
- 0.887
- 0.915
- 0.0
- 0.167
- 0.94
- 0.817
- 0.0
- 0.233
- 0.815
- 0.0
- 0.846
- 0.933
- 0.0
- 0.823
- 0.0
- 0.773
- 0.992
- 0.0
- 0.981
- 0.202
- 0.096
- 0.0
- 0.833
- 0.823
- 0.981
- 0.852
- 0.852
- 0.0
- 0.79
- 0.0
- 0.0
- 0.0
- 0.881
train_loss:
- 0.832
- 1.492
- 2.439
- 0.508
- 2.322
- 1.274
- 1.166
- 1.067
- 0.466
- 0.424
- 0.968
- 0.465
- 1.011
- 0.906
- 0.889
- 0.867
- 0.866
- 1.257
- 1.285
- 0.417
- 0.845
- 0.781
- 0.345
- 0.284
- 1.312
- 0.737
- 0.756
- 0.731
- 0.276
- 0.735
- 0.35
- 0.218
- 0.263
- 1.201
- 0.24
- 0.597
- 0.251
- 0.592
- 1.08
- 0.39
- 0.667
- 1.02
- 0.62
- 0.604
- 0.63
- 0.644
- 0.648
- 0.655
- 0.615
- 0.599
- 0.337
- 0.238
- 0.172
- 1.021
- 1.26
- 0.607
- 0.627
- 0.931
- 0.264
- 0.615
- 0.19
- 0.165
- 0.56
- 0.231
- 0.928
- 0.554
- 0.589
- 0.259
- 0.22
- 0.549
- 0.553
- 0.197
- 0.491
- 0.54
- 0.546
- 0.552
- 0.526
- 0.56
- 0.264
- 0.545
- 0.549
- 0.509
- 0.232
- 0.179
- 0.547
- 0.199
- 0.438
- 0.499
- 0.513
- 0.787
- 0.527
- 0.232
- 0.794
- 0.775
- 0.485
- 0.238
- 0.486
- 0.495
- 0.51
- 0.205
unequal: 0
verbose: 1
