avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033297872340425534
- 0.08457446808510638
- 0.18622340425531914
- 0.2999468085106383
- 0.06579787234042553
- 0.35138297872340424
- 0.3964893617021277
- 0.06808510638297872
- 0.4097340425531915
- 0.42734042553191487
- 0.43590425531914895
- 0.44813829787234044
- 0.46026595744680854
- 0.16297872340425532
- 0.46930851063829787
- 0.4760106382978723
- 0.28654255319148936
- 0.491436170212766
- 0.4922340425531915
- 0.5056382978723404
- 0.5133510638297872
- 0.5147340425531914
- 0.5153191489361703
- 0.5188829787234043
- 0.5246808510638298
- 0.5299468085106382
- 0.5307978723404255
- 0.30117021276595746
- 0.5340957446808511
- 0.26191489361702125
- 0.1494148936170213
- 0.5376595744680851
- 0.535904255319149
- 0.5407446808510639
- 0.5438829787234043
- 0.37670212765957445
- 0.18074468085106382
- 0.2025531914893617
- 0.5482446808510638
- 0.5445212765957447
- 0.5438829787234043
- 0.5479255319148936
- 0.5495212765957447
- 0.3758510638297872
- 0.5537234042553192
- 0.5552127659574468
- 0.4559042553191489
- 0.5575531914893617
- 0.5549468085106383
- 0.5561170212765958
- 0.5557446808510639
- 0.560372340425532
- 0.560531914893617
- 0.3498404255319149
- 0.25579787234042556
- 0.20547872340425533
- 0.5610106382978723
- 0.561968085106383
- 0.5624468085106383
- 0.5594148936170212
- 0.4647340425531915
- 0.5693085106382979
- 0.5685638297872341
- 0.5635106382978723
- 0.5641489361702128
- 0.5692553191489361
- 0.5658510638297872
- 0.3646276595744681
- 0.5692553191489361
- 0.5692021276595745
- 0.5676063829787235
- 0.45393617021276594
- 0.2839893617021277
- 0.21925531914893617
- 0.5778191489361703
- 0.5748936170212766
- 0.5736170212765958
- 0.5657978723404256
- 0.5720744680851064
- 0.5738829787234042
- 0.44377659574468087
- 0.5753191489361702
- 0.571968085106383
- 0.5732978723404255
- 0.5730851063829787
- 0.5740957446808511
- 0.41723404255319146
- 0.581063829787234
- 0.4812234042553192
- 0.5772340425531914
- 0.5762234042553191
- 0.5754255319148937
- 0.5753723404255319
- 0.5762234042553191
- 0.5746808510638298
- 0.5798936170212766
- 0.4584042553191489
- 0.5811702127659575
- 0.5788297872340425
- 0.5767021276595745
test_loss_list:
- 3.8205667559305825
- 3.8536597379048665
- 3.7604557355244954
- 3.689280796051025
- 4.741362775166829
- 3.3787275155385337
- 3.4182444477081297
- 5.10240550994873
- 3.0196825059254966
- 3.095342960357666
- 3.072093998591105
- 3.0856159019470213
- 3.1786588764190675
- 3.4357154432932537
- 2.717785250345866
- 2.819574343363444
- 2.8657805728912353
- 2.7645552444458006
- 2.8359812100728354
- 2.9536829090118406
- 2.9905619780222574
- 3.1735780525207518
- 3.1160024960835773
- 3.1017450586954753
- 3.073520787556966
- 3.0846381918589274
- 3.012605635325114
- 2.7427538776397706
- 2.717645190556844
- 2.9638656775156655
- 4.827636566162109
- 2.539402510325114
- 2.690110314687093
- 2.739895798365275
- 2.7735935179392497
- 2.468427168528239
- 4.200634762446086
- 3.4206834824879966
- 2.228746539751689
- 2.453888161977132
- 2.5806047439575197
- 2.56544997215271
- 2.594328680038452
- 2.4791958713531494
- 2.342555112838745
- 2.564169241587321
- 2.3102377732594808
- 2.3642823108037314
- 2.4954146734873452
- 2.421668399175008
- 2.553561038970947
- 2.5308273442586264
- 2.655263125101725
- 2.9846884187062583
- 2.7904793294270833
- 3.599552275339762
- 1.9627128012975057
- 2.205903231302897
- 2.2813442182540893
- 2.3895956389109294
- 2.150964182217916
- 2.125702144304911
- 2.3729433457056683
- 2.3074762709935506
- 2.3272106345494588
- 2.4704970423380535
- 2.434063784281413
- 2.1681909068425496
- 2.041034607887268
- 2.28825523853302
- 2.2951667404174803
- 1.9677435668309529
- 3.1326154613494874
- 3.6682436911265057
- 2.04579807917277
- 2.112752391497294
- 2.2088460111618042
- 2.2678568506240846
- 2.368605070114136
- 2.4004101880391437
- 2.1345199473698933
- 2.0992058420181277
- 2.2433191521962486
- 2.279293808937073
- 2.3500067520141603
- 2.3098087088267008
- 2.2681482442220053
- 2.0671849886576337
- 1.695847094853719
- 1.9045937951405842
- 2.0782223606109618
- 2.0826633167266846
- 2.1621866687138875
- 2.274197012583415
- 2.257401841481527
- 2.3590443468093873
- 2.1250566180547077
- 2.076177150408427
- 2.175119252204895
- 2.164320656458537
train_accuracy:
- 0.0
- 0.0
- 0.273
- 0.0
- 0.254
- 0.519
- 0.519
- 0.99
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.154
- 0.0
- 0.717
- 0.11
- 0.0
- 0.0
- 0.0
- 0.0
- 0.713
- 0.0
- 0.727
- 0.75
- 0.0
- 0.744
- 0.362
- 0.0
- 0.865
- 0.406
- 0.763
- 0.733
- 0.0
- 0.0
- 0.869
- 0.812
- 0.933
- 0.777
- 0.0
- 0.0
- 0.0
- 0.765
- 0.881
- 0.0
- 0.779
- 0.842
- 0.79
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.981
- 0.794
- 0.958
- 0.0
- 0.0
- 0.0
- 0.802
- 0.944
- 0.0
- 0.815
- 0.0
- 0.0
- 0.804
- 0.0
- 0.815
- 0.002
- 0.0
- 0.808
- 0.781
- 0.929
- 0.956
- 0.821
- 0.002
- 0.0
- 0.0
- 0.012
- 0.815
- 0.983
- 0.0
- 0.0
- 0.821
- 0.0
- 0.0
- 0.775
- 0.842
- 0.967
- 0.0
- 0.0
- 0.0
- 0.0
- 0.829
- 0.819
- 0.0
- 0.973
- 0.835
- 0.002
- 0.0
train_loss:
- 2.016
- 1.769
- 2.565
- 2.204
- 0.552
- 1.998
- 1.054
- 0.44
- 0.941
- 0.986
- 0.863
- 0.907
- 0.835
- 0.437
- 0.822
- 0.796
- 0.394
- 1.294
- 0.801
- 1.151
- 1.152
- 1.091
- 0.788
- 0.712
- 0.695
- 0.741
- 0.707
- 0.354
- 0.671
- 0.299
- 0.222
- 1.213
- 0.574
- 0.722
- 0.654
- 0.263
- 0.169
- 0.209
- 0.681
- 0.569
- 0.544
- 0.612
- 0.623
- 0.251
- 0.593
- 0.526
- 0.215
- 0.522
- 0.491
- 0.709
- 0.525
- 0.603
- 0.497
- 0.253
- 0.342
- 0.167
- 0.602
- 0.519
- 0.523
- 0.489
- 0.191
- 0.524
- 0.77
- 0.568
- 0.516
- 0.797
- 0.488
- 0.34
- 0.561
- 0.492
- 0.529
- 0.25
- 0.154
- 0.159
- 0.808
- 0.515
- 0.518
- 0.488
- 0.742
- 0.771
- 0.262
- 0.51
- 0.491
- 0.764
- 0.473
- 0.48
- 0.253
- 0.46
- 0.254
- 0.468
- 0.439
- 0.507
- 0.495
- 0.701
- 0.485
- 0.725
- 0.269
- 0.751
- 0.444
- 0.462
unequal: 0
verbose: 1
