avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05601063829787234
- 0.08414893617021277
- 0.20702127659574468
- 0.06675531914893618
- 0.048138297872340426
- 0.2651063829787234
- 0.31968085106382976
- 0.06164893617021277
- 0.3543085106382979
- 0.10143617021276596
- 0.4010106382978723
- 0.4195212765957447
- 0.42388297872340425
- 0.07781914893617022
- 0.44207446808510636
- 0.45468085106382977
- 0.4518617021276596
- 0.14845744680851064
- 0.08946808510638297
- 0.09776595744680851
- 0.46170212765957447
- 0.4792021276595745
- 0.48696808510638295
- 0.16792553191489362
- 0.09489361702127659
- 0.483031914893617
- 0.4934574468085106
- 0.5056914893617022
- 0.5074468085106383
- 0.5043617021276596
- 0.5192021276595745
- 0.515
- 0.5173404255319148
- 0.28425531914893615
- 0.5153191489361703
- 0.5282446808510638
- 0.5313297872340426
- 0.19835106382978723
- 0.5342021276595744
- 0.5364361702127659
- 0.5361702127659574
- 0.5376063829787234
- 0.35138297872340424
- 0.5375
- 0.5412765957446809
- 0.3670212765957447
- 0.1652127659574468
- 0.5457446808510639
- 0.5494148936170212
- 0.5470744680851064
- 0.5496276595744681
- 0.5495744680851063
- 0.5525531914893617
- 0.39356382978723403
- 0.5497340425531915
- 0.5582978723404255
- 0.5573936170212765
- 0.5585106382978723
- 0.42851063829787234
- 0.5611702127659575
- 0.5618085106382978
- 0.5591489361702128
- 0.5617553191489362
- 0.5651595744680851
- 0.5607978723404256
- 0.393031914893617
- 0.2575
- 0.564468085106383
- 0.566063829787234
- 0.5656382978723404
- 0.5668617021276596
- 0.5689893617021277
- 0.5679255319148936
- 0.4429787234042553
- 0.24473404255319148
- 0.1949468085106383
- 0.21340425531914894
- 0.5708510638297872
- 0.2928723404255319
- 0.578031914893617
- 0.574468085106383
- 0.5140425531914894
- 0.5703191489361702
- 0.5679255319148936
- 0.5740957446808511
- 0.5735106382978723
- 0.5712765957446808
- 0.5738297872340425
- 0.5682446808510638
- 0.5753191489361702
- 0.5738829787234042
- 0.5738297872340425
- 0.5757446808510638
- 0.5753723404255319
- 0.5743617021276596
- 0.5788829787234042
- 0.4695744680851064
- 0.20824468085106382
- 0.2926595744680851
- 0.5833510638297872
test_loss_list:
- 7.433481769561768
- 3.6979911454518635
- 3.519086322784424
- 4.867814903259277
- 5.297089742024739
- 3.220523360570272
- 3.1777200667063394
- 5.207757066090902
- 3.016199099222819
- 3.818868360519409
- 3.076801586151123
- 3.0852978515625
- 3.1283608722686767
- 4.366224466959635
- 2.9052488136291506
- 3.120125830968221
- 3.0478745301564536
- 3.6777907466888426
- 4.949111493428548
- 4.604952144622803
- 2.7866492080688476
- 2.827145776748657
- 2.918433256149292
- 3.629365758895874
- 5.9563744926452635
- 2.6685586166381836
- 2.9086727492014566
- 2.870592177708944
- 3.0441918690999348
- 2.891977383295695
- 2.9997009881337484
- 3.025324691136678
- 3.0826105213165285
- 3.107592471440633
- 2.8025620492299397
- 2.881966927846273
- 3.073430414199829
- 3.607707659403483
- 2.718797801335653
- 2.7787367312113442
- 2.8024066575368245
- 2.9269511858622232
- 2.5426073551177977
- 2.5549044386545816
- 2.7576758829752603
- 2.338098958333333
- 4.037668533325196
- 2.3948350683848063
- 2.5803145217895507
- 2.567780408859253
- 2.7813656743367514
- 2.7021461709340415
- 2.7057598272959393
- 2.378838628133138
- 2.547578140894572
- 2.62241405804952
- 2.701034911473592
- 2.712493902842204
- 2.2120215924580893
- 2.50236097017924
- 2.692078841527303
- 2.676532777150472
- 2.6225531101226807
- 2.751424814860026
- 2.70859832127889
- 2.338568671544393
- 3.521348403294881
- 2.387192907333374
- 2.454988873799642
- 2.5997161356608074
- 2.5961960315704347
- 2.5482692178090414
- 2.5265733083089192
- 2.210683240890503
- 3.522334836324056
- 3.577281068166097
- 3.1119299666086833
- 2.192220362027486
- 2.834440491994222
- 2.098858981132507
- 2.1590048456192017
- 1.6741877714792888
- 2.0235853513081867
- 2.126728892326355
- 2.294635583559672
- 2.4306124591827394
- 2.3646203517913817
- 2.529613593419393
- 2.4148946094512937
- 2.579385223388672
- 2.466285120646159
- 2.467567679087321
- 2.6726804320017497
- 2.475463612874349
- 2.47568689028422
- 2.490411122639974
- 2.070659942626953
- 3.707309277852376
- 2.9891871929168703
- 1.9173754326502481
train_accuracy:
- 0.0
- 0.0
- 0.288
- 0.0
- 0.981
- 0.362
- 0.448
- 0.906
- 0.0
- 0.388
- 0.0
- 0.0
- 0.631
- 0.919
- 0.631
- 0.0
- 0.0
- 0.719
- 0.887
- 0.504
- 0.669
- 0.696
- 0.7
- 0.704
- 0.069
- 0.0
- 0.0
- 0.0
- 0.746
- 0.729
- 0.0
- 0.0
- 0.737
- 0.935
- 0.0
- 0.0
- 0.771
- 0.867
- 0.763
- 0.0
- 0.777
- 0.771
- 0.821
- 0.771
- 0.0
- 0.971
- 0.523
- 0.792
- 0.0
- 0.0
- 0.8
- 0.0
- 0.812
- 0.919
- 0.0
- 0.815
- 0.806
- 0.819
- 0.585
- 0.81
- 0.792
- 0.002
- 0.0
- 0.0
- 0.002
- 0.935
- 0.954
- 0.002
- 0.812
- 0.831
- 0.815
- 0.815
- 0.0
- 0.548
- 0.925
- 0.229
- 0.698
- 0.11
- 0.965
- 0.819
- 0.815
- 0.95
- 0.823
- 0.0
- 0.844
- 0.821
- 0.823
- 0.846
- 0.823
- 0.0
- 0.0
- 0.0
- 0.852
- 0.833
- 0.844
- 0.825
- 0.946
- 0.952
- 0.831
- 0.0
train_loss:
- 0.751
- 1.511
- 2.583
- 0.43
- 0.395
- 1.166
- 1.202
- 0.415
- 1.32
- 0.378
- 1.762
- 1.037
- 0.91
- 0.365
- 1.598
- 1.428
- 0.816
- 0.494
- 0.369
- 0.348
- 1.559
- 0.881
- 0.819
- 0.336
- 0.216
- 0.802
- 0.704
- 0.732
- 0.679
- 0.8
- 0.767
- 0.77
- 0.709
- 0.276
- 0.809
- 0.639
- 1.039
- 0.452
- 1.153
- 0.671
- 0.656
- 0.617
- 0.31
- 0.704
- 0.578
- 0.287
- 0.263
- 1.049
- 0.948
- 0.666
- 0.945
- 0.59
- 0.594
- 0.255
- 0.587
- 0.918
- 0.552
- 0.921
- 0.307
- 0.947
- 0.858
- 0.531
- 0.543
- 0.84
- 0.526
- 0.3
- 0.158
- 0.568
- 0.5
- 0.858
- 0.895
- 0.591
- 0.562
- 0.264
- 0.237
- 0.185
- 0.213
- 0.857
- 0.244
- 0.878
- 0.546
- 0.223
- 0.483
- 0.547
- 0.814
- 0.76
- 0.528
- 0.779
- 0.523
- 0.754
- 0.501
- 0.512
- 0.727
- 0.547
- 0.572
- 0.501
- 0.25
- 0.175
- 0.219
- 0.516
unequal: 0
verbose: 1
