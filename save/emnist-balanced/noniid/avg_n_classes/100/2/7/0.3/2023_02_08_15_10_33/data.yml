avg_train_accuracy: 0.981
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04478723404255319
- 0.0424468085106383
- 0.12404255319148937
- 0.05840425531914894
- 0.0700531914893617
- 0.22691489361702127
- 0.29606382978723406
- 0.33148936170212767
- 0.3558510638297872
- 0.3783510638297872
- 0.40372340425531916
- 0.40856382978723405
- 0.4249468085106383
- 0.0775
- 0.09377659574468085
- 0.09
- 0.09234042553191489
- 0.08898936170212766
- 0.07574468085106383
- 0.08643617021276596
- 0.42606382978723406
- 0.4405851063829787
- 0.46239361702127657
- 0.46627659574468083
- 0.46574468085106385
- 0.4743617021276596
- 0.48473404255319147
- 0.49138297872340425
- 0.49398936170212765
- 0.4950531914893617
- 0.18728723404255318
- 0.5061170212765957
- 0.5024468085106383
- 0.5100531914893617
- 0.5099468085106383
- 0.20659574468085107
- 0.5180851063829788
- 0.341968085106383
- 0.5199468085106383
- 0.5254255319148936
- 0.5237234042553192
- 0.3452659574468085
- 0.533031914893617
- 0.5318085106382979
- 0.32170212765957445
- 0.16537234042553192
- 0.5342553191489362
- 0.5409574468085107
- 0.5354255319148936
- 0.541063829787234
- 0.5441489361702128
- 0.39441489361702126
- 0.5413829787234042
- 0.3296276595744681
- 0.5464893617021277
- 0.5492553191489362
- 0.5488829787234043
- 0.42345744680851066
- 0.551063829787234
- 0.45526595744680853
- 0.558031914893617
- 0.5506914893617021
- 0.5534574468085106
- 0.5571808510638298
- 0.5580851063829787
- 0.49877659574468086
- 0.5580851063829787
- 0.5568617021276596
- 0.5172340425531915
- 0.561063829787234
- 0.43420212765957444
- 0.5628191489361702
- 0.5648404255319149
- 0.5617553191489362
- 0.38143617021276593
- 0.5635638297872341
- 0.51
- 0.5719148936170213
- 0.5652127659574468
- 0.4782446808510638
- 0.5097872340425532
- 0.4010106382978723
- 0.5753723404255319
- 0.57
- 0.39952127659574466
- 0.5714361702127659
- 0.5673936170212766
- 0.4833510638297872
- 0.4771808510638298
- 0.57
- 0.5718085106382979
- 0.5675531914893617
- 0.568936170212766
- 0.4779255319148936
- 0.5778191489361703
- 0.5697872340425532
- 0.5727659574468085
- 0.5757978723404256
- 0.5751063829787234
- 0.41345744680851065
test_loss_list:
- 3.7745565954844156
- 5.240814100901286
- 3.569735600153605
- 4.877211106618246
- 4.632887732187907
- 3.251702165603638
- 3.214801158905029
- 3.1596916707356772
- 3.207201172510783
- 3.161959187189738
- 3.1698668893178303
- 3.2509271335601806
- 3.16453267733256
- 4.430867303212484
- 5.481847540537516
- 4.625946960449219
- 4.119688227971395
- 5.548096879323324
- 8.037718079884847
- 8.960718167622884
- 2.878162546157837
- 2.943600959777832
- 3.0668201351165774
- 2.982401968638102
- 3.004788885116577
- 3.020475107828776
- 2.959407917658488
- 3.1395078563690184
- 2.9635487620035805
- 3.0581359004974367
- 3.367252810796102
- 2.865311377843221
- 3.001185960769653
- 2.950253448486328
- 3.0808633009592694
- 3.4843311150868734
- 2.9307648277282716
- 2.8654579162597655
- 2.794905672073364
- 2.804992265701294
- 2.9130749320983886
- 2.4884066931406656
- 2.6593022886912028
- 2.623826033274333
- 2.83510360399882
- 3.696725304921468
- 2.420717134475708
- 2.5916853841145833
- 2.628841609954834
- 2.531377671559652
- 2.686166435877482
- 2.5423029232025147
- 2.3064666986465454
- 2.6877529780069986
- 2.367538652420044
- 2.506420373916626
- 2.47338809967041
- 2.2792908986409506
- 2.2009198888142905
- 2.0177021710077923
- 2.073491799036662
- 2.2998872009913125
- 2.2793079376220704
- 2.4272687911987303
- 2.494531208674113
- 1.8509673404693603
- 2.2824903917312622
- 2.2706646505991617
- 1.7896198670069376
- 2.252207891146342
- 2.3681640752156574
- 2.034405970573425
- 2.2004398743311566
- 2.2672401889165243
- 2.3739544423421224
- 2.0307664982477824
- 1.7058849716186524
- 1.9451219447453816
- 2.018908643722534
- 1.9241638978322346
- 1.6063516712188721
- 2.1659632364908856
- 1.7671354945500692
- 1.9020489597320556
- 2.1689954074223836
- 1.8173129320144654
- 2.006839280128479
- 1.9118681732813518
- 1.6927597284317017
- 1.6638885847727458
- 1.880025873184204
- 1.972492480278015
- 1.9894039630889893
- 1.905607557296753
- 1.7994906441370646
- 2.0206577444076537
- 2.040153915087382
- 1.52693807442983
- 1.8366408570607504
- 2.171710817019145
train_accuracy:
- 0.044
- 0.956
- 0.0
- 0.302
- 0.242
- 0.0
- 0.0
- 0.477
- 0.0
- 0.0
- 0.575
- 0.571
- 0.0
- 0.442
- 0.66
- 0.229
- 0.994
- 0.515
- 0.062
- 0.975
- 0.596
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.721
- 0.69
- 0.0
- 0.487
- 0.7
- 0.706
- 0.715
- 0.717
- 0.658
- 0.727
- 0.775
- 0.0
- 0.735
- 0.0
- 0.346
- 0.752
- 0.0
- 0.883
- 0.996
- 0.0
- 0.752
- 0.0
- 0.0
- 0.785
- 0.958
- 0.0
- 0.912
- 0.767
- 0.0
- 0.0
- 0.421
- 0.0
- 0.79
- 0.056
- 0.05
- 0.781
- 0.804
- 0.787
- 0.892
- 0.817
- 0.792
- 0.571
- 0.806
- 0.617
- 0.0
- 0.812
- 0.008
- 0.89
- 0.806
- 0.812
- 0.798
- 0.0
- 0.598
- 0.665
- 0.865
- 0.804
- 0.033
- 0.692
- 0.0
- 0.002
- 0.967
- 0.696
- 0.0
- 0.812
- 0.794
- 0.0
- 0.969
- 0.0
- 0.806
- 0.808
- 0.765
- 0.81
- 0.981
train_loss:
- 1.852
- 0.809
- 1.555
- 0.468
- 0.527
- 1.346
- 1.119
- 1.109
- 1.038
- 1.227
- 1.111
- 1.053
- 1.088
- 0.571
- 0.375
- 0.512
- 0.453
- 0.379
- 0.203
- 0.149
- 1.808
- 0.967
- 1.318
- 0.863
- 0.884
- 0.95
- 0.931
- 1.293
- 0.918
- 0.838
- 0.489
- 1.264
- 0.731
- 0.75
- 0.742
- 0.487
- 1.162
- 0.311
- 0.633
- 0.685
- 0.675
- 0.471
- 1.168
- 0.839
- 0.396
- 0.275
- 1.141
- 1.014
- 0.697
- 0.811
- 1.051
- 0.35
- 0.778
- 0.355
- 1.056
- 0.937
- 0.702
- 0.383
- 0.744
- 0.336
- 0.541
- 0.642
- 0.64
- 0.937
- 0.971
- 0.335
- 1.011
- 0.664
- 0.334
- 0.898
- 0.202
- 0.687
- 0.546
- 0.635
- 0.362
- 0.518
- 0.342
- 0.863
- 0.595
- 0.358
- 0.221
- 0.257
- 0.877
- 0.504
- 0.307
- 0.542
- 0.814
- 0.213
- 0.347
- 0.613
- 0.844
- 0.639
- 0.527
- 0.27
- 0.479
- 0.821
- 0.563
- 0.303
- 0.637
- 0.296
unequal: 0
verbose: 1
