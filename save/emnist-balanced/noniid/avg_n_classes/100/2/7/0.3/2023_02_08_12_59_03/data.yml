avg_train_accuracy: 0.0
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021382978723404257
- 0.09515957446808511
- 0.20335106382978724
- 0.2835106382978723
- 0.3217553191489362
- 0.35132978723404257
- 0.39111702127659576
- 0.4107446808510638
- 0.40893617021276596
- 0.42781914893617023
- 0.44053191489361704
- 0.4468617021276596
- 0.16484042553191489
- 0.46202127659574466
- 0.4605851063829787
- 0.12234042553191489
- 0.08473404255319149
- 0.46441489361702126
- 0.4769148936170213
- 0.4836170212765957
- 0.48367021276595745
- 0.491436170212766
- 0.49127659574468086
- 0.4948936170212766
- 0.5027659574468085
- 0.5080851063829788
- 0.5203723404255319
- 0.5178191489361702
- 0.5178723404255319
- 0.5199468085106383
- 0.5201595744680851
- 0.5334574468085106
- 0.5329255319148937
- 0.5339893617021276
- 0.24159574468085107
- 0.5290957446808511
- 0.5345744680851063
- 0.5397872340425532
- 0.535
- 0.20414893617021276
- 0.24648936170212765
- 0.14622340425531916
- 0.5311702127659574
- 0.5471276595744681
- 0.5470212765957447
- 0.5433510638297873
- 0.25765957446808513
- 0.5516489361702127
- 0.33808510638297873
- 0.5486702127659574
- 0.5552659574468085
- 0.5542021276595744
- 0.3725531914893617
- 0.5551063829787234
- 0.5563829787234043
- 0.5529255319148936
- 0.5559574468085107
- 0.5588829787234042
- 0.5562234042553191
- 0.4798936170212766
- 0.1974468085106383
- 0.5578723404255319
- 0.5596808510638298
- 0.5643617021276596
- 0.559468085106383
- 0.5632446808510638
- 0.563936170212766
- 0.5605851063829788
- 0.4785106382978723
- 0.5657978723404256
- 0.5630851063829787
- 0.5631382978723404
- 0.5640957446808511
- 0.5620744680851064
- 0.43675531914893617
- 0.5684574468085106
- 0.45063829787234044
- 0.569627659574468
- 0.5657978723404256
- 0.5662234042553191
- 0.3173936170212766
- 0.3355851063829787
- 0.5685638297872341
- 0.426436170212766
- 0.574627659574468
- 0.5721276595744681
- 0.4848404255319149
- 0.5779255319148936
- 0.38835106382978724
- 0.5723404255319149
- 0.5758510638297872
- 0.5712234042553191
- 0.5072872340425532
- 0.5747340425531915
- 0.5346276595744681
- 0.28845744680851065
- 0.5814893617021276
- 0.5749468085106383
- 0.5766489361702127
- 0.5762765957446808
test_loss_list:
- 7.030560111999511
- 3.6755579566955565
- 3.4573969904581707
- 3.351104793548584
- 3.219178860982259
- 3.2244642225901288
- 3.29272886912028
- 3.3070505491892495
- 3.2302857780456544
- 3.1616551971435545
- 3.2141253662109377
- 3.1869904295603435
- 3.4371876017252605
- 2.961772454579671
- 2.9662210591634115
- 3.646911678314209
- 4.8220274416605635
- 2.6686566003163654
- 2.9137547715504963
- 2.8572865517934165
- 2.9157746760050456
- 2.958732719421387
- 2.971531105041504
- 3.0126697889963787
- 2.919656483332316
- 3.0646729214986164
- 3.1313772996266684
- 3.0954750061035154
- 3.050470339457194
- 3.0728359413146973
- 3.105056521097819
- 3.1365585136413574
- 3.170171791712443
- 3.161098454793294
- 3.103839495976766
- 2.6563752428690592
- 2.8884679222106935
- 2.889077777862549
- 2.9905743408203125
- 3.262132104237874
- 2.734510367711385
- 3.9805633958180744
- 2.3173374366760253
- 2.673228216171265
- 2.6369645818074545
- 2.67093807220459
- 2.98312806447347
- 2.6063791370391844
- 2.6425338713328044
- 2.392573110262553
- 2.609541877110799
- 2.6544243653615314
- 2.3001501433054607
- 2.355031147003174
- 2.423461449940999
- 2.488255014419556
- 2.4749972724914553
- 2.612474422454834
- 2.52077925046285
- 1.965670584042867
- 3.731728359858195
- 2.2190413284301758
- 2.353683026631673
- 2.5014682674407958
- 2.4010476016998292
- 2.4412187639872234
- 2.565646753311157
- 2.4533313051859538
- 1.8411498165130615
- 2.2259285815556846
- 2.33291494846344
- 2.3199363072713215
- 2.3942593129475913
- 2.3788819948832196
- 2.0735117530822755
- 2.1736639467875163
- 2.1740480120976766
- 2.0701614793141685
- 2.234550148646037
- 2.2700088278452557
- 2.4192567920684813
- 2.240738789240519
- 1.9066776895523072
- 1.9066219425201416
- 1.8763099479675294
- 2.0212770064671832
- 1.745529286066691
- 1.9881763982772827
- 2.287138493855794
- 1.8760902245839437
- 2.0545719210306803
- 2.125370292663574
- 1.708356383641561
- 1.9802765544255574
- 1.5530370235443116
- 2.8765905857086183
- 1.844758276939392
- 2.0210767873128255
- 2.034008258183797
- 2.061113484700521
train_accuracy:
- 0.004
- 0.0
- 0.0
- 0.408
- 0.46
- 0.5
- 0.0
- 0.602
- 0.602
- 0.0
- 0.0
- 0.64
- 0.137
- 0.0
- 0.0
- 0.04
- 0.265
- 0.652
- 0.656
- 0.0
- 0.0
- 0.737
- 0.74
- 0.7
- 0.721
- 0.723
- 0.781
- 0.729
- 0.0
- 0.0
- 0.0
- 0.796
- 0.796
- 0.794
- 0.823
- 0.0
- 0.74
- 0.0
- 0.002
- 0.881
- 0.896
- 0.473
- 0.0
- 0.0
- 0.0
- 0.0
- 0.494
- 0.81
- 0.285
- 0.0
- 0.781
- 0.769
- 0.7
- 0.808
- 0.769
- 0.002
- 0.0
- 0.808
- 0.804
- 0.74
- 0.942
- 0.021
- 0.015
- 0.812
- 0.0
- 0.823
- 0.804
- 0.825
- 0.871
- 0.0
- 0.0
- 0.0
- 0.821
- 0.0
- 0.917
- 0.004
- 0.402
- 0.002
- 0.021
- 0.004
- 0.954
- 0.867
- 0.0
- 0.869
- 0.794
- 0.0
- 0.871
- 0.794
- 0.894
- 0.029
- 0.0
- 0.0
- 0.971
- 0.835
- 0.971
- 0.865
- 0.796
- 0.827
- 0.0
- 0.0
train_loss:
- 0.823
- 1.53
- 1.445
- 2.127
- 1.191
- 1.069
- 1.643
- 1.576
- 0.95
- 0.964
- 0.955
- 0.911
- 0.463
- 1.427
- 0.854
- 0.421
- 0.276
- 0.793
- 1.255
- 0.826
- 0.789
- 0.887
- 0.752
- 0.795
- 0.827
- 0.708
- 1.116
- 0.739
- 0.753
- 0.74
- 0.695
- 1.069
- 1.064
- 1.074
- 0.394
- 0.63
- 0.658
- 0.671
- 0.633
- 0.331
- 0.323
- 0.248
- 0.591
- 0.909
- 0.586
- 0.621
- 0.307
- 0.963
- 0.235
- 0.585
- 0.919
- 0.884
- 0.291
- 0.952
- 0.545
- 0.545
- 0.593
- 0.888
- 0.594
- 0.27
- 0.162
- 0.556
- 0.515
- 0.823
- 0.56
- 0.589
- 0.546
- 0.542
- 0.297
- 0.488
- 0.52
- 0.548
- 0.487
- 0.487
- 0.239
- 0.508
- 0.215
- 0.545
- 0.464
- 0.526
- 0.301
- 0.228
- 0.502
- 0.197
- 0.484
- 0.504
- 0.22
- 0.799
- 0.227
- 0.467
- 0.741
- 0.453
- 0.209
- 0.804
- 0.224
- 0.129
- 0.772
- 0.752
- 0.493
- 0.493
unequal: 0
verbose: 1
