avg_train_accuracy: 0.985
avg_train_loss: 0.002
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03845744680851064
- 0.12590425531914895
- 0.22952127659574467
- 0.3075531914893617
- 0.024787234042553192
- 0.061595744680851064
- 0.345
- 0.38090425531914895
- 0.06877659574468085
- 0.07095744680851064
- 0.07409574468085106
- 0.3976063829787234
- 0.08643617021276596
- 0.42595744680851066
- 0.11101063829787235
- 0.4378723404255319
- 0.4547340425531915
- 0.4597340425531915
- 0.4653191489361702
- 0.47372340425531917
- 0.4845744680851064
- 0.4902127659574468
- 0.14111702127659576
- 0.4950531914893617
- 0.49877659574468086
- 0.2103723404255319
- 0.5043085106382978
- 0.5070212765957447
- 0.5138829787234043
- 0.5188829787234043
- 0.521595744680851
- 0.22680851063829788
- 0.5240425531914894
- 0.5305319148936171
- 0.20436170212765958
- 0.5307978723404255
- 0.5308510638297872
- 0.5399468085106383
- 0.5378191489361702
- 0.2378191489361702
- 0.5381914893617021
- 0.286968085106383
- 0.5381382978723405
- 0.5440957446808511
- 0.5438829787234043
- 0.5460106382978723
- 0.5461702127659575
- 0.5535638297872341
- 0.551968085106383
- 0.5568617021276596
- 0.5525
- 0.5563297872340426
- 0.5591489361702128
- 0.5579787234042554
- 0.5600531914893617
- 0.5593085106382979
- 0.5569148936170213
- 0.5624468085106383
- 0.36617021276595746
- 0.5612765957446808
- 0.34462765957446806
- 0.5652127659574468
- 0.4002659574468085
- 0.565531914893617
- 0.561968085106383
- 0.5654787234042553
- 0.5671808510638298
- 0.5008510638297873
- 0.3203191489361702
- 0.5694148936170212
- 0.5647872340425532
- 0.4895212765957447
- 0.571063829787234
- 0.47345744680851065
- 0.5710106382978724
- 0.5306914893617021
- 0.2703191489361702
- 0.5813829787234043
- 0.5707446808510638
- 0.5704255319148936
- 0.5115425531914893
- 0.5833510638297872
- 0.5715957446808511
- 0.49106382978723406
- 0.5796808510638298
- 0.47202127659574467
- 0.3924468085106383
- 0.5765957446808511
- 0.5758510638297872
- 0.4596808510638298
- 0.5911702127659575
- 0.4457978723404255
- 0.2996276595744681
- 0.5854255319148937
- 0.5780851063829787
- 0.5740957446808511
- 0.5754787234042553
- 0.5737234042553192
- 0.45015957446808513
- 0.3704787234042553
test_loss_list:
- 3.7812519168853758
- 3.736586818695068
- 3.569770743052165
- 3.4467999013264974
- 5.9357952308654784
- 5.66244883219401
- 3.15435791015625
- 3.2012971782684327
- 4.7205564943949385
- 5.425956344604492
- 6.994791202545166
- 2.8999817498524982
- 5.148770338694255
- 2.930308853785197
- 3.891184581120809
- 2.9291990566253663
- 2.9533245182037353
- 2.98339763323466
- 3.0187976296742756
- 3.0528458309173585
- 3.238084243138631
- 3.2291793537139895
- 4.212095292409261
- 2.944849163691203
- 3.084738130569458
- 3.751061102549235
- 2.6266619237263997
- 2.826495320002238
- 2.8309425258636476
- 2.894598404566447
- 3.014425579706828
- 3.2254927730560303
- 2.56880410194397
- 2.946143471399943
- 3.598907168706258
- 2.4812866083780922
- 2.633877092997233
- 2.7056145413716632
- 2.6700825055440265
- 3.253965965906779
- 2.6676749992370605
- 2.924984442392985
- 2.3533953460057577
- 2.4718343098958333
- 2.537060283025106
- 2.4703796037038166
- 2.5792878818511964
- 2.6946011130015055
- 2.6086906750996905
- 2.5848846340179445
- 2.6531496556599934
- 2.585007530848185
- 2.607242727279663
- 2.6205103492736814
- 2.643257884979248
- 2.735317204793294
- 2.6728282356262207
- 2.6644954903920492
- 2.440789108276367
- 2.283516043027242
- 2.7939606221516926
- 2.376752864519755
- 2.4799620310465493
- 2.086166429519653
- 2.298066193262736
- 2.438106034596761
- 2.4413886324564618
- 1.940269791285197
- 2.6354987653096518
- 2.0925793727238973
- 2.1702124802271525
- 2.0052253421147666
- 2.142349637349447
- 1.9142026392618816
- 2.040404512087504
- 1.7949129549662273
- 3.4918932056427003
- 1.7905066188176473
- 1.9991010904312134
- 2.155775899887085
- 1.6847163550059001
- 1.9512175734837849
- 2.087054745356242
- 1.8139165019989014
- 1.863880647023519
- 1.9649669313430786
- 2.200712146759033
- 1.9568357960383098
- 1.9508571974436442
- 2.100960127512614
- 1.898384429613749
- 1.9078358364105226
- 3.095537099838257
- 1.7089326270421346
- 1.8737230205535889
- 1.9279716809590657
- 1.9240860509872437
- 1.9843088483810425
- 2.0571512826283773
- 2.421344191233317
train_accuracy:
- 0.06
- 0.0
- 0.0
- 0.0
- 0.996
- 0.896
- 0.0
- 0.537
- 0.831
- 0.756
- 0.835
- 0.0
- 0.015
- 0.617
- 0.973
- 0.619
- 0.0
- 0.0
- 0.0
- 0.685
- 0.713
- 0.725
- 0.887
- 0.735
- 0.735
- 0.881
- 0.0
- 0.746
- 0.0
- 0.0
- 0.0
- 0.923
- 0.01
- 0.781
- 0.973
- 0.0
- 0.0
- 0.75
- 0.0
- 0.067
- 0.804
- 0.983
- 0.0
- 0.0
- 0.0
- 0.769
- 0.0
- 0.796
- 0.0
- 0.773
- 0.804
- 0.0
- 0.0
- 0.0
- 0.817
- 0.821
- 0.0
- 0.0
- 0.912
- 0.815
- 0.971
- 0.823
- 0.994
- 0.79
- 0.819
- 0.0
- 0.0
- 0.725
- 0.906
- 0.002
- 0.077
- 0.744
- 0.833
- 0.946
- 0.821
- 0.621
- 0.946
- 0.296
- 0.817
- 0.0
- 0.887
- 0.106
- 0.827
- 0.921
- 0.0
- 0.796
- 0.923
- 0.806
- 0.0
- 0.965
- 0.81
- 0.829
- 0.877
- 0.019
- 0.0
- 0.815
- 0.0
- 0.0
- 0.931
- 0.985
train_loss:
- 2.734
- 1.698
- 2.341
- 1.269
- 0.581
- 0.388
- 1.148
- 1.268
- 0.415
- 0.385
- 0.243
- 1.116
- 0.358
- 1.674
- 0.358
- 0.894
- 0.854
- 0.856
- 0.837
- 0.817
- 1.266
- 1.226
- 0.501
- 1.317
- 1.172
- 0.357
- 0.771
- 0.687
- 0.765
- 0.707
- 1.068
- 0.332
- 0.667
- 1.421
- 0.311
- 0.721
- 0.64
- 0.626
- 0.653
- 0.329
- 0.979
- 0.304
- 0.615
- 0.582
- 0.565
- 0.65
- 0.574
- 0.906
- 0.62
- 0.582
- 0.603
- 0.593
- 0.599
- 0.584
- 0.545
- 0.528
- 0.552
- 0.557
- 0.306
- 0.511
- 0.206
- 0.864
- 0.269
- 0.522
- 0.502
- 0.811
- 0.799
- 0.258
- 0.202
- 0.508
- 0.475
- 0.205
- 0.492
- 0.22
- 0.835
- 0.193
- 0.202
- 0.52
- 0.488
- 0.486
- 0.218
- 0.422
- 0.473
- 0.214
- 0.5
- 0.219
- 0.157
- 1.137
- 0.484
- 0.167
- 0.424
- 0.226
- 0.139
- 0.448
- 0.477
- 0.482
- 0.514
- 0.488
- 0.202
- 0.187
unequal: 0
verbose: 1
