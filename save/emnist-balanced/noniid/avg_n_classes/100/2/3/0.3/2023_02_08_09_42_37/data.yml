avg_train_accuracy: 0.823
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026382978723404255
- 0.05132978723404255
- 0.12138297872340426
- 0.19861702127659575
- 0.3357978723404255
- 0.3984042553191489
- 0.4529787234042553
- 0.49031914893617023
- 0.5139893617021276
- 0.535
- 0.550372340425532
- 0.5605851063829788
- 0.5690425531914893
- 0.5752127659574469
- 0.5859042553191489
- 0.5956382978723405
- 0.5915425531914894
- 0.601063829787234
- 0.6077659574468085
- 0.615
- 0.6090425531914894
- 0.6226063829787234
- 0.6265425531914893
- 0.6298936170212766
- 0.6356914893617022
- 0.6342553191489362
- 0.6398404255319149
- 0.6441489361702127
- 0.642127659574468
- 0.6447872340425532
- 0.6424468085106383
- 0.6518085106382979
- 0.6573404255319149
- 0.6617553191489361
- 0.6616489361702128
- 0.6561702127659574
- 0.6612234042553191
- 0.6681914893617021
- 0.6698404255319149
- 0.6685106382978724
- 0.6745744680851063
- 0.6713829787234042
- 0.6776595744680851
- 0.6787765957446809
- 0.6787234042553192
- 0.681063829787234
- 0.6798404255319149
- 0.6813829787234043
- 0.6842021276595744
- 0.6839893617021277
- 0.6864893617021277
- 0.6806914893617021
- 0.6861702127659575
- 0.688936170212766
- 0.6926063829787235
- 0.6929787234042554
- 0.690531914893617
- 0.6889893617021277
- 0.6907446808510638
- 0.6950531914893617
- 0.6977127659574468
- 0.6926063829787235
- 0.6976595744680851
- 0.6979787234042554
- 0.6977127659574468
- 0.6982446808510638
- 0.6957446808510638
- 0.6988297872340425
- 0.7048936170212766
- 0.7021276595744681
- 0.7031914893617022
- 0.6990425531914893
- 0.704095744680851
- 0.7038829787234042
- 0.7062765957446808
- 0.7057978723404256
- 0.7063297872340426
- 0.7093617021276596
- 0.7070744680851064
- 0.7059042553191489
- 0.7057446808510638
- 0.7112234042553192
- 0.7058510638297872
- 0.7050531914893617
- 0.7045744680851064
- 0.7084574468085106
- 0.7126063829787234
- 0.7094148936170213
- 0.5321276595744681
- 0.7120744680851064
- 0.7146808510638298
- 0.7132446808510639
- 0.7127127659574468
- 0.7126063829787234
- 0.7118617021276595
- 0.7134574468085106
- 0.7078191489361703
- 0.7165425531914894
- 0.7168085106382979
- 0.7152127659574468
test_loss_list:
- 3.781080582936605
- 3.7420845476786297
- 3.6215009911855063
- 3.3662248516082762
- 3.044366715749105
- 2.7600455697377524
- 2.579122247695923
- 2.4651027393341063
- 2.3546257464090985
- 2.3390863609313963
- 2.250684962272644
- 2.2236236333847046
- 2.1922298940022786
- 2.1836981550852457
- 2.2019303115208944
- 2.1461745723088583
- 2.0726599963506063
- 2.1134483098983763
- 2.097111179033915
- 2.062065550486247
- 2.0541955359776813
- 2.083882441520691
- 2.0400744819641115
- 2.031167891820272
- 2.01814458211263
- 1.9610935974121093
- 2.007423661549886
- 2.04725811958313
- 2.0284229723612466
- 1.9248186333974202
- 1.905247187614441
- 1.9478211975097657
- 2.0049878978729248
- 2.0370905001958213
- 1.9462230443954467
- 1.8392208560307821
- 1.8763775507609048
- 1.9079902410507201
- 1.9452819458643595
- 1.8607772477467854
- 1.8648438103993734
- 1.8334418694178263
- 1.8440622329711913
- 1.867223949432373
- 1.8346732711791993
- 1.904637141227722
- 1.9055553340911866
- 1.7755806271235148
- 1.8872468582789104
- 1.7961582390467326
- 1.8992392746607463
- 1.749619402885437
- 1.886775042215983
- 1.8439437580108642
- 1.8923592058817547
- 1.7923824024200439
- 1.7658772039413453
- 1.719650600751241
- 1.7461670637130737
- 1.6667806895573933
- 1.7156687021255492
- 1.7058100811640422
- 1.7787806288401287
- 1.698325826327006
- 1.6864351431528728
- 1.7707651567459106
- 1.6814531660079957
- 1.727511577606201
- 1.77639830271403
- 1.7208237648010254
- 1.800696473121643
- 1.6191825199127197
- 1.6832434384028117
- 1.6551052236557007
- 1.7397718985875448
- 1.7115640576680502
- 1.6743428246180216
- 1.763649328549703
- 1.6698502826690673
- 1.6539644527435302
- 1.6111597887674967
- 1.7128693548838299
- 1.663376030921936
- 1.6797905302047729
- 1.552469720840454
- 1.6048596858978272
- 1.6712419414520263
- 1.6222143030166627
- 1.5159762382507325
- 1.3007987674077353
- 1.4154586092631023
- 1.4261464103062949
- 1.5127164061864218
- 1.457616998354594
- 1.4537717088063558
- 1.458378070195516
- 1.415399406750997
- 1.5180365610122681
- 1.4928292751312255
- 1.4814477252960205
train_accuracy:
- 0.031
- 0.056
- 0.0
- 0.0
- 0.396
- 0.0
- 0.0
- 0.0
- 0.598
- 0.612
- 0.0
- 0.683
- 0.0
- 0.692
- 0.713
- 0.706
- 0.713
- 0.0
- 0.694
- 0.713
- 0.0
- 0.702
- 0.0
- 0.0
- 0.727
- 0.735
- 0.727
- 0.698
- 0.729
- 0.0
- 0.0
- 0.746
- 0.777
- 0.742
- 0.771
- 0.0
- 0.0
- 0.0
- 0.725
- 0.0
- 0.758
- 0.0
- 0.8
- 0.0
- 0.777
- 0.771
- 0.773
- 0.0
- 0.804
- 0.75
- 0.796
- 0.0
- 0.783
- 0.794
- 0.763
- 0.817
- 0.763
- 0.0
- 0.798
- 0.0
- 0.833
- 0.806
- 0.79
- 0.0
- 0.0
- 0.806
- 0.819
- 0.812
- 0.806
- 0.817
- 0.794
- 0.0
- 0.0
- 0.806
- 0.815
- 0.808
- 0.0
- 0.81
- 0.785
- 0.0
- 0.0
- 0.844
- 0.0
- 0.825
- 0.0
- 0.815
- 0.804
- 0.0
- 0.827
- 0.831
- 0.817
- 0.84
- 0.848
- 0.823
- 0.0
- 0.829
- 0.0
- 0.846
- 0.842
- 0.823
train_loss:
- 3.835
- 2.875
- 1.822
- 1.602
- 3.244
- 1.293
- 1.921
- 1.777
- 1.747
- 2.25
- 1.605
- 1.506
- 1.467
- 1.464
- 1.897
- 1.381
- 0.896
- 1.308
- 1.319
- 1.27
- 0.854
- 1.683
- 1.193
- 1.177
- 1.185
- 0.812
- 1.109
- 1.551
- 1.193
- 0.784
- 0.766
- 1.129
- 1.483
- 1.416
- 1.149
- 0.777
- 0.71
- 1.027
- 1.418
- 1.104
- 1.078
- 1.079
- 1.014
- 0.976
- 1.033
- 1.338
- 1.342
- 0.774
- 1.318
- 1.014
- 1.294
- 0.738
- 1.291
- 0.968
- 1.263
- 0.987
- 0.968
- 0.642
- 0.671
- 0.677
- 0.927
- 0.923
- 1.22
- 0.957
- 0.938
- 1.214
- 0.983
- 0.935
- 1.181
- 0.896
- 1.153
- 0.631
- 0.878
- 0.966
- 1.169
- 0.922
- 0.901
- 1.147
- 0.936
- 0.879
- 0.628
- 1.159
- 0.911
- 0.851
- 0.673
- 0.583
- 1.138
- 0.91
- 0.338
- 0.905
- 1.143
- 0.818
- 1.115
- 0.862
- 0.876
- 0.867
- 0.563
- 1.128
- 0.841
- 0.816
unequal: 0
verbose: 1
