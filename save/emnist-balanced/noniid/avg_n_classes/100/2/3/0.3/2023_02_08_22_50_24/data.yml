avg_train_accuracy: 0.844
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03595744680851064
- 0.07026595744680851
- 0.1498936170212766
- 0.24872340425531914
- 0.33914893617021274
- 0.41606382978723405
- 0.4454787234042553
- 0.4725531914893617
- 0.49414893617021277
- 0.5207446808510638
- 0.545372340425532
- 0.5564361702127659
- 0.5653191489361702
- 0.5628723404255319
- 0.589627659574468
- 0.5959574468085106
- 0.6028191489361702
- 0.5956382978723405
- 0.6134042553191489
- 0.6175531914893617
- 0.6222340425531915
- 0.6211702127659574
- 0.6280851063829788
- 0.6363297872340425
- 0.6331382978723404
- 0.6425
- 0.6472340425531915
- 0.6486170212765957
- 0.6531914893617021
- 0.6488297872340425
- 0.6532978723404256
- 0.6548404255319149
- 0.653936170212766
- 0.6582978723404256
- 0.6654255319148936
- 0.6636702127659575
- 0.6700531914893617
- 0.6682978723404255
- 0.6668085106382978
- 0.6623936170212766
- 0.673031914893617
- 0.6758510638297872
- 0.674468085106383
- 0.6751063829787234
- 0.6773404255319149
- 0.6764361702127659
- 0.6766489361702127
- 0.683936170212766
- 0.6842553191489362
- 0.6797340425531915
- 0.68
- 0.6867553191489362
- 0.6812765957446808
- 0.38313829787234044
- 0.6850531914893617
- 0.6888829787234042
- 0.6891489361702128
- 0.6907978723404256
- 0.6888297872340425
- 0.6938829787234042
- 0.6873404255319149
- 0.6941489361702128
- 0.6925
- 0.6940425531914893
- 0.6947872340425532
- 0.6964893617021276
- 0.6986170212765958
- 0.6972340425531914
- 0.6930851063829787
- 0.6965425531914894
- 0.6978723404255319
- 0.6990425531914893
- 0.7003723404255319
- 0.6988297872340425
- 0.6990425531914893
- 0.7004787234042553
- 0.7007446808510638
- 0.7024468085106383
- 0.698031914893617
- 0.7010106382978724
- 0.7036170212765958
- 0.705
- 0.6981382978723404
- 0.7044680851063829
- 0.7052127659574469
- 0.7057978723404256
- 0.7051595744680851
- 0.7080851063829787
- 0.7011170212765957
- 0.7065425531914894
- 0.7023404255319149
- 0.7021808510638298
- 0.709627659574468
- 0.7093617021276596
- 0.71
- 0.7126595744680851
- 0.7085638297872341
- 0.7111170212765957
- 0.7104787234042553
- 0.7102659574468085
test_loss_list:
- 3.7812189038594566
- 3.729176403681437
- 3.5701050186157226
- 3.235159273147583
- 2.945126485824585
- 2.756586799621582
- 2.627572628657023
- 2.5225517495473224
- 2.464421787261963
- 2.4686109511057537
- 2.4238206005096434
- 2.4059363158543903
- 2.3672771008809406
- 2.2788758261998496
- 2.338991878827413
- 2.3394513845443727
- 2.274732073148092
- 2.20238663037618
- 2.326962634722392
- 2.316556208928426
- 2.33287526289622
- 2.246947944959005
- 2.237428994178772
- 2.2894094053904217
- 2.1477723773320516
- 2.2780235608418784
- 2.2856665817896524
- 2.181860720316569
- 2.2926524464289346
- 2.2151560751597086
- 2.1827959648768105
- 2.193883934020996
- 2.1326819547017415
- 2.1759936809539795
- 2.1428788995742796
- 2.100387371381124
- 2.1728514115015667
- 2.1815923833847046
- 2.106987150510152
- 2.067761886914571
- 2.132776951789856
- 2.139034708340963
- 2.0847028080622354
- 2.083896576563517
- 2.0730126444498698
- 2.0593456824620566
- 1.9627102661132811
- 2.084748344421387
- 2.0201406987508137
- 1.9341282304128011
- 1.9102369832992554
- 1.9838500595092774
- 1.8315249951680501
- 2.189721754391988
- 1.5716598383585612
- 1.630872926712036
- 1.6467905950546264
- 1.7386734549204508
- 1.7237225564320882
- 1.7866888173421225
- 1.6816083765029908
- 1.715613555908203
- 1.6817657883961996
- 1.719324884414673
- 1.6829847351710001
- 1.7003957732518513
- 1.7304784917831422
- 1.7116311947504679
- 1.6192138306299846
- 1.6756495412190755
- 1.6762250550587972
- 1.663431790669759
- 1.7102195199330648
- 1.6370709975560507
- 1.5713726154963175
- 1.6279694143931072
- 1.633019134203593
- 1.659598519007365
- 1.5971515973409016
- 1.5936715730031332
- 1.6737176688512165
- 1.7439346329371135
- 1.6176335922876994
- 1.6698688666025798
- 1.7314390103022257
- 1.700682069460551
- 1.649966711997986
- 1.7312247133255005
- 1.607376569112142
- 1.657984765370687
- 1.6334876918792725
- 1.5885996405283611
- 1.6297217305501301
- 1.6221883138020834
- 1.6039666525522869
- 1.6202675278981526
- 1.5567875178654988
- 1.5633876943588256
- 1.651061512629191
- 1.595039488474528
train_accuracy:
- 0.031
- 0.09
- 0.173
- 0.3
- 0.4
- 0.502
- 0.0
- 0.515
- 0.54
- 0.602
- 0.648
- 0.638
- 0.602
- 0.623
- 0.65
- 0.683
- 0.688
- 0.0
- 0.706
- 0.685
- 0.713
- 0.0
- 0.0
- 0.719
- 0.0
- 0.731
- 0.746
- 0.735
- 0.748
- 0.737
- 0.742
- 0.792
- 0.723
- 0.725
- 0.758
- 0.0
- 0.758
- 0.754
- 0.779
- 0.0
- 0.781
- 0.779
- 0.773
- 0.79
- 0.775
- 0.765
- 0.0
- 0.779
- 0.769
- 0.0
- 0.0
- 0.792
- 0.0
- 0.727
- 0.0
- 0.79
- 0.794
- 0.783
- 0.0
- 0.81
- 0.0
- 0.787
- 0.0
- 0.0
- 0.0
- 0.84
- 0.804
- 0.794
- 0.81
- 0.821
- 0.0
- 0.81
- 0.779
- 0.0
- 0.787
- 0.802
- 0.84
- 0.8
- 0.0
- 0.812
- 0.842
- 0.81
- 0.0
- 0.0
- 0.815
- 0.825
- 0.819
- 0.808
- 0.0
- 0.0
- 0.0
- 0.0
- 0.802
- 0.815
- 0.825
- 0.808
- 0.0
- 0.0
- 0.831
- 0.844
train_loss:
- 3.838
- 1.918
- 2.713
- 2.494
- 2.265
- 2.847
- 1.922
- 1.781
- 1.697
- 2.239
- 2.178
- 2.069
- 1.556
- 1.037
- 1.921
- 1.882
- 1.444
- 0.926
- 1.783
- 1.721
- 1.703
- 1.257
- 1.223
- 1.634
- 0.894
- 1.603
- 1.582
- 1.237
- 1.524
- 1.243
- 1.209
- 1.198
- 0.822
- 1.131
- 1.154
- 1.148
- 1.431
- 1.437
- 1.114
- 0.766
- 1.421
- 1.405
- 1.077
- 1.068
- 1.036
- 1.063
- 0.746
- 1.33
- 1.003
- 0.726
- 0.671
- 1.346
- 0.731
- 0.358
- 0.987
- 0.951
- 0.991
- 1.28
- 0.938
- 1.254
- 0.645
- 0.97
- 0.635
- 0.924
- 0.945
- 0.92
- 0.935
- 0.909
- 0.605
- 0.9
- 0.866
- 0.899
- 0.868
- 0.629
- 0.616
- 0.891
- 0.906
- 0.88
- 0.599
- 0.888
- 1.156
- 1.143
- 0.59
- 0.858
- 1.138
- 0.847
- 0.861
- 1.142
- 0.603
- 0.846
- 0.841
- 0.595
- 0.887
- 0.843
- 0.834
- 0.857
- 0.56
- 0.853
- 1.086
- 0.844
unequal: 0
verbose: 1
