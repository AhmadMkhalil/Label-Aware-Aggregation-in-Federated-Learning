avg_train_accuracy: 0.825
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02425531914893617
- 0.0627659574468085
- 0.11590425531914894
- 0.20547872340425533
- 0.3072872340425532
- 0.36611702127659573
- 0.40925531914893615
- 0.44446808510638297
- 0.4710106382978723
- 0.4925
- 0.5022340425531915
- 0.5219680851063829
- 0.5401595744680852
- 0.5490425531914893
- 0.5575
- 0.5681914893617022
- 0.5778191489361703
- 0.5869148936170213
- 0.5902127659574468
- 0.5965425531914894
- 0.6068617021276596
- 0.6076063829787234
- 0.6181382978723404
- 0.6186702127659575
- 0.6246808510638298
- 0.6236702127659575
- 0.634468085106383
- 0.638563829787234
- 0.6388829787234043
- 0.6442553191489362
- 0.643031914893617
- 0.6460638297872341
- 0.648563829787234
- 0.6516489361702128
- 0.6536170212765957
- 0.6571808510638298
- 0.6605319148936171
- 0.6654255319148936
- 0.6621276595744681
- 0.6655319148936171
- 0.6690425531914893
- 0.6706914893617021
- 0.6698404255319149
- 0.6727659574468086
- 0.6746276595744681
- 0.6743617021276596
- 0.674468085106383
- 0.6803191489361702
- 0.6777659574468086
- 0.6835106382978723
- 0.6818085106382978
- 0.6835638297872341
- 0.6857446808510639
- 0.6853191489361702
- 0.6853191489361702
- 0.6854787234042553
- 0.688404255319149
- 0.6883510638297873
- 0.689468085106383
- 0.6922872340425532
- 0.6912765957446808
- 0.6936702127659574
- 0.6914893617021277
- 0.695
- 0.6933510638297873
- 0.6955851063829788
- 0.6951595744680851
- 0.6978191489361703
- 0.6971808510638298
- 0.6990957446808511
- 0.6986702127659574
- 0.6997872340425532
- 0.6993617021276596
- 0.7011170212765957
- 0.7014361702127659
- 0.7029787234042553
- 0.7028723404255319
- 0.7012234042553191
- 0.699627659574468
- 0.7018617021276595
- 0.7031914893617022
- 0.7029255319148936
- 0.705531914893617
- 0.7037234042553191
- 0.7033510638297872
- 0.7047872340425532
- 0.7065957446808511
- 0.7072340425531914
- 0.7074468085106383
- 0.7090425531914893
- 0.7086702127659574
- 0.7099468085106383
- 0.7103191489361702
- 0.7088829787234042
- 0.709095744680851
- 0.7099468085106383
- 0.7108510638297872
- 0.7128191489361703
- 0.711063829787234
- 0.7126595744680851
test_loss_list:
- 3.7876972071329753
- 3.7404376633961998
- 3.5962914339701335
- 3.3054660193125405
- 2.9986301549275716
- 2.7715610218048097
- 2.6062200260162354
- 2.5102219168345132
- 2.4213348134358723
- 2.371013266245524
- 2.2636770645777387
- 2.2204932435353597
- 2.2081637891133625
- 2.1468589051564533
- 2.102851382891337
- 2.055845734278361
- 2.0373739274342855
- 2.0524326022466024
- 1.993937749862671
- 1.9552375094095866
- 2.008608775138855
- 1.9382606315612794
- 1.9547092882792154
- 1.8525610542297364
- 1.857346347173055
- 1.8030385923385621
- 1.859502895673116
- 1.8716998068491617
- 1.7587952740987143
- 1.7947280406951904
- 1.7186830854415893
- 1.704443909327189
- 1.7007834196090699
- 1.6811155764261883
- 1.645614972114563
- 1.7246108309427897
- 1.670516611735026
- 1.727074424425761
- 1.6719582319259643
- 1.6532391023635864
- 1.664020913441976
- 1.7122863308588663
- 1.5884109656016032
- 1.627636440594991
- 1.614098916053772
- 1.6040786170959473
- 1.5442557621002198
- 1.6289562018712362
- 1.5907563988367717
- 1.6279676548639934
- 1.5901048294703166
- 1.659782371520996
- 1.651030460993449
- 1.570233923594157
- 1.5460545460383097
- 1.492470506032308
- 1.5119272740681966
- 1.4961625464757284
- 1.4481729809443156
- 1.484808801015218
- 1.4212320280075073
- 1.463781204223633
- 1.396330688794454
- 1.4958646599451701
- 1.4478507486979166
- 1.4534906721115113
- 1.4522982168197631
- 1.498313873608907
- 1.3910518789291382
- 1.3849723784128825
- 1.4159861437479655
- 1.402599261601766
- 1.4682269303003948
- 1.4202770614624023
- 1.4177564477920532
- 1.4659844032923381
- 1.4134105857213337
- 1.3419571590423585
- 1.323719253540039
- 1.2977782042821249
- 1.3000185298919678
- 1.335719534556071
- 1.338912173906962
- 1.3514449993769329
- 1.301167065302531
- 1.3295696353912354
- 1.3316705004374185
- 1.3315111923217773
- 1.3154940112431843
- 1.3134788767496746
- 1.3855960257848103
- 1.3408242384592692
- 1.3242358875274658
- 1.2742486349741617
- 1.2917797803878783
- 1.302811042467753
- 1.2866211048762004
- 1.2751141309738159
- 1.2864818731943766
- 1.2881897481282552
train_accuracy:
- 0.025
- 0.079
- 0.11
- 0.269
- 0.39
- 0.431
- 0.448
- 0.496
- 0.515
- 0.558
- 0.558
- 0.629
- 0.635
- 0.65
- 0.0
- 0.644
- 0.704
- 0.685
- 0.71
- 0.717
- 0.74
- 0.0
- 0.742
- 0.725
- 0.717
- 0.0
- 0.752
- 0.737
- 0.0
- 0.737
- 0.0
- 0.744
- 0.756
- 0.752
- 0.754
- 0.787
- 0.0
- 0.0
- 0.758
- 0.779
- 0.781
- 0.785
- 0.787
- 0.0
- 0.0
- 0.783
- 0.0
- 0.771
- 0.777
- 0.804
- 0.81
- 0.792
- 0.831
- 0.0
- 0.796
- 0.792
- 0.783
- 0.783
- 0.783
- 0.831
- 0.808
- 0.0
- 0.798
- 0.842
- 0.806
- 0.0
- 0.0
- 0.804
- 0.848
- 0.0
- 0.804
- 0.0
- 0.846
- 0.823
- 0.844
- 0.819
- 0.84
- 0.831
- 0.0
- 0.0
- 0.802
- 0.0
- 0.808
- 0.808
- 0.831
- 0.854
- 0.819
- 0.0
- 0.81
- 0.854
- 0.84
- 0.0
- 0.827
- 0.0
- 0.81
- 0.0
- 0.808
- 0.0
- 0.835
- 0.825
train_loss:
- 2.981
- 2.953
- 2.855
- 2.667
- 2.43
- 2.219
- 2.049
- 2.237
- 1.897
- 2.022
- 1.497
- 1.678
- 1.829
- 1.585
- 1.501
- 1.514
- 1.44
- 1.649
- 1.392
- 1.395
- 1.527
- 1.334
- 1.488
- 1.124
- 1.278
- 1.081
- 1.428
- 1.381
- 1.054
- 1.174
- 1.021
- 1.01
- 1.159
- 1.153
- 0.977
- 1.29
- 1.115
- 1.243
- 1.115
- 1.093
- 1.068
- 1.201
- 0.924
- 1.065
- 1.034
- 1.06
- 0.894
- 1.183
- 1.027
- 1.146
- 0.993
- 1.129
- 1.147
- 1.003
- 0.985
- 0.853
- 0.971
- 0.965
- 0.84
- 0.953
- 0.829
- 0.948
- 0.82
- 1.06
- 0.939
- 0.933
- 0.939
- 1.07
- 0.803
- 0.794
- 0.912
- 0.909
- 1.048
- 0.907
- 0.92
- 1.038
- 0.898
- 0.782
- 0.771
- 0.761
- 0.754
- 0.893
- 0.873
- 0.87
- 0.756
- 0.876
- 0.88
- 0.874
- 0.872
- 0.875
- 0.983
- 0.858
- 0.855
- 0.736
- 0.855
- 0.85
- 0.85
- 0.847
- 0.845
- 0.838
unequal: 0
verbose: 1
