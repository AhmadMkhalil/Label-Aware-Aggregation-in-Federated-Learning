avg_train_accuracy: 0.802
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05377659574468085
- 0.09404255319148937
- 0.21207446808510638
- 0.3004787234042553
- 0.38101063829787235
- 0.4399468085106383
- 0.4697872340425532
- 0.49159574468085104
- 0.5278723404255319
- 0.54
- 0.5567021276595745
- 0.5648936170212766
- 0.5759574468085107
- 0.5852127659574468
- 0.5903191489361702
- 0.6031382978723404
- 0.6095744680851064
- 0.6105851063829787
- 0.6196808510638298
- 0.6253723404255319
- 0.6256382978723404
- 0.6304787234042554
- 0.6386702127659575
- 0.6402659574468085
- 0.641436170212766
- 0.65
- 0.6500531914893617
- 0.6568085106382979
- 0.6593617021276595
- 0.6612234042553191
- 0.6642553191489362
- 0.6688829787234043
- 0.6634574468085106
- 0.6711170212765958
- 0.6718085106382978
- 0.6742021276595744
- 0.6749468085106383
- 0.6768085106382978
- 0.6763829787234042
- 0.6810106382978723
- 0.6768617021276596
- 0.6790957446808511
- 0.6789893617021276
- 0.6827659574468085
- 0.6837765957446809
- 0.6870744680851064
- 0.6855851063829788
- 0.6877127659574468
- 0.6888297872340425
- 0.6876063829787235
- 0.6899468085106383
- 0.6891489361702128
- 0.6928723404255319
- 0.6888829787234042
- 0.6902659574468085
- 0.6952127659574469
- 0.6935638297872341
- 0.6952127659574469
- 0.6963829787234043
- 0.6966489361702127
- 0.6966489361702127
- 0.6978191489361703
- 0.6990425531914893
- 0.6973936170212766
- 0.7006914893617021
- 0.6982978723404255
- 0.7002659574468085
- 0.7025
- 0.7012765957446808
- 0.7022340425531914
- 0.7014893617021276
- 0.7023936170212766
- 0.7022872340425532
- 0.7019148936170213
- 0.7053723404255319
- 0.7044680851063829
- 0.7020212765957446
- 0.7071808510638298
- 0.7052659574468085
- 0.7083510638297872
- 0.7077659574468085
- 0.7073936170212766
- 0.706968085106383
- 0.7073404255319149
- 0.7043617021276596
- 0.7073936170212766
- 0.7082978723404255
- 0.7088829787234042
- 0.7093617021276596
- 0.7107446808510638
- 0.7099468085106383
- 0.7101595744680851
- 0.7117021276595744
- 0.7124468085106384
- 0.7111170212765957
- 0.7150531914893618
- 0.7129787234042553
- 0.7097872340425532
- 0.714095744680851
- 0.7102127659574468
test_loss_list:
- 3.772644348144531
- 3.685291945139567
- 3.4478952344258627
- 3.103805112838745
- 2.827218023935954
- 2.6282951545715334
- 2.481188147862752
- 2.3601604747772216
- 2.3341313076019286
- 2.2651828130086265
- 2.282415189743042
- 2.1808830722173056
- 2.1512008810043337
- 2.1270248238245646
- 2.045891431172689
- 2.1026467498143515
- 2.095374816258748
- 1.9811098512013754
- 1.9909694115320842
- 1.9901457818349202
- 1.9134529908498128
- 1.936680105527242
- 1.9619856182734172
- 1.8994277636210124
- 1.8792597421010335
- 1.9361036666234335
- 1.874172608057658
- 1.9124873272577922
- 1.9524359401067097
- 1.939420846303304
- 2.020205087661743
- 2.0415364265441895
- 1.8757478284835816
- 1.9544194730122884
- 1.941455078125
- 2.008033234278361
- 1.9443306795756021
- 1.9450028069814047
- 1.78670130888621
- 1.9234294160207113
- 1.8335754410425822
- 1.7462607701619466
- 1.70829443136851
- 1.758226868311564
- 1.8398592058817547
- 1.9394491990407308
- 1.7893476978937786
- 1.779921259880066
- 1.9281513198216755
- 1.7610326433181762
- 1.7486113993326824
- 1.8043901586532594
- 1.824387445449829
- 1.7157660706837972
- 1.6389149300257364
- 1.6759465789794923
- 1.7287638092041016
- 1.7781404463450114
- 1.8428145122528077
- 1.7816367483139037
- 1.7791736857096354
- 1.7615799331665039
- 1.6705445686976115
- 1.657570611635844
- 1.704762371381124
- 1.6510855706532797
- 1.6900552225112915
- 1.7111589574813844
- 1.6182560475667318
- 1.5964719470342
- 1.5663197008768717
- 1.7545721244812011
- 1.6462721586227418
- 1.6746015485127768
- 1.6000512186686198
- 1.568661748568217
- 1.5750216849644978
- 1.5507273006439208
- 1.558460415204366
- 1.5360839653015137
- 1.5875831937789917
- 1.5955384476979573
- 1.615237364768982
- 1.6500703636805216
- 1.4673278443018596
- 1.589295039176941
- 1.6184686374664308
- 1.553740463256836
- 1.543263921737671
- 1.6779017273585002
- 1.5979380655288695
- 1.487197159131368
- 1.5631934769948324
- 1.5644004901250204
- 1.4858126099904378
- 1.5481725756327311
- 1.5635686095555623
- 1.4336775414148966
- 1.6122856124242146
- 1.480488265355428
train_accuracy:
- 0.075
- 0.113
- 0.235
- 0.0
- 0.0
- 0.483
- 0.0
- 0.0
- 0.598
- 0.0
- 0.644
- 0.633
- 0.704
- 0.713
- 0.0
- 0.669
- 0.694
- 0.0
- 0.0
- 0.7
- 0.0
- 0.721
- 0.758
- 0.0
- 0.0
- 0.771
- 0.0
- 0.767
- 0.75
- 0.746
- 0.758
- 0.76
- 0.763
- 0.765
- 0.0
- 0.767
- 0.0
- 0.769
- 0.787
- 0.0
- 0.0
- 0.0
- 0.779
- 0.781
- 0.794
- 0.802
- 0.785
- 0.783
- 0.79
- 0.0
- 0.0
- 0.794
- 0.825
- 0.775
- 0.0
- 0.0
- 0.0
- 0.817
- 0.815
- 0.0
- 0.792
- 0.812
- 0.794
- 0.802
- 0.827
- 0.81
- 0.81
- 0.831
- 0.0
- 0.815
- 0.0
- 0.8
- 0.808
- 0.0
- 0.838
- 0.804
- 0.0
- 0.817
- 0.815
- 0.821
- 0.821
- 0.812
- 0.819
- 0.0
- 0.806
- 0.808
- 0.833
- 0.0
- 0.0
- 0.81
- 0.812
- 0.823
- 0.0
- 0.81
- 0.0
- 0.812
- 0.829
- 0.0
- 0.819
- 0.802
train_loss:
- 3.202
- 3.154
- 3.036
- 2.77
- 2.515
- 2.29
- 1.742
- 1.233
- 1.893
- 1.483
- 2.054
- 1.409
- 1.337
- 1.301
- 1.004
- 1.491
- 1.495
- 0.952
- 1.155
- 1.157
- 0.896
- 1.109
- 1.345
- 1.091
- 1.069
- 1.289
- 1.049
- 1.245
- 1.23
- 1.232
- 1.412
- 1.409
- 1.009
- 1.189
- 1.177
- 1.362
- 1.163
- 1.154
- 0.786
- 1.119
- 0.922
- 0.744
- 0.718
- 0.895
- 1.082
- 1.252
- 0.919
- 0.889
- 1.245
- 0.919
- 0.893
- 1.07
- 1.05
- 0.889
- 0.694
- 0.853
- 1.044
- 1.014
- 1.213
- 1.029
- 1.001
- 1.011
- 0.838
- 0.86
- 1.013
- 0.83
- 1.005
- 0.991
- 0.829
- 0.817
- 0.827
- 1.132
- 0.979
- 0.963
- 0.815
- 0.8
- 0.797
- 0.805
- 0.781
- 0.782
- 0.953
- 0.963
- 0.947
- 0.925
- 0.634
- 0.929
- 0.94
- 0.759
- 0.753
- 1.086
- 0.934
- 0.78
- 0.927
- 0.936
- 0.772
- 0.904
- 0.899
- 0.608
- 1.072
- 0.758
unequal: 0
verbose: 1
