avg_train_accuracy: 0.0
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.07175531914893617
- 0.12132978723404256
- 0.20962765957446808
- 0.3576063829787234
- 0.43622340425531914
- 0.47877659574468084
- 0.5131382978723404
- 0.5354787234042553
- 0.5531914893617021
- 0.5687765957446809
- 0.5793617021276596
- 0.580531914893617
- 0.6002127659574468
- 0.6075
- 0.6103191489361702
- 0.6147340425531915
- 0.623563829787234
- 0.6297340425531915
- 0.635904255319149
- 0.6395212765957446
- 0.6473404255319148
- 0.6482978723404256
- 0.651595744680851
- 0.6523936170212766
- 0.6604787234042553
- 0.6627659574468086
- 0.6624468085106383
- 0.6660106382978723
- 0.6609574468085107
- 0.6688297872340425
- 0.6718085106382978
- 0.6746276595744681
- 0.6725531914893617
- 0.673936170212766
- 0.6780851063829787
- 0.6768085106382978
- 0.6790957446808511
- 0.6798404255319149
- 0.6807978723404255
- 0.6771808510638297
- 0.6852127659574468
- 0.6858510638297872
- 0.6879787234042554
- 0.6907446808510638
- 0.6898936170212766
- 0.6897340425531915
- 0.6894148936170212
- 0.6941489361702128
- 0.6909042553191489
- 0.6940957446808511
- 0.6956382978723404
- 0.6957978723404256
- 0.696968085106383
- 0.6920744680851064
- 0.6986170212765958
- 0.6957978723404256
- 0.6985106382978723
- 0.696968085106383
- 0.6996808510638298
- 0.7012765957446808
- 0.7013829787234043
- 0.7036170212765958
- 0.7012765957446808
- 0.7010106382978724
- 0.7049468085106383
- 0.7031382978723404
- 0.7052659574468085
- 0.7059042553191489
- 0.7057978723404256
- 0.7069148936170213
- 0.7074468085106383
- 0.7079255319148936
- 0.7082978723404255
- 0.7100531914893617
- 0.7111702127659575
- 0.7036170212765958
- 0.7087234042553191
- 0.7088297872340426
- 0.7081382978723404
- 0.7104255319148937
- 0.71
- 0.7118085106382979
- 0.7125531914893617
- 0.7136170212765958
- 0.7148936170212766
- 0.7155851063829787
- 0.7135106382978723
- 0.7143617021276596
- 0.7144148936170213
- 0.7146808510638298
- 0.7145212765957447
- 0.7117553191489362
- 0.7162234042553192
- 0.7172340425531915
- 0.7188297872340426
- 0.7174468085106382
- 0.7195212765957447
- 0.7199468085106383
- 0.7203723404255319
- 0.7177659574468085
test_loss_list:
- 3.76611954053243
- 3.664546527862549
- 3.39351944287618
- 2.9974852180480958
- 2.659374402364095
- 2.480551347732544
- 2.3687371603647867
- 2.242882080078125
- 2.173574498494466
- 2.1673405949274698
- 2.1313033580780028
- 2.046249049504598
- 2.099451251029968
- 2.081244486172994
- 2.0841549412409464
- 2.0255768219629924
- 2.000178481737773
- 1.9537150239944459
- 2.02129146416982
- 1.9137649742762248
- 1.9832050450642904
- 1.8855836582183838
- 1.9761001189549765
- 1.8679879808425903
- 2.00998709042867
- 1.9364427359898886
- 1.8653482294082642
- 1.904289337793986
- 1.761074760754903
- 1.8936187442143757
- 1.8708648904164633
- 1.8652365922927856
- 1.7732941516240437
- 1.7445976225535076
- 1.929831314086914
- 1.8437833642959596
- 1.7438006528218588
- 1.7175284592310587
- 1.692865219116211
- 1.63627147992452
- 1.5981598663330079
- 1.6401621770858765
- 1.7060520712534586
- 1.8120477962493897
- 1.6783090400695801
- 1.72792538801829
- 1.720053613980611
- 1.727678583463033
- 1.5712468719482422
- 1.6725436560312907
- 1.6934247891108194
- 1.6963951539993287
- 1.627912418047587
- 1.521647006670634
- 1.6323828411102295
- 1.584266783396403
- 1.5615929094950358
- 1.4866844526926677
- 1.4583443450927733
- 1.573456481297811
- 1.5096704498926798
- 1.577941336631775
- 1.5274337355295817
- 1.4390290355682374
- 1.5540895382563273
- 1.5151409896214802
- 1.5419804604848226
- 1.4786426146825156
- 1.4674894539515178
- 1.529098089536031
- 1.4658376026153563
- 1.482316393852234
- 1.436197182337443
- 1.508949278195699
- 1.594984180132548
- 1.3961654154459635
- 1.512388401031494
- 1.4605277252197266
- 1.454484289487203
- 1.4408726644515992
- 1.4267916282018025
- 1.4044954140981039
- 1.4928989617029826
- 1.494287436803182
- 1.496075537999471
- 1.4876419178644815
- 1.446226461728414
- 1.4415580542882283
- 1.490450201034546
- 1.4131666533152263
- 1.4094613043467203
- 1.3405293877919515
- 1.4307283051808675
- 1.4485809071858724
- 1.5244431575139363
- 1.4152741781870524
- 1.4003249279657999
- 1.4378347905476887
- 1.3330885807673136
- 1.2931990766525268
train_accuracy:
- 0.085
- 0.0
- 0.208
- 0.421
- 0.46
- 0.542
- 0.0
- 0.604
- 0.0
- 0.665
- 0.0
- 0.0
- 0.685
- 0.708
- 0.704
- 0.0
- 0.723
- 0.0
- 0.0
- 0.713
- 0.754
- 0.752
- 0.756
- 0.767
- 0.744
- 0.775
- 0.0
- 0.783
- 0.0
- 0.74
- 0.748
- 0.792
- 0.775
- 0.0
- 0.769
- 0.781
- 0.79
- 0.792
- 0.779
- 0.0
- 0.798
- 0.781
- 0.79
- 0.804
- 0.0
- 0.0
- 0.796
- 0.819
- 0.0
- 0.8
- 0.0
- 0.821
- 0.0
- 0.787
- 0.815
- 0.796
- 0.8
- 0.0
- 0.769
- 0.802
- 0.798
- 0.815
- 0.0
- 0.0
- 0.817
- 0.8
- 0.0
- 0.0
- 0.0
- 0.815
- 0.825
- 0.0
- 0.808
- 0.833
- 0.79
- 0.794
- 0.8
- 0.833
- 0.819
- 0.0
- 0.808
- 0.825
- 0.821
- 0.835
- 0.0
- 0.798
- 0.815
- 0.0
- 0.821
- 0.0
- 0.0
- 0.0
- 0.827
- 0.84
- 0.821
- 0.812
- 0.802
- 0.808
- 0.84
- 0.0
train_loss:
- 3.211
- 3.142
- 2.982
- 3.231
- 1.872
- 1.738
- 1.973
- 1.488
- 1.398
- 1.682
- 1.618
- 0.996
- 1.527
- 1.482
- 1.469
- 1.158
- 1.115
- 1.131
- 1.347
- 1.086
- 1.283
- 1.071
- 1.249
- 1.012
- 1.453
- 1.223
- 0.976
- 1.178
- 0.772
- 1.147
- 1.188
- 1.157
- 0.951
- 0.919
- 1.311
- 1.127
- 0.927
- 0.915
- 0.892
- 0.695
- 0.687
- 0.868
- 1.057
- 1.239
- 0.857
- 1.034
- 1.047
- 1.041
- 0.678
- 1.041
- 1.015
- 1.02
- 0.838
- 0.647
- 1.006
- 0.821
- 0.801
- 0.64
- 0.629
- 0.973
- 0.806
- 0.968
- 0.785
- 0.617
- 0.958
- 0.768
- 0.955
- 0.774
- 0.772
- 0.962
- 0.772
- 0.759
- 0.776
- 0.922
- 1.096
- 0.614
- 0.907
- 0.743
- 0.746
- 0.738
- 0.752
- 0.745
- 0.882
- 0.912
- 0.9
- 0.911
- 0.744
- 0.73
- 0.887
- 0.736
- 0.72
- 0.558
- 0.868
- 0.875
- 1.034
- 0.715
- 0.707
- 0.891
- 0.564
- 0.552
unequal: 0
verbose: 1
