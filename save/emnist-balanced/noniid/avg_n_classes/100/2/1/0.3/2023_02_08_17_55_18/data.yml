avg_train_accuracy: 0.812
avg_train_loss: 0.011
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.032180851063829785
- 0.0599468085106383
- 0.11808510638297873
- 0.2275
- 0.3273404255319149
- 0.42664893617021277
- 0.4785106382978723
- 0.523563829787234
- 0.5467021276595745
- 0.5728191489361703
- 0.595531914893617
- 0.6012234042553192
- 0.6154255319148936
- 0.625904255319149
- 0.641595744680851
- 0.6468617021276596
- 0.6559574468085106
- 0.6671276595744681
- 0.673031914893617
- 0.6787234042553192
- 0.6837765957446809
- 0.6871276595744681
- 0.6931914893617022
- 0.6968617021276595
- 0.7013297872340426
- 0.7067553191489362
- 0.7092021276595745
- 0.7141489361702128
- 0.7127659574468085
- 0.7130851063829787
- 0.7172872340425532
- 0.7226063829787234
- 0.7280319148936171
- 0.7273936170212766
- 0.7307446808510638
- 0.7323404255319149
- 0.7356382978723405
- 0.7349468085106383
- 0.7371276595744681
- 0.738031914893617
- 0.7406382978723405
- 0.7349468085106383
- 0.7397872340425532
- 0.7448404255319149
- 0.7401063829787234
- 0.7475531914893617
- 0.7475
- 0.7481382978723404
- 0.7495744680851064
- 0.7517553191489361
- 0.7513297872340425
- 0.751436170212766
- 0.7501595744680851
- 0.7529255319148936
- 0.7501595744680851
- 0.7518085106382979
- 0.7553191489361702
- 0.7527127659574468
- 0.7577127659574469
- 0.758031914893617
- 0.7576063829787234
- 0.7576595744680851
- 0.7601063829787233
- 0.7598404255319149
- 0.7587765957446808
- 0.7639361702127659
- 0.7586170212765957
- 0.7634574468085107
- 0.7629255319148937
- 0.7637234042553191
- 0.765
- 0.7660106382978723
- 0.7617553191489361
- 0.7675531914893617
- 0.7686170212765957
- 0.7639893617021276
- 0.7615957446808511
- 0.7692021276595745
- 0.768031914893617
- 0.7672340425531915
- 0.7688829787234043
- 0.7697872340425532
- 0.7706914893617022
- 0.7722340425531915
- 0.7739893617021276
- 0.7754255319148936
- 0.7717021276595745
- 0.7725
- 0.7702659574468085
- 0.7716489361702128
- 0.7747340425531914
- 0.7711170212765958
- 0.7752127659574468
- 0.7744148936170213
- 0.7724468085106383
- 0.7752659574468085
- 0.7782978723404256
- 0.778031914893617
- 0.778936170212766
- 0.777127659574468
test_loss_list:
- 3.784565849304199
- 3.750851745605469
- 3.6647202237447103
- 3.4272693030039467
- 3.015352249145508
- 2.611652628580729
- 2.312824872334798
- 2.1151343409220376
- 1.9579310496648152
- 1.8509478950500489
- 1.7679142665863037
- 1.6791620095570883
- 1.6171386051177978
- 1.5546056270599364
- 1.5317455800374349
- 1.4897266419728596
- 1.4771877845128378
- 1.460133949915568
- 1.4335457229614257
- 1.410883954366048
- 1.4032313760121664
- 1.3895811780293783
- 1.3357394377390543
- 1.3187706327438355
- 1.2899768416086832
- 1.300056227048238
- 1.2973164971669515
- 1.295636167526245
- 1.3011809905370078
- 1.2212981541951498
- 1.2577340571085611
- 1.2709125932057699
- 1.2572893381118775
- 1.259181156953176
- 1.2497954201698303
- 1.231464397907257
- 1.2327834192911784
- 1.2468047587076823
- 1.2410722915331522
- 1.2366729195912678
- 1.229566117922465
- 1.173334371248881
- 1.1943214837710063
- 1.1330362431208292
- 1.1291753975550334
- 1.1633883786201478
- 1.1713406483332316
- 1.1807811443010967
- 1.1217760380109152
- 1.1517785755793253
- 1.0939222359657288
- 1.0727725903193155
- 1.1306609678268433
- 1.1237534165382386
- 1.0579059894879659
- 1.0499287033081055
- 1.0813734658559164
- 1.0968219645818074
- 1.0413169026374818
- 1.0779224681854247
- 1.0847769029935201
- 1.036633048057556
- 1.070745857556661
- 1.0847210303942363
- 1.0202448256810506
- 1.0698638272285461
- 1.0101892892519633
- 1.0586510475476583
- 1.0680773417154947
- 1.0678890800476075
- 1.0747989471753439
- 1.0692816082636516
- 1.0179682977994282
- 1.0525523392359415
- 1.0625647290547688
- 0.9966285196940105
- 0.9865260537465413
- 1.019298726717631
- 1.0445760917663574
- 0.9671111504236857
- 1.0269368632634481
- 1.027746418317159
- 1.024884780248006
- 1.024172505537669
- 1.0415096179644268
- 1.0447807518641155
- 0.9902720332145691
- 1.0257653530438742
- 0.9888396533330281
- 1.0155708805720012
- 1.0153350687026979
- 1.0197281591097513
- 1.0314424029986065
- 1.028409940401713
- 0.9627925054232279
- 1.0063922715187072
- 1.0137272310256957
- 1.0281579208374023
- 1.035377960205078
- 1.0324816552797953
train_accuracy:
- 0.042
- 0.062
- 0.125
- 0.269
- 0.342
- 0.45
- 0.0
- 0.56
- 0.0
- 0.665
- 0.662
- 0.0
- 0.581
- 0.0
- 0.673
- 0.0
- 0.723
- 0.69
- 0.744
- 0.66
- 0.723
- 0.677
- 0.748
- 0.708
- 0.0
- 0.76
- 0.771
- 0.748
- 0.773
- 0.0
- 0.765
- 0.792
- 0.75
- 0.777
- 0.779
- 0.771
- 0.771
- 0.779
- 0.771
- 0.787
- 0.792
- 0.744
- 0.771
- 0.787
- 0.79
- 0.806
- 0.756
- 0.781
- 0.794
- 0.752
- 0.806
- 0.798
- 0.796
- 0.765
- 0.804
- 0.0
- 0.792
- 0.79
- 0.787
- 0.765
- 0.804
- 0.0
- 0.798
- 0.81
- 0.763
- 0.792
- 0.767
- 0.769
- 0.806
- 0.794
- 0.817
- 0.817
- 0.769
- 0.81
- 0.806
- 0.802
- 0.825
- 0.819
- 0.817
- 0.777
- 0.819
- 0.806
- 0.812
- 0.819
- 0.819
- 0.825
- 0.781
- 0.79
- 0.8
- 0.819
- 0.817
- 0.783
- 0.817
- 0.779
- 0.0
- 0.812
- 0.823
- 0.825
- 0.831
- 0.812
train_loss:
- 3.843
- 3.816
- 3.768
- 3.642
- 3.38
- 3.047
- 1.995
- 2.588
- 1.737
- 2.271
- 2.143
- 1.513
- 1.421
- 1.388
- 1.846
- 1.291
- 1.763
- 1.689
- 1.695
- 1.658
- 1.644
- 1.568
- 1.164
- 1.121
- 1.12
- 1.537
- 1.502
- 1.463
- 1.44
- 1.086
- 1.394
- 1.369
- 1.382
- 1.374
- 1.406
- 1.4
- 1.336
- 1.323
- 1.341
- 1.331
- 1.297
- 1.001
- 1.331
- 0.998
- 0.992
- 1.28
- 1.236
- 1.234
- 0.939
- 1.273
- 0.933
- 0.943
- 1.252
- 1.243
- 0.953
- 0.924
- 1.21
- 1.201
- 0.883
- 1.199
- 1.223
- 0.904
- 1.2
- 1.167
- 0.903
- 1.173
- 0.878
- 1.156
- 1.147
- 1.128
- 1.131
- 1.138
- 0.851
- 1.159
- 1.137
- 0.857
- 0.846
- 1.159
- 1.115
- 0.87
- 1.098
- 1.14
- 1.124
- 1.122
- 1.116
- 1.138
- 0.836
- 1.107
- 0.825
- 1.088
- 1.136
- 1.097
- 1.085
- 1.104
- 0.833
- 1.116
- 1.106
- 1.079
- 1.074
- 1.078
unequal: 0
verbose: 1
