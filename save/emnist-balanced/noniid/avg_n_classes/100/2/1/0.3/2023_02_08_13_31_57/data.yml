avg_train_accuracy: 0.0
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04085106382978723
- 0.065
- 0.11425531914893618
- 0.23957446808510638
- 0.33904255319148935
- 0.4277659574468085
- 0.48675531914893616
- 0.5288829787234043
- 0.5523404255319149
- 0.5741489361702128
- 0.5916489361702127
- 0.6016489361702128
- 0.6175531914893617
- 0.6249468085106383
- 0.6313297872340425
- 0.6392021276595745
- 0.6550531914893617
- 0.6582978723404256
- 0.6691489361702128
- 0.671595744680851
- 0.6794148936170212
- 0.6840425531914893
- 0.6893085106382979
- 0.691968085106383
- 0.6936170212765957
- 0.6995212765957447
- 0.7044148936170213
- 0.7077127659574468
- 0.7101063829787234
- 0.7093085106382979
- 0.7148936170212766
- 0.7136170212765958
- 0.7164893617021276
- 0.7208510638297873
- 0.7190425531914894
- 0.7223936170212766
- 0.7244680851063829
- 0.726436170212766
- 0.7268085106382979
- 0.7279787234042553
- 0.7317021276595744
- 0.7342021276595745
- 0.7313297872340425
- 0.7362234042553192
- 0.7361702127659574
- 0.7357446808510638
- 0.7407978723404255
- 0.7421808510638298
- 0.7425
- 0.743031914893617
- 0.745
- 0.7454787234042554
- 0.7470212765957447
- 0.7476063829787234
- 0.7506914893617022
- 0.7511170212765957
- 0.7500531914893617
- 0.7502127659574468
- 0.7501063829787235
- 0.7537765957446808
- 0.7536170212765958
- 0.7555851063829787
- 0.7550531914893617
- 0.7559574468085106
- 0.7556382978723404
- 0.7563829787234042
- 0.7567021276595745
- 0.7618085106382979
- 0.7592021276595745
- 0.7606914893617022
- 0.7612765957446809
- 0.7614893617021277
- 0.7624468085106383
- 0.7642553191489362
- 0.7636702127659575
- 0.7645744680851064
- 0.7655851063829787
- 0.7664893617021277
- 0.7682446808510638
- 0.7656914893617022
- 0.7652127659574468
- 0.7691489361702127
- 0.7695212765957447
- 0.7708510638297872
- 0.7702127659574468
- 0.7696276595744681
- 0.7691489361702127
- 0.7695744680851064
- 0.7689893617021276
- 0.7695212765957447
- 0.7707978723404255
- 0.7721808510638298
- 0.7710106382978723
- 0.7736170212765957
- 0.7729787234042553
- 0.7775531914893618
- 0.7745744680851064
- 0.775904255319149
- 0.7761170212765958
- 0.7748404255319149
test_loss_list:
- 3.785541855494181
- 3.746464424133301
- 3.6447726662953697
- 3.4120405165354413
- 3.06026486714681
- 2.6836956469217936
- 2.381508846282959
- 2.1562584018707276
- 1.985431537628174
- 1.8683154726028441
- 1.8001829338073732
- 1.6978666989008586
- 1.6604600699742635
- 1.612026858329773
- 1.5487728532155354
- 1.5115750281016032
- 1.4996572653452556
- 1.4394778490066529
- 1.4350218550364175
- 1.3763282267252603
- 1.3798452854156493
- 1.3697156397501629
- 1.3538025824228923
- 1.3295043023427326
- 1.3236854155858357
- 1.2757547473907471
- 1.2962012847264608
- 1.2840421549479166
- 1.2408340056737264
- 1.2492758464813232
- 1.2499450620015462
- 1.251890427271525
- 1.2424031631151835
- 1.2498923269907634
- 1.2414657807350158
- 1.1964604353904724
- 1.2185779150327047
- 1.1681780695915223
- 1.1980232938130697
- 1.1391898798942566
- 1.1698385254542032
- 1.1698561565081278
- 1.121116803487142
- 1.1483333547910055
- 1.1459853331247964
- 1.105101560751597
- 1.1274800380071004
- 1.1304384056727093
- 1.0782295473416645
- 1.1067585476239523
- 1.109068169593811
- 1.1172887349128724
- 1.1251359264055887
- 1.07195010026296
- 1.100316670735677
- 1.1079489556948343
- 1.1105910706520081
- 1.050858949025472
- 1.040490931669871
- 1.0327183389663697
- 1.0552585132916767
- 1.0623705935478212
- 1.066691340605418
- 1.0746845897038777
- 1.0237474242846172
- 1.063413983186086
- 1.0611041315396628
- 1.0620564428965251
- 1.0100651105244955
- 0.9942897224426269
- 1.0288527925809225
- 0.9922144166628519
- 1.0162627418835959
- 1.026253618399302
- 1.0199375693003336
- 1.0264901844660441
- 1.0204520297050477
- 0.9916963156064351
- 0.9678496360778809
- 0.9667382884025574
- 0.9422868633270264
- 0.980568212668101
- 0.9895306126276652
- 0.9622435800234477
- 0.9805344120661418
- 0.9863373915354411
- 1.0023959000905356
- 0.998608668645223
- 0.991888567606608
- 0.9964877915382385
- 1.0062759629885356
- 1.0055940421422322
- 0.9650376272201538
- 0.988823393980662
- 0.9967563271522522
- 0.9935516937573751
- 0.9966502285003662
- 0.9649747093518575
- 0.9348614033063253
- 0.9308735299110412
train_accuracy:
- 0.037
- 0.067
- 0.123
- 0.267
- 0.365
- 0.427
- 0.508
- 0.567
- 0.0
- 0.619
- 0.648
- 0.625
- 0.625
- 0.633
- 0.685
- 0.0
- 0.685
- 0.702
- 0.731
- 0.0
- 0.708
- 0.681
- 0.702
- 0.719
- 0.735
- 0.737
- 0.737
- 0.787
- 0.769
- 0.735
- 0.75
- 0.767
- 0.758
- 0.729
- 0.729
- 0.719
- 0.8
- 0.802
- 0.744
- 0.0
- 0.783
- 0.796
- 0.0
- 0.752
- 0.779
- 0.0
- 0.75
- 0.779
- 0.752
- 0.815
- 0.81
- 0.815
- 0.808
- 0.758
- 0.785
- 0.817
- 0.777
- 0.81
- 0.0
- 0.798
- 0.769
- 0.817
- 0.819
- 0.808
- 0.767
- 0.815
- 0.806
- 0.823
- 0.81
- 0.806
- 0.802
- 0.0
- 0.8
- 0.798
- 0.804
- 0.765
- 0.802
- 0.802
- 0.0
- 0.783
- 0.0
- 0.798
- 0.821
- 0.815
- 0.8
- 0.812
- 0.8
- 0.81
- 0.808
- 0.796
- 0.825
- 0.815
- 0.0
- 0.825
- 0.794
- 0.808
- 0.804
- 0.0
- 0.0
- 0.0
train_loss:
- 3.848
- 3.817
- 3.76
- 3.644
- 3.416
- 3.138
- 2.861
- 2.64
- 1.814
- 2.34
- 2.243
- 1.581
- 2.07
- 1.997
- 1.448
- 1.39
- 1.859
- 1.353
- 1.802
- 1.3
- 1.717
- 1.687
- 1.674
- 1.644
- 1.589
- 1.199
- 1.566
- 1.572
- 1.159
- 1.547
- 1.51
- 1.485
- 1.492
- 1.463
- 1.471
- 1.099
- 1.436
- 1.061
- 1.402
- 1.061
- 1.377
- 1.4
- 1.045
- 1.38
- 1.357
- 1.01
- 1.342
- 1.342
- 1.01
- 1.315
- 1.319
- 1.305
- 1.294
- 0.971
- 1.284
- 1.252
- 1.275
- 0.96
- 0.924
- 0.935
- 1.233
- 1.249
- 1.221
- 1.255
- 0.916
- 1.202
- 1.206
- 1.19
- 0.901
- 0.917
- 1.201
- 0.907
- 1.202
- 1.176
- 1.193
- 1.156
- 1.176
- 0.884
- 0.854
- 0.831
- 0.837
- 1.128
- 1.172
- 0.837
- 1.158
- 1.176
- 1.134
- 1.126
- 1.176
- 1.135
- 1.132
- 1.139
- 0.841
- 1.094
- 1.113
- 1.145
- 1.088
- 0.833
- 0.831
- 0.812
unequal: 0
verbose: 1
