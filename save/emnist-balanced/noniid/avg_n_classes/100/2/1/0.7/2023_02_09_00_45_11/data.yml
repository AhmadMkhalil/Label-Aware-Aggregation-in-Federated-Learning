avg_train_accuracy: 0.821
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.048563829787234045
- 0.060904255319148934
- 0.07457446808510639
- 0.11867021276595745
- 0.21946808510638297
- 0.32840425531914896
- 0.4125531914893617
- 0.4732446808510638
- 0.5162765957446809
- 0.5492021276595744
- 0.5735106382978723
- 0.5930319148936171
- 0.6033510638297872
- 0.6167021276595744
- 0.6286702127659575
- 0.6364893617021277
- 0.6472340425531915
- 0.6546808510638298
- 0.6607978723404255
- 0.666063829787234
- 0.6730851063829787
- 0.6805851063829788
- 0.684468085106383
- 0.6908510638297872
- 0.6945212765957447
- 0.7011170212765957
- 0.7072340425531914
- 0.7075531914893617
- 0.7127127659574468
- 0.7154255319148937
- 0.7174468085106382
- 0.7207978723404256
- 0.7214893617021276
- 0.7255851063829787
- 0.7313297872340425
- 0.7315425531914893
- 0.733404255319149
- 0.7340425531914894
- 0.7360638297872341
- 0.7386170212765958
- 0.7403723404255319
- 0.7423404255319149
- 0.7423936170212766
- 0.7434042553191489
- 0.7469148936170212
- 0.7462234042553192
- 0.7489893617021277
- 0.7471276595744681
- 0.7496808510638298
- 0.7517021276595744
- 0.7522872340425532
- 0.7538297872340426
- 0.7550531914893617
- 0.7547872340425532
- 0.7548404255319149
- 0.7556382978723404
- 0.7556914893617022
- 0.7570212765957447
- 0.7594148936170213
- 0.7593617021276595
- 0.7586170212765957
- 0.7598936170212766
- 0.7606914893617022
- 0.760531914893617
- 0.7627127659574469
- 0.7610106382978723
- 0.7647872340425532
- 0.7635106382978724
- 0.7649468085106383
- 0.7638297872340426
- 0.7654787234042553
- 0.7639893617021276
- 0.7673404255319148
- 0.7697340425531914
- 0.7672872340425532
- 0.7670212765957447
- 0.7688297872340426
- 0.7683510638297872
- 0.7704255319148936
- 0.7715425531914893
- 0.7706914893617022
- 0.7711702127659574
- 0.7717553191489361
- 0.7718085106382979
- 0.7740425531914894
- 0.772127659574468
- 0.7719680851063829
- 0.7744148936170213
- 0.7750531914893617
- 0.7745212765957447
- 0.7767021276595745
- 0.7760106382978723
- 0.7736170212765957
- 0.7748936170212766
- 0.7764893617021277
- 0.7769680851063829
- 0.7779255319148937
- 0.7785106382978724
- 0.7777659574468085
- 0.7795744680851063
test_loss_list:
- 3.7941026306152343
- 3.7792278703053794
- 3.742796106338501
- 3.6512572224934896
- 3.454071267445882
- 3.09535914738973
- 2.7238706175486245
- 2.4089968649546307
- 2.193529348373413
- 2.0186095507939656
- 1.8967166535059612
- 1.7973689381281535
- 1.7175183375676473
- 1.650743881861369
- 1.6337144692738852
- 1.5541996924082437
- 1.5470743719736735
- 1.5221076472600301
- 1.4581992467244467
- 1.4223136901855469
- 1.3924279403686524
- 1.3964797449111939
- 1.3876091941197712
- 1.336122711499532
- 1.347527395884196
- 1.3340162976582846
- 1.322831088701884
- 1.272826468149821
- 1.2893353605270386
- 1.2406456073125203
- 1.2176586230595907
- 1.1905456058184305
- 1.1804312229156495
- 1.158758598168691
- 1.144451231956482
- 1.1809674922625224
- 1.1359688870112101
- 1.1122648326555888
- 1.103080883026123
- 1.0866949383417766
- 1.075260764757792
- 1.1140475026766459
- 1.076862285931905
- 1.1080353172620137
- 1.0681444239616393
- 1.0523558219273885
- 1.0354761989911396
- 1.0371674839655558
- 1.0737841796875
- 1.0340451669692994
- 1.0174586375554402
- 1.0026887345314026
- 1.05070516983668
- 1.0072562885284424
- 0.9942692073186239
- 1.0383825588226319
- 0.9943134570121765
- 1.0359025263786317
- 1.0413937592506408
- 0.9983369946479798
- 0.9759023960431417
- 0.9778216195106506
- 0.9629716976483663
- 0.9551887567838033
- 0.9938247966766357
- 0.9602137128512065
- 0.9978518962860108
- 0.9557943646113077
- 0.9472077027956645
- 0.9835839136441549
- 0.9443796030680338
- 0.937514774799347
- 0.9261034123102824
- 0.9684744421641032
- 0.9268595234553019
- 0.9199706490834554
- 0.909978268146515
- 0.9086316831906637
- 0.9463929017384847
- 0.9069725608825684
- 0.8990370949109395
- 0.8965681036313374
- 0.935920516649882
- 0.8970114429791768
- 0.8883022061983744
- 0.8866681043306986
- 0.8813124060630798
- 0.8790066734949747
- 0.9134478290875753
- 0.8841449332237243
- 0.8714110255241394
- 0.9125039601325988
- 0.9265048241615296
- 0.8868522675832112
- 0.8838490200042725
- 0.8710852376619975
- 0.865755782922109
- 0.8572726456324259
- 0.8527717574437459
- 0.8564381424585978
train_accuracy:
- 0.042
- 0.05
- 0.067
- 0.11
- 0.25
- 0.358
- 0.435
- 0.0
- 0.537
- 0.583
- 0.598
- 0.0
- 0.629
- 0.648
- 0.635
- 0.665
- 0.671
- 0.698
- 0.679
- 0.7
- 0.715
- 0.683
- 0.727
- 0.723
- 0.71
- 0.71
- 0.742
- 0.742
- 0.754
- 0.729
- 0.752
- 0.752
- 0.765
- 0.76
- 0.76
- 0.767
- 0.769
- 0.773
- 0.777
- 0.0
- 0.792
- 0.765
- 0.777
- 0.779
- 0.785
- 0.0
- 0.777
- 0.781
- 0.781
- 0.8
- 0.0
- 0.781
- 0.779
- 0.777
- 0.796
- 0.787
- 0.779
- 0.804
- 0.806
- 0.817
- 0.775
- 0.0
- 0.775
- 0.0
- 0.806
- 0.802
- 0.804
- 0.79
- 0.0
- 0.81
- 0.817
- 0.765
- 0.817
- 0.769
- 0.831
- 0.8
- 0.804
- 0.821
- 0.812
- 0.783
- 0.808
- 0.787
- 0.804
- 0.796
- 0.81
- 0.81
- 0.794
- 0.817
- 0.817
- 0.815
- 0.804
- 0.787
- 0.802
- 0.817
- 0.806
- 0.798
- 0.8
- 0.819
- 0.0
- 0.821
train_loss:
- 3.855
- 3.439
- 3.384
- 3.318
- 3.662
- 3.436
- 3.15
- 2.522
- 2.337
- 2.195
- 2.08
- 1.996
- 1.901
- 1.836
- 2.036
- 1.743
- 1.923
- 1.884
- 1.624
- 1.587
- 1.555
- 1.736
- 1.7
- 1.484
- 1.651
- 1.624
- 1.605
- 1.409
- 1.555
- 1.373
- 1.348
- 1.337
- 1.309
- 1.307
- 1.291
- 1.447
- 1.273
- 1.258
- 1.246
- 1.246
- 1.229
- 1.375
- 1.211
- 1.358
- 1.208
- 1.193
- 1.176
- 1.172
- 1.322
- 1.171
- 1.161
- 1.145
- 1.292
- 1.138
- 1.137
- 1.284
- 1.129
- 1.271
- 1.268
- 1.113
- 1.107
- 1.098
- 1.095
- 1.09
- 1.23
- 1.09
- 1.231
- 1.096
- 1.071
- 1.219
- 1.073
- 1.069
- 1.069
- 1.2
- 1.063
- 1.059
- 1.046
- 1.046
- 1.188
- 1.05
- 1.042
- 1.035
- 1.169
- 1.043
- 1.029
- 1.032
- 1.028
- 1.026
- 1.16
- 1.016
- 1.029
- 1.15
- 1.152
- 1.019
- 1.016
- 1.004
- 1.008
- 1.01
- 1.001
- 1.003
unequal: 0
verbose: 1
