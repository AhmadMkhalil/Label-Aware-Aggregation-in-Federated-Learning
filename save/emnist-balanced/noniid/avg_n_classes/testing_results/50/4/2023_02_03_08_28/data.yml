avg_train_accuracy: 0.887
avg_train_loss: 0.009
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.2
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05845744680851064
- 0.08909574468085106
- 0.2404255319148936
- 0.3481382978723404
- 0.36356382978723406
- 0.3783510638297872
- 0.3783510638297872
- 0.40638297872340423
- 0.41648936170212764
- 0.41648936170212764
- 0.41648936170212764
- 0.4267021276595745
- 0.4267021276595745
- 0.4267021276595745
- 0.4267021276595745
- 0.43377659574468086
- 0.43877659574468086
- 0.43877659574468086
- 0.43877659574468086
- 0.4428191489361702
- 0.4428191489361702
- 0.4527127659574468
- 0.4572340425531915
- 0.4572340425531915
- 0.4605851063829787
- 0.4605851063829787
- 0.46382978723404256
- 0.46382978723404256
- 0.46856382978723404
- 0.46888297872340423
- 0.46888297872340423
- 0.46888297872340423
- 0.4702127659574468
- 0.47675531914893615
- 0.47675531914893615
- 0.47675531914893615
- 0.47675531914893615
- 0.47675531914893615
- 0.4774468085106383
- 0.4774468085106383
- 0.48127659574468085
- 0.48164893617021276
- 0.48164893617021276
- 0.4823404255319149
- 0.4823404255319149
- 0.48595744680851066
- 0.48595744680851066
- 0.4877127659574468
- 0.4895212765957447
- 0.4895212765957447
test_loss_list:
- 997.2104253768921
- 552.8021929264069
- 532.6261036396027
- 559.1176037788391
- 541.2000286579132
- 549.796933889389
- 549.796933889389
- 631.9457795619965
- 678.6797544956207
- 678.6797544956207
- 678.6797544956207
- 649.8511581420898
- 649.8511581420898
- 649.8511581420898
- 649.8511581420898
- 535.3020100593567
- 561.0918312072754
- 561.0918312072754
- 561.0918312072754
- 488.7185335159302
- 488.7185335159302
- 544.1772634983063
- 587.0884895324707
- 587.0884895324707
- 545.2012979984283
- 545.2012979984283
- 549.3002123832703
- 549.3002123832703
- 584.9104571342468
- 537.9835691452026
- 537.9835691452026
- 537.9835691452026
- 477.4752345085144
- 568.7632904052734
- 568.7632904052734
- 568.7632904052734
- 568.7632904052734
- 568.7632904052734
- 459.82862162590027
- 459.82862162590027
- 430.1909568309784
- 527.5908362865448
- 527.5908362865448
- 493.1810290813446
- 493.1810290813446
- 532.0900683403015
- 532.0900683403015
- 553.2856314182281
- 574.4504578113556
- 574.4504578113556
train_accuracy:
- 0.985
- 0.137
- 0.477
- 0.665
- 0.694
- 0.0
- 0.681
- 0.721
- 0.731
- 0.463
- 0.0
- 0.783
- 0.006
- 0.746
- 0.74
- 0.767
- 0.777
- 0.0
- 0.817
- 0.0
- 0.867
- 0.783
- 0.819
- 0.0
- 0.819
- 0.396
- 0.808
- 0.0
- 0.815
- 0.0
- 0.369
- 0.821
- 0.831
- 0.827
- 0.723
- 0.662
- 0.0
- 0.863
- 0.0
- 0.212
- 0.838
- 0.842
- 0.369
- 0.844
- 0.0
- 0.877
- 0.838
- 0.848
- 0.842
- 0.887
train_loss:
- 1.76
- 3.833
- 2.182
- 2.724
- 1.648
- 1.42
- 1.579
- 1.832
- 1.736
- 0.937
- 1.545
- 1.632
- 1.05
- 1.384
- 1.357
- 0.987
- 1.117
- 0.943
- 1.008
- 1.182
- 0.603
- 1.598
- 1.317
- 1.132
- 1.03
- 0.803
- 1.382
- 1.0
- 1.202
- 1.031
- 0.77
- 1.113
- 0.848
- 1.145
- 0.611
- 0.696
- 0.919
- 0.968
- 0.836
- 0.649
- 0.812
- 1.098
- 0.785
- 1.19
- 0.797
- 1.04
- 1.017
- 1.009
- 1.003
- 0.915
unequal: 0
verbose: 1
