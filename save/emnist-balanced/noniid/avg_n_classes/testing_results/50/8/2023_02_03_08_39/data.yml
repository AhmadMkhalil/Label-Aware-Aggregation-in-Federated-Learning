avg_train_accuracy: 0.227
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.2
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 8
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0901595744680851
- 0.11547872340425532
- 0.11547872340425532
- 0.11547872340425532
- 0.13962765957446807
- 0.16186170212765957
- 0.16186170212765957
- 0.16186170212765957
- 0.16186170212765957
- 0.16186170212765957
- 0.16186170212765957
- 0.16186170212765957
- 0.1702127659574468
- 0.18632978723404256
- 0.18632978723404256
- 0.18632978723404256
- 0.18632978723404256
- 0.18632978723404256
- 0.18973404255319148
- 0.20063829787234042
- 0.20063829787234042
- 0.20063829787234042
- 0.20063829787234042
- 0.20063829787234042
- 0.21202127659574468
- 0.21202127659574468
- 0.21202127659574468
- 0.21319148936170212
- 0.21319148936170212
- 0.21930851063829787
- 0.21930851063829787
- 0.22170212765957448
- 0.22170212765957448
- 0.22170212765957448
- 0.22170212765957448
- 0.22186170212765957
- 0.22186170212765957
- 0.22186170212765957
- 0.22186170212765957
- 0.22186170212765957
- 0.22627659574468084
- 0.22627659574468084
- 0.22627659574468084
- 0.2296808510638298
- 0.23356382978723406
- 0.23356382978723406
- 0.23356382978723406
- 0.23356382978723406
- 0.23356382978723406
- 0.23356382978723406
test_loss_list:
- 685.3342604637146
- 798.4054656028748
- 798.4054656028748
- 798.4054656028748
- 653.5458190441132
- 762.131489276886
- 762.131489276886
- 762.131489276886
- 762.131489276886
- 762.131489276886
- 762.131489276886
- 762.131489276886
- 643.1823134422302
- 656.5266423225403
- 656.5266423225403
- 656.5266423225403
- 656.5266423225403
- 656.5266423225403
- 683.766339302063
- 777.5372104644775
- 777.5372104644775
- 777.5372104644775
- 777.5372104644775
- 777.5372104644775
- 879.6764130592346
- 879.6764130592346
- 879.6764130592346
- 883.5052027702332
- 883.5052027702332
- 814.9198637008667
- 814.9198637008667
- 761.4901595115662
- 761.4901595115662
- 761.4901595115662
- 761.4901595115662
- 840.8563165664673
- 840.8563165664673
- 840.8563165664673
- 840.8563165664673
- 840.8563165664673
- 898.506510257721
- 898.506510257721
- 898.506510257721
- 714.5474529266357
- 661.567774772644
- 661.567774772644
- 661.567774772644
- 661.567774772644
- 661.567774772644
- 661.567774772644
train_accuracy:
- 0.227
- 0.223
- 0.4
- 0.25
- 0.171
- 0.467
- 0.775
- 0.775
- 0.775
- 0.194
- 0.642
- 0.0
- 0.021
- 0.002
- 0.783
- 0.812
- 0.027
- 0.106
- 0.692
- 0.708
- 0.215
- 0.029
- 0.056
- 0.127
- 0.681
- 0.429
- 0.675
- 0.292
- 0.527
- 0.308
- 0.077
- 0.237
- 0.821
- 0.835
- 0.573
- 0.308
- 0.85
- 0.844
- 0.852
- 0.865
- 0.723
- 0.031
- 0.042
- 0.325
- 0.783
- 0.6
- 0.181
- 0.848
- 0.158
- 0.227
train_loss:
- 2.409
- 1.716
- 1.674
- 1.733
- 1.462
- 1.154
- 1.069
- 0.914
- 0.875
- 1.345
- 1.061
- 1.647
- 1.16
- 1.189
- 1.012
- 0.809
- 1.562
- 1.152
- 1.109
- 0.918
- 1.131
- 1.359
- 1.201
- 1.039
- 0.88
- 0.966
- 1.024
- 0.854
- 0.898
- 0.849
- 1.368
- 0.846
- 0.936
- 0.715
- 0.91
- 0.825
- 0.712
- 0.651
- 0.626
- 0.616
- 0.745
- 0.867
- 1.312
- 0.793
- 0.84
- 0.779
- 0.963
- 0.74
- 0.941
- 0.794
unequal: 0
verbose: 1
