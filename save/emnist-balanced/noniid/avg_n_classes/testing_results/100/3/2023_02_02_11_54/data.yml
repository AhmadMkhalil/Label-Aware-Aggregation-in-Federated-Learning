avg_train_accuracy: 0.904
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.10946808510638298
- 0.1249468085106383
- 0.1403191489361702
- 0.1525531914893617
- 0.15984042553191488
- 0.16287234042553192
- 0.16287234042553192
- 0.17420212765957446
- 0.17420212765957446
- 0.17420212765957446
- 0.18845744680851065
- 0.18845744680851065
- 0.19090425531914892
- 0.19090425531914892
- 0.19090425531914892
- 0.19090425531914892
- 0.1946808510638298
- 0.19579787234042553
- 0.19579787234042553
- 0.19579787234042553
- 0.19579787234042553
- 0.19904255319148936
- 0.19904255319148936
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20462765957446807
- 0.20856382978723403
- 0.20856382978723403
- 0.20856382978723403
- 0.20856382978723403
- 0.20856382978723403
- 0.20856382978723403
- 0.23063829787234041
- 0.23063829787234041
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.23664893617021276
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.25138297872340426
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2540425531914894
- 0.2618617021276596
- 0.2618617021276596
- 0.2627127659574468
- 0.2627127659574468
- 0.2627127659574468
- 0.2627127659574468
- 0.2627127659574468
- 0.2627127659574468
test_loss_list:
- 980.3911576271057
- 1299.038200378418
- 1278.113076210022
- 1049.1816034317017
- 936.5578784942627
- 775.4080939292908
- 775.4080939292908
- 688.2802784442902
- 688.2802784442902
- 688.2802784442902
- 1467.1732940673828
- 1467.1732940673828
- 1450.134705543518
- 1450.134705543518
- 1450.134705543518
- 1450.134705543518
- 1373.742504119873
- 1380.727912902832
- 1380.727912902832
- 1380.727912902832
- 1380.727912902832
- 1398.974588394165
- 1398.974588394165
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 673.5632491111755
- 823.6706266403198
- 823.6706266403198
- 823.6706266403198
- 823.6706266403198
- 823.6706266403198
- 823.6706266403198
- 689.1488134860992
- 689.1488134860992
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 942.125922203064
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 687.337920665741
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 597.7822194099426
- 529.2849111557007
- 529.2849111557007
- 620.4150576591492
- 620.4150576591492
- 620.4150576591492
- 620.4150576591492
- 620.4150576591492
- 620.4150576591492
train_accuracy:
- 0.485
- 0.546
- 0.623
- 0.671
- 0.725
- 0.696
- 0.0
- 0.0
- 0.0
- 0.0
- 0.837
- 0.0
- 0.846
- 0.733
- 0.0
- 0.815
- 0.85
- 0.844
- 0.815
- 0.006
- 0.823
- 0.871
- 0.0
- 0.0
- 0.85
- 0.879
- 0.852
- 0.862
- 0.848
- 0.0
- 0.208
- 0.829
- 0.877
- 0.86
- 0.908
- 0.888
- 0.908
- 0.856
- 0.898
- 0.0
- 0.875
- 0.008
- 0.877
- 0.892
- 0.883
- 0.9
- 0.904
- 0.883
- 0.906
- 0.0
- 0.152
- 0.896
- 0.894
- 0.883
- 0.904
- 0.906
- 0.879
- 0.883
- 0.898
- 0.9
- 0.0
- 0.0
- 0.902
- 0.002
- 0.91
- 0.881
- 0.894
- 0.148
- 0.877
- 0.902
- 0.908
- 0.906
- 0.89
- 0.888
- 0.91
- 0.894
- 0.898
- 0.896
- 0.0
- 0.913
- 0.877
- 0.027
- 0.898
- 0.0
- 0.894
- 0.902
- 0.919
- 0.002
- 0.9
- 0.0
- 0.0
- 0.904
- 0.898
- 0.883
- 0.292
- 0.89
- 0.902
- 0.908
- 0.902
- 0.904
train_loss:
- 3.17
- 1.771
- 1.403
- 1.28
- 1.267
- 1.246
- 1.191
- 0.937
- 0.802
- 0.965
- 1.042
- 1.056
- 1.005
- 1.158
- 0.957
- 0.857
- 0.882
- 0.859
- 0.936
- 0.943
- 0.842
- 0.792
- 0.808
- 0.838
- 0.733
- 0.729
- 0.708
- 0.693
- 0.732
- 0.723
- 0.65
- 0.723
- 0.677
- 0.683
- 0.623
- 0.64
- 0.62
- 0.731
- 0.648
- 0.69
- 0.593
- 0.566
- 0.613
- 0.59
- 0.564
- 0.574
- 0.563
- 0.508
- 0.504
- 0.544
- 0.48
- 0.599
- 0.541
- 0.639
- 0.531
- 0.547
- 0.635
- 0.583
- 0.53
- 0.569
- 0.604
- 0.663
- 0.532
- 0.526
- 0.502
- 0.618
- 0.544
- 0.58
- 0.527
- 0.507
- 0.483
- 0.557
- 0.542
- 0.562
- 0.493
- 0.489
- 0.532
- 0.59
- 0.499
- 0.474
- 0.53
- 0.509
- 0.448
- 0.58
- 0.449
- 0.47
- 0.518
- 0.468
- 0.498
- 0.492
- 0.493
- 0.491
- 0.469
- 0.493
- 0.447
- 0.427
- 0.476
- 0.45
- 0.432
- 0.462
unequal: 0
verbose: 1
