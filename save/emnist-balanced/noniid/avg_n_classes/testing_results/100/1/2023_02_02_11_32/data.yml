avg_train_accuracy: 0.854
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022393617021276596
- 0.0601063829787234
- 0.2255851063829787
- 0.3204255319148936
- 0.37590425531914895
- 0.4021276595744681
- 0.42606382978723406
- 0.43563829787234043
- 0.4588829787234043
- 0.46420212765957447
- 0.4777659574468085
- 0.48117021276595745
- 0.49648936170212765
- 0.504095744680851
- 0.5103191489361703
- 0.5218617021276596
- 0.5260106382978723
- 0.5287765957446808
- 0.5351063829787234
- 0.5394148936170213
- 0.5448936170212766
- 0.5498404255319149
- 0.5521808510638297
- 0.5572340425531915
- 0.5572340425531915
- 0.5618085106382978
- 0.5618085106382978
- 0.5675531914893617
- 0.5697340425531915
- 0.5745744680851064
- 0.5763297872340426
- 0.5771808510638298
- 0.5828723404255319
- 0.585531914893617
- 0.585531914893617
- 0.5868085106382979
- 0.5868085106382979
- 0.5918085106382979
- 0.5943085106382979
- 0.5962234042553192
- 0.5962234042553192
- 0.5993617021276596
- 0.5993617021276596
- 0.6018085106382979
- 0.6053723404255319
- 0.6053723404255319
- 0.607872340425532
- 0.607872340425532
- 0.607872340425532
- 0.607872340425532
- 0.607872340425532
- 0.6100531914893617
- 0.6100531914893617
- 0.6131382978723404
- 0.6131382978723404
- 0.6131382978723404
- 0.6137234042553191
- 0.6143617021276596
- 0.6171276595744681
- 0.6171276595744681
- 0.6171276595744681
- 0.6171276595744681
- 0.6196276595744681
- 0.6196276595744681
- 0.6196276595744681
- 0.6196276595744681
- 0.6206382978723404
- 0.6206382978723404
- 0.6207978723404255
- 0.6208510638297873
- 0.6216489361702128
- 0.6218617021276596
- 0.6229255319148936
- 0.6238297872340426
- 0.6238297872340426
- 0.6239361702127659
- 0.6239361702127659
- 0.625
- 0.6252659574468085
- 0.6252659574468085
- 0.6252659574468085
- 0.6265957446808511
- 0.6265957446808511
- 0.6265957446808511
- 0.6265957446808511
- 0.6265957446808511
- 0.6287234042553191
- 0.6287234042553191
- 0.6287234042553191
- 0.6291489361702127
- 0.6292553191489362
- 0.6292553191489362
- 0.6304255319148936
- 0.6304255319148936
- 0.6304255319148936
- 0.6304255319148936
- 0.6304255319148936
- 0.6304255319148936
- 0.6315425531914893
- 0.6315425531914893
test_loss_list:
- 565.3140828609467
- 557.3501906394958
- 534.1464560031891
- 505.56083941459656
- 495.37618923187256
- 490.1196491718292
- 487.5949738025665
- 493.935031414032
- 488.8872985839844
- 502.5844850540161
- 510.9063184261322
- 486.1518394947052
- 514.9655394554138
- 503.1114730834961
- 515.7272725105286
- 527.6690514087677
- 520.3784921169281
- 516.6802396774292
- 533.7757201194763
- 522.1110045909882
- 528.6416921615601
- 531.9047956466675
- 557.0999863147736
- 544.7542006969452
- 544.7542006969452
- 530.6229498386383
- 530.6229498386383
- 536.6508541107178
- 535.2326872348785
- 529.2828924655914
- 520.4550578594208
- 525.8516726493835
- 563.3639941215515
- 545.9793276786804
- 545.9793276786804
- 542.7031242847443
- 542.7031242847443
- 552.3893921375275
- 554.478474855423
- 543.8758366107941
- 543.8758366107941
- 558.6442003250122
- 558.6442003250122
- 540.1217997074127
- 576.269451379776
- 576.269451379776
- 548.0223383903503
- 548.0223383903503
- 548.0223383903503
- 548.0223383903503
- 548.0223383903503
- 572.7925968170166
- 572.7925968170166
- 562.6527938842773
- 562.6527938842773
- 562.6527938842773
- 544.7274231910706
- 560.0903477668762
- 587.896867275238
- 587.896867275238
- 587.896867275238
- 587.896867275238
- 546.7482712268829
- 546.7482712268829
- 546.7482712268829
- 546.7482712268829
- 563.1986801624298
- 563.1986801624298
- 580.826920747757
- 570.2400984764099
- 561.4089951515198
- 575.3045494556427
- 571.2985169887543
- 570.0272786617279
- 570.0272786617279
- 577.7411139011383
- 577.7411139011383
- 562.0614626407623
- 590.3450515270233
- 590.3450515270233
- 590.3450515270233
- 591.5037462711334
- 591.5037462711334
- 591.5037462711334
- 591.5037462711334
- 591.5037462711334
- 577.1829950809479
- 577.1829950809479
- 577.1829950809479
- 591.9096941947937
- 567.569746017456
- 567.569746017456
- 590.6444325447083
- 590.6444325447083
- 590.6444325447083
- 590.6444325447083
- 590.6444325447083
- 590.6444325447083
- 559.7108895778656
- 559.7108895778656
train_accuracy:
- 0.021
- 0.079
- 0.348
- 0.421
- 0.517
- 0.546
- 0.0
- 0.0
- 0.613
- 0.658
- 0.671
- 0.654
- 0.654
- 0.0
- 0.708
- 0.694
- 0.746
- 0.717
- 0.735
- 0.758
- 0.758
- 0.0
- 0.765
- 0.79
- 0.0
- 0.729
- 0.762
- 0.0
- 0.0
- 0.75
- 0.0
- 0.0
- 0.806
- 0.0
- 0.0
- 0.827
- 0.815
- 0.833
- 0.8
- 0.0
- 0.802
- 0.0
- 0.0
- 0.829
- 0.817
- 0.806
- 0.0
- 0.0
- 0.823
- 0.0
- 0.0
- 0.831
- 0.844
- 0.798
- 0.79
- 0.0
- 0.84
- 0.827
- 0.815
- 0.829
- 0.825
- 0.0
- 0.852
- 0.0
- 0.84
- 0.846
- 0.833
- 0.829
- 0.829
- 0.842
- 0.0
- 0.85
- 0.0
- 0.0
- 0.815
- 0.837
- 0.0
- 0.854
- 0.852
- 0.0
- 0.846
- 0.854
- 0.85
- 0.0
- 0.0
- 0.835
- 0.865
- 0.0
- 0.865
- 0.837
- 0.856
- 0.852
- 0.854
- 0.862
- 0.854
- 0.842
- 0.0
- 0.84
- 0.85
- 0.854
train_loss:
- 2.939
- 3.683
- 2.642
- 2.35
- 2.733
- 1.923
- 1.78
- 1.213
- 1.659
- 2.032
- 1.951
- 1.107
- 1.851
- 1.43
- 1.383
- 1.742
- 1.366
- 1.321
- 1.63
- 1.288
- 1.236
- 1.242
- 1.535
- 1.513
- 0.606
- 1.22
- 0.883
- 1.173
- 0.842
- 0.828
- 0.567
- 0.823
- 1.369
- 1.086
- 0.817
- 0.801
- 0.818
- 1.029
- 1.049
- 0.798
- 1.025
- 1.01
- 0.583
- 0.778
- 1.239
- 1.028
- 0.755
- 1.018
- 0.957
- 0.79
- 0.558
- 0.957
- 0.945
- 0.947
- 0.974
- 0.754
- 0.739
- 0.948
- 1.103
- 1.117
- 0.707
- 0.596
- 0.936
- 0.751
- 0.748
- 0.714
- 0.891
- 1.068
- 1.085
- 0.876
- 0.708
- 0.883
- 0.864
- 0.879
- 0.852
- 0.876
- 0.733
- 0.907
- 1.026
- 0.873
- 0.711
- 1.021
- 0.696
- 0.542
- 0.854
- 1.022
- 1.032
- 0.837
- 0.686
- 1.019
- 0.848
- 0.973
- 1.001
- 0.988
- 0.671
- 0.97
- 0.645
- 0.977
- 0.728
- 0.818
unequal: 0
verbose: 1
