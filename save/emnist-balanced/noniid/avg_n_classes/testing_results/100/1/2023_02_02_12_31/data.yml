avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0275531914893617
- 0.0275531914893617
- 0.10601063829787234
- 0.2643617021276596
- 0.3470744680851064
- 0.3817553191489362
- 0.41893617021276597
- 0.4368085106382979
- 0.46239361702127657
- 0.47122340425531917
- 0.48579787234042554
- 0.496436170212766
- 0.5045212765957446
- 0.517127659574468
- 0.5192021276595745
- 0.5302127659574468
- 0.5332978723404256
- 0.5393617021276595
- 0.5421808510638297
- 0.5504787234042553
- 0.5504787234042553
- 0.556595744680851
- 0.560531914893617
- 0.560531914893617
- 0.5665425531914894
- 0.5693085106382979
- 0.5705851063829788
- 0.5715425531914894
- 0.5779255319148936
- 0.5779255319148936
- 0.5807446808510638
- 0.5829255319148936
- 0.5867553191489362
- 0.5867553191489362
- 0.5867553191489362
- 0.5868617021276595
- 0.589627659574468
- 0.5905851063829787
- 0.5948404255319149
- 0.5965957446808511
- 0.5997340425531915
- 0.5997340425531915
- 0.5997340425531915
- 0.6001063829787234
- 0.601968085106383
- 0.6043085106382978
- 0.6043085106382978
- 0.6043085106382978
- 0.6043085106382978
- 0.6072872340425531
- 0.6072872340425531
- 0.6103723404255319
- 0.6103723404255319
- 0.6105851063829787
- 0.6107446808510638
- 0.611968085106383
- 0.611968085106383
- 0.611968085106383
- 0.612872340425532
- 0.6155851063829787
- 0.6155851063829787
- 0.6155851063829787
- 0.6178191489361702
- 0.6178191489361702
- 0.6178191489361702
- 0.6204787234042554
- 0.6204787234042554
- 0.6204787234042554
- 0.6204787234042554
- 0.6204787234042554
- 0.6204787234042554
- 0.6207978723404255
- 0.6207978723404255
- 0.6207978723404255
- 0.6207978723404255
- 0.6207978723404255
- 0.6214893617021277
- 0.6214893617021277
- 0.6220212765957447
- 0.624095744680851
- 0.624095744680851
- 0.624095744680851
- 0.624095744680851
- 0.624095744680851
- 0.624095744680851
- 0.624095744680851
- 0.625904255319149
- 0.6276063829787234
- 0.6276063829787234
- 0.6276063829787234
- 0.6276063829787234
- 0.6276063829787234
- 0.6276063829787234
- 0.6279255319148936
- 0.6279255319148936
- 0.6279255319148936
- 0.6279255319148936
- 0.6279255319148936
- 0.6279255319148936
- 0.6279255319148936
test_loss_list:
- 564.835695028305
- 564.835695028305
- 552.231564283371
- 518.9236068725586
- 492.3926146030426
- 475.4868152141571
- 474.8873600959778
- 470.7234699726105
- 482.875146150589
- 470.30401253700256
- 487.95323038101196
- 496.7535855770111
- 496.4027044773102
- 509.47112679481506
- 475.1420843601227
- 512.2659597396851
- 479.1235041618347
- 499.8094434738159
- 497.4506165981293
- 522.4627680778503
- 522.4627680778503
- 529.1495635509491
- 535.3391733169556
- 535.3391733169556
- 535.7748093605042
- 533.3154971599579
- 537.4132170677185
- 501.9090235233307
- 548.4278557300568
- 548.4278557300568
- 561.5497283935547
- 531.5715770721436
- 538.2654058933258
- 538.2654058933258
- 538.2654058933258
- 535.3295602798462
- 539.2197268009186
- 547.8338937759399
- 569.023371219635
- 566.5628354549408
- 569.5626752376556
- 569.5626752376556
- 569.5626752376556
- 557.9359660148621
- 546.9600605964661
- 572.478716135025
- 572.478716135025
- 572.478716135025
- 572.478716135025
- 581.9274411201477
- 581.9274411201477
- 577.5555009841919
- 577.5555009841919
- 588.82777094841
- 547.1408486366272
- 590.2940771579742
- 590.2940771579742
- 590.2940771579742
- 550.2740077972412
- 592.6482636928558
- 592.6482636928558
- 592.6482636928558
- 582.1488676071167
- 582.1488676071167
- 582.1488676071167
- 597.3249368667603
- 597.3249368667603
- 597.3249368667603
- 597.3249368667603
- 597.3249368667603
- 597.3249368667603
- 587.5192959308624
- 587.5192959308624
- 587.5192959308624
- 587.5192959308624
- 587.5192959308624
- 592.9219107627869
- 592.9219107627869
- 598.0615036487579
- 612.8708417415619
- 612.8708417415619
- 612.8708417415619
- 612.8708417415619
- 612.8708417415619
- 612.8708417415619
- 612.8708417415619
- 615.067061662674
- 592.3485765457153
- 592.3485765457153
- 592.3485765457153
- 592.3485765457153
- 592.3485765457153
- 592.3485765457153
- 593.7837879657745
- 593.7837879657745
- 593.7837879657745
- 593.7837879657745
- 593.7837879657745
- 593.7837879657745
- 593.7837879657745
train_accuracy:
- 0.04
- 0.985
- 0.135
- 0.327
- 0.0
- 0.0
- 0.604
- 0.0
- 0.629
- 0.0
- 0.671
- 0.671
- 0.0
- 0.719
- 0.0
- 0.702
- 0.717
- 0.721
- 0.733
- 0.75
- 0.746
- 0.742
- 0.775
- 0.754
- 0.79
- 0.769
- 0.0
- 0.79
- 0.758
- 0.0
- 0.812
- 0.81
- 0.771
- 0.0
- 0.0
- 0.79
- 0.827
- 0.812
- 0.819
- 0.819
- 0.802
- 0.831
- 0.0
- 0.835
- 0.808
- 0.842
- 0.825
- 0.819
- 0.8
- 0.846
- 0.84
- 0.848
- 0.833
- 0.846
- 0.0
- 0.79
- 0.844
- 0.0
- 0.0
- 0.837
- 0.815
- 0.85
- 0.0
- 0.867
- 0.0
- 0.86
- 0.0
- 0.846
- 0.837
- 0.842
- 0.0
- 0.0
- 0.86
- 0.0
- 0.0
- 0.865
- 0.85
- 0.0
- 0.852
- 0.873
- 0.837
- 0.856
- 0.823
- 0.862
- 0.862
- 0.0
- 0.852
- 0.0
- 0.86
- 0.856
- 0.871
- 0.842
- 0.0
- 0.848
- 0.862
- 0.867
- 0.862
- 0.0
- 0.0
- 0.0
train_loss:
- 2.962
- 0.419
- 2.873
- 2.61
- 2.294
- 1.417
- 1.862
- 1.213
- 2.141
- 1.117
- 1.92
- 1.856
- 1.42
- 1.76
- 1.009
- 1.683
- 0.952
- 1.254
- 1.235
- 1.514
- 1.209
- 1.483
- 1.154
- 0.867
- 1.136
- 1.116
- 1.093
- 0.835
- 1.335
- 1.038
- 1.302
- 1.052
- 1.05
- 0.813
- 0.834
- 0.775
- 1.021
- 0.984
- 1.208
- 1.211
- 1.194
- 0.961
- 0.548
- 0.955
- 0.966
- 1.157
- 0.98
- 0.753
- 0.945
- 1.124
- 0.726
- 1.137
- 1.103
- 1.092
- 0.734
- 1.086
- 0.736
- 0.567
- 0.693
- 1.058
- 1.052
- 1.077
- 0.874
- 0.892
- 0.739
- 1.042
- 0.732
- 0.884
- 0.866
- 1.031
- 0.869
- 0.865
- 0.862
- 0.843
- 0.857
- 0.831
- 0.848
- 0.845
- 0.829
- 1.011
- 1.007
- 0.822
- 0.985
- 0.817
- 0.81
- 0.566
- 0.997
- 0.848
- 0.814
- 0.806
- 0.837
- 0.793
- 0.847
- 0.785
- 0.691
- 0.95
- 0.629
- 0.624
- 0.773
- 0.675
unequal: 0
verbose: 1
