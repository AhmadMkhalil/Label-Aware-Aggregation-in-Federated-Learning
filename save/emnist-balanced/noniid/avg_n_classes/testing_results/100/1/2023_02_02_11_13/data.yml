avg_train_accuracy: 0.85
avg_train_loss: 0.01
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.035425531914893615
- 0.13670212765957446
- 0.28345744680851065
- 0.3465957446808511
- 0.41702127659574467
- 0.44904255319148934
- 0.46324468085106385
- 0.48090425531914893
- 0.49388297872340425
- 0.5013829787234042
- 0.5079787234042553
- 0.5192553191489362
- 0.5247340425531914
- 0.5300531914893617
- 0.5362765957446809
- 0.5406382978723404
- 0.5452659574468085
- 0.5523404255319149
- 0.5566489361702127
- 0.5623936170212765
- 0.5647872340425532
- 0.568936170212766
- 0.568936170212766
- 0.5728723404255319
- 0.5775531914893617
- 0.5775531914893617
- 0.5825
- 0.5838829787234042
- 0.5845744680851064
- 0.5885638297872341
- 0.589095744680851
- 0.589095744680851
- 0.5897872340425532
- 0.5919148936170213
- 0.5925531914893617
- 0.5972340425531915
- 0.5972340425531915
- 0.5999468085106383
- 0.5999468085106383
- 0.5999468085106383
- 0.6029787234042553
- 0.6029787234042553
- 0.6029787234042553
- 0.6029787234042553
- 0.6037234042553191
- 0.6078191489361702
- 0.6078191489361702
- 0.6078191489361702
- 0.6078191489361702
- 0.6081914893617021
- 0.6081914893617021
- 0.6110638297872341
- 0.6123936170212766
- 0.6123936170212766
- 0.6123936170212766
- 0.6123936170212766
- 0.6123936170212766
- 0.6138297872340426
- 0.6143617021276596
- 0.6143617021276596
- 0.6147340425531915
- 0.6154787234042554
- 0.6154787234042554
- 0.6171808510638298
- 0.6171808510638298
- 0.6172340425531915
- 0.6173404255319149
- 0.6186702127659575
- 0.6186702127659575
- 0.6186702127659575
- 0.6186702127659575
- 0.6198404255319149
- 0.6204255319148936
- 0.6204255319148936
- 0.6204255319148936
- 0.6204255319148936
- 0.6228191489361702
- 0.622872340425532
- 0.6235106382978723
- 0.6236702127659575
- 0.6236702127659575
- 0.6236702127659575
- 0.6236702127659575
- 0.6268617021276596
- 0.6268617021276596
- 0.6268617021276596
- 0.6268617021276596
- 0.6268617021276596
- 0.6268617021276596
- 0.6268617021276596
- 0.6268617021276596
- 0.6271808510638298
- 0.6280851063829788
- 0.6280851063829788
- 0.6280851063829788
- 0.6280851063829788
- 0.6292553191489362
- 0.6292553191489362
- 0.6292553191489362
- 0.6292553191489362
test_loss_list:
- 562.0381722450256
- 548.7950301170349
- 514.7178959846497
- 481.99533557891846
- 468.4429702758789
- 473.20377683639526
- 472.093510389328
- 480.22356033325195
- 481.7512836456299
- 497.6421537399292
- 489.1155252456665
- 508.12195014953613
- 505.2191307544708
- 496.60372972488403
- 516.3959314823151
- 508.7824423313141
- 530.2997312545776
- 522.8146016597748
- 538.8046391010284
- 537.7039079666138
- 550.9062328338623
- 525.2020797729492
- 525.2020797729492
- 522.9232141971588
- 549.2719812393188
- 549.2719812393188
- 546.9388496875763
- 542.9271867275238
- 542.0086050033569
- 547.9983022212982
- 570.320255279541
- 570.320255279541
- 552.4816317558289
- 524.285028219223
- 555.8526153564453
- 559.9984889030457
- 559.9984889030457
- 568.921126127243
- 568.921126127243
- 568.921126127243
- 556.711550951004
- 556.711550951004
- 556.711550951004
- 556.711550951004
- 559.4003658294678
- 563.7810442447662
- 563.7810442447662
- 563.7810442447662
- 563.7810442447662
- 582.6308372020721
- 582.6308372020721
- 551.1104483604431
- 585.4589245319366
- 585.4589245319366
- 585.4589245319366
- 585.4589245319366
- 585.4589245319366
- 576.9776623249054
- 577.1082172393799
- 577.1082172393799
- 576.332489490509
- 564.1929113864899
- 564.1929113864899
- 576.6997990608215
- 576.6997990608215
- 562.1058986186981
- 584.3669114112854
- 547.6968810558319
- 547.6968810558319
- 547.6968810558319
- 547.6968810558319
- 581.2666783332825
- 576.5254504680634
- 576.5254504680634
- 576.5254504680634
- 576.5254504680634
- 586.6654717922211
- 592.463972568512
- 561.7816097736359
- 573.9469034671783
- 573.9469034671783
- 573.9469034671783
- 573.9469034671783
- 557.8955321311951
- 557.8955321311951
- 557.8955321311951
- 557.8955321311951
- 557.8955321311951
- 557.8955321311951
- 557.8955321311951
- 557.8955321311951
- 555.9376170635223
- 564.5079140663147
- 564.5079140663147
- 564.5079140663147
- 564.5079140663147
- 573.240364074707
- 573.240364074707
- 573.240364074707
- 573.240364074707
train_accuracy:
- 0.038
- 0.21
- 0.0
- 0.438
- 0.0
- 0.625
- 0.0
- 0.64
- 0.681
- 0.685
- 0.669
- 0.744
- 0.0
- 0.721
- 0.729
- 0.0
- 0.758
- 0.0
- 0.76
- 0.777
- 0.769
- 0.777
- 0.0
- 0.748
- 0.779
- 0.0
- 0.806
- 0.779
- 0.0
- 0.0
- 0.806
- 0.0
- 0.783
- 0.829
- 0.792
- 0.0
- 0.783
- 0.829
- 0.806
- 0.825
- 0.802
- 0.0
- 0.81
- 0.0
- 0.808
- 0.835
- 0.827
- 0.802
- 0.0
- 0.8
- 0.821
- 0.829
- 0.817
- 0.835
- 0.825
- 0.837
- 0.0
- 0.833
- 0.825
- 0.0
- 0.86
- 0.833
- 0.827
- 0.833
- 0.842
- 0.84
- 0.823
- 0.0
- 0.817
- 0.0
- 0.84
- 0.852
- 0.842
- 0.85
- 0.819
- 0.0
- 0.0
- 0.848
- 0.837
- 0.837
- 0.85
- 0.827
- 0.852
- 0.846
- 0.85
- 0.848
- 0.856
- 0.844
- 0.84
- 0.848
- 0.865
- 0.842
- 0.854
- 0.821
- 0.852
- 0.86
- 0.844
- 0.0
- 0.0
- 0.85
train_loss:
- 2.958
- 2.822
- 2.578
- 1.633
- 2.057
- 2.392
- 1.727
- 2.092
- 1.54
- 1.912
- 1.467
- 1.777
- 1.352
- 1.339
- 1.66
- 1.269
- 1.57
- 1.228
- 1.513
- 1.495
- 1.452
- 1.177
- 0.875
- 0.876
- 1.39
- 0.867
- 1.357
- 1.075
- 1.092
- 1.045
- 1.286
- 0.814
- 0.794
- 0.59
- 1.017
- 1.022
- 1.016
- 1.219
- 0.794
- 1.001
- 0.976
- 0.983
- 1.179
- 0.755
- 0.987
- 0.984
- 1.15
- 0.782
- 0.933
- 1.129
- 0.939
- 0.964
- 1.107
- 0.917
- 0.74
- 0.915
- 0.734
- 1.103
- 1.093
- 0.895
- 1.101
- 0.903
- 0.734
- 0.878
- 0.896
- 0.912
- 1.067
- 0.741
- 1.039
- 0.881
- 1.026
- 1.062
- 0.86
- 0.881
- 1.037
- 0.686
- 0.84
- 1.034
- 0.7
- 0.855
- 0.856
- 0.852
- 0.674
- 0.873
- 0.863
- 0.684
- 1.014
- 0.549
- 0.863
- 0.654
- 0.853
- 0.832
- 0.831
- 0.965
- 0.996
- 0.659
- 0.987
- 0.859
- 0.541
- 0.986
unequal: 0
verbose: 1
