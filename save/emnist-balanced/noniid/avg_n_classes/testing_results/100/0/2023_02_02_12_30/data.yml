avg_train_accuracy: 0.717
avg_train_loss: 0.001
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 0
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021329787234042552
- 0.023617021276595745
- 0.023617021276595745
- 0.023617021276595745
- 0.025106382978723404
- 0.025106382978723404
- 0.025106382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.047606382978723404
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.048138297872340426
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.061861702127659575
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
- 0.06404255319148937
test_loss_list:
- 964.9323735237122
- 1215.3431525230408
- 1215.3431525230408
- 1215.3431525230408
- 898.121250629425
- 898.121250629425
- 898.121250629425
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 1054.2778387069702
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 951.6909012794495
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 821.1912655830383
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
- 744.9210004806519
train_accuracy:
- 0.996
- 0.756
- 0.0
- 0.031
- 0.998
- 0.19
- 0.0
- 0.06
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.979
- 0.0
- 0.0
- 0.0
- 0.0
- 0.035
- 0.998
- 1.0
- 0.99
- 0.0
- 0.0
- 0.0
- 0.181
- 0.306
- 0.831
- 0.0
- 1.0
- 0.825
- 0.01
- 0.002
- 0.0
- 0.981
- 0.967
- 0.942
- 0.958
- 0.0
- 0.06
- 0.023
- 0.0
- 0.765
- 0.029
- 0.602
- 0.873
- 0.098
- 0.746
- 0.771
- 0.0
- 0.967
- 0.431
- 0.098
- 0.785
- 0.0
- 0.967
- 0.081
- 0.994
- 0.944
- 0.54
- 0.329
- 0.317
- 0.0
- 0.006
- 0.325
- 0.946
- 1.0
- 0.798
- 0.379
- 0.846
- 0.633
- 0.99
- 0.606
- 0.002
- 1.0
- 0.0
- 0.558
- 0.219
- 0.915
- 0.377
- 0.156
- 0.056
- 0.917
- 0.979
- 0.846
- 0.79
- 0.994
- 0.071
- 0.0
- 0.977
- 0.598
- 0.596
- 0.158
- 0.873
- 0.225
- 0.99
- 0.133
- 0.04
- 0.725
- 0.717
train_loss:
- 0.326
- 0.146
- 0.165
- 0.172
- 0.163
- 0.111
- 0.163
- 0.14
- 0.15
- 0.129
- 0.144
- 0.113
- 0.133
- 0.125
- 0.186
- 0.102
- 0.08
- 0.146
- 0.167
- 0.136
- 0.106
- 0.143
- 0.136
- 0.122
- 0.098
- 0.118
- 0.133
- 0.08
- 0.134
- 0.089
- 0.127
- 0.157
- 0.108
- 0.142
- 0.098
- 0.133
- 0.127
- 0.116
- 0.129
- 0.138
- 0.126
- 0.105
- 0.108
- 0.12
- 0.1
- 0.098
- 0.086
- 0.071
- 0.125
- 0.086
- 0.157
- 0.087
- 0.078
- 0.113
- 0.084
- 0.092
- 0.107
- 0.11
- 0.085
- 0.085
- 0.108
- 0.112
- 0.091
- 0.102
- 0.089
- 0.091
- 0.095
- 0.095
- 0.12
- 0.089
- 0.125
- 0.077
- 0.089
- 0.11
- 0.106
- 0.101
- 0.096
- 0.094
- 0.091
- 0.081
- 0.095
- 0.092
- 0.095
- 0.069
- 0.102
- 0.108
- 0.085
- 0.096
- 0.122
- 0.077
- 0.101
- 0.095
- 0.094
- 0.102
- 0.094
- 0.075
- 0.113
- 0.103
- 0.085
- 0.09
unequal: 0
verbose: 1
