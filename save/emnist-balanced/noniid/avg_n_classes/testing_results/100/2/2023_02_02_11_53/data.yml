avg_train_accuracy: 0.91
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021595744680851063
- 0.14446808510638298
- 0.21271276595744681
- 0.28202127659574466
- 0.31053191489361703
- 0.33335106382978724
- 0.33335106382978724
- 0.35335106382978726
- 0.35877659574468085
- 0.3659574468085106
- 0.3726595744680851
- 0.37957446808510636
- 0.38361702127659575
- 0.38361702127659575
- 0.386968085106383
- 0.39287234042553193
- 0.3931914893617021
- 0.39372340425531915
- 0.39372340425531915
- 0.4006914893617021
- 0.4006914893617021
- 0.4007978723404255
- 0.40297872340425533
- 0.4075
- 0.4075
- 0.4118085106382979
- 0.4118085106382979
- 0.41212765957446806
- 0.41212765957446806
- 0.41212765957446806
- 0.41212765957446806
- 0.4154255319148936
- 0.4161170212765957
- 0.41632978723404257
- 0.41632978723404257
- 0.41840425531914893
- 0.41840425531914893
- 0.41840425531914893
- 0.4206382978723404
- 0.42069148936170214
- 0.42148936170212764
- 0.4226063829787234
- 0.4226063829787234
- 0.4226063829787234
- 0.4226063829787234
- 0.42361702127659573
- 0.42404255319148937
- 0.4254787234042553
- 0.4254787234042553
- 0.4254787234042553
- 0.4254787234042553
- 0.42638297872340425
- 0.42638297872340425
- 0.42638297872340425
- 0.42638297872340425
- 0.4276595744680851
- 0.4276595744680851
- 0.4276595744680851
- 0.4281382978723404
- 0.4281382978723404
- 0.4281382978723404
- 0.4281382978723404
- 0.4281382978723404
- 0.4281382978723404
- 0.4281382978723404
- 0.4295744680851064
- 0.4295744680851064
- 0.4295744680851064
- 0.4304787234042553
- 0.4304787234042553
- 0.4304787234042553
- 0.4304787234042553
- 0.4304787234042553
- 0.4305851063829787
- 0.4305851063829787
- 0.4305851063829787
- 0.4315425531914894
- 0.4315425531914894
- 0.4315425531914894
- 0.4315425531914894
- 0.43175531914893617
- 0.43175531914893617
- 0.43175531914893617
- 0.43175531914893617
- 0.43175531914893617
- 0.43175531914893617
- 0.4334574468085106
- 0.4346808510638298
- 0.4346808510638298
- 0.4346808510638298
- 0.4346808510638298
- 0.4346808510638298
- 0.4346808510638298
- 0.4346808510638298
- 0.43553191489361703
- 0.43553191489361703
- 0.43553191489361703
- 0.43553191489361703
- 0.43553191489361703
- 0.43632978723404253
test_loss_list:
- 574.5093216896057
- 615.597097158432
- 640.7679665088654
- 663.1761653423309
- 631.3239104747772
- 691.3510835170746
- 691.3510835170746
- 814.8254885673523
- 858.8415417671204
- 859.9374146461487
- 785.5592589378357
- 880.5898160934448
- 896.1189484596252
- 896.1189484596252
- 815.4796829223633
- 920.399037361145
- 840.1568837165833
- 817.6134595870972
- 817.6134595870972
- 838.9966025352478
- 838.9966025352478
- 726.5895988941193
- 727.4080398082733
- 838.7632412910461
- 838.7632412910461
- 811.9536499977112
- 811.9536499977112
- 934.8806486129761
- 934.8806486129761
- 934.8806486129761
- 934.8806486129761
- 837.3959550857544
- 869.8615026473999
- 859.0753231048584
- 859.0753231048584
- 751.7744646072388
- 751.7744646072388
- 751.7744646072388
- 945.8792715072632
- 975.5634746551514
- 952.3480358123779
- 839.909586429596
- 839.909586429596
- 839.909586429596
- 839.909586429596
- 883.1450805664062
- 974.2352542877197
- 973.3961138725281
- 973.3961138725281
- 973.3961138725281
- 973.3961138725281
- 960.8834185600281
- 960.8834185600281
- 960.8834185600281
- 960.8834185600281
- 956.2230744361877
- 956.2230744361877
- 956.2230744361877
- 964.321222782135
- 964.321222782135
- 964.321222782135
- 964.321222782135
- 964.321222782135
- 964.321222782135
- 964.321222782135
- 900.6885204315186
- 900.6885204315186
- 900.6885204315186
- 917.047935962677
- 917.047935962677
- 917.047935962677
- 917.047935962677
- 917.047935962677
- 913.5800013542175
- 913.5800013542175
- 913.5800013542175
- 901.203209400177
- 901.203209400177
- 901.203209400177
- 901.203209400177
- 804.0950679779053
- 804.0950679779053
- 804.0950679779053
- 804.0950679779053
- 804.0950679779053
- 804.0950679779053
- 745.6677129268646
- 879.9393911361694
- 879.9393911361694
- 879.9393911361694
- 879.9393911361694
- 879.9393911361694
- 879.9393911361694
- 879.9393911361694
- 887.7570376396179
- 887.7570376396179
- 887.7570376396179
- 887.7570376396179
- 887.7570376396179
- 896.2326192855835
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.56
- 0.665
- 0.656
- 0.0
- 0.762
- 0.794
- 0.735
- 0.796
- 0.775
- 0.806
- 0.756
- 0.775
- 0.817
- 0.792
- 0.0
- 0.0
- 0.81
- 0.0
- 0.0
- 0.81
- 0.858
- 0.865
- 0.837
- 0.85
- 0.848
- 0.831
- 0.84
- 0.0
- 0.84
- 0.871
- 0.856
- 0.867
- 0.865
- 0.0
- 0.846
- 0.883
- 0.885
- 0.885
- 0.854
- 0.865
- 0.84
- 0.858
- 0.0
- 0.867
- 0.873
- 0.854
- 0.883
- 0.875
- 0.877
- 0.869
- 0.86
- 0.0
- 0.867
- 0.875
- 0.0
- 0.869
- 0.0
- 0.869
- 0.867
- 0.0
- 0.879
- 0.858
- 0.875
- 0.0
- 0.877
- 0.883
- 0.875
- 0.898
- 0.871
- 0.879
- 0.875
- 0.875
- 0.0
- 0.896
- 0.888
- 0.0
- 0.888
- 0.89
- 0.888
- 0.888
- 0.869
- 0.0
- 0.0
- 0.908
- 0.89
- 0.869
- 0.885
- 0.0
- 0.89
- 0.9
- 0.879
- 0.881
- 0.875
- 0.888
- 0.0
- 0.89
- 0.91
train_loss:
- 1.625
- 2.001
- 1.162
- 1.869
- 1.316
- 1.55
- 1.302
- 1.689
- 1.587
- 1.553
- 1.278
- 1.435
- 1.406
- 1.141
- 1.117
- 1.285
- 1.093
- 1.067
- 0.803
- 1.046
- 0.913
- 0.824
- 0.785
- 0.987
- 0.981
- 0.964
- 0.93
- 1.034
- 0.905
- 0.93
- 0.914
- 0.893
- 0.884
- 0.845
- 0.846
- 0.799
- 0.873
- 0.817
- 0.949
- 0.898
- 0.932
- 0.809
- 0.894
- 0.786
- 0.735
- 0.801
- 0.87
- 0.873
- 0.755
- 0.745
- 0.768
- 0.875
- 0.728
- 0.847
- 0.597
- 0.846
- 0.725
- 0.647
- 0.814
- 0.627
- 0.808
- 0.723
- 0.693
- 0.531
- 0.67
- 0.797
- 0.628
- 0.744
- 0.79
- 0.655
- 0.692
- 0.71
- 0.707
- 0.772
- 0.63
- 0.639
- 0.784
- 0.756
- 0.607
- 0.663
- 0.689
- 0.691
- 0.519
- 0.688
- 0.599
- 0.582
- 0.684
- 0.745
- 0.737
- 0.648
- 0.574
- 0.613
- 0.713
- 0.554
- 0.726
- 0.635
- 0.662
- 0.51
- 0.656
- 0.702
unequal: 0
verbose: 1
