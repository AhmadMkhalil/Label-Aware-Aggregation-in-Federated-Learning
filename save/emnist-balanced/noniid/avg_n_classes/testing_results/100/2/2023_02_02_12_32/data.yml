avg_train_accuracy: 0.0
avg_train_loss: 0.007
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0376063829787234
- 0.2124468085106383
- 0.26574468085106384
- 0.30606382978723407
- 0.3270212765957447
- 0.34297872340425534
- 0.34297872340425534
- 0.3542021276595745
- 0.3579787234042553
- 0.3695212765957447
- 0.3741489361702128
- 0.37696808510638297
- 0.37696808510638297
- 0.37696808510638297
- 0.37851063829787235
- 0.37851063829787235
- 0.38872340425531915
- 0.38872340425531915
- 0.38872340425531915
- 0.39191489361702125
- 0.39191489361702125
- 0.39191489361702125
- 0.39361702127659576
- 0.39361702127659576
- 0.39659574468085107
- 0.4018617021276596
- 0.4046808510638298
- 0.405
- 0.405
- 0.405
- 0.40558510638297873
- 0.40622340425531916
- 0.4081382978723404
- 0.40962765957446806
- 0.41058510638297874
- 0.41058510638297874
- 0.41058510638297874
- 0.41297872340425534
- 0.41297872340425534
- 0.41558510638297874
- 0.41558510638297874
- 0.41558510638297874
- 0.4175531914893617
- 0.4175531914893617
- 0.4175531914893617
- 0.41888297872340424
- 0.41888297872340424
- 0.42021276595744683
- 0.42021276595744683
- 0.42021276595744683
- 0.4211170212765957
- 0.4211170212765957
- 0.42351063829787233
- 0.42351063829787233
- 0.42351063829787233
- 0.42351063829787233
- 0.42351063829787233
- 0.425531914893617
- 0.42606382978723406
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.42872340425531913
- 0.4294148936170213
- 0.4294148936170213
- 0.4294148936170213
- 0.4294148936170213
- 0.4294148936170213
- 0.4294148936170213
- 0.4297872340425532
- 0.4319148936170213
- 0.4319148936170213
- 0.4319148936170213
- 0.4319148936170213
- 0.4319148936170213
- 0.4319148936170213
- 0.4321808510638298
- 0.4321808510638298
- 0.4321808510638298
- 0.4321808510638298
- 0.4321808510638298
- 0.4323404255319149
- 0.4328723404255319
- 0.4328723404255319
- 0.4328723404255319
- 0.4328723404255319
- 0.43388297872340426
- 0.433936170212766
- 0.433936170212766
- 0.433936170212766
- 0.433936170212766
- 0.433936170212766
test_loss_list:
- 582.4788699150085
- 635.8018372058868
- 663.7599408626556
- 699.7924928665161
- 735.6330814361572
- 826.3419156074524
- 826.3419156074524
- 791.0461401939392
- 759.5648822784424
- 891.0131440162659
- 898.3391690254211
- 914.781976222992
- 914.781976222992
- 914.781976222992
- 812.9650144577026
- 812.9650144577026
- 930.7816648483276
- 930.7816648483276
- 930.7816648483276
- 835.5641498565674
- 835.5641498565674
- 835.5641498565674
- 760.1163554191589
- 760.1163554191589
- 744.2435920238495
- 834.3576316833496
- 927.7866530418396
- 821.5348091125488
- 821.5348091125488
- 821.5348091125488
- 838.9772734642029
- 738.6954290866852
- 846.5069622993469
- 846.447389125824
- 810.5258302688599
- 810.5258302688599
- 810.5258302688599
- 768.3421216011047
- 768.3421216011047
- 932.3677854537964
- 932.3677854537964
- 932.3677854537964
- 924.9017038345337
- 924.9017038345337
- 924.9017038345337
- 919.9372844696045
- 919.9372844696045
- 829.6793165206909
- 829.6793165206909
- 829.6793165206909
- 920.2084708213806
- 920.2084708213806
- 917.9996628761292
- 917.9996628761292
- 917.9996628761292
- 917.9996628761292
- 917.9996628761292
- 944.6215205192566
- 939.2201104164124
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 951.1288552284241
- 918.4757294654846
- 942.7582402229309
- 942.7582402229309
- 942.7582402229309
- 942.7582402229309
- 942.7582402229309
- 942.7582402229309
- 831.1146221160889
- 931.0153913497925
- 931.0153913497925
- 931.0153913497925
- 931.0153913497925
- 931.0153913497925
- 931.0153913497925
- 932.36048412323
- 932.36048412323
- 932.36048412323
- 932.36048412323
- 932.36048412323
- 931.684070110321
- 943.2419981956482
- 943.2419981956482
- 943.2419981956482
- 943.2419981956482
- 920.9917440414429
- 938.3805103302002
- 938.3805103302002
- 938.3805103302002
- 938.3805103302002
- 938.3805103302002
train_accuracy:
- 0.079
- 0.435
- 0.0
- 0.644
- 0.0
- 0.719
- 0.0
- 0.752
- 0.731
- 0.752
- 0.758
- 0.773
- 0.758
- 0.74
- 0.783
- 0.0
- 0.794
- 0.777
- 0.0
- 0.825
- 0.0
- 0.808
- 0.79
- 0.0
- 0.0
- 0.823
- 0.837
- 0.829
- 0.835
- 0.0
- 0.815
- 0.827
- 0.0
- 0.0
- 0.833
- 0.835
- 0.0
- 0.856
- 0.844
- 0.829
- 0.0
- 0.85
- 0.856
- 0.0
- 0.862
- 0.862
- 0.837
- 0.862
- 0.835
- 0.0
- 0.869
- 0.0
- 0.888
- 0.852
- 0.844
- 0.869
- 0.888
- 0.875
- 0.873
- 0.869
- 0.871
- 0.0
- 0.0
- 0.883
- 0.0
- 0.879
- 0.858
- 0.883
- 0.0
- 0.0
- 0.877
- 0.888
- 0.862
- 0.865
- 0.0
- 0.0
- 0.0
- 0.906
- 0.9
- 0.858
- 0.0
- 0.877
- 0.869
- 0.883
- 0.862
- 0.902
- 0.0
- 0.885
- 0.0
- 0.896
- 0.89
- 0.0
- 0.0
- 0.894
- 0.875
- 0.898
- 0.917
- 0.904
- 0.888
- 0.0
train_loss:
- 3.69
- 3.192
- 1.091
- 1.827
- 1.612
- 1.818
- 0.825
- 1.287
- 1.329
- 1.514
- 1.457
- 1.427
- 1.145
- 0.752
- 1.147
- 0.871
- 1.275
- 1.124
- 1.003
- 1.021
- 0.753
- 0.835
- 0.82
- 0.837
- 0.883
- 0.981
- 1.104
- 1.022
- 0.764
- 0.949
- 0.908
- 0.782
- 0.886
- 0.918
- 0.872
- 0.863
- 0.702
- 0.848
- 0.871
- 0.972
- 0.724
- 0.87
- 0.954
- 0.702
- 0.826
- 0.949
- 0.821
- 0.859
- 0.724
- 0.691
- 0.914
- 0.802
- 0.878
- 0.816
- 0.774
- 0.844
- 0.804
- 0.847
- 0.863
- 0.848
- 0.822
- 0.621
- 0.708
- 0.819
- 0.679
- 0.809
- 0.766
- 0.715
- 0.762
- 0.621
- 0.809
- 0.799
- 0.766
- 0.735
- 0.574
- 0.711
- 0.705
- 0.727
- 0.775
- 0.634
- 0.722
- 0.791
- 0.642
- 0.777
- 0.758
- 0.635
- 0.703
- 0.706
- 0.655
- 0.736
- 0.746
- 0.612
- 0.654
- 0.634
- 0.74
- 0.741
- 0.728
- 0.564
- 0.731
- 0.678
unequal: 0
verbose: 1
