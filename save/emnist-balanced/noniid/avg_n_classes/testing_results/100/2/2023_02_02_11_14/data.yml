avg_train_accuracy: 0.925
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.023829787234042554
- 0.14319148936170212
- 0.24771276595744682
- 0.2873936170212766
- 0.325
- 0.33526595744680854
- 0.3558510638297872
- 0.3558510638297872
- 0.3622872340425532
- 0.3702127659574468
- 0.3752127659574468
- 0.37824468085106383
- 0.38765957446808513
- 0.38765957446808513
- 0.3926595744680851
- 0.3926595744680851
- 0.3980851063829787
- 0.4006382978723404
- 0.40143617021276595
- 0.4018617021276596
- 0.40595744680851065
- 0.40595744680851065
- 0.4074468085106383
- 0.40941489361702127
- 0.40941489361702127
- 0.41132978723404257
- 0.41377659574468084
- 0.41377659574468084
- 0.4153723404255319
- 0.416968085106383
- 0.416968085106383
- 0.416968085106383
- 0.4193085106382979
- 0.42058510638297875
- 0.42058510638297875
- 0.42058510638297875
- 0.42069148936170214
- 0.4225531914893617
- 0.4225531914893617
- 0.4225531914893617
- 0.42308510638297875
- 0.42404255319148937
- 0.42404255319148937
- 0.42404255319148937
- 0.42425531914893616
- 0.42425531914893616
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.4272340425531915
- 0.42909574468085104
- 0.43031914893617024
- 0.43031914893617024
- 0.43031914893617024
- 0.43031914893617024
- 0.4303723404255319
- 0.4303723404255319
- 0.43164893617021277
- 0.43164893617021277
- 0.43164893617021277
- 0.43164893617021277
- 0.43164893617021277
- 0.4322872340425532
- 0.4322872340425532
- 0.4322872340425532
- 0.4322872340425532
- 0.4322872340425532
- 0.43303191489361703
- 0.43303191489361703
- 0.43303191489361703
- 0.43303191489361703
- 0.43303191489361703
- 0.4343085106382979
- 0.4343085106382979
- 0.4343085106382979
- 0.4343085106382979
- 0.4344148936170213
- 0.4344148936170213
- 0.4344148936170213
- 0.4344148936170213
- 0.4344148936170213
- 0.4344148936170213
- 0.435
- 0.4350531914893617
- 0.4352127659574468
- 0.4352127659574468
- 0.4352127659574468
- 0.4352127659574468
- 0.4356914893617021
- 0.4356914893617021
- 0.4356914893617021
- 0.4356914893617021
- 0.4356914893617021
- 0.4356914893617021
- 0.4356914893617021
- 0.43617021276595747
- 0.43617021276595747
test_loss_list:
- 583.3975405693054
- 640.0925724506378
- 721.8143911361694
- 755.7415432929993
- 804.1058783531189
- 767.9248509407043
- 837.4195408821106
- 837.4195408821106
- 758.5704593658447
- 750.4758157730103
- 779.6334161758423
- 786.1132483482361
- 877.32270860672
- 877.32270860672
- 898.1908688545227
- 898.1908688545227
- 902.212456703186
- 923.2922701835632
- 800.3638424873352
- 840.4517011642456
- 810.6752734184265
- 810.6752734184265
- 824.9915018081665
- 949.1691250801086
- 949.1691250801086
- 826.3076992034912
- 940.1662635803223
- 940.1662635803223
- 949.4778580665588
- 953.241518497467
- 953.241518497467
- 953.241518497467
- 955.532347202301
- 976.0999693870544
- 976.0999693870544
- 976.0999693870544
- 863.0211701393127
- 957.1651496887207
- 957.1651496887207
- 957.1651496887207
- 860.5730175971985
- 875.2538104057312
- 875.2538104057312
- 875.2538104057312
- 747.1774377822876
- 747.1774377822876
- 950.1839652061462
- 950.1839652061462
- 950.1839652061462
- 950.1839652061462
- 950.1839652061462
- 950.1839652061462
- 950.1839652061462
- 922.9991178512573
- 958.381754398346
- 958.381754398346
- 958.381754398346
- 958.381754398346
- 874.1255679130554
- 874.1255679130554
- 965.9299006462097
- 965.9299006462097
- 965.9299006462097
- 965.9299006462097
- 965.9299006462097
- 794.2770595550537
- 794.2770595550537
- 794.2770595550537
- 794.2770595550537
- 794.2770595550537
- 939.1294369697571
- 939.1294369697571
- 939.1294369697571
- 939.1294369697571
- 939.1294369697571
- 949.0209617614746
- 949.0209617614746
- 949.0209617614746
- 949.0209617614746
- 784.1994676589966
- 784.1994676589966
- 784.1994676589966
- 784.1994676589966
- 784.1994676589966
- 784.1994676589966
- 936.3755059242249
- 945.5639343261719
- 930.0545754432678
- 930.0545754432678
- 930.0545754432678
- 930.0545754432678
- 914.7964777946472
- 914.7964777946472
- 914.7964777946472
- 914.7964777946472
- 914.7964777946472
- 914.7964777946472
- 914.7964777946472
- 929.0147910118103
- 929.0147910118103
train_accuracy:
- 0.0
- 0.0
- 0.508
- 0.594
- 0.631
- 0.725
- 0.754
- 0.742
- 0.777
- 0.792
- 0.0
- 0.0
- 0.802
- 0.779
- 0.808
- 0.788
- 0.804
- 0.85
- 0.808
- 0.821
- 0.837
- 0.837
- 0.823
- 0.848
- 0.84
- 0.858
- 0.852
- 0.862
- 0.879
- 0.854
- 0.0
- 0.842
- 0.867
- 0.873
- 0.0
- 0.0
- 0.856
- 0.875
- 0.865
- 0.862
- 0.869
- 0.885
- 0.86
- 0.0
- 0.0
- 0.869
- 0.867
- 0.885
- 0.869
- 0.875
- 0.881
- 0.89
- 0.0
- 0.898
- 0.888
- 0.896
- 0.0
- 0.879
- 0.0
- 0.867
- 0.873
- 0.9
- 0.0
- 0.0
- 0.0
- 0.871
- 0.0
- 0.885
- 0.0
- 0.888
- 0.875
- 0.879
- 0.896
- 0.0
- 0.9
- 0.904
- 0.0
- 0.877
- 0.0
- 0.0
- 0.0
- 0.896
- 0.915
- 0.871
- 0.873
- 0.917
- 0.894
- 0.908
- 0.0
- 0.0
- 0.913
- 0.904
- 0.89
- 0.877
- 0.902
- 0.0
- 0.0
- 0.9
- 0.898
- 0.925
train_loss:
- 2.355
- 2.661
- 2.246
- 1.875
- 1.994
- 1.459
- 1.673
- 1.024
- 1.261
- 1.197
- 1.132
- 1.159
- 1.333
- 0.943
- 1.234
- 0.931
- 1.179
- 1.157
- 1.022
- 1.015
- 0.959
- 1.051
- 0.933
- 1.021
- 0.903
- 0.91
- 0.995
- 0.795
- 0.972
- 0.989
- 0.822
- 0.871
- 0.929
- 0.932
- 0.807
- 0.819
- 0.805
- 0.908
- 0.792
- 0.762
- 0.756
- 0.735
- 0.791
- 0.767
- 0.765
- 0.716
- 0.863
- 0.775
- 0.741
- 0.79
- 0.831
- 0.741
- 0.632
- 0.849
- 0.815
- 0.788
- 0.715
- 0.801
- 0.744
- 0.751
- 0.78
- 0.625
- 0.679
- 0.651
- 0.596
- 0.757
- 0.625
- 0.741
- 0.681
- 0.724
- 0.782
- 0.654
- 0.772
- 0.665
- 0.705
- 0.738
- 0.683
- 0.718
- 0.627
- 0.601
- 0.623
- 0.504
- 0.666
- 0.582
- 0.64
- 0.706
- 0.7
- 0.732
- 0.65
- 0.52
- 0.647
- 0.719
- 0.646
- 0.63
- 0.696
- 0.605
- 0.557
- 0.655
- 0.711
- 0.619
unequal: 0
verbose: 1
