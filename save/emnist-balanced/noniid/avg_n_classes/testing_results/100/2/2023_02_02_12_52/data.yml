avg_train_accuracy: 0.892
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.057765957446808514
- 0.18808510638297873
- 0.2509574468085106
- 0.2924468085106383
- 0.3175
- 0.3201063829787234
- 0.3406382978723404
- 0.354468085106383
- 0.355531914893617
- 0.355531914893617
- 0.3652659574468085
- 0.3652659574468085
- 0.3723404255319149
- 0.378563829787234
- 0.378563829787234
- 0.378563829787234
- 0.3802659574468085
- 0.3802659574468085
- 0.3871276595744681
- 0.3871276595744681
- 0.39101063829787236
- 0.3948936170212766
- 0.3948936170212766
- 0.3984042553191489
- 0.40191489361702126
- 0.4022872340425532
- 0.4023404255319149
- 0.4028191489361702
- 0.4028191489361702
- 0.4046276595744681
- 0.4077127659574468
- 0.4102659574468085
- 0.4102659574468085
- 0.41132978723404257
- 0.41132978723404257
- 0.4120744680851064
- 0.41356382978723405
- 0.41356382978723405
- 0.41436170212765955
- 0.4144148936170213
- 0.4170744680851064
- 0.4176595744680851
- 0.41877659574468085
- 0.41877659574468085
- 0.41973404255319147
- 0.42021276595744683
- 0.42095744680851066
- 0.42095744680851066
- 0.42095744680851066
- 0.4217021276595745
- 0.4217021276595745
- 0.4217021276595745
- 0.4224468085106383
- 0.42351063829787233
- 0.42351063829787233
- 0.42351063829787233
- 0.42446808510638295
- 0.4249468085106383
- 0.4249468085106383
- 0.42579787234042554
- 0.42579787234042554
- 0.42579787234042554
- 0.42579787234042554
- 0.42579787234042554
- 0.42579787234042554
- 0.4270212765957447
- 0.4275531914893617
- 0.4275531914893617
- 0.4277127659574468
- 0.4277127659574468
- 0.42792553191489363
- 0.42856382978723406
- 0.42856382978723406
- 0.42856382978723406
- 0.42856382978723406
- 0.42856382978723406
- 0.42909574468085104
- 0.42909574468085104
- 0.42909574468085104
- 0.42946808510638296
- 0.43042553191489363
- 0.43042553191489363
- 0.43042553191489363
- 0.43138297872340425
- 0.43138297872340425
- 0.43138297872340425
- 0.43138297872340425
- 0.43138297872340425
- 0.43138297872340425
- 0.4315425531914894
- 0.4327127659574468
- 0.4327127659574468
- 0.4327127659574468
- 0.4327127659574468
- 0.4327127659574468
- 0.4327127659574468
- 0.4327127659574468
- 0.4327127659574468
- 0.4330851063829787
- 0.4330851063829787
test_loss_list:
- 574.3908441066742
- 628.743803024292
- 715.9950084686279
- 736.9522728919983
- 704.2271480560303
- 654.4085068702698
- 728.4667315483093
- 827.5601058006287
- 760.5218577384949
- 760.5218577384949
- 769.6152901649475
- 769.6152901649475
- 786.2100248336792
- 887.209228515625
- 887.209228515625
- 887.209228515625
- 719.6173226833344
- 719.6173226833344
- 716.3453562259674
- 716.3453562259674
- 789.831759929657
- 728.8461561203003
- 728.8461561203003
- 811.7131671905518
- 903.4549651145935
- 901.1069722175598
- 807.7790746688843
- 818.9957628250122
- 818.9957628250122
- 803.3729286193848
- 808.1214957237244
- 905.6115927696228
- 905.6115927696228
- 829.1114826202393
- 829.1114826202393
- 811.8514556884766
- 819.1106343269348
- 819.1106343269348
- 816.6739468574524
- 828.8376908302307
- 812.1353664398193
- 839.0933084487915
- 925.5617170333862
- 925.5617170333862
- 823.2671127319336
- 935.7262163162231
- 929.0496773719788
- 929.0496773719788
- 929.0496773719788
- 829.1878199577332
- 829.1878199577332
- 829.1878199577332
- 908.2320079803467
- 824.2820558547974
- 824.2820558547974
- 824.2820558547974
- 838.9239740371704
- 913.1131806373596
- 913.1131806373596
- 927.5615081787109
- 927.5615081787109
- 927.5615081787109
- 927.5615081787109
- 927.5615081787109
- 927.5615081787109
- 828.3023409843445
- 915.4488863945007
- 915.4488863945007
- 921.5302109718323
- 921.5302109718323
- 951.5238671302795
- 839.3080353736877
- 839.3080353736877
- 839.3080353736877
- 839.3080353736877
- 839.3080353736877
- 941.0669460296631
- 941.0669460296631
- 941.0669460296631
- 923.8515944480896
- 935.5056986808777
- 935.5056986808777
- 935.5056986808777
- 950.0351414680481
- 950.0351414680481
- 950.0351414680481
- 950.0351414680481
- 950.0351414680481
- 950.0351414680481
- 815.7307291030884
- 942.8016595840454
- 942.8016595840454
- 942.8016595840454
- 942.8016595840454
- 942.8016595840454
- 942.8016595840454
- 942.8016595840454
- 942.8016595840454
- 847.7530045509338
- 847.7530045509338
train_accuracy:
- 0.0
- 0.413
- 0.55
- 0.627
- 0.663
- 0.0
- 0.708
- 0.748
- 0.706
- 0.0
- 0.771
- 0.719
- 0.0
- 0.804
- 0.0
- 0.0
- 0.756
- 0.0
- 0.754
- 0.808
- 0.0
- 0.0
- 0.0
- 0.802
- 0.785
- 0.837
- 0.846
- 0.0
- 0.0
- 0.846
- 0.862
- 0.85
- 0.0
- 0.798
- 0.862
- 0.0
- 0.867
- 0.81
- 0.0
- 0.84
- 0.842
- 0.871
- 0.835
- 0.85
- 0.831
- 0.877
- 0.844
- 0.0
- 0.89
- 0.852
- 0.825
- 0.0
- 0.875
- 0.871
- 0.875
- 0.858
- 0.875
- 0.875
- 0.883
- 0.9
- 0.842
- 0.871
- 0.0
- 0.904
- 0.848
- 0.881
- 0.894
- 0.0
- 0.883
- 0.0
- 0.89
- 0.873
- 0.0
- 0.877
- 0.913
- 0.9
- 0.9
- 0.892
- 0.0
- 0.869
- 0.896
- 0.892
- 0.89
- 0.869
- 0.892
- 0.0
- 0.858
- 0.896
- 0.0
- 0.888
- 0.898
- 0.881
- 0.877
- 0.848
- 0.915
- 0.904
- 0.0
- 0.898
- 0.0
- 0.892
train_loss:
- 2.213
- 3.262
- 2.696
- 2.309
- 1.697
- 1.261
- 1.587
- 1.75
- 1.388
- 1.073
- 1.362
- 0.995
- 1.223
- 1.411
- 1.162
- 0.839
- 0.955
- 0.928
- 1.008
- 1.083
- 1.057
- 0.933
- 0.854
- 0.973
- 1.169
- 1.153
- 1.007
- 0.973
- 0.814
- 0.963
- 1.032
- 1.077
- 0.937
- 0.917
- 0.767
- 0.88
- 0.85
- 0.835
- 0.873
- 0.959
- 0.943
- 0.844
- 0.939
- 0.948
- 0.849
- 0.929
- 0.937
- 0.722
- 0.69
- 0.836
- 0.839
- 0.679
- 0.9
- 0.836
- 0.767
- 0.794
- 0.79
- 0.88
- 0.774
- 0.852
- 0.795
- 0.715
- 0.771
- 0.717
- 0.755
- 0.739
- 0.831
- 0.72
- 0.827
- 0.738
- 0.789
- 0.755
- 0.74
- 0.689
- 0.72
- 0.78
- 0.785
- 0.727
- 0.617
- 0.782
- 0.775
- 0.726
- 0.787
- 0.764
- 0.734
- 0.747
- 0.767
- 0.779
- 0.693
- 0.706
- 0.76
- 0.734
- 0.74
- 0.746
- 0.668
- 0.738
- 0.677
- 0.75
- 0.663
- 0.648
unequal: 0
verbose: 1
