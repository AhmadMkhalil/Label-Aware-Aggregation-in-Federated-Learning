avg_train_accuracy: 0.965
avg_train_loss: 0.0
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.039521276595744684
- 0.02127659574468085
- 0.02473404255319149
- 0.04015957446808511
- 0.02127659574468085
- 0.044202127659574465
- 0.034414893617021276
- 0.04101063829787234
- 0.04175531914893617
- 0.03914893617021276
- 0.03893617021276596
- 0.05914893617021277
- 0.04186170212765957
- 0.030106382978723405
- 0.057340425531914894
- 0.047553191489361706
- 0.051702127659574465
- 0.06191489361702128
- 0.057925531914893615
- 0.028404255319148936
- 0.027180851063829788
- 0.06154255319148936
- 0.07196808510638297
- 0.2541489361702128
- 0.31393617021276593
- 0.06819148936170213
- 0.07308510638297873
- 0.056489361702127656
- 0.1072340425531915
- 0.08946808510638297
- 0.1375531914893617
- 0.06531914893617022
- 0.15696808510638297
- 0.0676063829787234
- 0.10962765957446809
- 0.1254255319148936
- 0.19
- 0.4099468085106383
- 0.538031914893617
- 0.3570212765957447
- 0.2666489361702128
- 0.4948404255319149
- 0.2425
- 0.07414893617021276
- 0.48186170212765955
- 0.15526595744680852
- 0.22398936170212766
- 0.5370212765957447
- 0.36127659574468085
- 0.31436170212765957
- 0.3131914893617021
- 0.2857446808510638
- 0.3343617021276596
- 0.2897872340425532
- 0.17680851063829786
- 0.4313297872340425
- 0.35186170212765955
- 0.12606382978723404
- 0.324468085106383
- 0.10819148936170213
- 0.5376063829787234
- 0.28829787234042553
- 0.5893085106382979
- 0.4670744680851064
- 0.5757446808510638
- 0.4247872340425532
- 0.16622340425531915
- 0.5998404255319149
- 0.4384574468085106
- 0.44074468085106383
- 0.5928723404255319
- 0.24680851063829787
- 0.15632978723404256
- 0.4181382978723404
- 0.42909574468085104
- 0.3758510638297872
- 0.17367021276595745
- 0.13356382978723405
- 0.32670212765957446
- 0.42829787234042555
- 0.43138297872340425
- 0.6062234042553192
- 0.5930851063829787
- 0.5220212765957447
- 0.44632978723404254
- 0.6352127659574468
- 0.30675531914893617
- 0.14095744680851063
- 0.3570212765957447
- 0.6227127659574468
- 0.6236170212765958
- 0.24452127659574469
- 0.4392553191489362
- 0.6142553191489362
- 0.3706382978723404
- 0.43207446808510636
- 0.5057978723404255
- 0.2781382978723404
- 0.4430851063829787
- 0.21159574468085107
test_loss_list:
- 5.435198008219401
- 3.9009228420257567
- 6.643776206970215
- 10.122094866434733
- 3.850231895446777
- 4.700504239400228
- 7.82686752319336
- 5.315260976155599
- 7.311656964619955
- 5.604410508473714
- 5.955325756072998
- 7.609792435963948
- 6.453842964172363
- 4.908512573242188
- 10.902359301249186
- 4.9797748311360674
- 5.49700023651123
- 6.964593346913656
- 10.166172561645508
- 12.505480066935222
- 4.720960852305095
- 4.634596061706543
- 3.782738478978475
- 2.7849369939168294
- 2.5424166170756024
- 5.9056449953715004
- 5.171293125152588
- 7.972472070058187
- 4.025674301783244
- 5.429316609700521
- 3.438245929082235
- 7.221141242980957
- 3.0190999507904053
- 6.874368623097737
- 3.7011341571807863
- 4.270440769195557
- 2.9127519035339358
- 2.116983970006307
- 2.036232271194458
- 2.45631814956665
- 2.9240350500742593
- 1.8950218280156454
- 2.6635303910573325
- 5.811173063913981
- 1.9258009815216064
- 3.7436641216278077
- 3.1950593980153403
- 1.7189538606007895
- 2.4184912045796714
- 2.4225049527486164
- 2.6627838134765627
- 2.447321351369222
- 2.466420628229777
- 2.587350794474284
- 3.6812608146667483
- 2.0234315808614096
- 2.442668628692627
- 5.417443059285482
- 2.4530374908447268
- 5.420672130584717
- 1.5700605376561483
- 3.136559934616089
- 1.530213615099589
- 1.936418766975403
- 1.6170667171478272
- 1.9661210505167643
- 4.385175463358562
- 1.4471276807785034
- 1.8325729052225748
- 2.0111353238423666
- 1.4153043921788533
- 3.7851128896077473
- 4.970798403422037
- 2.1368969249725343
- 1.9988199615478515
- 2.288928074836731
- 4.197572733561198
- 5.357754834493002
- 2.451217257181803
- 2.074763065973918
- 1.9795965544382732
- 1.3511269728342692
- 1.429433879852295
- 1.646418670018514
- 2.011365917523702
- 1.3522944498062133
- 2.855740718841553
- 5.554427382151286
- 2.278856503168742
- 1.3450973018010457
- 1.3501561657587686
- 3.4436347103118896
- 1.8989805046717325
- 1.3455778360366821
- 2.233287251790365
- 2.019326583544413
- 1.6631893905003865
- 3.4511813163757323
- 2.135612848599752
- 4.334139308929443
train_accuracy:
- 0.0
- 0.0
- 0.01
- 0.994
- 1.0
- 0.994
- 0.0
- 0.0
- 1.0
- 0.0
- 0.975
- 0.794
- 0.988
- 0.992
- 0.779
- 0.973
- 0.629
- 0.985
- 0.896
- 0.304
- 0.998
- 0.944
- 0.056
- 0.994
- 0.344
- 0.944
- 0.942
- 0.99
- 0.067
- 0.048
- 0.119
- 0.956
- 0.513
- 1.0
- 0.956
- 0.99
- 0.99
- 0.425
- 0.625
- 0.327
- 0.215
- 0.956
- 0.954
- 0.998
- 0.969
- 0.94
- 0.2
- 0.787
- 0.425
- 0.983
- 0.917
- 0.965
- 0.99
- 0.952
- 0.981
- 0.977
- 0.333
- 0.979
- 0.985
- 0.985
- 0.575
- 0.99
- 0.683
- 0.981
- 0.675
- 0.983
- 0.938
- 0.783
- 0.402
- 0.985
- 0.656
- 0.994
- 0.981
- 1.0
- 0.988
- 0.971
- 0.998
- 0.973
- 0.973
- 0.429
- 0.992
- 0.965
- 0.95
- 0.946
- 0.444
- 0.713
- 0.96
- 0.983
- 0.337
- 0.983
- 0.935
- 0.946
- 0.979
- 0.675
- 0.965
- 0.988
- 0.471
- 0.985
- 0.402
- 0.965
train_loss:
- 1.551
- 2.595
- 0.222
- 0.119
- 2.661
- 1.377
- 0.147
- 1.317
- 0.118
- 1.301
- 1.172
- 0.082
- 1.186
- 1.16
- 0.06
- 1.142
- 1.038
- 0.099
- 0.058
- 0.042
- 1.173
- 0.995
- 1.0
- 1.794
- 1.692
- 0.121
- 0.861
- 0.055
- 0.916
- 0.812
- 0.827
- 0.073
- 0.891
- 0.06
- 0.861
- 0.782
- 0.829
- 1.448
- 2.051
- 0.728
- 0.717
- 1.338
- 0.729
- 0.067
- 1.384
- 0.105
- 0.675
- 1.267
- 0.668
- 0.674
- 0.634
- 0.663
- 0.645
- 0.633
- 0.618
- 0.629
- 0.607
- 0.092
- 0.639
- 0.044
- 1.214
- 0.053
- 1.159
- 0.598
- 1.121
- 0.611
- 0.056
- 1.148
- 0.608
- 0.577
- 1.09
- 0.061
- 0.048
- 0.598
- 0.58
- 0.575
- 0.049
- 0.048
- 0.57
- 0.557
- 0.539
- 1.039
- 1.011
- 0.55
- 0.533
- 1.013
- 0.061
- 0.073
- 0.568
- 1.021
- 0.987
- 0.062
- 0.552
- 1.0
- 0.081
- 0.523
- 0.508
- 0.048
- 0.51
- 0.035
unequal: 0
verbose: 1
