avg_train_accuracy: 0.996
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.023404255319148935
- 0.02127659574468085
- 0.034840425531914895
- 0.033191489361702124
- 0.03180851063829787
- 0.021382978723404257
- 0.03702127659574468
- 0.034414893617021276
- 0.038085106382978726
- 0.032446808510638296
- 0.05712765957446809
- 0.04367021276595745
- 0.04372340425531915
- 0.03845744680851064
- 0.07159574468085106
- 0.04622340425531915
- 0.05941489361702128
- 0.024361702127659573
- 0.05414893617021277
- 0.05978723404255319
- 0.04803191489361702
- 0.0598404255319149
- 0.26611702127659576
- 0.25803191489361704
- 0.20053191489361702
- 0.0601063829787234
- 0.08622340425531914
- 0.1225531914893617
- 0.06696808510638298
- 0.11287234042553192
- 0.3974468085106383
- 0.32015957446808513
- 0.3997872340425532
- 0.06473404255319148
- 0.0801063829787234
- 0.19276595744680852
- 0.17372340425531915
- 0.08191489361702127
- 0.07271276595744681
- 0.17925531914893617
- 0.2023404255319149
- 0.4681382978723404
- 0.29808510638297875
- 0.5089361702127659
- 0.2501595744680851
- 0.07425531914893617
- 0.08585106382978723
- 0.09345744680851063
- 0.16164893617021275
- 0.4873936170212766
- 0.49042553191489363
- 0.5027127659574468
- 0.5745212765957447
- 0.5104255319148936
- 0.08702127659574468
- 0.21122340425531916
- 0.3704787234042553
- 0.3193617021276596
- 0.40324468085106385
- 0.3511170212765957
- 0.5334574468085106
- 0.40808510638297874
- 0.31627659574468087
- 0.1250531914893617
- 0.2684042553191489
- 0.3475
- 0.4588829787234043
- 0.2752127659574468
- 0.12723404255319148
- 0.5667553191489362
- 0.3758510638297872
- 0.3278723404255319
- 0.34143617021276595
- 0.39159574468085107
- 0.14170212765957446
- 0.15148936170212765
- 0.421968085106383
- 0.45218085106382977
- 0.40632978723404256
- 0.44941489361702125
- 0.3924468085106383
- 0.4473936170212766
- 0.42079787234042554
- 0.6099468085106383
- 0.49840425531914895
- 0.47138297872340423
- 0.41047872340425534
- 0.40622340425531916
- 0.6165957446808511
- 0.1545212765957447
- 0.4029255319148936
- 0.6185106382978723
- 0.5079255319148936
- 0.475
- 0.47393617021276596
- 0.12313829787234043
- 0.3671276595744681
- 0.24664893617021277
- 0.49138297872340425
test_loss_list:
- 7.945919551849365
- 3.8251281611124672
- 11.769575983683268
- 4.648791135152181
- 9.080568771362305
- 3.667328503926595
- 10.099428838094076
- 11.191441663106282
- 7.904359207153321
- 6.498443393707276
- 6.035201975504557
- 5.42484401067098
- 4.9647196133931475
- 4.846577612559001
- 4.952172368367513
- 4.129112583796183
- 5.0179876009623205
- 8.390059223175049
- 9.570359586079915
- 4.81049654006958
- 8.026561444600423
- 5.149609495798747
- 4.639926986694336
- 2.6426940123240152
- 2.6601432450612386
- 2.95948104540507
- 7.283895708719889
- 3.916905345916748
- 3.676324847539266
- 7.139863713582357
- 4.518906828562419
- 2.3266371472676597
- 2.466433957417806
- 2.2774323399861656
- 8.83176633834839
- 5.040021622975667
- 3.045541728337606
- 3.2795328871409097
- 7.318347778320312
- 11.443552131652831
- 3.538269348144531
- 2.9864637565612795
- 1.9006811173756917
- 2.4929527314503988
- 1.7640869442621867
- 3.2840609550476074
- 7.907478586832682
- 6.298787924448649
- 5.408029174804687
- 3.7007351970672606
- 1.8655471897125244
- 1.7625644461313883
- 1.800625998179118
- 1.9336300388971965
- 1.860158117612203
- 6.6850184694925945
- 3.5461138343811034
- 2.520976177851359
- 2.5970465914408365
- 2.1477281427383423
- 2.489135357538859
- 1.549249947865804
- 2.1602201716105145
- 2.5315957673390708
- 5.483665396372477
- 2.898292630513509
- 2.583689603805542
- 1.7997700516382853
- 2.6574339485168457
- 5.702024402618409
- 1.459292327562968
- 2.1291321404774983
- 2.3220170879364015
- 2.4625241279602053
- 2.2441623767217
- 5.828822727203369
- 5.047774937947591
- 2.2342308870951335
- 1.9851692247390746
- 2.062885988553365
- 2.102084584236145
- 2.138607652982076
- 1.9010876766840616
- 2.1389547952016197
- 1.2995297447840373
- 1.8755031728744507
- 2.0334948666890464
- 2.283216886520386
- 2.2896824264526368
- 1.2762495724360148
- 5.4239400863647464
- 2.4477658081054687
- 1.3570887962977092
- 1.6633088080088299
- 1.8862462838490803
- 1.915818502108256
- 5.835976467132569
- 2.484443785349528
- 3.8531653372446697
- 1.8830052630106608
train_accuracy:
- 1.0
- 0.004
- 0.0
- 1.0
- 0.619
- 0.017
- 0.0
- 1.0
- 0.0
- 0.904
- 0.0
- 0.929
- 0.85
- 0.96
- 0.983
- 0.019
- 0.64
- 0.958
- 0.065
- 0.992
- 0.917
- 0.006
- 0.804
- 0.267
- 0.275
- 0.948
- 0.881
- 0.785
- 0.958
- 0.952
- 0.217
- 0.942
- 0.34
- 0.419
- 0.965
- 0.077
- 0.923
- 0.965
- 0.988
- 0.944
- 0.863
- 0.933
- 0.498
- 0.99
- 0.558
- 0.223
- 0.925
- 0.746
- 0.998
- 0.938
- 0.523
- 0.946
- 0.569
- 0.673
- 0.983
- 0.79
- 0.988
- 0.365
- 0.979
- 0.971
- 0.965
- 0.558
- 0.992
- 0.983
- 0.925
- 0.975
- 0.985
- 0.994
- 0.946
- 0.988
- 0.617
- 0.342
- 0.996
- 0.983
- 0.319
- 0.985
- 0.446
- 0.992
- 0.996
- 0.971
- 0.419
- 0.967
- 0.998
- 0.971
- 0.696
- 0.985
- 0.981
- 0.362
- 0.985
- 0.698
- 0.981
- 0.994
- 0.698
- 0.527
- 0.479
- 0.458
- 0.994
- 0.948
- 0.988
- 0.996
train_loss:
- 0.325
- 2.662
- 0.172
- 1.389
- 0.141
- 2.63
- 0.115
- 0.072
- 0.162
- 1.277
- 1.203
- 0.166
- 1.198
- 1.169
- 1.122
- 1.089
- 1.042
- 0.092
- 0.142
- 1.086
- 0.056
- 1.025
- 1.0
- 1.895
- 1.786
- 1.72
- 0.128
- 0.909
- 0.89
- 0.105
- 0.872
- 1.63
- 1.585
- 1.508
- 0.076
- 0.139
- 0.805
- 0.778
- 0.053
- 0.02
- 0.794
- 0.758
- 1.439
- 0.747
- 1.387
- 0.676
- 0.058
- 0.103
- 0.095
- 0.728
- 1.356
- 1.318
- 1.261
- 1.848
- 1.226
- 0.117
- 0.682
- 0.668
- 0.61
- 0.613
- 0.634
- 1.227
- 0.611
- 0.587
- 0.048
- 0.617
- 0.608
- 0.605
- 0.608
- 0.041
- 1.177
- 0.601
- 0.578
- 0.584
- 0.579
- 0.036
- 0.053
- 0.579
- 0.556
- 0.564
- 0.543
- 0.548
- 0.532
- 0.545
- 1.04
- 0.554
- 0.528
- 0.532
- 0.502
- 1.023
- 0.052
- 0.539
- 0.984
- 0.507
- 0.494
- 0.498
- 0.049
- 0.52
- 0.046
- 0.516
unequal: 0
verbose: 1
