avg_train_accuracy: 0.96
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.0323936170212766
- 0.02127659574468085
- 0.02127659574468085
- 0.03558510638297872
- 0.05031914893617021
- 0.034574468085106384
- 0.039414893617021274
- 0.04632978723404255
- 0.03595744680851064
- 0.04973404255319149
- 0.1778191489361702
- 0.03888297872340426
- 0.05702127659574468
- 0.28175531914893615
- 0.1478723404255319
- 0.08797872340425532
- 0.16452127659574467
- 0.08542553191489362
- 0.10425531914893617
- 0.0798404255319149
- 0.21824468085106383
- 0.10845744680851063
- 0.12531914893617022
- 0.2579255319148936
- 0.11393617021276596
- 0.1175531914893617
- 0.1396808510638298
- 0.09361702127659574
- 0.21436170212765956
- 0.20425531914893616
- 0.12824468085106383
- 0.11611702127659575
- 0.46675531914893614
- 0.2754255319148936
- 0.25622340425531914
- 0.2950531914893617
- 0.24632978723404256
- 0.308936170212766
- 0.14813829787234042
- 0.12441489361702128
- 0.3072872340425532
- 0.21563829787234043
- 0.15595744680851065
- 0.15771276595744682
- 0.40154255319148935
- 0.33872340425531916
- 0.5328723404255319
- 0.15058510638297873
- 0.3726595744680851
- 0.3063297872340425
- 0.5622872340425532
- 0.39409574468085107
- 0.32585106382978724
- 0.42888297872340425
- 0.20287234042553193
- 0.5543085106382979
- 0.16175531914893618
- 0.25361702127659574
- 0.23968085106382978
- 0.43175531914893617
- 0.23957446808510638
- 0.4943085106382979
- 0.25446808510638297
- 0.30659574468085105
- 0.4753191489361702
- 0.26468085106382977
- 0.2277659574468085
- 0.44324468085106383
- 0.4750531914893617
- 0.4725
- 0.5757978723404256
- 0.604468085106383
- 0.27627659574468083
- 0.22170212765957448
- 0.24606382978723404
- 0.48069148936170214
- 0.4922872340425532
- 0.22925531914893618
- 0.23957446808510638
- 0.3558510638297872
- 0.2651063829787234
- 0.5348404255319149
- 0.3171276595744681
- 0.3439893617021277
- 0.3347872340425532
- 0.2846808510638298
- 0.19122340425531914
- 0.6389893617021276
- 0.6256382978723404
- 0.6257978723404255
- 0.32845744680851063
- 0.4775
- 0.6439893617021276
- 0.31361702127659574
- 0.28914893617021276
- 0.18329787234042552
- 0.5062765957446809
- 0.3574468085106383
- 0.5553191489361702
test_loss_list:
- 5.4156612714131676
- 4.3322434234619145
- 4.313953037261963
- 5.10181697845459
- 6.340806967417399
- 5.859647127787272
- 4.295056355794271
- 4.12119140625
- 4.7352996190389
- 5.339544951121012
- 4.000085843404134
- 3.033218886057536
- 5.998931706746419
- 4.649574782053629
- 2.7205937321980795
- 3.2998892402648927
- 4.847054538726806
- 3.0548447068532307
- 4.8762351989746096
- 4.379709561665853
- 6.586227569580078
- 2.7591769536336264
- 4.856026496887207
- 4.168422082265218
- 2.5562223847707113
- 4.2893959935506185
- 4.226625661849976
- 3.8061900424957273
- 7.66901575088501
- 2.698800910313924
- 2.9894636408487956
- 5.355851771036784
- 4.275831858317058
- 2.049644258817037
- 2.5799383799235027
- 2.7140232435862224
- 2.4562119992574054
- 2.8680675156911213
- 2.5181864802042644
- 3.8266032950083413
- 6.505178114573161
- 2.4891000684102376
- 2.9583542760213217
- 3.9845647525787355
- 3.9325984446207682
- 2.0814119148254395
- 2.4185546429951987
- 1.6802594661712646
- 4.067351045608521
- 2.032498002052307
- 2.3275052388509114
- 1.6232007153828938
- 2.231653037071228
- 2.2752355353037514
- 1.9230942598978678
- 4.023736832936605
- 1.5729215621948243
- 3.9851687367757163
- 2.9761977513631184
- 3.3417268657684325
- 1.9516880210240681
- 3.1652538267771404
- 1.7695869986216228
- 3.4449564901987713
- 3.0372087446848552
- 1.7414380232493083
- 3.02774876276652
- 3.485239833196004
- 1.8277208741505941
- 1.8227645746866863
- 1.8539619731903076
- 1.4714102252324421
- 1.3748741849263508
- 2.9442842547098795
- 3.4757817554473878
- 3.421778039932251
- 1.704398792584737
- 1.6716770553588867
- 3.410638017654419
- 3.270025094350179
- 2.4328874588012694
- 3.152623039881388
- 1.5787163591384887
- 3.0104528586069743
- 2.6926797008514405
- 2.7751371669769287
- 2.973288408915202
- 5.075910002390543
- 1.2220748408635458
- 1.239122200012207
- 1.2767612886428834
- 2.520892848968506
- 1.6777848482131958
- 1.2384369214375814
- 2.61680482228597
- 2.9137364546457927
- 4.5844807624816895
- 1.6604576524098713
- 2.629235906600952
- 1.4704741303126017
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.0
- 0.99
- 0.783
- 0.602
- 0.723
- 0.825
- 0.0
- 0.769
- 0.154
- 0.1
- 0.983
- 0.283
- 0.481
- 0.019
- 0.1
- 0.96
- 0.531
- 0.892
- 0.965
- 0.971
- 0.725
- 0.681
- 0.929
- 0.825
- 0.798
- 0.246
- 0.056
- 0.977
- 0.894
- 0.763
- 0.569
- 0.254
- 0.235
- 0.265
- 0.963
- 0.871
- 0.898
- 0.9
- 0.985
- 0.954
- 0.973
- 0.969
- 0.983
- 0.946
- 0.692
- 0.973
- 0.331
- 0.908
- 0.863
- 0.988
- 0.854
- 0.4
- 0.983
- 0.588
- 0.967
- 0.887
- 0.975
- 0.431
- 0.985
- 0.979
- 0.963
- 0.246
- 0.856
- 0.985
- 0.877
- 0.869
- 0.471
- 0.915
- 0.64
- 0.658
- 0.96
- 0.125
- 0.965
- 0.504
- 0.45
- 0.975
- 0.938
- 0.271
- 0.927
- 0.975
- 0.979
- 0.99
- 0.96
- 0.902
- 0.612
- 0.665
- 0.66
- 0.89
- 0.935
- 0.927
- 0.694
- 0.983
- 0.212
- 0.975
- 0.981
- 0.279
- 0.96
train_loss:
- 0.362
- 1.596
- 1.583
- 0.814
- 0.101
- 0.79
- 1.47
- 1.405
- 0.698
- 0.696
- 1.305
- 1.828
- 0.624
- 0.62
- 1.68
- 1.111
- 0.553
- 1.064
- 0.563
- 0.558
- 0.052
- 1.04
- 0.513
- 0.529
- 0.995
- 0.51
- 0.5
- 0.503
- 0.033
- 0.993
- 0.922
- 0.056
- 0.502
- 1.352
- 0.903
- 0.883
- 0.885
- 0.872
- 0.848
- 0.451
- 0.042
- 0.876
- 0.441
- 0.431
- 0.435
- 0.817
- 0.799
- 1.171
- 0.427
- 0.806
- 0.779
- 1.132
- 0.765
- 0.764
- 0.758
- 0.384
- 1.113
- 0.399
- 0.404
- 0.384
- 0.729
- 0.389
- 0.721
- 0.364
- 0.38
- 0.708
- 0.372
- 0.369
- 0.714
- 0.682
- 0.679
- 1.012
- 0.996
- 0.365
- 0.359
- 0.353
- 0.672
- 0.659
- 0.351
- 0.339
- 0.352
- 0.341
- 0.645
- 0.332
- 0.347
- 0.335
- 0.338
- 0.031
- 0.972
- 0.934
- 0.909
- 0.349
- 0.624
- 0.899
- 0.337
- 0.329
- 0.033
- 0.628
- 0.322
- 0.6
unequal: 0
verbose: 1
