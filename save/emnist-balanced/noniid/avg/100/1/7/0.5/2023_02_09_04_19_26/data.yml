avg_train_accuracy: 0.983
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.021329787234042552
- 0.03265957446808511
- 0.03595744680851064
- 0.04973404255319149
- 0.058031914893617025
- 0.058031914893617025
- 0.05925531914893617
- 0.06148936170212766
- 0.08824468085106384
- 0.07292553191489362
- 0.07845744680851063
- 0.14175531914893616
- 0.07191489361702127
- 0.07632978723404256
- 0.21218085106382978
- 0.3561170212765957
- 0.08680851063829788
- 0.08867021276595745
- 0.22377659574468084
- 0.22856382978723405
- 0.30696808510638296
- 0.09313829787234043
- 0.3345744680851064
- 0.10622340425531915
- 0.45335106382978724
- 0.2797872340425532
- 0.13239361702127658
- 0.3800531914893617
- 0.29845744680851066
- 0.36361702127659573
- 0.10537234042553191
- 0.2842021276595745
- 0.4039893617021277
- 0.17648936170212767
- 0.16042553191489362
- 0.13074468085106383
- 0.40925531914893615
- 0.15856382978723405
- 0.4251063829787234
- 0.39595744680851064
- 0.3976595744680851
- 0.335
- 0.5393085106382979
- 0.23829787234042554
- 0.4280851063829787
- 0.26835106382978724
- 0.20154255319148937
- 0.2928723404255319
- 0.5563297872340426
- 0.4273936170212766
- 0.5799468085106383
- 0.26845744680851064
- 0.13414893617021276
- 0.15095744680851064
- 0.2098404255319149
- 0.32909574468085107
- 0.3124468085106383
- 0.5006914893617022
- 0.3079787234042553
- 0.5350531914893617
- 0.48723404255319147
- 0.25324468085106383
- 0.45382978723404255
- 0.49425531914893617
- 0.5027659574468085
- 0.23031914893617023
- 0.29356382978723405
- 0.2979787234042553
- 0.5654787234042553
- 0.5334042553191489
- 0.6167553191489362
- 0.44196808510638297
- 0.5129255319148937
- 0.5281914893617021
- 0.3603723404255319
- 0.6258510638297873
- 0.5860106382978724
- 0.48579787234042554
- 0.6483510638297872
- 0.46180851063829786
- 0.4622872340425532
- 0.32101063829787235
- 0.37882978723404254
- 0.5456914893617021
- 0.5445212765957447
- 0.23882978723404255
- 0.3071276595744681
- 0.5712765957446808
- 0.3464893617021277
- 0.5732978723404255
- 0.33441489361702126
- 0.5927659574468085
- 0.22446808510638297
- 0.5445744680851063
- 0.5821808510638298
- 0.36648936170212765
- 0.5498404255319149
- 0.37930851063829785
- 0.5735638297872341
test_loss_list:
- 4.078128560384115
- 5.8018712870279945
- 4.425803826649983
- 4.226892948150635
- 4.519019190470377
- 5.842975114186605
- 6.046772658030192
- 4.0835321935017905
- 5.380464286804199
- 3.540100425084432
- 5.066789468129476
- 7.436812133789062
- 3.272506608963013
- 6.736738637288411
- 4.9621714464823405
- 2.738368721008301
- 2.3834023157755535
- 5.220031757354736
- 7.369823811848958
- 2.771665751139323
- 2.7658150164286295
- 2.4589681243896484
- 5.384657103220622
- 2.271422904332479
- 4.587705307006836
- 2.0211111005147298
- 2.436191142400106
- 4.270588782628377
- 2.11020601272583
- 2.557229471206665
- 2.163222557703654
- 7.838583812713623
- 2.4660068130493165
- 2.072566172281901
- 3.7350954882303875
- 4.262171853383382
- 5.702292003631592
- 2.0604922421773275
- 4.16154795328776
- 1.8895591640472411
- 2.0113691155115765
- 2.078599982261658
- 2.2244353834788004
- 1.6116056044896443
- 3.4626094659169513
- 1.9138434076309203
- 3.0243188540140786
- 3.730582507451375
- 2.800138584772746
- 1.5111889775594076
- 2.024307826360067
- 1.4823632669448852
- 3.009135907491048
- 6.390340919494629
- 4.6058159319559735
- 3.962448787689209
- 2.453182751337687
- 2.818098357518514
- 1.7288805596033732
- 3.0165834204355875
- 1.5384415165583292
- 1.7435044606526693
- 3.223405803044637
- 1.7748626168568928
- 1.6313720814387003
- 1.6725658400853476
- 3.6596152941385904
- 2.8159960746765136
- 2.9104820601145427
- 1.4842213773727417
- 1.537784145673116
- 1.3024379634857177
- 1.949170053799947
- 1.694418706893921
- 1.6276449505488078
- 2.616746644973755
- 1.2908456389109293
- 1.3395280694961549
- 1.70837743918101
- 1.2287996403376262
- 1.7165954065322877
- 1.7980619700749716
- 2.7559361394246418
- 2.4352782917022706
- 1.5037225484848022
- 1.5273909346262613
- 4.1852972730000815
- 2.874687608083089
- 1.4592303037643433
- 2.516351979573568
- 1.4028720251719158
- 2.5633530871073407
- 1.318889497121175
- 4.103503271738688
- 1.4233786487579345
- 1.4298976866404216
- 2.546110159556071
- 1.3957825628916423
- 2.4326935036977133
- 1.3209998734792074
train_accuracy:
- 1.0
- 0.0
- 0.994
- 0.577
- 0.825
- 0.0
- 0.008
- 0.977
- 0.588
- 0.927
- 0.952
- 0.933
- 0.944
- 0.873
- 0.829
- 0.865
- 0.388
- 0.9
- 0.948
- 0.969
- 0.173
- 0.94
- 0.604
- 0.321
- 0.908
- 0.523
- 0.942
- 0.879
- 0.975
- 0.25
- 0.967
- 0.742
- 0.946
- 0.85
- 0.058
- 0.958
- 0.967
- 0.9
- 0.921
- 0.844
- 0.942
- 0.983
- 0.288
- 0.94
- 0.983
- 0.931
- 0.973
- 0.948
- 0.919
- 0.596
- 0.981
- 0.592
- 0.131
- 0.881
- 0.073
- 0.51
- 0.204
- 0.981
- 0.49
- 0.919
- 0.525
- 0.919
- 0.875
- 0.881
- 0.965
- 0.892
- 0.927
- 0.933
- 0.981
- 0.879
- 0.498
- 0.565
- 0.985
- 0.979
- 0.94
- 0.979
- 0.706
- 0.65
- 0.446
- 0.715
- 0.892
- 0.979
- 0.965
- 0.988
- 0.513
- 0.948
- 0.935
- 0.979
- 0.985
- 0.994
- 0.992
- 0.973
- 0.54
- 0.942
- 0.967
- 0.983
- 0.931
- 0.963
- 0.965
- 0.983
train_loss:
- 1.82
- 0.868
- 1.59
- 1.558
- 1.491
- 0.743
- 0.716
- 1.356
- 0.655
- 1.263
- 0.622
- 0.049
- 1.193
- 0.066
- 0.597
- 1.122
- 1.56
- 0.533
- 0.048
- 1.025
- 0.973
- 0.956
- 0.503
- 0.944
- 0.48
- 1.352
- 0.88
- 0.474
- 0.883
- 0.849
- 0.842
- 0.046
- 0.868
- 0.832
- 0.431
- 0.429
- 0.031
- 0.813
- 0.427
- 0.8
- 0.778
- 0.766
- 0.764
- 1.117
- 0.405
- 0.764
- 0.39
- 0.386
- 0.385
- 1.074
- 0.719
- 1.058
- 0.397
- 0.028
- 0.385
- 0.044
- 0.383
- 0.361
- 0.693
- 0.361
- 0.695
- 0.68
- 0.364
- 0.681
- 0.668
- 0.673
- 0.344
- 0.357
- 0.356
- 0.672
- 0.649
- 0.952
- 0.647
- 0.656
- 0.634
- 0.331
- 0.944
- 0.924
- 0.624
- 0.916
- 0.617
- 0.604
- 0.329
- 0.315
- 0.614
- 0.596
- 0.031
- 0.329
- 0.602
- 0.314
- 0.605
- 0.312
- 0.593
- 0.034
- 0.603
- 0.592
- 0.309
- 0.585
- 0.303
- 0.591
unequal: 0
verbose: 1
