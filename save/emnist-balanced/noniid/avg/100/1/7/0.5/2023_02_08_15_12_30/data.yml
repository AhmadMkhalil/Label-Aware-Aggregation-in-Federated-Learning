avg_train_accuracy: 0.983
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022234042553191488
- 0.03851063829787234
- 0.021329787234042552
- 0.03723404255319149
- 0.038829787234042554
- 0.03803191489361702
- 0.03627659574468085
- 0.0772872340425532
- 0.10861702127659574
- 0.16585106382978723
- 0.05702127659574468
- 0.1675531914893617
- 0.08356382978723405
- 0.08170212765957446
- 0.12388297872340426
- 0.07664893617021276
- 0.22319148936170213
- 0.10861702127659574
- 0.26718085106382977
- 0.17702127659574468
- 0.28308510638297874
- 0.24393617021276595
- 0.09074468085106382
- 0.32563829787234044
- 0.4520744680851064
- 0.160531914893617
- 0.20851063829787234
- 0.30994680851063827
- 0.12558510638297873
- 0.12781914893617022
- 0.3784574468085106
- 0.44861702127659575
- 0.12829787234042553
- 0.18319148936170213
- 0.3485106382978723
- 0.11861702127659575
- 0.13542553191489362
- 0.21164893617021277
- 0.1174468085106383
- 0.41340425531914893
- 0.35335106382978726
- 0.5278191489361702
- 0.31574468085106383
- 0.1651063829787234
- 0.0972872340425532
- 0.4455851063829787
- 0.2048936170212766
- 0.44563829787234044
- 0.5597340425531915
- 0.3421276595744681
- 0.41898936170212764
- 0.23824468085106382
- 0.115
- 0.470531914893617
- 0.5056914893617022
- 0.22484042553191488
- 0.24122340425531916
- 0.5069148936170212
- 0.40202127659574466
- 0.2577659574468085
- 0.48143617021276597
- 0.4746808510638298
- 0.24670212765957447
- 0.33106382978723403
- 0.5882446808510639
- 0.5660106382978723
- 0.28952127659574467
- 0.4721808510638298
- 0.29781914893617023
- 0.3431382978723404
- 0.295531914893617
- 0.6134042553191489
- 0.5083510638297872
- 0.5104255319148936
- 0.3050531914893617
- 0.5032978723404256
- 0.3471808510638298
- 0.5348404255319149
- 0.6175531914893617
- 0.27808510638297873
- 0.27622340425531916
- 0.3422340425531915
- 0.5492021276595744
- 0.5145212765957446
- 0.3551063829787234
- 0.5292021276595744
- 0.39797872340425533
- 0.3568085106382979
- 0.3824468085106383
- 0.3423936170212766
- 0.5186170212765957
- 0.5386170212765957
- 0.5470212765957447
- 0.21414893617021277
- 0.30542553191489363
- 0.5666489361702127
- 0.5348404255319149
- 0.6193085106382978
- 0.39393617021276595
- 0.5477659574468086
test_loss_list:
- 4.0999554316202795
- 4.652743670145671
- 6.10893949508667
- 4.544507319132487
- 3.6794919268290203
- 4.006731077829997
- 4.424454040527344
- 3.7893441931406655
- 3.4546928437550863
- 3.2099880981445312
- 6.398808587392171
- 3.1343362681070963
- 4.093306058247884
- 4.693448505401611
- 3.8446473503112792
- 7.927069772084554
- 2.884487082163493
- 4.511333980560303
- 2.6301852385203044
- 3.1261075210571287
- 2.5902074209849038
- 2.8651133251190184
- 5.667468140920003
- 2.3665223439534504
- 2.005914158821106
- 3.5085989538828533
- 3.201213575998942
- 2.465710048675537
- 4.7268804295857745
- 4.5153460121154785
- 2.1398812119166055
- 1.9379241641362508
- 5.491749661763509
- 3.9948009999593097
- 2.293814096450806
- 7.12782611211141
- 4.688351891835531
- 3.2966524887084963
- 6.129565461476644
- 2.0217288573582968
- 2.3447848892211915
- 1.6604900042215982
- 2.5373371187845866
- 4.299645067850749
- 6.701255772908529
- 1.8226515293121337
- 3.6192504183451333
- 1.8108592732747395
- 1.535193181037903
- 2.498897199630737
- 1.9693051433563233
- 3.5988879648844403
- 7.078988361358642
- 1.7679351313908895
- 1.727182715733846
- 3.6413091977437335
- 3.702779836654663
- 1.6339313952128092
- 2.093499665260315
- 3.2930828507741294
- 1.8026762024561565
- 1.8557675679524739
- 3.5734074624379475
- 2.727972764968872
- 1.374475703239441
- 1.4712986373901367
- 3.0825180212656655
- 1.737440408070882
- 3.002470769882202
- 2.847799523671468
- 3.125235891342163
- 1.2935617542266846
- 1.6723714367548626
- 1.63137482325236
- 2.9252451864878335
- 1.7081775458653767
- 2.813707758585612
- 1.5219212992986044
- 1.2569389311472574
- 3.0677332337697347
- 3.452310498555501
- 2.996789442698161
- 1.4595043277740478
- 1.6471348031361899
- 2.383140459060669
- 1.5508786296844483
- 2.3643130970001223
- 2.7259893480936688
- 2.514628760019938
- 2.995478493372599
- 1.625805114110311
- 1.5531704378128053
- 1.4996470832824706
- 4.566425355275472
- 3.0905989742279054
- 1.4880639473597208
- 1.5351167758305868
- 1.2143799082438151
- 2.542831999460856
- 1.5579783407847088
train_accuracy:
- 0.996
- 0.99
- 1.0
- 0.017
- 0.0
- 0.327
- 0.0
- 0.033
- 0.912
- 0.977
- 0.104
- 0.135
- 0.39
- 0.81
- 0.917
- 0.963
- 0.163
- 0.875
- 0.769
- 0.952
- 0.812
- 0.192
- 0.944
- 0.973
- 0.527
- 0.885
- 0.975
- 0.246
- 0.04
- 0.042
- 0.369
- 0.473
- 0.921
- 0.91
- 0.969
- 0.938
- 0.985
- 0.16
- 0.95
- 0.433
- 0.896
- 0.606
- 0.948
- 0.96
- 0.812
- 0.594
- 0.142
- 0.908
- 0.575
- 0.967
- 0.883
- 0.144
- 0.981
- 0.848
- 0.973
- 0.921
- 0.956
- 0.825
- 0.963
- 0.848
- 0.49
- 0.95
- 0.142
- 0.975
- 0.373
- 0.977
- 0.929
- 0.456
- 0.975
- 0.973
- 0.225
- 0.621
- 0.427
- 0.931
- 0.973
- 0.985
- 0.271
- 0.992
- 0.625
- 0.965
- 0.985
- 0.971
- 0.912
- 0.967
- 0.96
- 0.958
- 0.34
- 0.96
- 0.975
- 0.973
- 0.983
- 0.921
- 0.983
- 0.969
- 0.952
- 0.542
- 0.527
- 0.667
- 0.969
- 0.983
train_loss:
- 1.815
- 1.59
- 0.841
- 1.565
- 2.207
- 1.42
- 1.323
- 1.265
- 1.236
- 1.706
- 0.589
- 1.104
- 0.574
- 0.554
- 0.575
- 0.053
- 1.043
- 0.523
- 1.001
- 0.95
- 0.941
- 0.925
- 0.485
- 0.934
- 1.306
- 0.879
- 0.459
- 0.854
- 0.442
- 0.444
- 0.837
- 1.212
- 0.436
- 0.424
- 0.81
- 0.042
- 0.422
- 0.431
- 0.041
- 0.806
- 0.783
- 1.131
- 0.754
- 0.406
- 0.042
- 0.786
- 0.394
- 0.755
- 1.085
- 0.738
- 0.735
- 0.377
- 0.029
- 0.753
- 0.71
- 0.377
- 0.374
- 0.705
- 0.685
- 0.362
- 0.694
- 0.684
- 0.359
- 0.365
- 0.998
- 0.976
- 0.368
- 0.663
- 0.346
- 0.35
- 0.355
- 0.968
- 0.663
- 0.647
- 0.34
- 0.642
- 0.343
- 0.639
- 0.923
- 0.344
- 0.332
- 0.33
- 0.633
- 0.61
- 0.323
- 0.612
- 0.335
- 0.324
- 0.322
- 0.316
- 0.604
- 0.604
- 0.599
- 0.038
- 0.323
- 0.606
- 0.59
- 0.877
- 0.329
- 0.591
unequal: 0
verbose: 1
