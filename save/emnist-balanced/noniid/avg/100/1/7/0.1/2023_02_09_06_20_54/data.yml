avg_train_accuracy: 0.619
avg_train_loss: 0.027
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.014361702127659574
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.04175531914893617
- 0.02127659574468085
- 0.04085106382978723
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.029148936170212764
- 0.02851063829787234
- 0.028191489361702127
- 0.02127659574468085
- 0.04382978723404255
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.06223404255319149
- 0.04111702127659574
- 0.023510638297872342
- 0.08202127659574468
- 0.07303191489361702
- 0.02127659574468085
- 0.08909574468085106
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.09095744680851064
- 0.11611702127659575
- 0.18212765957446808
- 0.021382978723404257
- 0.027606382978723403
- 0.02127659574468085
- 0.021914893617021276
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.03074468085106383
- 0.02622340425531915
- 0.024574468085106382
- 0.036702127659574466
- 0.030425531914893618
- 0.11409574468085107
- 0.2047340425531915
- 0.02127659574468085
- 0.021968085106382977
- 0.031595744680851065
- 0.235
- 0.285531914893617
- 0.07063829787234042
- 0.35085106382978726
- 0.4074468085106383
- 0.02127659574468085
- 0.428936170212766
- 0.4696808510638298
- 0.13851063829787233
- 0.1024468085106383
- 0.07117021276595745
- 0.039946808510638296
- 0.033138297872340426
- 0.03861702127659575
- 0.026329787234042553
- 0.0601063829787234
- 0.04781914893617021
- 0.06574468085106383
- 0.4735106382978723
- 0.03771276595744681
- 0.08154255319148936
- 0.06281914893617022
- 0.48388297872340424
- 0.29851063829787233
- 0.18393617021276595
- 0.14207446808510638
- 0.5216489361702128
test_loss_list:
- 28.729600982666014
- 3.800609340667725
- 21.347176462809244
- 23.854234364827473
- 25.7822748819987
- 3.807453498840332
- 17.5269140625
- 23.162318878173828
- 17.78513287862142
- 21.000111821492514
- 20.4684144337972
- 3.8107515939076744
- 22.184362131754558
- 14.992088470458985
- 15.735095443725585
- 15.075823720296224
- 3.8112347253163654
- 23.728602142333983
- 15.657615242004395
- 20.948147659301757
- 15.56833979288737
- 15.152475763956705
- 12.75223196665446
- 16.94521059672038
- 11.67940320332845
- 12.978267033894857
- 3.7916312567392985
- 15.479670626322429
- 3.778473443984985
- 18.165301895141603
- 16.983894500732422
- 19.458353627522786
- 3.786618455251058
- 7.92431604385376
- 14.600428454081218
- 18.65689509073893
- 3.7556984678904217
- 14.492516949971517
- 20.59210469563802
- 14.289577967325846
- 8.867419306437174
- 3.7259087721506754
- 7.230106131235758
- 13.538394660949708
- 3.6898620669047038
- 3.6295146973927817
- 27.674739583333334
- 3.5726845900217694
- 14.937777506510416
- 20.334245885213218
- 14.113388582865397
- 18.765706176757813
- 3.5348045349121096
- 3.3943995094299315
- 3.252273540496826
- 8.916511764526367
- 9.887364438374837
- 16.93074727376302
- 11.15680586496989
- 15.94295093536377
- 21.284871470133464
- 10.270346666971843
- 10.291865234375
- 9.557587687174479
- 12.096794357299805
- 13.960097681681315
- 7.95938985188802
- 9.395920092264811
- 3.363640995025635
- 3.13562247912089
- 15.269650344848634
- 9.087827949523925
- 11.548132044474285
- 3.034687655766805
- 2.8446712493896484
- 6.819963232676188
- 2.6601635932922365
- 2.5538138930002847
- 8.634939511617025
- 2.407694470087687
- 2.3450735219319663
- 5.828776213328044
- 6.3582778104146325
- 8.261039524078369
- 13.143914311726888
- 16.437759297688803
- 8.121324736277263
- 11.5128990427653
- 9.746774088541667
- 9.040878105163575
- 8.414402510325115
- 2.235045073827108
- 6.531226221720377
- 6.277486934661865
- 9.150687586466471
- 2.059453794161479
- 3.8197368017832436
- 7.473117033640544
- 9.707354151407877
- 1.9015223598480224
train_accuracy:
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.002
- 1.0
- 0.023
- 1.0
- 1.0
- 1.0
- 1.0
- 0.042
- 0.1
- 0.171
- 1.0
- 1.0
- 1.0
- 0.996
- 1.0
- 1.0
- 1.0
- 0.998
- 0.998
- 0.998
- 1.0
- 1.0
- 1.0
- 0.037
- 0.179
- 1.0
- 0.998
- 1.0
- 0.221
- 0.302
- 0.998
- 0.429
- 0.465
- 1.0
- 0.537
- 0.537
- 1.0
- 1.0
- 1.0
- 0.994
- 1.0
- 1.0
- 0.996
- 0.994
- 1.0
- 0.998
- 0.5
- 1.0
- 1.0
- 0.996
- 0.523
- 1.0
- 1.0
- 1.0
- 0.619
train_loss:
- 0.357
- 4.214
- 1.305
- 0.83
- 0.683
- 4.266
- 0.811
- 0.026
- 0.651
- 0.92
- 0.805
- 4.276
- 0.961
- 0.6
- 0.833
- 0.279
- 4.291
- 0.754
- 1.303
- 0.026
- 0.365
- 0.77
- 0.394
- 0.889
- 1.031
- 0.306
- 4.337
- 0.2
- 4.094
- 0.977
- 0.764
- 0.571
- 4.265
- 0.369
- 0.444
- 0.019
- 4.255
- 1.879
- 0.486
- 0.546
- 0.379
- 4.159
- 0.26
- 0.201
- 4.12
- 3.829
- 1.033
- 4.118
- 0.52
- 0.041
- 0.787
- 0.042
- 4.114
- 3.633
- 3.46
- 0.196
- 0.361
- 0.393
- 0.605
- 0.826
- 0.022
- 0.408
- 0.261
- 0.289
- 0.023
- 0.012
- 0.258
- 0.011
- 4.015
- 3.506
- 0.309
- 0.476
- 0.179
- 3.697
- 3.185
- 0.194
- 3.14
- 2.8
- 0.366
- 2.876
- 2.565
- 0.242
- 0.252
- 0.027
- 0.282
- 0.014
- 0.293
- 0.225
- 0.155
- 0.106
- 0.137
- 3.237
- 0.265
- 0.272
- 0.215
- 2.893
- 0.153
- 0.25
- 0.023
- 2.749
unequal: 0
verbose: 1
