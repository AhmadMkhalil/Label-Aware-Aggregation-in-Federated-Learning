avg_train_accuracy: 1.0
avg_train_loss: 0.002
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.03893617021276596
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02797872340425532
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.03888297872340426
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.054946808510638295
- 0.05361702127659575
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.06617021276595744
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.0627659574468085
- 0.02127659574468085
- 0.02175531914893617
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.07
- 0.10441489361702128
- 0.02127659574468085
- 0.02127659574468085
- 0.025053191489361703
- 0.095
- 0.021329787234042552
- 0.24601063829787234
- 0.3451063829787234
- 0.409468085106383
- 0.043882978723404256
- 0.46297872340425533
- 0.08526595744680851
- 0.04452127659574468
- 0.4902127659574468
- 0.5052127659574468
- 0.09808510638297872
- 0.03148936170212766
- 0.052074468085106386
- 0.05095744680851064
- 0.027659574468085105
- 0.027925531914893616
- 0.5192553191489362
- 0.5242021276595744
- 0.13382978723404254
- 0.09031914893617021
- 0.047021276595744683
- 0.0675531914893617
- 0.043882978723404256
- 0.06856382978723405
- 0.5506382978723404
- 0.12409574468085106
- 0.07829787234042553
- 0.06893617021276596
- 0.054787234042553194
- 0.06196808510638298
- 0.06026595744680851
- 0.07430851063829787
- 0.05404255319148936
- 0.07154255319148936
- 0.5489893617021276
- 0.14398936170212767
- 0.10143617021276596
- 0.5550531914893617
- 0.5638297872340425
- 0.25909574468085106
- 0.2076595744680851
- 0.08962765957446808
- 0.12617021276595744
- 0.575531914893617
- 0.1671808510638298
- 0.5849468085106383
- 0.3004787234042553
- 0.2546276595744681
- 0.12643617021276596
- 0.16382978723404254
- 0.6036702127659574
- 0.3169148936170213
- 0.2397340425531915
- 0.23462765957446807
- 0.1526063829787234
- 0.12047872340425532
- 0.09319148936170213
- 0.6003191489361702
- 0.1345744680851064
test_loss_list:
- 26.736903025309246
- 26.277210489908853
- 22.15981763203939
- 22.314591496785482
- 3.798590135574341
- 16.094909604390462
- 19.271825358072917
- 20.8545206451416
- 3.799189726511637
- 11.77933723449707
- 20.938455149332682
- 3.788207270304362
- 13.14005517323812
- 3.7712732791900634
- 12.213710708618164
- 18.434454727172852
- 3.7562293656667074
- 15.768112869262696
- 14.589275690714517
- 17.84169756571452
- 3.7384819412231445
- 3.7206757132212323
- 14.772229359944662
- 12.183753522237142
- 16.38045633951823
- 3.688945016860962
- 11.85068765004476
- 14.712061882019043
- 14.987957560221354
- 3.6535211340586344
- 7.781283747355143
- 12.699441655476887
- 15.388052736918132
- 13.985459391276041
- 16.85548652648926
- 3.597429765065511
- 3.4905344359079997
- 7.375979906717936
- 11.122550188700359
- 11.39605765024821
- 3.3906354681650797
- 8.294079596201579
- 3.083477150599162
- 2.7440993213653564
- 2.5190691248575847
- 7.327392381032308
- 2.387189842859904
- 6.5359868240356445
- 8.292183653513591
- 2.266961628595988
- 2.204026959737142
- 6.118020521799723
- 10.602727241516114
- 7.7773188273111975
- 7.616958090464274
- 10.651318041483561
- 8.572605959574382
- 1.9387601073582967
- 1.8975081888834635
- 5.9656755701700845
- 7.943178990681966
- 8.771080182393392
- 5.669948279062907
- 9.086638526916504
- 7.498869514465332
- 1.8089106639226278
- 6.735156389872233
- 9.14106803894043
- 8.029650084177653
- 7.229192523956299
- 8.75581361134847
- 7.629978402455648
- 7.479734121958415
- 6.58336456934611
- 7.669755229949951
- 1.7545769770940145
- 5.544105860392253
- 7.094047126770019
- 1.7321107625961303
- 1.7354856236775715
- 4.441028299331665
- 5.906436882019043
- 8.571311651865642
- 6.559180399576823
- 1.5972740459442138
- 5.933869883219401
- 1.5758618195851644
- 4.064703063964844
- 4.464162915547689
- 8.187207183837891
- 5.954191195170084
- 1.531963980992635
- 5.296087322235107
- 7.5548402722676595
- 4.760553137461344
- 5.841401672363281
- 7.635481046040852
- 6.650164407094319
- 1.4367568826675414
- 5.6821140352884925
train_accuracy:
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.04
- 1.0
- 1.0
- 0.998
- 0.019
- 1.0
- 0.277
- 0.412
- 0.521
- 1.0
- 0.6
- 1.0
- 1.0
- 0.623
- 0.554
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.606
- 0.565
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.552
- 0.996
- 0.998
- 0.998
- 1.0
- 1.0
- 1.0
- 0.994
- 1.0
- 0.994
- 0.652
- 1.0
- 1.0
- 0.604
- 0.608
- 1.0
- 1.0
- 1.0
- 1.0
- 0.623
- 0.998
- 0.713
- 1.0
- 1.0
- 1.0
- 1.0
- 0.652
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.648
- 1.0
train_loss:
- 0.448
- 0.571
- 0.69
- 0.66
- 4.189
- 0.864
- 0.611
- 0.712
- 4.211
- 0.641
- 0.694
- 4.218
- 1.176
- 4.106
- 0.848
- 0.389
- 4.191
- 1.403
- 0.436
- 0.742
- 4.205
- 3.868
- 1.053
- 0.454
- 0.346
- 4.145
- 0.35
- 0.012
- 0.489
- 4.099
- 0.361
- 0.226
- 0.011
- 0.271
- 0.009
- 4.102
- 3.733
- 0.347
- 0.292
- 0.274
- 3.899
- 0.209
- 3.606
- 3.108
- 2.791
- 0.13
- 2.812
- 0.109
- 0.257
- 2.738
- 2.414
- 0.202
- 0.266
- 0.07
- 0.192
- 0.424
- 0.452
- 2.871
- 2.293
- 0.181
- 0.014
- 0.225
- 0.263
- 0.195
- 0.173
- 2.719
- 0.147
- 0.013
- 0.188
- 0.211
- 0.084
- 0.061
- 0.1
- 0.221
- 0.089
- 2.66
- 0.097
- 0.008
- 2.282
- 2.02
- 0.156
- 0.013
- 0.446
- 0.184
- 2.309
- 0.197
- 2.076
- 0.116
- 0.134
- 0.185
- 0.077
- 2.195
- 0.13
- 0.019
- 0.105
- 0.218
- 0.011
- 0.322
- 2.261
- 0.22
unequal: 0
verbose: 1
