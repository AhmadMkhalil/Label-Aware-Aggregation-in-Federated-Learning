avg_train_accuracy: 0.965
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.013404255319148937
- 0.03398936170212766
- 0.041063829787234045
- 0.041382978723404254
- 0.059308510638297875
- 0.05117021276595745
- 0.05228723404255319
- 0.09425531914893617
- 0.09111702127659574
- 0.09297872340425532
- 0.08898936170212766
- 0.11606382978723405
- 0.11473404255319149
- 0.16127659574468084
- 0.20882978723404255
- 0.15303191489361703
- 0.12531914893617022
- 0.17824468085106382
- 0.12117021276595745
- 0.24521276595744682
- 0.2127659574468085
- 0.13319148936170214
- 0.18787234042553191
- 0.1199468085106383
- 0.1325531914893617
- 0.21781914893617021
- 0.31132978723404253
- 0.16627659574468084
- 0.15840425531914892
- 0.2402659574468085
- 0.4092021276595745
- 0.13920212765957446
- 0.19143617021276596
- 0.4229255319148936
- 0.37132978723404253
- 0.29856382978723406
- 0.27122340425531916
- 0.40893617021276596
- 0.2793617021276596
- 0.30409574468085104
- 0.3321276595744681
- 0.47547872340425534
- 0.29186170212765955
- 0.31898936170212766
- 0.3396276595744681
- 0.2093617021276596
- 0.5071808510638298
- 0.463031914893617
- 0.20962765957446808
- 0.22898936170212766
- 0.2373936170212766
- 0.3844148936170213
- 0.31957446808510637
- 0.4965425531914894
- 0.3663297872340426
- 0.24319148936170212
- 0.37563829787234043
- 0.24968085106382978
- 0.35069148936170214
- 0.3775
- 0.21329787234042552
- 0.4672340425531915
- 0.5331382978723405
- 0.3626063829787234
- 0.40845744680851065
- 0.38143617021276593
- 0.2543617021276596
- 0.43670212765957445
- 0.41819148936170214
- 0.4156382978723404
- 0.5665425531914894
- 0.49686170212765957
- 0.2575
- 0.25851063829787235
- 0.4673404255319149
- 0.45085106382978724
- 0.5624468085106383
- 0.2676595744680851
- 0.42696808510638296
- 0.4629255319148936
- 0.4302127659574468
- 0.406968085106383
- 0.29819148936170214
- 0.41143617021276596
- 0.41771276595744683
- 0.2024468085106383
- 0.4270744680851064
- 0.5804787234042553
- 0.4378191489361702
- 0.44111702127659574
- 0.431436170212766
- 0.6050531914893617
- 0.41877659574468085
- 0.5965957446808511
- 0.5877127659574468
- 0.591968085106383
- 0.48611702127659573
- 0.4849468085106383
- 0.4614893617021277
test_loss_list:
- 4.127160568237304
- 4.486539204915364
- 4.452356128692627
- 3.865209747950236
- 4.115463231404623
- 3.7514287058512368
- 4.214276771545411
- 4.96342763264974
- 3.689852720896403
- 3.9161256059010823
- 4.04440806388855
- 5.0934723854064945
- 3.3453414726257322
- 3.970697161356608
- 3.052057336171468
- 2.8940492343902586
- 3.514663887023926
- 4.557349599202474
- 3.0174266052246095
- 5.2725829569498694
- 2.825646635691325
- 3.1954952557881673
- 4.619272791544597
- 3.0239617315928142
- 5.66525266011556
- 4.34686731338501
- 3.032514575322469
- 2.5762004248301187
- 3.7829804770151774
- 4.351858024597168
- 2.875169464747111
- 2.0856242593129477
- 5.486696802775065
- 3.603794422149658
- 2.0210219621658325
- 2.2476341279347736
- 2.773155015309652
- 2.824569778442383
- 2.014832876523336
- 2.7618791739145916
- 2.6316412766774495
- 2.5025226497650146
- 1.8271681690216064
- 2.6274080340067547
- 2.5936925729115803
- 2.437940616607666
- 3.98618395169576
- 1.7052128553390502
- 1.859237739245097
- 4.025559921264648
- 3.5943261496225993
- 3.431370598475138
- 2.326737076441447
- 2.613740463256836
- 1.7598790184656778
- 2.494631776809692
- 3.569561160405477
- 2.1827526076634727
- 3.3260173066457113
- 2.424409386316935
- 2.3260846678415934
- 4.091617422103882
- 1.8383697525660196
- 1.579550518989563
- 2.3619445514678956
- 2.132863779067993
- 2.1761369689305625
- 3.469473959604899
- 2.0253587786356606
- 2.101822632153829
- 2.1813923597335814
- 1.4279191716512045
- 1.6701903851826985
- 3.423330332438151
- 3.608719889322917
- 1.8782632478078207
- 1.9940005000432333
- 1.4472254292170206
- 3.3555500348409018
- 1.9871229441960652
- 1.9300556310017905
- 1.9771207586924235
- 2.116386521657308
- 3.1654715379079184
- 2.155938584009806
- 2.157503360112508
- 5.0360639317830405
- 2.0482937208811443
- 1.3834054104487101
- 2.037644688288371
- 1.9687084531784058
- 2.0826750310262043
- 1.2907811164855958
- 2.1277422078450523
- 1.33121888478597
- 1.3767551358540853
- 1.342307006518046
- 1.870485348701477
- 1.7572558053334555
- 1.8518804375330606
train_accuracy:
- 1.0
- 0.0
- 0.0
- 0.965
- 0.279
- 0.315
- 0.01
- 0.012
- 0.033
- 0.977
- 0.504
- 0.26
- 0.423
- 0.04
- 0.883
- 0.94
- 0.852
- 0.844
- 0.865
- 0.969
- 0.163
- 0.798
- 0.719
- 0.996
- 0.948
- 0.192
- 0.931
- 0.212
- 0.969
- 0.927
- 0.827
- 0.715
- 0.973
- 0.579
- 0.787
- 0.356
- 0.977
- 0.977
- 0.931
- 0.792
- 0.971
- 0.798
- 0.417
- 0.879
- 0.948
- 0.927
- 0.94
- 0.779
- 0.912
- 0.89
- 0.975
- 0.883
- 0.283
- 0.944
- 0.456
- 0.91
- 0.954
- 0.273
- 0.95
- 0.221
- 0.304
- 0.981
- 0.956
- 0.91
- 0.94
- 0.983
- 0.298
- 0.933
- 0.981
- 0.965
- 0.879
- 0.802
- 0.923
- 0.967
- 0.929
- 0.929
- 0.925
- 0.965
- 0.958
- 0.938
- 0.36
- 0.94
- 0.979
- 0.844
- 0.288
- 0.935
- 0.875
- 0.99
- 0.581
- 0.967
- 0.312
- 0.979
- 0.885
- 0.917
- 0.546
- 0.963
- 0.571
- 0.965
- 0.948
- 0.965
train_loss:
- 1.896
- 1.201
- 1.165
- 1.66
- 1.095
- 1.543
- 1.004
- 0.511
- 0.952
- 0.908
- 0.885
- 0.451
- 0.855
- 0.818
- 0.808
- 1.147
- 0.765
- 0.387
- 0.742
- 0.376
- 0.722
- 0.701
- 0.359
- 0.688
- 0.044
- 0.359
- 0.674
- 0.661
- 0.649
- 0.339
- 0.639
- 0.934
- 0.33
- 0.333
- 0.92
- 0.894
- 0.603
- 0.601
- 0.871
- 0.588
- 0.578
- 0.58
- 0.834
- 0.565
- 0.561
- 0.551
- 0.291
- 0.825
- 0.802
- 0.29
- 0.285
- 0.285
- 0.538
- 0.53
- 0.782
- 0.519
- 0.276
- 0.522
- 0.273
- 0.524
- 0.515
- 0.264
- 0.521
- 0.741
- 0.502
- 0.501
- 0.494
- 0.261
- 0.5
- 0.492
- 0.489
- 0.717
- 0.707
- 0.256
- 0.255
- 0.487
- 0.474
- 0.697
- 0.25
- 0.477
- 0.461
- 0.465
- 0.458
- 0.245
- 0.461
- 0.452
- 0.025
- 0.464
- 0.669
- 0.453
- 0.448
- 0.451
- 0.662
- 0.442
- 0.651
- 0.641
- 0.642
- 0.444
- 0.437
- 0.43
unequal: 0
verbose: 1
