avg_train_accuracy: 0.89
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03196808510638298
- 0.027606382978723403
- 0.023510638297872342
- 0.026968085106382978
- 0.056063829787234044
- 0.030106382978723405
- 0.05781914893617021
- 0.05925531914893617
- 0.059468085106382976
- 0.08984042553191489
- 0.0699468085106383
- 0.1295744680851064
- 0.10920212765957447
- 0.24468085106382978
- 0.07308510638297873
- 0.22739361702127658
- 0.09154255319148936
- 0.10393617021276595
- 0.14319148936170212
- 0.14292553191489363
- 0.1827659574468085
- 0.2102127659574468
- 0.15925531914893618
- 0.3654787234042553
- 0.1622340425531915
- 0.37861702127659574
- 0.2932446808510638
- 0.15893617021276596
- 0.41617021276595745
- 0.1553723404255319
- 0.4186170212765957
- 0.23313829787234042
- 0.43425531914893617
- 0.13851063829787233
- 0.3004787234042553
- 0.2861170212765957
- 0.22292553191489362
- 0.31579787234042556
- 0.4398936170212766
- 0.21867021276595744
- 0.34441489361702127
- 0.2806382978723404
- 0.18212765957446808
- 0.3721808510638298
- 0.4557978723404255
- 0.26585106382978724
- 0.3102659574468085
- 0.2650531914893617
- 0.3223936170212766
- 0.35723404255319147
- 0.30909574468085105
- 0.36872340425531913
- 0.49042553191489363
- 0.4242021276595745
- 0.19191489361702127
- 0.5405319148936171
- 0.42340425531914894
- 0.4842021276595745
- 0.18074468085106382
- 0.5312765957446809
- 0.38
- 0.3479255319148936
- 0.5318617021276596
- 0.28441489361702127
- 0.5677127659574468
- 0.34127659574468083
- 0.5348936170212766
- 0.3225531914893617
- 0.38170212765957445
- 0.3638297872340426
- 0.35904255319148937
- 0.36234042553191487
- 0.423936170212766
- 0.4202659574468085
- 0.3848404255319149
- 0.5467021276595745
- 0.34914893617021275
- 0.4325
- 0.4284574468085106
- 0.5564893617021277
- 0.38468085106382977
- 0.5651063829787234
- 0.324468085106383
- 0.1828723404255319
- 0.5836702127659574
- 0.3862765957446809
- 0.25186170212765957
- 0.5975531914893617
- 0.4006914893617021
- 0.574468085106383
- 0.5481382978723405
- 0.4270744680851064
- 0.5902659574468085
- 0.4152127659574468
- 0.6040425531914894
- 0.40111702127659576
- 0.5940425531914894
- 0.394468085106383
- 0.4135106382978723
- 0.6004255319148936
test_loss_list:
- 4.604356460571289
- 4.0197547213236495
- 4.089182647069295
- 4.362042382558187
- 3.7663874117533367
- 5.058354784647624
- 3.7171968173980714
- 3.96936811765035
- 3.912545143763224
- 3.924621540705363
- 4.344911982218425
- 3.378597838083903
- 3.855384391148885
- 2.8246658484141034
- 5.779040584564209
- 2.8515225569407145
- 5.01032860438029
- 4.351408265431722
- 3.4435477924346922
- 3.5649348227183024
- 3.1092987855275473
- 2.9862310695648193
- 3.395728537241618
- 2.274440336227417
- 3.945733006795247
- 2.2105842622121177
- 2.5200084972381593
- 3.6123567644755044
- 2.0463598744074503
- 3.754221426645915
- 2.0340116008122764
- 2.938230593999227
- 1.95834707736969
- 4.707451426188151
- 2.437363926569621
- 2.6021533489227293
- 3.0149488830566407
- 2.5246694628397623
- 1.918916187286377
- 3.206334362030029
- 2.361243356068929
- 2.7418220901489256
- 3.980670315424601
- 2.2263374932607016
- 1.8629251066843668
- 2.991282386779785
- 2.3607658354441323
- 2.7446830813090006
- 2.4519616731007896
- 2.3757340399424236
- 2.628635800679525
- 2.2326889133453367
- 1.6621156120300293
- 1.935808835029602
- 4.338772118886312
- 1.5690086476008098
- 1.904756744702657
- 1.7268294493357341
- 4.624364941914877
- 1.6039109786351522
- 2.308577038447062
- 2.4681489594777424
- 1.546775385538737
- 2.780433651606242
- 1.4742310682932536
- 2.5789777056376137
- 1.5550601069132488
- 2.5167007223765054
- 2.2396394952138263
- 2.3247243944803873
- 2.3702934837341307
- 2.4363198184967043
- 2.020115451812744
- 2.1119225152333576
- 2.219495538075765
- 1.4982930278778077
- 2.4405288092295327
- 2.0969937515258787
- 2.0692086871465047
- 1.4767317438125611
- 2.265728022257487
- 1.405152629216512
- 2.7692706267038982
- 5.331538689931234
- 1.3582119019826253
- 2.186017147699992
- 3.45420002301534
- 1.3512676763534546
- 2.190034074783325
- 1.4164184029897053
- 1.556392126083374
- 2.0350613594055176
- 1.3240765555699667
- 2.306946045557658
- 1.3012915802001954
- 2.254056018193563
- 1.316333514849345
- 2.205440780321757
- 2.1487889194488528
- 1.288317486445109
train_accuracy:
- 0.0
- 0.071
- 0.0
- 0.0
- 0.681
- 0.102
- 0.008
- 0.283
- 0.019
- 0.89
- 0.398
- 0.846
- 0.979
- 0.217
- 0.0
- 0.223
- 0.746
- 0.019
- 0.929
- 0.963
- 0.9
- 0.919
- 0.942
- 0.24
- 0.06
- 0.398
- 0.454
- 0.8
- 0.827
- 0.912
- 0.448
- 0.76
- 0.625
- 0.84
- 0.206
- 0.227
- 0.965
- 0.954
- 0.867
- 0.983
- 0.885
- 0.956
- 0.892
- 0.631
- 0.973
- 0.985
- 0.91
- 0.96
- 0.942
- 0.883
- 0.892
- 0.308
- 0.929
- 0.935
- 0.973
- 0.604
- 0.379
- 0.865
- 0.84
- 0.954
- 0.285
- 0.965
- 0.523
- 0.2
- 0.585
- 0.971
- 0.737
- 0.921
- 0.317
- 0.973
- 0.294
- 0.898
- 0.365
- 0.965
- 0.308
- 0.481
- 0.929
- 0.354
- 0.352
- 0.965
- 0.948
- 0.869
- 0.975
- 0.975
- 0.733
- 0.842
- 0.958
- 0.908
- 0.985
- 0.944
- 0.977
- 0.831
- 0.59
- 0.298
- 0.931
- 0.873
- 0.981
- 0.912
- 0.337
- 0.89
train_loss:
- 0.852
- 1.705
- 1.69
- 1.118
- 1.6
- 0.557
- 1.505
- 0.983
- 0.939
- 0.918
- 0.479
- 0.876
- 0.846
- 1.239
- 0.437
- 1.204
- 0.427
- 0.418
- 0.774
- 0.747
- 0.745
- 0.721
- 0.713
- 1.043
- 0.688
- 1.003
- 0.978
- 0.663
- 0.963
- 0.647
- 0.938
- 0.631
- 0.911
- 0.33
- 0.616
- 0.609
- 0.603
- 0.592
- 0.87
- 0.593
- 0.589
- 0.576
- 0.31
- 0.577
- 0.841
- 0.564
- 0.57
- 0.558
- 0.557
- 0.55
- 0.553
- 0.552
- 0.803
- 0.793
- 0.288
- 0.806
- 0.778
- 0.778
- 0.282
- 0.794
- 0.526
- 0.521
- 0.765
- 0.521
- 0.758
- 0.509
- 0.748
- 0.501
- 0.508
- 0.503
- 0.5
- 0.501
- 0.502
- 0.493
- 0.492
- 0.719
- 0.485
- 0.495
- 0.486
- 0.709
- 0.486
- 0.706
- 0.478
- 0.027
- 0.725
- 0.472
- 0.253
- 0.702
- 0.467
- 0.69
- 0.682
- 0.467
- 0.677
- 0.46
- 0.673
- 0.457
- 0.673
- 0.454
- 0.451
- 0.668
unequal: 0
verbose: 1
