avg_train_accuracy: 0.404
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.035106382978723406
- 0.023085106382978723
- 0.05973404255319149
- 0.047606382978723404
- 0.06026595744680851
- 0.05143617021276596
- 0.062287234042553194
- 0.09824468085106383
- 0.12138297872340426
- 0.0875
- 0.11202127659574468
- 0.1227127659574468
- 0.12468085106382978
- 0.2002127659574468
- 0.09537234042553192
- 0.09515957446808511
- 0.16590425531914893
- 0.11031914893617022
- 0.15047872340425533
- 0.28319148936170213
- 0.1602127659574468
- 0.21819148936170213
- 0.13654255319148936
- 0.22686170212765958
- 0.14617021276595746
- 0.2508510638297872
- 0.2053191489361702
- 0.20191489361702128
- 0.23840425531914894
- 0.40611702127659577
- 0.3875
- 0.22819148936170214
- 0.40117021276595743
- 0.4269148936170213
- 0.4292021276595745
- 0.17888297872340425
- 0.4343085106382979
- 0.17648936170212767
- 0.46026595744680854
- 0.46638297872340423
- 0.19382978723404257
- 0.3375
- 0.3201063829787234
- 0.20659574468085107
- 0.37898936170212766
- 0.4950531914893617
- 0.19877659574468085
- 0.19441489361702127
- 0.5231382978723405
- 0.48521276595744683
- 0.3652659574468085
- 0.39276595744680853
- 0.3622872340425532
- 0.2325
- 0.3626595744680851
- 0.355531914893617
- 0.36617021276595746
- 0.21920212765957447
- 0.33
- 0.24968085106382978
- 0.551063829787234
- 0.5081914893617021
- 0.5424468085106383
- 0.38851063829787236
- 0.3997340425531915
- 0.40952127659574467
- 0.4024468085106383
- 0.5281382978723405
- 0.41393617021276596
- 0.45063829787234044
- 0.4380851063829787
- 0.28388297872340423
- 0.5596808510638298
- 0.27835106382978725
- 0.3729787234042553
- 0.4250531914893617
- 0.2925531914893617
- 0.27430851063829786
- 0.4127127659574468
- 0.4528723404255319
- 0.41829787234042554
- 0.4652659574468085
- 0.5566489361702127
- 0.5668617021276596
- 0.5418617021276596
- 0.426436170212766
- 0.48404255319148937
- 0.5915425531914894
- 0.5745744680851064
- 0.3048936170212766
- 0.4706382978723404
- 0.42840425531914894
- 0.5049468085106383
- 0.4652659574468085
- 0.5127659574468085
- 0.5976063829787234
- 0.2852127659574468
- 0.6214893617021277
- 0.49622340425531913
test_loss_list:
- 4.212507133483887
- 4.057861798604329
- 4.659917182922364
- 4.662206484476726
- 6.449529482523601
- 4.37064682006836
- 4.447174797058105
- 4.36236156463623
- 3.475292892456055
- 3.3142493851979573
- 4.452197500864664
- 3.4697355779012042
- 3.546646766662598
- 3.569612963994344
- 2.812135648727417
- 4.665332539876302
- 4.605957921346029
- 3.1401771863301593
- 4.572906964619954
- 3.344053471883138
- 2.421732012430827
- 3.403940839767456
- 2.9206811141967775
- 4.631017888387044
- 2.9923501777648926
- 4.707986977895101
- 2.6686846097310384
- 3.1006386534372967
- 3.0540710067749024
- 2.6910692183176677
- 2.059487050374349
- 2.08312726020813
- 3.0788938903808596
- 2.0602030340830484
- 1.9855863777796428
- 1.9678451283772787
- 3.963700122833252
- 1.8891370089848836
- 4.043093922932942
- 1.8062409830093384
- 1.8139092842737834
- 3.8645037841796874
- 2.22914542833964
- 2.3483743890126547
- 3.7677601178487143
- 2.2109058841069538
- 1.6811167192459107
- 3.8935645548502604
- 4.103790559768677
- 1.5749816751480104
- 1.6853494691848754
- 2.2928231461842854
- 2.139137538274129
- 2.2585743459065757
- 3.548092810312907
- 2.1821637614568075
- 2.343609717686971
- 2.1888665358225503
- 3.662767578760783
- 2.4164154434204104
- 3.229137913386027
- 1.4649262460072836
- 1.5882620096206665
- 1.4903504196802775
- 2.164336757659912
- 2.126881111462911
- 2.1053458897272748
- 2.039804213841756
- 1.5196431223551432
- 2.160235815048218
- 1.8216602341334025
- 2.016329298019409
- 3.2617732652028404
- 1.4045249970753988
- 3.1272186342875163
- 2.320083877245585
- 1.9932992204030355
- 3.0470765749613444
- 3.255519158045451
- 2.0802250051498414
- 1.8492037534713746
- 2.148127635320028
- 1.7568250370025635
- 1.4365119075775146
- 1.405676334698995
- 1.4991617345809936
- 2.0352900902430218
- 1.777500599225362
- 1.3562809038162231
- 1.3929802290598552
- 3.1163274606068927
- 1.7866162649790447
- 2.0111663707097374
- 1.6461361201604208
- 1.9212821118036907
- 1.5946729898452758
- 1.331987862586975
- 3.409887622197469
- 1.2153837776184082
- 1.7259545850753784
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.092
- 0.323
- 0.0
- 0.021
- 0.471
- 0.9
- 0.198
- 0.588
- 0.979
- 0.952
- 0.537
- 0.16
- 0.66
- 0.838
- 0.29
- 0.565
- 0.942
- 0.84
- 0.073
- 0.129
- 0.829
- 0.958
- 0.04
- 0.185
- 0.963
- 0.085
- 0.963
- 0.344
- 0.896
- 0.944
- 0.812
- 0.412
- 0.371
- 0.075
- 0.4
- 0.917
- 0.469
- 0.933
- 0.973
- 0.963
- 0.879
- 0.073
- 0.975
- 0.465
- 0.894
- 0.973
- 0.529
- 0.496
- 0.277
- 0.944
- 0.269
- 0.973
- 0.881
- 0.915
- 0.971
- 0.944
- 0.965
- 0.942
- 0.875
- 0.473
- 0.548
- 0.277
- 0.954
- 0.948
- 0.29
- 0.485
- 0.983
- 0.912
- 0.956
- 0.9
- 0.902
- 0.954
- 0.91
- 0.829
- 0.975
- 0.925
- 0.946
- 0.354
- 0.923
- 0.34
- 0.513
- 0.931
- 0.946
- 0.985
- 0.431
- 0.835
- 0.875
- 0.144
- 0.412
- 0.315
- 0.969
- 0.35
- 0.948
- 0.517
- 0.979
- 0.573
- 0.404
train_loss:
- 1.362
- 1.707
- 1.168
- 1.129
- 0.066
- 1.118
- 1.083
- 1.057
- 1.495
- 1.405
- 0.492
- 0.901
- 0.87
- 0.84
- 1.214
- 0.427
- 0.414
- 0.782
- 0.396
- 0.752
- 1.1
- 0.721
- 0.715
- 0.37
- 0.692
- 0.357
- 0.686
- 0.674
- 0.666
- 0.654
- 0.952
- 0.936
- 0.633
- 0.921
- 0.905
- 0.882
- 0.322
- 0.891
- 0.323
- 0.878
- 0.861
- 0.306
- 0.578
- 0.577
- 0.294
- 0.566
- 0.828
- 0.295
- 0.292
- 0.823
- 0.802
- 0.539
- 0.551
- 0.532
- 0.28
- 0.54
- 0.527
- 0.529
- 0.272
- 0.528
- 0.276
- 0.765
- 0.75
- 0.748
- 0.512
- 0.506
- 0.504
- 0.494
- 0.732
- 0.496
- 0.494
- 0.488
- 0.256
- 0.727
- 0.259
- 0.486
- 0.481
- 0.256
- 0.253
- 0.486
- 0.474
- 0.473
- 0.476
- 0.694
- 0.688
- 0.683
- 0.469
- 0.463
- 0.677
- 0.673
- 0.243
- 0.456
- 0.453
- 0.453
- 0.446
- 0.449
- 0.655
- 0.239
- 0.663
- 0.443
unequal: 0
verbose: 1
