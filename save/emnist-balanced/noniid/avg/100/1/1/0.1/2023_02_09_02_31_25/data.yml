avg_train_accuracy: 0.792
avg_train_loss: 0.013
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02675531914893617
- 0.0400531914893617
- 0.05303191489361702
- 0.07356382978723404
- 0.15468085106382978
- 0.24175531914893617
- 0.363031914893617
- 0.42058510638297875
- 0.02127659574468085
- 0.43861702127659574
- 0.4932446808510638
- 0.02127659574468085
- 0.5193085106382979
- 0.5542553191489362
- 0.5718085106382979
- 0.5875
- 0.6074468085106383
- 0.616436170212766
- 0.6334574468085107
- 0.637127659574468
- 0.6484574468085106
- 0.6565425531914894
- 0.6670744680851064
- 0.06707446808510638
- 0.6662765957446809
- 0.6678723404255319
- 0.6803191489361702
- 0.6861170212765958
- 0.69
- 0.6868617021276596
- 0.6971276595744681
- 0.7004787234042553
- 0.16585106382978723
- 0.7077127659574468
- 0.7084574468085106
- 0.7113829787234043
- 0.7120744680851064
- 0.7167553191489362
- 0.2518085106382979
- 0.1723404255319149
- 0.7152127659574468
- 0.7109042553191489
- 0.7213829787234043
- 0.7261702127659575
- 0.7276595744680852
- 0.7289361702127659
- 0.7281914893617021
- 0.7312765957446808
- 0.732872340425532
- 0.7337234042553191
- 0.3128723404255319
- 0.22223404255319149
- 0.7379255319148936
- 0.7276063829787234
- 0.7364893617021276
- 0.7398936170212767
- 0.7409042553191489
- 0.7367021276595744
- 0.7415957446808511
- 0.7451595744680851
- 0.7465957446808511
- 0.7472340425531915
- 0.7465425531914893
- 0.7426595744680851
- 0.3451595744680851
- 0.7495212765957446
- 0.748031914893617
- 0.75
- 0.7500531914893617
- 0.7520212765957447
- 0.7507446808510638
- 0.7525531914893617
- 0.7532446808510638
- 0.7537234042553191
- 0.7532978723404256
- 0.7545744680851064
- 0.7586170212765957
- 0.7593085106382979
- 0.7579787234042553
- 0.7534574468085107
- 0.7593617021276595
- 0.7637234042553191
- 0.7620744680851064
- 0.765
- 0.7634042553191489
- 0.7640957446808511
- 0.7666489361702128
- 0.7660106382978723
- 0.3769148936170213
- 0.7661702127659574
- 0.763563829787234
- 0.7655851063829787
- 0.7616489361702128
- 0.7626595744680851
- 0.7606382978723404
- 0.7667021276595745
- 0.7648936170212766
- 0.768563829787234
- 0.763563829787234
- 0.7662234042553191
test_loss_list:
- 3.792949393590291
- 3.782846647898356
- 3.7590354537963866
- 3.704622392654419
- 3.574858153661092
- 3.2924822775522866
- 2.8893684164683022
- 2.532654291788737
- 33.78357874552409
- 2.57222149848938
- 2.220423488616943
- 19.136609649658205
- 2.0150234731038412
- 1.8246859629948935
- 1.7223854557673137
- 1.633661691347758
- 1.5448929405212402
- 1.4950755516688028
- 1.4399460045496624
- 1.389121225674947
- 1.367291800181071
- 1.3234072971343993
- 1.296771478652954
- 9.90233772277832
- 1.1898048210144043
- 1.1758896287282308
- 1.1451348423957826
- 1.1366670282681783
- 1.1316056712468465
- 1.1204898047447205
- 1.100144788424174
- 1.1048729610443115
- 7.520777441660563
- 1.0266154789924622
- 1.0072608455022176
- 1.0078746525446574
- 1.0057310366630554
- 1.0116186650594075
- 6.459893379211426
- 8.870252876281738
- 0.9577430645624797
- 0.9698291301727295
- 0.962399202187856
- 0.9673158558209737
- 0.9677302821477254
- 0.9680757848421733
- 0.9591077073415121
- 0.9607224186261495
- 0.9588008872667948
- 0.9472699578603109
- 5.503130919138591
- 7.596696802775065
- 0.8611032803853352
- 0.8820679140090942
- 0.8890051015218099
- 0.8963077116012573
- 0.9007672611872355
- 0.8973756313323975
- 0.8970199918746948
- 0.8989366308848064
- 0.9063439599672953
- 0.89045849720637
- 0.8964905126889546
- 0.9016560212771098
- 5.077112445831299
- 0.8035259691874186
- 0.8216894706090291
- 0.8295485266049702
- 0.8346865177154541
- 0.8420846589406331
- 0.8498268127441406
- 0.8537408280372619
- 0.8550524926185608
- 0.8612681674957275
- 0.8516956400871277
- 0.8453500390052795
- 0.8448878566424052
- 0.849453661441803
- 0.8590399177869161
- 0.8548076430956523
- 0.8591209387779236
- 0.8740622440973917
- 0.8539934579531352
- 0.8568205642700195
- 0.8511786969502767
- 0.8517948508262634
- 0.8459861548741658
- 0.8344804183642069
- 4.914580430984497
- 0.7330579368273417
- 0.7567377312978109
- 0.7638043292363484
- 0.7824207480748494
- 0.7859989809989929
- 0.7935431694984436
- 0.806382216612498
- 0.7948457209269205
- 0.7967365169525147
- 0.7951770687103271
- 0.7968225828806559
train_accuracy:
- 0.019
- 0.056
- 0.046
- 0.083
- 0.14
- 0.263
- 0.319
- 0.375
- 1.0
- 0.429
- 0.529
- 1.0
- 0.531
- 0.571
- 0.6
- 0.6
- 0.602
- 0.619
- 0.625
- 0.667
- 0.681
- 0.615
- 0.698
- 1.0
- 0.7
- 0.692
- 0.719
- 0.721
- 0.742
- 0.646
- 0.742
- 0.758
- 1.0
- 0.727
- 0.715
- 0.721
- 0.737
- 0.748
- 1.0
- 1.0
- 0.752
- 0.735
- 0.769
- 0.754
- 0.767
- 0.771
- 0.727
- 0.763
- 0.76
- 0.737
- 1.0
- 1.0
- 0.775
- 0.696
- 0.75
- 0.752
- 0.785
- 0.7
- 0.754
- 0.787
- 0.777
- 0.758
- 0.775
- 0.765
- 1.0
- 0.777
- 0.76
- 0.754
- 0.765
- 0.771
- 0.744
- 0.754
- 0.792
- 0.808
- 0.785
- 0.781
- 0.763
- 0.779
- 0.812
- 0.773
- 0.804
- 0.8
- 0.794
- 0.771
- 0.792
- 0.817
- 0.775
- 0.794
- 1.0
- 0.783
- 0.806
- 0.781
- 0.767
- 0.785
- 0.783
- 0.81
- 0.792
- 0.794
- 0.721
- 0.792
train_loss:
- 3.851
- 3.841
- 3.825
- 3.797
- 3.723
- 3.569
- 3.316
- 3.014
- 0.273
- 3.668
- 2.873
- 0.261
- 3.016
- 2.528
- 2.372
- 2.313
- 2.173
- 2.072
- 2.042
- 2.019
- 1.947
- 1.909
- 1.847
- 0.214
- 2.147
- 1.841
- 1.745
- 1.789
- 1.769
- 1.708
- 1.638
- 1.685
- 0.165
- 1.86
- 1.632
- 1.624
- 1.58
- 1.589
- 0.147
- 0.011
- 1.8
- 1.581
- 1.539
- 1.528
- 1.563
- 1.509
- 1.476
- 1.482
- 1.483
- 1.415
- 0.161
- 0.011
- 1.692
- 1.489
- 1.398
- 1.433
- 1.417
- 1.427
- 1.48
- 1.388
- 1.44
- 1.407
- 1.353
- 1.396
- 0.164
- 1.514
- 1.374
- 1.335
- 1.339
- 1.403
- 1.301
- 1.274
- 1.379
- 1.339
- 1.323
- 1.369
- 1.248
- 1.322
- 1.308
- 1.305
- 1.335
- 1.275
- 1.32
- 1.226
- 1.268
- 1.312
- 1.297
- 1.28
- 0.196
- 1.436
- 1.277
- 1.22
- 1.278
- 1.202
- 1.192
- 1.268
- 1.186
- 1.246
- 1.284
- 1.256
unequal: 0
verbose: 1
