avg_train_accuracy: 0.756
avg_train_loss: 0.013
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026436170212765956
- 0.040106382978723404
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02170212765957447
- 0.02271276595744681
- 0.02553191489361702
- 0.06021276595744681
- 0.07223404255319149
- 0.09468085106382979
- 0.02127659574468085
- 0.02127659574468085
- 0.0700531914893617
- 0.02127659574468085
- 0.07164893617021277
- 0.13234042553191488
- 0.21867021276595744
- 0.3431382978723404
- 0.02127659574468085
- 0.38888297872340427
- 0.4579255319148936
- 0.49329787234042555
- 0.038670212765957446
- 0.021968085106382977
- 0.02127659574468085
- 0.02127659574468085
- 0.504095744680851
- 0.538031914893617
- 0.5616489361702127
- 0.5765425531914894
- 0.08356382978723405
- 0.5839893617021277
- 0.5998936170212766
- 0.6065425531914893
- 0.044202127659574465
- 0.623031914893617
- 0.630531914893617
- 0.16691489361702128
- 0.6348936170212766
- 0.21712765957446808
- 0.646436170212766
- 0.6439893617021276
- 0.22292553191489362
- 0.6475
- 0.656436170212766
- 0.6632446808510638
- 0.6625531914893616
- 0.2574468085106383
- 0.6691489361702128
- 0.315
- 0.6696808510638298
- 0.6697872340425531
- 0.2696276595744681
- 0.18404255319148935
- 0.6827127659574468
- 0.6878723404255319
- 0.07920212765957446
- 0.693404255319149
- 0.699468085106383
- 0.6973936170212766
- 0.3326595744680851
- 0.06430851063829787
- 0.14409574468085107
- 0.6929787234042554
- 0.3856914893617021
- 0.6915425531914894
- 0.7014893617021276
- 0.698404255319149
- 0.7081914893617022
- 0.4023404255319149
- 0.7075531914893617
- 0.7103723404255319
- 0.7108510638297872
- 0.7130851063829787
- 0.7187234042553191
- 0.7163297872340425
- 0.7126595744680851
- 0.41319148936170214
- 0.30319148936170215
- 0.06824468085106383
- 0.7283510638297872
- 0.7265957446808511
- 0.3729787234042553
- 0.7193085106382979
- 0.4135106382978723
- 0.7209574468085106
- 0.725531914893617
- 0.7304787234042553
- 0.4597340425531915
- 0.7244148936170213
- 0.7239893617021277
- 0.16893617021276597
- 0.737659574468085
- 0.7363829787234043
- 0.7289361702127659
- 0.4570212765957447
- 0.7375531914893617
- 0.7271276595744681
test_loss_list:
- 3.7956169128417967
- 3.784451541900635
- 28.188512318929035
- 22.376750030517577
- 22.769437866210936
- 3.797476765314738
- 3.7932288297017416
- 3.789004446665446
- 3.7825314521789553
- 3.772546294530233
- 3.756429386138916
- 3.7207433001200356
- 15.220037790934244
- 23.70307772318522
- 3.7081572437286376
- 14.976466852823894
- 3.6284036032358804
- 3.457557004292806
- 3.1888720766703287
- 2.862770643234253
- 14.233283348083496
- 2.609967292149862
- 2.3567951107025147
- 2.164613490104675
- 10.409117596944172
- 11.463149871826172
- 13.992264391581218
- 16.161387888590493
- 1.9995854822794596
- 1.8342775376637777
- 1.7503723621368408
- 1.6853181664148966
- 8.000375270843506
- 1.6080526542663574
- 1.551045258839925
- 1.5228384526570637
- 12.01719305674235
- 1.4456713517506918
- 1.4417725276947022
- 6.492707684834798
- 1.3581963396072387
- 7.878064104715983
- 1.2899709113438924
- 1.2901178216934204
- 5.910037924448649
- 1.2602845668792724
- 1.2704762156804403
- 1.2613051255544028
- 1.270004439353943
- 5.3130653381347654
- 1.2298102474212647
- 4.618249937693278
- 1.206538772583008
- 1.2091786964734395
- 7.280869197845459
- 10.753629582722981
- 1.1611201190948486
- 1.1684836610158285
- 10.126077613830567
- 1.0976917664210002
- 1.090331682364146
- 1.099881477355957
- 5.836172962188721
- 10.056306749979655
- 5.6860842005411785
- 1.0590619325637818
- 5.108649088541667
- 1.051746561527252
- 1.051962184906006
- 1.0494009160995483
- 1.0513509408632915
- 4.757627493540446
- 1.0554770557085673
- 1.0696213030815125
- 1.0624854032198587
- 1.069182562828064
- 1.068006936709086
- 1.0803511611620584
- 1.0933082548777262
- 4.765070705413819
- 7.413803323109945
- 10.022852745056152
- 0.9866558265686035
- 0.9966724443435669
- 4.320743465423584
- 0.9231592996915181
- 3.8510872300465904
- 0.9374673851331075
- 0.9552205324172973
- 0.9644923162460327
- 3.3057440376281737
- 0.9570745086669922
- 0.979841730594635
- 6.856048571268717
- 0.9131344437599183
- 0.9305735508600871
- 0.9617462698618571
- 3.2651232846577964
- 0.902279949982961
- 0.9459479729334513
train_accuracy:
- 0.031
- 0.052
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.035
- 0.088
- 0.079
- 1.0
- 1.0
- 0.035
- 1.0
- 0.031
- 0.137
- 0.227
- 0.356
- 1.0
- 0.362
- 0.519
- 0.546
- 1.0
- 1.0
- 1.0
- 1.0
- 0.571
- 0.556
- 0.633
- 0.654
- 1.0
- 0.608
- 0.683
- 0.696
- 1.0
- 0.702
- 0.692
- 1.0
- 0.673
- 1.0
- 0.654
- 0.727
- 1.0
- 0.731
- 0.667
- 0.723
- 0.69
- 1.0
- 0.69
- 1.0
- 0.756
- 0.754
- 1.0
- 1.0
- 0.704
- 0.713
- 1.0
- 0.729
- 0.708
- 0.76
- 1.0
- 1.0
- 1.0
- 0.729
- 1.0
- 0.744
- 0.721
- 0.79
- 0.765
- 1.0
- 0.717
- 0.754
- 0.771
- 0.735
- 0.787
- 0.74
- 0.733
- 1.0
- 1.0
- 1.0
- 0.746
- 0.758
- 1.0
- 0.744
- 1.0
- 0.819
- 0.792
- 0.765
- 1.0
- 0.767
- 0.752
- 0.998
- 0.76
- 0.75
- 0.746
- 1.0
- 0.771
- 0.756
train_loss:
- 3.853
- 3.836
- 0.726
- 0.598
- 0.84
- 4.193
- 3.867
- 3.857
- 3.85
- 3.837
- 3.817
- 3.785
- 0.321
- 0.324
- 4.117
- 1.06
- 3.984
- 3.674
- 3.483
- 3.251
- 0.203
- 3.257
- 2.848
- 2.627
- 0.148
- 0.208
- 0.007
- 0.363
- 2.972
- 2.431
- 2.33
- 2.195
- 0.145
- 2.331
- 2.037
- 1.991
- 0.198
- 2.171
- 1.914
- 0.168
- 2.041
- 0.223
- 2.009
- 1.793
- 0.134
- 1.881
- 1.774
- 1.734
- 1.682
- 0.138
- 1.773
- 0.085
- 1.756
- 1.586
- 0.198
- 0.015
- 1.843
- 1.606
- 0.265
- 1.81
- 1.546
- 1.579
- 0.169
- 0.213
- 0.298
- 1.891
- 0.104
- 1.657
- 1.529
- 1.492
- 1.512
- 0.143
- 1.605
- 1.442
- 1.476
- 1.419
- 1.417
- 1.386
- 1.36
- 0.162
- 0.014
- 0.283
- 1.726
- 1.392
- 0.201
- 1.495
- 0.082
- 1.5
- 1.387
- 1.31
- 0.114
- 1.471
- 1.306
- 0.191
- 1.477
- 1.335
- 1.371
- 0.139
- 1.383
- 1.296
unequal: 0
verbose: 1
