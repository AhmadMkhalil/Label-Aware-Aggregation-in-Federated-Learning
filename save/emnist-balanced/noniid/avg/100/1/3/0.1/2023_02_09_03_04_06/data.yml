avg_train_accuracy: 0.781
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04867021276595745
- 0.058031914893617025
- 0.02127659574468085
- 0.02319148936170213
- 0.07622340425531915
- 0.10090425531914894
- 0.15723404255319148
- 0.02127659574468085
- 0.21351063829787234
- 0.02127659574468085
- 0.23563829787234042
- 0.02143617021276596
- 0.02127659574468085
- 0.02127659574468085
- 0.22601063829787235
- 0.3381914893617021
- 0.026861702127659575
- 0.40058510638297873
- 0.458031914893617
- 0.5036702127659575
- 0.08675531914893617
- 0.04074468085106383
- 0.03888297872340426
- 0.5184574468085107
- 0.5526063829787234
- 0.5804787234042553
- 0.5939893617021277
- 0.606436170212766
- 0.18377659574468086
- 0.6102659574468086
- 0.19872340425531915
- 0.1295744680851064
- 0.6310106382978723
- 0.635
- 0.28154255319148935
- 0.6488297872340425
- 0.04803191489361702
- 0.6571276595744681
- 0.661595744680851
- 0.6664893617021277
- 0.6687234042553192
- 0.676063829787234
- 0.3149468085106383
- 0.6743617021276596
- 0.36425531914893616
- 0.6792021276595744
- 0.3658510638297872
- 0.6907446808510638
- 0.4060106382978723
- 0.3342553191489362
- 0.69
- 0.6923936170212766
- 0.6975531914893617
- 0.7017021276595745
- 0.7050531914893617
- 0.3565957446808511
- 0.7092021276595745
- 0.7109574468085106
- 0.7092553191489361
- 0.7106914893617021
- 0.7180851063829787
- 0.39404255319148934
- 0.713936170212766
- 0.43079787234042555
- 0.7153723404255319
- 0.7206914893617021
- 0.7200531914893618
- 0.7211170212765957
- 0.09090425531914893
- 0.0548936170212766
- 0.7292553191489362
- 0.7287765957446809
- 0.7218617021276595
- 0.7225
- 0.7238297872340426
- 0.729468085106383
- 0.733404255319149
- 0.7307978723404255
- 0.1548404255319149
- 0.31393617021276593
- 0.7294148936170213
- 0.7294148936170213
- 0.7350531914893617
- 0.7319148936170212
- 0.7392021276595745
- 0.7399468085106383
- 0.7377127659574468
- 0.3706382978723404
- 0.7394148936170213
- 0.48659574468085104
- 0.7397872340425532
- 0.7388297872340426
- 0.7425
- 0.46622340425531916
- 0.7421808510638298
- 0.1746808510638298
- 0.3331914893617021
- 0.7476595744680851
- 0.7456382978723404
- 0.7460638297872341
test_loss_list:
- 3.7899249458312987
- 3.763889643351237
- 29.562353846232096
- 3.7848836612701415
- 3.7595348326365152
- 3.6854674593607584
- 3.5319368330637615
- 25.633375345865886
- 3.3798043092091876
- 24.875370508829754
- 3.181799980799357
- 14.815303916931152
- 12.946930236816407
- 12.879846801757813
- 3.0995874627431235
- 2.6520174725850425
- 10.221345252990723
- 2.4159646320343016
- 2.2209681479136147
- 2.041508609453837
- 7.489294611612956
- 12.07999085744222
- 15.344230715433756
- 1.8667530425389607
- 1.774425400098165
- 1.683359948794047
- 1.6459235906600953
- 1.6094845914840699
- 6.446282711029053
- 1.5172945165634155
- 6.5311238543192545
- 6.685333989461263
- 1.409075436592102
- 1.376049329439799
- 5.504665520985921
- 1.349886515935262
- 11.896142094930013
- 1.2610586563746133
- 1.2694865401585897
- 1.249759472211202
- 1.2435860935846965
- 1.2311064370473226
- 5.156131814320882
- 1.184568411509196
- 4.57255197207133
- 1.1885035483042399
- 4.5983336067199705
- 1.1667390815416971
- 4.088871320088704
- 5.554736366271973
- 1.1647241099675496
- 1.1706463042895
- 1.174882632891337
- 1.1835213828086852
- 1.1724466538429261
- 4.460841716130575
- 1.0648917404810587
- 1.0704668919245401
- 1.0849699902534484
- 1.0936838618914286
- 1.1007729959487915
- 4.03220487912496
- 1.05581955909729
- 3.6367778746287027
- 1.042619613011678
- 1.0673107035954794
- 1.0706557218233745
- 1.0740218313535055
- 10.029720878601074
- 14.191915842692056
- 0.9855083282788595
- 0.999900012811025
- 1.0156448459625245
- 1.0258627875645956
- 1.034998807112376
- 1.0285993385314942
- 1.0298300925890604
- 1.0463436365127563
- 7.977494303385416
- 4.163655099868774
- 0.9506440798441569
- 0.9738537096977233
- 0.9638928771018982
- 0.9822251280148824
- 0.9962614742914836
- 0.9974862440427145
- 1.000093276500702
- 5.704120546976725
- 0.9275862352053325
- 3.7993799177805583
- 0.9183202608426412
- 0.9475091369946798
- 0.9608267839749655
- 3.8987367661794026
- 0.9315686615308126
- 6.933512439727783
- 3.8507315667470294
- 0.8170528801282247
- 0.8521606826782226
- 0.8702969559033712
train_accuracy:
- 0.054
- 0.054
- 1.0
- 0.006
- 0.056
- 0.104
- 0.167
- 1.0
- 0.219
- 1.0
- 0.256
- 1.0
- 1.0
- 1.0
- 0.204
- 0.371
- 1.0
- 0.417
- 0.506
- 0.527
- 1.0
- 1.0
- 1.0
- 0.575
- 0.6
- 0.617
- 0.606
- 0.638
- 1.0
- 0.654
- 1.0
- 1.0
- 0.658
- 0.692
- 1.0
- 0.704
- 1.0
- 0.698
- 0.694
- 0.733
- 0.708
- 0.746
- 1.0
- 0.723
- 1.0
- 0.76
- 1.0
- 0.731
- 1.0
- 1.0
- 0.733
- 0.733
- 0.783
- 0.733
- 0.748
- 1.0
- 0.721
- 0.752
- 0.802
- 0.752
- 0.752
- 1.0
- 0.804
- 1.0
- 0.765
- 0.765
- 0.744
- 0.742
- 0.998
- 1.0
- 0.771
- 0.821
- 0.767
- 0.806
- 0.767
- 0.779
- 0.771
- 0.783
- 0.998
- 1.0
- 0.81
- 0.783
- 0.758
- 0.821
- 0.771
- 0.763
- 0.775
- 1.0
- 0.773
- 0.998
- 0.794
- 0.765
- 0.831
- 1.0
- 0.798
- 0.998
- 1.0
- 0.767
- 0.792
- 0.781
train_loss:
- 3.844
- 3.823
- 0.657
- 4.175
- 3.823
- 3.778
- 3.683
- 0.462
- 3.93
- 0.462
- 3.827
- 0.193
- 0.598
- 0.272
- 3.698
- 3.139
- 0.161
- 3.123
- 2.746
- 2.521
- 0.154
- 0.253
- 0.011
- 2.798
- 2.338
- 2.171
- 2.141
- 2.05
- 0.157
- 2.13
- 0.185
- 0.116
- 2.144
- 1.842
- 0.107
- 1.946
- 0.262
- 2.025
- 1.793
- 1.687
- 1.643
- 1.615
- 0.167
- 1.705
- 0.083
- 1.657
- 0.085
- 1.672
- 0.079
- 0.007
- 1.704
- 1.493
- 1.464
- 1.54
- 1.454
- 0.236
- 1.698
- 1.402
- 1.397
- 1.377
- 1.438
- 0.143
- 1.469
- 0.087
- 1.45
- 1.447
- 1.415
- 1.359
- 0.277
- 0.016
- 1.617
- 1.301
- 1.312
- 1.26
- 1.258
- 1.27
- 1.327
- 1.219
- 0.169
- 0.269
- 1.512
- 1.239
- 1.317
- 1.234
- 1.309
- 1.256
- 1.197
- 0.308
- 1.352
- 0.085
- 1.292
- 1.209
- 1.184
- 0.114
- 1.259
- 0.204
- 0.218
- 1.469
- 1.279
- 1.172
unequal: 0
verbose: 1
