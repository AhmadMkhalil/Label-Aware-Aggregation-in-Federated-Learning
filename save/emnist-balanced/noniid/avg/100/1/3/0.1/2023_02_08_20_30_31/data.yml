avg_train_accuracy: 0.804
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04026595744680851
- 0.0648404255319149
- 0.09941489361702127
- 0.02127659574468085
- 0.02127659574468085
- 0.0798404255319149
- 0.09452127659574468
- 0.02127659574468085
- 0.02127659574468085
- 0.0947872340425532
- 0.12680851063829787
- 0.02127659574468085
- 0.20186170212765958
- 0.31292553191489364
- 0.02127659574468085
- 0.02127659574468085
- 0.30340425531914894
- 0.398031914893617
- 0.026063829787234042
- 0.02127659574468085
- 0.022021276595744682
- 0.4417553191489362
- 0.4971276595744681
- 0.03835106382978724
- 0.5355319148936171
- 0.5547872340425531
- 0.5746808510638298
- 0.5997872340425532
- 0.6152659574468086
- 0.6253723404255319
- 0.6352659574468085
- 0.15367021276595744
- 0.6422872340425532
- 0.6510106382978723
- 0.6638829787234043
- 0.6639893617021276
- 0.6712765957446809
- 0.15973404255319149
- 0.6719148936170213
- 0.6809042553191489
- 0.34
- 0.26053191489361704
- 0.17574468085106382
- 0.6841489361702128
- 0.05547872340425532
- 0.694468085106383
- 0.6950531914893617
- 0.6940957446808511
- 0.3825
- 0.7018085106382979
- 0.7030851063829787
- 0.7061170212765957
- 0.7021276595744681
- 0.7098404255319148
- 0.7116489361702127
- 0.4305851063829787
- 0.7111170212765957
- 0.7168085106382979
- 0.7154255319148937
- 0.721063829787234
- 0.43457446808510636
- 0.05079787234042553
- 0.20797872340425533
- 0.7177659574468085
- 0.39409574468085107
- 0.7152659574468085
- 0.4443617021276596
- 0.7209574468085106
- 0.18638297872340426
- 0.7349468085106383
- 0.726968085106383
- 0.7290425531914894
- 0.7245212765957447
- 0.7329787234042553
- 0.7341489361702128
- 0.7312234042553192
- 0.7273404255319149
- 0.3790425531914894
- 0.2978723404255319
- 0.29345744680851066
- 0.7326595744680852
- 0.7337234042553191
- 0.45867021276595743
- 0.734468085106383
- 0.5102659574468085
- 0.7309574468085106
- 0.7368617021276596
- 0.739468085106383
- 0.7375
- 0.21425531914893617
- 0.7476063829787234
- 0.47462765957446806
- 0.7423936170212766
- 0.7434574468085107
- 0.745904255319149
- 0.7426595744680851
- 0.7459574468085106
- 0.7439893617021277
- 0.7460638297872341
- 0.7433510638297872
test_loss_list:
- 3.7895754623413085
- 3.765676317214966
- 3.691462618509928
- 24.794972127278644
- 30.288818155924478
- 3.760642407735189
- 3.666659386952718
- 26.96056566874186
- 33.34061513264974
- 3.7088653977711994
- 3.5080226389567057
- 21.340326207478842
- 3.312162024180094
- 2.942333040237427
- 15.736368726094565
- 21.345961201985677
- 2.9537782669067383
- 2.5337654050191243
- 11.468480173746745
- 15.430229988098144
- 11.484692904154459
- 2.392507209777832
- 2.120636943181356
- 10.209779713948567
- 2.0018304856618245
- 1.8653245449066163
- 1.7778137334187825
- 1.6765552218755086
- 1.634306502342224
- 1.5872098811467488
- 1.545760768254598
- 10.254811744689942
- 1.4211728652318318
- 1.4087279319763184
- 1.3854023710886638
- 1.3702305889129638
- 1.3454516553878784
- 7.534545408884684
- 1.2413895575205485
- 1.2210592873891195
- 5.932221508026123
- 8.201376584370932
- 6.769799912770589
- 1.1490647029876708
- 10.442936108907064
- 1.0805418761571248
- 1.0940561842918397
- 1.104290627638499
- 4.9250118446350095
- 1.0687144700686138
- 1.082055847644806
- 1.0886532688140869
- 1.1048815162976582
- 1.0972059082984924
- 1.0977446754773459
- 4.663969033559163
- 1.0592388010025025
- 1.0641274976730346
- 1.0802017943064373
- 1.0801477233568828
- 4.541455170313517
- 10.049760805765787
- 5.2870251655578615
- 0.9471060943603515
- 3.936939951578776
- 0.9466868917147319
- 3.4462003612518313
- 0.9373100415865581
- 6.129136422475179
- 0.9153020771344503
- 0.9468990977605184
- 0.9671403948465983
- 0.9671526622772216
- 0.9832739583651224
- 0.9936323030789693
- 1.0057681179046631
- 1.011855600674947
- 5.710004024505615
- 8.181598682403564
- 4.873886216481527
- 0.8822715067863465
- 0.9213963301976522
- 3.3837255255381264
- 0.9116140111287435
- 2.8251302528381346
- 0.9190328296025594
- 0.928789246082306
- 0.9495072793960572
- 0.9626072692871094
- 6.053381061553955
- 0.8925253971417745
- 4.129320678710937
- 0.8582499170303345
- 0.8771892102559408
- 0.8978326710065206
- 0.9146897594134012
- 0.9177380998929342
- 0.942015430132548
- 0.9383434136708577
- 0.9447718604405722
train_accuracy:
- 0.042
- 0.067
- 0.096
- 1.0
- 1.0
- 0.079
- 0.106
- 1.0
- 1.0
- 0.113
- 0.144
- 1.0
- 0.223
- 0.337
- 1.0
- 1.0
- 0.319
- 0.429
- 1.0
- 1.0
- 1.0
- 0.471
- 0.544
- 0.998
- 0.558
- 0.573
- 0.61
- 0.629
- 0.646
- 0.669
- 0.677
- 1.0
- 0.698
- 0.71
- 0.717
- 0.727
- 0.715
- 1.0
- 0.694
- 0.733
- 1.0
- 1.0
- 1.0
- 0.748
- 1.0
- 0.733
- 0.763
- 0.756
- 1.0
- 0.756
- 0.719
- 0.725
- 0.76
- 0.773
- 0.771
- 1.0
- 0.779
- 0.781
- 0.792
- 0.723
- 1.0
- 1.0
- 1.0
- 0.725
- 1.0
- 0.737
- 1.0
- 0.773
- 1.0
- 0.781
- 0.733
- 0.783
- 0.796
- 0.802
- 0.781
- 0.775
- 0.802
- 1.0
- 1.0
- 1.0
- 0.775
- 0.756
- 1.0
- 0.794
- 1.0
- 0.794
- 0.798
- 0.74
- 0.781
- 0.998
- 0.81
- 1.0
- 0.808
- 0.794
- 0.758
- 0.8
- 0.815
- 0.812
- 0.775
- 0.804
train_loss:
- 3.847
- 3.82
- 3.781
- 0.404
- 0.009
- 4.17
- 3.77
- 0.525
- 0.01
- 4.199
- 3.683
- 0.392
- 3.807
- 3.281
- 0.192
- 0.687
- 3.696
- 3.02
- 0.18
- 0.238
- 0.217
- 3.167
- 2.657
- 0.122
- 2.74
- 2.379
- 2.247
- 2.127
- 2.016
- 2.026
- 1.934
- 0.382
- 2.101
- 1.845
- 1.818
- 1.704
- 1.724
- 0.252
- 1.949
- 1.641
- 0.201
- 0.014
- 0.146
- 1.971
- 0.24
- 1.868
- 1.568
- 1.502
- 0.145
- 1.674
- 1.591
- 1.536
- 1.446
- 1.527
- 1.441
- 0.145
- 1.515
- 1.452
- 1.412
- 1.467
- 0.132
- 0.262
- 0.357
- 1.797
- 0.102
- 1.547
- 0.09
- 1.573
- 0.143
- 1.508
- 1.372
- 1.38
- 1.389
- 1.325
- 1.376
- 1.283
- 1.327
- 0.195
- 0.013
- 0.185
- 1.525
- 1.346
- 0.102
- 1.354
- 0.081
- 1.302
- 1.289
- 1.288
- 1.177
- 0.213
- 1.447
- 0.162
- 1.351
- 1.311
- 1.259
- 1.261
- 1.291
- 1.213
- 1.231
- 1.249
unequal: 0
verbose: 1
