avg_train_accuracy: 0.79
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029148936170212764
- 0.06313829787234043
- 0.1356382978723404
- 0.02127659574468085
- 0.0851063829787234
- 0.19702127659574467
- 0.02127659574468085
- 0.24776595744680852
- 0.02127659574468085
- 0.27882978723404256
- 0.40382978723404256
- 0.02127659574468085
- 0.02127659574468085
- 0.4071808510638298
- 0.45404255319148934
- 0.05829787234042553
- 0.4829787234042553
- 0.5128191489361702
- 0.11143617021276596
- 0.041329787234042556
- 0.5297340425531915
- 0.5511702127659575
- 0.16851063829787233
- 0.5647872340425532
- 0.09622340425531915
- 0.5757446808510638
- 0.5864893617021276
- 0.024840425531914893
- 0.5972872340425532
- 0.6039893617021277
- 0.6118085106382979
- 0.6232978723404256
- 0.6302127659574468
- 0.23297872340425532
- 0.6348404255319149
- 0.635904255319149
- 0.643563829787234
- 0.20324468085106384
- 0.6450531914893617
- 0.6481914893617021
- 0.6510106382978723
- 0.6625
- 0.04930851063829787
- 0.6701063829787234
- 0.3243617021276596
- 0.23797872340425533
- 0.673031914893617
- 0.67
- 0.3055851063829787
- 0.6710106382978723
- 0.6784574468085106
- 0.07430851063829787
- 0.6841489361702128
- 0.6869148936170213
- 0.34595744680851065
- 0.6871276595744681
- 0.6856382978723404
- 0.6883510638297873
- 0.366436170212766
- 0.6899468085106383
- 0.694468085106383
- 0.7001595744680851
- 0.699468085106383
- 0.6993085106382979
- 0.6980851063829787
- 0.6981914893617022
- 0.7085638297872341
- 0.7077127659574468
- 0.7075531914893617
- 0.7148404255319148
- 0.7231914893617021
- 0.27941489361702126
- 0.72
- 0.41191489361702127
- 0.32324468085106384
- 0.27202127659574465
- 0.7185106382978723
- 0.7144680851063829
- 0.7162765957446808
- 0.7200531914893618
- 0.7193617021276596
- 0.09835106382978723
- 0.7241489361702128
- 0.726968085106383
- 0.3918617021276596
- 0.24601063829787234
- 0.7260106382978724
- 0.7218617021276595
- 0.7256382978723405
- 0.7228191489361702
- 0.7284574468085107
- 0.7245744680851064
- 0.7292553191489362
- 0.7311702127659574
- 0.7321276595744681
- 0.37968085106382976
- 0.724095744680851
- 0.7304787234042553
- 0.732872340425532
- 0.733404255319149
test_loss_list:
- 3.7844502480824787
- 3.7362086550394693
- 3.5901732126871746
- 26.300155258178712
- 3.7072061475118003
- 3.4150386174519856
- 23.496656392415364
- 3.2725247701009113
- 21.02568946838379
- 2.9947996362050375
- 2.6343767642974854
- 23.37735969543457
- 16.102032648722332
- 2.497726545333862
- 2.2574545701344806
- 10.238249168395996
- 2.0912214072545368
- 1.998523818651835
- 9.10795841852824
- 16.68396676381429
- 1.8523164987564087
- 1.7634798192977905
- 8.356303469340007
- 1.6914636659622193
- 8.857823893229167
- 1.603798230489095
- 1.5972061204910277
- 18.01238187154134
- 1.500449357032776
- 1.4879448207219441
- 1.4592489878336588
- 1.4361590067545573
- 1.4236476707458496
- 7.258591658274333
- 1.3578279574712118
- 1.3706069707870483
- 1.350844249725342
- 7.09497994740804
- 1.2781153138478596
- 1.2747491089502971
- 1.284094090461731
- 1.2817477480570476
- 12.490015920003255
- 1.2083562421798706
- 6.267934214274089
- 9.144472630818685
- 1.1593689505259197
- 1.1868941831588744
- 5.4928597132364905
- 1.133008364836375
- 1.1350905839602152
- 9.987632675170898
- 1.1051062687238058
- 1.1164221620559693
- 4.90253532409668
- 1.0909845900535584
- 1.1062734405199686
- 1.1182152342796325
- 4.466711285909017
- 1.0941971254348755
- 1.0966513530413309
- 1.102015065352122
- 1.1202008986473084
- 1.131036913394928
- 1.1281960678100587
- 1.1292011761665344
- 1.125094607671102
- 1.1278829209009806
- 1.1263086517651877
- 1.1309288907051087
- 1.1197315128644307
- 7.628582776387533
- 1.0516235582033793
- 4.845410432815552
- 7.103643849690755
- 5.73652037302653
- 0.9756332810719808
- 1.0140360116958618
- 1.0226786645253498
- 1.0436109471321107
- 1.0464072187741598
- 9.417401415507
- 0.9650092856089274
- 0.9739346559842428
- 5.071105359395345
- 5.703244895935058
- 0.877868246237437
- 0.913594643274943
- 0.9297497550646464
- 0.9526125478744507
- 0.9662846430142721
- 0.9743271279335022
- 0.9863382116953532
- 0.9963026086489359
- 1.006142834822337
- 5.704876225789388
- 0.9617733836174012
- 0.9789606650670369
- 0.9760563921928406
- 0.9906208729743957
train_accuracy:
- 0.023
- 0.058
- 0.156
- 1.0
- 0.083
- 0.212
- 1.0
- 0.275
- 1.0
- 0.298
- 0.381
- 1.0
- 1.0
- 0.4
- 0.492
- 1.0
- 0.51
- 0.556
- 1.0
- 1.0
- 0.579
- 0.552
- 1.0
- 0.592
- 1.0
- 0.585
- 0.654
- 1.0
- 0.606
- 0.677
- 0.648
- 0.679
- 0.704
- 1.0
- 0.7
- 0.708
- 0.652
- 1.0
- 0.685
- 0.679
- 0.69
- 0.733
- 1.0
- 0.733
- 1.0
- 1.0
- 0.725
- 0.74
- 1.0
- 0.742
- 0.742
- 1.0
- 0.708
- 0.742
- 1.0
- 0.725
- 0.725
- 0.746
- 1.0
- 0.763
- 0.696
- 0.781
- 0.771
- 0.771
- 0.748
- 0.733
- 0.723
- 0.763
- 0.792
- 0.752
- 0.781
- 1.0
- 0.79
- 1.0
- 1.0
- 1.0
- 0.785
- 0.794
- 0.771
- 0.794
- 0.725
- 0.998
- 0.787
- 0.785
- 1.0
- 1.0
- 0.792
- 0.748
- 0.777
- 0.806
- 0.81
- 0.796
- 0.787
- 0.808
- 0.817
- 1.0
- 0.754
- 0.781
- 0.794
- 0.79
train_loss:
- 3.852
- 3.813
- 3.74
- 0.26
- 4.111
- 3.638
- 0.296
- 3.873
- 0.445
- 3.711
- 3.073
- 0.259
- 0.274
- 3.388
- 2.807
- 0.135
- 2.776
- 2.498
- 0.136
- 0.202
- 2.809
- 2.282
- 0.124
- 2.327
- 0.153
- 2.295
- 2.09
- 0.391
- 2.328
- 2.03
- 1.916
- 1.898
- 1.877
- 0.201
- 1.997
- 1.767
- 1.745
- 0.199
- 1.942
- 1.702
- 1.685
- 1.703
- 0.244
- 1.899
- 0.197
- 0.013
- 1.897
- 1.61
- 0.183
- 1.856
- 1.654
- 0.174
- 1.78
- 1.601
- 0.143
- 1.696
- 1.528
- 1.589
- 0.124
- 1.672
- 1.518
- 1.491
- 1.453
- 1.403
- 1.456
- 1.415
- 1.443
- 1.492
- 1.472
- 1.407
- 1.438
- 0.264
- 1.565
- 0.106
- 0.011
- 0.211
- 1.668
- 1.348
- 1.436
- 1.319
- 1.361
- 0.263
- 1.659
- 1.382
- 0.176
- 0.154
- 1.578
- 1.363
- 1.336
- 1.375
- 1.279
- 1.332
- 1.292
- 1.257
- 1.22
- 0.186
- 1.439
- 1.259
- 1.339
- 1.228
unequal: 0
verbose: 1
