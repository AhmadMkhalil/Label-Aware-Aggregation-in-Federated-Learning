avg_train_accuracy: 0.815
avg_train_loss: 0.013
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02702127659574468
- 0.02127659574468085
- 0.02127659574468085
- 0.021861702127659574
- 0.02127659574468085
- 0.0598404255319149
- 0.10531914893617021
- 0.02127659574468085
- 0.1122872340425532
- 0.22734042553191489
- 0.2896808510638298
- 0.395531914893617
- 0.08829787234042553
- 0.05867021276595745
- 0.43627659574468086
- 0.4775
- 0.510531914893617
- 0.05723404255319149
- 0.5237765957446808
- 0.5457446808510639
- 0.5704787234042553
- 0.5875
- 0.5979255319148936
- 0.6065957446808511
- 0.6137765957446808
- 0.6294148936170213
- 0.13430851063829788
- 0.6263829787234042
- 0.029680851063829786
- 0.6314893617021277
- 0.6375
- 0.6510638297872341
- 0.6542553191489362
- 0.655904255319149
- 0.6690957446808511
- 0.6740425531914893
- 0.11175531914893617
- 0.678936170212766
- 0.6833510638297873
- 0.2077659574468085
- 0.6756914893617021
- 0.6857978723404256
- 0.680372340425532
- 0.6929255319148936
- 0.684468085106383
- 0.688031914893617
- 0.13872340425531915
- 0.706063829787234
- 0.7044680851063829
- 0.3206914893617021
- 0.6986702127659574
- 0.6942553191489361
- 0.2915957446808511
- 0.7094148936170213
- 0.698031914893617
- 0.43670212765957445
- 0.7126595744680851
- 0.17308510638297872
- 0.7151063829787234
- 0.4806382978723404
- 0.18058510638297873
- 0.7151063829787234
- 0.708031914893617
- 0.7135638297872341
- 0.722872340425532
- 0.7209042553191489
- 0.7254255319148936
- 0.7279255319148936
- 0.7287234042553191
- 0.7244680851063829
- 0.7319148936170212
- 0.7211170212765957
- 0.7330851063829787
- 0.7320212765957447
- 0.38835106382978724
- 0.734095744680851
- 0.7336170212765958
- 0.7359574468085106
- 0.7365957446808511
- 0.7373404255319149
- 0.4656382978723404
- 0.7367021276595744
- 0.7406914893617021
- 0.7425
- 0.40867021276595744
- 0.7414893617021276
- 0.7402127659574468
test_loss_list:
- 27.141802876790365
- 32.94805308024088
- 24.433959452311196
- 3.799882001876831
- 3.797505801518758
- 13.608011995951335
- 20.13299285888672
- 23.54581616719564
- 3.8031170908610026
- 3.7944913641611735
- 8.23778242111206
- 10.400641873677571
- 11.856130905151367
- 26.956263631184896
- 3.786638962427775
- 3.772201541264852
- 3.7382075150807696
- 21.593613306681316
- 3.6890444628397625
- 3.5769485092163085
- 17.19249537150065
- 3.458326505025228
- 3.202092056274414
- 2.8892635822296144
- 2.602275234858195
- 7.551090596516927
- 9.715352300008139
- 2.3804494444529216
- 2.2013408851623537
- 2.0565930128097536
- 9.984259643554687
- 1.9029025268554687
- 1.8418500884373983
- 1.74109143892924
- 1.696099166870117
- 1.662067216237386
- 1.6338437541325888
- 1.6137582349777222
- 1.5777415529886882
- 8.29492161432902
- 1.488335812886556
- 13.558956871032715
- 1.3953489828109742
- 1.3763836272557577
- 1.3649207639694214
- 1.3595525646209716
- 1.3585348335901897
- 1.3275195280710856
- 1.310822892189026
- 9.748773714701334
- 1.2772457393010457
- 1.2517281611760458
- 7.005978609720866
- 1.1922591590881348
- 1.1839218544960022
- 1.217624422709147
- 1.190607434908549
- 1.225173069636027
- 1.2318590482076008
- 8.217930742899577
- 1.1471637733777365
- 1.1628164354960124
- 5.084390500386556
- 1.1097274645169577
- 1.1453099624315897
- 6.767787157694499
- 1.02832763671875
- 1.061742738087972
- 4.081426045099894
- 1.033788398106893
- 7.285874684651692
- 1.0154420049985249
- 3.4273760318756104
- 6.361995760599772
- 0.9960041284561157
- 1.0275626548131307
- 1.0411323523521423
- 1.051854423681895
- 1.06231480439504
- 1.067820066610972
- 1.0597329950332641
- 1.0793286593755087
- 1.083869522412618
- 1.065736653804779
- 1.1021676190694174
- 1.0936918346087139
- 1.0959364024798075
- 4.445538959503174
- 0.9753074113527934
- 0.9908525085449219
- 1.01182542403539
- 1.0085058093070984
- 1.0248545702298482
- 3.9015945625305175
- 0.965576191743215
- 0.9847153353691102
- 0.9982827099164328
- 4.194224252700805
- 0.938865168094635
- 0.9545646373430888
train_accuracy:
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.002
- 1.0
- 0.017
- 0.094
- 1.0
- 0.098
- 0.25
- 0.302
- 0.392
- 1.0
- 1.0
- 0.504
- 0.552
- 0.552
- 1.0
- 0.581
- 0.617
- 0.571
- 0.638
- 0.65
- 0.675
- 0.648
- 0.692
- 1.0
- 0.654
- 1.0
- 0.665
- 0.681
- 0.725
- 0.737
- 0.706
- 0.752
- 0.696
- 1.0
- 0.748
- 0.69
- 1.0
- 0.733
- 0.744
- 0.742
- 0.715
- 0.74
- 0.737
- 1.0
- 0.723
- 0.754
- 1.0
- 0.746
- 0.74
- 1.0
- 0.752
- 0.737
- 1.0
- 0.767
- 1.0
- 0.756
- 1.0
- 1.0
- 0.756
- 0.748
- 0.771
- 0.792
- 0.777
- 0.771
- 0.74
- 0.796
- 0.806
- 0.742
- 0.763
- 0.781
- 0.815
- 1.0
- 0.804
- 0.817
- 0.817
- 0.783
- 0.79
- 1.0
- 0.787
- 0.808
- 0.829
- 1.0
- 0.787
- 0.815
train_loss:
- 0.352
- 0.006
- 0.717
- 4.151
- 3.853
- 1.32
- 0.045
- 0.014
- 4.183
- 3.868
- 0.308
- 0.014
- 0.008
- 0.537
- 4.236
- 3.862
- 3.835
- 0.68
- 4.1
- 3.745
- 0.387
- 3.911
- 3.524
- 3.255
- 3.033
- 0.157
- 0.014
- 3.08
- 2.633
- 2.496
- 0.258
- 2.591
- 2.352
- 2.19
- 2.123
- 2.012
- 2.019
- 1.9
- 1.968
- 0.224
- 2.126
- 0.313
- 2.139
- 1.793
- 1.805
- 1.734
- 1.686
- 1.673
- 1.662
- 0.175
- 1.919
- 1.605
- 0.221
- 1.804
- 1.59
- 1.538
- 1.527
- 1.499
- 1.471
- 0.179
- 1.693
- 1.526
- 0.175
- 1.613
- 1.388
- 0.294
- 1.687
- 1.394
- 0.137
- 1.568
- 0.168
- 1.641
- 0.125
- 0.14
- 1.624
- 1.366
- 1.413
- 1.483
- 1.365
- 1.364
- 1.376
- 1.421
- 1.396
- 1.314
- 1.308
- 1.314
- 1.34
- 0.214
- 1.569
- 1.345
- 1.307
- 1.307
- 1.285
- 0.236
- 1.371
- 1.368
- 1.286
- 0.158
- 1.377
- 1.297
unequal: 0
verbose: 1
