avg_train_accuracy: 0.804
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.025053191489361703
- 0.0375
- 0.04425531914893617
- 0.05361702127659575
- 0.09531914893617022
- 0.02127659574468085
- 0.09159574468085106
- 0.15771276595744682
- 0.02127659574468085
- 0.21888297872340426
- 0.02127659574468085
- 0.27414893617021274
- 0.3586170212765957
- 0.409468085106383
- 0.45989361702127657
- 0.02127659574468085
- 0.4979787234042553
- 0.04069148936170213
- 0.5203723404255319
- 0.5474468085106383
- 0.5676063829787235
- 0.11031914893617022
- 0.5793085106382979
- 0.6027127659574468
- 0.6137234042553191
- 0.6232446808510639
- 0.6306914893617022
- 0.6389361702127659
- 0.6488829787234043
- 0.24409574468085107
- 0.6528191489361702
- 0.2773936170212766
- 0.6543085106382979
- 0.07930851063829787
- 0.6629787234042553
- 0.6691489361702128
- 0.29351063829787233
- 0.6733510638297873
- 0.6745212765957447
- 0.6835638297872341
- 0.3247340425531915
- 0.07196808510638297
- 0.6834574468085106
- 0.16744680851063828
- 0.6944148936170212
- 0.2077127659574468
- 0.6969148936170213
- 0.6953723404255319
- 0.1952127659574468
- 0.7036702127659574
- 0.33632978723404255
- 0.7013829787234043
- 0.7037765957446809
- 0.7082446808510638
- 0.7056382978723404
- 0.7100531914893617
- 0.710531914893617
- 0.7111702127659575
- 0.7149468085106383
- 0.7156914893617021
- 0.7204255319148937
- 0.7194148936170213
- 0.725531914893617
- 0.34611702127659577
- 0.7213297872340425
- 0.4207446808510638
- 0.7217553191489362
- 0.7251063829787234
- 0.2901595744680851
- 0.1271808510638298
- 0.735
- 0.7301063829787234
- 0.4498936170212766
- 0.3646808510638298
- 0.7311170212765957
- 0.7316489361702128
- 0.7333510638297872
- 0.21457446808510638
- 0.7381914893617021
- 0.3558510638297872
- 0.7397872340425532
- 0.7339893617021277
- 0.7370744680851063
- 0.7410638297872341
- 0.22430851063829788
- 0.7480851063829788
- 0.7427127659574468
test_loss_list:
- 28.644819819132486
- 26.60162612915039
- 3.8007842286427818
- 16.414138056437174
- 22.619924977620443
- 23.55832354227702
- 3.808997449874878
- 3.802630214691162
- 3.7992702674865724
- 3.797393430074056
- 3.795204381942749
- 3.7920067914326987
- 16.807632675170897
- 3.7749847888946535
- 3.7668259557088217
- 3.7510247866312665
- 3.7253901131947837
- 3.6746340465545653
- 19.191410954793295
- 3.6167604605356853
- 3.457550818125407
- 11.940196482340495
- 3.2481509494781493
- 8.527650578816731
- 3.008796043395996
- 2.7554226525624594
- 2.5286791483561197
- 2.3402368354797365
- 14.97363774617513
- 2.18033358891805
- 9.448968976338705
- 2.044891209602356
- 1.9272685925165811
- 1.825063360532125
- 7.204472942352295
- 1.6899526691436768
- 1.638305778503418
- 1.5988079770406087
- 1.5547307125727337
- 1.5186831537882488
- 1.5016389163335164
- 1.4911524693171183
- 5.8751446024576826
- 1.3981882381439208
- 5.196415042877197
- 1.3873825295766196
- 11.509879595438639
- 1.2753829367955525
- 1.2654524914423624
- 6.820477600097656
- 1.247501942316691
- 1.2374726804097493
- 1.240850075085958
- 5.846643981933593
- 10.33413958231608
- 1.1415603176752727
- 7.276521320343018
- 1.1224000112215677
- 6.1745972887674965
- 1.1264116485913596
- 1.1238318133354186
- 6.201262785593669
- 1.11621551434199
- 4.464571860631307
- 1.0271631836891175
- 1.0405058320363363
- 1.064251495997111
- 1.0694162901242574
- 1.0861902817090352
- 1.096659619808197
- 1.1011941226323445
- 1.1058159796396891
- 1.0948775855700175
- 1.102860533396403
- 1.1088464736938477
- 1.1158219559987386
- 4.874589881896973
- 1.0297393123308818
- 3.82038636525472
- 1.044809055328369
- 1.053645220597585
- 7.003422012329102
- 7.532966842651367
- 0.9036659057935079
- 0.9311181004842123
- 3.446788504918416
- 4.797315902709961
- 0.9004887596766153
- 0.9295338479677836
- 0.9549644430478413
- 6.169071960449219
- 0.9217643149693807
- 5.895544211069743
- 0.8851585920651753
- 0.915991816520691
- 0.9327502139409383
- 0.9408194994926453
- 6.017224197387695
- 0.9109019978841146
- 0.9296188847223917
train_accuracy:
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 0.0
- 0.008
- 0.031
- 0.075
- 1.0
- 0.054
- 0.158
- 1.0
- 0.217
- 1.0
- 0.267
- 0.356
- 0.442
- 0.473
- 1.0
- 0.515
- 1.0
- 0.567
- 0.569
- 0.629
- 1.0
- 0.594
- 0.656
- 0.679
- 0.685
- 0.696
- 0.7
- 0.683
- 1.0
- 0.675
- 1.0
- 0.675
- 1.0
- 0.74
- 0.7
- 1.0
- 0.696
- 0.744
- 0.744
- 1.0
- 0.998
- 0.771
- 0.998
- 0.723
- 0.996
- 0.729
- 0.752
- 0.998
- 0.742
- 1.0
- 0.79
- 0.744
- 0.74
- 0.783
- 0.744
- 0.731
- 0.781
- 0.798
- 0.754
- 0.819
- 0.819
- 0.75
- 1.0
- 0.802
- 1.0
- 0.798
- 0.792
- 1.0
- 0.998
- 0.773
- 0.769
- 1.0
- 1.0
- 0.796
- 0.763
- 0.781
- 0.998
- 0.81
- 1.0
- 0.825
- 0.821
- 0.815
- 0.773
- 0.998
- 0.817
- 0.804
train_loss:
- 0.536
- 0.726
- 4.188
- 1.233
- 0.636
- 0.413
- 4.25
- 3.889
- 3.882
- 3.868
- 3.867
- 3.86
- 0.812
- 4.067
- 3.847
- 3.834
- 3.815
- 3.774
- 0.631
- 4.02
- 3.647
- 0.193
- 3.685
- 0.119
- 3.5
- 3.139
- 2.907
- 2.762
- 0.255
- 2.904
- 0.137
- 2.663
- 2.411
- 2.248
- 0.174
- 2.365
- 2.153
- 2.032
- 1.946
- 1.891
- 1.806
- 1.891
- 0.167
- 1.968
- 0.079
- 1.914
- 0.405
- 2.054
- 1.726
- 0.178
- 1.845
- 1.625
- 1.641
- 0.151
- 0.42
- 1.948
- 0.122
- 1.763
- 0.107
- 1.832
- 1.627
- 0.115
- 1.737
- 0.198
- 1.702
- 1.529
- 1.521
- 1.432
- 1.474
- 1.473
- 1.37
- 1.43
- 1.485
- 1.437
- 1.383
- 1.426
- 0.179
- 1.518
- 0.073
- 1.426
- 1.395
- 0.296
- 0.327
- 1.675
- 1.352
- 0.126
- 0.01
- 1.462
- 1.364
- 1.336
- 0.155
- 1.457
- 0.201
- 1.513
- 1.265
- 1.295
- 1.299
- 0.152
- 1.427
- 1.24
unequal: 0
verbose: 1
