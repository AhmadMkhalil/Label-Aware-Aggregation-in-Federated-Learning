avg_train_accuracy: 0.817
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04159574468085107
- 0.023776595744680853
- 0.06361702127659574
- 0.031117021276595744
- 0.1848404255319149
- 0.22808510638297871
- 0.3017021276595745
- 0.2153723404255319
- 0.39106382978723403
- 0.30127659574468085
- 0.4869148936170213
- 0.36861702127659574
- 0.3895212765957447
- 0.5361170212765958
- 0.44601063829787235
- 0.581968085106383
- 0.608563829787234
- 0.5822872340425532
- 0.4875
- 0.5101063829787233
- 0.62
- 0.6245212765957446
- 0.5454255319148936
- 0.5853191489361702
- 0.5893085106382979
- 0.5780851063829787
- 0.37138297872340426
- 0.6552659574468085
- 0.6115957446808511
- 0.6728723404255319
- 0.6752659574468085
- 0.6802127659574468
- 0.635
- 0.68
- 0.6774468085106383
- 0.6451595744680851
- 0.6877127659574468
- 0.6861170212765958
- 0.7022340425531914
- 0.6644148936170213
- 0.6940425531914893
- 0.6986170212765958
- 0.5548936170212766
- 0.7029787234042553
- 0.5671276595744681
- 0.706436170212766
- 0.7076063829787234
- 0.6968085106382979
- 0.681968085106383
- 0.684468085106383
- 0.6902659574468085
- 0.688404255319149
- 0.7142553191489361
- 0.6953191489361702
- 0.6877127659574468
- 0.7215425531914894
- 0.724095744680851
- 0.7213829787234043
- 0.7156382978723405
- 0.6967021276595745
- 0.608563829787234
- 0.725531914893617
- 0.695531914893617
- 0.7290425531914894
- 0.7254255319148936
- 0.7311170212765957
- 0.7338829787234042
- 0.7306382978723405
- 0.734468085106383
- 0.7326063829787234
- 0.7195744680851064
- 0.7452127659574468
- 0.6754787234042553
- 0.7281914893617021
- 0.728563829787234
- 0.724095744680851
- 0.7246808510638297
- 0.7412765957446809
- 0.7413297872340425
- 0.7524468085106383
- 0.7396276595744681
- 0.7381914893617021
- 0.7350531914893617
- 0.7431382978723404
- 0.7379787234042553
- 0.7406382978723405
- 0.7331382978723404
- 0.7488297872340426
- 0.748031914893617
- 0.7371808510638298
- 0.755
- 0.7478191489361702
- 0.7428191489361702
- 0.7439361702127659
- 0.7525531914893617
- 0.7392553191489362
- 0.7505851063829787
- 0.6936170212765957
- 0.7582978723404256
- 0.7601063829787233
test_loss_list:
- 3.866213893890381
- 3.7386160532633466
- 3.6292435773213705
- 3.6518473339080813
- 3.15049173672994
- 2.893047587076823
- 2.647687873840332
- 2.8910801728566486
- 2.3279424254099528
- 2.4922711435953775
- 2.021944408416748
- 2.221503321329753
- 2.1391014941533406
- 1.754509007136027
- 1.958286420504252
- 1.6399146334330241
- 1.672287564277649
- 1.6069002914428712
- 1.7640936501820883
- 1.6913502073287965
- 1.439008714358012
- 1.455861013730367
- 1.5976117579142253
- 1.4464171775182089
- 1.4484065945943196
- 1.443421155611674
- 2.3404253069559733
- 1.278989675839742
- 1.3982729975382486
- 1.2405739800135294
- 1.2538452132542928
- 1.2530167992909749
- 1.2730414644877115
- 1.1474921409289043
- 1.1683417876561484
- 1.2262843227386475
- 1.1197958517074584
- 1.1401079312960307
- 1.2307149791717529
- 1.2027728652954102
- 1.0924785367647807
- 1.1092752202351888
- 1.5702235078811646
- 1.0300468071301778
- 1.5462583049138388
- 1.0077155447006225
- 1.0124643770853679
- 1.0126644627253214
- 1.048824950059255
- 1.0303826196988424
- 0.992150673866272
- 1.0163721402486166
- 0.980537874698639
- 1.0593640716870625
- 1.005019517739614
- 0.9463809283574423
- 1.0573572071393331
- 0.9881676896413167
- 0.9567756414413452
- 0.9771971003214518
- 1.3843828058242797
- 0.9112413867314657
- 1.0011330588658651
- 1.012967278957367
- 0.9217428851127625
- 0.9169245529174804
- 1.0080089608828227
- 0.921784143447876
- 0.9960984031359355
- 0.9120870486895243
- 0.904517232577006
- 0.8906843511263529
- 1.051156502564748
- 0.8610377184549968
- 0.8693579324086507
- 0.8778984006245931
- 0.8777898414929708
- 0.8668179202079773
- 0.8588247442245484
- 0.8584463572502137
- 0.8684432291984558
- 0.8739852945009867
- 0.8467979208628337
- 0.8348432683944702
- 0.8691257119178772
- 0.8831612133979797
- 0.8979280082384745
- 0.8170911765098572
- 0.8475596920649211
- 0.8550191537539165
- 0.8369107969601949
- 0.8502526617050171
- 0.8411613941192627
- 0.810610036055247
- 0.8258565680185954
- 0.8626057481765748
- 0.8100632794698079
- 1.022520469824473
- 0.793667136033376
- 0.8291138172149658
train_accuracy:
- 0.0
- 0.0
- 0.04
- 1.0
- 0.173
- 0.217
- 0.306
- 0.181
- 0.365
- 0.835
- 0.496
- 0.927
- 0.798
- 0.279
- 0.721
- 0.469
- 0.629
- 0.625
- 0.481
- 0.683
- 0.671
- 0.677
- 0.537
- 0.796
- 0.602
- 0.938
- 0.973
- 0.704
- 0.629
- 0.735
- 0.74
- 0.719
- 0.642
- 0.71
- 0.756
- 0.633
- 0.129
- 0.692
- 0.752
- 0.698
- 0.537
- 0.744
- 0.967
- 0.771
- 0.975
- 0.773
- 0.713
- 0.69
- 0.671
- 0.715
- 0.796
- 0.685
- 0.765
- 0.979
- 0.863
- 0.075
- 0.794
- 0.852
- 0.721
- 0.898
- 0.969
- 0.008
- 0.706
- 0.806
- 0.75
- 0.8
- 0.754
- 0.758
- 0.8
- 0.763
- 0.863
- 0.754
- 0.971
- 0.95
- 0.856
- 0.748
- 0.733
- 0.444
- 0.779
- 0.804
- 0.775
- 0.777
- 0.76
- 0.771
- 0.646
- 0.763
- 0.756
- 0.771
- 0.781
- 0.754
- 0.81
- 0.896
- 0.798
- 0.75
- 0.802
- 0.973
- 0.798
- 0.702
- 0.8
- 0.817
train_loss:
- 2.44
- 3.089
- 3.051
- 2.25
- 2.783
- 2.6
- 2.412
- 1.737
- 2.167
- 1.552
- 1.952
- 1.45
- 1.384
- 1.784
- 1.311
- 1.667
- 2.017
- 1.597
- 1.175
- 1.155
- 1.499
- 1.489
- 1.119
- 1.07
- 1.068
- 1.083
- 0.724
- 1.387
- 1.035
- 1.337
- 1.322
- 1.302
- 0.993
- 1.292
- 1.265
- 0.962
- 1.241
- 1.224
- 1.517
- 0.944
- 1.216
- 1.187
- 0.652
- 1.183
- 0.625
- 1.169
- 1.144
- 0.866
- 0.885
- 0.86
- 0.871
- 0.859
- 1.138
- 0.858
- 0.88
- 1.107
- 1.362
- 1.123
- 0.844
- 0.842
- 0.571
- 1.101
- 0.842
- 1.35
- 0.836
- 1.079
- 1.318
- 0.829
- 1.304
- 0.816
- 0.816
- 1.041
- 0.547
- 0.793
- 0.791
- 0.792
- 0.785
- 1.025
- 1.033
- 1.04
- 1.007
- 1.034
- 0.769
- 1.03
- 1.001
- 0.768
- 0.753
- 1.012
- 0.99
- 0.758
- 0.996
- 0.979
- 0.985
- 0.756
- 0.985
- 0.748
- 0.994
- 0.517
- 0.988
- 0.961
unequal: 0
verbose: 1
