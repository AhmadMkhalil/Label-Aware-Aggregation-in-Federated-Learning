avg_train_accuracy: 0.783
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03170212765957447
- 0.033882978723404254
- 0.03489361702127659
- 0.024787234042553192
- 0.10702127659574467
- 0.33952127659574466
- 0.19132978723404256
- 0.06202127659574468
- 0.4397872340425532
- 0.4326595744680851
- 0.4689893617021277
- 0.28106382978723404
- 0.38648936170212767
- 0.4002127659574468
- 0.43898936170212766
- 0.4465425531914894
- 0.19829787234042554
- 0.5401063829787234
- 0.5927659574468085
- 0.5974468085106382
- 0.6003191489361702
- 0.6210638297872341
- 0.6447340425531914
- 0.6262234042553192
- 0.5243617021276595
- 0.6372340425531915
- 0.5297872340425532
- 0.5731382978723404
- 0.6067021276595744
- 0.612659574468085
- 0.6785638297872341
- 0.668936170212766
- 0.6258510638297873
- 0.6452127659574468
- 0.6453191489361703
- 0.6971808510638298
- 0.5573936170212765
- 0.7016489361702127
- 0.6864893617021277
- 0.6428191489361702
- 0.7003191489361702
- 0.6992553191489361
- 0.5577127659574468
- 0.6810106382978723
- 0.7126595744680851
- 0.6659574468085107
- 0.7165425531914894
- 0.6741489361702128
- 0.7135106382978723
- 0.715
- 0.6177127659574468
- 0.6956382978723404
- 0.6193617021276596
- 0.6891489361702128
- 0.7236702127659574
- 0.7173404255319149
- 0.7298404255319149
- 0.7252659574468086
- 0.728404255319149
- 0.7310106382978724
- 0.6458510638297872
- 0.7081914893617022
- 0.733563829787234
- 0.7296808510638297
- 0.7373936170212766
- 0.7380851063829788
- 0.72
- 0.7397872340425532
- 0.7075
- 0.7405851063829787
- 0.7154787234042553
- 0.7199468085106383
- 0.7425
- 0.722872340425532
- 0.7212765957446808
- 0.7461702127659574
- 0.7419148936170212
- 0.7422340425531915
- 0.741968085106383
- 0.7454787234042554
- 0.7445212765957446
- 0.7240425531914894
- 0.7527127659574468
- 0.7457978723404255
- 0.7503191489361702
- 0.7506914893617022
- 0.7094680851063829
- 0.7506914893617022
- 0.7500531914893617
- 0.7536170212765958
- 0.7516489361702128
- 0.7537765957446808
- 0.7514893617021277
- 0.7528191489361702
- 0.7381382978723404
- 0.7346276595744681
- 0.7570744680851064
- 0.7436170212765958
- 0.7427659574468085
- 0.7538297872340426
test_loss_list:
- 3.793130216598511
- 3.762196305592855
- 3.6656222407023114
- 3.7023167101542156
- 3.2816834513346356
- 2.945365873972575
- 3.000178502400716
- 4.457652956644694
- 2.317016716003418
- 2.292232675552368
- 2.1409068218866985
- 2.480379190444946
- 2.1546811358133953
- 2.1410108184814454
- 2.0248166704177857
- 1.9490011326471965
- 3.2057944997151693
- 1.6702359914779663
- 1.5637326224644978
- 1.5521860885620118
- 1.5596497615178426
- 1.512069238026937
- 1.548357580502828
- 1.4728728834788005
- 1.67311319510142
- 1.3514541467030843
- 1.6395044835408528
- 1.4819476668039957
- 1.3716271050771078
- 1.3557485914230347
- 1.3414130433400473
- 1.2988466469446818
- 1.3322002792358398
- 1.2535222387313842
- 1.260180508295695
- 1.267364691098531
- 1.5526829926172891
- 1.2037616475423176
- 1.1516697120666504
- 1.23466796875
- 1.0960584568977356
- 1.125365940729777
- 1.5280718326568603
- 1.05408535639445
- 1.0068481914202372
- 1.1498416177431743
- 1.0156863045692444
- 1.1013732759157817
- 1.0051761412620543
- 1.0353163782755535
- 1.3380883979797362
- 1.0008996454874675
- 1.3335684537887573
- 1.0273422400156658
- 0.9628075933456421
- 0.974601902961731
- 1.0482219131787618
- 1.0034318073590596
- 1.008591349919637
- 0.9580212926864624
- 1.2002136707305908
- 0.9476940496762594
- 0.9350000667572022
- 0.9377278153101604
- 0.9387228600184123
- 0.9495086781183879
- 0.9454547611872355
- 0.9181097523371379
- 0.9774771134058634
- 0.8766145586967469
- 0.9288371054331461
- 0.9071249707539877
- 0.8634799901644389
- 0.9095836647351583
- 0.8918802404403686
- 0.9428454891840616
- 0.9054927968978882
- 0.8883721009890239
- 0.8816833631197611
- 0.8863768951098124
- 0.8866034825642903
- 0.9197516202926636
- 0.8328420654932658
- 0.875019010702769
- 0.9504476881027222
- 0.9713658340771993
- 0.9417774287859598
- 0.8281917413075764
- 0.8708408506711324
- 0.8856179404258728
- 0.8438495349884033
- 0.9304799612363179
- 0.8775487065315246
- 0.8615933593114217
- 0.8412580482165019
- 0.8532164001464844
- 0.7984356856346131
- 0.8265477927525838
- 0.8278245194753011
- 0.8026993981997173
train_accuracy:
- 0.012
- 0.019
- 0.008
- 0.008
- 0.094
- 0.383
- 0.175
- 0.9
- 0.5
- 0.452
- 0.527
- 0.279
- 0.412
- 0.398
- 0.46
- 0.425
- 0.95
- 0.548
- 0.635
- 0.606
- 0.785
- 0.675
- 0.671
- 0.648
- 0.525
- 0.71
- 0.546
- 0.737
- 0.929
- 0.958
- 0.744
- 0.737
- 0.635
- 0.65
- 0.944
- 0.71
- 0.729
- 0.763
- 0.708
- 0.76
- 0.752
- 0.729
- 0.975
- 0.923
- 0.763
- 0.677
- 0.769
- 0.671
- 0.763
- 0.76
- 0.979
- 0.9
- 0.885
- 0.677
- 0.773
- 0.752
- 0.756
- 0.779
- 0.796
- 0.779
- 0.975
- 0.948
- 0.785
- 0.956
- 0.794
- 0.79
- 0.771
- 0.798
- 0.71
- 0.785
- 0.723
- 0.725
- 0.754
- 0.977
- 0.91
- 0.777
- 0.946
- 0.792
- 0.954
- 0.781
- 0.783
- 0.748
- 0.821
- 0.798
- 0.8
- 0.829
- 0.958
- 0.525
- 0.8
- 0.777
- 0.802
- 0.81
- 0.777
- 0.812
- 0.979
- 0.773
- 0.783
- 0.781
- 0.771
- 0.783
train_loss:
- 3.16
- 3.098
- 3.068
- 2.276
- 2.845
- 3.3
- 1.885
- 1.199
- 2.281
- 2.131
- 2.034
- 1.495
- 1.441
- 1.395
- 1.354
- 1.326
- 0.875
- 1.3
- 1.657
- 1.607
- 1.588
- 1.531
- 1.872
- 1.473
- 1.127
- 1.438
- 1.07
- 1.084
- 1.04
- 1.03
- 1.688
- 1.331
- 1.0
- 0.981
- 0.974
- 1.593
- 0.688
- 1.57
- 1.249
- 0.928
- 1.218
- 1.21
- 0.637
- 0.916
- 1.179
- 0.908
- 1.183
- 0.882
- 1.164
- 1.143
- 0.616
- 0.867
- 0.604
- 0.855
- 1.126
- 1.118
- 1.369
- 1.104
- 1.091
- 1.097
- 0.583
- 0.825
- 1.087
- 1.079
- 1.05
- 1.05
- 0.811
- 1.044
- 0.8
- 1.051
- 0.8
- 0.788
- 1.028
- 0.795
- 0.79
- 1.274
- 1.034
- 1.025
- 1.01
- 1.005
- 0.991
- 0.764
- 1.027
- 1.006
- 1.233
- 1.235
- 0.552
- 0.981
- 0.983
- 0.978
- 0.986
- 1.208
- 0.967
- 0.974
- 0.746
- 0.753
- 0.972
- 0.739
- 0.734
- 0.954
unequal: 0
verbose: 1
