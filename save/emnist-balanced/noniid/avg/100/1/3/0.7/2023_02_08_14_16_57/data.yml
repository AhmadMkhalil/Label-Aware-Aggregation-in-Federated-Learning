avg_train_accuracy: 0.948
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021382978723404257
- 0.05702127659574468
- 0.0647872340425532
- 0.10962765957446809
- 0.0701595744680851
- 0.17085106382978724
- 0.2698936170212766
- 0.4128723404255319
- 0.4330851063829787
- 0.38085106382978723
- 0.32382978723404254
- 0.5370744680851064
- 0.37542553191489364
- 0.5588829787234042
- 0.5820744680851064
- 0.5557978723404255
- 0.6031382978723404
- 0.5913829787234043
- 0.523563829787234
- 0.5553191489361702
- 0.5654255319148936
- 0.5788297872340425
- 0.5838297872340426
- 0.6319148936170212
- 0.6364893617021277
- 0.653936170212766
- 0.6478723404255319
- 0.6735638297872341
- 0.6250531914893617
- 0.6762234042553191
- 0.6678723404255319
- 0.6720744680851064
- 0.6887234042553192
- 0.6810106382978723
- 0.6821276595744681
- 0.6586170212765957
- 0.6892553191489361
- 0.6645744680851063
- 0.6986170212765958
- 0.6961702127659575
- 0.7006382978723404
- 0.6785106382978724
- 0.7047872340425532
- 0.7160106382978724
- 0.7182978723404255
- 0.7059574468085107
- 0.6920744680851064
- 0.7170744680851063
- 0.7135638297872341
- 0.721436170212766
- 0.7194680851063829
- 0.7202659574468085
- 0.7073936170212766
- 0.7257446808510638
- 0.7262234042553192
- 0.7145212765957447
- 0.7143617021276596
- 0.7347872340425532
- 0.7295744680851064
- 0.7313829787234043
- 0.7282978723404255
- 0.7367021276595744
- 0.7389893617021277
- 0.7293085106382978
- 0.7372340425531915
- 0.7376063829787234
- 0.7426063829787234
- 0.7246276595744681
- 0.7401063829787234
- 0.7382446808510639
- 0.7367553191489362
- 0.7439893617021277
- 0.7387234042553191
- 0.732872340425532
- 0.7465425531914893
- 0.7471808510638298
- 0.7408510638297873
- 0.7366489361702128
- 0.7472872340425532
- 0.7458510638297873
- 0.7464893617021277
- 0.7368617021276596
- 0.751436170212766
- 0.7532446808510638
- 0.746968085106383
- 0.7442021276595745
- 0.7527659574468085
- 0.7435106382978723
- 0.7454255319148936
- 0.7513829787234042
- 0.7523404255319149
- 0.7482978723404256
- 0.7511702127659574
- 0.7472872340425532
- 0.753563829787234
- 0.750904255319149
- 0.7611170212765958
- 0.7482446808510639
- 0.7596276595744681
- 0.7463829787234042
test_loss_list:
- 3.800447804133097
- 3.7738255055745444
- 3.7009850343068442
- 3.5805549589792887
- 3.651835085550944
- 3.12588072458903
- 2.771327206293742
- 2.440831416447957
- 2.297519458134969
- 2.294752836227417
- 2.3815971755981447
- 1.9010751215616861
- 2.1817874177296956
- 1.7497118091583252
- 1.7070191287994385
- 1.6505236434936523
- 1.5825331862767538
- 1.5474416414896648
- 1.643068240483602
- 1.5326673062642415
- 1.487508012453715
- 1.4524138069152832
- 1.42815727074941
- 1.2819889084498088
- 1.3050190130869548
- 1.24958110332489
- 1.2531442181269328
- 1.246662228902181
- 1.2840501356124878
- 1.14419664700826
- 1.169437402089437
- 1.1209834051132201
- 1.1035339045524597
- 1.0948183822631836
- 1.0766882880528768
- 1.1428045972188314
- 1.0408240628242493
- 1.1230267214775085
- 1.024940816561381
- 1.0508971627553303
- 1.0438341999053955
- 1.0720868492126465
- 1.0047546807924908
- 1.0491600950558981
- 1.0596019705136617
- 0.9770602003733317
- 1.0069992756843567
- 0.9426748402913412
- 0.9554419223467508
- 1.0711466391881308
- 0.9762479615211487
- 0.9674075388908386
- 0.9542562929789226
- 0.9062951938311259
- 0.9489759620030721
- 0.921036938826243
- 0.9207359592119853
- 0.9372290706634522
- 0.9386994290351868
- 0.9112435054779052
- 0.8796872687339783
- 0.876086581548055
- 0.9239751561482747
- 0.8674774710337321
- 0.86886692126592
- 0.873969452381134
- 0.9141390697161357
- 0.8637673362096151
- 0.8396843719482422
- 0.828889688650767
- 0.834322292804718
- 0.8379545219739278
- 0.8235066604614257
- 0.8404209216435751
- 0.8214567184448243
- 0.8726713911692301
- 0.8180383443832397
- 0.8237931394577026
- 0.8145294650395711
- 0.8126560068130493
- 0.8092995842297872
- 0.8195351266860962
- 0.8401253016789755
- 0.8167378918329875
- 0.8535869558652242
- 0.80531880458196
- 0.7840500434239706
- 0.8002224477132162
- 0.790734121799469
- 0.7732755939165751
- 0.780601905186971
- 0.8447465475400289
- 0.8520514726638794
- 0.8061000911394754
- 0.78420521179835
- 0.7830738123257955
- 0.7679499173164368
- 0.7900994849205017
- 0.7602556029955546
- 0.7898934125900269
train_accuracy:
- 0.0
- 0.917
- 0.088
- 0.096
- 0.931
- 0.15
- 0.271
- 0.406
- 0.46
- 0.348
- 0.792
- 0.073
- 0.346
- 0.608
- 0.625
- 0.252
- 0.642
- 0.375
- 0.735
- 0.531
- 0.527
- 0.565
- 0.55
- 0.646
- 0.74
- 0.577
- 0.652
- 0.715
- 0.821
- 0.704
- 0.679
- 0.683
- 0.754
- 0.71
- 0.723
- 0.629
- 0.729
- 0.887
- 0.471
- 0.694
- 0.725
- 0.967
- 0.74
- 0.769
- 0.771
- 0.731
- 0.688
- 0.752
- 0.76
- 0.783
- 0.537
- 0.75
- 0.781
- 0.577
- 0.787
- 0.775
- 0.685
- 0.804
- 0.79
- 0.554
- 0.769
- 0.479
- 0.804
- 0.781
- 0.771
- 0.781
- 0.794
- 0.165
- 0.792
- 0.773
- 0.783
- 0.537
- 0.604
- 0.692
- 0.812
- 0.796
- 0.708
- 0.769
- 0.808
- 0.704
- 0.769
- 0.815
- 0.492
- 0.79
- 0.802
- 0.796
- 0.662
- 0.74
- 0.76
- 0.792
- 0.698
- 0.815
- 0.821
- 0.798
- 0.8
- 0.821
- 0.796
- 0.76
- 0.51
- 0.948
train_loss:
- 2.929
- 2.819
- 3.294
- 2.721
- 2.089
- 2.443
- 2.275
- 2.537
- 2.358
- 1.869
- 1.446
- 2.066
- 1.34
- 1.937
- 1.856
- 1.517
- 1.761
- 1.436
- 1.132
- 1.107
- 1.083
- 1.093
- 1.063
- 1.292
- 1.283
- 1.27
- 1.249
- 1.455
- 0.991
- 1.192
- 1.179
- 1.162
- 1.159
- 1.134
- 1.127
- 0.924
- 1.112
- 0.891
- 1.111
- 1.087
- 1.075
- 0.86
- 1.062
- 1.264
- 1.238
- 1.055
- 0.831
- 1.025
- 1.023
- 1.411
- 1.016
- 1.007
- 0.833
- 0.995
- 1.178
- 1.002
- 0.81
- 1.172
- 1.156
- 0.962
- 0.959
- 0.956
- 1.14
- 0.959
- 0.946
- 0.945
- 1.117
- 0.76
- 0.925
- 0.929
- 0.926
- 0.929
- 0.93
- 0.74
- 0.904
- 1.083
- 0.927
- 0.739
- 0.898
- 0.898
- 0.897
- 0.727
- 1.065
- 0.911
- 1.054
- 0.73
- 0.883
- 0.714
- 0.708
- 0.876
- 0.889
- 1.041
- 1.04
- 0.873
- 0.877
- 0.709
- 0.864
- 0.716
- 0.866
- 0.705
unequal: 0
verbose: 1
