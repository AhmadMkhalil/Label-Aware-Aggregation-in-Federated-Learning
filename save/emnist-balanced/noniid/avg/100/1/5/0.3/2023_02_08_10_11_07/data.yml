avg_train_accuracy: 0.99
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.021329787234042552
- 0.022127659574468085
- 0.0398936170212766
- 0.04101063829787234
- 0.10303191489361702
- 0.04143617021276596
- 0.3828723404255319
- 0.05585106382978723
- 0.16361702127659575
- 0.251063829787234
- 0.27861702127659577
- 0.13941489361702128
- 0.33085106382978724
- 0.5229787234042553
- 0.36356382978723406
- 0.30367021276595746
- 0.14382978723404255
- 0.560531914893617
- 0.3102659574468085
- 0.11792553191489362
- 0.5721808510638298
- 0.1972872340425532
- 0.24202127659574468
- 0.505904255319149
- 0.5272872340425532
- 0.3225
- 0.33489361702127657
- 0.5535638297872341
- 0.38904255319148934
- 0.5423404255319149
- 0.37
- 0.1851063829787234
- 0.29351063829787233
- 0.5693617021276596
- 0.6218617021276596
- 0.551968085106383
- 0.629468085106383
- 0.4648404255319149
- 0.6084574468085107
- 0.5794148936170213
- 0.4474468085106383
- 0.6495212765957447
- 0.5982978723404255
- 0.43372340425531913
- 0.5814893617021276
- 0.4420212765957447
- 0.6152127659574468
- 0.491436170212766
- 0.6133510638297872
- 0.2881382978723404
- 0.6311170212765957
- 0.6170744680851064
- 0.6260106382978723
- 0.6277659574468085
- 0.3381382978723404
- 0.41260638297872343
- 0.49670212765957444
- 0.5534042553191489
- 0.5244148936170213
- 0.6599468085106382
- 0.6784574468085106
- 0.6477659574468085
- 0.6547872340425532
- 0.6565425531914894
- 0.6404787234042553
- 0.5451595744680852
- 0.4975531914893617
- 0.5176595744680851
- 0.6740425531914893
- 0.6725
- 0.5829787234042553
- 0.47175531914893615
- 0.16393617021276596
- 0.6536702127659575
- 0.6820212765957446
- 0.6506914893617022
- 0.5237234042553192
- 0.5346808510638298
- 0.6775
- 0.6829255319148936
- 0.6628723404255319
- 0.6842021276595744
- 0.6925
- 0.6656914893617021
- 0.6976063829787233
- 0.6790425531914893
- 0.6773404255319149
- 0.6718085106382978
- 0.4001595744680851
- 0.6953191489361702
- 0.7043085106382979
- 0.6262234042553192
- 0.5461702127659575
- 0.7023936170212766
- 0.6522340425531915
- 0.6952659574468085
- 0.6850531914893617
- 0.5704255319148936
test_loss_list:
- 3.9527150122324626
- 5.890620594024658
- 3.874939629236857
- 3.9029500039418537
- 10.701497039794923
- 7.5228469276428225
- 3.2658783785502115
- 5.033017539978028
- 2.8158645915985105
- 4.916029612223308
- 3.1736377747853597
- 2.882824141184489
- 2.703268839518229
- 3.3981269137064616
- 2.543760553995768
- 2.142341987291972
- 2.428955135345459
- 2.5703448836008707
- 3.880476016998291
- 1.9823891067504882
- 2.525102659861247
- 4.427045803070069
- 1.861564515431722
- 3.4735873063405354
- 2.7428427759806313
- 1.7792760531107585
- 1.7792244704564413
- 2.352708152135213
- 2.6556813208262127
- 1.7071981525421143
- 2.0674526500701904
- 1.6253383111953736
- 2.386662302017212
- 3.409357951482137
- 2.6815998299916584
- 1.5287852303187053
- 1.5174458964665731
- 1.6456089607874553
- 1.5464197142918905
- 1.9387617699305217
- 1.4355585670471191
- 1.5551400105158488
- 2.14452867825826
- 1.4314543835322062
- 1.4945404148101806
- 2.0659540367126463
- 1.437930572827657
- 1.8880222765604655
- 1.358848114013672
- 1.8814746872584025
- 1.3660677353541055
- 2.876624822616577
- 1.3164948256810507
- 1.3071978044509889
- 1.272891346613566
- 1.338101668357849
- 3.1463696416219076
- 2.1871016279856366
- 1.9140101782480876
- 1.443679388364156
- 1.7017545541127523
- 1.1502271103858948
- 1.2411918099721273
- 1.3183413044611614
- 1.2458188231786091
- 1.3182011079788207
- 1.236996267636617
- 1.6498512585957845
- 1.9499636109670002
- 1.8967474826176962
- 1.2288587180773418
- 1.1610425599416097
- 1.4839740705490112
- 1.9192526149749756
- 5.0884256935119625
- 1.1367193086942038
- 1.136960245768229
- 1.155224812825521
- 1.593824561436971
- 1.5137676270802816
- 1.0514206377665203
- 1.0937260572115581
- 1.215420757929484
- 1.053268248240153
- 1.0753399006525675
- 1.1854522053400676
- 1.186600641409556
- 1.1714474240938821
- 1.0898152589797974
- 1.148394333521525
- 2.492914072672526
- 0.9989587171872457
- 1.1269230500857035
- 1.2745946915944417
- 1.5208611901601155
- 1.1107884772618613
- 1.1935941807428996
- 1.0077999766667685
- 1.0509155583381653
- 1.5018848832448324
train_accuracy:
- 0.0
- 0.0
- 1.0
- 1.0
- 0.794
- 0.0
- 0.058
- 0.983
- 0.438
- 0.023
- 0.996
- 0.254
- 0.296
- 0.933
- 0.306
- 0.604
- 0.992
- 0.325
- 0.115
- 0.642
- 0.292
- 0.806
- 0.65
- 0.754
- 0.988
- 0.55
- 0.981
- 0.915
- 0.996
- 0.575
- 0.906
- 0.598
- 0.983
- 0.985
- 0.971
- 0.606
- 0.698
- 0.608
- 0.715
- 0.981
- 0.662
- 0.988
- 0.979
- 0.721
- 0.944
- 0.958
- 0.858
- 0.985
- 0.983
- 0.508
- 0.662
- 0.985
- 0.65
- 0.677
- 0.667
- 0.688
- 0.983
- 0.377
- 0.992
- 0.985
- 0.99
- 0.7
- 0.75
- 0.702
- 0.946
- 0.988
- 0.683
- 0.558
- 0.994
- 0.99
- 0.727
- 0.742
- 0.594
- 0.998
- 0.963
- 0.694
- 0.723
- 0.685
- 0.517
- 0.567
- 0.94
- 0.744
- 0.729
- 0.985
- 0.765
- 0.988
- 0.787
- 0.74
- 0.952
- 0.706
- 0.983
- 0.746
- 0.792
- 0.629
- 0.977
- 0.8
- 0.983
- 0.76
- 0.748
- 0.99
train_loss:
- 2.647
- 1.383
- 2.609
- 2.48
- 0.143
- 1.237
- 2.332
- 1.116
- 3.149
- 1.083
- 1.94
- 1.828
- 1.717
- 0.955
- 1.704
- 2.348
- 1.553
- 1.551
- 0.797
- 2.171
- 0.783
- 0.113
- 2.18
- 0.166
- 0.765
- 1.356
- 1.325
- 0.715
- 0.7
- 1.288
- 0.731
- 1.273
- 0.658
- 0.084
- 0.66
- 1.237
- 1.77
- 1.189
- 1.745
- 0.648
- 1.168
- 1.136
- 0.582
- 1.674
- 1.133
- 0.567
- 1.134
- 0.566
- 1.078
- 0.546
- 1.085
- 0.092
- 1.083
- 1.054
- 1.032
- 1.028
- 0.057
- 0.563
- 0.516
- 0.538
- 0.541
- 0.997
- 1.456
- 1.003
- 1.007
- 0.976
- 0.985
- 0.502
- 0.474
- 0.505
- 0.959
- 0.96
- 0.543
- 0.509
- 0.039
- 1.01
- 0.94
- 0.947
- 0.497
- 0.499
- 0.927
- 0.91
- 0.891
- 0.919
- 0.895
- 0.899
- 1.281
- 0.904
- 0.877
- 0.891
- 0.075
- 0.881
- 1.277
- 0.494
- 0.456
- 1.281
- 0.467
- 0.871
- 0.879
- 0.463
unequal: 0
verbose: 1
