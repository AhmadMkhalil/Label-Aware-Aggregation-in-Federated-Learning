avg_train_accuracy: 0.758
avg_train_loss: 0.013
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.025106382978723404
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.024361702127659573
- 0.036542553191489364
- 0.06420212765957446
- 0.02127659574468085
- 0.03632978723404255
- 0.08031914893617022
- 0.1626595744680851
- 0.02127659574468085
- 0.2447872340425532
- 0.3659574468085106
- 0.02127659574468085
- 0.4123936170212766
- 0.46441489361702126
- 0.02127659574468085
- 0.02430851063829787
- 0.4892021276595745
- 0.5159574468085106
- 0.05936170212765957
- 0.5374468085106383
- 0.10143617021276596
- 0.04382978723404255
- 0.5485106382978724
- 0.5648936170212766
- 0.18835106382978722
- 0.07824468085106383
- 0.5769148936170213
- 0.25590425531914895
- 0.5831382978723404
- 0.603563829787234
- 0.2789893617021277
- 0.07393617021276595
- 0.6071276595744681
- 0.6136702127659575
- 0.13797872340425532
- 0.058617021276595745
- 0.02877659574468085
- 0.03930851063829787
- 0.6192021276595745
- 0.31898936170212766
- 0.24101063829787234
- 0.05840425531914894
- 0.6212765957446809
- 0.1345744680851064
- 0.6312234042553192
- 0.6361170212765958
- 0.23340425531914893
- 0.16031914893617022
- 0.07718085106382978
- 0.04303191489361702
- 0.6541489361702127
- 0.6396276595744681
- 0.65
- 0.648563829787234
- 0.6540425531914894
- 0.2170744680851064
- 0.08414893617021277
- 0.09420212765957447
- 0.09212765957446808
- 0.09973404255319149
- 0.10393617021276595
- 0.6666489361702128
- 0.3949468085106383
- 0.27
- 0.6676595744680851
- 0.26468085106382977
- 0.6798936170212766
- 0.36542553191489363
- 0.6826063829787234
- 0.6763829787234042
- 0.6742021276595744
- 0.6810106382978723
- 0.6761170212765958
- 0.2700531914893617
- 0.6954787234042553
- 0.4096808510638298
- 0.691595744680851
- 0.2925
- 0.2098404255319149
- 0.6938297872340425
- 0.3372872340425532
- 0.26691489361702125
- 0.7038297872340425
- 0.10936170212765957
- 0.7014893617021276
- 0.6982446808510638
test_loss_list:
- 28.134529266357422
- 29.461885935465496
- 35.79739451090495
- 21.41810572306315
- 24.151590118408205
- 3.7957647037506104
- 20.946092376708986
- 23.57597930908203
- 3.8040606498718263
- 14.536724065144856
- 21.02681381225586
- 21.55923917134603
- 3.806855748494466
- 3.797560345331828
- 3.792198750178019
- 3.783287337621053
- 3.769673156738281
- 3.7491323852539065
- 12.856272684733073
- 3.7159121004740396
- 3.6282947794596354
- 3.453247054417928
- 21.622183634440105
- 3.261328716278076
- 2.8816759713490803
- 11.129685872395834
- 2.5774007193247477
- 2.3530338986714683
- 13.262073860168456
- 9.374615796407063
- 2.2405770270029706
- 2.080650887489319
- 9.04324119567871
- 1.935525992711385
- 7.184089088439942
- 11.71568239847819
- 1.8031409152348836
- 1.7420187934239706
- 6.8780283292134605
- 7.85383929570516
- 1.6759763209025065
- 5.789348856608073
- 1.6451577854156494
- 1.6135289001464843
- 5.200806039174398
- 8.079876550038655
- 1.5441399717330933
- 1.5474597851435343
- 7.173567695617676
- 7.96963129679362
- 18.607784118652344
- 8.188131955464682
- 1.44089687983195
- 4.903690408070882
- 7.038264382680257
- 10.865479049682618
- 1.4127398761113485
- 7.008140029907227
- 1.3934522946675618
- 1.4163611396153768
- 5.275720577239991
- 7.163429978688558
- 8.042316608428955
- 11.865317509969076
- 1.2446706438064574
- 1.2585545873641968
- 1.2844210704167685
- 1.2959320481618246
- 1.312149667739868
- 5.914604746500651
- 8.82506145477295
- 8.861116180419922
- 7.449995174407959
- 8.556982383728027
- 8.942583109537761
- 1.1541325759887695
- 4.188312193552653
- 5.521495869954427
- 1.1681082073847453
- 5.054168834686279
- 1.1752374203999838
- 4.114205411275228
- 1.1645637647310894
- 1.1897825161616007
- 1.2085358874003092
- 1.2248406314849853
- 1.243523982365926
- 5.088858102162679
- 1.2132147391637167
- 3.7473412227630614
- 1.1478977799415588
- 4.53515871365865
- 6.455384629567464
- 1.159812059402466
- 3.9242904376983643
- 5.358722203572591
- 1.1689595111211142
- 8.288742198944092
- 1.1002014096577961
- 1.125563481648763
train_accuracy:
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.027
- 1.0
- 0.006
- 0.067
- 0.175
- 1.0
- 0.271
- 0.406
- 1.0
- 0.487
- 0.521
- 1.0
- 1.0
- 0.517
- 0.588
- 0.996
- 0.606
- 1.0
- 1.0
- 0.61
- 0.631
- 1.0
- 0.998
- 0.612
- 1.0
- 0.665
- 0.654
- 1.0
- 1.0
- 0.667
- 0.677
- 0.998
- 1.0
- 1.0
- 1.0
- 0.69
- 1.0
- 1.0
- 1.0
- 0.692
- 1.0
- 0.7
- 0.704
- 1.0
- 1.0
- 0.996
- 1.0
- 0.694
- 0.719
- 0.7
- 0.704
- 0.717
- 0.996
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.719
- 1.0
- 1.0
- 0.742
- 0.996
- 0.746
- 1.0
- 0.729
- 0.752
- 0.74
- 0.752
- 0.763
- 0.998
- 0.754
- 1.0
- 0.748
- 0.998
- 0.998
- 0.75
- 0.998
- 0.998
- 0.777
- 1.0
- 0.754
- 0.758
train_loss:
- 0.345
- 0.699
- 0.01
- 0.67
- 0.81
- 4.194
- 1.61
- 0.42
- 4.224
- 0.927
- 0.766
- 0.501
- 4.25
- 3.89
- 3.874
- 3.86
- 3.841
- 3.818
- 0.681
- 4.027
- 3.756
- 3.647
- 0.528
- 3.842
- 3.263
- 0.183
- 3.237
- 2.776
- 0.189
- 0.328
- 2.915
- 2.499
- 0.213
- 2.548
- 0.16
- 0.201
- 2.603
- 2.123
- 0.135
- 0.237
- 2.332
- 0.109
- 2.152
- 1.941
- 0.127
- 0.173
- 2.141
- 1.822
- 0.189
- 0.138
- 0.405
- 0.223
- 2.31
- 0.141
- 0.014
- 0.271
- 2.116
- 0.136
- 1.948
- 1.713
- 0.145
- 0.012
- 0.2
- 0.35
- 2.17
- 1.66
- 1.662
- 1.617
- 1.557
- 0.171
- 0.185
- 0.218
- 0.167
- 0.043
- 0.075
- 1.959
- 0.092
- 0.094
- 1.811
- 0.139
- 1.73
- 0.105
- 1.651
- 1.559
- 1.478
- 1.493
- 1.49
- 0.165
- 1.61
- 0.157
- 1.574
- 0.118
- 0.011
- 1.571
- 0.094
- 0.008
- 1.547
- 0.28
- 1.594
- 1.322
unequal: 0
verbose: 1
