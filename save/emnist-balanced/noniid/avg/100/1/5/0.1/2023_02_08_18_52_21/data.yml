avg_train_accuracy: 0.996
avg_train_loss: 0.002
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02143617021276596
- 0.020053191489361702
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02297872340425532
- 0.02127659574468085
- 0.02127659574468085
- 0.03861702127659575
- 0.039946808510638296
- 0.041382978723404254
- 0.1623936170212766
- 0.02127659574468085
- 0.23952127659574468
- 0.02127659574468085
- 0.3040425531914894
- 0.029574468085106383
- 0.34345744680851065
- 0.02297872340425532
- 0.38122340425531914
- 0.02127659574468085
- 0.0325531914893617
- 0.41925531914893616
- 0.4476063829787234
- 0.4748404255319149
- 0.4951063829787234
- 0.5148936170212766
- 0.5297340425531915
- 0.06611702127659574
- 0.045
- 0.5347340425531915
- 0.5535106382978724
- 0.5631382978723404
- 0.1950531914893617
- 0.5727127659574468
- 0.5831914893617022
- 0.593404255319149
- 0.26404255319148934
- 0.05936170212765957
- 0.6032446808510639
- 0.30601063829787234
- 0.609468085106383
- 0.3465957446808511
- 0.6125531914893617
- 0.1325531914893617
- 0.09117021276595745
- 0.06617021276595744
- 0.6134042553191489
- 0.1971276595744681
- 0.1371276595744681
- 0.6323936170212766
- 0.24686170212765957
- 0.23930851063829786
- 0.6217553191489362
- 0.11351063829787233
- 0.08015957446808511
- 0.6262765957446809
- 0.6345744680851064
- 0.3468085106382979
- 0.19351063829787235
- 0.08143617021276596
- 0.6479255319148937
- 0.18329787234042552
- 0.6492021276595744
- 0.6459574468085106
- 0.28829787234042553
- 0.19936170212765958
- 0.1472872340425532
- 0.6435106382978724
- 0.37186170212765957
- 0.6497340425531914
- 0.6540425531914894
- 0.36898936170212765
- 0.10313829787234043
- 0.04989361702127659
- 0.0625531914893617
- 0.05351063829787234
- 0.13446808510638297
- 0.6774468085106383
- 0.33787234042553194
- 0.1696808510638298
- 0.6732978723404255
- 0.4125531914893617
- 0.16382978723404254
test_loss_list:
- 29.252224324544272
- 3.799675464630127
- 3.7958163928985598
- 29.695119781494142
- 3.8008624903361
- 3.7972868474324546
- 22.15473861694336
- 3.8086796124776203
- 19.5399875386556
- 28.194323018391927
- 26.86344607035319
- 3.8149609343210855
- 13.551221555074056
- 19.135898768107097
- 17.67511868794759
- 22.37495897928874
- 3.8396727148691814
- 3.8190780035654703
- 14.281033477783204
- 3.822458880742391
- 17.816607666015624
- 3.7934396012624103
- 11.229717661539713
- 13.83722671508789
- 3.776326414744059
- 3.7431428464253744
- 3.662573124567668
- 3.4752844047546385
- 16.12349614461263
- 3.2824302037556965
- 20.42437810262044
- 2.9971595732371012
- 9.052249768575033
- 2.764750216801961
- 9.62979549407959
- 2.556746346155802
- 15.451485595703126
- 8.636889813741048
- 2.386198565165202
- 2.2439608256022137
- 2.1691401274998983
- 2.0853048356374106
- 2.050794030825297
- 2.022320801417033
- 8.541011072794596
- 8.30616132736206
- 1.9093897422154744
- 1.8771604776382447
- 1.8548177925745646
- 6.319218985239664
- 1.7882476774851481
- 1.8023868338267008
- 1.7963052733739218
- 5.41508160273234
- 11.10030029296875
- 1.6237028169631957
- 4.791496073404948
- 1.5871159871419271
- 4.165039596557617
- 1.5859005641937256
- 9.872998034159343
- 8.30378054936727
- 11.001298128763835
- 1.4563601128260295
- 6.931621545155843
- 9.519886945088704
- 1.4237511698404948
- 7.306807282765706
- 5.3082906468709306
- 1.3813772010803222
- 9.461753794352214
- 13.503789405822754
- 1.3144150018692016
- 1.3167551279067993
- 4.058824351628622
- 6.3802386538187665
- 8.574436620076497
- 1.2252684577306112
- 6.488292630513509
- 1.2398288106918336
- 1.2746689732869465
- 6.409215901692709
- 9.630435028076171
- 12.60843282063802
- 1.2764471594492595
- 4.57225877126058
- 1.2781507380803425
- 1.3069565041859945
- 3.8940367126464843
- 7.807454217274984
- 8.466233717600504
- 8.616897258758545
- 8.194612604777019
- 5.151726856231689
- 1.1096726926167806
- 4.569348481496175
- 6.476580982208252
- 1.117449464003245
- 3.3657083384195965
- 6.428518975575765
train_accuracy:
- 1.0
- 0.0
- 0.023
- 1.0
- 0.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.15
- 1.0
- 0.219
- 1.0
- 0.298
- 0.998
- 0.36
- 1.0
- 0.438
- 1.0
- 0.998
- 0.427
- 0.481
- 0.542
- 0.55
- 0.581
- 0.604
- 1.0
- 1.0
- 0.592
- 0.654
- 0.648
- 1.0
- 0.685
- 0.66
- 0.654
- 1.0
- 1.0
- 0.654
- 1.0
- 0.706
- 1.0
- 0.685
- 1.0
- 1.0
- 1.0
- 0.713
- 1.0
- 1.0
- 0.679
- 1.0
- 1.0
- 0.692
- 1.0
- 1.0
- 0.685
- 0.727
- 1.0
- 1.0
- 0.998
- 0.7
- 0.998
- 0.737
- 0.692
- 1.0
- 1.0
- 1.0
- 0.698
- 1.0
- 0.731
- 0.742
- 1.0
- 0.996
- 0.996
- 1.0
- 1.0
- 1.0
- 0.706
- 1.0
- 1.0
- 0.723
- 1.0
- 0.996
train_loss:
- 0.243
- 4.193
- 3.839
- 0.771
- 4.184
- 3.845
- 1.68
- 4.131
- 1.26
- 0.033
- 1.024
- 4.286
- 2.315
- 0.661
- 0.586
- 0.024
- 4.329
- 3.937
- 1.065
- 4.146
- 1.332
- 4.145
- 0.481
- 0.305
- 4.148
- 3.88
- 3.816
- 3.672
- 0.534
- 3.815
- 0.488
- 3.65
- 0.212
- 3.352
- 0.199
- 3.141
- 0.417
- 0.274
- 3.157
- 2.633
- 2.524
- 2.373
- 2.288
- 2.187
- 0.195
- 0.327
- 2.497
- 2.15
- 2.037
- 0.143
- 2.155
- 1.948
- 1.866
- 0.127
- 0.327
- 2.246
- 0.094
- 1.987
- 0.093
- 1.89
- 0.296
- 0.366
- 0.017
- 2.157
- 0.154
- 0.014
- 2.036
- 0.157
- 0.166
- 2.009
- 0.384
- 0.027
- 2.042
- 1.72
- 0.138
- 0.176
- 0.191
- 2.035
- 0.128
- 1.815
- 1.684
- 0.198
- 0.023
- 0.017
- 1.907
- 0.114
- 1.746
- 1.567
- 0.153
- 0.209
- 0.326
- 0.073
- 0.286
- 0.125
- 2.086
- 0.099
- 0.155
- 1.794
- 0.117
- 0.189
unequal: 0
verbose: 1
