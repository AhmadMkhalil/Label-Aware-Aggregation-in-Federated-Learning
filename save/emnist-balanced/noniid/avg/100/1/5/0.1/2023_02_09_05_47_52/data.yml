avg_train_accuracy: 0.769
avg_train_loss: 0.015
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.020691489361702127
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.029893617021276596
- 0.021382978723404257
- 0.02127659574468085
- 0.02127659574468085
- 0.030425531914893618
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.024946808510638296
- 0.02946808510638298
- 0.10797872340425532
- 0.02127659574468085
- 0.09914893617021277
- 0.02127659574468085
- 0.15175531914893617
- 0.21813829787234043
- 0.2992021276595745
- 0.02127659574468085
- 0.02127659574468085
- 0.028829787234042552
- 0.02622340425531915
- 0.02127659574468085
- 0.02276595744680851
- 0.28585106382978726
- 0.035106382978723406
- 0.021861702127659574
- 0.34164893617021275
- 0.40867021276595744
- 0.07622340425531915
- 0.0350531914893617
- 0.033457446808510635
- 0.03526595744680851
- 0.4272872340425532
- 0.4653191489361702
- 0.4922340425531915
- 0.128031914893617
- 0.06063829787234042
- 0.5218085106382979
- 0.5304787234042553
- 0.15856382978723405
- 0.5681914893617022
- 0.573031914893617
- 0.2124468085106383
- 0.5828191489361703
- 0.5927659574468085
- 0.6042553191489362
- 0.03207446808510638
- 0.04904255319148936
- 0.04058510638297872
- 0.06260638297872341
- 0.05388297872340426
- 0.611968085106383
- 0.6218085106382979
- 0.6127659574468085
- 0.12292553191489362
- 0.09579787234042553
- 0.620904255319149
- 0.630904255319149
- 0.6325
- 0.31813829787234044
- 0.1675
- 0.1250531914893617
- 0.09888297872340425
- 0.6505319148936171
- 0.6573404255319149
- 0.6548936170212766
- 0.6618617021276596
- 0.6526595744680851
- 0.2952659574468085
- 0.6553723404255319
- 0.6678723404255319
- 0.3051595744680851
- 0.6645212765957447
- 0.6727659574468086
- 0.6748404255319149
- 0.22952127659574467
- 0.06515957446808511
- 0.6893085106382979
- 0.3783510638297872
- 0.20462765957446807
- 0.11292553191489361
- 0.14356382978723403
- 0.6934574468085106
- 0.22138297872340426
- 0.7039893617021277
- 0.6905851063829788
- 0.6860106382978723
- 0.6908510638297872
- 0.6858510638297872
- 0.6892553191489361
- 0.6902659574468085
test_loss_list:
- 3.7880797894795735
- 24.32482561747233
- 30.03462412516276
- 23.351938145955405
- 3.7947240670522056
- 18.34769297281901
- 20.26256108601888
- 17.307424392700195
- 16.321108220418296
- 3.8073274993896487
- 3.800823465983073
- 16.95111661275228
- 22.245078481038412
- 3.7968786080678303
- 12.806444854736329
- 3.796164083480835
- 3.783837095896403
- 3.7660505326588947
- 3.7385972531636558
- 3.686359198888143
- 12.189251225789388
- 3.6119257609049478
- 9.603076705932617
- 3.463338867823283
- 3.2540441099802653
- 3.036345771153768
- 14.488215370178223
- 18.228629786173503
- 8.680702603658041
- 10.975107561747233
- 15.283986854553223
- 11.613773714701335
- 3.0895022710164386
- 8.795147031148275
- 13.082885322570801
- 2.8015008989969887
- 2.583211520512899
- 7.7695898373921715
- 12.72459582010905
- 9.576407051086425
- 11.006982968648275
- 2.4094129276275633
- 2.198758004506429
- 2.1005457623799644
- 8.033325951894124
- 7.8164222653706865
- 1.9866164191563924
- 1.920693105061849
- 5.682237739562988
- 1.8299372784296672
- 1.7754705890019735
- 6.769681981404623
- 1.724171913464864
- 1.69883425394694
- 1.6769593318303426
- 14.146738828023274
- 8.972247098286946
- 10.192064119974772
- 7.320019601186116
- 8.286287797292074
- 1.5059994665781657
- 1.4355092589060465
- 1.4554271014531452
- 7.810909474690755
- 8.27262664159139
- 1.4269606860478719
- 1.4086935997009278
- 1.4264515511194864
- 4.122338542938232
- 6.905101051330567
- 8.985578358968098
- 6.918143062591553
- 1.2989187399546305
- 1.2974189186096192
- 1.31850154876709
- 1.312181323369344
- 1.331634685198466
- 6.392317657470703
- 1.2818542512257893
- 1.2924492692947387
- 5.0348320579528805
- 1.2344155645370483
- 1.2635505517323813
- 1.2751367664337159
- 5.95061580657959
- 9.603632329305013
- 1.151638609568278
- 4.02504602432251
- 5.594577000935872
- 7.355152575174968
- 6.079555257161458
- 1.0773403517405191
- 5.632317028045654
- 1.0572868839899698
- 1.1100694902737935
- 1.1310741662979127
- 1.1323330267270406
- 1.1667127561569215
- 1.1674793076515197
- 1.197597614924113
train_accuracy:
- 0.025
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.092
- 1.0
- 0.094
- 1.0
- 0.169
- 0.237
- 0.325
- 1.0
- 1.0
- 0.998
- 1.0
- 1.0
- 0.998
- 0.258
- 1.0
- 1.0
- 0.346
- 0.44
- 0.992
- 1.0
- 1.0
- 1.0
- 0.475
- 0.527
- 0.544
- 1.0
- 1.0
- 0.552
- 0.617
- 1.0
- 0.625
- 0.629
- 1.0
- 0.669
- 0.681
- 0.673
- 1.0
- 1.0
- 1.0
- 0.992
- 1.0
- 0.673
- 0.713
- 0.708
- 1.0
- 1.0
- 0.694
- 0.704
- 0.715
- 1.0
- 1.0
- 1.0
- 0.992
- 0.675
- 0.746
- 0.715
- 0.74
- 0.742
- 1.0
- 0.742
- 0.756
- 1.0
- 0.769
- 0.75
- 0.769
- 0.996
- 0.998
- 0.754
- 1.0
- 0.998
- 0.996
- 1.0
- 0.737
- 1.0
- 0.783
- 0.75
- 0.754
- 0.779
- 0.769
- 0.785
- 0.769
train_loss:
- 3.848
- 0.644
- 0.009
- 0.728
- 4.135
- 1.45
- 0.635
- 0.371
- 0.355
- 4.148
- 3.883
- 1.729
- 0.341
- 4.234
- 0.909
- 4.122
- 3.894
- 3.865
- 3.831
- 3.779
- 0.307
- 3.929
- 0.181
- 3.785
- 3.453
- 3.234
- 0.249
- 0.392
- 0.41
- 0.013
- 0.315
- 0.101
- 3.736
- 0.233
- 0.215
- 3.399
- 2.907
- 0.146
- 0.587
- 0.263
- 0.25
- 3.364
- 2.698
- 2.532
- 0.158
- 0.196
- 2.659
- 2.34
- 0.105
- 2.337
- 2.149
- 0.164
- 2.218
- 2.02
- 1.926
- 0.253
- 0.549
- 0.241
- 0.276
- 0.212
- 2.602
- 1.96
- 1.897
- 0.147
- 0.215
- 2.09
- 1.8
- 1.717
- 0.127
- 0.157
- 0.011
- 0.204
- 2.086
- 1.755
- 1.64
- 1.645
- 1.643
- 0.248
- 1.745
- 1.562
- 0.181
- 1.737
- 1.512
- 1.48
- 0.2
- 0.274
- 1.827
- 0.148
- 0.112
- 0.163
- 0.23
- 1.862
- 0.119
- 1.697
- 1.527
- 1.472
- 1.462
- 1.425
- 1.42
- 1.453
unequal: 0
verbose: 1
