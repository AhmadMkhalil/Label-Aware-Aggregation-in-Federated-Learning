avg_train_accuracy: 1.0
avg_train_loss: 0.002
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.022127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.03031914893617021
- 0.035
- 0.041382978723404254
- 0.07537234042553191
- 0.10122340425531914
- 0.12420212765957447
- 0.20372340425531915
- 0.02127659574468085
- 0.2579787234042553
- 0.02127659574468085
- 0.32904255319148934
- 0.045159574468085106
- 0.021382978723404257
- 0.39537234042553193
- 0.4315425531914894
- 0.4673936170212766
- 0.02127659574468085
- 0.02127659574468085
- 0.028351063829787235
- 0.5110638297872341
- 0.0275
- 0.5330851063829787
- 0.095
- 0.5518617021276596
- 0.16095744680851065
- 0.5684574468085106
- 0.02946808510638298
- 0.034574468085106384
- 0.5818617021276595
- 0.13632978723404254
- 0.6025
- 0.08202127659574468
- 0.6081382978723404
- 0.1949468085106383
- 0.6032978723404255
- 0.27377659574468083
- 0.16414893617021276
- 0.12351063829787234
- 0.09228723404255319
- 0.6258510638297873
- 0.2765957446808511
- 0.6338829787234043
- 0.30372340425531913
- 0.6438829787234043
- 0.025691489361702128
- 0.20308510638297872
- 0.11925531914893617
- 0.6546276595744681
- 0.11920212765957447
- 0.12664893617021278
- 0.6480851063829787
- 0.6452659574468085
- 0.32345744680851063
- 0.06367021276595744
- 0.6673404255319149
- 0.6660106382978723
- 0.6651595744680852
- 0.6639893617021276
- 0.6597872340425532
- 0.6620212765957447
- 0.6671808510638297
- 0.6670744680851064
- 0.07579787234042554
- 0.20904255319148937
- 0.6921808510638298
- 0.3980851063829787
- 0.31409574468085105
- 0.6853191489361702
- 0.34797872340425534
- 0.6755851063829788
- 0.6759042553191489
- 0.36031914893617023
- 0.28627659574468084
- 0.691063829787234
- 0.4084042553191489
- 0.694468085106383
- 0.42345744680851066
- 0.1201063829787234
- 0.07643617021276596
- 0.7076595744680851
- 0.6967021276595745
- 0.6935106382978723
- 0.6870744680851064
- 0.11372340425531915
test_loss_list:
- 28.45556142171224
- 23.171106389363608
- 22.004778696695965
- 3.8001156012217203
- 3.797285919189453
- 15.543254966735839
- 20.020523300170897
- 20.035591990152994
- 19.861396052042643
- 3.8001459376017253
- 15.946754302978515
- 3.7948331610361734
- 21.805110117594403
- 3.7873779106140137
- 13.859778683980306
- 16.047227541605633
- 3.7770738474527996
- 3.7657553323109947
- 3.749877233505249
- 3.7196692911783855
- 3.663954823811849
- 3.5464785703023276
- 3.364926904042562
- 17.330010884602864
- 3.185126298268636
- 11.810978546142579
- 2.944087136586507
- 9.35316396077474
- 9.67632625579834
- 2.720747127532959
- 2.4709793663024904
- 2.314281638463338
- 14.917522608439128
- 18.059573720296225
- 8.601017430623372
- 2.1910962597529093
- 9.728700103759765
- 1.9426882235209146
- 6.884643955230713
- 1.8473094495137532
- 7.311484546661377
- 1.7511840867996216
- 11.578743845621744
- 8.724885762532551
- 1.626037351290385
- 6.644460182189942
- 1.5373864396413168
- 9.600409228006999
- 1.51187997341156
- 5.408207149505615
- 1.4698421271642048
- 4.504881728490194
- 6.156965001424154
- 6.388889802296957
- 8.054966888427735
- 1.4357779773076376
- 4.752713273366292
- 1.4208204332987469
- 4.460126384099325
- 1.4111823240915935
- 12.034702987670899
- 4.519975191752116
- 8.7321852684021
- 1.3094431718190511
- 7.56370854695638
- 5.54190351486206
- 1.2278667561213175
- 1.2455796480178833
- 4.15012310663859
- 8.97601587931315
- 1.225939426422119
- 1.2306769402821858
- 1.249487582842509
- 1.261937804222107
- 1.2845569928487142
- 1.28398193359375
- 1.3043369722366334
- 1.3050587860743206
- 8.660902137756347
- 5.673056246439616
- 1.2256071345011392
- 3.5790484110514322
- 4.801827723185221
- 1.1507995216051738
- 5.512420641581217
- 1.122795422077179
- 1.1576745494206746
- 4.27060284614563
- 5.8461108462015785
- 1.1369233202934266
- 4.175333773295085
- 1.1328707536061604
- 3.572268994649251
- 8.720055821736654
- 12.648191083272298
- 1.058707405726115
- 1.081949737071991
- 1.1043965713183086
- 1.1390416916211445
- 7.810849952697754
train_accuracy:
- 1.0
- 1.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 1.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.012
- 0.048
- 0.083
- 0.094
- 0.219
- 1.0
- 0.258
- 1.0
- 0.373
- 1.0
- 1.0
- 0.444
- 0.508
- 0.556
- 1.0
- 1.0
- 1.0
- 0.6
- 1.0
- 0.633
- 1.0
- 0.681
- 1.0
- 0.662
- 1.0
- 1.0
- 0.629
- 1.0
- 0.685
- 0.996
- 0.646
- 1.0
- 0.669
- 1.0
- 1.0
- 1.0
- 1.0
- 0.746
- 1.0
- 0.677
- 1.0
- 0.719
- 1.0
- 1.0
- 1.0
- 0.713
- 0.998
- 1.0
- 0.683
- 0.742
- 1.0
- 1.0
- 0.763
- 0.744
- 0.767
- 0.779
- 0.771
- 0.752
- 0.781
- 0.746
- 1.0
- 1.0
- 0.746
- 1.0
- 1.0
- 0.779
- 1.0
- 0.769
- 0.744
- 1.0
- 1.0
- 0.752
- 0.998
- 0.804
- 1.0
- 0.998
- 1.0
- 0.806
- 0.767
- 0.798
- 0.758
- 1.0
train_loss:
- 0.434
- 0.567
- 0.769
- 4.181
- 3.854
- 0.98
- 0.023
- 0.504
- 0.727
- 4.19
- 0.572
- 4.112
- 1.334
- 4.161
- 0.504
- 0.317
- 4.126
- 3.864
- 3.832
- 3.799
- 3.768
- 3.677
- 3.545
- 0.352
- 3.659
- 0.185
- 3.4
- 0.3
- 0.203
- 3.257
- 2.781
- 2.545
- 0.244
- 0.008
- 0.365
- 2.741
- 0.41
- 2.614
- 0.117
- 2.383
- 0.235
- 2.304
- 0.337
- 0.191
- 2.391
- 0.177
- 2.203
- 0.162
- 2.145
- 0.144
- 2.018
- 0.092
- 0.155
- 0.095
- 0.009
- 2.096
- 0.081
- 1.894
- 0.071
- 1.862
- 0.289
- 0.2
- 0.222
- 2.092
- 0.221
- 0.177
- 1.956
- 1.673
- 0.097
- 0.268
- 1.901
- 1.639
- 1.576
- 1.525
- 1.465
- 1.516
- 1.444
- 1.503
- 0.176
- 0.208
- 1.652
- 0.19
- 0.01
- 1.656
- 0.239
- 1.609
- 1.453
- 0.117
- 0.012
- 1.589
- 0.143
- 1.515
- 0.083
- 0.271
- 0.022
- 1.692
- 1.402
- 1.374
- 1.378
- 0.213
unequal: 0
verbose: 1
