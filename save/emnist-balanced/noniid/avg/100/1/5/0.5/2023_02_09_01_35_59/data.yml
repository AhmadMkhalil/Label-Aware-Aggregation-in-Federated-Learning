avg_train_accuracy: 0.581
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021861702127659574
- 0.02303191489361702
- 0.02574468085106383
- 0.06074468085106383
- 0.04664893617021276
- 0.1553723404255319
- 0.13654255319148936
- 0.2976063829787234
- 0.22670212765957448
- 0.21691489361702126
- 0.4132446808510638
- 0.2568617021276596
- 0.1879787234042553
- 0.13617021276595745
- 0.34117021276595744
- 0.4970212765957447
- 0.40452127659574466
- 0.21712765957446808
- 0.33861702127659576
- 0.49803191489361703
- 0.5178191489361702
- 0.47585106382978726
- 0.5192021276595745
- 0.19994680851063829
- 0.5334042553191489
- 0.3231914893617021
- 0.5574468085106383
- 0.6000531914893616
- 0.4754255319148936
- 0.5601595744680851
- 0.34154255319148935
- 0.4420212765957447
- 0.4956382978723404
- 0.15643617021276596
- 0.4371808510638298
- 0.29212765957446807
- 0.5900531914893618
- 0.2772872340425532
- 0.620531914893617
- 0.6012234042553192
- 0.40345744680851064
- 0.6317021276595745
- 0.5547340425531915
- 0.6287234042553191
- 0.5451595744680852
- 0.5528723404255319
- 0.5372340425531915
- 0.5363829787234042
- 0.6222872340425532
- 0.6681382978723405
- 0.5779255319148936
- 0.6613829787234042
- 0.6450531914893617
- 0.6404255319148936
- 0.5683510638297873
- 0.5773404255319149
- 0.660904255319149
- 0.673936170212766
- 0.5432446808510638
- 0.6697872340425531
- 0.4750531914893617
- 0.6818085106382978
- 0.6204255319148936
- 0.5756914893617021
- 0.5852127659574468
- 0.6849468085106383
- 0.6711170212765958
- 0.6079787234042553
- 0.43867021276595747
- 0.5617021276595745
- 0.6913297872340426
- 0.6137234042553191
- 0.5808510638297872
- 0.6995744680851064
- 0.42186170212765955
- 0.7040425531914893
- 0.6798936170212766
- 0.5406914893617021
- 0.6906382978723404
- 0.7054787234042553
- 0.6435106382978724
- 0.706968085106383
- 0.688936170212766
- 0.6887765957446809
- 0.7055851063829788
- 0.701968085106383
- 0.6319148936170212
- 0.6370744680851064
- 0.6315957446808511
- 0.6313297872340425
- 0.7136702127659574
- 0.7030851063829787
- 0.6440957446808511
- 0.6472872340425532
- 0.7206382978723405
- 0.7003723404255319
- 0.7203191489361702
- 0.663563829787234
- 0.6472872340425532
- 0.6339361702127659
test_loss_list:
- 4.102655092875163
- 4.2335851160685225
- 4.185951271057129
- 4.2713423983256025
- 4.385687389373779
- 3.2249827988942465
- 3.172376759847005
- 2.76238702138265
- 2.9233144410451253
- 2.8952318223317466
- 2.3989270718892417
- 2.869231929779053
- 3.4919855054219564
- 4.156307916641236
- 2.3558576901753745
- 1.9697785234451295
- 2.1828536796569824
- 3.188508030573527
- 2.413663215637207
- 1.9068619108200073
- 1.8602945311864216
- 1.9216769345601399
- 1.7990769735972088
- 3.4109941895802818
- 1.6770024188359578
- 2.574448159535726
- 1.6435065762201946
- 1.620278836886088
- 1.7892548147837322
- 1.553099020322164
- 2.393695913950602
- 1.9280510870615641
- 1.715748791694641
- 4.96565060933431
- 1.9020614210764568
- 2.8474820772806804
- 1.3582527017593384
- 3.0836585172017417
- 1.2996344788869223
- 1.3877079709370932
- 2.1142928647994994
- 1.2730604966481527
- 1.547893230120341
- 1.2940982580184937
- 1.5159389400482177
- 1.5234907754262288
- 1.5802087672551473
- 1.6137714497248332
- 1.2434650166829426
- 1.211531639099121
- 1.4144531361262003
- 1.1529450217882793
- 1.1727218500773111
- 1.153730869293213
- 1.4608745956420899
- 1.407100618680318
- 1.118725299835205
- 1.1030158106486003
- 1.6121934636433919
- 1.1302445944150288
- 1.9481975237528484
- 1.1235243153572083
- 1.252592544555664
- 1.4716015164057414
- 1.367814826965332
- 1.0150857949256897
- 1.068999814192454
- 1.330804402033488
- 2.237835070292155
- 1.5268319209416708
- 0.9865590564409892
- 1.299837589263916
- 1.4158930317560832
- 0.9658579262097676
- 2.409048426946004
- 1.0129415408770244
- 1.0410540580749512
- 1.6794649283091228
- 0.9763272643089295
- 0.9427691396077474
- 1.1708896279335022
- 0.952624393304189
- 1.0181703225771586
- 1.0055998762448628
- 0.9436755394935608
- 0.942446391582489
- 1.1942229350407918
- 1.1684427706400553
- 1.1748878455162048
- 1.2584420585632323
- 0.9113111567497253
- 0.9490880020459493
- 1.1399394130706788
- 1.095621550877889
- 0.9787868428230285
- 0.995070305665334
- 0.9267210690180461
- 1.1155932410558065
- 1.1768459955851236
- 1.200235211054484
train_accuracy:
- 1.0
- 0.994
- 0.175
- 0.0
- 0.948
- 0.156
- 0.865
- 0.769
- 0.902
- 0.79
- 0.552
- 0.869
- 0.84
- 0.692
- 0.35
- 0.56
- 0.39
- 0.979
- 0.908
- 0.569
- 0.56
- 0.6
- 0.515
- 0.927
- 0.735
- 0.973
- 0.623
- 0.696
- 0.81
- 0.565
- 0.308
- 0.933
- 0.967
- 0.96
- 0.935
- 0.944
- 0.923
- 0.985
- 0.646
- 0.606
- 0.963
- 0.717
- 0.542
- 0.64
- 0.975
- 0.494
- 0.494
- 0.975
- 0.804
- 0.748
- 0.562
- 0.715
- 0.656
- 0.652
- 0.985
- 0.938
- 0.798
- 0.75
- 0.502
- 0.781
- 0.979
- 0.731
- 0.617
- 0.973
- 0.581
- 0.902
- 0.694
- 0.983
- 0.988
- 0.519
- 0.704
- 0.923
- 0.517
- 0.704
- 0.973
- 0.787
- 0.94
- 0.506
- 0.702
- 0.696
- 0.956
- 0.785
- 0.71
- 0.783
- 0.704
- 0.748
- 0.983
- 0.973
- 0.892
- 0.988
- 0.948
- 0.767
- 0.983
- 0.633
- 0.763
- 0.944
- 0.76
- 0.981
- 0.912
- 0.581
train_loss:
- 1.764
- 1.616
- 1.596
- 1.551
- 1.5
- 2.828
- 1.981
- 2.455
- 1.723
- 1.645
- 2.097
- 1.505
- 0.996
- 0.538
- 1.461
- 1.826
- 1.347
- 0.896
- 0.87
- 1.269
- 1.654
- 1.234
- 1.197
- 0.453
- 1.194
- 0.784
- 1.155
- 1.483
- 0.788
- 1.109
- 0.74
- 0.745
- 0.727
- 0.046
- 0.755
- 0.387
- 1.053
- 0.378
- 1.067
- 1.01
- 0.378
- 1.356
- 0.67
- 1.008
- 0.68
- 0.667
- 0.658
- 0.664
- 0.971
- 1.26
- 0.663
- 0.938
- 0.945
- 0.919
- 0.629
- 0.619
- 0.922
- 0.896
- 0.634
- 1.191
- 0.342
- 1.18
- 0.613
- 0.603
- 0.6
- 0.867
- 0.844
- 0.585
- 0.305
- 0.589
- 0.84
- 0.568
- 0.589
- 0.838
- 0.3
- 1.124
- 0.841
- 0.304
- 0.834
- 0.836
- 0.569
- 0.822
- 0.813
- 0.811
- 0.819
- 0.806
- 0.539
- 0.558
- 0.548
- 0.534
- 0.788
- 0.775
- 0.522
- 0.532
- 1.034
- 0.767
- 0.787
- 0.535
- 0.516
- 0.531
unequal: 0
verbose: 1
