avg_train_accuracy: 0.796
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021329787234042552
- 0.037819148936170215
- 0.023563829787234043
- 0.041329787234042556
- 0.04228723404255319
- 0.04196808510638298
- 0.1046808510638298
- 0.0725
- 0.08180851063829787
- 0.16867021276595745
- 0.08446808510638298
- 0.17835106382978724
- 0.45904255319148934
- 0.2103191489361702
- 0.3669148936170213
- 0.23569148936170212
- 0.25930851063829785
- 0.14627659574468085
- 0.2796808510638298
- 0.3995744680851064
- 0.43670212765957445
- 0.47829787234042553
- 0.2296276595744681
- 0.4971276595744681
- 0.5585638297872341
- 0.37563829787234043
- 0.551595744680851
- 0.5201595744680851
- 0.3902127659574468
- 0.41382978723404257
- 0.3971276595744681
- 0.39398936170212767
- 0.5717021276595745
- 0.38553191489361704
- 0.398031914893617
- 0.4921808510638298
- 0.5937765957446809
- 0.39835106382978724
- 0.6042021276595745
- 0.27324468085106385
- 0.6057446808510638
- 0.5704787234042553
- 0.44941489361702125
- 0.48398936170212764
- 0.6059574468085106
- 0.4441489361702128
- 0.4927127659574468
- 0.461968085106383
- 0.45914893617021274
- 0.6254787234042554
- 0.4854255319148936
- 0.6298936170212766
- 0.6571808510638298
- 0.6056914893617021
- 0.4645744680851064
- 0.6354255319148936
- 0.47297872340425534
- 0.6419680851063829
- 0.31617021276595747
- 0.3572872340425532
- 0.32728723404255317
- 0.5253723404255319
- 0.6597340425531915
- 0.5318617021276596
- 0.6667553191489362
- 0.49196808510638296
- 0.3540957446808511
- 0.6703191489361702
- 0.5434042553191489
- 0.6722872340425532
- 0.658936170212766
- 0.5340425531914894
- 0.6804255319148936
- 0.6697872340425531
- 0.5395212765957447
- 0.5773936170212766
- 0.683936170212766
- 0.5596808510638298
- 0.5763829787234043
- 0.6918617021276596
- 0.5744148936170212
- 0.6756382978723404
- 0.6627659574468086
- 0.42840425531914894
- 0.5727127659574468
- 0.6052127659574468
- 0.6118617021276596
- 0.6941489361702128
- 0.7009042553191489
- 0.5768085106382979
- 0.7015957446808511
- 0.7003723404255319
- 0.7006382978723404
- 0.6292553191489362
- 0.7053723404255319
- 0.7172340425531915
- 0.7102659574468085
- 0.7046808510638298
- 0.6971808510638298
- 0.7088297872340426
test_loss_list:
- 4.621909923553467
- 3.76118865331014
- 4.172043533325195
- 3.6639587465922037
- 4.2618115234375
- 5.075148499806722
- 3.22767302831014
- 4.822828845977783
- 4.455585899353028
- 2.9501128514607746
- 4.204500179290772
- 3.017422631581624
- 2.2819611485799154
- 2.9550402386983237
- 2.2551695473988853
- 2.8016351795196535
- 2.619861567815145
- 3.900001881917318
- 2.558600746790568
- 2.036615088780721
- 2.0222050046920774
- 1.9083668931325277
- 3.073942813873291
- 1.8784348742167154
- 1.7790659983952841
- 2.24251682917277
- 1.6627530765533447
- 1.6875175380706786
- 2.18891717116038
- 2.0164501841863
- 2.1414455207188925
- 2.1765700912475587
- 1.4982570648193358
- 2.279045057296753
- 2.1421352672576903
- 1.6843280919392905
- 1.4171625391642253
- 2.191238241195679
- 1.4336430072784423
- 3.226884625752767
- 1.3782382027308147
- 1.468467461268107
- 1.9166477394104005
- 1.7911233854293824
- 1.2991034777959187
- 1.978400117556254
- 1.7281703027089437
- 1.8047569290796917
- 1.9096968364715576
- 1.2621326875686645
- 1.7742254304885865
- 1.2150606505076091
- 1.2770801464716592
- 1.344018219312032
- 1.8765880409876505
- 1.21088663260142
- 1.8284498723347982
- 1.2150942929585775
- 3.0948239262898762
- 2.6618379306793214
- 3.0211334864298505
- 1.6467949231465657
- 1.1003863064448038
- 1.6746486536661784
- 1.0839262620608012
- 1.7081076335906982
- 2.790988410313924
- 1.0623320388793944
- 1.564659865697225
- 1.0579610935846964
- 1.0867466259002685
- 1.5891963322957356
- 1.0628708418210346
- 1.1048474502563477
- 1.5629847558339436
- 1.4003081274032594
- 1.0018408370018006
- 1.5648129924138388
- 1.3913117424647012
- 1.0464752538998923
- 1.4759787638982138
- 1.0375978144009907
- 1.046710664431254
- 2.2147811301549276
- 1.4593086051940918
- 1.319981149037679
- 1.2593290424346923
- 0.9666382336616516
- 1.0150970236460368
- 1.4461969343821208
- 1.0318417239189148
- 1.024621720314026
- 1.0351105467478434
- 1.230352479616801
- 0.9551418749491374
- 1.050058090686798
- 1.0240469249089559
- 0.9765733091036478
- 0.9924397603670756
- 0.9975410254796346
train_accuracy:
- 0.0
- 0.006
- 0.09
- 0.867
- 0.04
- 0.99
- 0.119
- 0.523
- 0.015
- 0.815
- 0.99
- 0.56
- 0.463
- 0.173
- 0.388
- 0.981
- 0.915
- 0.952
- 0.921
- 0.379
- 0.965
- 0.898
- 0.973
- 0.525
- 0.623
- 0.958
- 0.765
- 0.51
- 0.956
- 0.896
- 0.4
- 0.981
- 0.877
- 0.373
- 0.358
- 0.469
- 0.744
- 0.969
- 0.646
- 0.931
- 0.719
- 0.604
- 0.423
- 0.977
- 0.665
- 0.448
- 0.963
- 0.942
- 0.469
- 0.671
- 0.983
- 0.677
- 0.769
- 0.898
- 0.96
- 0.925
- 0.967
- 0.91
- 0.977
- 0.956
- 0.217
- 0.977
- 0.692
- 0.971
- 0.713
- 0.948
- 0.971
- 0.721
- 0.96
- 0.71
- 0.833
- 0.965
- 0.71
- 0.698
- 0.967
- 0.973
- 0.737
- 0.519
- 0.548
- 0.769
- 0.975
- 0.742
- 0.729
- 0.971
- 0.975
- 0.981
- 0.983
- 0.729
- 0.806
- 0.973
- 0.773
- 0.731
- 0.929
- 0.981
- 0.763
- 0.806
- 0.49
- 0.771
- 0.852
- 0.796
train_loss:
- 1.105
- 3.137
- 1.62
- 2.253
- 1.465
- 0.734
- 2.02
- 0.67
- 0.658
- 1.808
- 0.615
- 1.139
- 2.122
- 1.047
- 1.484
- 0.989
- 0.96
- 0.488
- 0.92
- 1.354
- 1.319
- 1.27
- 0.868
- 1.269
- 1.618
- 0.823
- 1.182
- 1.176
- 0.786
- 0.771
- 0.746
- 0.76
- 1.103
- 0.751
- 0.745
- 0.741
- 1.064
- 0.735
- 1.052
- 0.393
- 1.07
- 1.03
- 0.707
- 0.688
- 1.011
- 0.679
- 0.667
- 0.665
- 0.667
- 0.965
- 0.659
- 0.958
- 1.254
- 0.931
- 0.633
- 0.926
- 0.63
- 0.922
- 0.335
- 0.345
- 0.326
- 0.616
- 0.907
- 0.626
- 0.905
- 0.618
- 0.315
- 0.911
- 0.584
- 0.867
- 0.89
- 0.602
- 0.886
- 0.858
- 0.599
- 0.58
- 0.841
- 0.575
- 0.574
- 1.111
- 0.569
- 0.818
- 0.822
- 0.311
- 0.567
- 0.553
- 0.555
- 0.818
- 1.076
- 0.562
- 1.063
- 0.816
- 0.786
- 0.548
- 0.784
- 1.025
- 1.033
- 0.772
- 0.793
- 1.012
unequal: 0
verbose: 1
