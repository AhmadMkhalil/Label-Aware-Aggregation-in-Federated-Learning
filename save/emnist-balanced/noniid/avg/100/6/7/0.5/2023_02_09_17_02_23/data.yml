avg_train_accuracy: 0.906
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03404255319148936
- 0.11617021276595745
- 0.08367021276595744
- 0.08670212765957447
- 0.08787234042553191
- 0.15595744680851065
- 0.16654255319148936
- 0.19430851063829788
- 0.16446808510638297
- 0.13558510638297872
- 0.09861702127659575
- 0.18771276595744682
- 0.24106382978723404
- 0.16686170212765958
- 0.2272340425531915
- 0.19138297872340426
- 0.23627659574468085
- 0.1298936170212766
- 0.26574468085106384
- 0.10888297872340426
- 0.24398936170212765
- 0.2779255319148936
- 0.26893617021276595
- 0.2882446808510638
- 0.2725531914893617
- 0.27622340425531916
- 0.30936170212765957
- 0.28095744680851065
- 0.20824468085106382
- 0.24819148936170213
- 0.24164893617021277
- 0.2372340425531915
- 0.23154255319148936
- 0.22361702127659575
- 0.308936170212766
- 0.33372340425531916
- 0.3457978723404255
- 0.3403191489361702
- 0.3278723404255319
- 0.3471808510638298
- 0.3330851063829787
- 0.346968085106383
- 0.3696808510638298
- 0.2473936170212766
- 0.3034574468085106
- 0.29382978723404257
- 0.2730851063829787
- 0.3532446808510638
- 0.3477659574468085
- 0.3769148936170213
- 0.2448404255319149
- 0.30611702127659574
- 0.4050531914893617
- 0.4052659574468085
- 0.25292553191489364
- 0.3880851063829787
- 0.3305851063829787
- 0.2738829787234043
- 0.37909574468085105
- 0.3078723404255319
- 0.3795212765957447
- 0.30856382978723407
- 0.285531914893617
- 0.321968085106383
- 0.31340425531914895
- 0.30553191489361703
- 0.1778723404255319
- 0.33351063829787236
- 0.3981914893617021
- 0.32441489361702125
- 0.4104255319148936
- 0.4221808510638298
- 0.33228723404255317
- 0.3115425531914894
- 0.2051063829787234
- 0.4384574468085106
- 0.39
- 0.39622340425531916
- 0.3169148936170213
- 0.4596276595744681
- 0.42696808510638296
- 0.4173936170212766
- 0.39930851063829786
- 0.35085106382978726
- 0.4501063829787234
- 0.4422340425531915
- 0.45132978723404255
- 0.21420212765957447
- 0.4182446808510638
- 0.36920212765957444
- 0.4402659574468085
- 0.44101063829787235
- 0.3502659574468085
- 0.41867021276595745
- 0.17797872340425533
- 0.3557446808510638
- 0.3521808510638298
- 0.45606382978723403
- 0.34888297872340424
- 0.3701595744680851
test_loss_list:
- 4.764740486145019
- 4.148283058802287
- 6.476037165323893
- 4.896171798706055
- 4.546545607248942
- 3.56536935488383
- 3.5384210999806722
- 3.3243186060587564
- 3.6772382418314615
- 3.757815059026082
- 5.456595942179362
- 3.420331497192383
- 3.3154289023081462
- 3.8355632559458415
- 3.2477325057983397
- 3.9565838623046874
- 3.364709269205729
- 3.7082909393310546
- 3.141165771484375
- 5.16619696299235
- 3.414319003423055
- 3.032628777821859
- 3.0707634544372557
- 3.087038227717082
- 3.5478835773468016
- 3.0261292552947996
- 3.620222692489624
- 3.1785507361094156
- 3.9269135125478107
- 3.540153074264526
- 3.738310070037842
- 3.430952606201172
- 3.8246950562795003
- 4.0133997948964435
- 3.3951645374298094
- 3.2421848265329998
- 2.996942590077718
- 3.279198932647705
- 3.0701484870910645
- 3.2288092041015624
- 3.2218754227956135
- 3.2337448914845783
- 2.958780272801717
- 4.117587283452352
- 3.2039879385630288
- 3.485832986831665
- 3.6878994369506835
- 3.13351349512736
- 3.0589936288197834
- 3.0230135536193847
- 3.9351035722096763
- 3.5337846024831134
- 2.951296590169271
- 3.209839013417562
- 4.260028654734294
- 3.216398935317993
- 3.2321763324737547
- 3.5449595197041828
- 3.21262796719869
- 3.517019135157267
- 3.174516388575236
- 3.4818816153208414
- 3.6491700267791747
- 3.2490981006622315
- 3.5056350485483807
- 3.7550790945688886
- 4.911491540273031
- 3.377560609181722
- 3.049718055725098
- 3.3846555932362876
- 3.02961882909139
- 3.028737440109253
- 3.5937090142567953
- 3.6743640931447348
- 5.085054105122884
- 2.8590221277872723
- 3.153931179046631
- 3.224718786875407
- 3.467399984995524
- 2.862843561172485
- 3.065944175720215
- 3.2182380040486653
- 3.4342334365844724
- 3.5250738525390624
- 2.868690347671509
- 2.9647456137339274
- 2.987329616546631
- 4.65377503712972
- 3.1028424453735353
- 3.3238412030537923
- 3.1121998469034833
- 3.1818167114257814
- 3.560761941274007
- 3.2097369956970216
- 5.410467542012532
- 3.7753273169199626
- 3.63775673866272
- 2.9156797313690186
- 3.6899401473999025
- 3.541916780471802
train_accuracy:
- 0.212
- 0.535
- 0.808
- 0.81
- 0.825
- 0.035
- 0.023
- 0.065
- 0.04
- 0.071
- 0.863
- 0.648
- 0.027
- 0.85
- 0.04
- 0.092
- 0.058
- 0.017
- 0.406
- 0.902
- 0.698
- 0.027
- 0.721
- 0.079
- 0.044
- 0.11
- 0.019
- 0.125
- 0.058
- 0.012
- 0.002
- 0.067
- 0.008
- 0.892
- 0.029
- 0.765
- 0.731
- 0.098
- 0.085
- 0.719
- 0.127
- 0.031
- 0.142
- 0.062
- 0.002
- 0.877
- 0.91
- 0.627
- 0.042
- 0.119
- 0.042
- 0.821
- 0.123
- 0.037
- 0.019
- 0.025
- 0.017
- 0.102
- 0.115
- 0.921
- 0.017
- 0.923
- 0.931
- 0.892
- 0.912
- 0.002
- 0.048
- 0.892
- 0.083
- 0.915
- 0.098
- 0.129
- 0.104
- 0.008
- 0.954
- 0.579
- 0.108
- 0.004
- 0.113
- 0.133
- 0.148
- 0.09
- 0.74
- 0.0
- 0.062
- 0.787
- 0.113
- 0.0
- 0.142
- 0.056
- 0.071
- 0.154
- 0.106
- 0.142
- 0.973
- 0.898
- 0.919
- 0.158
- 0.135
- 0.906
train_loss:
- 1.919
- 1.281
- 1.018
- 0.866
- 0.928
- 0.911
- 0.866
- 0.843
- 0.717
- 0.728
- 0.666
- 0.689
- 0.684
- 0.623
- 0.636
- 0.62
- 0.672
- 0.669
- 0.621
- 0.578
- 0.601
- 0.666
- 0.606
- 0.56
- 0.6
- 0.597
- 0.563
- 0.559
- 0.519
- 0.548
- 0.496
- 0.49
- 0.483
- 0.462
- 0.478
- 0.511
- 0.491
- 0.463
- 0.468
- 0.466
- 0.47
- 0.448
- 0.469
- 0.411
- 0.454
- 0.424
- 0.423
- 0.44
- 0.438
- 0.431
- 0.379
- 0.413
- 0.413
- 0.398
- 0.378
- 0.421
- 0.38
- 0.416
- 0.419
- 0.378
- 0.411
- 0.377
- 0.417
- 0.362
- 0.336
- 0.352
- 0.352
- 0.361
- 0.369
- 0.368
- 0.367
- 0.4
- 0.323
- 0.376
- 0.315
- 0.41
- 0.401
- 0.38
- 0.316
- 0.409
- 0.358
- 0.362
- 0.339
- 0.348
- 0.334
- 0.358
- 0.37
- 0.297
- 0.374
- 0.306
- 0.36
- 0.348
- 0.318
- 0.334
- 0.334
- 0.325
- 0.294
- 0.358
- 0.321
- 0.283
unequal: 0
verbose: 1
