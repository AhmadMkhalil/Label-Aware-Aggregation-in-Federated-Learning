avg_train_accuracy: 0.142
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05558510638297872
- 0.06170212765957447
- 0.09606382978723405
- 0.08361702127659575
- 0.1275
- 0.11446808510638298
- 0.08606382978723404
- 0.15680851063829787
- 0.18867021276595744
- 0.10952127659574468
- 0.0999468085106383
- 0.21148936170212765
- 0.21574468085106382
- 0.25579787234042556
- 0.2546276595744681
- 0.2348936170212766
- 0.2746808510638298
- 0.27835106382978725
- 0.2958510638297872
- 0.3019148936170213
- 0.19739361702127659
- 0.21856382978723404
- 0.26601063829787236
- 0.1926595744680851
- 0.22356382978723405
- 0.2931382978723404
- 0.29079787234042553
- 0.2936170212765957
- 0.20595744680851064
- 0.31574468085106383
- 0.23622340425531915
- 0.33877659574468083
- 0.2641489361702128
- 0.32159574468085106
- 0.22888297872340427
- 0.3252127659574468
- 0.32340425531914896
- 0.354468085106383
- 0.3301063829787234
- 0.26904255319148934
- 0.33180851063829786
- 0.34308510638297873
- 0.35382978723404257
- 0.2745744680851064
- 0.30606382978723407
- 0.2623936170212766
- 0.28888297872340424
- 0.3377127659574468
- 0.23287234042553193
- 0.14803191489361703
- 0.3338829787234043
- 0.2752659574468085
- 0.3000531914893617
- 0.37813829787234043
- 0.2885106382978723
- 0.2987234042553191
- 0.32872340425531915
- 0.3984042553191489
- 0.43164893617021277
- 0.3829787234042553
- 0.1723936170212766
- 0.31420212765957445
- 0.15611702127659574
- 0.33191489361702126
- 0.15978723404255318
- 0.18425531914893617
- 0.3592021276595745
- 0.4026063829787234
- 0.2506914893617021
- 0.3321276595744681
- 0.4021276595744681
- 0.42861702127659573
- 0.42031914893617023
- 0.30484042553191487
- 0.42425531914893616
- 0.4356914893617021
- 0.4165957446808511
- 0.41654255319148936
- 0.4097872340425532
- 0.43617021276595747
- 0.32648936170212767
- 0.43148936170212765
- 0.45074468085106384
- 0.35936170212765955
- 0.4667021276595745
- 0.19547872340425532
- 0.42
- 0.46047872340425533
- 0.32611702127659575
- 0.4416489361702128
- 0.4718085106382979
- 0.3518085106382979
- 0.3554787234042553
- 0.42351063829787233
- 0.33835106382978725
- 0.4618617021276596
- 0.21553191489361703
- 0.42148936170212764
- 0.31117021276595747
- 0.4566489361702128
test_loss_list:
- 4.254661051432292
- 5.630959250132243
- 4.077217953999837
- 7.425303440093995
- 3.8853719361623127
- 3.6765146446228028
- 4.845387388865153
- 3.5679175949096678
- 3.5785537433624266
- 3.8949702231089276
- 5.679863300323486
- 3.280892244974772
- 3.3725251547495523
- 3.300579179128011
- 3.329926595687866
- 3.5500842316945396
- 3.197264134089152
- 3.3238366508483885
- 3.23472638130188
- 3.385247065226237
- 3.880507911046346
- 3.741926517486572
- 3.1966433715820313
- 3.684985389709473
- 3.7520101006825763
- 3.2513507048288983
- 3.2101433658599854
- 3.17526748975118
- 3.6039138412475586
- 3.028858620325724
- 3.678483985265096
- 2.9717918968200685
- 3.52138201713562
- 3.156402724583944
- 3.8310164801279702
- 2.93593466758728
- 3.0998129081726074
- 3.121303930282593
- 3.2704166189829507
- 3.643015693028768
- 3.0881704330444335
- 3.266241423288981
- 3.15461363474528
- 3.914946428934733
- 3.6703589502970377
- 3.957311054865519
- 3.9798479715983075
- 3.1340207862854004
- 4.271784852345784
- 4.808852996826172
- 3.097185328801473
- 3.945773639678955
- 3.2104709116617838
- 3.1456098206837972
- 3.5746105607350667
- 3.6178154691060382
- 3.110499172210693
- 3.079170389175415
- 2.8180159505208335
- 3.1513707129160564
- 5.445044600168864
- 3.7193416945139566
- 6.131978969573975
- 3.126545794804891
- 5.487750186920166
- 4.959433046976725
- 3.0425612703959146
- 3.0181178506215414
- 3.9593194262186686
- 3.210162401199341
- 3.0666434288024904
- 2.8650997829437257
- 2.8801083056132
- 3.630926554997762
- 2.958197310765584
- 2.8768540223439536
- 3.111226011912028
- 3.008955071767171
- 3.2507550303141275
- 3.0219177913665773
- 3.4751429080963137
- 2.8043540318806968
- 2.9468145815531415
- 3.1964642906188967
- 2.8445738538106284
- 5.269755134582519
- 2.945808407465617
- 2.9137567965189617
- 3.6344858423868813
- 2.9277758185068765
- 2.8732004006703695
- 3.5674122174580893
- 3.573630386988322
- 2.9940517552693686
- 3.7179064750671387
- 2.9502763811747235
- 4.814611873626709
- 3.040340935389201
- 3.7873414834340413
- 3.042449967066447
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.808
- 0.629
- 0.008
- 0.0
- 0.367
- 0.123
- 0.0
- 0.875
- 0.458
- 0.027
- 0.01
- 0.054
- 0.044
- 0.0
- 0.058
- 0.044
- 0.106
- 0.004
- 0.033
- 0.031
- 0.881
- 0.015
- 0.1
- 0.031
- 0.058
- 0.877
- 0.102
- 0.906
- 0.06
- 0.042
- 0.137
- 0.91
- 0.6
- 0.11
- 0.133
- 0.046
- 0.102
- 0.083
- 0.727
- 0.09
- 0.102
- 0.044
- 0.923
- 0.119
- 0.056
- 0.075
- 0.952
- 0.123
- 0.919
- 0.885
- 0.806
- 0.079
- 0.096
- 0.865
- 0.071
- 0.025
- 0.108
- 0.006
- 0.1
- 0.054
- 0.869
- 0.017
- 0.081
- 0.123
- 0.863
- 0.942
- 0.904
- 0.029
- 0.088
- 0.075
- 0.142
- 0.748
- 0.077
- 0.156
- 0.792
- 0.106
- 0.096
- 0.021
- 0.119
- 0.775
- 0.925
- 0.758
- 0.006
- 0.106
- 0.098
- 0.048
- 0.748
- 0.835
- 0.085
- 0.117
- 0.119
- 0.037
- 0.129
- 0.956
- 0.096
- 0.933
- 0.142
train_loss:
- 2.34
- 1.434
- 1.136
- 0.887
- 0.863
- 0.834
- 0.835
- 0.853
- 0.786
- 0.708
- 0.64
- 0.672
- 0.716
- 0.6
- 0.646
- 0.642
- 0.53
- 0.612
- 0.533
- 0.534
- 0.505
- 0.573
- 0.575
- 0.507
- 0.559
- 0.522
- 0.56
- 0.495
- 0.488
- 0.475
- 0.447
- 0.457
- 0.481
- 0.508
- 0.504
- 0.457
- 0.505
- 0.454
- 0.473
- 0.432
- 0.455
- 0.406
- 0.432
- 0.402
- 0.416
- 0.407
- 0.388
- 0.465
- 0.371
- 0.361
- 0.457
- 0.393
- 0.396
- 0.407
- 0.365
- 0.386
- 0.385
- 0.361
- 0.43
- 0.374
- 0.372
- 0.357
- 0.331
- 0.389
- 0.345
- 0.339
- 0.372
- 0.353
- 0.34
- 0.347
- 0.318
- 0.359
- 0.345
- 0.338
- 0.345
- 0.308
- 0.316
- 0.37
- 0.352
- 0.343
- 0.363
- 0.355
- 0.307
- 0.356
- 0.322
- 0.312
- 0.323
- 0.319
- 0.325
- 0.343
- 0.293
- 0.295
- 0.295
- 0.301
- 0.306
- 0.305
- 0.304
- 0.345
- 0.308
- 0.344
unequal: 0
verbose: 1
