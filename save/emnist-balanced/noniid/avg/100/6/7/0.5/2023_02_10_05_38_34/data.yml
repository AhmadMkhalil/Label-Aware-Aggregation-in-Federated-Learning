avg_train_accuracy: 0.11
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.035159574468085104
- 0.08356382978723405
- 0.09920212765957447
- 0.09686170212765957
- 0.13031914893617022
- 0.10643617021276595
- 0.1848936170212766
- 0.11308510638297872
- 0.1150531914893617
- 0.21515957446808512
- 0.21382978723404256
- 0.16382978723404254
- 0.09654255319148936
- 0.19638297872340427
- 0.2274468085106383
- 0.2351063829787234
- 0.14909574468085107
- 0.2515425531914894
- 0.24654255319148935
- 0.16914893617021276
- 0.25872340425531914
- 0.19696808510638297
- 0.2932446808510638
- 0.18861702127659574
- 0.2679787234042553
- 0.2945212765957447
- 0.22404255319148936
- 0.3204255319148936
- 0.20175531914893616
- 0.1300531914893617
- 0.30829787234042555
- 0.21670212765957447
- 0.3158510638297872
- 0.31643617021276593
- 0.33287234042553193
- 0.2324468085106383
- 0.2822340425531915
- 0.3215425531914894
- 0.34617021276595744
- 0.3510106382978723
- 0.3599468085106383
- 0.35723404255319147
- 0.34856382978723405
- 0.2693617021276596
- 0.3633510638297872
- 0.14430851063829786
- 0.3153723404255319
- 0.27877659574468083
- 0.26867021276595743
- 0.4023404255319149
- 0.3617021276595745
- 0.3798936170212766
- 0.37617021276595747
- 0.38872340425531915
- 0.30042553191489363
- 0.4223936170212766
- 0.2823404255319149
- 0.3887765957446809
- 0.2834042553191489
- 0.30117021276595746
- 0.4031382978723404
- 0.3675
- 0.41319148936170214
- 0.3201063829787234
- 0.3390957446808511
- 0.43409574468085105
- 0.3246276595744681
- 0.3253723404255319
- 0.3486170212765957
- 0.35845744680851066
- 0.16324468085106383
- 0.41388297872340424
- 0.3270212765957447
- 0.35898936170212764
- 0.40914893617021275
- 0.45074468085106384
- 0.44324468085106383
- 0.30829787234042555
- 0.2001595744680851
- 0.36404255319148937
- 0.32159574468085106
- 0.45617021276595743
- 0.33606382978723404
- 0.17627659574468085
- 0.43340425531914895
- 0.3228723404255319
- 0.3356914893617021
- 0.42654255319148937
- 0.3274468085106383
- 0.4346808510638298
- 0.37420212765957445
- 0.3780851063829787
- 0.44101063829787235
- 0.4381914893617021
- 0.4845744680851064
- 0.4251595744680851
- 0.38324468085106383
- 0.20856382978723403
- 0.2776063829787234
- 0.3270212765957447
test_loss_list:
- 4.024287306467692
- 7.209253508249919
- 4.416464888254802
- 4.444709657033284
- 4.001368389129639
- 4.040882047017416
- 3.5604092280069985
- 3.620702231725057
- 4.624545892079671
- 3.3285903390248617
- 3.3468731117248534
- 4.24748784383138
- 5.766016845703125
- 3.3682182534535725
- 3.1809112803141275
- 3.472184975941976
- 3.7987710857391357
- 3.2854750378926596
- 3.1489980030059814
- 4.144291067123413
- 3.0551742458343507
- 3.5769455337524416
- 3.154557002385457
- 4.177889801661173
- 3.0116297308603923
- 3.0544835408528646
- 3.728522605895996
- 2.964406026204427
- 3.606704209645589
- 5.416112995147705
- 2.9429261589050295
- 3.7186272144317627
- 3.1521986452738444
- 3.2079185581207277
- 3.1686277834574383
- 3.5992993831634523
- 3.426893644332886
- 3.3679014428456626
- 3.027206061681112
- 3.1549647521972655
- 2.938106304804484
- 3.0078519217173256
- 3.248223190307617
- 3.4070773537953696
- 3.0195839754740397
- 5.382087020874024
- 3.2153409004211424
- 3.486492598851522
- 3.258282801310221
- 2.8440458456675213
- 2.8931707922617593
- 2.936862471898397
- 3.0960895442962646
- 2.7789228121439615
- 3.1929833126068115
- 2.6695363012949627
- 3.351903448104858
- 2.811893091201782
- 3.591558879216512
- 3.5152981726328534
- 2.8928551197052004
- 3.1669294293721517
- 2.887027883529663
- 3.1470252386728923
- 3.1853051439921063
- 2.7775179704030353
- 3.3666107590993244
- 3.4631673749287923
- 3.3514871565500894
- 3.1583834075927735
- 4.388676993052164
- 2.7888897132873534
- 3.5835925356547036
- 3.055814510981242
- 2.9562881342569987
- 2.8389678382873536
- 2.6946588134765626
- 3.597178961435954
- 4.470896364847819
- 2.929816754659017
- 3.175886704126994
- 2.6530708503723144
- 3.4602943801879884
- 5.0054095967610674
- 2.738722823460897
- 3.661147893269857
- 3.2228323713938396
- 2.896311149597168
- 3.3373661041259766
- 2.7920004240671794
- 3.073602145512899
- 3.1264109388987222
- 2.800884911219279
- 2.993789081573486
- 2.7145167922973634
- 3.1066339683532713
- 3.188721389770508
- 5.208366769154867
- 3.7443139584859213
- 3.434223779042562
train_accuracy:
- 0.0
- 0.8
- 0.017
- 0.0
- 0.008
- 0.0
- 0.0
- 0.029
- 0.869
- 0.0
- 0.002
- 0.012
- 0.002
- 0.583
- 0.0
- 0.487
- 0.838
- 0.094
- 0.554
- 0.887
- 0.008
- 0.065
- 0.094
- 0.027
- 0.44
- 0.081
- 0.829
- 0.065
- 0.894
- 0.927
- 0.056
- 0.0
- 0.029
- 0.773
- 0.044
- 0.906
- 0.077
- 0.098
- 0.713
- 0.104
- 0.01
- 0.123
- 0.529
- 0.0
- 0.735
- 0.942
- 0.0
- 0.008
- 0.923
- 0.152
- 0.05
- 0.158
- 0.158
- 0.135
- 0.896
- 0.081
- 0.025
- 0.071
- 0.006
- 0.892
- 0.054
- 0.129
- 0.092
- 0.917
- 0.871
- 0.09
- 0.898
- 0.117
- 0.133
- 0.925
- 0.0
- 0.119
- 0.921
- 0.885
- 0.733
- 0.76
- 0.717
- 0.119
- 0.95
- 0.902
- 0.923
- 0.812
- 0.944
- 0.085
- 0.065
- 0.927
- 0.954
- 0.042
- 0.95
- 0.071
- 0.944
- 0.137
- 0.119
- 0.14
- 0.856
- 0.137
- 0.933
- 0.958
- 0.963
- 0.11
train_loss:
- 1.903
- 1.156
- 1.009
- 0.865
- 1.025
- 1.056
- 0.914
- 0.906
- 0.713
- 0.845
- 0.797
- 0.754
- 0.594
- 0.682
- 0.812
- 0.691
- 0.756
- 0.717
- 0.609
- 0.549
- 0.766
- 0.692
- 0.622
- 0.52
- 0.703
- 0.68
- 0.572
- 0.669
- 0.617
- 0.493
- 0.681
- 0.521
- 0.506
- 0.614
- 0.484
- 0.572
- 0.487
- 0.459
- 0.454
- 0.455
- 0.555
- 0.444
- 0.391
- 0.55
- 0.535
- 0.511
- 0.417
- 0.462
- 0.514
- 0.495
- 0.491
- 0.405
- 0.483
- 0.498
- 0.497
- 0.495
- 0.464
- 0.445
- 0.446
- 0.454
- 0.356
- 0.338
- 0.434
- 0.396
- 0.365
- 0.403
- 0.371
- 0.432
- 0.381
- 0.374
- 0.409
- 0.35
- 0.356
- 0.428
- 0.435
- 0.373
- 0.434
- 0.335
- 0.301
- 0.418
- 0.424
- 0.408
- 0.325
- 0.31
- 0.439
- 0.408
- 0.378
- 0.331
- 0.38
- 0.423
- 0.408
- 0.411
- 0.387
- 0.341
- 0.388
- 0.302
- 0.392
- 0.292
- 0.356
- 0.293
unequal: 0
verbose: 1
