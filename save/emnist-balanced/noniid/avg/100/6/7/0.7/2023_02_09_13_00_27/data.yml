avg_train_accuracy: 0.075
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.025319148936170214
- 0.09361702127659574
- 0.1271276595744681
- 0.09436170212765957
- 0.1529787234042553
- 0.0874468085106383
- 0.158031914893617
- 0.0975
- 0.10984042553191489
- 0.21127659574468086
- 0.25351063829787235
- 0.2195212765957447
- 0.13691489361702128
- 0.23712765957446807
- 0.2503723404255319
- 0.2872340425531915
- 0.2552659574468085
- 0.29723404255319147
- 0.21164893617021277
- 0.31159574468085105
- 0.11771276595744681
- 0.255
- 0.2509574468085106
- 0.29664893617021276
- 0.19404255319148936
- 0.2929255319148936
- 0.3069148936170213
- 0.18808510638297873
- 0.30606382978723407
- 0.2872340425531915
- 0.3323404255319149
- 0.21308510638297873
- 0.34856382978723405
- 0.16643617021276597
- 0.34180851063829787
- 0.34085106382978725
- 0.3722340425531915
- 0.3422872340425532
- 0.38313829787234044
- 0.2425
- 0.26898936170212767
- 0.3705851063829787
- 0.3451063829787234
- 0.39702127659574465
- 0.34941489361702127
- 0.2828191489361702
- 0.37175531914893617
- 0.28712765957446806
- 0.39797872340425533
- 0.2570212765957447
- 0.34164893617021275
- 0.42792553191489363
- 0.3957978723404255
- 0.38574468085106384
- 0.38468085106382977
- 0.2815957446808511
- 0.4454787234042553
- 0.2255851063829787
- 0.45382978723404255
- 0.2918085106382979
- 0.33074468085106384
- 0.3920744680851064
- 0.4627127659574468
- 0.43361702127659574
- 0.47441489361702127
- 0.48404255319148937
- 0.4217021276595745
- 0.42409574468085104
- 0.3399468085106383
- 0.44
- 0.44292553191489364
- 0.418031914893617
- 0.44840425531914896
- 0.41840425531914893
- 0.428031914893617
- 0.4481914893617021
- 0.4882446808510638
- 0.4932446808510638
- 0.44303191489361704
- 0.33313829787234045
- 0.4596276595744681
- 0.41925531914893616
- 0.4626595744680851
- 0.33026595744680853
- 0.3648936170212766
- 0.5090957446808511
- 0.2927659574468085
- 0.38872340425531915
- 0.323563829787234
- 0.363031914893617
- 0.3565957446808511
- 0.33691489361702126
- 0.46952127659574466
- 0.45053191489361705
- 0.32654255319148934
- 0.4772872340425532
- 0.5227659574468085
- 0.47510638297872343
- 0.523936170212766
- 0.44611702127659575
test_loss_list:
- 4.198396701812744
- 4.319803225199381
- 3.743858731587728
- 4.018224652608236
- 3.5496443780263265
- 5.19165989557902
- 3.610607630411784
- 4.121877063115438
- 4.223403991063436
- 3.2045401922861734
- 3.3016538365681964
- 3.4350629234313965
- 3.9580512968699137
- 3.195163536071777
- 3.4000471115112303
- 3.386410140991211
- 3.2855356216430662
- 3.3131515566507974
- 3.361745309829712
- 3.0237809975941974
- 4.698914941151937
- 3.319079230626424
- 3.2332607396443684
- 3.133661839167277
- 3.7024281056722006
- 3.160352897644043
- 3.2123856353759765
- 3.7277271366119384
- 3.060001211166382
- 3.1722222264607747
- 3.182506669362386
- 3.8665583896636964
- 2.9731682999928792
- 4.143082729975382
- 3.0928380839029948
- 2.960971253712972
- 2.875636514027913
- 3.082494379679362
- 2.838634786605835
- 3.6184674453735353
- 3.5595856126149497
- 2.9681310907999676
- 3.2262792142232257
- 2.8500792884826662
- 3.1770531876881916
- 3.579818639755249
- 3.036385917663574
- 3.55221204439799
- 3.0440658696492515
- 3.61766894976298
- 3.2503438504536946
- 2.9203857008616128
- 2.9958473205566407
- 3.039625555674235
- 3.082731383641561
- 3.7450272274017333
- 2.756175219217936
- 4.021983067194621
- 2.8073495165507
- 3.6544704659779867
- 3.3518239148457845
- 2.998896983464559
- 2.7639601103464764
- 3.0114446544647215
- 2.71616548538208
- 2.8036174074808757
- 3.0721829414367674
- 3.0344975630442304
- 3.3850604470570884
- 2.9573609193166095
- 2.993643051783244
- 3.0719828097025554
- 2.8873189226786296
- 3.048680712381999
- 3.057778835296631
- 2.9421876303354897
- 2.7894475428263346
- 2.835034554799398
- 3.0516684595743815
- 3.81307123819987
- 2.8843352667490643
- 3.2683461920420327
- 2.9659837182362874
- 3.8689975293477374
- 3.391437079111735
- 2.7798734283447266
- 3.9529512214660643
- 3.235636059443156
- 3.6706863339742024
- 3.4976017570495603
- 3.5441122468312583
- 3.4590560022989907
- 3.007780809402466
- 3.055207166671753
- 3.544237356185913
- 3.004993658065796
- 2.8352769947052003
- 3.0390021928151447
- 2.813342323303223
- 3.1681652386983234
train_accuracy:
- 0.0
- 0.733
- 0.0
- 0.0
- 0.0
- 0.0
- 0.004
- 0.852
- 0.86
- 0.012
- 0.0
- 0.01
- 0.0
- 0.012
- 0.029
- 0.802
- 0.819
- 0.002
- 0.883
- 0.731
- 0.006
- 0.831
- 0.865
- 0.031
- 0.927
- 0.76
- 0.0
- 0.006
- 0.012
- 0.885
- 0.104
- 0.048
- 0.0
- 0.927
- 0.0
- 0.062
- 0.06
- 0.0
- 0.1
- 0.0
- 0.929
- 0.106
- 0.029
- 0.617
- 0.904
- 0.102
- 0.037
- 0.929
- 0.115
- 0.942
- 0.881
- 0.033
- 0.01
- 0.906
- 0.006
- 0.025
- 0.137
- 0.0
- 0.048
- 0.95
- 0.935
- 0.904
- 0.815
- 0.094
- 0.821
- 0.012
- 0.906
- 0.046
- 0.952
- 0.027
- 0.902
- 0.056
- 0.848
- 0.904
- 0.029
- 0.04
- 0.115
- 0.09
- 0.044
- 0.95
- 0.8
- 0.044
- 0.056
- 0.935
- 0.037
- 0.125
- 0.0
- 0.131
- 0.96
- 0.952
- 0.956
- 0.017
- 0.127
- 0.058
- 0.0
- 0.86
- 0.767
- 0.048
- 0.104
- 0.075
train_loss:
- 2.222
- 1.221
- 1.046
- 0.866
- 0.85
- 0.751
- 0.766
- 0.742
- 0.719
- 0.752
- 0.676
- 0.64
- 0.59
- 0.634
- 0.585
- 0.548
- 0.6
- 0.568
- 0.6
- 0.59
- 0.548
- 0.545
- 0.538
- 0.525
- 0.526
- 0.494
- 0.481
- 0.504
- 0.499
- 0.468
- 0.479
- 0.459
- 0.482
- 0.47
- 0.471
- 0.472
- 0.456
- 0.437
- 0.444
- 0.432
- 0.413
- 0.431
- 0.417
- 0.444
- 0.422
- 0.415
- 0.405
- 0.376
- 0.387
- 0.397
- 0.376
- 0.376
- 0.397
- 0.381
- 0.379
- 0.378
- 0.388
- 0.363
- 0.368
- 0.378
- 0.355
- 0.366
- 0.367
- 0.356
- 0.369
- 0.336
- 0.341
- 0.331
- 0.361
- 0.325
- 0.323
- 0.337
- 0.334
- 0.317
- 0.314
- 0.321
- 0.331
- 0.324
- 0.308
- 0.31
- 0.339
- 0.311
- 0.307
- 0.293
- 0.298
- 0.32
- 0.304
- 0.315
- 0.303
- 0.295
- 0.308
- 0.302
- 0.294
- 0.296
- 0.293
- 0.286
- 0.295
- 0.294
- 0.306
- 0.281
unequal: 0
verbose: 1
