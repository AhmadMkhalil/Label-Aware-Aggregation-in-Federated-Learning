avg_train_accuracy: 0.75
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04058510638297872
- 0.07111702127659575
- 0.08686170212765958
- 0.09069148936170213
- 0.1472872340425532
- 0.14925531914893617
- 0.1397340425531915
- 0.09632978723404255
- 0.09973404255319149
- 0.14186170212765958
- 0.16867021276595745
- 0.1671808510638298
- 0.19191489361702127
- 0.13191489361702127
- 0.1851063829787234
- 0.08702127659574468
- 0.17654255319148937
- 0.1951063829787234
- 0.18170212765957447
- 0.18351063829787234
- 0.18632978723404256
- 0.2103191489361702
- 0.18670212765957447
- 0.20186170212765958
- 0.2175531914893617
- 0.1976063829787234
- 0.22484042553191488
- 0.12196808510638298
- 0.22319148936170213
- 0.211968085106383
- 0.22351063829787235
- 0.128031914893617
- 0.2529787234042553
- 0.24617021276595744
- 0.24468085106382978
- 0.22430851063829788
- 0.24351063829787234
- 0.22734042553191489
- 0.14117021276595745
- 0.22877659574468084
- 0.24361702127659574
- 0.2630851063829787
- 0.2451063829787234
- 0.13654255319148936
- 0.24962765957446809
- 0.25372340425531914
- 0.2962234042553191
- 0.2648936170212766
- 0.2847872340425532
- 0.27356382978723404
- 0.27356382978723404
- 0.26324468085106384
- 0.2942021276595745
- 0.29654255319148937
- 0.28308510638297874
- 0.29047872340425535
- 0.3
- 0.2848404255319149
- 0.29143617021276597
- 0.2654787234042553
- 0.2809042553191489
- 0.3082446808510638
- 0.27861702127659577
- 0.3068085106382979
- 0.30569148936170215
- 0.13813829787234042
- 0.3396808510638298
- 0.2720744680851064
- 0.33563829787234045
- 0.14638297872340425
- 0.1752127659574468
- 0.2957446808510638
- 0.2854255319148936
- 0.2851595744680851
- 0.2809042553191489
- 0.31840425531914895
- 0.33526595744680854
- 0.3535106382978723
- 0.3021276595744681
- 0.1725531914893617
- 0.26313829787234044
- 0.3248936170212766
- 0.35648936170212764
- 0.16191489361702127
- 0.1671276595744681
- 0.2782978723404255
- 0.35723404255319147
- 0.1625
- 0.36781914893617024
- 0.3173936170212766
- 0.3497872340425532
- 0.363031914893617
- 0.35595744680851066
- 0.30292553191489363
- 0.3525531914893617
- 0.36
- 0.34117021276595744
- 0.36734042553191487
- 0.3694148936170213
- 0.38515957446808513
test_loss_list:
- 4.892953713734944
- 5.389492778778076
- 8.529760373433431
- 4.960063451131185
- 5.242031904856364
- 5.708708680470784
- 5.573245175679525
- 8.353466714223226
- 7.141456972757975
- 4.172929347356161
- 4.5554932022094725
- 3.8974719429016114
- 3.688208834330241
- 4.156940762201945
- 3.834132645924886
- 5.275802065531413
- 3.8482271099090575
- 4.608389123280843
- 4.5798327954610185
- 3.9533213583628335
- 4.112292054494222
- 4.484895442326864
- 3.5021584955851237
- 3.8855154673258463
- 4.125789349873861
- 3.805685288111369
- 4.729745388031006
- 6.0559281158447265
- 3.817324275970459
- 4.420883884429932
- 4.234091844558716
- 7.834055786132812
- 3.6331287733713786
- 3.823185472488403
- 4.679333833058675
- 3.6109762795766196
- 3.7989276854197183
- 3.8470727507273357
- 5.816209710439046
- 3.7498027515411376
- 3.763679389953613
- 3.626505870819092
- 3.997224572499593
- 6.182984917958578
- 3.792548135121663
- 4.5329459889729815
- 3.442823553085327
- 3.6280691623687744
- 3.402530419031779
- 3.8717259724934894
- 3.4677728271484374
- 3.874864638646444
- 3.875838483174642
- 3.8940933767954506
- 3.812324701944987
- 4.025422681172689
- 3.720192060470581
- 4.3061480077107746
- 3.6946905199686686
- 4.5806465943654375
- 4.457965189615885
- 3.7677963256835936
- 4.421750431060791
- 3.709876569112142
- 3.4115860080718994
- 5.921398957570394
- 3.034174566268921
- 4.066666409174601
- 3.271049003601074
- 6.07281795501709
- 5.533847001393636
- 4.029916067123413
- 3.9110596307118732
- 3.804648469289144
- 4.439581921895345
- 3.4929202047983807
- 3.555492935180664
- 3.357816727956136
- 3.747119509379069
- 5.279011917114258
- 4.463599739074707
- 3.643081029256185
- 3.158059829076131
- 5.692657585144043
- 5.538108215332032
- 3.8112069193522133
- 3.7392144107818606
- 6.224911066691081
- 3.124872341156006
- 3.8390435377756753
- 3.553800064722697
- 3.23889643351237
- 3.565574213663737
- 4.419574553171794
- 3.618702071507772
- 3.5244856198628742
- 3.6029589144388834
- 3.723557087580363
- 3.571419947942098
- 3.2942494042714436
train_accuracy:
- 0.006
- 0.067
- 0.0
- 0.204
- 0.0
- 0.017
- 0.458
- 0.863
- 0.0
- 0.094
- 0.035
- 0.667
- 0.0
- 0.052
- 0.025
- 0.8
- 0.108
- 0.108
- 0.125
- 0.05
- 0.04
- 0.642
- 0.115
- 0.7
- 0.065
- 0.042
- 0.081
- 0.017
- 0.104
- 0.065
- 0.129
- 0.027
- 0.581
- 0.154
- 0.125
- 0.615
- 0.085
- 0.058
- 0.056
- 0.046
- 0.11
- 0.075
- 0.131
- 0.933
- 0.121
- 0.133
- 0.069
- 0.117
- 0.148
- 0.765
- 0.154
- 0.048
- 0.129
- 0.083
- 0.154
- 0.106
- 0.746
- 0.085
- 0.106
- 0.119
- 0.125
- 0.144
- 0.725
- 0.827
- 0.094
- 0.931
- 0.137
- 0.81
- 0.779
- 0.933
- 0.912
- 0.131
- 0.877
- 0.127
- 0.144
- 0.129
- 0.129
- 0.129
- 0.104
- 0.04
- 0.115
- 0.129
- 0.133
- 0.956
- 0.094
- 0.133
- 0.115
- 0.077
- 0.129
- 0.113
- 0.74
- 0.096
- 0.085
- 0.852
- 0.127
- 0.144
- 0.152
- 0.067
- 0.127
- 0.75
train_loss:
- 1.967
- 1.255
- 0.841
- 1.031
- 0.825
- 0.695
- 0.805
- 0.66
- 0.653
- 0.917
- 0.812
- 0.781
- 0.844
- 1.077
- 0.829
- 0.905
- 0.741
- 0.677
- 0.59
- 0.767
- 0.631
- 0.696
- 0.82
- 0.619
- 0.586
- 0.631
- 0.488
- 0.578
- 0.648
- 0.599
- 0.537
- 0.444
- 0.631
- 0.617
- 0.491
- 0.647
- 0.524
- 0.558
- 0.444
- 0.584
- 0.572
- 0.535
- 0.514
- 0.463
- 0.587
- 0.448
- 0.571
- 0.509
- 0.558
- 0.5
- 0.49
- 0.48
- 0.503
- 0.483
- 0.425
- 0.436
- 0.491
- 0.438
- 0.493
- 0.417
- 0.377
- 0.454
- 0.391
- 0.49
- 0.478
- 0.404
- 0.517
- 0.413
- 0.442
- 0.353
- 0.362
- 0.379
- 0.387
- 0.459
- 0.349
- 0.427
- 0.398
- 0.46
- 0.401
- 0.412
- 0.342
- 0.397
- 0.427
- 0.321
- 0.332
- 0.397
- 0.324
- 0.314
- 0.512
- 0.38
- 0.369
- 0.411
- 0.362
- 0.337
- 0.408
- 0.349
- 0.385
- 0.318
- 0.372
- 0.386
unequal: 0
verbose: 1
