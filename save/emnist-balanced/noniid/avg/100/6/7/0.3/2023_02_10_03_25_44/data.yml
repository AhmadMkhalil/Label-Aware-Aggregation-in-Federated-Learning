avg_train_accuracy: 0.123
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05829787234042553
- 0.0777127659574468
- 0.11797872340425532
- 0.12196808510638298
- 0.13648936170212767
- 0.12904255319148936
- 0.12537234042553191
- 0.1525
- 0.08345744680851064
- 0.18138297872340425
- 0.1751595744680851
- 0.08872340425531915
- 0.1497872340425532
- 0.17446808510638298
- 0.1798404255319149
- 0.0925531914893617
- 0.1423404255319149
- 0.0901595744680851
- 0.18095744680851064
- 0.09563829787234042
- 0.2097872340425532
- 0.19452127659574467
- 0.1997872340425532
- 0.19404255319148936
- 0.18936170212765957
- 0.2173936170212766
- 0.22313829787234044
- 0.2227127659574468
- 0.11984042553191489
- 0.22601063829787235
- 0.12611702127659574
- 0.1498404255319149
- 0.22569148936170214
- 0.23356382978723406
- 0.23590425531914894
- 0.24457446808510638
- 0.2401595744680851
- 0.26154255319148934
- 0.11957446808510638
- 0.24904255319148935
- 0.2323404255319149
- 0.11771276595744681
- 0.2450531914893617
- 0.2403191489361702
- 0.2530851063829787
- 0.24132978723404255
- 0.27367021276595743
- 0.2546276595744681
- 0.16867021276595745
- 0.29388297872340424
- 0.265
- 0.2637765957446809
- 0.3
- 0.256063829787234
- 0.26351063829787236
- 0.2398936170212766
- 0.2865957446808511
- 0.15563829787234043
- 0.29601063829787233
- 0.27297872340425533
- 0.2575
- 0.32898936170212767
- 0.2917021276595745
- 0.30090425531914894
- 0.3343617021276596
- 0.1848404255319149
- 0.2772340425531915
- 0.27606382978723404
- 0.2781914893617021
- 0.2739893617021277
- 0.32420212765957446
- 0.16489361702127658
- 0.2703191489361702
- 0.28856382978723405
- 0.3040425531914894
- 0.3079787234042553
- 0.32574468085106384
- 0.3058510638297872
- 0.30946808510638296
- 0.28106382978723404
- 0.17430851063829786
- 0.29664893617021276
- 0.1748404255319149
- 0.1553723404255319
- 0.3381382978723404
- 0.1748936170212766
- 0.3241489361702128
- 0.3627127659574468
- 0.19808510638297872
- 0.4047340425531915
- 0.36686170212765956
- 0.3298936170212766
- 0.34632978723404256
- 0.3338829787234043
- 0.19452127659574467
- 0.18925531914893617
- 0.33585106382978724
- 0.4482978723404255
- 0.4067021276595745
- 0.35132978723404257
test_loss_list:
- 4.825726801554362
- 5.080406246185302
- 5.273774681091308
- 3.9576166661580405
- 4.356677042643229
- 3.92736146291097
- 3.599371945063273
- 4.142611195246379
- 7.312420647939046
- 4.771982911427815
- 4.548494822184245
- 5.842861296335856
- 4.103673591613769
- 4.648807703653971
- 5.021836795806885
- 7.240553754170736
- 4.14025621732076
- 5.534535230000814
- 3.967294715245565
- 6.4284139823913575
- 4.121205377578735
- 4.0008977540334065
- 3.9385453987121584
- 4.113983001708984
- 4.576980355580647
- 3.875103619893392
- 4.423796831766764
- 4.132388353347778
- 5.91609935760498
- 4.820913168589274
- 5.8649541346232095
- 6.305168539683024
- 3.969793389638265
- 3.780233475367228
- 3.8521841271718342
- 4.1174456373850505
- 4.218278207778931
- 3.548979714711507
- 6.728477319081624
- 4.241037588119507
- 3.715085735321045
- 6.5335476684570315
- 3.5577009042104084
- 4.1678717263539635
- 4.393791688283285
- 3.930785207748413
- 4.006691859563191
- 4.049594980875651
- 6.229762935638428
- 3.585336968104045
- 4.465737193425497
- 4.300855102539063
- 3.5333761405944824
- 4.210117527643839
- 3.9144647757212323
- 3.8003054523468016
- 4.125649992624918
- 6.1109921137491865
- 3.559154739379883
- 3.7366181373596192
- 4.489103218714396
- 3.3375915241241456
- 3.937102918624878
- 3.854745562871297
- 3.6093590386708576
- 5.334911880493164
- 3.7493299802144366
- 4.593541297912598
- 4.479107208251953
- 4.804311720530192
- 3.4236672719319663
- 6.564649200439453
- 4.28959456761678
- 4.340667680104573
- 4.202314097086589
- 3.8845720354715985
- 3.958620541890462
- 3.965219243367513
- 3.7624143664042156
- 4.62205738067627
- 5.649247074127198
- 4.020213702519735
- 5.846461785634359
- 5.470042819976807
- 3.2456438891092936
- 5.656900513966878
- 3.904790194829305
- 3.302025861740112
- 5.442343482971191
- 3.1362342198689777
- 3.3611174647013344
- 3.5239941851298013
- 3.633665049870809
- 3.694574867884318
- 5.7880371538798014
- 6.1815295473734535
- 3.4894024340311685
- 3.0291077264149986
- 3.18190899848938
- 3.813383242289225
train_accuracy:
- 0.267
- 0.0
- 0.0
- 0.579
- 0.012
- 0.01
- 0.452
- 0.0
- 0.0
- 0.069
- 0.137
- 0.856
- 0.044
- 0.037
- 0.05
- 0.863
- 0.544
- 0.006
- 0.642
- 0.0
- 0.073
- 0.033
- 0.1
- 0.61
- 0.621
- 0.098
- 0.681
- 0.048
- 0.885
- 0.079
- 0.892
- 0.865
- 0.008
- 0.125
- 0.088
- 0.054
- 0.115
- 0.1
- 0.0
- 0.133
- 0.077
- 0.0
- 0.113
- 0.704
- 0.14
- 0.8
- 0.733
- 0.1
- 0.925
- 0.113
- 0.71
- 0.117
- 0.104
- 0.74
- 0.129
- 0.021
- 0.027
- 0.89
- 0.121
- 0.127
- 0.077
- 0.081
- 0.117
- 0.146
- 0.137
- 0.0
- 0.125
- 0.794
- 0.15
- 0.142
- 0.113
- 0.123
- 0.596
- 0.125
- 0.808
- 0.144
- 0.144
- 0.798
- 0.794
- 0.119
- 0.956
- 0.146
- 0.94
- 0.946
- 0.119
- 0.929
- 0.081
- 0.794
- 0.915
- 0.1
- 0.129
- 0.135
- 0.142
- 0.133
- 0.96
- 0.954
- 0.11
- 0.15
- 0.11
- 0.123
train_loss:
- 1.911
- 1.319
- 1.017
- 1.222
- 0.968
- 0.965
- 1.05
- 0.924
- 0.898
- 0.737
- 0.773
- 0.789
- 0.89
- 0.663
- 0.619
- 0.827
- 1.016
- 0.8
- 0.781
- 0.719
- 0.702
- 0.755
- 0.726
- 0.604
- 0.689
- 0.693
- 0.579
- 0.648
- 0.573
- 0.51
- 0.57
- 0.509
- 0.665
- 0.712
- 0.559
- 0.538
- 0.578
- 0.602
- 0.554
- 0.466
- 0.584
- 0.543
- 0.57
- 0.472
- 0.459
- 0.564
- 0.453
- 0.528
- 0.432
- 0.582
- 0.459
- 0.471
- 0.448
- 0.512
- 0.524
- 0.483
- 0.45
- 0.43
- 0.521
- 0.499
- 0.39
- 0.54
- 0.449
- 0.436
- 0.448
- 0.419
- 0.467
- 0.35
- 0.393
- 0.397
- 0.47
- 0.356
- 0.379
- 0.399
- 0.369
- 0.385
- 0.396
- 0.421
- 0.405
- 0.338
- 0.406
- 0.416
- 0.411
- 0.441
- 0.444
- 0.387
- 0.417
- 0.487
- 0.356
- 0.402
- 0.369
- 0.436
- 0.376
- 0.41
- 0.345
- 0.306
- 0.451
- 0.369
- 0.373
- 0.32
unequal: 0
verbose: 1
