avg_train_accuracy: 0.973
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05297872340425532
- 0.1024468085106383
- 0.07377659574468085
- 0.1305851063829787
- 0.160531914893617
- 0.08946808510638297
- 0.17196808510638298
- 0.13361702127659575
- 0.17398936170212767
- 0.1823404255319149
- 0.17382978723404255
- 0.1848936170212766
- 0.1722340425531915
- 0.20319148936170212
- 0.22026595744680852
- 0.2200531914893617
- 0.23180851063829788
- 0.11218085106382979
- 0.18824468085106383
- 0.20446808510638298
- 0.23186170212765958
- 0.11420212765957446
- 0.14324468085106384
- 0.23851063829787233
- 0.2377127659574468
- 0.20430851063829789
- 0.2226063829787234
- 0.13888297872340424
- 0.2598936170212766
- 0.24079787234042555
- 0.11515957446808511
- 0.23542553191489363
- 0.2571276595744681
- 0.30340425531914894
- 0.2591489361702128
- 0.25127659574468086
- 0.26303191489361705
- 0.28297872340425534
- 0.26180851063829785
- 0.2594148936170213
- 0.2473936170212766
- 0.12930851063829787
- 0.2376063829787234
- 0.27872340425531916
- 0.2602659574468085
- 0.2701063829787234
- 0.1271808510638298
- 0.2948936170212766
- 0.28973404255319146
- 0.2695744680851064
- 0.28867021276595745
- 0.2911170212765957
- 0.3248404255319149
- 0.2898936170212766
- 0.2993085106382979
- 0.32813829787234045
- 0.16638297872340427
- 0.1778191489361702
- 0.17414893617021276
- 0.10106382978723404
- 0.28617021276595744
- 0.30079787234042554
- 0.30920212765957444
- 0.4031382978723404
- 0.31398936170212766
- 0.2979255319148936
- 0.3000531914893617
- 0.34675531914893615
- 0.31393617021276593
- 0.34808510638297874
- 0.3196276595744681
- 0.3854787234042553
- 0.18170212765957447
- 0.3280851063829787
- 0.36803191489361703
- 0.3243617021276596
- 0.36223404255319147
- 0.3401595744680851
- 0.34867021276595744
- 0.3001595744680851
- 0.17106382978723406
- 0.17398936170212767
- 0.3020744680851064
- 0.3575531914893617
- 0.30670212765957444
- 0.30398936170212765
- 0.3544148936170213
- 0.3680851063829787
- 0.3177127659574468
- 0.3371276595744681
- 0.3094148936170213
- 0.3300531914893617
- 0.18723404255319148
- 0.21297872340425533
- 0.31101063829787234
- 0.3476063829787234
- 0.31648936170212766
- 0.16920212765957446
- 0.18111702127659574
- 0.17542553191489363
test_loss_list:
- 5.124435532887777
- 4.579021962483724
- 4.115047861735026
- 4.383271541595459
- 4.487906525929769
- 8.128663730621337
- 4.282728786468506
- 3.7525963401794433
- 4.341102600097656
- 4.0374511591593425
- 4.175243883132935
- 3.431285384496053
- 3.765742053985596
- 3.5634872690836588
- 3.7602690569559734
- 3.8416377321879067
- 3.7278514194488523
- 5.991843039194743
- 4.123454297383626
- 4.196855840682983
- 3.6594981225331624
- 6.191863562266032
- 6.227003784179687
- 4.183224156697591
- 4.67687640508016
- 3.8569358507792155
- 3.5862039279937745
- 6.261441485087077
- 3.6787621561686197
- 3.686889139811198
- 6.080201225280762
- 3.7113834889729818
- 3.9411958185831706
- 3.314851404825846
- 3.8843190479278564
- 4.071552305221558
- 4.221656827926636
- 3.313561855951945
- 4.562204596201579
- 4.297952683766683
- 3.4170294284820555
- 6.1805420430501306
- 3.618767178853353
- 3.6593695290883383
- 3.639811404546102
- 4.135996541976929
- 5.2923171552022295
- 3.4166149044036866
- 3.3988563219706216
- 3.76161190032959
- 3.9479573726654054
- 3.575287939707438
- 3.007799564997355
- 3.6048436260223387
- 3.5054990164438884
- 3.3452642345428467
- 5.353564338684082
- 5.980203247070312
- 4.986368363698324
- 10.803729197184245
- 3.395804958343506
- 3.1866886202494302
- 3.207381258010864
- 2.8805845959981284
- 3.3747377649943036
- 3.8050213718414305
- 4.025136019388834
- 3.284818874994914
- 3.6327757358551027
- 3.2218775939941406
- 3.632518482208252
- 2.8977529939015705
- 5.1403504053751625
- 3.3574346478780113
- 3.095089470545451
- 3.6647014967600504
- 3.2442530314127604
- 3.3738229115804037
- 3.4378935050964357
- 4.113012507756551
- 5.953541984558106
- 6.152161738077799
- 3.8667692534128824
- 3.126804450352987
- 3.868716770807902
- 3.79856315612793
- 3.547175283432007
- 3.2877485847473142
- 3.6864746125539143
- 3.4793763256072996
- 4.083948551813761
- 3.674218867619832
- 6.182679373423259
- 4.630102240244548
- 3.4886057980855307
- 3.5107530307769776
- 3.944361454645793
- 5.3491303253173825
- 5.05245813369751
- 5.7919975280761715
train_accuracy:
- 0.0
- 0.292
- 0.133
- 0.0
- 0.065
- 0.858
- 0.09
- 0.054
- 0.402
- 0.088
- 0.054
- 0.077
- 0.048
- 0.119
- 0.094
- 0.083
- 0.129
- 0.877
- 0.535
- 0.052
- 0.073
- 0.883
- 0.887
- 0.115
- 0.1
- 0.104
- 0.825
- 0.067
- 0.475
- 0.1
- 0.052
- 0.121
- 0.125
- 0.094
- 0.775
- 0.09
- 0.842
- 0.15
- 0.119
- 0.102
- 0.181
- 0.946
- 0.092
- 0.142
- 0.898
- 0.838
- 0.01
- 0.083
- 0.152
- 0.863
- 0.129
- 0.079
- 0.106
- 0.135
- 0.444
- 0.108
- 0.977
- 0.938
- 0.042
- 0.977
- 0.787
- 0.102
- 0.746
- 0.156
- 0.154
- 0.133
- 0.121
- 0.154
- 0.146
- 0.79
- 0.881
- 0.088
- 0.081
- 0.148
- 0.11
- 0.125
- 0.844
- 0.115
- 0.142
- 0.156
- 0.954
- 0.96
- 0.9
- 0.825
- 0.158
- 0.906
- 0.123
- 0.465
- 0.142
- 0.142
- 0.144
- 0.148
- 0.071
- 0.06
- 0.346
- 0.14
- 0.152
- 0.969
- 0.11
- 0.973
train_loss:
- 1.847
- 1.308
- 1.337
- 0.908
- 0.732
- 0.704
- 0.917
- 1.122
- 0.795
- 0.781
- 0.801
- 0.989
- 0.763
- 0.803
- 0.741
- 0.636
- 0.627
- 0.684
- 0.719
- 0.662
- 0.579
- 0.541
- 0.5
- 0.574
- 0.508
- 0.625
- 0.627
- 0.482
- 0.667
- 0.614
- 0.564
- 0.553
- 0.549
- 0.532
- 0.506
- 0.499
- 0.44
- 0.484
- 0.403
- 0.472
- 0.596
- 0.477
- 0.56
- 0.575
- 0.483
- 0.383
- 0.449
- 0.492
- 0.47
- 0.424
- 0.356
- 0.506
- 0.524
- 0.395
- 0.44
- 0.446
- 0.4
- 0.361
- 0.379
- 0.278
- 0.566
- 0.453
- 0.42
- 0.449
- 0.409
- 0.341
- 0.329
- 0.407
- 0.333
- 0.436
- 0.374
- 0.46
- 0.369
- 0.378
- 0.379
- 0.307
- 0.458
- 0.34
- 0.408
- 0.307
- 0.313
- 0.285
- 0.363
- 0.394
- 0.318
- 0.351
- 0.333
- 0.396
- 0.404
- 0.313
- 0.275
- 0.328
- 0.267
- 0.347
- 0.359
- 0.328
- 0.287
- 0.4
- 0.32
- 0.348
unequal: 0
verbose: 1
