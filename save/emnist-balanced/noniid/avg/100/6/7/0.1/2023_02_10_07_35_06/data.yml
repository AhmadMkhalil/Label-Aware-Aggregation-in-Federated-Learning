avg_train_accuracy: 0.15
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.09638297872340426
- 0.0876595744680851
- 0.09941489361702127
- 0.0947872340425532
- 0.09595744680851064
- 0.07632978723404256
- 0.09090425531914893
- 0.0972872340425532
- 0.09430851063829787
- 0.09297872340425532
- 0.09659574468085107
- 0.10074468085106383
- 0.0973404255319149
- 0.10058510638297873
- 0.10170212765957447
- 0.10404255319148936
- 0.09792553191489362
- 0.10053191489361703
- 0.0973936170212766
- 0.10111702127659575
- 0.09457446808510639
- 0.10925531914893617
- 0.10776595744680852
- 0.12446808510638298
- 0.10914893617021276
- 0.10132978723404255
- 0.1254255319148936
- 0.11936170212765958
- 0.11856382978723404
- 0.1296808510638298
- 0.11526595744680851
- 0.12042553191489362
- 0.12829787234042553
- 0.11781914893617021
- 0.11824468085106384
- 0.13792553191489362
- 0.11335106382978724
- 0.11462765957446809
- 0.1371276595744681
- 0.1477659574468085
- 0.13297872340425532
- 0.1428723404255319
- 0.11920212765957447
- 0.1348404255319149
- 0.13845744680851063
- 0.13882978723404255
- 0.15984042553191488
- 0.12537234042553191
- 0.09962765957446809
- 0.12101063829787234
- 0.11909574468085106
- 0.10659574468085106
- 0.15090425531914894
- 0.1400531914893617
- 0.14542553191489363
- 0.15808510638297874
- 0.1322340425531915
- 0.13696808510638298
- 0.15090425531914894
- 0.15829787234042553
- 0.15585106382978722
- 0.13180851063829788
- 0.11398936170212766
- 0.13617021276595745
- 0.1551063829787234
- 0.1626063829787234
- 0.1376595744680851
- 0.12601063829787235
- 0.12069148936170213
- 0.16382978723404254
- 0.12361702127659574
- 0.15856382978723405
- 0.15867021276595744
- 0.1477127659574468
- 0.15595744680851065
- 0.16351063829787235
- 0.1529787234042553
- 0.16292553191489362
- 0.14047872340425532
- 0.14680851063829786
- 0.16946808510638298
- 0.16579787234042553
- 0.1650531914893617
- 0.18063829787234043
- 0.16335106382978723
- 0.16138297872340426
- 0.19829787234042554
- 0.18010638297872342
- 0.21329787234042552
- 0.21069148936170212
- 0.21436170212765956
- 0.18122340425531916
- 0.17856382978723404
- 0.2027659574468085
- 0.17845744680851064
- 0.19127659574468084
- 0.17601063829787233
- 0.15978723404255318
- 0.13909574468085106
- 0.20356382978723403
test_loss_list:
- 11.950090192159017
- 13.746681098937989
- 13.150518086751303
- 12.842679875691731
- 11.70440633138021
- 9.962690785725911
- 8.938863156636556
- 11.851860987345377
- 9.34389326731364
- 9.29879800160726
- 10.531573321024577
- 8.901799761454264
- 10.01402837117513
- 10.32956942240397
- 8.707219060262045
- 9.351894989013672
- 9.47091739654541
- 7.675345478057861
- 11.866765912373861
- 7.567314612070719
- 6.772722784678141
- 6.587490533192953
- 7.784478689829508
- 7.184286441802978
- 8.532803497314454
- 9.637906735738119
- 8.520277322133381
- 7.3728762563069665
- 8.384998188018798
- 7.891641381581624
- 8.857622172037761
- 7.315415910085043
- 7.95693681716919
- 7.604501965840657
- 7.614356371561686
- 6.971485754648844
- 6.962586135864258
- 7.3398750940958655
- 7.597059218088786
- 7.188664716084798
- 7.076193103790283
- 7.341158790588379
- 8.650477828979492
- 7.0957779121398925
- 9.293406677246093
- 7.978410224914551
- 7.196852582295736
- 6.97229741414388
- 10.104876556396484
- 6.814181950887044
- 6.3748908042907715
- 8.166937503814697
- 6.0360399373372395
- 7.110040734608968
- 7.441812356313069
- 6.030034249623617
- 5.8310847663879395
- 5.874919910430908
- 6.802648754119873
- 7.06017609278361
- 6.4354547500610355
- 7.574755172729493
- 8.427870807647706
- 5.9710435358683265
- 5.8084202003479
- 5.721841952006022
- 7.036261024475098
- 7.800022411346435
- 8.276505699157715
- 5.958040726979574
- 8.001624654134115
- 6.080290775299073
- 5.739788462320964
- 6.429022699991862
- 7.047553634643554
- 6.19089953104655
- 5.635654074350993
- 6.777739950815836
- 8.554126199086507
- 6.601620241800944
- 6.389308376312256
- 6.184383862813314
- 5.648431205749512
- 5.889684715270996
- 5.808520787556966
- 6.680282917022705
- 5.8327961349487305
- 6.263469193776449
- 5.38997761408488
- 5.933391640981038
- 5.858889338175456
- 6.373374869028727
- 6.5396873664855955
- 5.685066661834717
- 6.557445748647054
- 6.24971518834432
- 6.58541259765625
- 6.906913051605224
- 7.965507628122966
- 6.351194820404053
train_accuracy:
- 0.156
- 0.858
- 0.154
- 0.135
- 0.163
- 0.11
- 0.858
- 0.14
- 0.123
- 0.883
- 0.142
- 0.154
- 0.135
- 0.146
- 0.144
- 0.135
- 0.158
- 0.879
- 0.144
- 0.146
- 0.152
- 0.904
- 0.137
- 0.902
- 0.912
- 0.921
- 0.137
- 0.154
- 0.137
- 0.154
- 0.163
- 0.927
- 0.14
- 0.14
- 0.137
- 0.156
- 0.146
- 0.931
- 0.142
- 0.165
- 0.942
- 0.144
- 0.16
- 0.144
- 0.163
- 0.146
- 0.958
- 0.154
- 0.15
- 0.156
- 0.14
- 0.15
- 0.95
- 0.154
- 0.163
- 0.165
- 0.156
- 0.158
- 0.165
- 0.163
- 0.144
- 0.144
- 0.148
- 0.158
- 0.142
- 0.956
- 0.94
- 0.944
- 0.965
- 0.16
- 0.15
- 0.16
- 0.158
- 0.96
- 0.158
- 0.165
- 0.16
- 0.156
- 0.16
- 0.96
- 0.152
- 0.967
- 0.163
- 0.158
- 0.156
- 0.16
- 0.156
- 0.96
- 0.163
- 0.158
- 0.16
- 0.15
- 0.95
- 0.163
- 0.952
- 0.154
- 0.969
- 0.973
- 0.973
- 0.15
train_loss:
- 1.666
- 1.844
- 0.831
- 1.976
- 1.786
- 2.545
- 1.744
- 1.205
- 2.131
- 1.177
- 2.338
- 1.111
- 1.166
- 1.179
- 1.196
- 0.865
- 1.644
- 1.51
- 1.795
- 1.099
- 2.631
- 1.249
- 1.003
- 0.864
- 0.561
- 0.492
- 0.695
- 0.961
- 0.602
- 0.569
- 1.36
- 1.024
- 0.661
- 1.416
- 0.57
- 0.779
- 1.466
- 0.933
- 0.608
- 1.166
- 0.797
- 0.557
- 1.391
- 0.495
- 0.584
- 0.412
- 0.844
- 1.127
- 1.692
- 0.934
- 1.185
- 0.555
- 0.849
- 0.671
- 0.92
- 1.315
- 0.954
- 0.881
- 0.751
- 0.8
- 0.851
- 0.293
- 0.248
- 0.793
- 0.921
- 0.987
- 0.46
- 0.386
- 0.357
- 0.722
- 1.365
- 0.52
- 0.865
- 0.692
- 0.888
- 0.949
- 0.602
- 0.733
- 0.4
- 0.759
- 0.806
- 0.556
- 0.632
- 0.763
- 0.936
- 0.697
- 0.62
- 0.675
- 0.607
- 0.57
- 0.372
- 0.738
- 0.635
- 0.463
- 0.503
- 0.807
- 0.478
- 0.331
- 0.266
- 0.618
unequal: 0
verbose: 1
