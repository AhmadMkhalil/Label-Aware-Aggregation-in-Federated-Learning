avg_train_accuracy: 0.965
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06643617021276596
- 0.08531914893617021
- 0.08090425531914894
- 0.06154255319148936
- 0.08696808510638297
- 0.08882978723404256
- 0.04351063829787234
- 0.06882978723404255
- 0.07047872340425532
- 0.08186170212765957
- 0.09031914893617021
- 0.08478723404255319
- 0.09276595744680852
- 0.07425531914893617
- 0.09377659574468085
- 0.08909574468085106
- 0.09345744680851063
- 0.09882978723404255
- 0.08877659574468084
- 0.09234042553191489
- 0.09090425531914893
- 0.09962765957446809
- 0.10292553191489362
- 0.10936170212765957
- 0.0850531914893617
- 0.10404255319148936
- 0.10553191489361702
- 0.10648936170212767
- 0.10462765957446808
- 0.10276595744680851
- 0.13170212765957448
- 0.09952127659574468
- 0.13686170212765958
- 0.09579787234042553
- 0.09867021276595744
- 0.09515957446808511
- 0.10053191489361703
- 0.10021276595744681
- 0.15053191489361703
- 0.11643617021276596
- 0.1024468085106383
- 0.10085106382978723
- 0.10079787234042553
- 0.11595744680851064
- 0.13074468085106383
- 0.12308510638297872
- 0.10904255319148937
- 0.11632978723404255
- 0.10154255319148936
- 0.1296808510638298
- 0.1127659574468085
- 0.10308510638297873
- 0.15936170212765957
- 0.1176595744680851
- 0.10218085106382979
- 0.12196808510638298
- 0.1475
- 0.11265957446808511
- 0.1122872340425532
- 0.15675531914893617
- 0.12361702127659574
- 0.17654255319148937
- 0.15872340425531914
- 0.17670212765957446
- 0.15914893617021278
- 0.13936170212765958
- 0.12452127659574468
- 0.1151063829787234
- 0.10898936170212765
- 0.10691489361702128
- 0.13702127659574467
- 0.1276595744680851
- 0.12047872340425532
- 0.10968085106382978
- 0.10654255319148936
- 0.13361702127659575
- 0.14053191489361702
- 0.19021276595744682
- 0.17101063829787233
- 0.15627659574468086
- 0.1596276595744681
- 0.1524468085106383
- 0.23659574468085107
- 0.20457446808510638
- 0.16196808510638297
- 0.1922340425531915
- 0.18978723404255318
- 0.1322340425531915
- 0.1148404255319149
- 0.19696808510638297
- 0.19382978723404257
- 0.19021276595744682
- 0.15851063829787235
- 0.1522872340425532
- 0.15675531914893617
- 0.16446808510638297
- 0.15691489361702127
- 0.2653191489361702
- 0.193031914893617
- 0.15186170212765956
test_loss_list:
- 13.60750509897868
- 14.707544530232747
- 12.863666063944498
- 14.40359577178955
- 12.574149640401204
- 14.500474662780762
- 7.368609320322673
- 9.569208183288573
- 8.471490103403728
- 11.458455721537272
- 9.841605135599773
- 13.114213053385416
- 12.156199709574382
- 11.097854143778482
- 9.970069910685222
- 12.885520362854004
- 8.061539510091146
- 9.909783706665038
- 9.760226364135741
- 9.469377899169922
- 9.168493639628092
- 9.205714632670084
- 9.38370085398356
- 8.162133293151856
- 10.889563344319662
- 8.727921155293783
- 8.003481852213541
- 7.8417671839396155
- 8.80914800008138
- 10.08300853729248
- 7.082142435709636
- 8.17023125330607
- 8.02676373163859
- 13.077864532470704
- 16.55035284678141
- 8.576834678649902
- 9.32445962270101
- 11.062156117757162
- 6.6892977587382
- 7.6543682670593265
- 9.41646250406901
- 10.08774969736735
- 11.103267669677734
- 9.182914009094238
- 8.093485520680746
- 9.022215805053712
- 10.206406542460124
- 7.408139419555664
- 9.328656222025554
- 7.853335253397623
- 8.836706364949544
- 9.746062189737955
- 7.337000370025635
- 7.626090577443441
- 9.854603093465169
- 7.433467127482096
- 6.947818915049235
- 9.657222226460775
- 7.762577648162842
- 6.410836187998454
- 7.3792492993672685
- 6.6596647580464685
- 7.397997099558513
- 7.521566549936931
- 8.009017798105875
- 8.636441764831543
- 9.208836186726888
- 8.259953212738036
- 10.201235694885254
- 11.40046745300293
- 7.050396976470947
- 8.096682484944662
- 7.779642848968506
- 9.256098136901855
- 10.028906885782877
- 7.3796701367696125
- 6.505388609568278
- 6.38785005569458
- 7.511624838511149
- 6.993710276285808
- 6.41294708887736
- 7.258235772450765
- 6.130275395711263
- 7.4861523755391435
- 7.961957028706869
- 6.553534940083821
- 6.860948734283447
- 7.970090847015381
- 9.966448364257813
- 7.0582150522867835
- 6.6976455879211425
- 6.557674312591553
- 6.355332247416178
- 6.3494471740722656
- 6.499030386606853
- 6.052408142089844
- 6.142512524922688
- 5.788446203867594
- 6.094202569325765
- 6.332627544403076
train_accuracy:
- 0.052
- 0.127
- 0.802
- 0.065
- 0.092
- 0.129
- 0.01
- 0.15
- 0.127
- 0.077
- 0.158
- 0.827
- 0.137
- 0.083
- 0.163
- 0.867
- 0.16
- 0.144
- 0.135
- 0.14
- 0.867
- 0.146
- 0.165
- 0.135
- 0.046
- 0.167
- 0.921
- 0.156
- 0.156
- 0.158
- 0.14
- 0.908
- 0.15
- 0.127
- 0.146
- 0.135
- 0.167
- 0.167
- 0.152
- 0.919
- 0.938
- 0.95
- 0.952
- 0.167
- 0.95
- 0.167
- 0.167
- 0.167
- 0.167
- 0.948
- 0.96
- 0.956
- 0.148
- 0.158
- 0.148
- 0.167
- 0.958
- 0.152
- 0.158
- 0.15
- 0.956
- 0.167
- 0.956
- 0.167
- 0.958
- 0.965
- 0.965
- 0.081
- 0.14
- 0.152
- 0.965
- 0.971
- 0.167
- 0.167
- 0.167
- 0.165
- 0.967
- 0.15
- 0.154
- 0.167
- 0.965
- 0.167
- 0.167
- 0.167
- 0.167
- 0.956
- 0.167
- 0.148
- 0.142
- 0.167
- 0.146
- 0.967
- 0.16
- 0.967
- 0.14
- 0.965
- 0.167
- 0.167
- 0.163
- 0.965
train_loss:
- 2.325
- 1.962
- 2.183
- 1.95
- 2.156
- 1.261
- 2.899
- 2.626
- 2.917
- 1.956
- 1.768
- 1.49
- 1.355
- 2.256
- 1.161
- 1.189
- 1.958
- 1.046
- 1.307
- 2.036
- 1.305
- 0.925
- 1.177
- 1.149
- 1.701
- 0.865
- 1.134
- 1.247
- 0.823
- 0.371
- 1.1
- 0.953
- 0.709
- 1.772
- 0.62
- 1.525
- 0.94
- 0.424
- 0.78
- 0.881
- 0.489
- 0.424
- 0.375
- 0.701
- 0.613
- 0.54
- 0.316
- 1.522
- 0.589
- 0.683
- 0.409
- 0.349
- 0.991
- 1.357
- 1.235
- 0.849
- 0.705
- 0.795
- 1.122
- 0.826
- 0.626
- 0.928
- 0.507
- 0.563
- 0.432
- 0.307
- 0.271
- 1.677
- 0.624
- 0.51
- 0.594
- 0.3
- 0.972
- 0.356
- 0.291
- 0.95
- 0.648
- 0.937
- 0.422
- 0.706
- 0.603
- 0.497
- 0.878
- 0.405
- 0.742
- 0.612
- 0.541
- 1.011
- 0.485
- 0.569
- 0.828
- 0.552
- 1.44
- 0.543
- 0.867
- 0.445
- 0.762
- 0.653
- 0.879
- 0.608
unequal: 0
verbose: 1
