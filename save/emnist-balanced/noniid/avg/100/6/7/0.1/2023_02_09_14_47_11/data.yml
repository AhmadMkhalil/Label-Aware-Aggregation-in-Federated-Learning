avg_train_accuracy: 0.163
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.08962765957446808
- 0.07813829787234043
- 0.08537234042553192
- 0.0876595744680851
- 0.09063829787234043
- 0.0922340425531915
- 0.09095744680851064
- 0.0898936170212766
- 0.09164893617021276
- 0.0875531914893617
- 0.09712765957446809
- 0.0976063829787234
- 0.08787234042553191
- 0.09260638297872341
- 0.09914893617021277
- 0.09914893617021277
- 0.09771276595744681
- 0.09622340425531915
- 0.09547872340425533
- 0.09441489361702128
- 0.09867021276595744
- 0.07680851063829787
- 0.0972872340425532
- 0.09489361702127659
- 0.09207446808510639
- 0.09632978723404255
- 0.10638297872340426
- 0.09670212765957446
- 0.10074468085106383
- 0.10228723404255319
- 0.09515957446808511
- 0.09861702127659575
- 0.10063829787234042
- 0.10569148936170213
- 0.10659574468085106
- 0.10212765957446808
- 0.10148936170212766
- 0.1149468085106383
- 0.09941489361702127
- 0.12606382978723404
- 0.12095744680851064
- 0.10627659574468085
- 0.11648936170212766
- 0.12537234042553191
- 0.10367021276595745
- 0.11930851063829787
- 0.11010638297872341
- 0.11441489361702127
- 0.1504255319148936
- 0.12611702127659574
- 0.11101063829787235
- 0.1052127659574468
- 0.10303191489361702
- 0.13803191489361702
- 0.13085106382978723
- 0.14106382978723403
- 0.14138297872340425
- 0.18425531914893617
- 0.12260638297872341
- 0.16861702127659575
- 0.14468085106382977
- 0.12154255319148936
- 0.13287234042553192
- 0.1822872340425532
- 0.15675531914893617
- 0.16622340425531915
- 0.17712765957446808
- 0.17718085106382978
- 0.16829787234042554
- 0.14111702127659576
- 0.16952127659574467
- 0.14297872340425533
- 0.19021276595744682
- 0.16154255319148936
- 0.1545744680851064
- 0.17079787234042554
- 0.16553191489361702
- 0.20180851063829788
- 0.15058510638297873
- 0.18819148936170213
- 0.14659574468085107
- 0.12351063829787234
- 0.17590425531914894
- 0.20175531914893616
- 0.1576063829787234
- 0.21090425531914894
- 0.15531914893617021
- 0.15606382978723404
- 0.19329787234042553
- 0.17457446808510638
- 0.14659574468085107
- 0.1300531914893617
- 0.15606382978723404
- 0.1900531914893617
- 0.18377659574468086
- 0.18436170212765957
- 0.1826063829787234
- 0.18101063829787234
- 0.16388297872340427
- 0.18180851063829787
test_loss_list:
- 14.145902366638184
- 13.10823984781901
- 14.928127454121908
- 15.14664794921875
- 16.05352400461833
- 16.027796859741212
- 12.142602653503419
- 10.377175585428875
- 9.259621505737305
- 11.780994211832683
- 11.019876530965169
- 11.307816963195801
- 10.40776959737142
- 10.023706359863281
- 10.205084660847982
- 12.235401713053385
- 9.283681971232097
- 11.156585273742676
- 11.497190437316895
- 9.165482711791991
- 8.358900877634683
- 8.253174470265707
- 7.9524161211649576
- 9.746182047526041
- 13.349851150512695
- 9.817879435221354
- 9.526438585917155
- 11.630254974365235
- 9.222639541625977
- 7.764132258097331
- 8.035914173126221
- 8.90723789215088
- 8.334456316630046
- 8.01023115793864
- 8.411339467366536
- 9.740628509521484
- 10.792804692586262
- 8.473893178304037
- 9.726948941548665
- 8.721887346903483
- 7.775380229949951
- 8.814407704671224
- 6.573708241780599
- 6.839798895517985
- 7.373031838734945
- 6.718770516713461
- 8.264790484110515
- 8.017523733774821
- 6.230192438761393
- 7.171123523712158
- 8.555887120564778
- 9.645742314656575
- 10.189319775899252
- 6.884149958292643
- 7.262111104329427
- 6.884384187062581
- 6.953518486022949
- 6.223398081461588
- 7.786550693511963
- 6.67319060643514
- 6.89821880976359
- 7.596237678527832
- 6.42869260152181
- 6.004880485534668
- 7.21611852645874
- 6.423851559956868
- 5.850389048258464
- 5.68791441599528
- 6.164219881693522
- 5.838026555379232
- 6.237632846832275
- 7.240093421936035
- 5.317345663706462
- 7.266294873555501
- 6.120443464914958
- 5.954456685384114
- 6.259594033559163
- 5.858383846282959
- 6.16895289738973
- 6.085901177724202
- 6.283963553110758
- 7.508987515767416
- 6.256042518615723
- 5.39093687693278
- 6.188257738749186
- 6.039731000264486
- 6.5780721728007
- 6.481956411997477
- 5.25108045578003
- 6.019891541798909
- 6.747617925008138
- 7.7249597040812175
- 6.372283274332682
- 5.763206672668457
- 5.42232037862142
- 6.230648981730143
- 6.016963456471761
- 6.627130947113037
- 5.7549317232767745
- 5.695587298075358
train_accuracy:
- 0.148
- 0.754
- 0.815
- 0.827
- 0.846
- 0.856
- 0.127
- 0.115
- 0.875
- 0.148
- 0.154
- 0.131
- 0.129
- 0.881
- 0.158
- 0.131
- 0.894
- 0.904
- 0.144
- 0.158
- 0.902
- 0.002
- 0.879
- 0.146
- 0.098
- 0.158
- 0.154
- 0.14
- 0.158
- 0.137
- 0.113
- 0.919
- 0.163
- 0.148
- 0.921
- 0.94
- 0.95
- 0.156
- 0.135
- 0.16
- 0.131
- 0.919
- 0.146
- 0.144
- 0.163
- 0.948
- 0.929
- 0.16
- 0.108
- 0.935
- 0.952
- 0.948
- 0.956
- 0.146
- 0.156
- 0.148
- 0.154
- 0.131
- 0.942
- 0.163
- 0.146
- 0.163
- 0.942
- 0.14
- 0.165
- 0.167
- 0.163
- 0.148
- 0.165
- 0.952
- 0.158
- 0.137
- 0.137
- 0.14
- 0.952
- 0.148
- 0.163
- 0.16
- 0.952
- 0.163
- 0.973
- 0.956
- 0.163
- 0.144
- 0.969
- 0.163
- 0.952
- 0.158
- 0.14
- 0.946
- 0.971
- 0.96
- 0.163
- 0.165
- 0.967
- 0.167
- 0.969
- 0.142
- 0.971
- 0.163
train_loss:
- 1.831
- 1.852
- 0.861
- 0.696
- 0.635
- 0.58
- 1.941
- 2.724
- 1.334
- 2.769
- 1.636
- 1.309
- 2.582
- 1.235
- 1.128
- 0.975
- 0.93
- 0.54
- 1.524
- 1.819
- 0.908
- 2.577
- 0.799
- 2.057
- 0.691
- 1.329
- 0.87
- 1.196
- 1.227
- 1.611
- 1.699
- 1.002
- 1.202
- 1.015
- 0.816
- 0.44
- 0.39
- 1.012
- 1.086
- 0.689
- 1.297
- 0.723
- 2.885
- 1.089
- 1.17
- 0.82
- 0.391
- 1.326
- 1.102
- 0.58
- 0.374
- 0.316
- 0.306
- 1.034
- 1.022
- 0.587
- 1.194
- 0.94
- 0.653
- 0.683
- 1.298
- 1.0
- 0.646
- 0.741
- 0.711
- 0.893
- 0.745
- 0.902
- 0.741
- 0.787
- 0.688
- 0.894
- 0.877
- 0.57
- 0.659
- 0.836
- 0.702
- 0.721
- 0.68
- 0.483
- 0.516
- 0.29
- 0.65
- 0.832
- 0.474
- 0.531
- 0.451
- 1.602
- 0.692
- 0.445
- 0.271
- 0.238
- 1.04
- 0.785
- 0.49
- 0.444
- 0.381
- 0.929
- 0.432
- 0.689
unequal: 0
verbose: 1
