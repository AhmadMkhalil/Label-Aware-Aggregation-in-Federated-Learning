avg_train_accuracy: 0.023
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.053404255319148934
- 0.08329787234042553
- 0.10952127659574468
- 0.20941489361702129
- 0.28122340425531916
- 0.3528191489361702
- 0.40632978723404256
- 0.4559042553191489
- 0.5139893617021276
- 0.5082446808510638
- 0.5479255319148936
- 0.5643617021276596
- 0.5509042553191489
- 0.5811702127659575
- 0.5704255319148936
- 0.5956382978723405
- 0.6016489361702128
- 0.5915425531914894
- 0.6003723404255319
- 0.6036702127659574
- 0.6097340425531915
- 0.6247872340425532
- 0.6156382978723405
- 0.6222872340425532
- 0.6275
- 0.630531914893617
- 0.6395744680851064
- 0.6445212765957447
- 0.6394148936170213
- 0.6412234042553191
- 0.6441489361702127
- 0.6576595744680851
- 0.6484574468085106
- 0.6540957446808511
- 0.6563297872340426
- 0.6568085106382979
- 0.6603191489361702
- 0.6620744680851064
- 0.6648404255319149
- 0.6679255319148936
- 0.668031914893617
- 0.67
- 0.6802127659574468
- 0.6733510638297873
- 0.6742553191489362
- 0.6775531914893617
- 0.6794148936170212
- 0.6812234042553191
- 0.6818617021276596
- 0.6836170212765957
- 0.6842553191489362
- 0.6863297872340426
- 0.6864361702127659
- 0.6894148936170212
- 0.6882446808510638
- 0.6903723404255319
- 0.6924468085106383
- 0.6942553191489361
- 0.6953191489361702
- 0.6972340425531914
- 0.6978191489361703
- 0.6953723404255319
- 0.7008510638297872
- 0.6994148936170212
- 0.7011702127659575
- 0.7025
- 0.7048404255319148
- 0.7068617021276595
- 0.7075
- 0.71
- 0.7102127659574468
- 0.7118617021276595
- 0.7101595744680851
- 0.7097340425531915
- 0.7106382978723405
- 0.7126595744680851
- 0.7143617021276596
- 0.7153191489361702
- 0.716063829787234
- 0.7156914893617021
- 0.7170744680851063
- 0.7144148936170213
- 0.7146808510638298
- 0.7138829787234042
- 0.7148936170212766
- 0.7138829787234042
- 0.7147872340425532
- 0.7147340425531915
- 0.7149468085106383
- 0.7166489361702127
- 0.7146808510638298
- 0.7188297872340426
- 0.7222872340425532
- 0.7184574468085106
- 0.7209574468085106
- 0.722872340425532
- 0.7244148936170213
- 0.7258510638297873
- 0.7192021276595745
- 0.7230319148936171
test_loss_list:
- 3.7820666058858237
- 3.7209377002716066
- 3.546539233525594
- 3.2360288683573404
- 2.8980911350250245
- 2.644498240152995
- 2.4575185426076254
- 2.2961847305297853
- 2.3541945743560793
- 2.107668021519979
- 2.24634979724884
- 2.249676996866862
- 1.9890375979741415
- 2.185133803685506
- 1.9274516836802165
- 2.1497005287806195
- 2.1803923654556274
- 1.8785172335306803
- 1.8344383843739827
- 1.7852514171600342
- 1.7537689733505248
- 2.024382980664571
- 1.744132604598999
- 1.7124226299921672
- 1.6902985715866088
- 1.66440611521403
- 1.958808078765869
- 2.0035956001281736
- 1.6706240701675414
- 1.641296893755595
- 1.601127241452535
- 1.907279699643453
- 1.5899746084213258
- 1.5829937585194906
- 1.567661231358846
- 1.5423669815063477
- 1.5184156099955242
- 1.509629537264506
- 1.4944551547368368
- 1.4800129874547323
- 1.4873961369196573
- 1.4562677097320558
- 1.7724968957901002
- 1.4762910477320352
- 1.4692753330866495
- 1.4300962257385255
- 1.434147327740987
- 1.4391742944717407
- 1.4137126859029134
- 1.4039608097076417
- 1.409181235631307
- 1.3891298214594523
- 1.391141856511434
- 1.3763572438557943
- 1.3786803563435872
- 1.3749022102355957
- 1.3758020520210266
- 1.3682171336809794
- 1.358176407814026
- 1.3454058837890626
- 1.6617558113733928
- 1.374547377427419
- 1.6988725407918295
- 1.3848018980026244
- 1.3595877289772034
- 1.3474638311068217
- 1.3513557895024617
- 1.3386787796020507
- 1.3341738398869831
- 1.3303838404019674
- 1.321922051111857
- 1.3122226786613465
- 1.331308696269989
- 1.630621140797933
- 1.33897918065389
- 1.3272850275039674
- 1.3226836872100831
- 1.3163055753707886
- 1.311279231707255
- 1.3230090196927389
- 1.3092055082321168
- 1.6210865084330242
- 1.6760330041249594
- 1.3551933415730795
- 1.6607115809122721
- 1.694588238398234
- 1.3711839993794759
- 1.6853044573465983
- 1.3528014294306436
- 1.6465480327606201
- 1.3590779415766399
- 1.321974417368571
- 1.3142310714721679
- 1.6071853478749594
- 1.315692093372345
- 1.3083946490287781
- 1.3184187547365824
- 1.2845728230476379
- 1.606439356803894
- 1.3157559935251872
train_accuracy:
- 0.0
- 0.104
- 0.117
- 0.0
- 0.0
- 0.417
- 0.46
- 0.529
- 0.592
- 0.577
- 0.608
- 0.652
- 0.652
- 0.673
- 0.673
- 0.658
- 0.702
- 0.667
- 0.713
- 0.677
- 0.683
- 0.719
- 0.706
- 0.733
- 0.0
- 0.702
- 0.721
- 0.756
- 0.71
- 0.737
- 0.746
- 0.771
- 0.0
- 0.752
- 0.765
- 0.76
- 0.74
- 0.742
- 0.765
- 0.765
- 0.769
- 0.777
- 0.794
- 0.75
- 0.785
- 0.787
- 0.012
- 0.771
- 0.812
- 0.01
- 0.8
- 0.8
- 0.794
- 0.785
- 0.796
- 0.012
- 0.804
- 0.812
- 0.819
- 0.815
- 0.796
- 0.819
- 0.817
- 0.008
- 0.008
- 0.81
- 0.821
- 0.021
- 0.81
- 0.804
- 0.833
- 0.821
- 0.81
- 0.833
- 0.806
- 0.804
- 0.808
- 0.819
- 0.812
- 0.81
- 0.84
- 0.798
- 0.815
- 0.817
- 0.833
- 0.806
- 0.84
- 0.825
- 0.8
- 0.833
- 0.84
- 0.835
- 0.812
- 0.846
- 0.833
- 0.021
- 0.846
- 0.842
- 0.844
- 0.023
train_loss:
- 3.594
- 3.46
- 3.324
- 3.108
- 2.846
- 2.609
- 2.417
- 2.255
- 2.396
- 2.015
- 2.166
- 2.088
- 1.824
- 1.967
- 1.729
- 1.869
- 1.827
- 1.637
- 1.596
- 1.569
- 1.543
- 1.695
- 1.493
- 1.469
- 1.453
- 1.437
- 1.582
- 1.558
- 1.396
- 1.363
- 1.356
- 1.5
- 1.328
- 1.311
- 1.299
- 1.286
- 1.281
- 1.265
- 1.257
- 1.252
- 1.24
- 1.227
- 1.359
- 1.213
- 1.191
- 1.19
- 1.182
- 1.173
- 1.163
- 1.164
- 1.148
- 1.147
- 1.144
- 1.138
- 1.121
- 1.124
- 1.115
- 1.108
- 1.096
- 1.103
- 1.222
- 1.089
- 1.21
- 1.084
- 1.075
- 1.065
- 1.051
- 1.05
- 1.049
- 1.051
- 1.046
- 1.039
- 1.028
- 1.153
- 1.027
- 1.026
- 1.017
- 1.013
- 1.012
- 1.004
- 0.997
- 1.118
- 1.113
- 1.001
- 1.105
- 1.099
- 0.992
- 1.094
- 0.994
- 1.094
- 0.982
- 0.965
- 0.972
- 1.083
- 0.97
- 0.959
- 0.958
- 0.956
- 1.062
- 0.953
unequal: 0
verbose: 1
