avg_train_accuracy: 0.821
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.10053191489361703
- 0.075
- 0.1224468085106383
- 0.18101063829787234
- 0.2976595744680851
- 0.38335106382978723
- 0.4201595744680851
- 0.4481914893617021
- 0.4577127659574468
- 0.4853723404255319
- 0.5037234042553191
- 0.5172340425531915
- 0.5184042553191489
- 0.5412234042553191
- 0.10207446808510638
- 0.5417021276595745
- 0.555531914893617
- 0.5650531914893617
- 0.10345744680851064
- 0.573404255319149
- 0.5804255319148937
- 0.5887234042553191
- 0.5923936170212766
- 0.5995212765957447
- 0.605531914893617
- 0.6140425531914894
- 0.6156382978723405
- 0.614095744680851
- 0.6250531914893617
- 0.10542553191489362
- 0.6246276595744681
- 0.11430851063829787
- 0.6280851063829788
- 0.6329787234042553
- 0.6395212765957446
- 0.6356914893617022
- 0.6410638297872341
- 0.6455851063829787
- 0.11882978723404256
- 0.6523936170212766
- 0.6522872340425532
- 0.6540957446808511
- 0.6588297872340425
- 0.6604255319148936
- 0.6604787234042553
- 0.6590425531914894
- 0.6643085106382979
- 0.6632978723404256
- 0.12069148936170213
- 0.6699468085106383
- 0.6692553191489362
- 0.6683510638297873
- 0.6699468085106383
- 0.1346808510638298
- 0.6768085106382978
- 0.6763829787234042
- 0.6781382978723405
- 0.6781914893617021
- 0.6763297872340426
- 0.6772340425531915
- 0.68
- 0.1503191489361702
- 0.693936170212766
- 0.6832978723404255
- 0.6853191489361702
- 0.6852127659574468
- 0.6869148936170213
- 0.6897340425531915
- 0.6911702127659575
- 0.6875531914893617
- 0.6893617021276596
- 0.6911170212765958
- 0.6920212765957446
- 0.16670212765957446
- 0.7033510638297872
- 0.6980851063829787
- 0.6945744680851064
- 0.6962765957446808
- 0.6992021276595745
- 0.18148936170212765
- 0.1494148936170213
- 0.13446808510638297
- 0.7128723404255319
- 0.6986170212765958
- 0.7002127659574469
- 0.6933510638297873
- 0.695
- 0.6958510638297872
- 0.696063829787234
- 0.1879255319148936
- 0.7127127659574468
- 0.7092021276595745
- 0.7043085106382979
- 0.7025
- 0.704627659574468
- 0.7018085106382979
- 0.2021808510638298
- 0.7195212765957447
- 0.7123404255319149
- 0.7048936170212766
test_loss_list:
- 14.765119654337566
- 3.745680554707845
- 3.612437505722046
- 3.3413372453053793
- 3.027986952463786
- 2.75650647799174
- 2.648809849421183
- 2.522578109105428
- 2.4956509685516357
- 2.438492186864217
- 2.408489329020182
- 2.3579074859619142
- 2.379295597076416
- 2.343469082514445
- 12.432299677530924
- 1.9765924882888795
- 2.0117069975535076
- 2.076722815831502
- 11.198315862019857
- 1.8567561928431193
- 1.9294640525182087
- 1.9503843561808267
- 1.955485912958781
- 1.9543164857228597
- 1.980006472269694
- 1.9846414105097452
- 1.9955427471796672
- 1.9973044888178508
- 2.0268850390116375
- 9.782979965209961
- 1.6384869607289632
- 7.862719548543295
- 1.57879412651062
- 1.6563520844777424
- 1.7050142351786295
- 1.7438170115152996
- 1.7661782868703206
- 1.8125089518229167
- 7.565193595886231
- 1.5459311962127686
- 1.595500996907552
- 1.6545091358820598
- 1.664151422182719
- 1.7113927920659384
- 1.732999013264974
- 1.7498816808064779
- 1.745272029240926
- 1.795790516535441
- 7.504964726765951
- 1.4881177441279094
- 1.5625960938135783
- 1.6469409529368082
- 1.6917075173060099
- 7.030510940551758
- 1.4751620546976725
- 1.5532489681243897
- 1.566312681833903
- 1.608107180595398
- 1.690931708017985
- 1.655358419418335
- 1.6997708288828532
- 6.40078961054484
- 1.4119370810190837
- 1.5050294589996338
- 1.5560849857330323
- 1.6417592891057333
- 1.63390154838562
- 1.626208740870158
- 1.634358491897583
- 1.6751985804239908
- 1.7212839317321778
- 1.729146359761556
- 1.7178736130396526
- 6.300283552805583
- 1.4203844436009725
- 1.4734940926233928
- 1.529032572110494
- 1.5825602261225382
- 1.6001750532786052
- 6.08276475906372
- 7.3606634585062665
- 8.197197310129802
- 1.337410967350006
- 1.4510842847824097
- 1.4904593070348104
- 1.550611964861552
- 1.5591425752639771
- 1.62446533203125
- 1.6714363114039104
- 5.953351351420085
- 1.3397891028722126
- 1.4402548313140868
- 1.4971733713150024
- 1.5330294132232667
- 1.5294088395436605
- 1.5879343763987224
- 5.771538734436035
- 1.3436932961146038
- 1.430626112620036
- 1.4948514445622763
train_accuracy:
- 0.163
- 0.042
- 0.104
- 0.219
- 0.327
- 0.454
- 0.483
- 0.51
- 0.537
- 0.525
- 0.583
- 0.571
- 0.583
- 0.617
- 0.163
- 0.625
- 0.646
- 0.662
- 0.165
- 0.667
- 0.677
- 0.654
- 0.671
- 0.696
- 0.692
- 0.721
- 0.696
- 0.665
- 0.725
- 0.165
- 0.727
- 0.165
- 0.719
- 0.702
- 0.754
- 0.713
- 0.746
- 0.754
- 0.165
- 0.742
- 0.737
- 0.713
- 0.74
- 0.744
- 0.748
- 0.752
- 0.744
- 0.767
- 0.165
- 0.773
- 0.735
- 0.781
- 0.74
- 0.167
- 0.769
- 0.75
- 0.742
- 0.758
- 0.79
- 0.769
- 0.81
- 0.167
- 0.744
- 0.767
- 0.804
- 0.802
- 0.81
- 0.744
- 0.812
- 0.8
- 0.763
- 0.815
- 0.783
- 0.167
- 0.806
- 0.779
- 0.806
- 0.806
- 0.821
- 0.167
- 0.167
- 0.167
- 0.787
- 0.8
- 0.775
- 0.792
- 0.796
- 0.794
- 0.781
- 0.167
- 0.798
- 0.823
- 0.827
- 0.819
- 0.773
- 0.815
- 0.167
- 0.783
- 0.825
- 0.821
train_loss:
- 1.629
- 4.028
- 3.767
- 3.583
- 3.295
- 3.02
- 2.866
- 2.665
- 2.491
- 2.481
- 2.333
- 2.298
- 2.225
- 2.207
- 0.984
- 2.504
- 2.085
- 2.009
- 0.681
- 2.313
- 1.895
- 1.955
- 1.82
- 1.864
- 1.787
- 1.819
- 1.757
- 1.79
- 1.675
- 0.68
- 2.058
- 0.479
- 1.969
- 1.721
- 1.677
- 1.608
- 1.591
- 1.56
- 0.581
- 1.82
- 1.595
- 1.546
- 1.569
- 1.51
- 1.539
- 1.477
- 1.527
- 1.443
- 0.605
- 1.658
- 1.464
- 1.386
- 1.42
- 0.504
- 1.672
- 1.374
- 1.44
- 1.388
- 1.356
- 1.395
- 1.38
- 0.554
- 1.574
- 1.341
- 1.351
- 1.292
- 1.306
- 1.331
- 1.332
- 1.318
- 1.277
- 1.29
- 1.355
- 0.609
- 1.54
- 1.256
- 1.274
- 1.248
- 1.236
- 0.489
- 0.197
- 0.168
- 1.643
- 1.305
- 1.249
- 1.241
- 1.269
- 1.218
- 1.18
- 0.474
- 1.492
- 1.23
- 1.194
- 1.21
- 1.254
- 1.19
- 0.463
- 1.441
- 1.2
- 1.18
unequal: 0
verbose: 1
