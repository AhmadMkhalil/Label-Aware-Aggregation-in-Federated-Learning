avg_train_accuracy: 0.835
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0598404255319149
- 0.21015957446808511
- 0.2540425531914894
- 0.24515957446808512
- 0.2899468085106383
- 0.35521276595744683
- 0.33409574468085107
- 0.38659574468085106
- 0.3959042553191489
- 0.42696808510638296
- 0.3806914893617021
- 0.4039893617021277
- 0.42398936170212764
- 0.41723404255319146
- 0.44122340425531914
- 0.4060106382978723
- 0.4475531914893617
- 0.4512765957446809
- 0.45867021276595743
- 0.47888297872340424
- 0.4702127659574468
- 0.4704255319148936
- 0.4768085106382979
- 0.48143617021276597
- 0.47925531914893615
- 0.4833510638297872
- 0.49601063829787234
- 0.48175531914893616
- 0.5185106382978724
- 0.4922872340425532
- 0.4951595744680851
- 0.5269148936170213
- 0.5397340425531915
- 0.491436170212766
- 0.4952659574468085
- 0.49457446808510636
- 0.5396276595744681
- 0.5021808510638298
- 0.5562234042553191
- 0.5434574468085106
- 0.571063829787234
- 0.5089361702127659
- 0.551968085106383
- 0.5587765957446809
- 0.5673404255319149
- 0.5525
- 0.5202127659574468
- 0.5137234042553191
- 0.5635106382978723
- 0.5150531914893617
- 0.5197872340425532
- 0.5207446808510638
- 0.5802127659574469
- 0.5795744680851064
- 0.5254255319148936
- 0.5306382978723404
- 0.5498936170212766
- 0.5139893617021276
- 0.5216489361702128
- 0.6037765957446809
- 0.5160106382978723
- 0.5780851063829787
- 0.5785638297872341
- 0.6261170212765957
- 0.5364893617021277
- 0.5858510638297872
- 0.5945212765957447
- 0.5943085106382979
- 0.5336170212765957
- 0.5171808510638298
- 0.5779787234042553
- 0.5874468085106384
- 0.6039361702127659
- 0.604095744680851
- 0.5445744680851063
- 0.6044148936170213
- 0.5497340425531915
- 0.6042021276595745
- 0.5908510638297872
- 0.6128191489361702
- 0.6153723404255319
- 0.5383510638297873
- 0.5384042553191489
- 0.5223404255319148
- 0.5456382978723404
- 0.5488297872340425
- 0.5997340425531915
- 0.5364893617021277
- 0.6153191489361702
- 0.6175
- 0.646436170212766
- 0.5373404255319149
- 0.6260638297872341
- 0.5575
- 0.6230851063829788
- 0.6230851063829788
- 0.6070212765957447
- 0.6688297872340425
- 0.5241489361702127
- 0.6268617021276596
test_loss_list:
- 3.7595496940612794
- 3.6444531790415446
- 3.362736889521281
- 3.1540895620981853
- 3.003371222813924
- 3.1011953067779543
- 2.7736129570007324
- 2.983599173227946
- 3.0419046370188396
- 3.753793903986613
- 2.619469029108683
- 2.600682195027669
- 2.556466646194458
- 2.4265123971303306
- 3.0428233528137207
- 2.2998600514729817
- 2.3320887724558514
- 2.9650841744740806
- 2.367934916814168
- 2.4024869918823244
- 2.273671228090922
- 3.8262646611531577
- 2.2671970653533937
- 2.3733055369059244
- 3.86166779200236
- 2.9611105346679687
- 2.347631713549296
- 2.9735890420277915
- 2.315373617808024
- 3.1086458015441893
- 2.182973624865214
- 2.292718949317932
- 2.3141318146387735
- 2.876355717976888
- 2.9699786281585694
- 2.84911789894104
- 2.2417973327636718
- 2.8628719679514565
- 1.906393575668335
- 2.1887292369206746
- 1.8810423612594604
- 2.751903117497762
- 2.094270869890849
- 2.138002495765686
- 2.2113570594787597
- 2.104493432044983
- 2.8690658028920493
- 2.827407290140788
- 2.099816697438558
- 2.832622702916463
- 2.8454470507303875
- 2.9315553601582844
- 2.236924525896708
- 2.3124598693847656
- 3.043770144780477
- 3.024428520202637
- 2.220961880683899
- 2.886808993021647
- 2.953123092651367
- 1.8272848399480184
- 3.7189220333099366
- 2.1108002630869547
- 2.0829161643981933
- 1.794363751411438
- 2.674143517812093
- 2.0424072790145873
- 2.1086272541681925
- 2.0536816946665444
- 2.7257714653015137
- 3.6869242159525553
- 2.1110349384943645
- 2.080234301884969
- 2.0933777046203614
- 2.1242482964197795
- 2.739084250132243
- 2.105989235242208
- 2.73352889696757
- 2.0871996625264484
- 2.09254860719045
- 2.034572710990906
- 2.119688542683919
- 2.675102726618449
- 2.7989360586802166
- 3.6930219237009685
- 2.7319119135538736
- 2.907789758046468
- 2.1863890663782755
- 2.8174346097310385
- 2.1397477277119954
- 2.2253262837727865
- 1.8397099002202353
- 2.66580632686615
- 2.0276040029525757
- 2.7590158875783284
- 2.123531139691671
- 2.2101023387908936
- 2.062412347793579
- 1.7805655511220295
- 3.4831082248687744
- 2.016753525733948
train_accuracy:
- 0.0
- 0.342
- 0.41
- 0.002
- 0.404
- 0.625
- 0.0
- 0.0
- 0.654
- 0.748
- 0.61
- 0.025
- 0.006
- 0.0
- 0.723
- 0.479
- 0.0
- 0.731
- 0.662
- 0.708
- 0.004
- 0.769
- 0.71
- 0.773
- 0.781
- 0.775
- 0.706
- 0.787
- 0.021
- 0.0
- 0.744
- 0.767
- 0.017
- 0.802
- 0.8
- 0.792
- 0.023
- 0.792
- 0.05
- 0.798
- 0.654
- 0.806
- 0.785
- 0.042
- 0.029
- 0.8
- 0.825
- 0.033
- 0.04
- 0.821
- 0.808
- 0.821
- 0.787
- 0.798
- 0.827
- 0.008
- 0.794
- 0.84
- 0.04
- 0.654
- 0.865
- 0.029
- 0.058
- 0.69
- 0.842
- 0.017
- 0.033
- 0.075
- 0.867
- 0.848
- 0.81
- 0.852
- 0.81
- 0.094
- 0.875
- 0.069
- 0.852
- 0.05
- 0.829
- 0.806
- 0.056
- 0.842
- 0.856
- 0.846
- 0.865
- 0.842
- 0.05
- 0.852
- 0.835
- 0.025
- 0.725
- 0.863
- 0.029
- 0.827
- 0.023
- 0.019
- 0.844
- 0.083
- 0.85
- 0.835
train_loss:
- 3.023
- 3.508
- 2.613
- 2.012
- 1.788
- 1.929
- 1.671
- 1.779
- 1.662
- 1.787
- 1.395
- 1.29
- 1.25
- 1.27
- 1.389
- 1.025
- 1.175
- 1.323
- 1.119
- 1.085
- 1.103
- 1.416
- 1.076
- 1.014
- 1.347
- 1.151
- 0.995
- 1.145
- 0.964
- 1.096
- 0.999
- 0.934
- 0.909
- 1.101
- 1.064
- 1.056
- 0.901
- 1.049
- 0.761
- 0.885
- 0.73
- 1.022
- 0.875
- 0.852
- 0.837
- 0.851
- 0.965
- 0.981
- 0.842
- 0.963
- 0.944
- 0.941
- 0.799
- 0.785
- 0.914
- 0.904
- 0.814
- 0.924
- 0.906
- 0.688
- 1.042
- 0.799
- 0.796
- 0.648
- 0.909
- 0.775
- 0.757
- 0.772
- 0.873
- 0.991
- 0.771
- 0.759
- 0.746
- 0.742
- 0.851
- 0.734
- 0.852
- 0.741
- 0.734
- 0.737
- 0.724
- 0.85
- 0.82
- 0.947
- 0.836
- 0.817
- 0.721
- 0.827
- 0.709
- 0.696
- 0.591
- 0.839
- 0.711
- 0.805
- 0.699
- 0.682
- 0.701
- 0.581
- 0.941
- 0.703
unequal: 0
verbose: 1
