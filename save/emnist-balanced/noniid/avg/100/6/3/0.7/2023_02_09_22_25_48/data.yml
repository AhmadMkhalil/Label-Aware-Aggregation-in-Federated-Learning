avg_train_accuracy: 0.842
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.027872340425531914
- 0.1175
- 0.25632978723404254
- 0.2722872340425532
- 0.31920212765957445
- 0.33601063829787237
- 0.3540957446808511
- 0.3622872340425532
- 0.3620212765957447
- 0.4096808510638298
- 0.3798936170212766
- 0.425
- 0.40106382978723404
- 0.42021276595744683
- 0.4118617021276596
- 0.4237234042553191
- 0.4428191489361702
- 0.43111702127659574
- 0.4378191489361702
- 0.44303191489361704
- 0.45872340425531916
- 0.4525531914893617
- 0.4581914893617021
- 0.4727659574468085
- 0.46941489361702127
- 0.4774468085106383
- 0.46643617021276595
- 0.4847872340425532
- 0.47638297872340424
- 0.4801063829787234
- 0.48212765957446807
- 0.486436170212766
- 0.49920212765957445
- 0.4926063829787234
- 0.49617021276595746
- 0.49696808510638296
- 0.4925
- 0.5176595744680851
- 0.5234042553191489
- 0.5011702127659574
- 0.5355851063829787
- 0.5319148936170213
- 0.5443085106382979
- 0.5451063829787234
- 0.5150531914893617
- 0.5178191489361702
- 0.5066489361702128
- 0.5081914893617021
- 0.5049468085106383
- 0.5478723404255319
- 0.5156914893617022
- 0.5212234042553191
- 0.5102659574468085
- 0.5209574468085106
- 0.5219680851063829
- 0.5266489361702128
- 0.5106382978723404
- 0.523936170212766
- 0.5673936170212766
- 0.5287765957446808
- 0.5792021276595745
- 0.5802127659574469
- 0.5151595744680851
- 0.5398936170212766
- 0.5386702127659575
- 0.5370744680851064
- 0.5461170212765958
- 0.5375531914893616
- 0.5377127659574468
- 0.535904255319149
- 0.5328191489361702
- 0.5364893617021277
- 0.5912765957446808
- 0.5188829787234043
- 0.5190957446808511
- 0.5207978723404255
- 0.586968085106383
- 0.5225
- 0.5553191489361702
- 0.5589893617021277
- 0.5635638297872341
- 0.55
- 0.5483510638297873
- 0.546968085106383
- 0.6084574468085107
- 0.523563829787234
- 0.5503191489361702
- 0.5220212765957447
- 0.5553191489361702
- 0.6058510638297873
- 0.6097872340425532
- 0.5270744680851064
- 0.617872340425532
- 0.5471276595744681
- 0.5635638297872341
- 0.5300531914893617
- 0.5553191489361702
- 0.5483510638297873
- 0.5593617021276596
- 0.5531914893617021
test_loss_list:
- 3.8111124738057454
- 3.75910751024882
- 3.5864341831207276
- 3.14071364402771
- 3.18599196434021
- 3.0008104451497397
- 2.942468640009562
- 2.9108158111572267
- 2.621470330556234
- 3.3241946061452228
- 2.5087289301554363
- 3.3156445121765135
- 2.4400077438354493
- 2.8403938897450765
- 2.6601580715179445
- 2.3647388362884523
- 3.182872527440389
- 2.6293185583750405
- 2.306793518066406
- 2.6405869007110594
- 3.165021931330363
- 2.619872039159139
- 2.630500275293986
- 3.3976367696126304
- 2.585232547124227
- 2.718900868097941
- 2.569724645614624
- 2.140186999638875
- 2.572328977584839
- 2.5829946931203205
- 2.47388440767924
- 3.181396942138672
- 2.0522552299499512
- 2.5452746709187823
- 2.4959137535095213
- 2.5272311051686605
- 2.5007849375406903
- 2.016611590385437
- 1.9962379423777263
- 3.129488388697306
- 1.9345529158910115
- 1.9941219250361124
- 1.9386269442240398
- 1.9377049541473388
- 2.438276392618815
- 2.2977067041397095
- 3.133230047225952
- 2.3126239744822183
- 3.025801591873169
- 1.9182703145345052
- 2.4357215356826782
- 2.320200252532959
- 3.021948226292928
- 2.387342521349589
- 2.3335243240992227
- 2.392421181996663
- 2.972980028788249
- 2.3543743101755776
- 1.8980849091211955
- 2.408337712287903
- 1.8670105012257894
- 1.8729376204808552
- 2.902192039489746
- 2.2631777413686116
- 2.245610992113749
- 2.3460207017262777
- 2.3541027800242107
- 2.2247058804829916
- 2.2937976217269895
- 2.286657204627991
- 2.2486058489481606
- 2.2851072057088215
- 1.8198889366785684
- 2.9077195835113527
- 2.92618688583374
- 2.989426482518514
- 1.8485444895426433
- 2.9689188321431477
- 2.307993909517924
- 2.367160356839498
- 2.3524376646677654
- 2.2356560866038007
- 2.235206184387207
- 2.2082859961191814
- 1.8270125881830852
- 2.8425563907623292
- 2.1710403029123944
- 2.9428561147054038
- 2.235874319076538
- 1.8506864992777508
- 1.8309095398585002
- 2.775722173055013
- 1.7676181968053182
- 2.2356650034586587
- 2.2237806781133016
- 2.8950834306081137
- 2.1774929745992027
- 2.2428600374857584
- 2.260340016682943
- 2.1892299699783324
train_accuracy:
- 0.046
- 0.202
- 0.471
- 0.431
- 0.002
- 0.56
- 0.602
- 0.588
- 0.546
- 0.677
- 0.592
- 0.665
- 0.642
- 0.675
- 0.66
- 0.017
- 0.708
- 0.002
- 0.685
- 0.677
- 0.744
- 0.717
- 0.748
- 0.744
- 0.773
- 0.727
- 0.0
- 0.688
- 0.746
- 0.002
- 0.75
- 0.838
- 0.006
- 0.798
- 0.0
- 0.794
- 0.796
- 0.023
- 0.025
- 0.84
- 0.758
- 0.002
- 0.765
- 0.05
- 0.012
- 0.779
- 0.829
- 0.773
- 0.817
- 0.771
- 0.01
- 0.0
- 0.815
- 0.777
- 0.771
- 0.04
- 0.817
- 0.8
- 0.023
- 0.012
- 0.756
- 0.09
- 0.821
- 0.79
- 0.804
- 0.819
- 0.025
- 0.0
- 0.854
- 0.827
- 0.819
- 0.827
- 0.065
- 0.827
- 0.819
- 0.86
- 0.785
- 0.844
- 0.835
- 0.023
- 0.838
- 0.819
- 0.829
- 0.8
- 0.048
- 0.846
- 0.002
- 0.833
- 0.821
- 0.012
- 0.802
- 0.84
- 0.094
- 0.002
- 0.852
- 0.833
- 0.865
- 0.831
- 0.829
- 0.842
train_loss:
- 3.494
- 3.245
- 2.798
- 2.052
- 2.008
- 1.863
- 1.728
- 1.635
- 1.424
- 1.666
- 1.331
- 1.565
- 1.249
- 1.357
- 1.303
- 1.161
- 1.399
- 1.23
- 1.096
- 1.183
- 1.286
- 1.14
- 1.156
- 1.247
- 1.107
- 1.071
- 1.08
- 0.958
- 1.044
- 1.057
- 1.025
- 1.115
- 0.92
- 1.0
- 0.977
- 0.973
- 0.989
- 0.866
- 0.854
- 1.06
- 0.859
- 0.833
- 0.827
- 0.824
- 0.928
- 0.917
- 1.004
- 0.919
- 0.985
- 0.806
- 0.887
- 0.882
- 0.974
- 0.878
- 0.868
- 0.864
- 0.945
- 0.867
- 0.754
- 0.848
- 0.747
- 0.752
- 0.926
- 0.842
- 0.83
- 0.823
- 0.815
- 0.823
- 0.807
- 0.803
- 0.818
- 0.802
- 0.718
- 0.891
- 0.89
- 0.883
- 0.716
- 0.887
- 0.793
- 0.789
- 0.776
- 0.78
- 0.77
- 0.784
- 0.683
- 0.855
- 0.774
- 0.865
- 0.764
- 0.687
- 0.676
- 0.844
- 0.682
- 0.76
- 0.761
- 0.84
- 0.748
- 0.755
- 0.741
- 0.746
unequal: 0
verbose: 1
