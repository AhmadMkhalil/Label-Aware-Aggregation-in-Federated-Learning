avg_train_accuracy: 0.844
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.08148936170212766
- 0.09367021276595745
- 0.09702127659574468
- 0.07930851063829787
- 0.18680851063829787
- 0.2518085106382979
- 0.09351063829787234
- 0.26090425531914896
- 0.2915957446808511
- 0.09702127659574468
- 0.3049468085106383
- 0.32851063829787236
- 0.09218085106382978
- 0.3353191489361702
- 0.3567021276595745
- 0.3668085106382979
- 0.38351063829787235
- 0.38978723404255317
- 0.40361702127659577
- 0.4122340425531915
- 0.4186170212765957
- 0.4200531914893617
- 0.42867021276595746
- 0.43329787234042555
- 0.43882978723404253
- 0.4461702127659574
- 0.44643617021276594
- 0.0973936170212766
- 0.10021276595744681
- 0.44515957446808513
- 0.4486702127659574
- 0.4520212765957447
- 0.45867021276595743
- 0.465
- 0.4677127659574468
- 0.09845744680851064
- 0.10430851063829787
- 0.4676063829787234
- 0.4678191489361702
- 0.4754255319148936
- 0.47686170212765955
- 0.48186170212765955
- 0.48611702127659573
- 0.10792553191489361
- 0.4848404255319149
- 0.4875531914893617
- 0.491436170212766
- 0.10271276595744681
- 0.11106382978723404
- 0.4895212765957447
- 0.4898936170212766
- 0.1295212765957447
- 0.4947872340425532
- 0.4952127659574468
- 0.49632978723404253
- 0.4980851063829787
- 0.10808510638297872
- 0.5019148936170212
- 0.4980851063829787
- 0.49936170212765957
- 0.5017553191489361
- 0.5035106382978723
- 0.5051595744680851
- 0.14574468085106382
- 0.5131914893617021
- 0.1773936170212766
- 0.5157978723404255
- 0.51
- 0.5102659574468085
- 0.5096808510638298
- 0.511436170212766
- 0.5082446808510638
- 0.5118617021276596
- 0.5128191489361702
- 0.5110106382978723
- 0.5146808510638298
- 0.175
- 0.5263829787234042
- 0.2125
- 0.5332978723404256
- 0.13813829787234042
- 0.08691489361702127
- 0.15898936170212766
- 0.14617021276595746
- 0.14877659574468086
- 0.16430851063829788
- 0.16404255319148936
- 0.5299468085106382
- 0.5151595744680851
- 0.19585106382978723
- 0.16824468085106384
- 0.5358510638297872
- 0.518031914893617
- 0.5157446808510638
- 0.5186702127659575
- 0.5168085106382979
- 0.23888297872340425
- 0.535372340425532
- 0.5249468085106384
- 0.5237234042553192
test_loss_list:
- 13.580231437683105
- 16.110032857259114
- 16.78233070373535
- 3.6718205801645913
- 3.6324614461263023
- 3.768817122777303
- 11.335555623372397
- 3.609598436355591
- 3.807106027603149
- 8.799652938842774
- 3.765753564834595
- 3.9073181470235188
- 10.857973187764486
- 3.717437988917033
- 3.828451191584269
- 4.081990900039673
- 4.110303500493368
- 4.068592297236124
- 4.313430312474568
- 4.35347715695699
- 4.569416313171387
- 4.67287535349528
- 4.697283592224121
- 4.744838116963704
- 4.8730494435628255
- 4.756211274464925
- 4.826761207580566
- 9.359076156616212
- 9.052265446980794
- 3.667727518081665
- 4.0450031153361
- 4.084030377070109
- 4.223819913864136
- 4.375368970235189
- 4.3260242462158205
- 10.313993822733561
- 9.5271515528361
- 3.4938869921366376
- 3.823251276016235
- 4.1365879408518476
- 4.137640841801962
- 4.134196926752726
- 4.168560018539429
- 8.241613101959228
- 3.71336088180542
- 4.006840073267619
- 3.9795262527465822
- 9.984089126586914
- 6.913941904703776
- 3.1865717347462974
- 3.4534017658233642
- 7.360584023793538
- 3.3335106913248698
- 3.5796810881296794
- 3.675958855946859
- 3.8651463572184244
- 8.879717051188152
- 3.3094612566630044
- 3.542281109491984
- 3.699279950459798
- 3.80132963180542
- 3.9792635281880697
- 3.9054642740885415
- 6.880937048594157
- 3.3150737698872885
- 6.503644669850667
- 3.455567623774211
- 3.598893756866455
- 3.6517333380381265
- 3.9396138127644855
- 4.009719244639078
- 4.231579875946045
- 4.147491938273112
- 4.112479435602824
- 4.14739891688029
- 4.090524272918701
- 6.484364369710287
- 3.59309489885966
- 6.212577699025472
- 3.571960767110189
- 7.28043186823527
- 8.577552833557128
- 5.2790260505676265
- 7.327847550710042
- 5.85117379506429
- 6.722701918284098
- 6.0832536506652835
- 2.3861733786265056
- 2.748971087137858
- 5.459400100708008
- 5.156380093892415
- 2.5310108629862467
- 2.8397546577453614
- 3.089060287475586
- 3.3284794902801513
- 3.311027431488037
- 5.076579570770264
- 3.008831284840902
- 3.1668029340108235
- 3.311068458557129
train_accuracy:
- 0.163
- 0.16
- 0.158
- 0.127
- 0.331
- 0.421
- 0.15
- 0.408
- 0.477
- 0.144
- 0.487
- 0.54
- 0.135
- 0.552
- 0.59
- 0.594
- 0.677
- 0.65
- 0.679
- 0.665
- 0.685
- 0.673
- 0.715
- 0.725
- 0.731
- 0.721
- 0.725
- 0.165
- 0.154
- 0.758
- 0.71
- 0.727
- 0.746
- 0.729
- 0.735
- 0.156
- 0.16
- 0.733
- 0.744
- 0.773
- 0.783
- 0.792
- 0.798
- 0.163
- 0.783
- 0.775
- 0.81
- 0.165
- 0.165
- 0.773
- 0.792
- 0.165
- 0.802
- 0.781
- 0.802
- 0.8
- 0.165
- 0.804
- 0.8
- 0.81
- 0.802
- 0.804
- 0.842
- 0.165
- 0.808
- 0.165
- 0.812
- 0.829
- 0.831
- 0.823
- 0.833
- 0.821
- 0.835
- 0.817
- 0.838
- 0.842
- 0.167
- 0.835
- 0.167
- 0.823
- 0.165
- 0.16
- 0.165
- 0.163
- 0.165
- 0.16
- 0.165
- 0.827
- 0.825
- 0.165
- 0.165
- 0.81
- 0.823
- 0.842
- 0.825
- 0.825
- 0.165
- 0.844
- 0.848
- 0.844
train_loss:
- 2.206
- 0.893
- 0.61
- 3.909
- 3.345
- 2.966
- 2.133
- 3.197
- 2.609
- 1.306
- 2.793
- 2.463
- 1.551
- 2.679
- 2.289
- 2.159
- 2.13
- 2.081
- 1.981
- 1.944
- 1.828
- 1.822
- 1.767
- 1.683
- 1.639
- 1.697
- 1.682
- 2.44
- 1.197
- 2.168
- 1.682
- 1.647
- 1.551
- 1.54
- 1.482
- 1.567
- 0.887
- 1.939
- 1.516
- 1.429
- 1.4
- 1.423
- 1.409
- 0.701
- 1.648
- 1.339
- 1.337
- 1.349
- 0.821
- 1.736
- 1.354
- 0.545
- 1.516
- 1.273
- 1.227
- 1.191
- 0.974
- 1.507
- 1.17
- 1.15
- 1.165
- 1.104
- 1.178
- 0.648
- 1.413
- 0.458
- 1.335
- 1.154
- 1.141
- 1.061
- 1.086
- 1.026
- 1.044
- 1.08
- 1.061
- 1.068
- 0.614
- 1.283
- 0.422
- 1.259
- 1.07
- 1.882
- 0.661
- 1.06
- 0.767
- 0.798
- 0.476
- 1.855
- 1.17
- 0.58
- 0.512
- 1.42
- 1.114
- 1.032
- 1.015
- 1.023
- 0.475
- 1.25
- 1.039
- 1.022
unequal: 0
verbose: 1
