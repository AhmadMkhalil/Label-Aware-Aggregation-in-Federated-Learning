avg_train_accuracy: 0.829
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041914893617021276
- 0.13585106382978723
- 0.1295744680851064
- 0.3098936170212766
- 0.14122340425531915
- 0.1620744680851064
- 0.22
- 0.35452127659574467
- 0.40127659574468083
- 0.2829255319148936
- 0.3775
- 0.42601063829787233
- 0.2517553191489362
- 0.3226063829787234
- 0.415
- 0.4353191489361702
- 0.4406914893617021
- 0.45324468085106384
- 0.45797872340425533
- 0.42398936170212764
- 0.46393617021276595
- 0.4627659574468085
- 0.4685106382978723
- 0.47138297872340423
- 0.42127659574468085
- 0.4921808510638298
- 0.4945212765957447
- 0.4950531914893617
- 0.48404255319148937
- 0.4849468085106383
- 0.488031914893617
- 0.504095744680851
- 0.4776595744680851
- 0.4925
- 0.4944148936170213
- 0.5141489361702127
- 0.5202659574468085
- 0.4971808510638298
- 0.509468085106383
- 0.5127659574468085
- 0.5243617021276595
- 0.5165425531914893
- 0.5434574468085106
- 0.5425531914893617
- 0.5362765957446809
- 0.5485638297872341
- 0.5511702127659575
- 0.5079255319148936
- 0.5446276595744681
- 0.5529255319148936
- 0.5472872340425532
- 0.5632446808510638
- 0.5651063829787234
- 0.5101595744680851
- 0.5537765957446809
- 0.5329787234042553
- 0.5652659574468085
- 0.5360106382978723
- 0.5124468085106383
- 0.563404255319149
- 0.5696808510638298
- 0.5137765957446808
- 0.5536170212765957
- 0.5163297872340425
- 0.5518085106382978
- 0.5628723404255319
- 0.5661170212765958
- 0.5177659574468085
- 0.5643085106382979
- 0.5702127659574469
- 0.5647872340425532
- 0.5693085106382979
- 0.5738297872340425
- 0.5682978723404255
- 0.6030319148936171
- 0.5749468085106383
- 0.5907446808510638
- 0.520904255319149
- 0.5201595744680851
- 0.5742553191489361
- 0.5203723404255319
- 0.5795744680851064
- 0.5204787234042553
- 0.5233510638297872
- 0.5729787234042554
- 0.5666489361702127
- 0.5759042553191489
- 0.5751595744680851
- 0.5668085106382978
- 0.5228191489361702
- 0.5780851063829787
- 0.5774468085106383
- 0.523563829787234
- 0.5822340425531914
- 0.5829255319148936
- 0.5835638297872341
- 0.5821276595744681
- 0.6162765957446809
- 0.5921276595744681
- 0.5844148936170213
test_loss_list:
- 3.789964869817098
- 3.8405087248484295
- 3.6648341178894044
- 3.8159203656514484
- 3.42608029683431
- 3.172397197087606
- 3.0103960100809735
- 2.928396701812744
- 3.7560791714986164
- 2.870630111694336
- 2.8688916397094726
- 4.014302333196004
- 2.971605494817098
- 2.5469951502482098
- 2.6762342707316082
- 2.6810534381866455
- 2.7278725306193032
- 3.941110219955444
- 4.175036417643229
- 2.3645710277557375
- 3.741379330952962
- 2.575285647710164
- 4.009671586354574
- 2.611249885559082
- 2.470227133433024
- 2.6711866887410483
- 2.550592304865519
- 2.467115640640259
- 3.8555302588144937
- 4.02757895787557
- 4.235699230829875
- 2.610532646179199
- 2.3153499142328897
- 3.9007395140329995
- 3.9826417128245035
- 2.6272360134124755
- 2.8333577219645183
- 4.069256194432577
- 2.577911189397176
- 2.2973168436686198
- 2.1436867173512777
- 1.967167272567749
- 2.433232488632202
- 2.1369185622533164
- 2.3747992610931394
- 2.4810208098093667
- 2.192456521987915
- 3.824898977279663
- 2.3093680858612062
- 1.944114416440328
- 2.2311512231826782
- 2.4217528247833253
- 2.146613279978434
- 3.725766544342041
- 2.2498910188674928
- 2.33536904335022
- 1.8982605934143066
- 2.1323439566294353
- 3.5015281295776366
- 2.181205275853475
- 2.4325400416056313
- 3.6179158020019533
- 1.887252640724182
- 3.481972869237264
- 2.228471884727478
- 2.2951792669296265
- 2.069984583854675
- 3.4536882209777833
- 2.01929571946462
- 2.0147187662124635
- 2.1858866802851358
- 2.200279148419698
- 2.1268131144841513
- 2.3167388677597045
- 1.7930867115656535
- 1.9905467271804809
- 1.8877898693084716
- 3.2166201400756838
- 3.44970664024353
- 2.1411888806025186
- 3.5366861883799237
- 1.898463077545166
- 3.456203079223633
- 3.5593131732940675
- 2.3219666131337484
- 2.3217998711268106
- 2.4115717458724975
- 2.484276286760966
- 2.1770041879018147
- 3.5296480369567873
- 2.0925146373112997
- 2.2399098618825275
- 3.4160059674580894
- 1.9742496077219645
- 2.313761068979899
- 2.399738492965698
- 2.212491068840027
- 1.816790140469869
- 2.08738286336263
- 2.240575696627299
train_accuracy:
- 0.069
- 0.194
- 0.133
- 0.49
- 0.125
- 0.031
- 0.085
- 0.531
- 0.713
- 0.215
- 0.594
- 0.671
- 0.081
- 0.148
- 0.015
- 0.669
- 0.638
- 0.754
- 0.783
- 0.458
- 0.794
- 0.685
- 0.817
- 0.654
- 0.071
- 0.767
- 0.763
- 0.69
- 0.825
- 0.833
- 0.848
- 0.737
- 0.546
- 0.852
- 0.819
- 0.067
- 0.077
- 0.808
- 0.756
- 0.785
- 0.131
- 0.071
- 0.123
- 0.769
- 0.787
- 0.729
- 0.765
- 0.81
- 0.767
- 0.64
- 0.069
- 0.794
- 0.102
- 0.838
- 0.121
- 0.133
- 0.583
- 0.115
- 0.819
- 0.752
- 0.821
- 0.873
- 0.154
- 0.865
- 0.115
- 0.806
- 0.144
- 0.846
- 0.135
- 0.069
- 0.804
- 0.825
- 0.094
- 0.09
- 0.129
- 0.577
- 0.146
- 0.852
- 0.817
- 0.11
- 0.823
- 0.658
- 0.858
- 0.858
- 0.106
- 0.846
- 0.123
- 0.792
- 0.831
- 0.887
- 0.098
- 0.858
- 0.831
- 0.66
- 0.794
- 0.85
- 0.852
- 0.681
- 0.106
- 0.829
train_loss:
- 3.785
- 3.546
- 2.263
- 2.964
- 1.739
- 1.525
- 1.277
- 1.718
- 2.117
- 1.132
- 1.559
- 1.867
- 1.141
- 1.081
- 1.414
- 1.338
- 1.309
- 1.619
- 1.56
- 0.982
- 1.585
- 1.184
- 1.455
- 1.169
- 0.876
- 1.089
- 1.102
- 1.07
- 1.357
- 1.3
- 1.265
- 1.038
- 0.812
- 1.293
- 1.245
- 0.974
- 0.942
- 1.19
- 0.986
- 1.015
- 0.694
- 0.74
- 0.917
- 0.954
- 0.915
- 0.92
- 0.94
- 1.129
- 0.912
- 0.682
- 0.925
- 0.84
- 0.888
- 1.08
- 0.885
- 0.604
- 0.642
- 0.589
- 1.129
- 0.88
- 0.817
- 1.051
- 0.704
- 1.071
- 0.833
- 0.827
- 0.567
- 1.027
- 0.6
- 0.878
- 0.815
- 0.808
- 0.821
- 0.8
- 0.597
- 0.575
- 0.534
- 1.029
- 0.967
- 0.793
- 0.979
- 0.638
- 1.005
- 0.95
- 0.805
- 0.758
- 0.737
- 0.743
- 0.771
- 0.948
- 0.801
- 0.745
- 0.936
- 0.597
- 0.75
- 0.702
- 0.775
- 0.545
- 0.755
- 0.732
unequal: 0
verbose: 1
