avg_train_accuracy: 0.85
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.08175531914893618
- 0.13164893617021275
- 0.07648936170212765
- 0.2277127659574468
- 0.1349468085106383
- 0.3046808510638298
- 0.21074468085106382
- 0.33627659574468083
- 0.23888297872340425
- 0.2641489361702128
- 0.39622340425531916
- 0.3974468085106383
- 0.3779787234042553
- 0.4042021276595745
- 0.4323404255319149
- 0.40819148936170213
- 0.44143617021276593
- 0.44585106382978723
- 0.41382978723404257
- 0.45074468085106384
- 0.4206382978723404
- 0.334468085106383
- 0.4431914893617021
- 0.4620744680851064
- 0.45680851063829786
- 0.44851063829787235
- 0.46888297872340423
- 0.4704255319148936
- 0.47808510638297874
- 0.47308510638297874
- 0.48143617021276597
- 0.47712765957446807
- 0.33585106382978724
- 0.4773404255319149
- 0.48808510638297875
- 0.48558510638297875
- 0.48590425531914894
- 0.4173404255319149
- 0.4993085106382979
- 0.5062765957446809
- 0.515904255319149
- 0.371436170212766
- 0.5604787234042553
- 0.44835106382978723
- 0.5201595744680851
- 0.5151595744680851
- 0.4948404255319149
- 0.5187234042553192
- 0.5484042553191489
- 0.5219680851063829
- 0.5254255319148936
- 0.5252127659574468
- 0.5229787234042553
- 0.546968085106383
- 0.4504787234042553
- 0.5318617021276596
- 0.5340425531914894
- 0.5337765957446808
- 0.558404255319149
- 0.5063829787234042
- 0.5395744680851063
- 0.5593617021276596
- 0.5088297872340426
- 0.5529787234042554
- 0.5336170212765957
- 0.5405851063829787
- 0.510904255319149
- 0.5104255319148936
- 0.5129787234042553
- 0.5124468085106383
- 0.5177127659574469
- 0.5104787234042554
- 0.5527659574468086
- 0.5137765957446808
- 0.5150531914893617
- 0.516595744680851
- 0.533936170212766
- 0.5141489361702127
- 0.5293085106382979
- 0.5172872340425532
- 0.5593085106382979
- 0.5156914893617022
- 0.5488297872340425
- 0.5188829787234043
- 0.5185106382978724
- 0.5184574468085107
- 0.5520212765957446
- 0.5606914893617021
- 0.5196808510638298
- 0.5645212765957447
- 0.5760106382978724
- 0.563031914893617
- 0.5682978723404255
- 0.5937234042553191
- 0.5196276595744681
- 0.521436170212766
- 0.5233510638297872
- 0.5612765957446808
- 0.6093085106382978
- 0.568936170212766
test_loss_list:
- 3.824173469543457
- 3.798491134643555
- 5.119767074584961
- 3.4181346893310547
- 3.6980421638488767
- 3.0328064250946043
- 3.0129213746388754
- 2.829582182566325
- 2.9050267855326335
- 2.8537325477600097
- 2.743256762822469
- 2.9596574465433756
- 2.685501985549927
- 2.889579699834188
- 3.7763038285573325
- 3.018931697209676
- 3.954040511449178
- 4.088552122116089
- 2.710223738352458
- 4.08728302637736
- 2.6592575963338216
- 3.1274728870391844
- 2.896929194132487
- 2.908723332087199
- 2.639090280532837
- 2.4239819113413494
- 2.5789612356821694
- 2.6790815003712973
- 2.8805277506510416
- 2.568336877822876
- 2.7224189535776775
- 3.9140867678324383
- 2.79757030804952
- 3.6799741331736247
- 2.6296670881907147
- 3.7353602409362794
- 3.956183293660482
- 2.4430458768208823
- 2.5614841588338217
- 2.5347714392344156
- 2.708117815653483
- 3.4003705883026125
- 1.9236807680130006
- 2.364653989473979
- 2.3816850566864014
- 2.4226943270365395
- 3.5707743708292643
- 2.6129110463460288
- 2.024636171658834
- 2.1381379969914756
- 2.1973336521784463
- 2.3619359985987347
- 2.529537460009257
- 2.241463918685913
- 2.5689538033803303
- 2.2987669801712034
- 2.325762448310852
- 2.472100396156311
- 2.2091422208150227
- 3.5245868078867595
- 2.366574988365173
- 2.2742978048324587
- 3.552400166193644
- 2.3469329913457235
- 2.341423989931742
- 2.48972373008728
- 3.6479781595865886
- 3.7435362911224366
- 3.8284709390004474
- 4.059263385136922
- 2.4257133483886717
- 3.5801015853881837
- 2.5576149654388427
- 3.652358061472575
- 3.7276826985677083
- 3.8366092999776202
- 2.424521005948385
- 3.6371950976053875
- 2.033178904851278
- 3.4010559781392415
- 2.4396117544174194
- 3.490221668879191
- 2.4658250681559246
- 3.5017760149637858
- 3.72501171429952
- 3.8199111525217693
- 2.646782150268555
- 2.527638003031413
- 3.623722515106201
- 2.28168549378713
- 2.4124804401397704
- 2.469163316090902
- 1.9450518798828125
- 2.206803623835246
- 3.3988812573750815
- 3.5154874833424885
- 3.672290261586507
- 2.5162971274058026
- 1.9999903472264609
- 2.1882381582260133
train_accuracy:
- 0.129
- 0.198
- 0.062
- 0.108
- 0.048
- 0.467
- 0.05
- 0.04
- 0.088
- 0.108
- 0.542
- 0.05
- 0.533
- 0.548
- 0.754
- 0.56
- 0.737
- 0.754
- 0.554
- 0.767
- 0.588
- 0.131
- 0.725
- 0.619
- 0.04
- 0.667
- 0.681
- 0.64
- 0.085
- 0.7
- 0.719
- 0.79
- 0.275
- 0.765
- 0.704
- 0.827
- 0.821
- 0.094
- 0.688
- 0.673
- 0.702
- 0.131
- 0.631
- 0.113
- 0.756
- 0.654
- 0.827
- 0.71
- 0.144
- 0.119
- 0.779
- 0.76
- 0.708
- 0.769
- 0.108
- 0.048
- 0.76
- 0.729
- 0.752
- 0.833
- 0.085
- 0.796
- 0.835
- 0.748
- 0.777
- 0.033
- 0.846
- 0.858
- 0.852
- 0.835
- 0.133
- 0.86
- 0.737
- 0.835
- 0.852
- 0.863
- 0.625
- 0.821
- 0.573
- 0.819
- 0.787
- 0.867
- 0.75
- 0.85
- 0.85
- 0.86
- 0.748
- 0.825
- 0.823
- 0.808
- 0.125
- 0.806
- 0.135
- 0.827
- 0.854
- 0.863
- 0.842
- 0.775
- 0.125
- 0.85
train_loss:
- 3.704
- 2.868
- 1.424
- 2.296
- 1.589
- 1.895
- 1.391
- 1.718
- 1.239
- 1.132
- 1.566
- 1.527
- 1.483
- 1.403
- 1.787
- 1.327
- 1.688
- 1.614
- 1.279
- 1.573
- 1.312
- 0.958
- 1.187
- 1.134
- 1.177
- 1.246
- 1.146
- 1.122
- 1.071
- 1.109
- 1.057
- 1.354
- 0.876
- 1.4
- 1.049
- 1.328
- 1.257
- 0.876
- 1.004
- 1.014
- 0.943
- 0.673
- 0.787
- 0.726
- 0.941
- 0.959
- 1.215
- 0.937
- 0.729
- 0.663
- 0.95
- 0.889
- 0.861
- 0.955
- 0.633
- 0.945
- 0.864
- 0.853
- 0.929
- 1.127
- 0.888
- 0.908
- 1.068
- 0.878
- 0.864
- 0.83
- 1.054
- 1.014
- 1.047
- 1.001
- 0.669
- 1.06
- 0.842
- 0.993
- 1.022
- 0.979
- 0.651
- 1.051
- 0.711
- 1.045
- 0.801
- 0.989
- 0.775
- 0.992
- 0.932
- 0.938
- 0.789
- 0.779
- 0.946
- 0.828
- 0.804
- 0.764
- 0.644
- 0.778
- 0.945
- 0.936
- 0.904
- 0.769
- 0.594
- 0.796
unequal: 0
verbose: 1
