avg_train_accuracy: 0.037
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.056648936170212764
- 0.1625531914893617
- 0.1726595744680851
- 0.17361702127659576
- 0.20675531914893616
- 0.22627659574468084
- 0.22877659574468084
- 0.2517553191489362
- 0.274468085106383
- 0.26787234042553193
- 0.3103191489361702
- 0.3054787234042553
- 0.2756382978723404
- 0.2881382978723404
- 0.3575531914893617
- 0.28
- 0.3571808510638298
- 0.2993085106382979
- 0.3045744680851064
- 0.37111702127659574
- 0.3565957446808511
- 0.3678723404255319
- 0.3095212765957447
- 0.3929787234042553
- 0.3828723404255319
- 0.2969148936170213
- 0.41856382978723405
- 0.3799468085106383
- 0.3375
- 0.44941489361702125
- 0.3355851063829787
- 0.4206382978723404
- 0.4079255319148936
- 0.355
- 0.44101063829787235
- 0.351968085106383
- 0.36484042553191487
- 0.43457446808510636
- 0.4329787234042553
- 0.3671808510638298
- 0.38457446808510637
- 0.4525
- 0.35877659574468085
- 0.405
- 0.36829787234042555
- 0.39739361702127657
- 0.3230851063829787
- 0.4073404255319149
- 0.4634042553191489
- 0.4531914893617021
- 0.37148936170212765
- 0.49792553191489364
- 0.476968085106383
- 0.48595744680851066
- 0.4867021276595745
- 0.4029255319148936
- 0.4047872340425532
- 0.39601063829787236
- 0.49670212765957444
- 0.3898404255319149
- 0.4917021276595745
- 0.47686170212765955
- 0.4893085106382979
- 0.5016489361702128
- 0.3372340425531915
- 0.5075
- 0.5055851063829787
- 0.5121808510638298
- 0.421968085106383
- 0.5290425531914894
- 0.5763297872340426
- 0.40606382978723404
- 0.5427127659574468
- 0.42143617021276597
- 0.5295744680851063
- 0.4093085106382979
- 0.4428191489361702
- 0.5093617021276595
- 0.5145212765957446
- 0.5189893617021276
- 0.43632978723404253
- 0.3679787234042553
- 0.5316489361702128
- 0.5134042553191489
- 0.4280851063829787
- 0.5350531914893617
- 0.4298936170212766
- 0.47372340425531917
- 0.43340425531914895
- 0.5464361702127659
- 0.6014893617021276
- 0.5548936170212766
- 0.5635638297872341
- 0.4401595744680851
- 0.4652659574468085
- 0.45356382978723403
- 0.4475
- 0.5474468085106383
- 0.5292553191489362
- 0.36696808510638296
test_loss_list:
- 4.031519241333008
- 4.812195040384928
- 3.755445636113485
- 3.3567098585764565
- 3.73474352200826
- 3.1327853838602704
- 3.127665786743164
- 2.9945172309875487
- 2.8729576110839843
- 3.006709785461426
- 2.857245871225993
- 2.9371132882436117
- 3.1949588362375896
- 3.1392545731862387
- 2.72060307820638
- 3.3624316469828286
- 2.6563075606028237
- 3.052007525761922
- 3.2048707389831543
- 2.6714417298634845
- 2.7741023317972817
- 2.637161366144816
- 3.318497323989868
- 2.6191850121816
- 2.68977944056193
- 4.112106901804606
- 2.5758453750610353
- 2.668416913350423
- 3.0796805381774903
- 2.4124405352274576
- 3.2494698905944825
- 2.568685131072998
- 2.5982421239217124
- 3.0794545809427896
- 2.553831179936727
- 3.1666422653198243
- 2.90978541692098
- 2.5383264700571697
- 2.5173654492696125
- 3.086570027669271
- 2.810578463872274
- 2.504889132181803
- 3.2129325517018636
- 2.8299413903554282
- 3.1218235969543455
- 2.929135398864746
- 3.8444531536102295
- 2.8846063296000164
- 2.5600188477834065
- 2.4603035990397135
- 3.1067170333862304
- 2.4694101365407306
- 2.507107858657837
- 2.476165270805359
- 2.5067514324188234
- 3.081038757960002
- 2.8350378767649334
- 3.011276257832845
- 2.4165587504704793
- 2.9911127630869547
- 2.3723021952311196
- 2.4857331879933677
- 2.468830213546753
- 2.4266721487045286
- 3.8798349539438886
- 2.3608811902999878
- 2.4299113082885744
- 2.451250581741333
- 2.9521405760447186
- 2.3684267234802245
- 2.2064814281463625
- 3.038600091934204
- 2.309743235905965
- 3.021725247701009
- 2.3809683561325072
- 2.948301502863566
- 2.848735939661662
- 2.4029789988199868
- 2.4554387378692626
- 2.509319225947062
- 2.95501233736674
- 3.573009427388509
- 2.359482067426046
- 2.3912934017181398
- 2.9213631343841553
- 2.3498496627807617
- 2.988912372589111
- 2.76327091217041
- 2.856185261408488
- 2.363856358528137
- 2.2025871976216633
- 2.432639204661051
- 2.3772386264801026
- 2.859732100168864
- 2.8296593761444093
- 2.8154640642801922
- 2.8498289934794108
- 2.391316868464152
- 2.4179876248041787
- 3.831468569437663
train_accuracy:
- 0.0
- 0.454
- 0.0
- 0.0
- 0.581
- 0.006
- 0.019
- 0.004
- 0.002
- 0.002
- 0.042
- 0.621
- 0.0
- 0.696
- 0.598
- 0.715
- 0.646
- 0.7
- 0.737
- 0.002
- 0.019
- 0.696
- 0.004
- 0.094
- 0.069
- 0.798
- 0.033
- 0.054
- 0.785
- 0.071
- 0.021
- 0.098
- 0.04
- 0.06
- 0.71
- 0.798
- 0.792
- 0.002
- 0.002
- 0.002
- 0.802
- 0.081
- 0.042
- 0.787
- 0.054
- 0.002
- 0.85
- 0.81
- 0.09
- 0.031
- 0.833
- 0.023
- 0.115
- 0.006
- 0.798
- 0.838
- 0.0
- 0.002
- 0.123
- 0.015
- 0.796
- 0.083
- 0.012
- 0.787
- 0.0
- 0.783
- 0.113
- 0.798
- 0.865
- 0.088
- 0.146
- 0.052
- 0.779
- 0.877
- 0.773
- 0.873
- 0.877
- 0.798
- 0.123
- 0.798
- 0.877
- 0.902
- 0.058
- 0.846
- 0.046
- 0.119
- 0.025
- 0.05
- 0.858
- 0.835
- 0.123
- 0.831
- 0.033
- 0.069
- 0.848
- 0.067
- 0.858
- 0.09
- 0.825
- 0.037
train_loss:
- 2.739
- 2.306
- 1.866
- 1.465
- 1.423
- 1.3
- 1.203
- 1.191
- 0.999
- 1.063
- 1.013
- 1.005
- 1.078
- 1.07
- 0.921
- 1.012
- 0.927
- 1.019
- 0.967
- 0.882
- 0.818
- 0.841
- 0.88
- 0.807
- 0.774
- 0.974
- 0.777
- 0.783
- 0.834
- 0.668
- 0.832
- 0.708
- 0.732
- 0.757
- 0.68
- 0.768
- 0.73
- 0.686
- 0.669
- 0.734
- 0.744
- 0.639
- 0.699
- 0.708
- 0.708
- 0.696
- 0.729
- 0.692
- 0.613
- 0.637
- 0.648
- 0.584
- 0.598
- 0.588
- 0.582
- 0.634
- 0.684
- 0.634
- 0.577
- 0.647
- 0.587
- 0.562
- 0.569
- 0.564
- 0.674
- 0.586
- 0.565
- 0.547
- 0.602
- 0.553
- 0.484
- 0.621
- 0.527
- 0.575
- 0.533
- 0.609
- 0.578
- 0.543
- 0.52
- 0.511
- 0.56
- 0.655
- 0.537
- 0.531
- 0.566
- 0.509
- 0.557
- 0.545
- 0.589
- 0.515
- 0.447
- 0.495
- 0.481
- 0.57
- 0.543
- 0.563
- 0.555
- 0.495
- 0.506
- 0.596
unequal: 0
verbose: 1
