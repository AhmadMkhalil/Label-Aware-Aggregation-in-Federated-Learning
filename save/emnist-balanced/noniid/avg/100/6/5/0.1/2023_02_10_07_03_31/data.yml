avg_train_accuracy: 0.881
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0599468085106383
- 0.09367021276595745
- 0.1775
- 0.07601063829787234
- 0.08164893617021277
- 0.1895212765957447
- 0.23638297872340425
- 0.249468085106383
- 0.2503191489361702
- 0.08297872340425531
- 0.08558510638297873
- 0.09882978723404255
- 0.085
- 0.2603191489361702
- 0.10218085106382979
- 0.2707978723404255
- 0.09856382978723405
- 0.2748404255319149
- 0.0924468085106383
- 0.09882978723404255
- 0.27377659574468083
- 0.2775531914893617
- 0.28595744680851065
- 0.2872340425531915
- 0.10808510638297872
- 0.1025531914893617
- 0.11138297872340426
- 0.10377659574468086
- 0.12281914893617021
- 0.30186170212765956
- 0.29638297872340424
- 0.2957446808510638
- 0.3000531914893617
- 0.2996276595744681
- 0.3019148936170213
- 0.09925531914893616
- 0.09968085106382979
- 0.30042553191489363
- 0.30234042553191487
- 0.12111702127659575
- 0.11207446808510638
- 0.32563829787234044
- 0.14388297872340425
- 0.1249468085106383
- 0.1124468085106383
- 0.10781914893617021
- 0.32861702127659576
- 0.3107446808510638
- 0.3083510638297872
- 0.12430851063829787
- 0.3274468085106383
- 0.16414893617021276
- 0.12723404255319148
- 0.14074468085106384
- 0.34
- 0.3205851063829787
- 0.11659574468085106
- 0.10824468085106383
- 0.11186170212765957
- 0.1097872340425532
- 0.32335106382978723
- 0.3091489361702128
- 0.30920212765957444
- 0.30946808510638296
- 0.12872340425531914
- 0.13069148936170213
- 0.11398936170212766
- 0.3401063829787234
- 0.32127659574468087
- 0.1425531914893617
- 0.1301595744680851
- 0.3359042553191489
- 0.32
- 0.15468085106382978
- 0.3325
- 0.14595744680851064
- 0.15340425531914895
- 0.35010638297872343
- 0.17898936170212765
- 0.15074468085106382
- 0.16101063829787235
- 0.1747340425531915
- 0.1477659574468085
- 0.17696808510638298
- 0.15414893617021277
- 0.38324468085106383
- 0.34319148936170213
- 0.32856382978723403
- 0.17361702127659576
- 0.35617021276595745
- 0.33808510638297873
- 0.33361702127659576
- 0.3253191489361702
- 0.3246276595744681
- 0.19319148936170213
- 0.15632978723404256
- 0.13031914893617022
- 0.3638297872340426
- 0.33739361702127657
- 0.33132978723404255
test_loss_list:
- 4.053237180709839
- 15.963972676595052
- 5.040748831431071
- 11.409779167175293
- 11.61528507232666
- 5.179053249359131
- 6.37974027633667
- 6.482870559692383
- 6.814764747619629
- 12.087489636739095
- 10.559751180013022
- 13.954568735758464
- 10.60287181854248
- 5.24400837580363
- 10.775279184977213
- 5.472898146311442
- 12.250862299601238
- 4.925026302337646
- 11.327739995320638
- 11.784860712687175
- 4.697320626576741
- 5.351014391581217
- 5.62648370107015
- 5.942962532043457
- 9.749140917460124
- 9.136101468404133
- 9.5029509862264
- 11.601642761230469
- 8.85688969930013
- 4.847851053873698
- 5.222511552174886
- 5.6375464248657225
- 5.865363330841064
- 5.891054267883301
- 6.095748818715413
- 10.279415906270344
- 12.025755132039388
- 5.262799015045166
- 5.778706595102946
- 8.3007310740153
- 10.248093528747559
- 5.197372519175212
- 8.367441520690917
- 8.461953353881835
- 9.989597930908204
- 8.061787802378337
- 4.140916051864624
- 4.722704121271769
- 4.899194424947103
- 7.6047946739196775
- 4.632292420069376
- 7.338976357777914
- 7.639656918843587
- 7.206453285217285
- 4.342492341995239
- 4.744519186019898
- 9.2727965037028
- 10.824975407918295
- 8.098998572031658
- 6.659121176401774
- 3.812627201080322
- 4.345928351084392
- 4.584840259552002
- 4.9735812632242835
- 7.312629820505778
- 7.2315359306335445
- 8.733397432963054
- 4.103971608479818
- 4.614072408676147
- 6.2040659523010255
- 6.554059511820475
- 4.0593590100606285
- 4.5341890366872155
- 6.9710759290059405
- 4.35369119644165
- 7.462890179951986
- 6.9302073097229
- 3.819018405278524
- 5.685334752400716
- 6.284352137247722
- 7.242673136393229
- 6.350927575429281
- 7.341414063771566
- 7.436537132263184
- 8.72032242457072
- 3.692371565500895
- 4.156977322896322
- 4.4761530303955075
- 6.3535626856486
- 4.087293221155803
- 4.547438166936239
- 4.644368998209635
- 4.709399407704671
- 5.025725339253744
- 6.74411745707194
- 6.288794790903728
- 7.739661782582601
- 4.0987967681884765
- 4.543839896519978
- 4.839894733428955
train_accuracy:
- 0.173
- 0.154
- 0.496
- 0.148
- 0.04
- 0.54
- 0.652
- 0.652
- 0.719
- 0.154
- 0.158
- 0.16
- 0.156
- 0.723
- 0.165
- 0.765
- 0.16
- 0.787
- 0.15
- 0.15
- 0.767
- 0.773
- 0.763
- 0.787
- 0.165
- 0.16
- 0.165
- 0.165
- 0.163
- 0.831
- 0.815
- 0.81
- 0.829
- 0.835
- 0.827
- 0.158
- 0.158
- 0.831
- 0.835
- 0.165
- 0.165
- 0.863
- 0.165
- 0.165
- 0.165
- 0.154
- 0.829
- 0.844
- 0.86
- 0.165
- 0.867
- 0.165
- 0.163
- 0.165
- 0.848
- 0.879
- 0.156
- 0.158
- 0.163
- 0.158
- 0.854
- 0.858
- 0.85
- 0.885
- 0.158
- 0.165
- 0.165
- 0.863
- 0.86
- 0.163
- 0.158
- 0.871
- 0.863
- 0.163
- 0.869
- 0.165
- 0.165
- 0.865
- 0.163
- 0.165
- 0.165
- 0.16
- 0.163
- 0.165
- 0.165
- 0.883
- 0.869
- 0.896
- 0.165
- 0.873
- 0.89
- 0.877
- 0.877
- 0.879
- 0.165
- 0.16
- 0.16
- 0.86
- 0.875
- 0.881
train_loss:
- 3.641
- 1.951
- 3.278
- 1.761
- 2.151
- 3.104
- 2.073
- 1.834
- 1.663
- 2.202
- 1.32
- 1.949
- 0.972
- 2.296
- 0.944
- 1.864
- 1.222
- 1.815
- 1.546
- 1.505
- 1.832
- 1.324
- 1.282
- 1.182
- 0.825
- 1.101
- 0.578
- 0.297
- 0.815
- 1.675
- 1.188
- 1.112
- 1.035
- 1.036
- 1.019
- 1.372
- 0.666
- 1.41
- 0.999
- 0.693
- 0.259
- 1.275
- 0.423
- 0.935
- 0.531
- 1.425
- 1.503
- 0.966
- 0.951
- 0.818
- 1.141
- 0.585
- 1.299
- 0.46
- 1.264
- 0.898
- 1.209
- 0.527
- 0.806
- 1.162
- 1.322
- 0.896
- 0.899
- 0.837
- 0.654
- 0.749
- 0.259
- 1.221
- 0.853
- 1.027
- 0.59
- 1.135
- 0.85
- 0.47
- 1.01
- 0.615
- 0.798
- 1.108
- 0.87
- 0.606
- 0.511
- 0.698
- 0.454
- 0.392
- 0.181
- 1.285
- 0.836
- 0.789
- 0.559
- 1.02
- 0.755
- 0.746
- 0.757
- 0.692
- 0.489
- 0.786
- 0.222
- 1.088
- 0.759
- 0.708
unequal: 0
verbose: 1
