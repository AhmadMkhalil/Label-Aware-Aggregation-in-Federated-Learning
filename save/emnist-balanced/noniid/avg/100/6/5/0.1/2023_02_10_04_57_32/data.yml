avg_train_accuracy: 0.154
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.09579787234042553
- 0.11797872340425532
- 0.18813829787234043
- 0.08531914893617021
- 0.20680851063829786
- 0.22664893617021276
- 0.24
- 0.25170212765957445
- 0.2546276595744681
- 0.2625531914893617
- 0.26813829787234045
- 0.08856382978723404
- 0.09776595744680851
- 0.2705851063829787
- 0.09170212765957447
- 0.2756914893617021
- 0.10079787234042553
- 0.2821808510638298
- 0.0925
- 0.09313829787234043
- 0.27952127659574466
- 0.2851063829787234
- 0.28856382978723405
- 0.10276595744680851
- 0.29319148936170214
- 0.11372340425531915
- 0.3052127659574468
- 0.13617021276595745
- 0.31638297872340426
- 0.3058510638297872
- 0.1477659574468085
- 0.10276595744680851
- 0.11
- 0.3090425531914894
- 0.30356382978723406
- 0.3019148936170213
- 0.3043085106382979
- 0.30398936170212765
- 0.3073936170212766
- 0.12840425531914892
- 0.0998404255319149
- 0.12170212765957447
- 0.115
- 0.33367021276595743
- 0.17840425531914894
- 0.34712765957446806
- 0.1150531914893617
- 0.33356382978723403
- 0.12228723404255319
- 0.3324468085106383
- 0.3227127659574468
- 0.13893617021276597
- 0.20446808510638298
- 0.12127659574468085
- 0.3498936170212766
- 0.16117021276595744
- 0.3393617021276596
- 0.32595744680851063
- 0.1698936170212766
- 0.32515957446808513
- 0.1998936170212766
- 0.33361702127659576
- 0.3230851063829787
- 0.16202127659574467
- 0.34617021276595744
- 0.1849468085106383
- 0.351968085106383
- 0.336968085106383
- 0.32882978723404255
- 0.32303191489361704
- 0.3215425531914894
- 0.3198936170212766
- 0.21867021276595744
- 0.36579787234042555
- 0.3426595744680851
- 0.2454255319148936
- 0.37930851063829785
- 0.1972340425531915
- 0.16329787234042553
- 0.3759574468085106
- 0.21319148936170212
- 0.36398936170212765
- 0.2025531914893617
- 0.23968085106382978
- 0.13622340425531915
- 0.15840425531914892
- 0.3901063829787234
- 0.15276595744680851
- 0.3733510638297872
- 0.2730851063829787
- 0.18319148936170213
- 0.2297872340425532
- 0.1850531914893617
- 0.16159574468085106
- 0.1775
- 0.21425531914893617
- 0.3978191489361702
- 0.3697340425531915
- 0.22101063829787235
- 0.26218085106382977
test_loss_list:
- 14.156927846272787
- 4.9570044326782225
- 6.264335848490397
- 12.430907974243164
- 5.956636905670166
- 6.148569494883219
- 6.544085807800293
- 7.070871206919352
- 6.789163424173991
- 7.240636425018311
- 7.119227142333984
- 11.19495023091634
- 12.931943524678548
- 5.658303140004476
- 11.601081733703614
- 5.428908011118571
- 10.507437985738118
- 5.442043883005778
- 9.09610055287679
- 11.969105466206868
- 4.8388609759012855
- 5.5357524744669595
- 6.206711622873942
- 10.804052594502767
- 5.5215985997517905
- 9.45614651997884
- 5.091665236155192
- 9.12814042409261
- 5.06044750213623
- 5.6541855494181315
- 8.96009656270345
- 8.652319463094075
- 9.838260854085286
- 4.07495320002238
- 4.689030348459879
- 5.1880561637878415
- 5.6051726722717286
- 6.027499491373698
- 5.927826658884684
- 9.165453122456869
- 9.756410649617512
- 6.908700675964355
- 7.543294423421224
- 4.182561251322428
- 7.0134183756510415
- 4.522648801803589
- 7.350737806955974
- 4.711963685353597
- 7.283454481760661
- 4.214747374852498
- 4.525125802357992
- 7.326155554453532
- 6.713013750712077
- 7.453809185028076
- 3.770704752604167
- 7.3470443216959636
- 4.117820132573446
- 4.342118342717488
- 6.67625446955363
- 3.908654177983602
- 6.745019283294678
- 4.093718614578247
- 4.423709338506063
- 6.355218067169189
- 4.158360249201457
- 7.07770092646281
- 4.081935396194458
- 4.222281325658162
- 4.47023567199707
- 4.5891471735636395
- 4.875286451975504
- 4.911274770100912
- 6.382505537668864
- 4.217779461542765
- 4.573307701746622
- 6.633286685943603
- 4.408592262268066
- 6.050607681274414
- 6.981248811086019
- 4.1461456044514975
- 6.457557455698649
- 4.078978284200033
- 6.139735940297444
- 5.1935297330220545
- 6.632816111246745
- 5.492635142008464
- 3.187761386235555
- 5.874908822377523
- 3.3836332098642985
- 5.333201440175374
- 5.98923126856486
- 5.76388370513916
- 6.400161298116048
- 7.416805051167806
- 5.459659544626872
- 5.937389659881592
- 3.2982729943593343
- 3.7334573554992674
- 5.617140483856201
- 5.029311580657959
train_accuracy:
- 0.156
- 0.335
- 0.535
- 0.144
- 0.565
- 0.633
- 0.667
- 0.719
- 0.671
- 0.71
- 0.729
- 0.123
- 0.163
- 0.725
- 0.127
- 0.733
- 0.156
- 0.769
- 0.125
- 0.11
- 0.775
- 0.835
- 0.796
- 0.156
- 0.802
- 0.152
- 0.827
- 0.148
- 0.858
- 0.835
- 0.148
- 0.158
- 0.144
- 0.844
- 0.867
- 0.823
- 0.831
- 0.84
- 0.85
- 0.156
- 0.154
- 0.15
- 0.158
- 0.887
- 0.152
- 0.887
- 0.16
- 0.846
- 0.156
- 0.89
- 0.894
- 0.156
- 0.152
- 0.148
- 0.844
- 0.152
- 0.85
- 0.848
- 0.156
- 0.863
- 0.16
- 0.867
- 0.867
- 0.156
- 0.894
- 0.156
- 0.863
- 0.89
- 0.869
- 0.881
- 0.877
- 0.885
- 0.15
- 0.875
- 0.879
- 0.154
- 0.875
- 0.158
- 0.156
- 0.9
- 0.154
- 0.867
- 0.163
- 0.154
- 0.158
- 0.152
- 0.892
- 0.16
- 0.875
- 0.152
- 0.163
- 0.154
- 0.163
- 0.165
- 0.152
- 0.156
- 0.894
- 0.869
- 0.16
- 0.154
train_loss:
- 1.462
- 3.486
- 2.517
- 2.032
- 2.676
- 2.042
- 1.812
- 1.665
- 1.542
- 1.44
- 1.384
- 1.651
- 0.8
- 1.831
- 2.043
- 1.753
- 0.964
- 1.578
- 2.569
- 1.696
- 1.829
- 1.337
- 1.162
- 1.003
- 1.435
- 0.965
- 1.349
- 0.621
- 1.361
- 1.032
- 0.577
- 1.55
- 1.49
- 1.638
- 1.091
- 0.999
- 0.912
- 0.877
- 0.892
- 1.026
- 1.808
- 1.059
- 0.874
- 1.539
- 0.561
- 1.178
- 0.81
- 1.168
- 0.976
- 1.163
- 0.881
- 0.569
- 0.717
- 1.324
- 1.288
- 0.654
- 1.074
- 0.866
- 1.061
- 1.114
- 0.585
- 1.059
- 0.825
- 0.693
- 1.015
- 0.756
- 0.993
- 0.805
- 0.766
- 0.775
- 0.721
- 0.746
- 0.79
- 0.935
- 0.728
- 0.482
- 0.866
- 0.678
- 0.255
- 0.993
- 0.764
- 0.931
- 0.88
- 0.751
- 1.209
- 0.795
- 1.21
- 0.718
- 1.001
- 0.502
- 0.616
- 0.373
- 0.457
- 0.304
- 0.785
- 0.438
- 1.245
- 0.788
- 0.818
- 0.522
unequal: 0
verbose: 1
