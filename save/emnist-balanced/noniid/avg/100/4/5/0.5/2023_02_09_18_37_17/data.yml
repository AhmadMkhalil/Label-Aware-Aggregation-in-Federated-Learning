avg_train_accuracy: 0.84
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.037393617021276596
- 0.11164893617021276
- 0.10537234042553191
- 0.13175531914893618
- 0.23335106382978724
- 0.17579787234042554
- 0.3194148936170213
- 0.31079787234042555
- 0.2782978723404255
- 0.2176063829787234
- 0.3287765957446809
- 0.3768085106382979
- 0.3371276595744681
- 0.3772340425531915
- 0.3993617021276596
- 0.37138297872340426
- 0.4157446808510638
- 0.40617021276595744
- 0.426436170212766
- 0.3231914893617021
- 0.4416489361702128
- 0.4371808510638298
- 0.3748404255319149
- 0.4554787234042553
- 0.45787234042553193
- 0.47117021276595744
- 0.47627659574468084
- 0.4571808510638298
- 0.48175531914893616
- 0.46930851063829787
- 0.4748936170212766
- 0.5140957446808511
- 0.4773936170212766
- 0.4981914893617021
- 0.49622340425531913
- 0.49659574468085105
- 0.5192553191489362
- 0.5148936170212766
- 0.5012234042553192
- 0.5561170212765958
- 0.4117021276595745
- 0.5232978723404256
- 0.5145212765957446
- 0.5204787234042553
- 0.5104787234042554
- 0.47579787234042553
- 0.48090425531914893
- 0.5275531914893618
- 0.48611702127659573
- 0.517127659574468
- 0.5307446808510639
- 0.48675531914893616
- 0.5338297872340425
- 0.47638297872340424
- 0.5681914893617022
- 0.5495212765957447
- 0.5452659574468085
- 0.5625531914893617
- 0.5548404255319149
- 0.5862765957446808
- 0.5616489361702127
- 0.5626595744680851
- 0.5582446808510638
- 0.5386170212765957
- 0.5370212765957447
- 0.5686170212765957
- 0.5546808510638298
- 0.568936170212766
- 0.5561702127659575
- 0.5059574468085106
- 0.5661170212765958
- 0.6118085106382979
- 0.5937234042553191
- 0.5973936170212766
- 0.6063829787234043
- 0.5876595744680851
- 0.583404255319149
- 0.5112765957446809
- 0.6031382978723404
- 0.5663829787234043
- 0.586063829787234
- 0.5872872340425532
- 0.5210106382978723
- 0.6015425531914894
- 0.5572340425531915
- 0.5795744680851064
- 0.5735106382978723
- 0.6032446808510639
- 0.5611170212765958
- 0.6209574468085106
- 0.6158510638297873
- 0.6282978723404256
- 0.6330851063829788
- 0.5667553191489362
- 0.5696808510638298
- 0.6278191489361702
- 0.6191489361702127
- 0.5740425531914893
- 0.606436170212766
- 0.5871808510638298
test_loss_list:
- 3.9010290241241456
- 3.6980160077412925
- 3.6490447966257733
- 3.3329425144195555
- 3.0832297452290853
- 3.066796868642171
- 2.850579169591268
- 2.8433692773183186
- 2.8781258646647134
- 2.9085613759358724
- 2.60160839398702
- 2.6230061531066893
- 2.5285307947794595
- 2.357675641377767
- 2.5044946543375652
- 2.3910091718037925
- 2.2162308152516683
- 2.196662702560425
- 2.2658695697784426
- 2.5175335534413654
- 2.141641451517741
- 2.9793063100179036
- 2.1801974980036416
- 2.306330318450928
- 2.2073804759979248
- 2.2143167209625245
- 2.2495165220896403
- 2.0452068614959718
- 1.9093804136912027
- 1.8726247437795003
- 2.116861243247986
- 1.7419508918126425
- 1.8276053476333618
- 1.7735391108194987
- 1.814677840868632
- 1.7809627135594686
- 1.7110325368245443
- 1.7486725028355916
- 1.7647800079981486
- 1.5820997301737467
- 2.0005436515808106
- 1.9362758922576904
- 1.9449476194381714
- 1.7028339115778606
- 1.8798546632130941
- 2.655963306427002
- 2.637786633173625
- 1.8190417242050172
- 1.73603396097819
- 1.8825075038274128
- 1.8617721350987753
- 2.508700256347656
- 1.631614759763082
- 1.739738785425822
- 1.5425607347488404
- 1.5679101769129435
- 1.8038383690516153
- 1.7551122872034708
- 1.5197352075576782
- 1.438689300219218
- 1.8084244950612387
- 1.7882458146413167
- 1.7386550951004027
- 1.7372795470555624
- 1.809984769821167
- 1.7384186919530233
- 1.7000762414932251
- 1.7398633400599162
- 1.7398110326131184
- 2.439471305211385
- 1.7538410472869872
- 1.3600258700052896
- 1.377415410677592
- 1.3680526367823282
- 1.3851863702138265
- 1.4286659987767538
- 1.652267967859904
- 2.3383296966552733
- 1.3378606541951497
- 1.62752507686615
- 1.4218393834431966
- 1.527326356569926
- 1.5878285042444864
- 1.3053321011861165
- 1.6482049751281738
- 1.630583701133728
- 1.6348472277323405
- 1.4200865761439005
- 1.7279753557840982
- 1.2205303414662678
- 1.2705174891153972
- 1.2308837509155273
- 1.2140989208221435
- 1.5897133111953736
- 1.5752539984385172
- 1.251473372777303
- 1.2873652410507201
- 1.5820206054051718
- 1.3170333814620971
- 1.5387493340174356
train_accuracy:
- 0.0
- 0.123
- 0.158
- 0.0
- 0.002
- 0.127
- 0.006
- 0.423
- 0.237
- 0.044
- 0.042
- 0.0
- 0.31
- 0.002
- 0.644
- 0.237
- 0.05
- 0.042
- 0.635
- 0.169
- 0.498
- 0.754
- 0.438
- 0.0
- 0.733
- 0.708
- 0.017
- 0.144
- 0.617
- 0.083
- 0.696
- 0.629
- 0.546
- 0.027
- 0.552
- 0.554
- 0.356
- 0.615
- 0.154
- 0.26
- 0.444
- 0.773
- 0.002
- 0.177
- 0.765
- 0.819
- 0.808
- 0.779
- 0.442
- 0.048
- 0.792
- 0.004
- 0.263
- 0.369
- 0.658
- 0.123
- 0.823
- 0.792
- 0.337
- 0.713
- 0.81
- 0.825
- 0.0
- 0.042
- 0.092
- 0.815
- 0.815
- 0.802
- 0.248
- 0.84
- 0.833
- 0.723
- 0.698
- 0.669
- 0.581
- 0.654
- 0.11
- 0.0
- 0.127
- 0.098
- 0.033
- 0.831
- 0.425
- 0.681
- 0.831
- 0.808
- 0.827
- 0.533
- 0.842
- 0.192
- 0.1
- 0.733
- 0.188
- 0.85
- 0.012
- 0.69
- 0.729
- 0.84
- 0.446
- 0.84
train_loss:
- 2.386
- 2.384
- 1.632
- 1.535
- 1.399
- 1.265
- 1.548
- 1.405
- 1.062
- 0.775
- 1.006
- 1.345
- 0.957
- 0.962
- 1.222
- 0.91
- 0.903
- 0.905
- 1.106
- 0.627
- 0.834
- 1.265
- 0.834
- 1.044
- 1.001
- 1.014
- 0.964
- 0.77
- 0.801
- 0.731
- 0.919
- 0.779
- 0.713
- 0.709
- 0.682
- 0.72
- 0.712
- 0.695
- 0.673
- 0.712
- 0.471
- 0.902
- 0.875
- 0.684
- 0.84
- 1.01
- 0.978
- 0.84
- 0.499
- 0.8
- 0.787
- 0.963
- 0.658
- 0.445
- 0.611
- 0.588
- 0.791
- 0.762
- 0.603
- 0.604
- 0.74
- 0.771
- 0.743
- 0.73
- 0.707
- 0.76
- 0.732
- 0.722
- 0.716
- 0.885
- 0.713
- 0.59
- 0.553
- 0.574
- 0.564
- 0.548
- 0.675
- 0.837
- 0.563
- 0.662
- 0.529
- 0.703
- 0.396
- 0.527
- 0.662
- 0.666
- 0.686
- 0.526
- 0.637
- 0.554
- 0.518
- 0.537
- 0.525
- 0.637
- 0.647
- 0.516
- 0.52
- 0.627
- 0.505
- 0.628
unequal: 0
verbose: 1
