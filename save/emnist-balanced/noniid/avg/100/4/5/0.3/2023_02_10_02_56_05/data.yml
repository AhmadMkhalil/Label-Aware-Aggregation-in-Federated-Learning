avg_train_accuracy: 0.01
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05813829787234043
- 0.07920212765957446
- 0.12095744680851064
- 0.10505319148936171
- 0.1296276595744681
- 0.14824468085106382
- 0.35356382978723405
- 0.300531914893617
- 0.34372340425531916
- 0.3097340425531915
- 0.3731914893617021
- 0.18207446808510638
- 0.3875531914893617
- 0.23968085106382978
- 0.4102659574468085
- 0.25601063829787235
- 0.3397340425531915
- 0.2901595744680851
- 0.4233510638297872
- 0.428936170212766
- 0.40132978723404256
- 0.4344148936170213
- 0.3131914893617021
- 0.2649468085106383
- 0.33191489361702126
- 0.3128723404255319
- 0.43031914893617024
- 0.4346276595744681
- 0.4442553191489362
- 0.45659574468085107
- 0.2154787234042553
- 0.46595744680851064
- 0.45468085106382977
- 0.38680851063829785
- 0.4192021276595745
- 0.2700531914893617
- 0.4726063829787234
- 0.4468617021276596
- 0.413031914893617
- 0.48845744680851066
- 0.3802127659574468
- 0.4651063829787234
- 0.4103191489361702
- 0.5054255319148936
- 0.4423404255319149
- 0.510904255319149
- 0.4877659574468085
- 0.5157446808510638
- 0.495
- 0.49398936170212765
- 0.5161702127659574
- 0.5132978723404256
- 0.5201595744680851
- 0.5058510638297873
- 0.4970212765957447
- 0.513563829787234
- 0.5080851063829788
- 0.49632978723404253
- 0.24595744680851064
- 0.4556914893617021
- 0.5204787234042553
- 0.37090425531914895
- 0.5225531914893617
- 0.4831382978723404
- 0.4772872340425532
- 0.4846808510638298
- 0.5180851063829788
- 0.5134574468085107
- 0.3642021276595745
- 0.4697340425531915
- 0.4677659574468085
- 0.541968085106383
- 0.5157446808510638
- 0.5158510638297872
- 0.5368617021276596
- 0.5408510638297872
- 0.4699468085106383
- 0.5407978723404255
- 0.32324468085106384
- 0.48409574468085104
- 0.49127659574468086
- 0.5536702127659574
- 0.5380851063829787
- 0.34888297872340424
- 0.47164893617021275
- 0.4915425531914894
- 0.5797872340425532
- 0.5713297872340426
- 0.5263297872340426
- 0.5438829787234043
- 0.49569148936170215
- 0.5086702127659575
- 0.5431382978723405
- 0.5457978723404255
- 0.4927659574468085
- 0.49388297872340425
- 0.5507978723404255
- 0.5372340425531915
- 0.4926063829787234
- 0.5495744680851063
test_loss_list:
- 3.8141370010375977
- 3.845215737024943
- 4.415881500244141
- 3.6846977202097575
- 3.8913840103149413
- 3.939520673751831
- 4.063963546752929
- 3.3112302303314207
- 3.3833039474487303
- 3.0103614425659178
- 3.1223578675587973
- 3.206966635386149
- 3.0266104157765708
- 2.9437317562103273
- 3.0678909047444662
- 3.3341024208068846
- 2.828070748647054
- 2.813831860224406
- 3.949762357076009
- 4.173075358072917
- 2.88324164390564
- 4.215943015416463
- 2.9446899477640787
- 3.490044730504354
- 2.8460731347401937
- 2.751114041010539
- 2.652449452082316
- 2.669144846598307
- 2.808996985753377
- 2.599335511525472
- 3.406738551457723
- 2.6272696463267007
- 3.9804469871520998
- 2.5604422505696616
- 2.228234640757243
- 2.9348066679636635
- 2.47680144627889
- 1.9222848653793334
- 2.300021492640177
- 2.1890240637461345
- 2.232289694150289
- 3.5281292088826497
- 2.0961221154530842
- 2.1464439868927
- 2.145944900512695
- 2.163012959162394
- 1.9651258929570516
- 2.192332895596822
- 2.1499215936660767
- 2.0416297245025636
- 2.130267718633016
- 1.8510601409276326
- 2.131432712872823
- 2.0331351550420127
- 2.127065830230713
- 2.1003376150131228
- 2.0976422532399495
- 1.8205901177724202
- 3.446007229487101
- 2.012945810953776
- 2.1462101872762043
- 2.242386596997579
- 1.9684995094935098
- 3.311846113204956
- 1.8473069508870443
- 3.293338642120361
- 2.219880010286967
- 1.6457868480682374
- 2.3823187923431397
- 1.8514057238896688
- 1.9869772481918335
- 1.8942283884684246
- 1.855520567893982
- 1.8724431959788004
- 2.022979350090027
- 1.8467356856664021
- 1.997220222155253
- 1.9119094896316529
- 2.7175263277689616
- 1.9010804096857707
- 3.10823130607605
- 1.5353789917627971
- 1.81901877562205
- 2.3073193804423013
- 1.7212250057856242
- 1.8591823403040568
- 1.3191085894902548
- 1.6842371877034505
- 1.6409569787979126
- 1.9122000646591186
- 3.0481854502360024
- 1.8216464058558146
- 1.9752723964055379
- 1.9761141236623128
- 3.2260617510477703
- 1.6699609025319417
- 1.86619415918986
- 2.1599136797587075
- 1.9237292877833048
- 1.9651355441411336
train_accuracy:
- 0.004
- 0.202
- 0.748
- 0.027
- 0.175
- 0.423
- 0.648
- 0.402
- 0.033
- 0.002
- 0.615
- 0.196
- 0.633
- 0.554
- 0.638
- 0.627
- 0.417
- 0.048
- 0.742
- 0.765
- 0.625
- 0.769
- 0.337
- 0.548
- 0.519
- 0.167
- 0.7
- 0.656
- 0.717
- 0.721
- 0.027
- 0.723
- 0.817
- 0.477
- 0.725
- 0.506
- 0.36
- 0.706
- 0.492
- 0.025
- 0.746
- 0.821
- 0.55
- 0.748
- 0.319
- 0.777
- 0.592
- 0.494
- 0.054
- 0.769
- 0.777
- 0.156
- 0.783
- 0.04
- 0.792
- 0.771
- 0.04
- 0.535
- 0.781
- 0.45
- 0.8
- 0.604
- 0.796
- 0.873
- 0.552
- 0.863
- 0.498
- 0.669
- 0.84
- 0.556
- 0.848
- 0.04
- 0.417
- 0.835
- 0.05
- 0.792
- 0.765
- 0.046
- 0.308
- 0.498
- 0.867
- 0.367
- 0.846
- 0.65
- 0.51
- 0.575
- 0.227
- 0.627
- 0.6
- 0.827
- 0.858
- 0.513
- 0.823
- 0.844
- 0.865
- 0.815
- 0.829
- 0.821
- 0.804
- 0.01
train_loss:
- 2.993
- 2.746
- 1.473
- 1.48
- 1.287
- 1.139
- 2.408
- 1.603
- 1.554
- 1.656
- 1.462
- 1.143
- 1.369
- 1.007
- 1.352
- 0.832
- 0.871
- 0.974
- 1.673
- 1.576
- 1.258
- 1.476
- 0.919
- 0.745
- 0.842
- 0.807
- 1.1
- 1.025
- 0.988
- 1.044
- 0.426
- 1.076
- 1.308
- 0.797
- 0.748
- 0.408
- 1.047
- 0.729
- 0.705
- 0.996
- 0.662
- 1.295
- 0.697
- 0.948
- 0.626
- 0.932
- 0.671
- 0.909
- 0.937
- 0.891
- 0.884
- 0.641
- 0.859
- 0.855
- 0.929
- 0.864
- 0.82
- 0.653
- 0.326
- 0.549
- 0.859
- 0.366
- 0.892
- 1.073
- 0.615
- 1.095
- 0.86
- 0.596
- 0.322
- 0.5
- 0.553
- 0.834
- 0.548
- 0.565
- 0.783
- 0.795
- 0.54
- 0.796
- 0.305
- 0.515
- 1.063
- 0.617
- 0.787
- 0.314
- 0.52
- 0.526
- 0.549
- 0.771
- 0.503
- 0.756
- 0.997
- 0.517
- 0.732
- 0.792
- 0.97
- 0.393
- 0.764
- 0.716
- 0.465
- 0.706
unequal: 0
verbose: 1
