avg_train_accuracy: 0.567
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0648404255319149
- 0.11414893617021277
- 0.09117021276595745
- 0.0901063829787234
- 0.09888297872340425
- 0.1322340425531915
- 0.2700531914893617
- 0.10313829787234043
- 0.17643617021276595
- 0.17404255319148937
- 0.18984042553191488
- 0.2704255319148936
- 0.14047872340425532
- 0.249468085106383
- 0.15909574468085105
- 0.23648936170212767
- 0.20063829787234042
- 0.17595744680851064
- 0.22574468085106383
- 0.2248936170212766
- 0.1376595744680851
- 0.2852127659574468
- 0.3081382978723404
- 0.2975531914893617
- 0.3171276595744681
- 0.20191489361702128
- 0.3359042553191489
- 0.2978723404255319
- 0.3018085106382979
- 0.3377127659574468
- 0.2771808510638298
- 0.20079787234042554
- 0.33106382978723403
- 0.3255851063829787
- 0.2624468085106383
- 0.3503723404255319
- 0.2247340425531915
- 0.2179787234042553
- 0.35356382978723405
- 0.35675531914893616
- 0.35148936170212763
- 0.35856382978723406
- 0.3578723404255319
- 0.25611702127659575
- 0.3722872340425532
- 0.21877659574468086
- 0.3574468085106383
- 0.4203723404255319
- 0.3076063829787234
- 0.31872340425531914
- 0.2447872340425532
- 0.23606382978723403
- 0.34638297872340423
- 0.3834574468085106
- 0.28138297872340423
- 0.23569148936170212
- 0.3193617021276596
- 0.35819148936170214
- 0.39691489361702126
- 0.4122872340425532
- 0.2947872340425532
- 0.40797872340425534
- 0.4272872340425532
- 0.41047872340425534
- 0.37946808510638297
- 0.37457446808510636
- 0.2999468085106383
- 0.4006914893617021
- 0.46095744680851064
- 0.38218085106382976
- 0.39691489361702126
- 0.27941489361702126
- 0.4104255319148936
- 0.38861702127659575
- 0.3728723404255319
- 0.46297872340425533
- 0.3946808510638298
- 0.41393617021276596
- 0.45659574468085107
- 0.40287234042553194
- 0.2584574468085106
- 0.45398936170212767
- 0.44707446808510637
- 0.4149468085106383
- 0.41829787234042554
- 0.3775
- 0.35579787234042554
- 0.26409574468085106
- 0.4842021276595745
- 0.4277659574468085
- 0.40180851063829787
- 0.420531914893617
- 0.486436170212766
- 0.28872340425531917
- 0.47132978723404256
- 0.2925531914893617
- 0.26526595744680853
- 0.4172872340425532
- 0.43186170212765956
- 0.45393617021276594
test_loss_list:
- 4.288655440012614
- 4.036566591262817
- 4.991079819997152
- 4.03516760190328
- 4.011678886413574
- 3.3975377464294434
- 5.288117109934489
- 4.129375419616699
- 3.8177224731445314
- 3.8716783618927
- 3.3945066420237224
- 3.016912622451782
- 5.203808390299479
- 3.2042099761962892
- 4.352547499338786
- 3.510431966781616
- 3.1399751249949137
- 3.489400202433268
- 3.193879826863607
- 3.138030614852905
- 5.131348393758138
- 2.7550502014160156
- 3.1196893501281737
- 3.030099522272746
- 3.366611623764038
- 3.9102944278717042
- 2.477301073074341
- 2.889132572809855
- 3.1411376158396402
- 3.1432258097330728
- 2.878326110839844
- 3.7384655253092447
- 2.6588460540771486
- 2.981334425608317
- 2.9166124725341795
- 3.242071857452393
- 3.43823263168335
- 3.7288710117340087
- 2.53499560991923
- 2.985097901026408
- 2.6948945808410643
- 3.4021541754404705
- 2.3854038461049396
- 3.0375259335835776
- 2.562953815460205
- 4.329157295227051
- 2.751926918029785
- 2.3068633906046547
- 2.6139725240071616
- 2.5669681358337404
- 3.2975733439127604
- 3.6368031374613445
- 2.4013493569691975
- 2.847964652379354
- 2.8223185125986734
- 3.703916753133138
- 2.6537354787190757
- 2.605062526067098
- 2.5300552717844647
- 2.1611491664250693
- 2.8822631549835207
- 1.9879602193832397
- 2.1033545605341595
- 2.2124519554773965
- 2.1877006848653155
- 3.07474902788798
- 2.685452264149984
- 2.3830247656504313
- 1.8951606686909994
- 2.8917839336395263
- 2.5733616511027018
- 3.472456111907959
- 2.063228767712911
- 2.7161982917785643
- 2.235087103843689
- 2.0731743987401328
- 2.7058799997965495
- 2.105768658320109
- 1.9110722160339355
- 2.338178915977478
- 3.4387665780385337
- 1.9151250489552816
- 2.0714402373631797
- 2.396577205657959
- 2.2490171225865683
- 2.352748351097107
- 2.4964411513010663
- 3.2242174339294434
- 1.792441504796346
- 2.232743776639303
- 2.3054480218887328
- 2.1700472688674926
- 1.8118974622090658
- 2.863306795756022
- 1.7701330931981405
- 3.005415185292562
- 3.170397930145264
- 2.240377597808838
- 2.0311888519922894
- 1.7902736171086628
train_accuracy:
- 0.0
- 0.263
- 0.0
- 0.0
- 0.01
- 0.004
- 0.683
- 0.012
- 0.025
- 0.16
- 0.21
- 0.198
- 0.002
- 0.108
- 0.517
- 0.55
- 0.258
- 0.044
- 0.033
- 0.271
- 0.102
- 0.392
- 0.337
- 0.546
- 0.781
- 0.515
- 0.444
- 0.619
- 0.19
- 0.715
- 0.252
- 0.333
- 0.633
- 0.333
- 0.498
- 0.75
- 0.746
- 0.662
- 0.654
- 0.746
- 0.592
- 0.025
- 0.533
- 0.204
- 0.542
- 0.377
- 0.779
- 0.229
- 0.798
- 0.525
- 0.556
- 0.452
- 0.846
- 0.206
- 0.025
- 0.552
- 0.463
- 0.475
- 0.106
- 0.4
- 0.673
- 0.267
- 0.671
- 0.427
- 0.131
- 0.783
- 0.656
- 0.777
- 0.398
- 0.119
- 0.592
- 0.033
- 0.879
- 0.835
- 0.748
- 0.806
- 0.485
- 0.344
- 0.51
- 0.783
- 0.269
- 0.692
- 0.662
- 0.817
- 0.608
- 0.646
- 0.812
- 0.181
- 0.335
- 0.827
- 0.535
- 0.562
- 0.713
- 0.852
- 0.273
- 0.777
- 0.583
- 0.542
- 0.769
- 0.567
train_loss:
- 2.188
- 2.528
- 0.834
- 1.332
- 0.771
- 1.305
- 2.137
- 0.759
- 0.957
- 0.936
- 0.967
- 1.036
- 0.57
- 0.908
- 0.507
- 0.871
- 0.998
- 0.459
- 0.88
- 0.866
- 0.48
- 0.826
- 0.736
- 0.676
- 0.654
- 0.463
- 0.84
- 0.686
- 0.649
- 1.03
- 0.74
- 0.443
- 0.75
- 0.648
- 0.396
- 0.973
- 0.49
- 0.316
- 0.712
- 0.949
- 0.582
- 0.886
- 0.731
- 0.396
- 0.576
- 0.272
- 0.941
- 0.618
- 0.381
- 0.346
- 0.249
- 0.274
- 0.613
- 0.874
- 0.425
- 0.285
- 0.286
- 0.553
- 0.863
- 0.603
- 0.325
- 0.611
- 0.52
- 0.556
- 0.574
- 0.811
- 0.305
- 0.891
- 0.574
- 0.767
- 0.485
- 0.249
- 0.566
- 0.778
- 0.535
- 0.512
- 0.716
- 0.57
- 0.519
- 0.476
- 0.268
- 0.527
- 0.488
- 0.711
- 0.483
- 0.451
- 0.344
- 0.267
- 0.556
- 0.721
- 0.45
- 0.469
- 0.473
- 0.272
- 0.52
- 0.246
- 0.241
- 0.46
- 0.467
- 0.481
unequal: 0
verbose: 1
