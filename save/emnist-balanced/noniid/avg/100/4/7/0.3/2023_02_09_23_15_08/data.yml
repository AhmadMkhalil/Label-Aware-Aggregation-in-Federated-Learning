avg_train_accuracy: 0.771
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.059893617021276595
- 0.04026595744680851
- 0.06765957446808511
- 0.0875531914893617
- 0.10835106382978724
- 0.12925531914893618
- 0.12393617021276596
- 0.18106382978723404
- 0.17957446808510638
- 0.1425531914893617
- 0.15585106382978722
- 0.14095744680851063
- 0.13696808510638298
- 0.1701595744680851
- 0.24095744680851064
- 0.160531914893617
- 0.21468085106382978
- 0.2910106382978723
- 0.26122340425531915
- 0.18159574468085107
- 0.17547872340425533
- 0.15414893617021277
- 0.1671808510638298
- 0.3203191489361702
- 0.17648936170212767
- 0.14664893617021277
- 0.2839893617021277
- 0.3156914893617021
- 0.1970744680851064
- 0.19228723404255318
- 0.3356914893617021
- 0.28627659574468084
- 0.3349468085106383
- 0.34430851063829787
- 0.36414893617021277
- 0.27095744680851064
- 0.3542021276595745
- 0.24367021276595743
- 0.20925531914893616
- 0.2962234042553191
- 0.3218617021276596
- 0.3172872340425532
- 0.29
- 0.26851063829787236
- 0.21718085106382978
- 0.3529255319148936
- 0.37196808510638296
- 0.3898936170212766
- 0.4103191489361702
- 0.26313829787234044
- 0.3725531914893617
- 0.34191489361702126
- 0.20292553191489363
- 0.3861702127659574
- 0.25053191489361704
- 0.3223936170212766
- 0.42601063829787233
- 0.4340425531914894
- 0.37372340425531914
- 0.26159574468085106
- 0.38813829787234044
- 0.4152659574468085
- 0.41569148936170214
- 0.43351063829787234
- 0.3925
- 0.37579787234042555
- 0.31
- 0.43042553191489363
- 0.29675531914893616
- 0.2701063829787234
- 0.4350531914893617
- 0.26930851063829786
- 0.47925531914893615
- 0.4282446808510638
- 0.4651595744680851
- 0.43670212765957445
- 0.4326595744680851
- 0.42425531914893616
- 0.4156382978723404
- 0.44904255319148934
- 0.4222872340425532
- 0.4546276595744681
- 0.44361702127659575
- 0.2878723404255319
- 0.488031914893617
- 0.44457446808510637
- 0.45930851063829786
- 0.46595744680851064
- 0.3076595744680851
- 0.4778191489361702
- 0.4048404255319149
- 0.4601595744680851
- 0.44601063829787235
- 0.4798936170212766
- 0.5015957446808511
- 0.49425531914893617
- 0.41425531914893615
- 0.42861702127659573
- 0.4029255319148936
- 0.32404255319148934
test_loss_list:
- 4.589424769083659
- 4.1511919275919595
- 3.9166681480407717
- 3.9125443363189696
- 4.939107723236084
- 3.726823002497355
- 3.3946497344970705
- 3.5024877993265786
- 3.54850315729777
- 4.770892976125081
- 3.50919153213501
- 4.011688594818115
- 4.331588045756022
- 3.464984591801961
- 3.115748208363851
- 3.8344794495900474
- 3.2357339986165363
- 4.034541629155477
- 2.9904825433095295
- 3.80446946144104
- 4.249208548863729
- 3.863710511525472
- 4.10477430343628
- 3.116205628712972
- 4.124298906326294
- 3.9398764260609944
- 2.8123149776458742
- 3.148154630661011
- 3.9459654458363853
- 3.5750653680165607
- 3.327285321553548
- 3.247398831049601
- 3.551298163731893
- 2.9679834524790447
- 2.259589303334554
- 2.7602688376108806
- 2.592658672332764
- 3.1693272527058918
- 3.803595298131307
- 2.9453216361999512
- 2.6600980122884113
- 2.917986650466919
- 2.9681342029571534
- 3.0770333925882976
- 3.8469787311553953
- 2.9988796361287435
- 2.513096996943156
- 2.6516052150726317
- 2.4817731698354084
- 3.157903645833333
- 2.05921639919281
- 2.428763818740845
- 3.640369170506795
- 2.8513677978515624
- 3.4356791877746584
- 2.379013694127401
- 2.096075652440389
- 1.9997258313496908
- 2.861397473017375
- 2.928113152186076
- 2.6606986204783123
- 2.367629810969035
- 2.063303920427958
- 2.278951369921366
- 2.1925924173990885
- 3.3446514987945557
- 2.6107024256388347
- 2.2117289527257284
- 2.7508405017852784
- 2.933603219985962
- 1.9700599304835003
- 2.945304346084595
- 1.8705999898910521
- 2.0189539702733357
- 1.8823528893788655
- 1.9918025509516397
- 2.1370233805974324
- 2.1318796173731487
- 2.19766836643219
- 1.964264399210612
- 1.9658638270696005
- 1.9750353113810222
- 2.021985402107239
- 3.0263575077056886
- 1.7107897631327311
- 2.0058607292175292
- 1.7086215384801229
- 1.7465530506769815
- 2.6801994546254475
- 1.796564253171285
- 2.4645952288309734
- 1.8600665966669718
- 1.95112317721049
- 1.9399858713150024
- 1.697628418604533
- 1.7416412830352783
- 1.9816157992680867
- 2.284971761703491
- 2.4851470756530762
- 2.814195884068807
train_accuracy:
- 0.0
- 0.004
- 0.446
- 0.035
- 0.035
- 0.348
- 0.696
- 0.079
- 0.344
- 0.121
- 0.173
- 0.237
- 0.006
- 0.042
- 0.46
- 0.725
- 0.081
- 0.642
- 0.452
- 0.012
- 0.379
- 0.46
- 0.252
- 0.685
- 0.742
- 0.21
- 0.379
- 0.606
- 0.14
- 0.558
- 0.723
- 0.54
- 0.031
- 0.55
- 0.308
- 0.45
- 0.787
- 0.456
- 0.675
- 0.069
- 0.381
- 0.777
- 0.127
- 0.267
- 0.577
- 0.763
- 0.525
- 0.217
- 0.623
- 0.294
- 0.231
- 0.496
- 0.169
- 0.35
- 0.5
- 0.76
- 0.217
- 0.583
- 0.042
- 0.675
- 0.237
- 0.64
- 0.623
- 0.927
- 0.652
- 0.012
- 0.698
- 0.812
- 0.75
- 0.7
- 0.944
- 0.337
- 0.827
- 0.571
- 0.229
- 0.577
- 0.617
- 0.638
- 0.846
- 0.61
- 0.696
- 0.694
- 0.944
- 0.867
- 0.621
- 0.971
- 0.54
- 0.337
- 0.64
- 0.727
- 0.012
- 0.706
- 0.654
- 0.806
- 0.269
- 0.635
- 0.869
- 0.848
- 0.01
- 0.771
train_loss:
- 2.132
- 1.869
- 1.622
- 1.327
- 0.673
- 1.178
- 0.687
- 0.967
- 1.111
- 0.656
- 1.053
- 0.505
- 0.6
- 0.976
- 1.042
- 0.47
- 0.805
- 1.22
- 0.909
- 0.449
- 0.466
- 0.512
- 0.376
- 1.251
- 0.401
- 0.416
- 0.892
- 0.771
- 0.349
- 0.285
- 1.22
- 0.772
- 1.02
- 0.642
- 0.724
- 0.374
- 0.662
- 0.314
- 0.316
- 0.615
- 0.65
- 0.617
- 0.268
- 0.231
- 0.293
- 1.1
- 0.694
- 0.552
- 0.569
- 0.328
- 0.65
- 0.638
- 0.271
- 0.974
- 0.361
- 0.337
- 0.616
- 0.615
- 0.813
- 0.356
- 0.862
- 0.542
- 0.528
- 0.561
- 0.485
- 0.72
- 0.375
- 0.507
- 0.305
- 0.284
- 0.509
- 0.273
- 0.525
- 0.5
- 0.524
- 0.453
- 0.486
- 0.469
- 0.441
- 0.521
- 0.554
- 0.459
- 0.477
- 0.32
- 0.486
- 0.492
- 0.485
- 0.469
- 0.245
- 0.564
- 0.727
- 0.491
- 0.488
- 0.487
- 0.462
- 0.502
- 0.242
- 0.683
- 0.673
- 0.266
unequal: 0
verbose: 1
