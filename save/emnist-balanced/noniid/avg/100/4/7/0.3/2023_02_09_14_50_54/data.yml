avg_train_accuracy: 0.846
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04723404255319149
- 0.0451063829787234
- 0.115
- 0.06904255319148936
- 0.1525
- 0.07898936170212766
- 0.10686170212765958
- 0.2175
- 0.22680851063829788
- 0.19957446808510637
- 0.205
- 0.19531914893617022
- 0.2781914893617021
- 0.13664893617021276
- 0.12648936170212766
- 0.19170212765957448
- 0.21829787234042553
- 0.13909574468085106
- 0.1997340425531915
- 0.2498936170212766
- 0.2595212765957447
- 0.1596276595744681
- 0.22920212765957446
- 0.3198404255319149
- 0.2767553191489362
- 0.15021276595744681
- 0.23686170212765958
- 0.27558510638297873
- 0.2649468085106383
- 0.27845744680851064
- 0.25468085106382976
- 0.31063829787234043
- 0.1775531914893617
- 0.16335106382978723
- 0.16632978723404254
- 0.18920212765957448
- 0.1876063829787234
- 0.23585106382978724
- 0.22994680851063828
- 0.20132978723404255
- 0.17680851063829786
- 0.3421276595744681
- 0.18207446808510638
- 0.20101063829787233
- 0.3381382978723404
- 0.21425531914893617
- 0.3093085106382979
- 0.36425531914893616
- 0.34691489361702127
- 0.2227127659574468
- 0.19888297872340427
- 0.3097340425531915
- 0.359468085106383
- 0.344468085106383
- 0.20303191489361702
- 0.36
- 0.3131914893617021
- 0.3448404255319149
- 0.4122872340425532
- 0.3674468085106383
- 0.3882978723404255
- 0.36829787234042555
- 0.3008510638297872
- 0.25079787234042555
- 0.37840425531914895
- 0.3173404255319149
- 0.36377659574468085
- 0.27132978723404255
- 0.3703723404255319
- 0.40654255319148935
- 0.36031914893617023
- 0.3771276595744681
- 0.3821276595744681
- 0.42319148936170214
- 0.3718085106382979
- 0.4270744680851064
- 0.3895212765957447
- 0.4271276595744681
- 0.3770212765957447
- 0.3217553191489362
- 0.3705851063829787
- 0.3675
- 0.42611702127659573
- 0.27414893617021274
- 0.38148936170212766
- 0.3242553191489362
- 0.4775531914893617
- 0.3592021276595745
- 0.42404255319148937
- 0.39537234042553193
- 0.2925531914893617
- 0.3906914893617021
- 0.3901063829787234
- 0.46047872340425533
- 0.4375
- 0.39
- 0.4157446808510638
- 0.4852659574468085
- 0.4720744680851064
- 0.41175531914893615
test_loss_list:
- 4.027423572540283
- 4.410661182403564
- 4.199016838073731
- 4.336719487508138
- 4.007618522644043
- 4.0707600307464595
- 3.8171559079488118
- 4.134235744476318
- 3.71449800491333
- 3.5436302280426024
- 3.64851957321167
- 3.5799309253692626
- 4.136476513544719
- 3.6290165201822915
- 4.910424219767252
- 3.328742453257243
- 3.41662589708964
- 3.8824119091033937
- 3.2847564760843913
- 3.0019957065582275
- 3.1406455707550047
- 3.5589021968841554
- 3.4602675183614093
- 3.806612335840861
- 3.3336987908681235
- 4.726589705149332
- 3.5075027656555178
- 2.83762246131897
- 2.947093941370646
- 2.9055714861551922
- 3.067574202219645
- 2.797496115366618
- 3.6612654717763267
- 4.12838316599528
- 3.9393731594085692
- 3.5532959651947023
- 3.7405295085906984
- 3.1797903124491373
- 3.1335036436716717
- 3.8363820044199626
- 3.987421776453654
- 3.2748033301035564
- 3.6994315878550212
- 3.543441435496012
- 2.3967819690704344
- 3.0792609723409017
- 2.435871260960897
- 2.2662823534011842
- 3.4768163204193114
- 3.22407945950826
- 3.568031702041626
- 2.640412804285685
- 2.2604676564534505
- 3.0544414424896242
- 3.658190507888794
- 3.3546786212921145
- 2.6043780008951822
- 2.314670000076294
- 2.2272672128677367
- 2.677718718846639
- 2.382759617169698
- 3.1647296810150145
- 2.803157663345337
- 3.0360272979736327
- 2.647459529240926
- 2.323541202545166
- 2.223340794245402
- 3.0478932571411135
- 2.7480703894297283
- 2.143928914070129
- 2.496979513168335
- 2.8537646929423013
- 2.606153580347697
- 2.2318656714757283
- 3.1423396110534667
- 2.0953601805369058
- 2.6381745529174805
- 2.2057521120707193
- 3.248001168568929
- 2.957098134358724
- 2.625459626515706
- 2.360535545349121
- 2.0212034352620445
- 3.084884510040283
- 2.7661786874135337
- 2.644318103790283
- 1.8067194207509358
- 2.2644977807998656
- 1.9368654855092367
- 2.4512737147013346
- 2.6807641410827636
- 2.257042277654012
- 2.4431628131866456
- 1.9777524852752686
- 2.1449133936564126
- 2.6366395314534503
- 2.1902951542536417
- 1.9235285631815593
- 1.8160562594731648
- 2.3859100325902305
train_accuracy:
- 0.104
- 0.0
- 0.0
- 0.0
- 0.348
- 0.0
- 0.088
- 0.015
- 0.096
- 0.265
- 0.062
- 0.358
- 0.615
- 0.562
- 0.006
- 0.271
- 0.192
- 0.037
- 0.221
- 0.104
- 0.369
- 0.494
- 0.258
- 0.058
- 0.412
- 0.258
- 0.146
- 0.177
- 0.435
- 0.34
- 0.373
- 0.463
- 0.565
- 0.558
- 0.554
- 0.142
- 0.331
- 0.74
- 0.908
- 0.567
- 0.156
- 0.717
- 0.202
- 0.181
- 0.39
- 0.229
- 0.31
- 0.55
- 0.769
- 0.269
- 0.804
- 0.8
- 0.456
- 0.79
- 0.113
- 0.792
- 0.631
- 0.487
- 0.469
- 0.083
- 0.667
- 0.006
- 0.471
- 0.65
- 0.802
- 0.44
- 0.494
- 0.565
- 0.812
- 0.471
- 0.404
- 0.252
- 0.579
- 0.617
- 0.821
- 0.679
- 0.833
- 0.644
- 0.0
- 0.34
- 0.629
- 0.658
- 0.156
- 0.135
- 0.838
- 0.933
- 0.425
- 0.608
- 0.846
- 0.144
- 0.767
- 0.263
- 0.352
- 0.1
- 0.235
- 0.833
- 0.638
- 0.454
- 0.619
- 0.846
train_loss:
- 2.89
- 1.186
- 1.483
- 0.837
- 1.947
- 0.959
- 1.191
- 1.684
- 1.435
- 1.145
- 1.104
- 0.988
- 1.396
- 0.803
- 0.642
- 1.078
- 0.984
- 0.517
- 0.907
- 0.966
- 0.907
- 0.53
- 0.901
- 1.174
- 0.867
- 0.585
- 0.882
- 0.887
- 0.825
- 0.83
- 0.825
- 0.792
- 0.493
- 0.519
- 0.455
- 0.44
- 0.484
- 0.766
- 0.512
- 0.466
- 0.373
- 1.159
- 0.435
- 0.398
- 0.764
- 0.496
- 0.777
- 0.795
- 0.994
- 0.413
- 0.423
- 0.71
- 0.691
- 0.955
- 0.406
- 1.014
- 0.485
- 0.734
- 0.669
- 0.933
- 0.648
- 0.912
- 0.384
- 0.327
- 0.965
- 0.438
- 0.605
- 0.376
- 0.883
- 0.657
- 0.592
- 0.829
- 0.567
- 0.597
- 0.836
- 0.625
- 0.803
- 0.56
- 0.775
- 0.371
- 0.559
- 0.364
- 0.578
- 0.324
- 0.821
- 0.347
- 0.578
- 0.333
- 0.579
- 0.745
- 0.35
- 0.5
- 0.495
- 0.537
- 0.508
- 0.75
- 0.515
- 0.557
- 0.551
- 0.711
unequal: 0
verbose: 1
