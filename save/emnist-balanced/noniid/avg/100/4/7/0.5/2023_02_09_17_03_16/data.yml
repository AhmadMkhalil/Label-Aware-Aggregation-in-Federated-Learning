avg_train_accuracy: 0.479
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.050691489361702126
- 0.12420212765957447
- 0.15170212765957447
- 0.21829787234042553
- 0.12111702127659575
- 0.22031914893617022
- 0.22069148936170213
- 0.3003723404255319
- 0.264468085106383
- 0.26132978723404254
- 0.22936170212765958
- 0.28106382978723404
- 0.3012234042553191
- 0.20840425531914894
- 0.3323936170212766
- 0.34297872340425534
- 0.3302127659574468
- 0.3648936170212766
- 0.3472340425531915
- 0.2703191489361702
- 0.3217553191489362
- 0.35148936170212763
- 0.33824468085106385
- 0.3375531914893617
- 0.29117021276595745
- 0.36101063829787233
- 0.40606382978723404
- 0.32978723404255317
- 0.3758510638297872
- 0.3907978723404255
- 0.3997340425531915
- 0.40691489361702127
- 0.39324468085106384
- 0.35425531914893615
- 0.42946808510638296
- 0.4377127659574468
- 0.3656382978723404
- 0.39430851063829786
- 0.37340425531914895
- 0.38930851063829786
- 0.43813829787234043
- 0.44941489361702125
- 0.4344148936170213
- 0.41377659574468084
- 0.4563829787234043
- 0.45617021276595743
- 0.44430851063829785
- 0.43053191489361703
- 0.4628191489361702
- 0.4474468085106383
- 0.470531914893617
- 0.4193085106382979
- 0.47
- 0.46367021276595743
- 0.4453191489361702
- 0.4710106382978723
- 0.35723404255319147
- 0.4046808510638298
- 0.4765957446808511
- 0.4491489361702128
- 0.4399468085106383
- 0.49457446808510636
- 0.5006382978723404
- 0.40856382978723405
- 0.49117021276595746
- 0.5346808510638298
- 0.3740425531914894
- 0.4632978723404255
- 0.49813829787234043
- 0.5070744680851064
- 0.5254255319148936
- 0.4896276595744681
- 0.5108510638297873
- 0.5103723404255319
- 0.44148936170212766
- 0.5334042553191489
- 0.5308510638297872
- 0.5174468085106383
- 0.42984042553191487
- 0.5363829787234042
- 0.5181382978723404
- 0.5078191489361702
- 0.5551595744680851
- 0.4450531914893617
- 0.5377127659574468
- 0.5467553191489362
- 0.5315425531914894
- 0.49606382978723407
- 0.5279255319148937
- 0.5863297872340425
- 0.5380851063829787
- 0.5203191489361703
- 0.5262765957446809
- 0.5143085106382979
- 0.5143617021276595
- 0.5021808510638298
- 0.5595744680851064
- 0.47425531914893615
- 0.5371808510638297
- 0.5627127659574468
test_loss_list:
- 4.074270467758179
- 3.611805556615194
- 3.518873227437337
- 3.3721767234802247
- 3.5784407329559325
- 3.260440867741903
- 3.1596886698404947
- 3.3077067502339683
- 2.984467528661092
- 3.067498426437378
- 3.213544953664144
- 2.755837024052938
- 2.880521332422892
- 3.0737168979644776
- 2.6288962586720785
- 2.640175193150838
- 2.777779426574707
- 2.583794806798299
- 2.594171355565389
- 2.9516336917877197
- 3.1628881454467774
- 2.8813020038604735
- 2.597146371205648
- 2.467785676320394
- 2.8360345268249514
- 2.3266755549112954
- 2.334138059616089
- 2.4033256657918294
- 2.288581790924072
- 2.2166835244496665
- 2.0984498246510825
- 2.272056293487549
- 2.446890459060669
- 2.4694051424662273
- 2.4109138425191246
- 2.1098140986760456
- 2.3767271200815836
- 2.179490836461385
- 2.960079298019409
- 2.8018074957529704
- 2.161245903968811
- 1.9738715918858847
- 2.040399603843689
- 2.0524498716990154
- 1.986018133163452
- 1.9531950807571412
- 1.892583940823873
- 2.0053201977411907
- 1.9636073382695516
- 2.1293254137039184
- 1.970989621480306
- 2.106289610862732
- 1.7791747506459554
- 1.8632495594024658
- 1.9360141992568969
- 1.969863977432251
- 2.3378822580973306
- 2.3184172407786052
- 1.7785667244593302
- 1.8751753568649292
- 2.098812085787455
- 1.8781015094121296
- 1.7969125938415527
- 2.0318560441335043
- 1.699283423423767
- 1.530908571879069
- 2.237954797744751
- 1.7536808856328328
- 1.6806163120269775
- 1.6868509340286255
- 1.555163327852885
- 1.6639585733413695
- 1.7025890779495239
- 1.6186690203348795
- 1.9113391415278116
- 1.5327935616175334
- 1.4903664986292522
- 1.6007373507817586
- 2.1599295202891033
- 1.5415236552556355
- 1.5307163333892821
- 1.622111037572225
- 1.4658125241597493
- 2.043265463511149
- 1.4887332169214884
- 1.4806914265950522
- 1.6083960898717244
- 1.7855309756596882
- 1.625860538482666
- 1.3202828756968181
- 1.4310045512517293
- 1.5146998612085978
- 1.5774899005889893
- 1.621120049158732
- 1.6577036062876382
- 1.6482801198959351
- 1.399639523824056
- 1.7906145970026652
- 1.5678707059224446
- 1.3667941745122274
train_accuracy:
- 0.002
- 0.137
- 0.221
- 0.212
- 0.0
- 0.463
- 0.331
- 0.525
- 0.008
- 0.223
- 0.169
- 0.206
- 0.006
- 0.0
- 0.246
- 0.569
- 0.194
- 0.081
- 0.192
- 0.21
- 0.752
- 0.002
- 0.344
- 0.117
- 0.237
- 0.125
- 0.633
- 0.444
- 0.148
- 0.408
- 0.075
- 0.027
- 0.375
- 0.306
- 0.735
- 0.673
- 0.094
- 0.456
- 0.804
- 0.773
- 0.692
- 0.621
- 0.023
- 0.677
- 0.713
- 0.15
- 0.088
- 0.354
- 0.006
- 0.485
- 0.733
- 0.685
- 0.731
- 0.86
- 0.15
- 0.725
- 0.415
- 0.827
- 0.113
- 0.071
- 0.688
- 0.544
- 0.783
- 0.073
- 0.396
- 0.392
- 0.102
- 0.415
- 0.683
- 0.542
- 0.283
- 0.487
- 0.792
- 0.769
- 0.848
- 0.746
- 0.427
- 0.76
- 0.773
- 0.773
- 0.6
- 0.487
- 0.796
- 0.198
- 0.648
- 0.446
- 0.548
- 0.727
- 0.027
- 0.24
- 0.529
- 0.156
- 0.615
- 0.871
- 0.765
- 0.883
- 0.773
- 0.504
- 0.804
- 0.479
train_loss:
- 1.999
- 1.878
- 1.589
- 1.321
- 0.959
- 1.306
- 0.874
- 1.071
- 1.105
- 0.779
- 0.74
- 0.775
- 0.926
- 0.489
- 0.904
- 0.876
- 0.849
- 0.838
- 0.817
- 0.451
- 1.026
- 0.973
- 0.602
- 0.6
- 0.367
- 0.548
- 0.738
- 0.554
- 0.547
- 0.532
- 0.544
- 0.692
- 0.661
- 0.465
- 0.653
- 0.694
- 0.517
- 0.505
- 0.797
- 0.79
- 0.658
- 0.504
- 0.66
- 0.489
- 0.617
- 0.635
- 0.462
- 0.419
- 0.592
- 0.58
- 0.607
- 0.44
- 0.45
- 0.443
- 0.447
- 0.564
- 0.302
- 0.764
- 0.442
- 0.432
- 0.399
- 0.544
- 0.564
- 0.258
- 0.408
- 0.415
- 0.249
- 0.409
- 0.386
- 0.375
- 0.557
- 0.38
- 0.525
- 0.525
- 0.254
- 0.569
- 0.395
- 0.527
- 0.226
- 0.548
- 0.363
- 0.368
- 0.525
- 0.653
- 0.536
- 0.359
- 0.508
- 0.362
- 0.353
- 0.389
- 0.365
- 0.356
- 0.491
- 0.358
- 0.37
- 0.359
- 0.504
- 0.224
- 0.484
- 0.478
unequal: 0
verbose: 1
