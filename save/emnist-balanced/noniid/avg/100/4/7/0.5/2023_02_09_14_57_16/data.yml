avg_train_accuracy: 0.163
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03425531914893617
- 0.06335106382978724
- 0.1548404255319149
- 0.1797872340425532
- 0.1320744680851064
- 0.2521276595744681
- 0.2399468085106383
- 0.20542553191489363
- 0.2911170212765957
- 0.3022340425531915
- 0.30159574468085104
- 0.18372340425531916
- 0.2954255319148936
- 0.31398936170212766
- 0.3435106382978723
- 0.3479255319148936
- 0.35829787234042554
- 0.3428191489361702
- 0.33489361702127657
- 0.3728191489361702
- 0.34569148936170213
- 0.3644148936170213
- 0.32776595744680853
- 0.3797340425531915
- 0.34202127659574466
- 0.3620744680851064
- 0.30909574468085105
- 0.37542553191489364
- 0.4046808510638298
- 0.3503723404255319
- 0.4067021276595745
- 0.3152127659574468
- 0.4077659574468085
- 0.29377659574468085
- 0.40356382978723404
- 0.4371276595744681
- 0.4466489361702128
- 0.42090425531914893
- 0.42531914893617023
- 0.45074468085106384
- 0.44303191489361704
- 0.45345744680851063
- 0.3373404255319149
- 0.4843085106382979
- 0.4419148936170213
- 0.37303191489361703
- 0.46324468085106385
- 0.4466489361702128
- 0.45154255319148934
- 0.4772872340425532
- 0.47356382978723405
- 0.46819148936170213
- 0.4607978723404255
- 0.38132978723404254
- 0.4268085106382979
- 0.4493617021276596
- 0.4617553191489362
- 0.40122340425531916
- 0.4541489361702128
- 0.4761170212765957
- 0.45335106382978724
- 0.44638297872340427
- 0.49361702127659574
- 0.46382978723404256
- 0.5133510638297872
- 0.5093617021276595
- 0.46170212765957447
- 0.48617021276595745
- 0.4874468085106383
- 0.4926063829787234
- 0.5003723404255319
- 0.4777659574468085
- 0.42984042553191487
- 0.5431914893617021
- 0.46143617021276595
- 0.5095744680851064
- 0.49888297872340426
- 0.4772872340425532
- 0.4952127659574468
- 0.48904255319148937
- 0.5106382978723404
- 0.5107978723404255
- 0.5048404255319149
- 0.4995212765957447
- 0.4934574468085106
- 0.5263297872340426
- 0.5186170212765957
- 0.5211702127659574
- 0.4959574468085106
- 0.48856382978723406
- 0.5490957446808511
- 0.5366489361702128
- 0.5294148936170213
- 0.5485638297872341
- 0.4998936170212766
- 0.5625531914893617
- 0.5155851063829787
- 0.5419148936170213
- 0.44138297872340426
- 0.5067553191489361
test_loss_list:
- 3.9868434778849284
- 3.9581959788004557
- 3.6024804306030274
- 3.5135474077860516
- 3.541850439707438
- 3.265666837692261
- 3.1141567039489746
- 3.084272829691569
- 3.0582958030700684
- 2.8043144226074217
- 2.859474391937256
- 3.1048490047454833
- 2.5880968697865803
- 2.82559757232666
- 2.750432914098104
- 2.536330591837565
- 2.56021858215332
- 2.4169577439626058
- 2.405295082728068
- 2.405875873565674
- 2.579329423904419
- 2.391176513036092
- 2.438678865432739
- 2.2427963320414226
- 2.9704978116353353
- 2.855363747278849
- 2.4955695056915284
- 2.263814163208008
- 2.2006681044896443
- 2.4025459639231364
- 2.1271812200546263
- 2.4785116481781007
- 2.07788773059845
- 2.625035959879557
- 2.07124883333842
- 2.0096017122268677
- 2.008842554092407
- 2.1758187087376912
- 1.9549276908238729
- 1.8817365026474
- 2.027208744684855
- 1.9688822968800863
- 2.3681861337025962
- 1.7153629477818806
- 1.908213547070821
- 2.2276841735839845
- 1.882555546760559
- 2.0311863215764365
- 1.917329805692037
- 1.7617289511362713
- 1.9202576478322346
- 1.8931492471694946
- 1.9547195609410604
- 2.6789612611134848
- 2.0899788188934325
- 1.900273536046346
- 2.085056177775065
- 2.7493968200683594
- 2.033906928698222
- 2.040368062655131
- 1.9172084760665893
- 2.161887224515279
- 1.8032849868138632
- 1.8653329531351726
- 1.58212508837382
- 1.7526523733139039
- 1.7702983156840006
- 1.6786698118845622
- 1.8356852356592814
- 1.8354321908950806
- 1.6332964134216308
- 1.7787770144144694
- 1.835036390622457
- 1.498931614557902
- 1.7519612407684326
- 1.6721341117223103
- 1.728508736292521
- 1.7352296702067058
- 1.765490787823995
- 1.8395085112253824
- 1.7040365393956503
- 1.7727985699971518
- 1.6646027421951295
- 1.6745967260996502
- 1.8051076332728069
- 1.6398746792475383
- 1.6100113900502522
- 1.6969565312067667
- 1.7778422053654988
- 1.8663145065307618
- 1.4528458086649576
- 1.5367884985605875
- 1.594678093592326
- 1.4655746873219808
- 1.5819530200958252
- 1.454316341082255
- 1.6533725865681965
- 1.487926648457845
- 2.2002125549316407
- 1.587954060236613
train_accuracy:
- 0.0
- 0.008
- 0.269
- 0.0
- 0.096
- 0.004
- 0.0
- 0.323
- 0.0
- 0.385
- 0.142
- 0.098
- 0.033
- 0.525
- 0.51
- 0.035
- 0.098
- 0.052
- 0.077
- 0.662
- 0.56
- 0.415
- 0.156
- 0.337
- 0.76
- 0.742
- 0.1
- 0.035
- 0.006
- 0.123
- 0.46
- 0.292
- 0.088
- 0.34
- 0.048
- 0.281
- 0.683
- 0.079
- 0.081
- 0.496
- 0.012
- 0.244
- 0.056
- 0.233
- 0.033
- 0.41
- 0.054
- 0.669
- 0.167
- 0.283
- 0.713
- 0.14
- 0.037
- 0.021
- 0.652
- 0.123
- 0.754
- 0.829
- 0.21
- 0.008
- 0.469
- 0.431
- 0.006
- 0.075
- 0.071
- 0.01
- 0.473
- 0.254
- 0.812
- 0.175
- 0.175
- 0.354
- 0.231
- 0.054
- 0.135
- 0.167
- 0.102
- 0.117
- 0.354
- 0.154
- 0.76
- 0.002
- 0.183
- 0.579
- 0.798
- 0.737
- 0.542
- 0.275
- 0.079
- 0.123
- 0.169
- 0.775
- 0.633
- 0.302
- 0.438
- 0.34
- 0.26
- 0.633
- 0.002
- 0.163
train_loss:
- 1.927
- 1.397
- 1.539
- 1.381
- 0.993
- 1.184
- 1.152
- 0.842
- 1.044
- 0.788
- 1.003
- 0.577
- 0.799
- 0.895
- 0.866
- 0.884
- 0.894
- 0.644
- 0.705
- 0.78
- 0.841
- 0.654
- 0.601
- 0.572
- 0.975
- 0.867
- 0.435
- 0.602
- 0.793
- 0.576
- 0.603
- 0.409
- 0.585
- 0.388
- 0.571
- 0.665
- 0.702
- 0.691
- 0.536
- 0.541
- 0.671
- 0.478
- 0.369
- 0.532
- 0.514
- 0.293
- 0.69
- 0.597
- 0.655
- 0.453
- 0.641
- 0.64
- 0.628
- 0.708
- 0.632
- 0.472
- 0.604
- 0.684
- 0.629
- 0.601
- 0.459
- 0.39
- 0.472
- 0.612
- 0.467
- 0.597
- 0.396
- 0.445
- 0.581
- 0.564
- 0.416
- 0.442
- 0.294
- 0.394
- 0.37
- 0.578
- 0.507
- 0.357
- 0.424
- 0.491
- 0.49
- 0.543
- 0.527
- 0.428
- 0.544
- 0.478
- 0.382
- 0.562
- 0.472
- 0.484
- 0.45
- 0.537
- 0.396
- 0.405
- 0.37
- 0.557
- 0.527
- 0.403
- 0.599
- 0.355
unequal: 0
verbose: 1
