avg_train_accuracy: 0.204
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03340425531914894
- 0.08111702127659574
- 0.13196808510638297
- 0.1271276595744681
- 0.17952127659574468
- 0.2375
- 0.1879255319148936
- 0.2451063829787234
- 0.2629787234042553
- 0.2501063829787234
- 0.2825
- 0.2987234042553191
- 0.31042553191489364
- 0.3142553191489362
- 0.2570212765957447
- 0.26526595744680853
- 0.30819148936170215
- 0.3600531914893617
- 0.3675
- 0.39526595744680854
- 0.3122340425531915
- 0.3470744680851064
- 0.35404255319148936
- 0.32638297872340427
- 0.3422872340425532
- 0.33170212765957446
- 0.3768085106382979
- 0.37909574468085105
- 0.3421276595744681
- 0.3776063829787234
- 0.34441489361702127
- 0.3886702127659574
- 0.3964893617021277
- 0.3677659574468085
- 0.39585106382978724
- 0.41138297872340424
- 0.42367021276595745
- 0.329468085106383
- 0.39914893617021274
- 0.3902127659574468
- 0.4340425531914894
- 0.3179787234042553
- 0.44872340425531915
- 0.44377659574468087
- 0.4160106382978723
- 0.44585106382978723
- 0.43367021276595746
- 0.42840425531914894
- 0.3604255319148936
- 0.46037234042553193
- 0.44909574468085106
- 0.44648936170212766
- 0.3346276595744681
- 0.4454255319148936
- 0.4659042553191489
- 0.44042553191489364
- 0.4529255319148936
- 0.456968085106383
- 0.45015957446808513
- 0.46117021276595743
- 0.4757446808510638
- 0.4426595744680851
- 0.4775
- 0.48696808510638295
- 0.47111702127659577
- 0.48877659574468085
- 0.46367021276595743
- 0.4952659574468085
- 0.3962765957446808
- 0.5010638297872341
- 0.5037234042553191
- 0.48686170212765956
- 0.41069148936170213
- 0.4888297872340426
- 0.5418617021276596
- 0.5228191489361702
- 0.5026063829787234
- 0.5036170212765958
- 0.5062765957446809
- 0.5169680851063829
- 0.4907446808510638
- 0.5096808510638298
- 0.5162234042553191
- 0.4745744680851064
- 0.5371276595744681
- 0.4179255319148936
- 0.46893617021276596
- 0.5261702127659574
- 0.43292553191489364
- 0.4996808510638298
- 0.49590425531914895
- 0.5310106382978723
- 0.5331914893617021
- 0.49936170212765957
- 0.5136170212765957
- 0.42664893617021277
- 0.4228723404255319
- 0.5206382978723404
- 0.5518085106382978
- 0.5496808510638298
test_loss_list:
- 3.9471567344665526
- 4.001704912185669
- 3.682117862701416
- 4.357934093475341
- 3.5751861254374186
- 3.7406578636169434
- 3.226711905797323
- 3.1580326461791994
- 3.2482775338490804
- 2.8732371075948078
- 2.958099479675293
- 3.5713832855224608
- 2.850501012802124
- 3.4628356806437175
- 2.8772894668579103
- 2.876877835591634
- 2.511847972869873
- 2.589721762339274
- 2.5171011225382487
- 2.558620055516561
- 2.669926109313965
- 2.542399861017863
- 2.634394826889038
- 2.5591064993540447
- 2.541302490234375
- 3.1109920152028403
- 2.4919530550638833
- 2.2061391639709473
- 2.4911518065134683
- 2.455518445968628
- 2.4637555726369222
- 2.2912180264790853
- 2.2250956662495933
- 2.3862038898468017
- 2.4236093870798747
- 2.3704989910125733
- 2.385939016342163
- 2.4404109954833983
- 2.224165315628052
- 2.2485302686691284
- 2.3247462050120036
- 2.5484754753112795
- 2.224549600283305
- 2.41914493560791
- 2.1373829237620035
- 2.094756317138672
- 1.9818837817509969
- 2.0424140310287475
- 2.4905573495229087
- 2.04722687403361
- 1.8726346747080485
- 2.0177430152893066
- 2.4677319208780926
- 1.9902528095245362
- 1.8488808886210124
- 1.916903896331787
- 1.8895958439509073
- 1.7817707220713297
- 2.0536179542541504
- 2.0022281710306804
- 1.8897021738688151
- 1.8513848400115966
- 1.9579205258687338
- 1.7490194161732993
- 1.8094765361150105
- 1.7882181088129678
- 1.8142551199595134
- 1.7375550444920858
- 2.1420710976918538
- 1.689535444577535
- 1.773173327445984
- 1.7856073665618897
- 2.5756538486480713
- 1.8090543238321941
- 1.5612399705251059
- 1.5935656547546386
- 1.5894831355412802
- 1.5976887400945028
- 1.6891816806793214
- 1.6521338796615601
- 1.815493491490682
- 1.6985913006464641
- 1.6367836205164592
- 1.7166508674621581
- 1.5542192920049032
- 2.5013558292388915
- 1.8227853027979533
- 1.6229980532328288
- 2.5938371562957765
- 1.7373930708567302
- 1.8085451316833496
- 1.5673848136266073
- 1.6037586688995362
- 1.8152788432439169
- 1.6660017744700113
- 2.035240149497986
- 2.3982704305648803
- 1.6375556659698487
- 1.4742642577489218
- 1.5393493445714315
train_accuracy:
- 0.0
- 0.0
- 0.181
- 0.0
- 0.233
- 0.537
- 0.0
- 0.002
- 0.0
- 0.044
- 0.537
- 0.679
- 0.102
- 0.75
- 0.294
- 0.181
- 0.069
- 0.069
- 0.683
- 0.673
- 0.342
- 0.015
- 0.033
- 0.275
- 0.315
- 0.785
- 0.135
- 0.092
- 0.006
- 0.692
- 0.412
- 0.002
- 0.033
- 0.065
- 0.144
- 0.035
- 0.688
- 0.596
- 0.133
- 0.113
- 0.692
- 0.135
- 0.66
- 0.669
- 0.448
- 0.012
- 0.027
- 0.427
- 0.375
- 0.76
- 0.479
- 0.067
- 0.865
- 0.108
- 0.74
- 0.217
- 0.196
- 0.075
- 0.077
- 0.237
- 0.037
- 0.579
- 0.79
- 0.025
- 0.548
- 0.0
- 0.179
- 0.015
- 0.235
- 0.635
- 0.802
- 0.015
- 0.017
- 0.006
- 0.35
- 0.86
- 0.281
- 0.302
- 0.25
- 0.183
- 0.758
- 0.142
- 0.052
- 0.556
- 0.017
- 0.85
- 0.681
- 0.571
- 0.002
- 0.446
- 0.798
- 0.102
- 0.727
- 0.629
- 0.015
- 0.227
- 0.008
- 0.465
- 0.458
- 0.204
train_loss:
- 1.921
- 1.303
- 1.579
- 0.605
- 1.247
- 1.494
- 0.888
- 1.138
- 0.985
- 0.764
- 0.933
- 1.087
- 0.922
- 1.036
- 0.664
- 0.674
- 0.621
- 0.789
- 0.81
- 0.783
- 0.577
- 0.546
- 0.736
- 0.544
- 0.555
- 0.902
- 0.693
- 0.552
- 0.544
- 0.667
- 0.499
- 0.676
- 0.66
- 0.659
- 0.639
- 0.652
- 0.606
- 0.333
- 0.466
- 0.463
- 0.594
- 0.319
- 0.615
- 0.583
- 0.432
- 0.603
- 0.608
- 0.467
- 0.298
- 0.621
- 0.423
- 0.593
- 0.297
- 0.614
- 0.568
- 0.441
- 0.415
- 0.43
- 0.563
- 0.565
- 0.542
- 0.421
- 0.55
- 0.551
- 0.388
- 0.575
- 0.383
- 0.56
- 0.287
- 0.406
- 0.531
- 0.54
- 0.637
- 0.514
- 0.395
- 0.409
- 0.381
- 0.373
- 0.534
- 0.517
- 0.518
- 0.513
- 0.521
- 0.372
- 0.378
- 0.623
- 0.386
- 0.376
- 0.616
- 0.371
- 0.355
- 0.531
- 0.343
- 0.361
- 0.472
- 0.223
- 0.631
- 0.406
- 0.36
- 0.464
unequal: 0
verbose: 1
