avg_train_accuracy: 0.315
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06904255319148936
- 0.07037234042553192
- 0.12170212765957447
- 0.15329787234042552
- 0.12489361702127659
- 0.21127659574468086
- 0.19537234042553192
- 0.2602659574468085
- 0.25803191489361704
- 0.28154255319148935
- 0.29819148936170214
- 0.2920744680851064
- 0.32441489361702125
- 0.33622340425531916
- 0.3528191489361702
- 0.36861702127659574
- 0.334468085106383
- 0.3728723404255319
- 0.3439893617021277
- 0.361436170212766
- 0.38430851063829785
- 0.38803191489361705
- 0.3670744680851064
- 0.3771808510638298
- 0.38170212765957445
- 0.40414893617021275
- 0.3743085106382979
- 0.4032978723404255
- 0.38053191489361704
- 0.3827659574468085
- 0.413031914893617
- 0.44361702127659575
- 0.44335106382978723
- 0.45409574468085107
- 0.43292553191489364
- 0.43111702127659574
- 0.43803191489361704
- 0.4183510638297872
- 0.47
- 0.40712765957446806
- 0.4142021276595745
- 0.475531914893617
- 0.4706382978723404
- 0.43207446808510636
- 0.40324468085106385
- 0.4323404255319149
- 0.44207446808510636
- 0.4282446808510638
- 0.43420212765957444
- 0.5009574468085106
- 0.44388297872340426
- 0.4944148936170213
- 0.44707446808510637
- 0.47345744680851065
- 0.5000531914893617
- 0.47074468085106386
- 0.5096808510638298
- 0.5094148936170213
- 0.46414893617021274
- 0.5235106382978724
- 0.4804255319148936
- 0.515904255319149
- 0.49531914893617024
- 0.5055851063829787
- 0.465531914893617
- 0.5085106382978724
- 0.5110638297872341
- 0.5329787234042553
- 0.4815957446808511
- 0.48223404255319147
- 0.41702127659574467
- 0.5436170212765957
- 0.5492553191489362
- 0.5332978723404256
- 0.5317553191489361
- 0.4946808510638298
- 0.5386702127659575
- 0.4833510638297872
- 0.5197340425531914
- 0.5334574468085106
- 0.5042553191489362
- 0.4778191489361702
- 0.5213297872340426
- 0.5077127659574469
- 0.5163297872340425
- 0.5623936170212765
- 0.5013297872340425
- 0.5246808510638298
- 0.5151595744680851
- 0.5336702127659575
- 0.5562234042553191
- 0.5647340425531915
- 0.5300531914893617
- 0.566595744680851
- 0.5789893617021277
- 0.5723404255319149
- 0.5173404255319148
- 0.5674468085106383
- 0.5519148936170213
- 0.5585106382978723
test_loss_list:
- 3.8889372730255127
- 3.7556716855367025
- 3.4562582047780355
- 3.3033400122324625
- 3.3613154538472494
- 3.0509084987640382
- 3.0311448764801026
- 2.8731077512105307
- 2.8809412129720053
- 3.012633171081543
- 2.8408039379119874
- 2.815823596318563
- 2.6228325366973877
- 2.5751840400695802
- 2.461170914967855
- 2.468070430755615
- 2.490518706639608
- 2.338553997675578
- 2.357919708887736
- 2.5066766007741292
- 2.2870178254445395
- 2.272855304082235
- 2.3222146701812743
- 2.2855309104919432
- 2.3483653672536215
- 2.162183709144592
- 2.305843499501546
- 2.3393119653066
- 2.2187887318929036
- 2.347907018661499
- 2.110323297182719
- 2.0367513863245645
- 2.1007944250106814
- 2.0156768465042116
- 2.0186071729660036
- 2.0509145784378053
- 2.0255198256174722
- 2.0289100392659507
- 1.8760647757848103
- 2.120364899635315
- 2.121863668759664
- 1.834557941754659
- 1.8313225587209065
- 2.0543649005889892
- 2.17737363020579
- 2.0892025947570803
- 1.9557095702489218
- 2.0999360497792563
- 2.022225046157837
- 1.726315401395162
- 1.9987016836802165
- 1.7691366815567016
- 1.932466788291931
- 1.9329193878173827
- 1.7096371491750082
- 1.8147193225224814
- 1.742074286142985
- 1.737099151611328
- 1.8834152857462565
- 1.7272270218531292
- 1.7606228876113892
- 1.7580006233851115
- 1.9060869487126668
- 1.675625901222229
- 1.8478434912363688
- 1.8575092347462971
- 1.7018468729654948
- 1.6368726380666097
- 1.8200118398666383
- 1.9176472314198811
- 2.221222298940023
- 1.5446252171198527
- 1.5272890996932984
- 1.5726991430918376
- 1.6001805750528972
- 1.7315932814280193
- 1.59974089940389
- 1.755361811319987
- 1.6919306627909343
- 1.6375761461257934
- 1.700561243693034
- 1.8367521858215332
- 1.704372189839681
- 1.697559831937154
- 1.613944665590922
- 1.5574250094095865
- 1.701590116818746
- 1.7421111567815144
- 1.6433687114715576
- 1.6265232372283935
- 1.5119466511408488
- 1.4691791041692097
- 1.7375492715835572
- 1.4386698039372763
- 1.404718526204427
- 1.4093218119939168
- 1.64395059744517
- 1.4192209800084432
- 1.5050433047612508
- 1.5164510822296142
train_accuracy:
- 0.0
- 0.002
- 0.048
- 0.004
- 0.0
- 0.275
- 0.383
- 0.0
- 0.0
- 0.523
- 0.058
- 0.002
- 0.073
- 0.496
- 0.0
- 0.546
- 0.027
- 0.006
- 0.081
- 0.698
- 0.517
- 0.335
- 0.031
- 0.017
- 0.083
- 0.56
- 0.025
- 0.227
- 0.471
- 0.025
- 0.092
- 0.242
- 0.169
- 0.11
- 0.529
- 0.008
- 0.015
- 0.023
- 0.285
- 0.225
- 0.008
- 0.579
- 0.077
- 0.085
- 0.281
- 0.052
- 0.242
- 0.042
- 0.175
- 0.596
- 0.727
- 0.367
- 0.158
- 0.129
- 0.273
- 0.273
- 0.41
- 0.375
- 0.227
- 0.431
- 0.59
- 0.231
- 0.771
- 0.231
- 0.756
- 0.325
- 0.196
- 0.369
- 0.29
- 0.01
- 0.454
- 0.067
- 0.056
- 0.596
- 0.623
- 0.815
- 0.6
- 0.756
- 0.085
- 0.319
- 0.146
- 0.006
- 0.088
- 0.806
- 0.49
- 0.631
- 0.66
- 0.388
- 0.269
- 0.002
- 0.525
- 0.692
- 0.3
- 0.642
- 0.033
- 0.31
- 0.202
- 0.306
- 0.335
- 0.315
train_loss:
- 2.018
- 1.193
- 1.285
- 1.146
- 0.557
- 1.027
- 0.952
- 0.9
- 0.878
- 1.067
- 0.994
- 0.993
- 0.781
- 0.761
- 0.739
- 0.717
- 0.734
- 0.71
- 0.692
- 0.836
- 0.677
- 0.66
- 0.673
- 0.685
- 0.797
- 0.647
- 0.776
- 0.79
- 0.628
- 0.764
- 0.62
- 0.603
- 0.595
- 0.591
- 0.57
- 0.59
- 0.578
- 0.44
- 0.581
- 0.433
- 0.725
- 0.568
- 0.541
- 0.669
- 0.426
- 0.694
- 0.546
- 0.684
- 0.418
- 0.525
- 0.649
- 0.523
- 0.628
- 0.625
- 0.519
- 0.4
- 0.522
- 0.49
- 0.388
- 0.508
- 0.506
- 0.498
- 0.596
- 0.507
- 0.612
- 0.587
- 0.488
- 0.478
- 0.372
- 0.599
- 0.266
- 0.486
- 0.455
- 0.477
- 0.465
- 0.589
- 0.455
- 0.55
- 0.544
- 0.443
- 0.347
- 0.565
- 0.535
- 0.574
- 0.35
- 0.428
- 0.344
- 0.537
- 0.545
- 0.529
- 0.415
- 0.442
- 0.538
- 0.445
- 0.428
- 0.431
- 0.531
- 0.426
- 0.328
- 0.328
unequal: 0
verbose: 1
