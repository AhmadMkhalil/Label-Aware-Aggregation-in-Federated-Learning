avg_train_accuracy: 0.74
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04670212765957447
- 0.08037234042553192
- 0.10154255319148936
- 0.16553191489361702
- 0.13590425531914893
- 0.1322340425531915
- 0.2302127659574468
- 0.273031914893617
- 0.24569148936170213
- 0.28691489361702127
- 0.2928191489361702
- 0.3074468085106383
- 0.2393617021276596
- 0.32526595744680853
- 0.28877659574468084
- 0.34074468085106385
- 0.3255851063829787
- 0.33489361702127657
- 0.33627659574468083
- 0.3544148936170213
- 0.34829787234042553
- 0.3649468085106383
- 0.3625531914893617
- 0.38851063829787236
- 0.37292553191489364
- 0.37244680851063827
- 0.3866489361702128
- 0.3886702127659574
- 0.418031914893617
- 0.43042553191489363
- 0.401968085106383
- 0.43101063829787234
- 0.46941489361702127
- 0.478031914893617
- 0.47388297872340424
- 0.42186170212765955
- 0.47132978723404256
- 0.399468085106383
- 0.4817021276595745
- 0.41840425531914893
- 0.48398936170212764
- 0.4319148936170213
- 0.47058510638297874
- 0.4371808510638298
- 0.49398936170212765
- 0.43638297872340426
- 0.4796808510638298
- 0.5081382978723404
- 0.47393617021276596
- 0.459468085106383
- 0.4858510638297872
- 0.4983510638297872
- 0.47904255319148936
- 0.529468085106383
- 0.5209574468085106
- 0.5340425531914894
- 0.5281914893617021
- 0.48686170212765956
- 0.5007446808510638
- 0.5092553191489362
- 0.47867021276595745
- 0.5559042553191489
- 0.5400531914893617
- 0.5390957446808511
- 0.5370212765957447
- 0.5265425531914893
- 0.5532978723404255
- 0.5168085106382979
- 0.5291489361702127
- 0.5748936170212766
- 0.5682978723404255
- 0.5376063829787234
- 0.5107978723404255
- 0.5426595744680851
- 0.5613829787234043
- 0.509468085106383
- 0.5261170212765958
- 0.5295744680851063
- 0.5295744680851063
- 0.5470744680851064
- 0.518031914893617
- 0.5855851063829787
- 0.5162234042553191
- 0.5418617021276596
- 0.5153191489361703
- 0.5260106382978723
- 0.5747340425531915
- 0.5662234042553191
- 0.5678191489361702
- 0.5706914893617021
- 0.5523404255319149
- 0.5181382978723404
- 0.5426063829787234
- 0.5104255319148936
- 0.5545744680851064
- 0.5473936170212766
- 0.5776595744680851
- 0.5380851063829787
- 0.5787234042553191
- 0.5834574468085106
test_loss_list:
- 3.88091867129008
- 3.773447233835856
- 3.457624921798706
- 3.3683824284871418
- 3.494704399108887
- 3.2097200266520183
- 3.1885654671986896
- 3.012511568069458
- 2.8956302420298257
- 2.856364898681641
- 2.7132594998677573
- 2.667463525136312
- 2.7930498790740965
- 2.832605708440145
- 2.584026616414388
- 2.5656718826293945
- 2.4329796632130942
- 2.7093291600545246
- 2.5296303749084474
- 2.43899627049764
- 2.558136819203695
- 2.600574951171875
- 2.5371097564697265
- 2.4348001035054523
- 2.4423182169596354
- 2.4388799381256105
- 2.1349703661600747
- 2.473583567937215
- 2.107519578933716
- 2.0855827887852985
- 2.089373124440511
- 2.016273323694865
- 1.9084090121587118
- 1.8792586517333985
- 1.873159769376119
- 2.265334637959798
- 1.864730798403422
- 2.270124258995056
- 1.8274007749557495
- 2.212845788002014
- 1.8556145556767782
- 2.155763589541117
- 1.8227001428604126
- 2.106214493115743
- 1.7115733814239502
- 2.189580419858297
- 1.7526501242319743
- 1.7289782079060871
- 1.7757815678914388
- 1.9080530961354574
- 1.8719661982854208
- 1.7098926242192587
- 1.9297763601938884
- 1.6181360880533855
- 1.637676887512207
- 1.6408432896931966
- 1.6353658517201741
- 1.8188580910364787
- 1.838697420756022
- 1.624497013092041
- 1.8404172484079997
- 1.511231598854065
- 1.5631312735875447
- 1.5952883259455364
- 1.5812678400675455
- 1.6098219537734986
- 1.526457848548889
- 1.5617432641983031
- 1.5255414819717408
- 1.4724267037709553
- 1.4517219765981038
- 1.4936667935053507
- 1.7199593257904053
- 1.5160545444488525
- 1.4648594458897908
- 1.753662257194519
- 1.5310665782292683
- 1.6465062284469605
- 1.6622392988204957
- 1.5068689711888632
- 1.7483893426259358
- 1.3931142282485962
- 1.7220962413152059
- 1.5825602769851685
- 1.7128761291503907
- 1.6659072224299114
- 1.4551353391011557
- 1.4292589712142945
- 1.4575547981262207
- 1.4730991808573406
- 1.453758864402771
- 1.7225996414820353
- 1.51224689801534
- 1.6486819426218668
- 1.4210897858937581
- 1.572015560468038
- 1.38485977490743
- 1.6144901164372762
- 1.3585019906361897
- 1.379650405248006
train_accuracy:
- 0.0
- 0.263
- 0.0
- 0.337
- 0.0
- 0.115
- 0.0
- 0.542
- 0.281
- 0.01
- 0.1
- 0.527
- 0.0
- 0.683
- 0.244
- 0.0
- 0.198
- 0.002
- 0.0
- 0.404
- 0.015
- 0.625
- 0.721
- 0.033
- 0.708
- 0.002
- 0.031
- 0.079
- 0.598
- 0.662
- 0.173
- 0.644
- 0.183
- 0.665
- 0.373
- 0.0
- 0.077
- 0.019
- 0.092
- 0.075
- 0.402
- 0.75
- 0.269
- 0.735
- 0.104
- 0.04
- 0.329
- 0.052
- 0.442
- 0.006
- 0.796
- 0.188
- 0.221
- 0.042
- 0.388
- 0.096
- 0.24
- 0.275
- 0.075
- 0.26
- 0.004
- 0.373
- 0.115
- 0.652
- 0.179
- 0.654
- 0.002
- 0.113
- 0.042
- 0.217
- 0.446
- 0.46
- 0.798
- 0.206
- 0.185
- 0.829
- 0.071
- 0.802
- 0.115
- 0.331
- 0.821
- 0.706
- 0.804
- 0.208
- 0.223
- 0.227
- 0.688
- 0.071
- 0.185
- 0.7
- 0.204
- 0.812
- 0.458
- 0.625
- 0.61
- 0.244
- 0.171
- 0.817
- 0.288
- 0.74
train_loss:
- 2.158
- 1.259
- 1.336
- 1.487
- 0.635
- 0.825
- 1.232
- 1.171
- 0.893
- 0.884
- 0.825
- 0.817
- 0.642
- 0.96
- 0.62
- 0.792
- 0.564
- 0.922
- 0.893
- 0.711
- 0.862
- 0.847
- 0.809
- 0.81
- 0.795
- 0.786
- 0.513
- 0.736
- 0.619
- 0.611
- 0.479
- 0.596
- 0.579
- 0.589
- 0.562
- 0.687
- 0.59
- 0.681
- 0.552
- 0.676
- 0.555
- 0.654
- 0.539
- 0.67
- 0.416
- 0.622
- 0.405
- 0.508
- 0.417
- 0.649
- 0.618
- 0.511
- 0.628
- 0.501
- 0.513
- 0.499
- 0.498
- 0.597
- 0.582
- 0.369
- 0.604
- 0.494
- 0.476
- 0.486
- 0.474
- 0.473
- 0.455
- 0.359
- 0.361
- 0.456
- 0.448
- 0.357
- 0.561
- 0.443
- 0.44
- 0.528
- 0.365
- 0.567
- 0.539
- 0.454
- 0.547
- 0.435
- 0.538
- 0.546
- 0.536
- 0.517
- 0.42
- 0.441
- 0.424
- 0.418
- 0.328
- 0.518
- 0.338
- 0.227
- 0.311
- 0.507
- 0.428
- 0.505
- 0.431
- 0.415
unequal: 0
verbose: 1
