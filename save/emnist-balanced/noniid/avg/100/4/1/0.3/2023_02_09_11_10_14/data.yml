avg_train_accuracy: 0.823
avg_train_loss: 0.011
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05372340425531915
- 0.057180851063829786
- 0.07776595744680852
- 0.2078723404255319
- 0.3303191489361702
- 0.4325
- 0.48659574468085104
- 0.5234574468085106
- 0.5475
- 0.5715425531914894
- 0.5018617021276596
- 0.597872340425532
- 0.6117021276595744
- 0.6196808510638298
- 0.6281914893617021
- 0.6397872340425532
- 0.5629787234042554
- 0.5844680851063829
- 0.6546276595744681
- 0.6026063829787234
- 0.6628723404255319
- 0.6681914893617021
- 0.6690957446808511
- 0.6748404255319149
- 0.6787234042553192
- 0.6822872340425532
- 0.6868617021276596
- 0.635
- 0.6911170212765958
- 0.6924468085106383
- 0.6952127659574469
- 0.6980851063829787
- 0.7016489361702127
- 0.7028723404255319
- 0.7029255319148936
- 0.7057446808510638
- 0.6627659574468086
- 0.6766489361702127
- 0.7059574468085107
- 0.7108510638297872
- 0.6745212765957447
- 0.7137234042553191
- 0.7136170212765958
- 0.7153191489361702
- 0.718936170212766
- 0.7207446808510638
- 0.7207446808510638
- 0.6839893617021277
- 0.7242553191489361
- 0.7227659574468085
- 0.6982446808510638
- 0.7227127659574468
- 0.7244148936170213
- 0.7264893617021276
- 0.7052127659574469
- 0.7079255319148936
- 0.7140425531914893
- 0.7175531914893617
- 0.73
- 0.7293617021276596
- 0.7323404255319149
- 0.7313829787234043
- 0.7336702127659575
- 0.7345744680851064
- 0.735531914893617
- 0.7362765957446809
- 0.7178191489361702
- 0.7372872340425531
- 0.7394148936170213
- 0.7362765957446809
- 0.7387765957446808
- 0.7368617021276596
- 0.7375
- 0.7421808510638298
- 0.7375531914893617
- 0.7420744680851064
- 0.737872340425532
- 0.7200531914893618
- 0.7418617021276596
- 0.7418617021276596
- 0.7407978723404255
- 0.7417553191489362
- 0.7413297872340425
- 0.7275
- 0.7443085106382978
- 0.7445744680851064
- 0.7397340425531915
- 0.7367021276595744
- 0.7384574468085107
- 0.742872340425532
- 0.7454787234042554
- 0.7456382978723404
- 0.7409574468085106
- 0.7455851063829787
- 0.7428191489361702
- 0.7439893617021277
- 0.7458510638297873
- 0.7447872340425532
- 0.7477127659574468
- 0.7481914893617021
test_loss_list:
- 3.8091707102457684
- 3.73765243212382
- 3.631143751144409
- 3.3573034795125327
- 2.9471070353190103
- 2.549055986404419
- 2.30694540977478
- 2.155730818112691
- 2.040846376419067
- 1.9674160051345826
- 1.845687796274821
- 1.7641236384709675
- 1.7486313358942667
- 1.731013790766398
- 1.7204355478286744
- 1.7176987632115681
- 1.5352650356292725
- 1.398011825879415
- 1.4773115650812785
- 1.3683996677398682
- 1.4094301176071167
- 1.4473839982350667
- 1.4786144193013508
- 1.4778767093022664
- 1.4798042345046998
- 1.494957750638326
- 1.491892549196879
- 1.19932404200236
- 1.3586195611953735
- 1.3848732248942057
- 1.404608718554179
- 1.4323773574829102
- 1.4191862805684408
- 1.4457697757085164
- 1.4513825066884358
- 1.4711829312642415
- 1.0825560275713604
- 1.0281466778119406
- 1.2501116927464804
- 1.2821060625712077
- 1.0376816534996032
- 1.2235085805257162
- 1.2669841623306275
- 1.2989449691772461
- 1.3165242417653402
- 1.3295978450775146
- 1.3563299560546875
- 0.9820880707105001
- 1.2091181484858196
- 1.249367396036784
- 0.9527685062090556
- 1.1696353244781494
- 1.2169978713989258
- 1.2507572555541993
- 0.9297460810343424
- 0.8962076409657797
- 0.8830600261688233
- 0.8743707855542501
- 1.1036055572827657
- 1.152370924949646
- 1.1816208942731221
- 1.2286561012268067
- 1.2239395801226298
- 1.2503045264879862
- 1.2621437009175618
- 1.2847110255559286
- 0.8735097750027975
- 1.1209167702992757
- 1.1665567350387573
- 1.1976251157124838
- 1.2275992266337077
- 1.2407733750343324
- 1.2487186479568482
- 1.2664284666379293
- 1.27654887676239
- 1.2821696265538534
- 1.3147225062052408
- 0.8644753774007161
- 1.125859903494517
- 1.147754068374634
- 1.192487751642863
- 1.2156127127011618
- 1.2396919004122415
- 0.830833515326182
- 1.1000465337435406
- 1.121959884961446
- 1.170313900311788
- 0.8171136506398519
- 0.786416056950887
- 1.0255467263857523
- 1.081834545135498
- 1.1080421606699626
- 0.7987301357587179
- 0.7783081110318502
- 1.01652548233668
- 1.0724284934997559
- 0.7909107073148092
- 1.0177552461624146
- 1.070423493385315
- 1.0985733588536581
train_accuracy:
- 0.0
- 0.058
- 0.079
- 0.252
- 0.352
- 0.473
- 0.548
- 0.585
- 0.602
- 0.648
- 0.542
- 0.669
- 0.66
- 0.71
- 0.698
- 0.715
- 0.606
- 0.579
- 0.74
- 0.379
- 0.735
- 0.767
- 0.729
- 0.771
- 0.756
- 0.773
- 0.769
- 0.65
- 0.771
- 0.765
- 0.781
- 0.783
- 0.781
- 0.779
- 0.777
- 0.779
- 0.673
- 0.229
- 0.775
- 0.775
- 0.671
- 0.779
- 0.775
- 0.806
- 0.804
- 0.808
- 0.794
- 0.746
- 0.802
- 0.823
- 0.679
- 0.798
- 0.815
- 0.802
- 0.74
- 0.454
- 0.708
- 0.662
- 0.81
- 0.79
- 0.806
- 0.81
- 0.79
- 0.804
- 0.817
- 0.802
- 0.758
- 0.819
- 0.802
- 0.819
- 0.825
- 0.8
- 0.8
- 0.823
- 0.825
- 0.817
- 0.804
- 0.183
- 0.808
- 0.81
- 0.806
- 0.815
- 0.819
- 0.75
- 0.806
- 0.802
- 0.827
- 0.729
- 0.76
- 0.827
- 0.823
- 0.821
- 0.51
- 0.725
- 0.819
- 0.806
- 0.748
- 0.825
- 0.808
- 0.823
train_loss:
- 3.061
- 3.837
- 3.76
- 3.605
- 3.327
- 2.972
- 2.689
- 2.48
- 2.315
- 2.188
- 1.675
- 2.066
- 1.95
- 1.903
- 1.83
- 1.8
- 1.381
- 1.275
- 1.71
- 1.259
- 1.669
- 1.615
- 1.577
- 1.582
- 1.553
- 1.506
- 1.501
- 1.166
- 1.504
- 1.468
- 1.43
- 1.447
- 1.434
- 1.408
- 1.385
- 1.361
- 1.068
- 1.004
- 1.368
- 1.33
- 1.047
- 1.371
- 1.317
- 1.332
- 1.321
- 1.305
- 1.306
- 1.013
- 1.325
- 1.283
- 0.976
- 1.281
- 1.255
- 1.263
- 0.962
- 0.932
- 0.916
- 0.895
- 1.268
- 1.247
- 1.222
- 1.237
- 1.209
- 1.215
- 1.209
- 1.21
- 0.942
- 1.203
- 1.194
- 1.179
- 1.168
- 1.168
- 1.191
- 1.173
- 1.179
- 1.162
- 1.171
- 0.928
- 1.167
- 1.144
- 1.144
- 1.126
- 1.139
- 0.897
- 1.152
- 1.133
- 1.141
- 0.893
- 0.836
- 1.138
- 1.119
- 1.129
- 0.858
- 0.821
- 1.135
- 1.107
- 0.844
- 1.114
- 1.113
- 1.111
unequal: 0
verbose: 1
