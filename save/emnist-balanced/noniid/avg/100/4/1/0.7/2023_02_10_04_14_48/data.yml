avg_train_accuracy: 0.827
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026382978723404255
- 0.04521276595744681
- 0.11654255319148936
- 0.2378723404255319
- 0.3924468085106383
- 0.4326063829787234
- 0.5083510638297872
- 0.5354787234042553
- 0.5331914893617021
- 0.5722340425531914
- 0.5704787234042553
- 0.5793085106382979
- 0.59
- 0.6132978723404255
- 0.6243617021276596
- 0.6186170212765958
- 0.6262765957446809
- 0.6356914893617022
- 0.6406914893617022
- 0.6520744680851064
- 0.6517021276595745
- 0.6561170212765958
- 0.6617553191489361
- 0.6652659574468085
- 0.6721276595744681
- 0.6761702127659575
- 0.675159574468085
- 0.6845744680851064
- 0.683031914893617
- 0.6937234042553192
- 0.6887765957446809
- 0.695531914893617
- 0.6991489361702128
- 0.6994148936170212
- 0.6975
- 0.7015425531914894
- 0.7055851063829788
- 0.7079255319148936
- 0.708031914893617
- 0.7108510638297872
- 0.7135106382978723
- 0.7156914893617021
- 0.7178191489361702
- 0.718404255319149
- 0.7182446808510639
- 0.7188829787234042
- 0.7203723404255319
- 0.7219148936170213
- 0.7247340425531915
- 0.7261170212765957
- 0.7229787234042553
- 0.7268617021276595
- 0.7303723404255319
- 0.73
- 0.7275531914893617
- 0.7313297872340425
- 0.7331914893617021
- 0.7361170212765957
- 0.7293617021276596
- 0.7355851063829787
- 0.737872340425532
- 0.7375531914893617
- 0.739468085106383
- 0.7406914893617021
- 0.7348404255319149
- 0.737872340425532
- 0.7401063829787234
- 0.7368617021276596
- 0.7407978723404255
- 0.7402127659574468
- 0.7369148936170212
- 0.7378191489361702
- 0.7387234042553191
- 0.7393085106382978
- 0.7386170212765958
- 0.7412234042553192
- 0.742872340425532
- 0.7443085106382978
- 0.7405851063829787
- 0.7438829787234043
- 0.7458510638297873
- 0.7403723404255319
- 0.743563829787234
- 0.7452659574468085
- 0.7468617021276596
- 0.7476063829787234
- 0.7447340425531915
- 0.7465425531914893
- 0.7482978723404256
- 0.7450531914893617
- 0.7486702127659575
- 0.7504787234042554
- 0.7449468085106383
- 0.7503723404255319
- 0.7471808510638298
- 0.7510106382978723
- 0.7534042553191489
- 0.7538297872340426
- 0.7483510638297872
- 0.7530851063829788
test_loss_list:
- 3.7754853916168214
- 3.7284514331817626
- 3.577792584101359
- 3.186520160039266
- 2.8347455088297524
- 2.4934684944152834
- 2.2992667229970296
- 2.1790550915400186
- 2.0013068087895713
- 1.979679191907247
- 1.837599507967631
- 1.7310743236541748
- 1.65655770778656
- 1.7556473286946614
- 1.7525619538625081
- 1.572565466562907
- 1.5075837071736653
- 1.4552663866678874
- 1.4101005442937216
- 1.5706944640477498
- 1.3886264451344807
- 1.3444586372375489
- 1.3005370426177978
- 1.2736437733968098
- 1.450385030110677
- 1.4800849850972493
- 1.262610026995341
- 1.438574636777242
- 1.2344501606623333
- 1.4161786619822185
- 1.2064388020833334
- 1.3822242673238119
- 1.4040130345026651
- 1.426223341623942
- 1.1944357093175253
- 1.147224071820577
- 1.1102488080660502
- 1.3044357585906983
- 1.0921548016866047
- 1.0787020913759868
- 1.0534635361035665
- 1.0377168941497803
- 1.0171579384803773
- 1.0154594389597575
- 1.2285795942942301
- 1.0252923194567363
- 1.016337543328603
- 0.9897580663363139
- 0.9800809653600057
- 0.970229750474294
- 1.163902668952942
- 0.9770219031969706
- 0.9598960598309835
- 0.9460611565907796
- 1.1394396328926086
- 0.951291921933492
- 0.9389206608136494
- 0.9276910273234049
- 1.1345365031560262
- 0.9314177401860555
- 0.9187891697883606
- 0.9063514351844788
- 0.902860852877299
- 0.8834320783615113
- 1.0928337597846984
- 0.9064749805132548
- 0.8955741477012634
- 1.084711452325185
- 0.892341152826945
- 0.8872670992215475
- 1.0787561774253844
- 1.1195609919230143
- 1.1463234496116639
- 0.9324087595939636
- 1.102795569896698
- 0.9028926388422648
- 0.8752491998672486
- 0.8601552168528239
- 1.0616753959655763
- 0.864510002930959
- 0.8492917577425639
- 1.042155605951945
- 1.075816171169281
- 0.8754762148857117
- 0.8525107781092326
- 0.8298512061436971
- 1.030033373037974
- 0.8464872654279073
- 0.8303258140881856
- 1.0207409071922302
- 0.8370384947458903
- 0.8221144739786784
- 1.0179111893971762
- 0.8312917311986288
- 1.0106195131937663
- 0.831056588490804
- 0.8093869169553121
- 0.8036290550231934
- 0.9966251579920451
- 0.8120416355133057
train_accuracy:
- 0.0
- 0.035
- 0.115
- 0.285
- 0.4
- 0.485
- 0.546
- 0.638
- 0.598
- 0.631
- 0.673
- 0.642
- 0.696
- 0.675
- 0.688
- 0.694
- 0.731
- 0.0
- 0.702
- 0.769
- 0.706
- 0.71
- 0.7
- 0.727
- 0.748
- 0.765
- 0.777
- 0.804
- 0.0
- 0.76
- 0.779
- 0.779
- 0.763
- 0.802
- 0.771
- 0.769
- 0.763
- 0.8
- 0.819
- 0.002
- 0.821
- 0.8
- 0.806
- 0.81
- 0.802
- 0.808
- 0.796
- 0.812
- 0.802
- 0.81
- 0.815
- 0.808
- 0.796
- 0.792
- 0.792
- 0.806
- 0.815
- 0.802
- 0.812
- 0.004
- 0.844
- 0.808
- 0.808
- 0.025
- 0.806
- 0.817
- 0.85
- 0.838
- 0.006
- 0.815
- 0.819
- 0.831
- 0.838
- 0.798
- 0.831
- 0.798
- 0.004
- 0.812
- 0.815
- 0.817
- 0.84
- 0.81
- 0.844
- 0.842
- 0.815
- 0.821
- 0.831
- 0.833
- 0.806
- 0.871
- 0.838
- 0.842
- 0.823
- 0.848
- 0.825
- 0.819
- 0.821
- 0.819
- 0.825
- 0.827
train_loss:
- 3.476
- 3.806
- 3.719
- 3.161
- 3.212
- 2.588
- 2.658
- 2.457
- 2.074
- 2.194
- 1.908
- 1.811
- 1.769
- 1.934
- 1.86
- 1.647
- 1.603
- 1.562
- 1.544
- 1.701
- 1.49
- 1.462
- 1.456
- 1.43
- 1.585
- 1.554
- 1.393
- 1.517
- 1.36
- 1.489
- 1.322
- 1.464
- 1.448
- 1.41
- 1.28
- 1.25
- 1.244
- 1.382
- 1.233
- 1.226
- 1.218
- 1.2
- 1.187
- 1.18
- 1.316
- 1.18
- 1.169
- 1.157
- 1.158
- 1.146
- 1.288
- 1.142
- 1.136
- 1.127
- 1.266
- 1.11
- 1.108
- 1.108
- 1.238
- 1.108
- 1.082
- 1.084
- 1.081
- 1.068
- 1.204
- 1.065
- 1.057
- 1.191
- 1.07
- 1.041
- 1.186
- 1.177
- 1.188
- 1.036
- 1.172
- 1.045
- 1.041
- 1.018
- 1.164
- 1.023
- 1.018
- 1.152
- 1.151
- 1.028
- 1.018
- 1.009
- 1.141
- 0.995
- 0.994
- 1.14
- 0.994
- 0.999
- 1.119
- 0.996
- 1.126
- 1.0
- 0.99
- 0.981
- 1.121
- 0.983
unequal: 0
verbose: 1
