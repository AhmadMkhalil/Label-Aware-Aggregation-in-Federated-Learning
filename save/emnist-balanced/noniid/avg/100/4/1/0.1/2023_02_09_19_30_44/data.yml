avg_train_accuracy: 0.773
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033829787234042556
- 0.062127659574468086
- 0.0675
- 0.11319148936170213
- 0.23861702127659573
- 0.3096808510638298
- 0.38335106382978723
- 0.4330851063829787
- 0.4723404255319149
- 0.5026063829787234
- 0.5297340425531915
- 0.5508510638297872
- 0.5594148936170212
- 0.5654787234042553
- 0.5823404255319149
- 0.5873936170212766
- 0.6025
- 0.6071276595744681
- 0.6146276595744681
- 0.6197872340425532
- 0.6262234042553192
- 0.6254787234042554
- 0.6388829787234043
- 0.6427659574468085
- 0.6489893617021276
- 0.6510638297872341
- 0.6583510638297873
- 0.6630851063829787
- 0.666063829787234
- 0.6622872340425532
- 0.6722340425531915
- 0.6782978723404255
- 0.6773404255319149
- 0.08303191489361703
- 0.6747872340425531
- 0.674468085106383
- 0.6834574468085106
- 0.11478723404255319
- 0.6811170212765958
- 0.6818085106382978
- 0.6831914893617022
- 0.6891489361702128
- 0.6895744680851064
- 0.6931914893617022
- 0.6951063829787234
- 0.1472340425531915
- 0.693404255319149
- 0.6984574468085106
- 0.699840425531915
- 0.6954787234042553
- 0.7018085106382979
- 0.7047872340425532
- 0.7054787234042553
- 0.7032446808510638
- 0.7076063829787234
- 0.7085638297872341
- 0.7088829787234042
- 0.7085106382978723
- 0.7127659574468085
- 0.1747340425531915
- 0.7125
- 0.7117021276595744
- 0.7161702127659575
- 0.715531914893617
- 0.7153191489361702
- 0.7185106382978723
- 0.23882978723404255
- 0.7225
- 0.7196808510638298
- 0.7174468085106382
- 0.7148404255319148
- 0.2724468085106383
- 0.7223936170212766
- 0.7172340425531915
- 0.7240425531914894
- 0.721968085106383
- 0.7203723404255319
- 0.7256914893617021
- 0.2653723404255319
- 0.7294148936170213
- 0.7197340425531915
- 0.7243617021276596
- 0.7247340425531915
- 0.7209042553191489
- 0.7229787234042553
- 0.726063829787234
- 0.7268617021276595
- 0.7286702127659574
- 0.725
- 0.7246808510638297
- 0.7298404255319149
- 0.7303723404255319
- 0.7282978723404255
- 0.7318085106382979
- 0.729468085106383
- 0.73
- 0.7273404255319149
- 0.7301063829787234
- 0.7315425531914893
- 0.7247340425531915
test_loss_list:
- 3.787366778055827
- 14.077978375752767
- 3.722870299021403
- 3.5724158763885496
- 3.222411972681681
- 2.8734889221191406
- 2.6147234439849854
- 2.447506475448608
- 2.295334971745809
- 2.1953527386983236
- 2.1195919291178384
- 2.052562322616577
- 2.01549955368042
- 1.9802036841710409
- 1.95324720064799
- 1.9554567639033
- 1.896679768562317
- 1.891249443689982
- 1.8667679309844971
- 1.8410474205017089
- 1.8198499949773153
- 1.834233120282491
- 1.7977887868881226
- 1.8182685279846191
- 1.8014906613032022
- 1.8117820199330648
- 1.7844259103139242
- 1.7793272829055786
- 1.7685378535588583
- 1.816324944496155
- 1.7731170749664307
- 1.7670813767115274
- 1.7679561440149942
- 11.821639238993328
- 1.3407730356852214
- 1.4054202445348103
- 1.4149535210927326
- 8.013800048828125
- 1.1629701606432596
- 1.233739005724589
- 1.2461213191350302
- 1.293257924715678
- 1.2991834704081218
- 1.3320480473836263
- 1.3558641624450685
- 6.4746150779724125
- 1.071892442703247
- 1.1165254743893942
- 1.1418276278177897
- 1.1848850949605305
- 1.1948019218444825
- 1.2045393753051759
- 1.2150446208318075
- 1.2452696212132772
- 1.248527503013611
- 1.2635047435760498
- 1.2742458327611288
- 1.2657606156667074
- 1.270885804494222
- 5.746435718536377
- 0.9825317589441935
- 1.0446668497721354
- 1.0782559688886006
- 1.1089416162172954
- 1.1281026188532512
- 1.1311580141385396
- 4.783361326853434
- 0.916496045589447
- 0.990769640604655
- 1.034171357154846
- 1.0533005976676941
- 4.409613593419393
- 0.9040324433644613
- 0.965293980439504
- 0.9982468668619792
- 1.0295449169476827
- 1.0515605489412942
- 1.0691498692830403
- 4.516072266896566
- 0.8914636381467184
- 0.9471914100646973
- 0.9899683062235515
- 1.00918807665507
- 1.0290911626815795
- 1.0671688199043274
- 1.090843985080719
- 1.0958101558685303
- 1.1103028782208761
- 1.1062552531560261
- 1.132526125907898
- 1.1299926082293192
- 1.1681196769078572
- 1.1816714445749918
- 1.162279388109843
- 1.18111448208491
- 1.1726511843999228
- 1.2092049876848856
- 1.203124885559082
- 1.2230050627390543
- 1.2028004431724548
train_accuracy:
- 0.023
- 0.008
- 0.021
- 0.135
- 0.263
- 0.333
- 0.394
- 0.452
- 0.54
- 0.546
- 0.56
- 0.583
- 0.619
- 0.575
- 0.619
- 0.625
- 0.66
- 0.662
- 0.665
- 0.65
- 0.683
- 0.675
- 0.729
- 0.681
- 0.702
- 0.698
- 0.719
- 0.725
- 0.725
- 0.698
- 0.756
- 0.752
- 0.731
- 0.894
- 0.727
- 0.737
- 0.779
- 0.904
- 0.735
- 0.737
- 0.752
- 0.775
- 0.752
- 0.767
- 0.775
- 0.923
- 0.767
- 0.752
- 0.763
- 0.744
- 0.8
- 0.746
- 0.796
- 0.796
- 0.796
- 0.798
- 0.777
- 0.758
- 0.798
- 0.929
- 0.777
- 0.775
- 0.783
- 0.777
- 0.792
- 0.804
- 0.938
- 0.781
- 0.79
- 0.798
- 0.769
- 0.946
- 0.785
- 0.756
- 0.81
- 0.819
- 0.81
- 0.785
- 0.95
- 0.79
- 0.798
- 0.779
- 0.815
- 0.819
- 0.785
- 0.796
- 0.817
- 0.787
- 0.831
- 0.823
- 0.808
- 0.81
- 0.817
- 0.833
- 0.823
- 0.808
- 0.821
- 0.802
- 0.802
- 0.773
train_loss:
- 3.853
- 1.903
- 4.02
- 3.77
- 3.571
- 3.259
- 2.97
- 2.727
- 2.597
- 2.485
- 2.361
- 2.245
- 2.196
- 2.123
- 2.133
- 2.035
- 1.962
- 1.929
- 1.914
- 1.841
- 1.815
- 1.791
- 1.732
- 1.726
- 1.762
- 1.718
- 1.687
- 1.642
- 1.635
- 1.614
- 1.555
- 1.59
- 1.582
- 0.94
- 1.966
- 1.536
- 1.503
- 0.558
- 1.841
- 1.494
- 1.524
- 1.482
- 1.472
- 1.427
- 1.381
- 0.52
- 1.688
- 1.415
- 1.375
- 1.42
- 1.382
- 1.429
- 1.338
- 1.303
- 1.387
- 1.358
- 1.325
- 1.34
- 1.323
- 0.536
- 1.56
- 1.273
- 1.36
- 1.281
- 1.292
- 1.255
- 0.447
- 1.493
- 1.281
- 1.251
- 1.293
- 0.375
- 1.444
- 1.279
- 1.256
- 1.247
- 1.197
- 1.232
- 0.4
- 1.414
- 1.25
- 1.214
- 1.207
- 1.198
- 1.194
- 1.199
- 1.229
- 1.171
- 1.186
- 1.126
- 1.251
- 1.168
- 1.189
- 1.185
- 1.166
- 1.144
- 1.133
- 1.143
- 1.162
- 1.196
unequal: 0
verbose: 1
