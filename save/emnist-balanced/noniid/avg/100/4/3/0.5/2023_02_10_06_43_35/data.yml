avg_train_accuracy: 0.85
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026542553191489363
- 0.11218085106382979
- 0.21675531914893617
- 0.3103191489361702
- 0.31627659574468087
- 0.3606382978723404
- 0.415531914893617
- 0.4297340425531915
- 0.4467553191489362
- 0.4057978723404255
- 0.4771808510638298
- 0.48898936170212765
- 0.5073936170212766
- 0.5006382978723404
- 0.46143617021276595
- 0.5166489361702128
- 0.5190957446808511
- 0.508031914893617
- 0.5461170212765958
- 0.5436170212765957
- 0.5264893617021277
- 0.5301595744680851
- 0.5520212765957446
- 0.5620212765957446
- 0.5320212765957447
- 0.5753191489361702
- 0.565
- 0.5712234042553191
- 0.5487234042553192
- 0.5807446808510638
- 0.5954255319148937
- 0.5715957446808511
- 0.5899468085106383
- 0.5956914893617021
- 0.5961170212765957
- 0.5979255319148936
- 0.5955851063829787
- 0.5926595744680851
- 0.5746808510638298
- 0.605531914893617
- 0.5858510638297872
- 0.5811702127659575
- 0.5827127659574468
- 0.5904255319148937
- 0.5881382978723404
- 0.5886702127659574
- 0.5933510638297872
- 0.5961702127659575
- 0.6217021276595744
- 0.6167021276595744
- 0.5972872340425532
- 0.627127659574468
- 0.6198404255319149
- 0.6060106382978724
- 0.6384042553191489
- 0.6301595744680851
- 0.6418617021276596
- 0.6133510638297872
- 0.6493085106382979
- 0.6027127659574468
- 0.655
- 0.6221276595744681
- 0.6251063829787235
- 0.6295744680851064
- 0.6472340425531915
- 0.6305851063829787
- 0.6484574468085106
- 0.6207978723404255
- 0.6297340425531915
- 0.6086702127659575
- 0.6103723404255319
- 0.6113829787234043
- 0.6184042553191489
- 0.616436170212766
- 0.6368617021276596
- 0.6173404255319149
- 0.6121276595744681
- 0.6364893617021277
- 0.6258510638297873
- 0.6134042553191489
- 0.6287234042553191
- 0.6375531914893617
- 0.6422340425531915
- 0.6137765957446808
- 0.6247340425531915
- 0.620904255319149
- 0.6508510638297872
- 0.665
- 0.6797340425531915
- 0.6692021276595744
- 0.6707446808510639
- 0.6170212765957447
- 0.645
- 0.630904255319149
- 0.6333510638297872
- 0.6493085106382979
- 0.6651595744680852
- 0.69
- 0.6737765957446809
- 0.6463829787234042
test_loss_list:
- 3.7661592229207357
- 3.6521228885650636
- 3.4020878791809084
- 3.1483634980519613
- 2.9916569932301837
- 2.690537494023641
- 2.7158749961853026
- 2.4405928738911946
- 2.581438538233439
- 2.290632158915202
- 2.4444292481740315
- 2.4389170042673745
- 2.4626479307810465
- 2.3420444997151693
- 2.1716735951105752
- 2.3044136508305866
- 2.0198021030426023
- 2.24031502087911
- 1.853266487121582
- 1.875369784037272
- 1.8359649229049682
- 2.125311841964722
- 2.141810212135315
- 2.2140235884984336
- 1.7821561686197918
- 1.6823198699951172
- 2.026120263735453
- 2.046159030596415
- 2.0353768062591553
- 1.689296841621399
- 1.675786156654358
- 2.5487257925669353
- 2.0662932046254476
- 1.7308384625116984
- 2.087082970937093
- 1.6236085557937623
- 1.4338782930374145
- 1.5022549613316853
- 1.8903057130177816
- 1.3628448057174682
- 2.38136651357015
- 1.8731182686487833
- 1.9646766058603922
- 2.5193163776397705
- 2.010716505050659
- 2.0156956752141317
- 1.9634580278396607
- 1.9960530217488606
- 1.595935304959615
- 1.2872685225804648
- 2.3199521176020306
- 1.2597992245356242
- 1.3465119838714599
- 1.7006171909968057
- 1.2155521901448567
- 1.2895099353790282
- 1.292445421218872
- 1.6349637842178344
- 1.1717618020375569
- 2.179203807512919
- 1.1596051263809204
- 1.662577338218689
- 1.7635425551732382
- 1.8036374187469482
- 1.367732710838318
- 1.8066904592514037
- 1.3971622530619303
- 1.5934055852890014
- 1.277712508837382
- 2.1429978370666505
- 2.248558677037557
- 1.7846279732386272
- 1.7184112564722698
- 1.7612124411265055
- 1.3856540743509929
- 1.7408746687571208
- 2.2846246004104613
- 1.4111626243591309
- 1.7612743504842123
- 1.6764001448949177
- 1.695105102856954
- 1.7492569128672282
- 1.2312909396489462
- 2.097320605913798
- 1.6695002381006876
- 1.6325088214874268
- 1.2342882664998371
- 1.1785986431439717
- 1.0244887471199036
- 1.1376761730511984
- 1.1664270973205566
- 2.019410122235616
- 1.203743543624878
- 1.5402743053436279
- 1.6008581972122193
- 1.2544825744628907
- 1.1772981882095337
- 0.9898367730776468
- 1.0813853136698406
- 1.5002528540293376
train_accuracy:
- 0.033
- 0.152
- 0.323
- 0.417
- 0.45
- 0.0
- 0.546
- 0.558
- 0.017
- 0.0
- 0.646
- 0.646
- 0.673
- 0.706
- 0.156
- 0.683
- 0.0
- 0.698
- 0.042
- 0.002
- 0.212
- 0.679
- 0.0
- 0.74
- 0.652
- 0.046
- 0.754
- 0.09
- 0.0
- 0.735
- 0.731
- 0.798
- 0.783
- 0.702
- 0.804
- 0.096
- 0.102
- 0.719
- 0.804
- 0.652
- 0.81
- 0.733
- 0.004
- 0.815
- 0.006
- 0.777
- 0.0
- 0.798
- 0.012
- 0.683
- 0.817
- 0.662
- 0.037
- 0.825
- 0.673
- 0.754
- 0.783
- 0.817
- 0.685
- 0.823
- 0.725
- 0.804
- 0.019
- 0.04
- 0.2
- 0.021
- 0.796
- 0.825
- 0.017
- 0.85
- 0.819
- 0.825
- 0.833
- 0.846
- 0.804
- 0.825
- 0.86
- 0.808
- 0.84
- 0.002
- 0.006
- 0.838
- 0.808
- 0.817
- 0.833
- 0.84
- 0.838
- 0.096
- 0.704
- 0.05
- 0.067
- 0.848
- 0.821
- 0.835
- 0.844
- 0.798
- 0.073
- 0.721
- 0.067
- 0.85
train_loss:
- 2.913
- 3.152
- 2.876
- 2.544
- 2.406
- 1.821
- 2.017
- 1.592
- 1.853
- 1.2
- 1.726
- 1.651
- 1.606
- 1.591
- 1.323
- 1.508
- 1.236
- 1.47
- 1.182
- 1.159
- 1.177
- 1.349
- 1.342
- 1.287
- 1.113
- 1.073
- 1.293
- 1.283
- 1.27
- 1.033
- 1.007
- 1.429
- 1.189
- 0.986
- 1.16
- 0.989
- 0.778
- 0.959
- 1.132
- 0.754
- 1.357
- 1.11
- 1.106
- 1.291
- 1.086
- 1.08
- 1.084
- 1.065
- 0.874
- 0.721
- 1.248
- 0.723
- 0.883
- 1.071
- 0.695
- 0.855
- 0.852
- 1.039
- 0.668
- 1.223
- 0.68
- 1.009
- 0.997
- 0.982
- 0.832
- 0.989
- 0.818
- 1.004
- 0.824
- 1.153
- 1.138
- 0.969
- 0.995
- 0.946
- 0.786
- 0.943
- 1.087
- 0.797
- 0.948
- 0.953
- 0.943
- 0.934
- 0.803
- 1.092
- 0.926
- 0.944
- 0.784
- 0.772
- 0.594
- 0.743
- 0.728
- 1.073
- 0.783
- 0.928
- 0.893
- 0.769
- 0.756
- 0.58
- 0.73
- 0.9
unequal: 0
verbose: 1
