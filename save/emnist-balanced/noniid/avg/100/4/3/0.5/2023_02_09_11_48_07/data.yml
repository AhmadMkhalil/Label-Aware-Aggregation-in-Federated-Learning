avg_train_accuracy: 0.84
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0350531914893617
- 0.06457446808510638
- 0.1570212765957447
- 0.3206914893617021
- 0.31579787234042556
- 0.2875
- 0.2246276595744681
- 0.2743617021276596
- 0.3709574468085106
- 0.4578191489361702
- 0.4371808510638298
- 0.38563829787234044
- 0.49122340425531913
- 0.4213297872340426
- 0.47648936170212763
- 0.48356382978723406
- 0.48845744680851066
- 0.5251595744680851
- 0.4656382978723404
- 0.5342553191489362
- 0.5054255319148936
- 0.5086702127659575
- 0.5125
- 0.531595744680851
- 0.535
- 0.5380851063829787
- 0.5424468085106383
- 0.5407978723404255
- 0.5519148936170213
- 0.5186702127659575
- 0.5551595744680851
- 0.5606914893617021
- 0.5468085106382978
- 0.5681914893617022
- 0.5827127659574468
- 0.566595744680851
- 0.5779255319148936
- 0.5712765957446808
- 0.583031914893617
- 0.5856914893617021
- 0.5793085106382979
- 0.5810106382978724
- 0.6039361702127659
- 0.5898936170212766
- 0.6029255319148936
- 0.6091489361702128
- 0.5888297872340426
- 0.5879787234042553
- 0.6147340425531915
- 0.602872340425532
- 0.5944680851063829
- 0.5908510638297872
- 0.600531914893617
- 0.6186170212765958
- 0.6025
- 0.6098936170212766
- 0.6157978723404255
- 0.6023404255319149
- 0.5901063829787234
- 0.6002659574468086
- 0.6237765957446808
- 0.6039893617021277
- 0.606063829787234
- 0.6296276595744681
- 0.6088297872340426
- 0.6159042553191489
- 0.6397872340425532
- 0.6327127659574469
- 0.6078191489361702
- 0.6380851063829788
- 0.6100531914893617
- 0.6493085106382979
- 0.6401063829787234
- 0.6487234042553192
- 0.6519680851063829
- 0.6201063829787234
- 0.616436170212766
- 0.6256382978723404
- 0.6499468085106384
- 0.6262234042553192
- 0.6525
- 0.6509574468085106
- 0.6177659574468085
- 0.6211170212765957
- 0.6565425531914894
- 0.653031914893617
- 0.6544148936170213
- 0.6265425531914893
- 0.6664361702127659
- 0.6296276595744681
- 0.6156382978723405
- 0.6218085106382979
- 0.631968085106383
- 0.6172340425531915
- 0.6184574468085107
- 0.6553723404255319
- 0.6260638297872341
- 0.6153723404255319
- 0.6291489361702127
- 0.6211170212765957
test_loss_list:
- 3.798942136764526
- 3.691796194712321
- 3.4568748092651367
- 3.2759183851877847
- 3.0544587898254396
- 2.9088474305470786
- 2.9271582158406577
- 2.734945109685262
- 2.53002646446228
- 2.902600326538086
- 2.5642142963409422
- 2.4387646357218427
- 2.9581833267211914
- 2.3459958394368488
- 2.5664557456970214
- 2.3853024164835612
- 2.4810958449045817
- 2.937555726369222
- 2.0840390586853026
- 2.886201286315918
- 2.4032546583811443
- 2.0479804690678916
- 2.039738227526347
- 2.2269972880681355
- 2.2951951440175375
- 2.1855524492263796
- 2.2745651229222617
- 2.2744527769088747
- 2.2689580233891804
- 1.7259097305933635
- 1.7564369328816731
- 2.134484445254008
- 1.6045837052663168
- 2.056420292854309
- 1.6711095952987671
- 1.6602521832784016
- 2.5692854181925457
- 1.5794304037094116
- 1.5918925062815348
- 1.963484435081482
- 1.9431904649734497
- 1.515820059776306
- 1.5286586618423461
- 1.9346933762232463
- 1.3676620308558147
- 1.3236950731277466
- 1.7900100421905518
- 1.8274963506062825
- 1.4676441923777261
- 1.3932399288813273
- 1.7984258937835693
- 1.825650199254354
- 1.802922387123108
- 1.4477866156895955
- 1.8474309666951498
- 1.3753237660725912
- 1.384100734392802
- 1.787535343170166
- 1.7611320034662883
- 1.7747945642471314
- 1.4348759237925213
- 1.7348225371042887
- 1.7316070000330608
- 1.2093113311131796
- 1.7000467093785603
- 1.6731348403294881
- 1.3458068466186524
- 1.3021184174219766
- 2.264290515581767
- 1.3526309696833292
- 1.6589950259526571
- 1.2735746320088703
- 1.2264048480987548
- 1.2343922201792399
- 1.2759304682413737
- 1.7015439510345458
- 1.5885580650965372
- 1.6472784837086996
- 1.291229289372762
- 1.733371615409851
- 1.320260059038798
- 1.2263434314727784
- 1.601904795964559
- 1.5593526442845662
- 1.2115710512797038
- 1.1567352732022604
- 1.1589737923940022
- 1.6008290179570517
- 1.114520358244578
- 1.612161161104838
- 2.2167434136072797
- 1.6521613756815592
- 1.6484789625803629
- 2.2615979528427124
- 2.37972017288208
- 1.3164703464508056
- 1.7137840112050375
- 1.5833176104227702
- 1.6298636674880982
- 1.6129468297958374
train_accuracy:
- 0.021
- 0.073
- 0.208
- 0.467
- 0.0
- 0.0
- 0.242
- 0.0
- 0.0
- 0.608
- 0.002
- 0.004
- 0.644
- 0.556
- 0.0
- 0.648
- 0.673
- 0.702
- 0.612
- 0.704
- 0.7
- 0.629
- 0.0
- 0.7
- 0.0
- 0.721
- 0.74
- 0.0
- 0.765
- 0.002
- 0.0
- 0.0
- 0.565
- 0.763
- 0.008
- 0.021
- 0.76
- 0.729
- 0.75
- 0.002
- 0.79
- 0.737
- 0.006
- 0.773
- 0.635
- 0.108
- 0.815
- 0.773
- 0.767
- 0.05
- 0.002
- 0.794
- 0.0
- 0.758
- 0.004
- 0.181
- 0.773
- 0.827
- 0.815
- 0.798
- 0.737
- 0.0
- 0.831
- 0.204
- 0.002
- 0.002
- 0.094
- 0.758
- 0.808
- 0.773
- 0.817
- 0.787
- 0.035
- 0.017
- 0.033
- 0.827
- 0.002
- 0.825
- 0.117
- 0.804
- 0.071
- 0.135
- 0.002
- 0.846
- 0.042
- 0.773
- 0.154
- 0.812
- 0.81
- 0.829
- 0.817
- 0.867
- 0.002
- 0.858
- 0.883
- 0.015
- 0.848
- 0.0
- 0.852
- 0.84
train_loss:
- 2.94
- 3.286
- 3.041
- 3.206
- 2.483
- 1.946
- 1.449
- 1.339
- 1.641
- 2.258
- 1.835
- 1.49
- 2.004
- 1.412
- 1.616
- 1.593
- 1.55
- 1.771
- 1.284
- 1.715
- 1.438
- 1.196
- 1.158
- 1.407
- 1.347
- 1.339
- 1.29
- 1.297
- 1.256
- 0.879
- 1.074
- 1.257
- 0.825
- 1.238
- 1.019
- 1.019
- 1.399
- 0.991
- 0.984
- 1.152
- 1.181
- 0.957
- 0.941
- 1.122
- 0.76
- 0.717
- 1.134
- 1.111
- 0.905
- 0.908
- 1.074
- 1.097
- 1.078
- 0.883
- 1.047
- 0.865
- 0.845
- 1.022
- 1.073
- 1.018
- 0.847
- 1.047
- 1.045
- 0.663
- 1.018
- 1.01
- 0.834
- 0.83
- 1.187
- 0.827
- 0.982
- 0.82
- 0.808
- 0.814
- 0.798
- 0.972
- 0.964
- 0.972
- 0.801
- 0.962
- 0.793
- 0.783
- 0.954
- 0.961
- 0.794
- 0.783
- 0.759
- 0.93
- 0.788
- 0.933
- 1.087
- 0.925
- 0.93
- 1.074
- 1.073
- 0.78
- 0.916
- 0.931
- 0.929
- 0.912
unequal: 0
verbose: 1
