avg_train_accuracy: 0.829
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05037234042553192
- 0.0848404255319149
- 0.15430851063829787
- 0.16824468085106384
- 0.28872340425531917
- 0.3803191489361702
- 0.3941489361702128
- 0.3950531914893617
- 0.4034042553191489
- 0.46101063829787237
- 0.4723936170212766
- 0.4452127659574468
- 0.4773936170212766
- 0.42851063829787234
- 0.4832446808510638
- 0.5006382978723404
- 0.46106382978723404
- 0.488936170212766
- 0.5235106382978724
- 0.5371808510638297
- 0.5370744680851064
- 0.5404255319148936
- 0.5463829787234042
- 0.5293085106382979
- 0.545
- 0.546968085106383
- 0.5597340425531915
- 0.560531914893617
- 0.585
- 0.5667553191489362
- 0.5795744680851064
- 0.5965425531914894
- 0.5900531914893618
- 0.569468085106383
- 0.5732446808510638
- 0.5848936170212766
- 0.5859042553191489
- 0.5854255319148937
- 0.5948936170212766
- 0.5910106382978724
- 0.5936170212765958
- 0.6023936170212766
- 0.5915957446808511
- 0.5992021276595745
- 0.6220744680851064
- 0.6270744680851064
- 0.6349468085106383
- 0.5937234042553191
- 0.6098936170212766
- 0.6020744680851063
- 0.6416489361702128
- 0.6110106382978724
- 0.6033510638297872
- 0.6086170212765958
- 0.6399468085106383
- 0.6172340425531915
- 0.6082446808510639
- 0.6484574468085106
- 0.6453723404255319
- 0.6108510638297873
- 0.629095744680851
- 0.6377127659574469
- 0.6433510638297872
- 0.6179787234042553
- 0.6725531914893617
- 0.6571276595744681
- 0.6218617021276596
- 0.6273936170212766
- 0.614095744680851
- 0.6731914893617021
- 0.6592021276595744
- 0.6299468085106383
- 0.632127659574468
- 0.6414893617021277
- 0.6303191489361702
- 0.6313829787234042
- 0.6192553191489362
- 0.6379787234042553
- 0.6501595744680851
- 0.6670212765957447
- 0.6664361702127659
- 0.638563829787234
- 0.6347340425531914
- 0.6642553191489362
- 0.6568617021276596
- 0.6364893617021277
- 0.640531914893617
- 0.6537234042553192
- 0.675
- 0.6823404255319149
- 0.6892021276595744
- 0.6363829787234042
- 0.6920212765957446
- 0.6788829787234043
- 0.6302127659574468
- 0.6848936170212766
- 0.6846276595744681
- 0.630904255319149
- 0.7002659574468085
- 0.6387234042553191
test_loss_list:
- 3.797321001688639
- 3.710475047429403
- 3.4031315898895262
- 3.1697686862945558
- 2.828338998158773
- 2.71794753074646
- 2.6684384695688883
- 2.434654719034831
- 2.329834057490031
- 2.436525770823161
- 2.4065578746795655
- 2.192774689992269
- 2.388529577255249
- 2.019528727531433
- 2.020099177360535
- 2.381054153442383
- 1.8842427651087443
- 1.7500935729344687
- 2.2021163574854534
- 2.823990691502889
- 1.835393967628479
- 2.229036506017049
- 2.15312774181366
- 1.783561110496521
- 2.267995934486389
- 1.5610962041219076
- 1.6758274126052857
- 1.9873716068267822
- 1.6143474674224854
- 2.0318568833669026
- 1.6127652549743652
- 1.5620077228546143
- 1.385427680015564
- 2.017553908030192
- 2.053794366518656
- 1.8635672076543173
- 2.704845898946126
- 1.5631320937474569
- 1.509122854868571
- 1.8880402596791586
- 2.610136661529541
- 1.4994522937138874
- 2.067438818613688
- 1.8926746575037638
- 1.5211478471755981
- 1.3871044572194418
- 1.3989436515172322
- 1.8799581321080525
- 1.384551781018575
- 1.895628023147583
- 1.292664834658305
- 1.7870856507619222
- 1.846859672864278
- 1.9151065015792847
- 1.2928213024139403
- 1.8107297817866008
- 1.8495408121744792
- 1.2790927219390869
- 1.3324349228541057
- 2.418036677042643
- 1.3112036514282226
- 1.3431546529134115
- 1.3280486392974853
- 1.8028106705347697
- 1.0565220999717713
- 1.2056546354293822
- 1.6644459835688272
- 1.6193140904108683
- 2.3349069929122925
- 1.0573219815889994
- 1.22171453555425
- 1.6563961982727051
- 1.6829337930679322
- 1.2759367720286052
- 1.5940498781204224
- 1.6770313882827759
- 2.3466078488032025
- 1.260739541053772
- 1.2704064146677654
- 1.1566297618548076
- 1.1637964646021526
- 1.581528574625651
- 1.5288014300664265
- 1.1673451908429464
- 1.1484172828992207
- 1.5817884333928427
- 1.5402320178349813
- 1.1635348502794902
- 1.1198119473457337
- 1.1490151818593344
- 0.9764034263292949
- 1.522198754946391
- 0.9749680670102437
- 1.091955217520396
- 1.5386621729532877
- 1.0445495208104452
- 1.1099676752090455
- 1.4835415728886923
- 0.9224137330055237
- 1.5031030241648355
train_accuracy:
- 0.065
- 0.088
- 0.0
- 0.0
- 0.0
- 0.477
- 0.55
- 0.0
- 0.523
- 0.588
- 0.0
- 0.544
- 0.646
- 0.006
- 0.0
- 0.665
- 0.025
- 0.044
- 0.696
- 0.725
- 0.633
- 0.748
- 0.706
- 0.652
- 0.704
- 0.046
- 0.729
- 0.0
- 0.71
- 0.0
- 0.746
- 0.696
- 0.14
- 0.779
- 0.769
- 0.0
- 0.765
- 0.01
- 0.0
- 0.775
- 0.773
- 0.765
- 0.0
- 0.825
- 0.729
- 0.748
- 0.8
- 0.794
- 0.748
- 0.771
- 0.735
- 0.002
- 0.785
- 0.8
- 0.771
- 0.785
- 0.79
- 0.008
- 0.017
- 0.812
- 0.76
- 0.754
- 0.777
- 0.806
- 0.258
- 0.077
- 0.798
- 0.815
- 0.821
- 0.729
- 0.765
- 0.812
- 0.0
- 0.763
- 0.806
- 0.006
- 0.821
- 0.781
- 0.0
- 0.073
- 0.84
- 0.017
- 0.812
- 0.062
- 0.783
- 0.825
- 0.802
- 0.742
- 0.796
- 0.192
- 0.546
- 0.842
- 0.723
- 0.804
- 0.023
- 0.79
- 0.823
- 0.825
- 0.5
- 0.829
train_loss:
- 3.362
- 3.273
- 2.517
- 1.69
- 1.973
- 2.191
- 2.06
- 1.619
- 1.478
- 1.73
- 1.632
- 1.325
- 1.639
- 1.047
- 1.32
- 1.505
- 0.976
- 0.951
- 1.408
- 1.624
- 1.141
- 1.305
- 1.281
- 1.156
- 1.297
- 0.847
- 1.062
- 1.224
- 0.986
- 1.23
- 1.013
- 0.947
- 0.749
- 1.187
- 1.14
- 1.128
- 1.292
- 0.921
- 0.944
- 1.08
- 1.253
- 0.921
- 1.05
- 1.069
- 0.877
- 0.853
- 0.832
- 1.033
- 0.836
- 1.018
- 0.839
- 1.021
- 0.998
- 0.987
- 0.819
- 0.977
- 0.986
- 0.788
- 0.811
- 1.12
- 0.8
- 0.776
- 0.761
- 0.946
- 0.612
- 0.766
- 0.932
- 0.912
- 1.086
- 0.629
- 0.755
- 0.889
- 0.877
- 0.752
- 0.927
- 0.894
- 1.03
- 0.764
- 0.72
- 0.738
- 0.75
- 0.895
- 0.874
- 0.74
- 0.709
- 0.861
- 0.874
- 0.735
- 0.709
- 0.692
- 0.551
- 0.862
- 0.549
- 0.723
- 0.856
- 0.703
- 0.687
- 0.869
- 0.55
- 0.846
unequal: 0
verbose: 1
