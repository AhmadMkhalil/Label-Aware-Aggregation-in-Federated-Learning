avg_train_accuracy: 0.658
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05654255319148936
- 0.10718085106382978
- 0.10968085106382978
- 0.33787234042553194
- 0.22787234042553192
- 0.30856382978723407
- 0.36414893617021277
- 0.45622340425531915
- 0.33808510638297873
- 0.4778723404255319
- 0.4025
- 0.3834574468085106
- 0.5073404255319149
- 0.17659574468085107
- 0.51
- 0.23388297872340424
- 0.4728723404255319
- 0.5029255319148936
- 0.5275
- 0.5337234042553192
- 0.49351063829787234
- 0.4267021276595745
- 0.5332978723404256
- 0.38159574468085106
- 0.38574468085106384
- 0.527127659574468
- 0.5375
- 0.5251595744680851
- 0.44313829787234044
- 0.551595744680851
- 0.5576063829787234
- 0.5637234042553192
- 0.4734042553191489
- 0.5669148936170213
- 0.5510106382978723
- 0.5782446808510638
- 0.5806382978723404
- 0.576968085106383
- 0.579627659574468
- 0.5655851063829788
- 0.5824468085106383
- 0.5678191489361702
- 0.5813297872340426
- 0.4726063829787234
- 0.5918085106382979
- 0.46835106382978725
- 0.5881382978723404
- 0.5920744680851063
- 0.5974468085106382
- 0.5305851063829787
- 0.5104255319148936
- 0.5920744680851063
- 0.593404255319149
- 0.5940425531914894
- 0.529468085106383
- 0.6087234042553191
- 0.5481382978723405
- 0.5965957446808511
- 0.6116489361702128
- 0.6161702127659574
- 0.6141489361702127
- 0.615531914893617
- 0.6195744680851064
- 0.6235106382978723
- 0.6014893617021276
- 0.5757446808510638
- 0.6206914893617022
- 0.6043617021276596
- 0.6262765957446809
- 0.6046808510638297
- 0.6051595744680851
- 0.6241489361702127
- 0.6201063829787234
- 0.6029787234042553
- 0.6086170212765958
- 0.6253723404255319
- 0.6092021276595745
- 0.6096808510638297
- 0.6257978723404255
- 0.6307446808510638
- 0.6345212765957446
- 0.613031914893617
- 0.6352659574468085
- 0.6113829787234043
- 0.6353191489361703
- 0.6138297872340426
- 0.6131914893617021
- 0.6337765957446808
- 0.6159574468085106
- 0.6293085106382978
- 0.6145744680851064
- 0.6386170212765957
- 0.6417553191489361
- 0.652127659574468
- 0.6503723404255319
- 0.6237234042553191
- 0.6105851063829787
- 0.6103723404255319
- 0.6590425531914894
- 0.6229787234042553
test_loss_list:
- 3.84025032043457
- 3.641402152379354
- 3.491226119995117
- 3.133998098373413
- 3.1425076293945313
- 2.842311108907064
- 2.7115532557169595
- 2.9126235675811767
- 2.7305628649393716
- 2.8821022001902263
- 2.5502320448557536
- 2.5381806532541913
- 2.8472473335266115
- 3.4055626996358237
- 2.52189403851827
- 2.8698262564341226
- 2.095976235071818
- 2.036298672358195
- 2.5994091002146402
- 2.7060695457458497
- 2.217970862388611
- 2.111084435780843
- 1.8636347595850626
- 2.249087444941203
- 2.283885475794474
- 1.8969908380508422
- 1.8109932470321655
- 1.8978705819447834
- 2.018361371358236
- 1.833408587773641
- 1.9120037746429444
- 2.4681180795033772
- 1.9665364599227906
- 2.4341939369837444
- 1.9669502464930217
- 1.6204453674952188
- 1.7309179782867432
- 2.442907110850016
- 2.4961381181081137
- 1.9231520875295003
- 2.5246093972524006
- 1.8464790789286296
- 1.877852209409078
- 1.89386092821757
- 1.6116282399495443
- 1.8459450419743855
- 2.2678443733851115
- 2.350255498886108
- 1.8109315427144368
- 1.6951667817433675
- 1.7037992668151856
- 2.2198303159077963
- 1.5955290842056273
- 2.317064563433329
- 1.6841001494725545
- 1.486009817123413
- 1.6212528642018635
- 2.09326486269633
- 1.5829799032211305
- 1.6825947459538777
- 1.7329306030273437
- 1.7714732058842977
- 1.8045413986841838
- 1.4665558560689291
- 2.2761288913091025
- 1.4128104623158773
- 1.5192385085423787
- 2.156406658490499
- 1.6969141308466593
- 2.228037961324056
- 2.4016764783859252
- 1.6059192148844401
- 1.4813397789001466
- 2.2019105466206867
- 2.277397545178731
- 1.661868397394816
- 2.2611211125055948
- 2.36006206035614
- 1.5818264611562094
- 1.6672792530059815
- 1.6725803565979005
- 2.218743635813395
- 1.599964919090271
- 2.2956292231877646
- 1.738421343167623
- 2.261828023592631
- 2.382154100735982
- 1.8573539495468139
- 2.3776990938186646
- 1.4890161196390788
- 2.2163341840108237
- 1.487141852378845
- 1.586250680287679
- 1.4520051336288453
- 1.5260791015625
- 1.486463925043742
- 1.578046948115031
- 1.3281520080566407
- 1.2880102936426798
- 1.3775297451019286
train_accuracy:
- 0.01
- 0.065
- 0.058
- 0.473
- 0.237
- 0.042
- 0.215
- 0.625
- 0.408
- 0.665
- 0.542
- 0.448
- 0.617
- 0.01
- 0.725
- 0.006
- 0.085
- 0.567
- 0.735
- 0.74
- 0.629
- 0.0
- 0.042
- 0.642
- 0.504
- 0.662
- 0.225
- 0.227
- 0.46
- 0.638
- 0.671
- 0.74
- 0.365
- 0.781
- 0.706
- 0.706
- 0.706
- 0.756
- 0.779
- 0.731
- 0.798
- 0.292
- 0.735
- 0.49
- 0.717
- 0.471
- 0.812
- 0.817
- 0.7
- 0.385
- 0.773
- 0.812
- 0.713
- 0.808
- 0.508
- 0.729
- 0.325
- 0.787
- 0.577
- 0.769
- 0.556
- 0.783
- 0.725
- 0.133
- 0.817
- 0.371
- 0.113
- 0.802
- 0.188
- 0.8
- 0.831
- 0.8
- 0.767
- 0.84
- 0.835
- 0.085
- 0.844
- 0.823
- 0.544
- 0.544
- 0.088
- 0.844
- 0.727
- 0.844
- 0.804
- 0.806
- 0.846
- 0.804
- 0.833
- 0.075
- 0.848
- 0.513
- 0.823
- 0.8
- 0.794
- 0.673
- 0.85
- 0.604
- 0.781
- 0.658
train_loss:
- 2.988
- 2.824
- 2.444
- 3.008
- 1.942
- 2.054
- 1.712
- 2.246
- 1.746
- 2.05
- 1.645
- 1.535
- 1.88
- 0.68
- 1.978
- 0.603
- 1.424
- 1.297
- 1.708
- 1.662
- 1.275
- 0.915
- 1.192
- 0.793
- 0.744
- 1.248
- 1.135
- 1.168
- 0.789
- 1.172
- 1.123
- 1.472
- 0.795
- 1.466
- 1.098
- 1.062
- 1.009
- 1.387
- 1.352
- 1.058
- 1.329
- 1.043
- 1.036
- 0.661
- 1.038
- 0.673
- 1.331
- 1.298
- 0.989
- 0.63
- 0.639
- 1.288
- 0.974
- 1.228
- 0.665
- 1.0
- 0.618
- 1.261
- 0.945
- 0.894
- 0.897
- 0.871
- 0.882
- 0.917
- 1.174
- 0.668
- 0.924
- 1.153
- 0.918
- 1.18
- 1.105
- 0.86
- 0.897
- 1.137
- 1.116
- 0.895
- 1.12
- 1.099
- 0.856
- 0.85
- 0.891
- 1.107
- 0.856
- 1.091
- 0.856
- 1.091
- 1.063
- 0.848
- 1.064
- 0.849
- 1.055
- 0.831
- 0.816
- 0.794
- 0.785
- 0.569
- 0.526
- 0.533
- 0.822
- 0.521
unequal: 0
verbose: 1
