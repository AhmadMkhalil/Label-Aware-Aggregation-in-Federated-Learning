avg_train_accuracy: 0.81
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05356382978723404
- 0.08638297872340425
- 0.17627659574468085
- 0.2300531914893617
- 0.2752659574468085
- 0.39170212765957446
- 0.3595212765957447
- 0.4101595744680851
- 0.42664893617021277
- 0.4471276595744681
- 0.45861702127659576
- 0.44053191489361704
- 0.4803191489361702
- 0.46627659574468083
- 0.47840425531914893
- 0.5079787234042553
- 0.513031914893617
- 0.5136702127659575
- 0.5269148936170213
- 0.527127659574468
- 0.5473404255319149
- 0.5505851063829788
- 0.5411170212765958
- 0.5487234042553192
- 0.5410106382978723
- 0.5537765957446809
- 0.5591489361702128
- 0.5547872340425531
- 0.5682978723404255
- 0.571063829787234
- 0.5794148936170213
- 0.5706914893617021
- 0.5714893617021276
- 0.5795212765957447
- 0.5731914893617022
- 0.5863297872340425
- 0.581063829787234
- 0.5857978723404256
- 0.579627659574468
- 0.5961702127659575
- 0.5909042553191489
- 0.6096276595744681
- 0.6172340425531915
- 0.6006382978723405
- 0.5924468085106382
- 0.5962765957446808
- 0.6161702127659574
- 0.6228191489361702
- 0.6301063829787235
- 0.6343617021276595
- 0.6088829787234042
- 0.6163297872340425
- 0.6132446808510639
- 0.6188829787234043
- 0.6211170212765957
- 0.6019148936170213
- 0.6430851063829788
- 0.6230851063829788
- 0.6136170212765958
- 0.6512234042553191
- 0.6262765957446809
- 0.6060106382978724
- 0.6529787234042553
- 0.6071276595744681
- 0.6080851063829787
- 0.6565425531914894
- 0.6317553191489361
- 0.6624468085106383
- 0.6187234042553191
- 0.6393617021276595
- 0.6092553191489362
- 0.6622872340425532
- 0.6664893617021277
- 0.6438829787234043
- 0.6259574468085106
- 0.641436170212766
- 0.6416489361702128
- 0.6406914893617022
- 0.6724468085106383
- 0.6763829787234042
- 0.6790425531914893
- 0.6492021276595744
- 0.6813297872340426
- 0.6846808510638298
- 0.6147340425531915
- 0.6454255319148936
- 0.6354787234042554
- 0.6331382978723404
- 0.6442021276595745
- 0.6342553191489362
- 0.6370212765957447
- 0.6265425531914893
- 0.6431914893617021
- 0.6746276595744681
- 0.6519680851063829
- 0.683404255319149
- 0.6406382978723404
- 0.6396808510638298
- 0.689627659574468
- 0.6214893617021277
test_loss_list:
- 3.784232193628947
- 3.71503386815389
- 3.5110112857818603
- 3.1633849970499672
- 2.8551477845509847
- 2.815634562174479
- 2.5343424638112384
- 2.495161689122518
- 2.392857030232747
- 2.3709274609883626
- 2.2926681359608967
- 2.0942466259002686
- 2.1627630853652953
- 1.9549456230799358
- 1.90128333568573
- 2.0641759268442788
- 2.0282606347401937
- 1.9782624133427937
- 1.9727809572219848
- 1.9502897135416666
- 2.2676123189926147
- 2.2794403664271035
- 1.9622659762700398
- 1.9654960250854492
- 1.8651790221532185
- 1.8853258577982586
- 1.8576165342330933
- 1.7731991370519002
- 1.5504466835657755
- 1.7780518500010172
- 1.4961361662546793
- 2.0504788223902386
- 1.695176239013672
- 2.097506316502889
- 1.6938213189442952
- 1.4690451876322428
- 2.017464590072632
- 2.0422902886072793
- 1.6718584632873534
- 1.4199301465352376
- 1.6262403376897177
- 1.3589542245864867
- 1.3228676732381184
- 1.6022795645395915
- 1.8736938254038493
- 1.990530416170756
- 1.3343419408798218
- 1.3082704830169678
- 1.2744622453053793
- 1.2560895601908366
- 1.5135012594858805
- 1.4621918853123983
- 1.540786542892456
- 1.536982717514038
- 1.5253663206100463
- 1.8280444399515787
- 1.235100925763448
- 1.4700478506088257
- 1.4762242428461712
- 1.1967464526494345
- 1.4777496862411499
- 1.776691314379374
- 1.1896889853477477
- 1.8077762858072917
- 1.8722904555002848
- 1.1905960432688396
- 1.463195211092631
- 1.1535592412948608
- 1.7820598300298054
- 1.4490471108754477
- 1.740898739496867
- 1.1535222593943277
- 1.1419576795895894
- 1.3405325110753377
- 1.3826575517654418
- 1.3518256489435831
- 1.3738830439249674
- 1.4083172146479288
- 1.0947929175694784
- 1.0850002988179526
- 1.0726383288701375
- 1.360292550722758
- 1.0595319978396098
- 1.0417703731854757
- 2.0705031633377073
- 1.3794747034708659
- 1.3380019569396973
- 1.3798254251480102
- 1.324866582552592
- 1.3436187473932901
- 1.3631226698557535
- 1.7659589958190918
- 1.3036316633224487
- 1.0644552969932557
- 1.2967551946640015
- 1.0421173731486002
- 1.2995815960566204
- 1.3234599002202352
- 1.0190483665466308
- 2.04393626054128
train_accuracy:
- 0.062
- 0.108
- 0.269
- 0.296
- 0.377
- 0.508
- 0.433
- 0.552
- 0.612
- 0.635
- 0.004
- 0.0
- 0.0
- 0.56
- 0.008
- 0.002
- 0.004
- 0.692
- 0.002
- 0.69
- 0.74
- 0.717
- 0.719
- 0.75
- 0.737
- 0.76
- 0.74
- 0.742
- 0.742
- 0.737
- 0.035
- 0.769
- 0.75
- 0.763
- 0.763
- 0.029
- 0.794
- 0.796
- 0.756
- 0.035
- 0.802
- 0.748
- 0.733
- 0.817
- 0.808
- 0.0
- 0.823
- 0.067
- 0.746
- 0.75
- 0.767
- 0.794
- 0.783
- 0.773
- 0.802
- 0.815
- 0.767
- 0.798
- 0.792
- 0.76
- 0.01
- 0.833
- 0.754
- 0.825
- 0.821
- 0.108
- 0.031
- 0.117
- 0.017
- 0.835
- 0.838
- 0.792
- 0.031
- 0.854
- 0.808
- 0.794
- 0.821
- 0.002
- 0.846
- 0.838
- 0.806
- 0.015
- 0.792
- 0.152
- 0.846
- 0.065
- 0.823
- 0.804
- 0.798
- 0.023
- 0.021
- 0.833
- 0.012
- 0.108
- 0.806
- 0.783
- 0.829
- 0.804
- 0.86
- 0.81
train_loss:
- 3.236
- 3.035
- 3.214
- 2.554
- 1.97
- 2.419
- 1.677
- 1.834
- 1.751
- 1.695
- 1.621
- 1.355
- 1.518
- 1.282
- 1.235
- 1.415
- 1.398
- 1.367
- 1.334
- 1.308
- 1.452
- 1.407
- 1.243
- 1.208
- 1.223
- 1.174
- 1.148
- 1.17
- 0.983
- 1.118
- 0.959
- 1.275
- 1.095
- 1.233
- 1.094
- 0.915
- 1.205
- 1.188
- 1.036
- 0.897
- 1.023
- 0.857
- 0.856
- 1.0
- 1.141
- 1.113
- 0.86
- 0.827
- 0.831
- 0.815
- 0.955
- 0.952
- 0.938
- 0.928
- 0.928
- 1.065
- 0.8
- 0.92
- 0.923
- 0.779
- 0.898
- 1.035
- 0.786
- 1.023
- 1.009
- 0.778
- 0.885
- 0.745
- 0.999
- 0.862
- 0.999
- 0.746
- 0.744
- 0.859
- 0.864
- 0.848
- 0.842
- 0.849
- 0.726
- 0.716
- 0.71
- 0.844
- 0.725
- 0.704
- 1.078
- 0.834
- 0.832
- 0.816
- 0.819
- 0.812
- 0.816
- 0.923
- 0.835
- 0.695
- 0.811
- 0.686
- 0.801
- 0.804
- 0.679
- 1.028
unequal: 0
verbose: 1
