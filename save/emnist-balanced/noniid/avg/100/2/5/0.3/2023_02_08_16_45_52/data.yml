avg_train_accuracy: 0.748
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03377659574468085
- 0.0398936170212766
- 0.20840425531914894
- 0.035106382978723406
- 0.06882978723404255
- 0.3963829787234043
- 0.2099468085106383
- 0.4618617021276596
- 0.27893617021276595
- 0.34829787234042553
- 0.5075531914893617
- 0.20617021276595746
- 0.14101063829787233
- 0.25143617021276593
- 0.46654255319148935
- 0.23101063829787233
- 0.4151595744680851
- 0.11148936170212766
- 0.10154255319148936
- 0.47414893617021275
- 0.14441489361702128
- 0.4817021276595745
- 0.5101063829787233
- 0.4906382978723404
- 0.36388297872340425
- 0.5135106382978724
- 0.53
- 0.33808510638297873
- 0.5187234042553192
- 0.4346808510638298
- 0.5316489361702128
- 0.3252127659574468
- 0.1977127659574468
- 0.5379787234042553
- 0.5588829787234042
- 0.5493617021276596
- 0.25813829787234044
- 0.5668085106382978
- 0.5743085106382979
- 0.5666489361702127
- 0.38180851063829785
- 0.4771808510638298
- 0.25659574468085106
- 0.1377127659574468
- 0.5943085106382979
- 0.5044148936170213
- 0.6024468085106383
- 0.5845212765957447
- 0.5938297872340426
- 0.5934574468085106
- 0.48212765957446807
- 0.6082446808510639
- 0.5197872340425532
- 0.614468085106383
- 0.5251595744680851
- 0.4118085106382979
- 0.6131914893617021
- 0.6080851063829787
- 0.5424468085106383
- 0.5371276595744681
- 0.6238829787234043
- 0.6147340425531915
- 0.5403191489361702
- 0.4476063829787234
- 0.6257978723404255
- 0.5324468085106383
- 0.625
- 0.6215957446808511
- 0.5321276595744681
- 0.6245212765957446
- 0.5726595744680851
- 0.5168085106382979
- 0.3146276595744681
- 0.6394148936170213
- 0.5289893617021276
- 0.6414893617021277
- 0.6252659574468085
- 0.5446276595744681
- 0.5456382978723404
- 0.6390957446808511
- 0.6336170212765957
- 0.5658510638297872
- 0.5781382978723404
- 0.6420212765957447
- 0.6340957446808511
- 0.5633510638297873
- 0.6356382978723404
- 0.6387765957446808
- 0.6525
- 0.5354787234042553
- 0.6391489361702127
- 0.3141489361702128
- 0.47
- 0.665372340425532
- 0.6530851063829787
- 0.6374468085106383
- 0.539468085106383
- 0.660904255319149
- 0.6519680851063829
- 0.645904255319149
test_loss_list:
- 3.9049685033162436
- 3.8097848796844485
- 3.482479295730591
- 4.405620880126953
- 4.785001118977864
- 2.930973259607951
- 3.1809206199645996
- 2.7651212469736737
- 2.969425039291382
- 2.85682466506958
- 2.7417015329996746
- 3.298029867808024
- 4.483010136286418
- 2.9598306210835776
- 2.2968636830647786
- 3.111846939722697
- 2.3357127571105956
- 4.540208199818929
- 6.604560407002767
- 2.1357643222808838
- 4.40298815091451
- 1.9856932767232258
- 1.9604513518015543
- 2.016147387822469
- 2.3433055973052976
- 1.937754333813985
- 1.9844586849212646
- 2.717517925898234
- 1.9003343359629312
- 2.0412062851587933
- 1.7759219042460124
- 2.752102842330933
- 3.217760051091512
- 1.6946252918243407
- 1.7175583410263062
- 1.7219395303726197
- 3.2053564739227296
- 1.532636365890503
- 1.618768000602722
- 1.6295018402735393
- 2.4442484887441
- 1.7350185489654542
- 3.204467674891154
- 6.247054360707601
- 1.4557984574635823
- 1.740930282274882
- 1.9221226263046265
- 1.5995644585291544
- 1.5536266533533731
- 1.536439266204834
- 1.9430873743693033
- 1.9841337458292643
- 1.8537979523340862
- 1.9910401153564452
- 1.670582086245219
- 1.9792258469263713
- 1.9185429032643635
- 1.773445733388265
- 1.6962913354237874
- 1.6665325212478637
- 1.422121264139811
- 1.6687890672683716
- 1.444174566268921
- 1.8009395949045817
- 1.292223359743754
- 1.4875560983022054
- 1.8158838017781576
- 1.6755893691380819
- 1.5059133291244506
- 1.8451279497146607
- 1.467429084777832
- 1.8470925490061443
- 3.306079874038696
- 1.232342728773753
- 1.598656086921692
- 1.179680256843567
- 1.275855172475179
- 1.4374401839574178
- 1.5423232698440552
- 1.2621230745315553
- 1.2732217343648276
- 1.3692241748174032
- 1.3762984307607016
- 1.313533868789673
- 1.2457613213857015
- 1.4649120410283407
- 1.32851806640625
- 1.293799293835958
- 1.2182301123936972
- 1.5659429613749187
- 1.2236212889353435
- 3.430453996658325
- 1.8688273890813192
- 1.104460009733836
- 1.182227112452189
- 1.279708530108134
- 1.4436834414800008
- 1.1212138199806214
- 1.15733598391215
- 1.2607064962387085
train_accuracy:
- 0.6
- 0.0
- 0.273
- 0.015
- 0.004
- 0.508
- 0.25
- 0.606
- 0.335
- 0.442
- 0.665
- 0.6
- 0.8
- 0.61
- 0.548
- 0.498
- 0.485
- 0.91
- 0.708
- 0.66
- 0.729
- 0.548
- 0.571
- 0.612
- 0.367
- 0.638
- 0.635
- 0.919
- 0.6
- 0.473
- 0.877
- 0.944
- 0.904
- 0.619
- 0.865
- 0.66
- 0.865
- 0.654
- 0.677
- 0.938
- 0.373
- 0.463
- 0.865
- 0.89
- 0.796
- 0.952
- 0.796
- 0.715
- 0.717
- 0.838
- 0.896
- 0.767
- 0.562
- 0.787
- 0.977
- 0.444
- 0.81
- 0.887
- 0.615
- 0.967
- 0.721
- 0.754
- 0.517
- 0.802
- 0.771
- 0.542
- 0.817
- 0.746
- 0.552
- 0.804
- 0.967
- 0.979
- 0.969
- 0.925
- 0.971
- 0.752
- 0.733
- 0.865
- 0.99
- 0.929
- 0.721
- 0.608
- 0.91
- 0.812
- 0.763
- 0.542
- 0.731
- 0.775
- 0.769
- 0.973
- 0.742
- 0.981
- 0.973
- 0.787
- 0.908
- 0.74
- 0.571
- 0.906
- 0.748
- 0.748
train_loss:
- 2.844
- 2.692
- 3.574
- 1.488
- 1.185
- 2.948
- 1.886
- 2.426
- 1.638
- 1.552
- 2.108
- 0.928
- 0.827
- 0.895
- 1.367
- 0.846
- 1.412
- 0.24
- 0.175
- 1.387
- 0.189
- 1.394
- 1.269
- 1.216
- 0.687
- 1.243
- 1.144
- 0.659
- 1.198
- 0.663
- 1.134
- 0.631
- 0.181
- 1.198
- 1.08
- 1.089
- 0.192
- 1.133
- 1.076
- 1.038
- 0.564
- 0.639
- 0.153
- 0.107
- 1.16
- 0.597
- 1.461
- 0.997
- 0.991
- 0.975
- 0.561
- 1.394
- 0.572
- 1.399
- 0.602
- 0.561
- 1.378
- 0.964
- 0.534
- 0.544
- 0.929
- 0.908
- 0.583
- 0.523
- 0.948
- 0.537
- 1.319
- 0.899
- 0.541
- 1.301
- 0.556
- 0.472
- 0.136
- 0.897
- 0.513
- 0.905
- 0.888
- 0.509
- 0.493
- 0.864
- 0.852
- 0.5
- 0.5
- 0.844
- 0.832
- 0.484
- 0.841
- 0.855
- 0.868
- 0.499
- 0.845
- 0.108
- 0.496
- 0.859
- 0.821
- 0.838
- 0.491
- 0.83
- 0.83
- 0.808
unequal: 0
verbose: 1
