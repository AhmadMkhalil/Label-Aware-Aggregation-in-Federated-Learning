avg_train_accuracy: 0.9
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.040638297872340426
- 0.0400531914893617
- 0.04398936170212766
- 0.1124468085106383
- 0.10638297872340426
- 0.17696808510638298
- 0.16601063829787235
- 0.4122872340425532
- 0.1829787234042553
- 0.13627659574468085
- 0.08728723404255319
- 0.10601063829787234
- 0.10053191489361703
- 0.17702127659574468
- 0.10473404255319149
- 0.38622340425531915
- 0.18723404255319148
- 0.09845744680851064
- 0.1376063829787234
- 0.20382978723404255
- 0.15478723404255318
- 0.21372340425531916
- 0.383563829787234
- 0.11563829787234042
- 0.19946808510638298
- 0.2636702127659574
- 0.18861702127659574
- 0.20457446808510638
- 0.4559042553191489
- 0.4718085106382979
- 0.25313829787234043
- 0.47058510638297874
- 0.1503191489361702
- 0.25930851063829785
- 0.4972872340425532
- 0.5104787234042554
- 0.4990425531914894
- 0.5687234042553192
- 0.5110638297872341
- 0.5304255319148936
- 0.3372872340425532
- 0.3090425531914894
- 0.3852659574468085
- 0.5469148936170213
- 0.5504255319148936
- 0.3550531914893617
- 0.33952127659574466
- 0.3672340425531915
- 0.30446808510638296
- 0.31351063829787235
- 0.5938297872340426
- 0.36696808510638296
- 0.571968085106383
- 0.5671276595744681
- 0.6034574468085107
- 0.5736702127659574
- 0.5673936170212766
- 0.5802127659574469
- 0.5873404255319149
- 0.25127659574468086
- 0.39914893617021274
- 0.6056914893617021
- 0.2637765957446809
- 0.6146808510638297
- 0.4929787234042553
- 0.6095212765957447
- 0.6129255319148936
- 0.6025
- 0.4446276595744681
- 0.6134042553191489
- 0.6203191489361702
- 0.6053723404255319
- 0.42186170212765955
- 0.19026595744680852
- 0.6334042553191489
- 0.6173404255319149
- 0.22345744680851065
- 0.63
- 0.4670744680851064
- 0.628031914893617
- 0.6257978723404255
- 0.48398936170212764
- 0.6281382978723404
- 0.6349468085106383
- 0.6288297872340426
- 0.6286170212765958
- 0.47936170212765955
- 0.6403191489361703
- 0.6197872340425532
- 0.3272340425531915
- 0.624468085106383
- 0.6160106382978724
- 0.5565425531914894
- 0.3043085106382979
- 0.6337234042553191
- 0.5783510638297872
- 0.6364893617021277
- 0.446968085106383
- 0.5402659574468085
- 0.6029787234042553
test_loss_list:
- 3.816691312789917
- 3.818093738555908
- 4.315618082682292
- 3.4917246214548747
- 3.561545909245809
- 3.2605010509490966
- 3.161335859298706
- 2.9158881346384686
- 3.2517737674713136
- 3.9264172331492104
- 4.878407770792643
- 4.4842416826883955
- 5.530195967356364
- 3.103927345275879
- 5.006039835611979
- 2.4353689416249593
- 2.9918935743967694
- 5.173888810475668
- 3.414340613683065
- 3.0724757957458495
- 3.706942253112793
- 2.859223664601644
- 2.324831075668335
- 5.459765033721924
- 2.8267824331919353
- 2.680780378977458
- 3.2285866069793703
- 3.1325604502360025
- 2.0985537576675415
- 1.980833257039388
- 2.6854518445332847
- 1.9785675366719564
- 5.00340669631958
- 2.551071418126424
- 1.9022655375798543
- 2.0125238513946533
- 1.9208414300282797
- 2.282602831522624
- 1.935009258588155
- 1.9665981356302897
- 2.478322903315226
- 2.4805198319753012
- 2.104189605712891
- 1.721023055712382
- 1.7941268587112427
- 2.2370293505986534
- 2.4907430458068847
- 2.2083929538726808
- 2.418533369700114
- 2.6173451550801596
- 2.0213315280278525
- 2.0924792782465618
- 1.5475472609202068
- 1.6988705492019653
- 2.1236154937744143
- 1.7041865507761638
- 1.6441372060775756
- 1.630373290379842
- 1.6475224637985229
- 3.3146868578592934
- 1.996221268971761
- 1.3932606506347656
- 3.126353375116984
- 1.3733610963821412
- 1.6720697450637818
- 1.4703168265024822
- 1.3937266190846762
- 1.441341905593872
- 1.9098250373204548
- 1.4216094811757405
- 1.3712827936808267
- 1.4667422723770143
- 1.9549291594823202
- 5.0024245198567705
- 1.3370594612757365
- 1.4465180269877116
- 4.127470404307047
- 1.4030277315775554
- 2.0612956269582114
- 1.366888755162557
- 1.4970977481206258
- 1.9871391423543294
- 1.4099755970637005
- 1.5153394985198974
- 1.4656102132797242
- 1.371994400024414
- 1.8968600463867187
- 1.3900707244873047
- 1.4344611358642578
- 2.780799420674642
- 1.3412169392903646
- 1.5173900095621744
- 1.561682801246643
- 3.170348742802938
- 1.644688418706258
- 1.4011187108357748
- 1.7273642094930013
- 2.0272629245122276
- 1.4906890757878621
- 1.2523864603042603
train_accuracy:
- 0.963
- 0.865
- 0.002
- 0.919
- 0.092
- 0.169
- 0.615
- 0.523
- 0.621
- 0.271
- 0.998
- 0.048
- 0.65
- 0.135
- 0.156
- 0.444
- 0.119
- 0.898
- 0.069
- 0.131
- 0.412
- 0.183
- 0.727
- 0.565
- 0.912
- 0.194
- 0.123
- 0.906
- 0.537
- 0.558
- 0.946
- 0.535
- 0.881
- 0.76
- 0.673
- 0.608
- 0.573
- 0.727
- 0.612
- 0.64
- 0.892
- 0.871
- 0.898
- 0.74
- 0.671
- 0.852
- 0.258
- 0.319
- 0.242
- 0.842
- 0.721
- 0.952
- 0.644
- 0.669
- 0.731
- 0.95
- 0.658
- 0.677
- 0.706
- 0.881
- 0.354
- 0.717
- 0.867
- 0.806
- 0.467
- 0.715
- 0.725
- 0.713
- 0.452
- 0.731
- 0.744
- 0.721
- 0.404
- 0.871
- 0.763
- 0.794
- 0.95
- 0.725
- 0.865
- 0.483
- 0.723
- 0.5
- 0.752
- 0.8
- 0.796
- 0.715
- 0.908
- 0.794
- 0.952
- 0.863
- 0.721
- 0.942
- 0.979
- 0.929
- 0.823
- 0.915
- 0.808
- 0.958
- 0.912
- 0.9
train_loss:
- 2.824
- 2.606
- 1.521
- 2.418
- 2.216
- 2.032
- 1.954
- 2.592
- 1.783
- 1.007
- 0.364
- 0.936
- 0.905
- 0.942
- 0.286
- 1.625
- 0.897
- 0.857
- 0.842
- 0.868
- 0.82
- 0.824
- 1.386
- 0.2
- 0.844
- 0.775
- 0.777
- 0.729
- 1.291
- 1.297
- 0.732
- 1.294
- 0.172
- 0.723
- 1.253
- 1.189
- 1.189
- 1.685
- 1.165
- 1.157
- 0.643
- 0.628
- 0.652
- 1.104
- 1.08
- 0.631
- 0.607
- 0.596
- 0.583
- 0.596
- 1.554
- 0.599
- 1.057
- 1.02
- 1.426
- 1.002
- 1.015
- 0.978
- 0.998
- 0.224
- 0.6
- 0.994
- 0.15
- 1.014
- 0.529
- 0.971
- 0.943
- 0.962
- 0.536
- 0.926
- 0.962
- 0.952
- 0.514
- 0.105
- 0.971
- 0.916
- 0.121
- 0.924
- 0.498
- 0.956
- 0.883
- 0.502
- 0.923
- 0.87
- 0.9
- 0.897
- 0.505
- 0.854
- 0.872
- 0.159
- 0.913
- 0.828
- 0.485
- 0.12
- 1.331
- 0.526
- 1.24
- 0.185
- 0.482
- 0.492
unequal: 0
verbose: 1
