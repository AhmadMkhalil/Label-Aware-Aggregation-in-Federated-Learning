avg_train_accuracy: 0.706
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04031914893617021
- 0.0551063829787234
- 0.041648936170212765
- 0.05882978723404255
- 0.32404255319148934
- 0.07877659574468085
- 0.41547872340425535
- 0.2199468085106383
- 0.12925531914893618
- 0.12457446808510639
- 0.09952127659574468
- 0.3946276595744681
- 0.49281914893617024
- 0.3324468085106383
- 0.19664893617021276
- 0.3945744680851064
- 0.18659574468085105
- 0.22111702127659574
- 0.22122340425531914
- 0.18973404255319148
- 0.4226595744680851
- 0.46882978723404256
- 0.24888297872340426
- 0.5168085106382979
- 0.5077127659574469
- 0.29404255319148936
- 0.26154255319148934
- 0.13031914893617022
- 0.32159574468085106
- 0.5364893617021277
- 0.49579787234042555
- 0.5311702127659574
- 0.3023936170212766
- 0.4162234042553192
- 0.5726595744680851
- 0.3683510638297872
- 0.15414893617021277
- 0.5526595744680851
- 0.37611702127659574
- 0.3791489361702128
- 0.2052659574468085
- 0.3816489361702128
- 0.5735106382978723
- 0.27606382978723404
- 0.5801595744680851
- 0.4097340425531915
- 0.36734042553191487
- 0.42611702127659573
- 0.3748404255319149
- 0.604468085106383
- 0.4006382978723404
- 0.47367021276595744
- 0.4453191489361702
- 0.4728723404255319
- 0.21861702127659574
- 0.1722872340425532
- 0.4752659574468085
- 0.46404255319148935
- 0.4588829787234043
- 0.4103191489361702
- 0.17585106382978724
- 0.6300531914893617
- 0.613031914893617
- 0.44180851063829785
- 0.6258510638297873
- 0.4268085106382979
- 0.5446808510638298
- 0.23946808510638298
- 0.6388297872340426
- 0.6275
- 0.30398936170212765
- 0.470531914893617
- 0.6325531914893617
- 0.6204255319148936
- 0.6392553191489362
- 0.5124468085106383
- 0.46877659574468084
- 0.6320212765957447
- 0.6282978723404256
- 0.6357978723404255
- 0.5785106382978723
- 0.624468085106383
- 0.6225531914893617
- 0.5168085106382979
- 0.6398404255319149
- 0.6256382978723404
- 0.5094148936170213
- 0.2785106382978723
- 0.5218617021276596
- 0.6398936170212766
- 0.6456914893617022
- 0.5543617021276596
- 0.6293617021276596
- 0.6295744680851064
- 0.6384042553191489
- 0.6495744680851064
- 0.6453723404255319
- 0.6563829787234042
- 0.5253723404255319
- 0.6490425531914894
test_loss_list:
- 3.8464552402496337
- 4.348232339223226
- 4.059851299921672
- 4.858153158823649
- 3.100003538131714
- 4.343598168690999
- 2.8615588251749675
- 3.274093313217163
- 4.225848871866862
- 3.6678325812021892
- 4.304724957148234
- 2.643048652013143
- 2.663741518656413
- 2.8939190928141274
- 2.9697451782226563
- 2.5590341726938886
- 3.0858483346303305
- 2.8006398169199627
- 2.975128434499105
- 3.5401976331075033
- 2.2508717314402262
- 2.2701226615905763
- 2.9549754683176674
- 2.0914642318089802
- 2.158252665201823
- 2.6551705837249755
- 2.9905379327138264
- 4.600478674570719
- 2.395632708867391
- 1.9266618617375693
- 2.0071120564142864
- 2.0158576726913453
- 2.4079823970794676
- 2.015063691139221
- 1.7902094729741413
- 2.1164562368392943
- 4.349840943018595
- 1.7352130476633707
- 2.4384345531463625
- 2.5299029286702472
- 3.583070812225342
- 2.290140864054362
- 1.73074005762736
- 2.7762476348876954
- 1.53573574701945
- 2.0305965455373127
- 2.235075209935506
- 1.9040452814102173
- 2.1680446577072146
- 1.5066653728485107
- 2.1340303897857664
- 1.7881605736414592
- 1.9515601921081542
- 1.8745449590682983
- 3.9559554862976074
- 5.139990660349528
- 1.9431740268071493
- 1.8877304697036743
- 1.766496402422587
- 2.0861978324254355
- 4.731234238942464
- 1.431442050933838
- 1.4514714161554971
- 1.9465924533208212
- 1.4276214917500814
- 2.0619831116994223
- 1.522397484779358
- 4.175339136123657
- 1.399223918914795
- 1.304500125249227
- 2.9869903914133706
- 1.6987329483032227
- 1.296831382115682
- 1.3867682933807373
- 1.3788511164983113
- 1.6407959127426148
- 1.8511434920628866
- 1.3356639544169109
- 1.4647654930750529
- 1.371720643043518
- 1.371979014078776
- 1.8091483306884766
- 1.379335905710856
- 1.5723846181233725
- 1.3033868376413982
- 1.877712001800537
- 1.6803292878468832
- 3.038358252843221
- 1.5453573894500732
- 1.1839027380943299
- 1.308324171702067
- 1.5734953816731772
- 1.753296504020691
- 1.8730102491378784
- 1.498967645963033
- 1.3634094635645548
- 1.3573279333114625
- 1.40933270295461
- 1.6914952007929485
- 1.4006445678075155
train_accuracy:
- 0.917
- 0.0
- 0.662
- 0.975
- 0.415
- 0.904
- 0.523
- 0.223
- 0.873
- 0.885
- 0.667
- 0.271
- 0.619
- 0.317
- 0.465
- 0.454
- 0.76
- 0.208
- 0.771
- 0.163
- 0.498
- 0.573
- 0.948
- 0.638
- 0.594
- 0.867
- 0.912
- 0.394
- 0.344
- 0.652
- 0.583
- 0.717
- 0.938
- 0.706
- 0.631
- 0.954
- 0.869
- 0.867
- 0.633
- 0.925
- 0.917
- 0.915
- 0.679
- 0.869
- 0.565
- 0.971
- 0.942
- 0.362
- 0.95
- 0.746
- 0.396
- 0.879
- 0.398
- 0.963
- 0.9
- 0.973
- 0.969
- 0.429
- 0.983
- 0.967
- 0.887
- 0.875
- 0.706
- 0.985
- 0.688
- 0.419
- 0.487
- 0.965
- 0.777
- 0.665
- 0.956
- 0.877
- 0.735
- 0.708
- 0.754
- 0.971
- 0.975
- 0.675
- 0.76
- 0.744
- 0.948
- 0.806
- 0.744
- 0.513
- 0.752
- 0.796
- 0.965
- 0.894
- 0.438
- 0.748
- 0.769
- 0.542
- 0.787
- 0.825
- 0.958
- 0.794
- 0.742
- 0.921
- 0.954
- 0.706
train_loss:
- 2.851
- 1.729
- 2.542
- 1.323
- 3.277
- 1.227
- 2.795
- 1.803
- 0.961
- 1.104
- 0.953
- 1.703
- 2.187
- 1.469
- 0.927
- 1.461
- 0.887
- 0.842
- 0.814
- 0.749
- 1.411
- 1.344
- 0.746
- 1.312
- 1.304
- 0.738
- 0.691
- 0.171
- 0.738
- 1.238
- 1.257
- 1.206
- 0.695
- 0.7
- 1.154
- 0.708
- 0.15
- 1.182
- 0.625
- 0.622
- 0.151
- 0.644
- 1.112
- 0.2
- 1.195
- 0.608
- 0.611
- 0.637
- 0.607
- 1.084
- 0.587
- 0.591
- 0.578
- 0.558
- 0.124
- 0.088
- 0.584
- 0.557
- 0.566
- 0.582
- 0.087
- 1.058
- 1.003
- 0.569
- 1.012
- 0.565
- 0.559
- 0.091
- 1.014
- 0.998
- 0.13
- 0.576
- 0.971
- 0.947
- 0.95
- 0.543
- 0.51
- 0.958
- 0.935
- 0.924
- 0.56
- 1.337
- 0.919
- 0.54
- 0.908
- 1.278
- 0.536
- 0.114
- 0.53
- 0.894
- 0.869
- 0.505
- 1.267
- 1.203
- 0.852
- 0.862
- 0.89
- 0.842
- 0.504
- 0.866
unequal: 0
verbose: 1
