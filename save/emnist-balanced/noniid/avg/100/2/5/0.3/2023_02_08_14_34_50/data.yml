avg_train_accuracy: 0.973
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03962765957446809
- 0.04143617021276596
- 0.20452127659574468
- 0.07170212765957447
- 0.08946808510638297
- 0.0724468085106383
- 0.22223404255319149
- 0.436436170212766
- 0.2756382978723404
- 0.11111702127659574
- 0.3248404255319149
- 0.34888297872340424
- 0.4022872340425532
- 0.19819148936170214
- 0.21170212765957447
- 0.4127659574468085
- 0.38776595744680853
- 0.4128723404255319
- 0.44101063829787235
- 0.5443085106382979
- 0.47648936170212763
- 0.4679255319148936
- 0.2750531914893617
- 0.2933510638297872
- 0.31574468085106383
- 0.29367021276595745
- 0.5177127659574469
- 0.5161170212765958
- 0.5357978723404255
- 0.5468617021276596
- 0.5053723404255319
- 0.3034574468085106
- 0.32409574468085106
- 0.5616489361702127
- 0.5738829787234042
- 0.1747340425531915
- 0.5908510638297872
- 0.48154255319148936
- 0.5666489361702127
- 0.5744148936170212
- 0.3103191489361702
- 0.5848404255319148
- 0.5709574468085107
- 0.4306382978723404
- 0.5995212765957447
- 0.5918617021276595
- 0.4268085106382979
- 0.6028191489361702
- 0.4017553191489362
- 0.6094148936170213
- 0.5891489361702128
- 0.6115425531914893
- 0.5
- 0.4678191489361702
- 0.6033510638297872
- 0.47202127659574467
- 0.5967553191489362
- 0.6186702127659575
- 0.6255851063829787
- 0.5144148936170213
- 0.47132978723404256
- 0.606968085106383
- 0.6149468085106383
- 0.47627659574468084
- 0.4089893617021277
- 0.6163829787234043
- 0.6083510638297872
- 0.5585638297872341
- 0.6396808510638298
- 0.6467021276595745
- 0.6406914893617022
- 0.4913297872340426
- 0.5577659574468085
- 0.6421808510638298
- 0.6452127659574468
- 0.4770744680851064
- 0.47664893617021276
- 0.6579255319148937
- 0.4975531914893617
- 0.528031914893617
- 0.5134574468085107
- 0.6380851063829788
- 0.6330851063829788
- 0.5692021276595745
- 0.598563829787234
- 0.6623936170212766
- 0.6611702127659574
- 0.4999468085106383
- 0.4392553191489362
- 0.6422872340425532
- 0.611436170212766
- 0.6664361702127659
- 0.5139893617021276
- 0.6119148936170212
- 0.6418617021276596
- 0.32101063829787235
- 0.676968085106383
- 0.6146808510638297
- 0.6886702127659574
- 0.6221808510638298
test_loss_list:
- 3.8662677892049153
- 3.7582341543833415
- 3.4833577187856037
- 3.632432228724162
- 7.014807758331298
- 3.623114767074585
- 2.9807267634073895
- 2.760826203028361
- 2.9398497200012206
- 3.781174825032552
- 2.7844499365488686
- 2.5719348430633544
- 2.510482864379883
- 3.104494635264079
- 2.9467037137349448
- 2.2438935089111327
- 2.4129324022928875
- 2.3033388741811116
- 2.2294496583938597
- 2.4437203216552734
- 2.298204337755839
- 2.1958738629023236
- 2.5294305801391603
- 2.508653554916382
- 2.483991324106852
- 2.7180649757385256
- 2.0216426118214925
- 2.134871926307678
- 1.8334287738800048
- 1.8977031056086222
- 2.0711013015111286
- 2.4726402950286865
- 2.2165157000223794
- 1.6753673791885375
- 1.7617077700297037
- 4.58605458577474
- 2.0801243575414023
- 2.091523456573486
- 1.6103175210952758
- 1.6774720001220702
- 3.0338243293762206
- 1.6233806276321412
- 1.8102737426757813
- 1.9890589459737142
- 1.6220032437642415
- 1.5600837310155233
- 1.9043096923828124
- 1.567665410041809
- 2.0675044949849446
- 1.9935556920369466
- 1.6639459959665934
- 1.5667287588119507
- 1.7710885175069173
- 1.979049056371053
- 1.4737845023473104
- 1.709660758972168
- 1.4892857774098713
- 1.9088812144597371
- 1.56484885374705
- 1.7306626669565837
- 1.8063589890797933
- 1.4796106465657552
- 1.462779803276062
- 1.8567804670333863
- 2.2880871597925823
- 1.4848554229736328
- 1.6280327701568604
- 1.7394877370198567
- 1.371030837694804
- 1.2512399021784464
- 1.391355538368225
- 1.8159652376174926
- 1.7917650969823202
- 1.2361685800552369
- 1.3436539999643962
- 1.6123300886154175
- 1.7103990856806437
- 1.218305648167928
- 1.7557321278254192
- 1.5554391956329345
- 1.7131395800908407
- 1.2458707237243651
- 1.7190008195241293
- 1.3929251829783122
- 1.310322518348694
- 1.1837404044469197
- 1.2036842155456542
- 1.7437484121322633
- 1.927564868927002
- 1.2356760040918986
- 1.423841978708903
- 1.1528566829363505
- 1.553887840906779
- 1.255153430302938
- 1.1444848926862081
- 3.4769691149393718
- 1.0583966255187989
- 1.2306066568692524
- 1.0161898056666057
- 1.2277723916371663
train_accuracy:
- 0.0
- 0.0
- 0.283
- 0.887
- 0.869
- 0.802
- 0.229
- 0.581
- 0.931
- 0.631
- 0.39
- 0.388
- 0.76
- 0.594
- 0.463
- 0.49
- 0.467
- 0.479
- 0.85
- 0.681
- 0.558
- 0.708
- 0.59
- 0.271
- 0.3
- 0.969
- 0.621
- 0.923
- 0.631
- 0.648
- 0.6
- 0.848
- 0.981
- 0.652
- 0.773
- 0.946
- 0.76
- 0.975
- 0.644
- 0.683
- 0.971
- 0.7
- 0.906
- 0.427
- 0.713
- 0.727
- 0.952
- 0.717
- 0.408
- 0.794
- 0.76
- 0.735
- 0.496
- 0.979
- 0.696
- 0.942
- 0.719
- 0.804
- 0.91
- 0.965
- 0.456
- 0.698
- 0.71
- 0.963
- 0.983
- 0.737
- 0.731
- 0.983
- 0.767
- 0.758
- 0.894
- 0.981
- 0.981
- 0.925
- 0.777
- 0.948
- 0.938
- 0.771
- 0.977
- 0.921
- 0.952
- 0.75
- 0.821
- 0.95
- 0.967
- 0.702
- 0.75
- 0.988
- 0.963
- 0.646
- 0.602
- 0.777
- 0.927
- 0.975
- 0.773
- 0.956
- 0.802
- 0.9
- 0.656
- 0.973
train_loss:
- 2.765
- 2.688
- 3.601
- 2.328
- 0.276
- 1.458
- 2.023
- 2.619
- 1.677
- 1.049
- 1.597
- 1.591
- 1.511
- 0.878
- 0.944
- 1.459
- 1.399
- 1.376
- 1.324
- 1.834
- 1.253
- 1.253
- 0.834
- 0.728
- 0.707
- 0.676
- 1.18
- 1.136
- 1.252
- 1.169
- 1.171
- 0.687
- 0.671
- 1.189
- 1.112
- 0.189
- 1.648
- 0.652
- 1.1
- 1.05
- 0.555
- 1.062
- 1.001
- 0.642
- 1.011
- 1.069
- 0.612
- 1.005
- 0.575
- 1.408
- 0.975
- 0.967
- 0.589
- 0.531
- 0.951
- 0.573
- 0.947
- 1.335
- 0.952
- 0.581
- 0.535
- 0.895
- 0.889
- 0.556
- 0.491
- 0.883
- 0.858
- 0.524
- 0.895
- 0.902
- 0.91
- 0.493
- 0.496
- 0.935
- 0.885
- 0.515
- 0.51
- 0.878
- 0.489
- 0.497
- 0.479
- 0.825
- 1.206
- 0.534
- 0.524
- 0.844
- 0.844
- 0.506
- 0.463
- 0.835
- 0.483
- 0.827
- 0.506
- 0.501
- 0.812
- 0.12
- 0.893
- 0.481
- 0.82
- 0.483
unequal: 0
verbose: 1
