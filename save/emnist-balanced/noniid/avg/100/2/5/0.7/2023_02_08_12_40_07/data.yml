avg_train_accuracy: 0.81
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02154255319148936
- 0.047872340425531915
- 0.14765957446808511
- 0.19829787234042554
- 0.26441489361702125
- 0.2552659574468085
- 0.2952659574468085
- 0.3511170212765957
- 0.2797340425531915
- 0.35521276595744683
- 0.3645744680851064
- 0.3794148936170213
- 0.3270212765957447
- 0.41345744680851065
- 0.4505851063829787
- 0.25303191489361704
- 0.4541489361702128
- 0.40047872340425533
- 0.41702127659574467
- 0.4117021276595745
- 0.4102127659574468
- 0.4751595744680851
- 0.4751595744680851
- 0.40643617021276596
- 0.44053191489361704
- 0.43877659574468086
- 0.49425531914893617
- 0.5057978723404255
- 0.35771276595744683
- 0.5303723404255319
- 0.5165425531914893
- 0.461968085106383
- 0.5322872340425532
- 0.5001595744680851
- 0.5369680851063829
- 0.47856382978723405
- 0.5163297872340425
- 0.5632446808510638
- 0.5621276595744681
- 0.5629787234042554
- 0.5630851063829787
- 0.5516489361702127
- 0.5806382978723404
- 0.5512765957446808
- 0.528936170212766
- 0.5546276595744681
- 0.5934574468085106
- 0.6006914893617021
- 0.5760106382978724
- 0.5434574468085106
- 0.6020212765957447
- 0.5870212765957447
- 0.5776063829787234
- 0.6148404255319149
- 0.6156914893617021
- 0.6218085106382979
- 0.47191489361702127
- 0.6132446808510639
- 0.6255851063829787
- 0.6186702127659575
- 0.6231382978723404
- 0.6294148936170213
- 0.6020212765957447
- 0.5204255319148936
- 0.6371808510638298
- 0.6365425531914893
- 0.6385106382978724
- 0.6353723404255319
- 0.6156382978723405
- 0.6218617021276596
- 0.6412765957446809
- 0.6432978723404256
- 0.6582446808510638
- 0.6522872340425532
- 0.5339893617021276
- 0.6579787234042553
- 0.6276595744680851
- 0.6606382978723404
- 0.6533510638297872
- 0.6331382978723404
- 0.6551595744680851
- 0.6533510638297872
- 0.6436702127659575
- 0.6757978723404255
- 0.6355851063829787
- 0.6724468085106383
- 0.6701063829787234
- 0.6476595744680851
- 0.5834574468085106
- 0.6757978723404255
- 0.6799468085106383
- 0.649468085106383
- 0.6613829787234042
- 0.6460106382978723
- 0.6743617021276596
- 0.6702127659574468
- 0.684468085106383
- 0.6864361702127659
- 0.6649468085106383
- 0.6535106382978724
test_loss_list:
- 3.8414103507995607
- 3.7265464369455974
- 3.4849331760406494
- 3.1818723424275714
- 3.038381004333496
- 2.940388619105021
- 2.7941062959035237
- 2.6265311431884766
- 2.7119754536946616
- 2.5377218310038248
- 2.495046819051107
- 2.4000973828633625
- 2.44528933207194
- 2.3026275412241617
- 2.2794363784790037
- 2.7481506633758546
- 2.1652690331141153
- 2.1637614218393963
- 2.1083090607325237
- 2.087755227088928
- 2.0636807616551716
- 2.010277996063232
- 2.0036620807647707
- 2.1359753068288168
- 1.9941794554392496
- 2.007089579900106
- 1.8814122931162516
- 1.882704348564148
- 2.2212127526601155
- 1.761019147237142
- 1.7497544558842977
- 1.8341055901845296
- 1.7070266135533652
- 1.7130341784159342
- 1.6881884558995566
- 1.7938846445083618
- 1.6508281532923381
- 1.65490891456604
- 1.59061780611674
- 1.623003748257955
- 1.5979758135477702
- 1.5702547391255697
- 1.5475324646631876
- 1.5439190355936687
- 1.6037040535608929
- 1.5145079612731933
- 1.4630748891830445
- 1.6209728399912515
- 1.5012985754013062
- 1.5282626406351725
- 1.5812307834625243
- 1.4016188065210977
- 1.4325427150726318
- 1.5412380647659303
- 1.4104902426401773
- 1.5233337020874023
- 1.7396672852834065
- 1.2990589094161988
- 1.3570751015345255
- 1.5290501197179158
- 1.327226119041443
- 1.2856517664591471
- 1.3257902272542317
- 1.6225431410471598
- 1.2872782643636067
- 1.492111914952596
- 1.3744819068908691
- 1.2039728736877442
- 1.2713377618789672
- 1.2605432303746542
- 1.1822144730885824
- 1.1710406637191773
- 1.1751907738049825
- 1.2056590874989828
- 1.5691903750101726
- 1.1775403308868408
- 1.2707029136021932
- 1.2222411076227824
- 1.1531768496831258
- 1.2146280018488567
- 1.1327551213900249
- 1.136701983610789
- 1.172555300394694
- 1.177739675839742
- 1.222976304690043
- 1.1036038096745808
- 1.1477990555763244
- 1.266062609354655
- 1.4034067360560099
- 1.059703814983368
- 1.0567214790980022
- 1.1419201707839965
- 1.2837960894902547
- 1.2111355916659037
- 1.0571467868487041
- 1.081061187585195
- 1.0337045868237813
- 1.0689398415883382
- 1.1163582070668538
- 1.2678625583648682
train_accuracy:
- 0.0
- 0.0
- 0.198
- 0.046
- 0.102
- 0.002
- 0.012
- 0.438
- 0.344
- 0.104
- 0.46
- 0.479
- 0.352
- 0.121
- 0.612
- 0.29
- 0.031
- 0.598
- 0.502
- 0.425
- 0.185
- 0.594
- 0.537
- 0.438
- 0.396
- 0.442
- 0.231
- 0.194
- 0.625
- 0.137
- 0.633
- 0.517
- 0.625
- 0.352
- 0.006
- 0.475
- 0.419
- 0.275
- 0.194
- 0.223
- 0.725
- 0.631
- 0.185
- 0.525
- 0.433
- 0.583
- 0.706
- 0.744
- 0.117
- 0.51
- 0.756
- 0.688
- 0.577
- 0.804
- 0.225
- 0.15
- 0.548
- 0.702
- 0.748
- 0.773
- 0.71
- 0.733
- 0.348
- 0.81
- 0.704
- 0.733
- 0.71
- 0.365
- 0.604
- 0.619
- 0.558
- 0.842
- 0.6
- 0.773
- 0.579
- 0.729
- 0.583
- 0.765
- 0.735
- 0.7
- 0.698
- 0.7
- 0.625
- 0.758
- 0.74
- 0.74
- 0.725
- 0.771
- 0.944
- 0.675
- 0.181
- 0.781
- 0.779
- 0.227
- 0.717
- 0.677
- 0.746
- 0.754
- 0.66
- 0.81
train_loss:
- 2.484
- 2.335
- 2.596
- 1.983
- 2.174
- 1.704
- 1.567
- 1.487
- 1.171
- 1.415
- 1.372
- 1.332
- 1.026
- 1.271
- 1.505
- 0.731
- 1.217
- 0.937
- 0.935
- 0.906
- 0.889
- 1.137
- 1.106
- 0.886
- 0.858
- 0.852
- 1.075
- 1.049
- 0.612
- 1.041
- 1.036
- 0.81
- 1.001
- 0.793
- 0.986
- 0.778
- 0.758
- 0.946
- 0.951
- 0.936
- 0.949
- 0.93
- 0.934
- 0.723
- 0.707
- 0.72
- 0.893
- 1.073
- 0.894
- 0.68
- 1.067
- 0.691
- 0.675
- 1.03
- 0.844
- 1.015
- 0.51
- 0.847
- 0.817
- 0.982
- 0.828
- 0.81
- 0.643
- 0.459
- 0.805
- 0.955
- 0.779
- 0.81
- 0.624
- 0.617
- 0.613
- 0.61
- 0.768
- 0.755
- 0.447
- 0.771
- 0.59
- 0.751
- 0.764
- 0.599
- 0.586
- 0.591
- 0.595
- 0.741
- 0.575
- 0.755
- 0.732
- 0.89
- 0.434
- 0.578
- 0.732
- 0.573
- 0.881
- 0.883
- 0.57
- 0.569
- 0.715
- 0.715
- 0.557
- 0.86
unequal: 0
verbose: 1
