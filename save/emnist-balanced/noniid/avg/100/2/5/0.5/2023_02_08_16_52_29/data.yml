avg_train_accuracy: 0.86
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.029574468085106383
- 0.05031914893617021
- 0.05952127659574468
- 0.06191489361702128
- 0.09776595744680851
- 0.14808510638297873
- 0.1176595744680851
- 0.14819148936170212
- 0.33095744680851064
- 0.3708510638297872
- 0.38393617021276594
- 0.3779787234042553
- 0.4122872340425532
- 0.33611702127659576
- 0.3002659574468085
- 0.35558510638297874
- 0.4722872340425532
- 0.3820212765957447
- 0.34324468085106385
- 0.3856914893617021
- 0.4990425531914894
- 0.5340957446808511
- 0.4109042553191489
- 0.4399468085106383
- 0.4315425531914894
- 0.4698404255319149
- 0.4571276595744681
- 0.33867021276595743
- 0.4735106382978723
- 0.500904255319149
- 0.48127659574468085
- 0.479468085106383
- 0.49196808510638296
- 0.5665425531914894
- 0.5732446808510638
- 0.5792553191489361
- 0.4965425531914894
- 0.5272872340425532
- 0.5151595744680851
- 0.5234042553191489
- 0.5040425531914894
- 0.6163297872340425
- 0.5193085106382979
- 0.5571276595744681
- 0.5428191489361702
- 0.5623404255319149
- 0.6111702127659574
- 0.5188297872340426
- 0.5495744680851063
- 0.6155851063829787
- 0.6046276595744681
- 0.5544148936170212
- 0.5831914893617022
- 0.6298936170212766
- 0.3771276595744681
- 0.5991489361702128
- 0.6457978723404255
- 0.6306914893617022
- 0.5770744680851064
- 0.6317553191489361
- 0.6286170212765958
- 0.5637765957446809
- 0.6194148936170213
- 0.5967021276595744
- 0.6253191489361702
- 0.6098936170212766
- 0.6011170212765957
- 0.6526063829787234
- 0.6116489361702128
- 0.646595744680851
- 0.6430851063829788
- 0.5955851063829787
- 0.6135106382978723
- 0.6665425531914894
- 0.5972340425531915
- 0.6092021276595745
- 0.675372340425532
- 0.42143617021276597
- 0.6696808510638298
- 0.6807978723404255
- 0.6262765957446809
- 0.6723404255319149
- 0.6685106382978724
- 0.6295212765957446
- 0.6368617021276596
- 0.5235106382978724
- 0.6272340425531915
- 0.6218617021276596
- 0.6307446808510638
- 0.6836170212765957
- 0.6273936170212766
- 0.6572340425531915
- 0.6095212765957447
- 0.6531382978723405
- 0.6892553191489361
- 0.6423404255319148
- 0.6961702127659575
- 0.6723936170212766
- 0.6452127659574468
- 0.48138297872340424
test_loss_list:
- 3.8209751415252686
- 3.7908911418914797
- 3.6717946561177572
- 3.798201519648234
- 3.491689697901408
- 3.1719960371653237
- 3.331256554921468
- 3.130168565114339
- 2.636182107925415
- 2.5693098513285317
- 2.4328531551361086
- 2.4518142191569012
- 2.2577399412790933
- 2.336731039683024
- 2.4711204179128012
- 2.2878170172373453
- 2.0208881950378417
- 2.1440148798624676
- 2.2689782555898033
- 2.131524362564087
- 1.9381042353312175
- 1.8851684125264485
- 2.043210368156433
- 1.9234659846623738
- 1.972684539159139
- 1.8744143025080362
- 1.8891329034169515
- 2.350928332010905
- 1.7982069937388103
- 1.6721201213200887
- 1.7264469877878825
- 1.8120841868718465
- 1.707644656499227
- 1.5783595848083496
- 1.5985186147689818
- 1.4873027642567953
- 1.7018780374526978
- 1.583225399653117
- 1.6650912936528524
- 1.6050501982371013
- 1.6370992247263592
- 1.4913386917114257
- 1.5993095874786376
- 1.4632306019465129
- 1.5367989333470662
- 1.4411129649480183
- 1.3851407877604167
- 1.7161917654673258
- 1.5109179258346557
- 1.3479980866114298
- 1.3720726203918456
- 1.5291303873062134
- 1.386849226951599
- 1.3617444594701131
- 2.1813326485951743
- 1.2901831356684368
- 1.3035649156570435
- 1.5854892031351726
- 1.4034844223658245
- 1.2934615580240885
- 1.2156858189900717
- 1.4791398525238038
- 1.5203005663553875
- 1.3082647657394408
- 1.2068285512924195
- 1.2924848731358847
- 1.2882997449239095
- 1.206967560450236
- 1.2475930992762247
- 1.2346910913785298
- 1.1477879699071247
- 1.2896131229400636
- 1.2280976788202922
- 1.1953810445467632
- 1.3016322104136149
- 1.25911501566569
- 1.2405589135487873
- 2.266621789932251
- 1.080649270216624
- 1.1241380659739177
- 1.1819942275683084
- 1.1596827952067057
- 1.0586064728101094
- 1.1624875720342
- 1.3190627257029215
- 1.6637499698003133
- 1.1523157652219136
- 1.2371483914057413
- 1.191903928120931
- 1.1380871121088665
- 1.2480521853764852
- 1.3570429976781209
- 1.2436195834477743
- 1.1301189676920573
- 1.0550029977162678
- 1.1241891638437906
- 1.1105884861946107
- 1.0737866139411927
- 1.124385104974111
- 1.855030517578125
train_accuracy:
- 0.396
- 0.66
- 0.017
- 0.008
- 0.071
- 0.0
- 0.192
- 0.104
- 0.381
- 0.402
- 0.496
- 0.546
- 0.119
- 0.302
- 0.85
- 0.294
- 0.325
- 0.096
- 0.406
- 0.331
- 0.327
- 0.265
- 0.792
- 0.621
- 0.36
- 0.871
- 0.427
- 0.598
- 0.638
- 0.519
- 0.733
- 0.892
- 0.646
- 0.633
- 0.669
- 0.65
- 0.483
- 0.554
- 0.515
- 0.744
- 0.583
- 0.415
- 0.519
- 0.85
- 0.535
- 0.794
- 0.635
- 0.827
- 0.498
- 0.717
- 0.673
- 0.546
- 0.754
- 0.702
- 0.275
- 0.735
- 0.723
- 0.769
- 0.917
- 0.746
- 0.706
- 0.952
- 0.8
- 0.496
- 0.679
- 0.706
- 0.948
- 0.744
- 0.629
- 0.713
- 0.329
- 0.56
- 0.694
- 0.742
- 0.894
- 0.931
- 0.765
- 0.929
- 0.623
- 0.823
- 0.621
- 0.531
- 0.552
- 0.858
- 0.794
- 0.906
- 0.858
- 0.585
- 0.956
- 0.777
- 0.604
- 0.796
- 0.885
- 0.65
- 0.796
- 0.838
- 0.842
- 0.129
- 0.654
- 0.86
train_loss:
- 2.603
- 2.405
- 2.273
- 1.557
- 1.455
- 1.409
- 1.291
- 1.242
- 1.668
- 1.566
- 1.492
- 1.438
- 1.433
- 0.96
- 0.948
- 0.947
- 1.289
- 0.932
- 0.879
- 0.85
- 1.236
- 1.182
- 0.842
- 0.844
- 0.821
- 0.81
- 0.799
- 0.459
- 0.783
- 0.78
- 0.747
- 0.781
- 0.74
- 1.047
- 1.05
- 1.024
- 0.716
- 0.726
- 0.708
- 0.678
- 0.713
- 0.967
- 0.676
- 0.674
- 0.669
- 0.686
- 0.931
- 0.677
- 0.642
- 0.899
- 0.915
- 0.634
- 0.624
- 0.899
- 0.381
- 0.63
- 0.878
- 1.107
- 0.642
- 0.863
- 0.879
- 0.592
- 1.088
- 0.625
- 0.823
- 0.809
- 0.61
- 0.848
- 0.571
- 0.801
- 0.824
- 0.579
- 0.573
- 0.808
- 0.563
- 0.577
- 0.79
- 0.359
- 0.809
- 0.805
- 0.547
- 0.782
- 0.785
- 0.544
- 0.997
- 0.351
- 0.552
- 0.554
- 0.532
- 0.751
- 0.538
- 0.975
- 0.559
- 0.545
- 0.754
- 0.533
- 0.744
- 0.74
- 0.534
- 0.298
unequal: 0
verbose: 1
