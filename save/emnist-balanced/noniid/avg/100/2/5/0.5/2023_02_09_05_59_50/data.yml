avg_train_accuracy: 0.794
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03489361702127659
- 0.04654255319148936
- 0.0648404255319149
- 0.09095744680851064
- 0.15787234042553192
- 0.09207446808510639
- 0.29148936170212764
- 0.13063829787234044
- 0.3320744680851064
- 0.3286702127659574
- 0.20319148936170212
- 0.22069148936170213
- 0.4225
- 0.21659574468085108
- 0.39595744680851064
- 0.39351063829787236
- 0.1522872340425532
- 0.4319148936170213
- 0.14638297872340425
- 0.21936170212765957
- 0.451063829787234
- 0.468031914893617
- 0.5105851063829787
- 0.4671808510638298
- 0.3617021276595745
- 0.48106382978723405
- 0.4820212765957447
- 0.3772340425531915
- 0.4035106382978723
- 0.5390957446808511
- 0.5275
- 0.33845744680851064
- 0.51
- 0.4322340425531915
- 0.5573404255319149
- 0.4127127659574468
- 0.4642553191489362
- 0.541968085106383
- 0.44670212765957445
- 0.4970212765957447
- 0.5555851063829788
- 0.42058510638297875
- 0.43632978723404253
- 0.4377127659574468
- 0.5383510638297873
- 0.4465425531914894
- 0.49164893617021277
- 0.3017021276595745
- 0.581063829787234
- 0.5800531914893617
- 0.5889893617021277
- 0.29595744680851066
- 0.5956382978723405
- 0.594095744680851
- 0.5472340425531915
- 0.5526063829787234
- 0.5627659574468085
- 0.6204787234042554
- 0.3279787234042553
- 0.6059574468085106
- 0.6248404255319149
- 0.6267021276595744
- 0.5294148936170213
- 0.6135106382978723
- 0.6252127659574468
- 0.475
- 0.6395212765957446
- 0.3568085106382979
- 0.6405851063829787
- 0.6409574468085106
- 0.5545212765957447
- 0.3596808510638298
- 0.574627659574468
- 0.6544148936170213
- 0.6445744680851064
- 0.6266489361702128
- 0.6486702127659575
- 0.568936170212766
- 0.6484574468085106
- 0.6502659574468085
- 0.584627659574468
- 0.6274468085106383
- 0.568404255319149
- 0.6598936170212766
- 0.565
- 0.6322872340425532
- 0.6582978723404256
- 0.3823936170212766
- 0.6595212765957447
- 0.5985106382978723
- 0.40143617021276595
- 0.6664361702127659
- 0.6688829787234043
- 0.605
- 0.6322872340425532
- 0.6365957446808511
- 0.6754255319148936
- 0.6545212765957447
- 0.6361702127659574
- 0.658936170212766
test_loss_list:
- 4.077860094706217
- 3.752679634094238
- 4.0842995230356856
- 3.4854408359527587
- 3.2131958134969074
- 3.6155781523386636
- 2.8331573073069256
- 3.4390246454874673
- 2.640382293065389
- 2.660337683359782
- 2.897605323791504
- 2.9244936593373616
- 2.3720964272816976
- 2.8605001672108967
- 2.399529151916504
- 2.2867938486735024
- 5.644740187327067
- 2.376751766204834
- 4.016866645812988
- 3.223581453959147
- 2.1652175331115724
- 2.0703532807032268
- 2.272538011868795
- 2.0880537621180215
- 2.272985273996989
- 1.944440984725952
- 1.9080427805582683
- 2.133670384089152
- 2.074856751759847
- 1.8789314619700115
- 1.8285141483942668
- 2.314619105656942
- 1.771942777633667
- 1.9598871676127116
- 1.7643806044260661
- 2.0634061606725056
- 1.9028182013829549
- 1.5994925689697266
- 1.8982339429855346
- 1.7461932722727458
- 1.8544085375467936
- 2.109759618441264
- 2.023027574221293
- 1.94228031317393
- 1.5919858201344808
- 1.9503764661153158
- 1.7060491148630779
- 2.9597270107269287
- 1.5169790236155192
- 1.5410331789652507
- 1.4598266235987345
- 2.9582633558909097
- 1.4999066321055095
- 1.7178436533610026
- 1.5679311577479045
- 1.5137241156895955
- 1.4989492479960125
- 1.4398594919840495
- 2.7765184179941813
- 1.322481230099996
- 1.3629455582300822
- 1.2707907629013062
- 1.6193117157618204
- 1.5623225784301757
- 1.3107597017288208
- 1.774234159787496
- 1.276727056503296
- 2.5532704099019368
- 1.2732632605234782
- 1.2823711935679118
- 1.480871605873108
- 2.7160138193766277
- 1.3820301389694214
- 1.1945580410957337
- 1.2402931038538616
- 1.4358190123240153
- 1.2138411768277486
- 1.4260011847813925
- 1.1736001110076903
- 1.1392109179496765
- 1.3754466247558594
- 1.3844078969955445
- 1.4154527203241984
- 1.1817968050638834
- 1.4295272779464723
- 1.4251912498474122
- 1.1447656114896139
- 2.4981911182403564
- 1.1011013762156168
- 1.2768033329645794
- 2.4135750039418538
- 1.0761936044692992
- 1.1153778115908304
- 1.3396709807713827
- 1.6530319579442343
- 1.1826313622792561
- 1.086804497241974
- 1.3739514700571696
- 1.1624694108963012
- 1.3668978373209635
train_accuracy:
- 0.0
- 0.894
- 0.0
- 0.037
- 0.683
- 0.713
- 0.381
- 0.848
- 0.023
- 0.356
- 0.16
- 0.137
- 0.581
- 0.179
- 0.194
- 0.45
- 0.933
- 0.567
- 0.263
- 0.102
- 0.025
- 0.581
- 0.617
- 0.492
- 0.652
- 0.119
- 0.558
- 0.767
- 0.402
- 0.635
- 0.615
- 0.296
- 0.621
- 0.827
- 0.194
- 0.71
- 0.433
- 0.631
- 0.415
- 0.848
- 0.71
- 0.412
- 0.819
- 0.39
- 0.64
- 0.335
- 0.885
- 0.856
- 0.183
- 0.656
- 0.66
- 0.508
- 0.748
- 0.748
- 0.879
- 0.898
- 0.55
- 0.406
- 0.252
- 0.444
- 0.713
- 0.66
- 0.74
- 0.454
- 0.662
- 0.973
- 0.733
- 0.838
- 0.729
- 0.804
- 0.513
- 0.783
- 0.552
- 0.76
- 0.727
- 0.777
- 0.769
- 0.787
- 0.44
- 0.742
- 0.923
- 0.208
- 0.952
- 0.852
- 0.875
- 0.787
- 0.742
- 0.992
- 0.765
- 0.621
- 0.944
- 0.769
- 0.502
- 0.535
- 0.815
- 0.65
- 0.635
- 0.835
- 0.927
- 0.794
train_loss:
- 1.959
- 2.45
- 1.638
- 2.192
- 2.04
- 1.382
- 1.789
- 1.179
- 1.665
- 1.566
- 1.131
- 1.039
- 1.449
- 1.018
- 1.427
- 1.35
- 0.542
- 1.394
- 0.577
- 0.572
- 1.319
- 1.26
- 1.602
- 1.201
- 0.831
- 1.237
- 1.165
- 0.813
- 0.779
- 1.11
- 1.132
- 0.762
- 1.134
- 0.791
- 1.075
- 0.76
- 0.763
- 1.073
- 0.736
- 0.711
- 1.349
- 0.735
- 0.702
- 0.712
- 0.7
- 0.709
- 0.687
- 0.387
- 0.992
- 0.98
- 0.977
- 0.39
- 0.962
- 1.209
- 0.674
- 0.651
- 0.648
- 0.895
- 0.38
- 0.941
- 0.911
- 0.899
- 0.634
- 1.152
- 0.898
- 0.622
- 0.867
- 0.374
- 0.865
- 0.857
- 0.599
- 0.337
- 0.599
- 0.852
- 0.819
- 1.087
- 0.83
- 0.577
- 0.836
- 0.822
- 0.586
- 1.058
- 0.578
- 0.786
- 0.57
- 1.04
- 0.816
- 0.341
- 0.82
- 0.551
- 0.319
- 0.807
- 0.753
- 0.564
- 1.232
- 0.594
- 0.751
- 0.958
- 0.569
- 0.97
unequal: 0
verbose: 1
