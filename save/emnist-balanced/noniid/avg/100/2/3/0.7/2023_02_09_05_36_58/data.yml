avg_train_accuracy: 0.81
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03728723404255319
- 0.0627659574468085
- 0.07526595744680852
- 0.09787234042553192
- 0.20574468085106384
- 0.3334042553191489
- 0.36664893617021277
- 0.3705851063829787
- 0.46632978723404256
- 0.43803191489361704
- 0.43579787234042555
- 0.47973404255319146
- 0.43031914893617024
- 0.5278191489361702
- 0.47579787234042553
- 0.485531914893617
- 0.5022872340425532
- 0.5511170212765958
- 0.5545212765957447
- 0.5262765957446809
- 0.5467553191489362
- 0.5467553191489362
- 0.561063829787234
- 0.5939893617021277
- 0.5882978723404255
- 0.5753191489361702
- 0.6008510638297873
- 0.5801595744680851
- 0.6267553191489361
- 0.6023404255319149
- 0.5967553191489362
- 0.6278191489361702
- 0.6338297872340426
- 0.6097340425531915
- 0.5979255319148936
- 0.6294148936170213
- 0.5987765957446809
- 0.6545212765957447
- 0.6367553191489361
- 0.6175
- 0.647127659574468
- 0.6188829787234043
- 0.6533510638297872
- 0.6714361702127659
- 0.6646808510638298
- 0.6427127659574469
- 0.655
- 0.68
- 0.6556382978723404
- 0.6857446808510639
- 0.6685106382978724
- 0.6879787234042554
- 0.6732978723404255
- 0.6698404255319149
- 0.6892021276595744
- 0.6605851063829787
- 0.6784042553191489
- 0.6961702127659575
- 0.6882978723404255
- 0.6759574468085107
- 0.6813297872340426
- 0.7031382978723404
- 0.7083510638297872
- 0.68
- 0.7056914893617021
- 0.6903723404255319
- 0.6854787234042553
- 0.705
- 0.6876595744680851
- 0.7023936170212766
- 0.6982978723404255
- 0.6928723404255319
- 0.6995744680851064
- 0.713404255319149
- 0.6959042553191489
- 0.6961702127659575
- 0.6995212765957447
- 0.7111170212765957
- 0.7047872340425532
- 0.7101063829787234
- 0.7044680851063829
- 0.6997872340425532
- 0.7231382978723404
- 0.7267553191489362
- 0.7108510638297872
- 0.7179255319148936
- 0.7138829787234042
- 0.723404255319149
- 0.7155851063829787
- 0.7113829787234043
- 0.7172340425531915
- 0.7067021276595745
- 0.7166489361702127
- 0.7261702127659575
- 0.7185106382978723
- 0.7296276595744681
- 0.732872340425532
- 0.7248404255319149
- 0.7113829787234043
- 0.7118085106382979
test_loss_list:
- 3.803862148920695
- 3.8078262106577556
- 3.6721271514892577
- 3.528664782842
- 3.2181996218363444
- 2.925614827473958
- 2.7170742988586425
- 2.5986581675211586
- 2.483529313405355
- 2.3736143175760906
- 2.283885491689046
- 2.1817681233088178
- 2.154406162897746
- 2.086694809595744
- 2.0366933997472128
- 1.9311759265263875
- 1.8447942876815795
- 1.7950075181325276
- 1.7677957693735757
- 1.772684555053711
- 1.7133854484558106
- 1.701555905342102
- 1.6538991324106853
- 1.7379347562789917
- 1.7388059059778849
- 1.6163149150212606
- 1.5320022662480672
- 1.511629745165507
- 1.6486118491490682
- 1.5057059367497763
- 1.4647596883773804
- 1.5659329430262248
- 1.5667622725168864
- 1.3990789461135864
- 1.3845410108566285
- 1.345197679201762
- 1.3694153706232706
- 1.2943841298421224
- 1.2747249762217203
- 1.2898985163370769
- 1.2432997131347656
- 1.2809535678227741
- 1.2161978809038798
- 1.20240207195282
- 1.3592272885640462
- 1.191255478064219
- 1.1400982586542765
- 1.157725474834442
- 1.1412993081410725
- 1.136777237256368
- 1.1328133233388265
- 1.1168613608678182
- 1.1215632939338684
- 1.0898116493225098
- 1.0886886644363403
- 1.1059675733248393
- 1.0638326334953307
- 1.069467704296112
- 1.2305974992116293
- 1.0505245359738669
- 1.0209802691141765
- 1.033456027507782
- 1.046354832649231
- 1.0230127803484599
- 1.0233701332410177
- 1.1740529012680054
- 1.0381027388572692
- 1.0283059136072794
- 0.9954767870903015
- 0.9922687260309855
- 0.9743659488360087
- 0.9712955617904663
- 0.963511221408844
- 0.9648103721936544
- 1.291142102877299
- 1.022473517258962
- 1.0068673459688822
- 0.9692708071072896
- 0.9315924104054769
- 0.927165858745575
- 0.9530540919303894
- 0.9334494471549988
- 0.9144258220990499
- 0.9277061669031779
- 0.9004844331741333
- 0.8824865841865539
- 1.047400618394216
- 0.9390291523933411
- 1.0833346009254456
- 0.9120089403788249
- 0.8840526103973388
- 1.0323681902885438
- 0.8871411577860514
- 0.8519930299123128
- 1.0112116535504658
- 0.914302933216095
- 0.8779959869384766
- 0.8519181458155314
- 0.9888420343399048
- 1.0302136913935342
train_accuracy:
- 0.019
- 0.012
- 0.046
- 0.004
- 0.256
- 0.39
- 0.0
- 0.427
- 0.567
- 0.498
- 0.481
- 0.537
- 0.463
- 0.61
- 0.081
- 0.019
- 0.3
- 0.623
- 0.619
- 0.142
- 0.658
- 0.592
- 0.669
- 0.667
- 0.652
- 0.652
- 0.658
- 0.654
- 0.696
- 0.66
- 0.64
- 0.71
- 0.094
- 0.677
- 0.604
- 0.037
- 0.594
- 0.144
- 0.685
- 0.604
- 0.75
- 0.556
- 0.727
- 0.177
- 0.8
- 0.654
- 0.369
- 0.223
- 0.446
- 0.744
- 0.06
- 0.758
- 0.783
- 0.696
- 0.74
- 0.683
- 0.787
- 0.756
- 0.779
- 0.685
- 0.531
- 0.798
- 0.781
- 0.675
- 0.76
- 0.779
- 0.794
- 0.787
- 0.729
- 0.146
- 0.742
- 0.658
- 0.754
- 0.785
- 0.785
- 0.292
- 0.756
- 0.121
- 0.742
- 0.742
- 0.444
- 0.76
- 0.802
- 0.773
- 0.506
- 0.692
- 0.173
- 0.81
- 0.838
- 0.812
- 0.506
- 0.831
- 0.71
- 0.702
- 0.831
- 0.825
- 0.823
- 0.604
- 0.796
- 0.81
train_loss:
- 3.025
- 2.444
- 2.785
- 2.237
- 2.547
- 2.73
- 2.124
- 2.031
- 2.225
- 1.828
- 1.752
- 1.693
- 1.352
- 1.856
- 1.549
- 1.257
- 1.216
- 1.43
- 1.404
- 1.407
- 1.38
- 1.354
- 1.327
- 1.563
- 1.511
- 1.283
- 1.268
- 1.231
- 1.431
- 1.207
- 1.205
- 1.397
- 1.374
- 1.15
- 0.958
- 1.133
- 0.924
- 1.121
- 1.105
- 0.909
- 1.081
- 0.899
- 1.077
- 1.079
- 1.246
- 0.88
- 0.864
- 1.042
- 0.864
- 1.041
- 1.019
- 1.034
- 1.009
- 1.008
- 1.011
- 0.819
- 0.99
- 1.006
- 1.155
- 0.812
- 0.806
- 0.967
- 0.972
- 0.795
- 0.967
- 1.109
- 0.952
- 0.944
- 0.779
- 0.941
- 0.924
- 0.761
- 0.919
- 0.919
- 1.234
- 0.922
- 0.904
- 0.915
- 0.75
- 0.902
- 0.886
- 0.744
- 0.901
- 0.884
- 0.738
- 0.734
- 1.041
- 0.874
- 1.022
- 0.887
- 0.723
- 1.018
- 0.719
- 0.714
- 1.018
- 0.865
- 0.856
- 0.706
- 1.007
- 0.99
unequal: 0
verbose: 1
