avg_train_accuracy: 0.806
avg_train_loss: 0.014
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.041382978723404254
- 0.023723404255319148
- 0.02574468085106383
- 0.06303191489361702
- 0.04180851063829787
- 0.06324468085106383
- 0.041914893617021276
- 0.04186170212765957
- 0.105
- 0.1451063829787234
- 0.22069148936170213
- 0.32622340425531915
- 0.3949468085106383
- 0.44377659574468087
- 0.4749468085106383
- 0.5013829787234042
- 0.5334042553191489
- 0.5388829787234043
- 0.5559042553191489
- 0.5745212765957447
- 0.5842021276595745
- 0.5887765957446809
- 0.5996276595744681
- 0.606436170212766
- 0.6126063829787234
- 0.6186702127659575
- 0.04239361702127659
- 0.05372340425531915
- 0.6021276595744681
- 0.6159574468085106
- 0.6242553191489362
- 0.6325
- 0.6365425531914893
- 0.6411702127659574
- 0.6470212765957447
- 0.0524468085106383
- 0.6477127659574468
- 0.646436170212766
- 0.6566489361702128
- 0.6585106382978724
- 0.16079787234042553
- 0.6587765957446808
- 0.2970744680851064
- 0.22484042553191488
- 0.6615425531914894
- 0.6601063829787234
- 0.6623404255319149
- 0.6673404255319149
- 0.6673936170212766
- 0.08414893617021277
- 0.11664893617021277
- 0.6738297872340425
- 0.06723404255319149
- 0.047180851063829785
- 0.1400531914893617
- 0.6682978723404255
- 0.6653191489361702
- 0.668936170212766
- 0.34127659574468083
- 0.11117021276595744
- 0.685372340425532
- 0.6781914893617021
- 0.6790425531914893
- 0.19228723404255318
- 0.12117021276595745
- 0.6754255319148936
- 0.6802127659574468
- 0.6807446808510639
- 0.14680851063829786
- 0.6883510638297873
- 0.6848936170212766
- 0.6812234042553191
- 0.6822340425531915
- 0.1925
- 0.6986170212765958
- 0.69
- 0.6851063829787234
- 0.6891489361702128
- 0.686595744680851
- 0.21888297872340426
- 0.7002127659574469
- 0.6945744680851064
- 0.6972340425531914
- 0.6929787234042554
- 0.6945744680851064
- 0.36361702127659573
- 0.7017021276595745
- 0.7003723404255319
- 0.7035106382978723
- 0.2322872340425532
- 0.6988829787234042
- 0.6975
- 0.7014893617021276
- 0.4040957446808511
- 0.7112765957446808
- 0.7056914893617021
- 0.7050531914893617
- 0.4324468085106383
- 0.35085106382978726
- 0.7128723404255319
test_loss_list:
- 22.59664873758952
- 3.79333443959554
- 3.782203753789266
- 3.755239311854045
- 22.880891672770183
- 3.741288153330485
- 14.249767748514811
- 19.698412246704102
- 3.6786099688212075
- 3.520457445780436
- 3.2713590463002524
- 2.992566680908203
- 2.7496593697865803
- 2.600812520980835
- 2.4530169614156088
- 2.388579149246216
- 2.35843976020813
- 2.2963934389750165
- 2.2905507961908977
- 2.237481516202291
- 2.2175073448816933
- 2.211765300432841
- 2.173787897427877
- 2.185043651262919
- 2.1727204593022664
- 2.1901437028249107
- 18.43587287902832
- 10.745830586751302
- 1.7464925972620646
- 1.7978983036677043
- 1.835472191174825
- 1.8705816857020061
- 1.8727128664652506
- 1.9264470767974853
- 1.9189995082219442
- 10.811848996480306
- 1.6891584221522014
- 1.7265994071960449
- 1.7512456671396892
- 1.7430784304936726
- 6.739135354359945
- 1.5416358359654745
- 4.845255107879638
- 6.382591063181559
- 1.5364693641662597
- 1.57208154519399
- 1.6221128384272256
- 1.6657525952657064
- 1.6672085205713907
- 9.236044832865398
- 6.265575218200683
- 1.3865317424138388
- 8.493718783060709
- 11.276879323323568
- 5.918670221964518
- 1.1781911532084146
- 1.2749603780110677
- 1.3324881060918172
- 3.9915909894307453
- 6.911050777435303
- 1.1558348449071247
- 1.2161497529347738
- 1.2962298663457235
- 5.504562492370606
- 7.38090171178182
- 1.213036679426829
- 1.2415176900227864
- 1.2796824979782104
- 6.701987692515055
- 1.1748267062505087
- 1.2426177819569906
- 1.2945899407068888
- 1.330573099454244
- 6.060417588551839
- 1.2225394479433696
- 1.3006381781895955
- 1.3377095905939738
- 1.379031647046407
- 1.417189490000407
- 5.4779659970601395
- 1.2745208994547526
- 1.3568200079600017
- 1.340508173306783
- 1.3858559052149455
- 1.4354417785008748
- 3.933649530410767
- 1.2039693442980448
- 1.2688831981023152
- 1.3057286087671915
- 5.01755999247233
- 1.1456844345728556
- 1.2049920852979024
- 1.21654017051061
- 3.558149388631185
- 1.100110665957133
- 1.1771420256296794
- 1.185640323162079
- 3.4922543080647785
- 4.666609128316243
- 1.1608192324638367
train_accuracy:
- 0.96
- 0.023
- 0.044
- 0.075
- 0.985
- 0.031
- 0.979
- 0.969
- 0.054
- 0.119
- 0.242
- 0.352
- 0.513
- 0.49
- 0.612
- 0.617
- 0.615
- 0.667
- 0.673
- 0.673
- 0.654
- 0.665
- 0.698
- 0.679
- 0.69
- 0.746
- 0.998
- 0.994
- 0.685
- 0.723
- 0.708
- 0.765
- 0.715
- 0.727
- 0.744
- 0.992
- 0.733
- 0.765
- 0.744
- 0.74
- 0.994
- 0.746
- 0.994
- 0.998
- 0.767
- 0.75
- 0.806
- 0.754
- 0.773
- 0.998
- 0.994
- 0.781
- 1.0
- 1.0
- 0.996
- 0.742
- 0.756
- 0.767
- 0.998
- 1.0
- 0.765
- 0.779
- 0.773
- 1.0
- 1.0
- 0.771
- 0.79
- 0.787
- 0.994
- 0.794
- 0.821
- 0.825
- 0.817
- 0.998
- 0.777
- 0.802
- 0.817
- 0.833
- 0.829
- 0.998
- 0.794
- 0.831
- 0.79
- 0.806
- 0.84
- 0.998
- 0.806
- 0.831
- 0.802
- 0.998
- 0.808
- 0.842
- 0.804
- 0.998
- 0.79
- 0.808
- 0.812
- 0.998
- 1.0
- 0.806
train_loss:
- 0.813
- 4.125
- 3.839
- 3.805
- 1.081
- 4.087
- 0.545
- 0.755
- 4.053
- 3.711
- 3.528
- 3.233
- 2.962
- 2.739
- 2.54
- 2.418
- 2.301
- 2.161
- 2.033
- 2.054
- 2.025
- 1.918
- 1.896
- 1.886
- 1.79
- 1.742
- 0.669
- 0.697
- 2.352
- 1.82
- 1.714
- 1.632
- 1.657
- 1.574
- 1.57
- 0.562
- 1.861
- 1.537
- 1.468
- 1.505
- 0.311
- 1.694
- 0.167
- 0.045
- 1.643
- 1.486
- 1.406
- 1.382
- 1.402
- 0.357
- 0.341
- 1.757
- 0.62
- 0.116
- 0.336
- 1.841
- 1.427
- 1.505
- 0.197
- 0.35
- 1.686
- 1.377
- 1.3
- 0.361
- 0.082
- 1.545
- 1.384
- 1.337
- 0.261
- 1.497
- 1.296
- 1.25
- 1.227
- 0.214
- 1.463
- 1.289
- 1.239
- 1.211
- 1.15
- 0.225
- 1.533
- 1.158
- 1.252
- 1.227
- 1.127
- 0.31
- 1.373
- 1.119
- 1.213
- 0.447
- 1.375
- 1.113
- 1.296
- 0.239
- 1.388
- 1.172
- 1.186
- 0.178
- 0.041
- 1.43
unequal: 0
verbose: 1
