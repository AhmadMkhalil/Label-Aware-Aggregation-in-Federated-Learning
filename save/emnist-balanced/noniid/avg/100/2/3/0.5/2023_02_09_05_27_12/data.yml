avg_train_accuracy: 0.742
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04170212765957447
- 0.03973404255319149
- 0.051968085106382976
- 0.08372340425531914
- 0.25138297872340426
- 0.3424468085106383
- 0.3196276595744681
- 0.43542553191489364
- 0.39872340425531916
- 0.23441489361702128
- 0.345
- 0.4376063829787234
- 0.35840425531914893
- 0.4979787234042553
- 0.4867021276595745
- 0.4397872340425532
- 0.325
- 0.4812234042553192
- 0.5227659574468085
- 0.46914893617021275
- 0.49
- 0.4856382978723404
- 0.4966489361702128
- 0.591968085106383
- 0.4157446808510638
- 0.5454255319148936
- 0.5413829787234042
- 0.5996276595744681
- 0.41606382978723405
- 0.6029787234042553
- 0.55
- 0.6086170212765958
- 0.5758510638297872
- 0.6295744680851064
- 0.5975531914893617
- 0.5894148936170213
- 0.6267553191489361
- 0.5956914893617021
- 0.6152127659574468
- 0.6160106382978724
- 0.6461170212765958
- 0.6344148936170213
- 0.6516489361702128
- 0.6264893617021277
- 0.645531914893617
- 0.5604787234042553
- 0.651436170212766
- 0.6602127659574468
- 0.6551063829787234
- 0.6506382978723404
- 0.668031914893617
- 0.5925531914893617
- 0.6649468085106383
- 0.6599468085106382
- 0.6651063829787234
- 0.6687234042553192
- 0.6532446808510638
- 0.6806382978723404
- 0.6752659574468085
- 0.6637765957446808
- 0.6780851063829787
- 0.6902659574468085
- 0.6857978723404256
- 0.6831914893617022
- 0.676063829787234
- 0.6367553191489361
- 0.6873404255319149
- 0.6841489361702128
- 0.6858510638297872
- 0.6871276595744681
- 0.6979255319148936
- 0.6971276595744681
- 0.6910106382978723
- 0.6925531914893617
- 0.6901595744680851
- 0.6807446808510639
- 0.6918617021276596
- 0.7103723404255319
- 0.6964361702127659
- 0.6983510638297873
- 0.69
- 0.6945744680851064
- 0.6957446808510638
- 0.6870212765957446
- 0.6636702127659575
- 0.711063829787234
- 0.6969148936170213
- 0.6964893617021276
- 0.7031382978723404
- 0.7129255319148936
- 0.7156914893617021
- 0.701063829787234
- 0.7176063829787234
- 0.7175
- 0.7196276595744681
- 0.6801063829787234
- 0.7251063829787234
- 0.7228191489361702
- 0.704095744680851
- 0.7102659574468085
test_loss_list:
- 3.7881565443674723
- 3.8000821622212726
- 3.7684968185424803
- 3.516613804499308
- 3.12065136273702
- 2.894638754526774
- 2.7460600407918294
- 2.6262043952941894
- 2.565326484044393
- 2.767568031946818
- 2.4125223191579184
- 2.2575925890604656
- 2.372703383763631
- 2.119684181213379
- 2.0812289269765216
- 2.087852462132772
- 2.3231187502543134
- 1.8800100247065226
- 2.0023870531717938
- 1.9300155019760132
- 1.8834523757298787
- 1.786265614827474
- 1.7966311279932659
- 1.9263155555725098
- 1.968000456492106
- 1.6205925051371257
- 1.582561772664388
- 1.6267393048604328
- 1.9436220677693685
- 1.5662095975875854
- 1.6002539952596029
- 1.5311252291997273
- 1.5184373792012533
- 1.7371745586395264
- 1.5043464040756225
- 1.4158771165211996
- 1.536016090710958
- 1.3824213600158692
- 1.3369472455978393
- 1.343122673034668
- 1.4099942334493
- 1.4664739306767782
- 1.3972188965479533
- 1.2935654576619466
- 1.3533762232462565
- 1.438316666285197
- 1.2991380834579467
- 1.5538073698679606
- 1.3467239824930828
- 1.2291719007492066
- 1.3082926003138224
- 1.3044420862197876
- 1.1275924444198608
- 1.1599774090449015
- 1.2337482047080994
- 1.2911679983139037
- 1.1897083918253581
- 1.101330103079478
- 1.2762320931752522
- 1.1405265871683756
- 1.4481325817108155
- 1.1409209791819255
- 1.1528443559010824
- 1.2659989023208618
- 1.0984390473365784
- 1.1741755652427672
- 1.0179447468121847
- 1.368548239072164
- 1.0798074952761332
- 1.3663179477055867
- 1.0789955830574036
- 1.0717598915100097
- 1.1450601498285928
- 1.0963782914479574
- 1.3602082951863608
- 1.0586359945933024
- 1.135459546248118
- 0.9861718066533407
- 1.1254950467745464
- 1.1711769684155782
- 1.1016904226938884
- 1.3479065863291422
- 1.1577363459269205
- 1.0608020242055256
- 1.07785706837972
- 1.0620733586947124
- 1.3016108433405558
- 0.9856669441858927
- 1.106660103003184
- 1.0751487358411154
- 1.010336450735728
- 1.0187853733698526
- 0.9508636784553528
- 0.9745310187339783
- 1.0689696566263835
- 0.9950925874710083
- 0.9189743463198344
- 1.0462350495656332
- 1.2622541395823161
- 0.9287928422292073
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.046
- 0.294
- 0.427
- 0.358
- 0.544
- 0.44
- 0.688
- 0.385
- 0.527
- 0.075
- 0.533
- 0.002
- 0.46
- 0.465
- 0.188
- 0.035
- 0.19
- 0.487
- 0.46
- 0.531
- 0.69
- 0.375
- 0.592
- 0.519
- 0.706
- 0.429
- 0.681
- 0.4
- 0.692
- 0.588
- 0.715
- 0.615
- 0.175
- 0.683
- 0.606
- 0.504
- 0.629
- 0.717
- 0.035
- 0.715
- 0.635
- 0.76
- 0.54
- 0.758
- 0.74
- 0.775
- 0.683
- 0.14
- 0.61
- 0.296
- 0.45
- 0.754
- 0.746
- 0.675
- 0.454
- 0.756
- 0.692
- 0.794
- 0.46
- 0.573
- 0.758
- 0.698
- 0.696
- 0.3
- 0.775
- 0.715
- 0.787
- 0.719
- 0.646
- 0.775
- 0.719
- 0.802
- 0.727
- 0.785
- 0.75
- 0.296
- 0.79
- 0.804
- 0.787
- 0.131
- 0.477
- 0.794
- 0.8
- 0.84
- 0.748
- 0.79
- 0.792
- 0.752
- 0.804
- 0.79
- 0.783
- 0.779
- 0.487
- 0.571
- 0.823
- 0.817
- 0.742
train_loss:
- 3.222
- 2.535
- 2.394
- 2.319
- 3.434
- 3.115
- 2.382
- 2.726
- 2.13
- 1.221
- 1.578
- 1.948
- 1.493
- 1.887
- 1.81
- 1.387
- 0.984
- 1.346
- 1.713
- 1.298
- 1.262
- 1.275
- 1.25
- 1.926
- 0.899
- 1.206
- 1.176
- 1.488
- 0.842
- 1.483
- 1.132
- 1.438
- 1.098
- 1.709
- 1.081
- 1.092
- 1.356
- 1.058
- 1.032
- 1.018
- 1.307
- 1.309
- 1.285
- 0.99
- 1.266
- 0.713
- 1.268
- 1.516
- 1.236
- 0.972
- 1.208
- 0.69
- 0.929
- 0.903
- 1.185
- 1.194
- 0.911
- 0.916
- 1.172
- 0.899
- 1.404
- 0.909
- 0.884
- 1.136
- 0.893
- 0.625
- 0.872
- 1.357
- 0.861
- 1.343
- 0.874
- 0.834
- 1.09
- 0.827
- 1.318
- 0.859
- 1.067
- 0.848
- 1.062
- 1.051
- 1.046
- 1.266
- 1.034
- 0.815
- 0.577
- 1.038
- 1.244
- 0.816
- 1.025
- 1.019
- 0.798
- 1.028
- 0.792
- 0.777
- 0.991
- 0.574
- 0.781
- 0.986
- 1.205
- 0.789
unequal: 0
verbose: 1
