avg_train_accuracy: 0.956
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.036382978723404256
- 0.04148936170212766
- 0.0398936170212766
- 0.05723404255319149
- 0.07739361702127659
- 0.06367021276595744
- 0.0601063829787234
- 0.06265957446808511
- 0.06021276595744681
- 0.09234042553191489
- 0.10063829787234042
- 0.09058510638297872
- 0.1325531914893617
- 0.0922340425531915
- 0.12521276595744682
- 0.2994148936170213
- 0.1102659574468085
- 0.14388297872340425
- 0.11079787234042553
- 0.09808510638297872
- 0.1723936170212766
- 0.4001595744680851
- 0.19164893617021275
- 0.17404255319148937
- 0.23351063829787233
- 0.14856382978723404
- 0.11962765957446808
- 0.44824468085106384
- 0.3049468085106383
- 0.22632978723404254
- 0.09771276595744681
- 0.2890957446808511
- 0.29186170212765955
- 0.4944148936170213
- 0.12936170212765957
- 0.2859042553191489
- 0.15345744680851064
- 0.11686170212765958
- 0.2963297872340426
- 0.13085106382978723
- 0.12920212765957448
- 0.13882978723404255
- 0.52
- 0.32622340425531915
- 0.14425531914893616
- 0.15111702127659574
- 0.15978723404255318
- 0.5237234042553192
- 0.1981382978723404
- 0.31659574468085105
- 0.17638297872340425
- 0.12888297872340426
- 0.15893617021276596
- 0.5242553191489362
- 0.5181382978723404
- 0.2632978723404255
- 0.13037234042553192
- 0.39106382978723403
- 0.16313829787234044
- 0.37574468085106383
- 0.4015957446808511
- 0.2026063829787234
- 0.4313297872340425
- 0.1747340425531915
- 0.528031914893617
- 0.45074468085106384
- 0.43590425531914895
- 0.22079787234042553
- 0.40037234042553194
- 0.5369148936170213
- 0.24053191489361703
- 0.3715425531914894
- 0.47904255319148936
- 0.22941489361702128
- 0.21920212765957447
- 0.17851063829787234
- 0.4129255319148936
- 0.4732446808510638
- 0.4848936170212766
- 0.4726595744680851
- 0.48138297872340424
- 0.573404255319149
- 0.48148936170212764
- 0.4520212765957447
- 0.2173936170212766
- 0.1748936170212766
- 0.19553191489361701
- 0.40622340425531916
- 0.4929787234042553
- 0.49638297872340426
- 0.214468085106383
- 0.18132978723404256
- 0.4454787234042553
- 0.5761170212765957
- 0.24319148936170212
- 0.40824468085106386
- 0.5351595744680852
- 0.4524468085106383
- 0.4753723404255319
- 0.43340425531914895
test_loss_list:
- 4.498828245798747
- 8.775534553527832
- 9.307892506917318
- 5.244262752532959
- 8.845114758809407
- 4.676542212168376
- 4.669066975911458
- 4.260846665700277
- 5.192205181121826
- 7.3820599238077795
- 8.191971626281738
- 7.777969519297282
- 6.391877314249674
- 4.012177998224894
- 3.457378835678101
- 2.706810105641683
- 3.53216916402181
- 3.20760126431783
- 3.818092622756958
- 5.781769205729167
- 3.132622474034627
- 2.555048360824585
- 3.2846617762247723
- 3.600012747446696
- 2.6933952140808106
- 3.307938273747762
- 5.993565737406413
- 2.173001012802124
- 2.585280402501424
- 3.208061803181966
- 7.69803550084432
- 2.4810159683227537
- 2.644598903656006
- 2.118138952255249
- 5.860974210103353
- 2.923233429590861
- 4.963708661397298
- 7.847760238647461
- 2.303913240432739
- 5.5211625734965
- 7.092765267690023
- 6.744376099904378
- 1.8720876121520995
- 2.5383559195200602
- 5.2757018915812175
- 5.503554318745931
- 6.021066462198894
- 1.7385574388504028
- 3.735597667694092
- 2.2096721808115642
- 4.710465742746989
- 6.230057652791341
- 6.08216521581014
- 1.6448008489608765
- 1.768279749552409
- 3.292125562032064
- 6.84981061299642
- 2.181602257092794
- 5.041920852661133
- 2.155187732378642
- 1.9568234697977702
- 4.201622362136841
- 1.9531864643096923
- 4.668758792877197
- 2.2905704673131306
- 1.9904243818918863
- 1.9129335610071818
- 3.9279538440704345
- 1.9960795561472575
- 2.3567557175954184
- 2.9753763389587404
- 2.196470897992452
- 1.603032684326172
- 3.715498555501302
- 3.8593707052866617
- 4.5700754547119145
- 2.0158968496322633
- 1.7250462611516317
- 1.6999537531534832
- 1.709485411643982
- 1.761825394630432
- 1.5435086552302042
- 1.71542129834493
- 1.7659965070088703
- 3.776627337137858
- 4.9236592737833655
- 5.230281092325846
- 2.2268805758158368
- 1.536018174489339
- 1.636293109258016
- 4.227822634379069
- 5.2446789487202965
- 1.9552221473058065
- 1.5394492657979328
- 3.6052450625101726
- 2.083227688471476
- 1.4443085432052611
- 1.8653720490137735
- 1.8306656058629354
- 1.8783103609085083
train_accuracy:
- 0.0
- 0.981
- 0.973
- 0.99
- 0.994
- 0.885
- 0.977
- 0.002
- 0.01
- 0.892
- 0.946
- 0.671
- 0.91
- 0.944
- 0.044
- 0.354
- 0.717
- 0.91
- 0.835
- 0.894
- 0.906
- 0.527
- 0.171
- 0.973
- 0.94
- 0.077
- 0.685
- 0.604
- 0.873
- 0.19
- 0.727
- 0.971
- 0.969
- 0.444
- 0.954
- 0.983
- 0.756
- 0.748
- 0.925
- 0.954
- 0.933
- 0.892
- 0.433
- 0.86
- 0.933
- 0.777
- 0.96
- 0.352
- 0.988
- 0.95
- 0.954
- 0.879
- 0.985
- 0.704
- 0.685
- 0.965
- 0.883
- 0.898
- 0.971
- 0.354
- 0.969
- 0.946
- 0.408
- 0.921
- 0.76
- 0.963
- 0.969
- 0.988
- 0.373
- 0.779
- 0.833
- 0.985
- 0.923
- 0.748
- 0.871
- 0.933
- 0.981
- 0.981
- 0.956
- 0.946
- 0.979
- 0.642
- 0.983
- 0.938
- 0.958
- 0.979
- 0.929
- 0.988
- 0.96
- 0.983
- 0.838
- 0.979
- 0.392
- 0.752
- 0.988
- 0.44
- 0.879
- 0.979
- 0.475
- 0.956
train_loss:
- 1.788
- 0.477
- 0.47
- 1.446
- 0.271
- 1.443
- 1.312
- 1.249
- 0.359
- 0.248
- 0.178
- 0.22
- 0.232
- 1.237
- 1.09
- 1.853
- 1.006
- 0.957
- 0.926
- 0.212
- 0.887
- 1.536
- 0.887
- 0.828
- 0.837
- 0.818
- 0.17
- 1.458
- 0.783
- 0.749
- 0.148
- 0.839
- 0.739
- 1.297
- 0.21
- 0.688
- 0.208
- 0.105
- 0.781
- 0.144
- 0.112
- 0.127
- 1.325
- 0.645
- 0.146
- 0.159
- 0.136
- 1.256
- 0.175
- 0.673
- 0.109
- 0.088
- 0.087
- 1.272
- 1.13
- 0.148
- 0.103
- 0.654
- 0.1
- 0.625
- 0.634
- 0.123
- 0.613
- 0.089
- 1.635
- 0.609
- 0.584
- 0.076
- 0.614
- 1.506
- 0.262
- 0.597
- 0.588
- 0.138
- 0.128
- 0.104
- 0.61
- 0.555
- 0.579
- 0.55
- 0.532
- 0.977
- 0.528
- 0.541
- 0.141
- 0.103
- 0.089
- 0.535
- 0.554
- 0.516
- 0.106
- 0.082
- 0.551
- 0.945
- 0.101
- 0.502
- 0.541
- 0.524
- 0.477
- 0.503
unequal: 0
verbose: 1
