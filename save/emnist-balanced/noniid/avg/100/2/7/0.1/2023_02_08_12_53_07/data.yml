avg_train_accuracy: 0.69
avg_train_loss: 0.023
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04148936170212766
- 0.043617021276595745
- 0.03819148936170213
- 0.041914893617021276
- 0.042074468085106384
- 0.03047872340425532
- 0.04170212765957447
- 0.042074468085106384
- 0.04212765957446808
- 0.04638297872340426
- 0.04170212765957447
- 0.04170212765957447
- 0.042340425531914895
- 0.08882978723404256
- 0.041648936170212765
- 0.04202127659574468
- 0.08648936170212766
- 0.12526595744680852
- 0.1621276595744681
- 0.0425
- 0.23590425531914894
- 0.04409574468085106
- 0.04367021276595745
- 0.29601063829787233
- 0.05473404255319149
- 0.04824468085106383
- 0.04069148936170213
- 0.04212765957446808
- 0.05218085106382979
- 0.3300531914893617
- 0.06547872340425531
- 0.07367021276595745
- 0.06691489361702127
- 0.07356382978723404
- 0.05223404255319149
- 0.04090425531914894
- 0.06744680851063829
- 0.33861702127659576
- 0.38101063829787235
- 0.39095744680851063
- 0.052819148936170214
- 0.4157446808510638
- 0.13808510638297872
- 0.4372340425531915
- 0.07968085106382979
- 0.07074468085106383
- 0.4451063829787234
- 0.051808510638297875
- 0.4574468085106383
- 0.46367021276595743
- 0.4724468085106383
- 0.07367021276595745
- 0.08132978723404255
- 0.4899468085106383
- 0.0748936170212766
- 0.07537234042553191
- 0.07909574468085107
- 0.08851063829787234
- 0.08106382978723405
- 0.5078723404255319
- 0.13585106382978723
- 0.08441489361702127
- 0.09659574468085107
- 0.5126595744680851
- 0.19196808510638297
- 0.09579787234042553
- 0.07138297872340425
- 0.09452127659574468
- 0.08287234042553192
- 0.07845744680851063
- 0.09367021276595745
- 0.08712765957446808
- 0.1000531914893617
- 0.08457446808510638
- 0.10569148936170213
- 0.11611702127659575
- 0.1322340425531915
- 0.12372340425531915
- 0.11930851063829787
- 0.1175
- 0.5564361702127659
- 0.14180851063829789
- 0.16792553191489362
- 0.5256914893617022
- 0.15898936170212766
- 0.5276595744680851
- 0.24393617021276595
- 0.23095744680851063
- 0.5323404255319149
- 0.22122340425531914
- 0.09888297872340425
- 0.14904255319148937
- 0.1201063829787234
- 0.1025531914893617
- 0.11526595744680851
- 0.10127659574468086
- 0.0747340425531915
- 0.09882978723404255
- 0.09670212765957446
- 0.5643085106382979
test_loss_list:
- 19.571066106160483
- 3.7893855412801107
- 19.73595369974772
- 27.15289764404297
- 34.265103352864585
- 19.356433385213215
- 19.222806040445963
- 27.88453608194987
- 17.697439092000327
- 14.120821812947591
- 17.43813191731771
- 20.80418332417806
- 17.79290288289388
- 3.7569474760691324
- 10.87679037729899
- 11.904872868855794
- 3.7045448048909506
- 3.59868852297465
- 3.4437315972646076
- 16.872362111409505
- 3.2213740984598798
- 10.648453420003255
- 9.397807693481445
- 2.9986560440063474
- 9.40128901163737
- 9.189209734598796
- 11.247453435262043
- 14.057817637125652
- 11.435193138122559
- 2.754042946497599
- 6.971158644358317
- 9.782942161560058
- 12.20454922993978
- 8.496538963317871
- 12.016288528442383
- 16.216871617635093
- 7.867546933492025
- 2.6374909273783365
- 2.4826266288757326
- 2.4658785406748454
- 9.484779218037923
- 2.431179332733154
- 6.012427679697672
- 2.37141406695048
- 7.729812463124593
- 8.408406899770101
- 2.308788210550944
- 10.101283416748046
- 2.293650312423706
- 2.3647027842203774
- 2.3748509820302326
- 9.25296272277832
- 7.926725508371989
- 2.316910581588745
- 10.2434241994222
- 8.17624024073283
- 7.904633833567302
- 7.866099815368653
- 8.44777598698934
- 2.006308946609497
- 6.191564159393311
- 8.53693780263265
- 7.273343289693196
- 1.981986338297526
- 5.5359621938069665
- 7.595584837595622
- 8.535312455495198
- 7.87543586730957
- 6.97016757329305
- 7.510664126078288
- 6.366791051228841
- 6.130664221445719
- 6.78495636622111
- 8.66454220453898
- 6.6574695078531905
- 6.451348559061686
- 7.627697734832764
- 8.859597104390462
- 7.248905245463053
- 6.387510185241699
- 1.5832341146469116
- 5.889191201527914
- 4.864846013387044
- 1.562420875231425
- 5.7519521840413415
- 1.6578422371546429
- 4.239647022883097
- 4.472758502960205
- 1.6403748321533203
- 4.451811180114746
- 6.7805229123433435
- 4.660997982025147
- 6.583044611612956
- 7.804443683624267
- 8.231975542704264
- 7.165538851420084
- 9.13804822921753
- 6.268620643615723
- 7.5310639444986975
- 1.3915161259969075
train_accuracy:
- 0.983
- 0.088
- 0.815
- 0.971
- 0.979
- 0.415
- 0.979
- 0.99
- 0.99
- 0.946
- 0.985
- 0.988
- 0.988
- 0.0
- 0.977
- 0.983
- 0.01
- 0.129
- 0.19
- 0.994
- 0.335
- 0.994
- 0.983
- 0.385
- 0.994
- 0.996
- 0.925
- 0.983
- 0.965
- 0.444
- 0.994
- 0.977
- 0.981
- 0.998
- 0.988
- 0.963
- 0.998
- 0.431
- 0.492
- 0.565
- 0.969
- 0.562
- 0.998
- 0.66
- 0.975
- 0.983
- 0.606
- 0.99
- 0.669
- 0.662
- 0.692
- 0.99
- 0.99
- 0.708
- 0.981
- 0.99
- 0.998
- 0.992
- 0.979
- 0.679
- 0.981
- 0.988
- 0.99
- 0.683
- 0.996
- 0.992
- 0.99
- 0.99
- 0.998
- 0.99
- 0.983
- 0.998
- 0.988
- 0.99
- 0.994
- 0.998
- 0.988
- 0.99
- 0.99
- 0.985
- 0.638
- 0.99
- 0.988
- 0.679
- 0.992
- 0.685
- 0.998
- 0.985
- 0.71
- 0.981
- 0.992
- 0.994
- 0.998
- 0.998
- 0.994
- 0.992
- 0.992
- 0.988
- 0.99
- 0.69
train_loss:
- 0.743
- 4.066
- 1.205
- 1.199
- 0.137
- 2.105
- 1.343
- 0.149
- 1.277
- 0.91
- 0.82
- 0.121
- 0.948
- 4.223
- 0.839
- 0.652
- 4.122
- 3.774
- 3.605
- 0.566
- 3.688
- 0.284
- 0.435
- 3.391
- 0.261
- 0.685
- 1.174
- 0.746
- 0.418
- 3.456
- 0.365
- 0.524
- 0.09
- 0.417
- 0.484
- 1.436
- 0.493
- 3.439
- 2.751
- 2.439
- 0.478
- 2.566
- 0.326
- 2.442
- 0.383
- 0.528
- 2.495
- 0.485
- 2.271
- 1.916
- 1.923
- 0.342
- 0.367
- 2.165
- 0.794
- 0.513
- 0.535
- 0.504
- 0.401
- 2.408
- 0.518
- 0.137
- 0.482
- 2.189
- 0.44
- 0.292
- 0.416
- 0.161
- 0.378
- 0.628
- 0.542
- 0.252
- 0.221
- 0.371
- 0.162
- 0.349
- 0.251
- 0.063
- 0.23
- 0.415
- 2.732
- 0.572
- 0.254
- 2.153
- 0.35
- 1.919
- 0.268
- 0.229
- 1.933
- 0.356
- 0.415
- 0.264
- 0.363
- 0.052
- 0.291
- 0.484
- 0.12
- 0.302
- 0.2
- 2.322
unequal: 0
verbose: 1
