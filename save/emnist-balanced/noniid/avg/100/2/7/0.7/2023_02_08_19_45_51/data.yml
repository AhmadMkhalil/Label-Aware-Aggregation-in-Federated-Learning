avg_train_accuracy: 0.421
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022872340425531913
- 0.047446808510638296
- 0.0599468085106383
- 0.09723404255319149
- 0.09452127659574468
- 0.11984042553191489
- 0.12664893617021278
- 0.12861702127659574
- 0.15978723404255318
- 0.1822872340425532
- 0.2509574468085106
- 0.19946808510638298
- 0.2631914893617021
- 0.26835106382978724
- 0.21728723404255318
- 0.19595744680851063
- 0.2850531914893617
- 0.18345744680851064
- 0.3268617021276596
- 0.3809574468085106
- 0.2352127659574468
- 0.39904255319148935
- 0.29
- 0.275531914893617
- 0.29531914893617023
- 0.290531914893617
- 0.3565957446808511
- 0.19585106382978723
- 0.3676063829787234
- 0.25601063829787235
- 0.3348404255319149
- 0.2077127659574468
- 0.38148936170212766
- 0.3040425531914894
- 0.4668617021276596
- 0.2767553191489362
- 0.38148936170212766
- 0.33180851063829786
- 0.46622340425531916
- 0.30590425531914894
- 0.38265957446808513
- 0.34372340425531916
- 0.48675531914893616
- 0.29367021276595745
- 0.28585106382978726
- 0.40361702127659577
- 0.4913297872340426
- 0.3601063829787234
- 0.38382978723404254
- 0.2728191489361702
- 0.3059574468085106
- 0.41175531914893615
- 0.3925531914893617
- 0.3621276595744681
- 0.523031914893617
- 0.36340425531914894
- 0.30425531914893617
- 0.45138297872340427
- 0.5026595744680851
- 0.271968085106383
- 0.4709042553191489
- 0.42484042553191487
- 0.5400531914893617
- 0.3917553191489362
- 0.4434574468085106
- 0.31553191489361704
- 0.5530851063829787
- 0.4358510638297872
- 0.4027127659574468
- 0.5692553191489361
- 0.5342021276595744
- 0.5585638297872341
- 0.31132978723404253
- 0.33085106382978724
- 0.5748936170212766
- 0.42340425531914894
- 0.49138297872340425
- 0.47452127659574467
- 0.5828723404255319
- 0.4428723404255319
- 0.360531914893617
- 0.47058510638297874
- 0.4354787234042553
- 0.5955851063829787
- 0.5548936170212766
- 0.5023936170212766
- 0.49632978723404253
- 0.5004255319148936
- 0.5985106382978723
- 0.46654255319148935
- 0.5995212765957447
- 0.583936170212766
- 0.47952127659574467
- 0.6109042553191489
- 0.48829787234042554
- 0.49117021276595746
- 0.5001063829787235
- 0.36484042553191487
- 0.5187234042553192
- 0.5128723404255319
test_loss_list:
- 4.088601373036703
- 3.922586145401001
- 4.111905215581258
- 4.001612415313721
- 3.957021147410075
- 3.4213071886698403
- 3.7519952233632408
- 3.700398661295573
- 3.4102226225535075
- 2.971667461395264
- 2.7975502904256184
- 3.0239859104156492
- 2.7037520694732664
- 2.7048412958780923
- 2.902384853363037
- 3.136716858545939
- 2.574303773244222
- 3.6850700187683105
- 2.4600420792897544
- 2.29724445660909
- 3.003298447926839
- 2.2712934112548826
- 2.4985786469777427
- 2.549668992360433
- 2.482637322743734
- 2.541306406656901
- 2.2138280073801675
- 3.9034549681345623
- 2.3044888973236084
- 2.95972793896993
- 2.2698792775472003
- 3.7446998755137124
- 2.0934742863972984
- 2.591335045496623
- 1.9439183108011882
- 2.695186834335327
- 2.1007170788447063
- 2.388067197799683
- 1.8706215604146321
- 2.644726428985596
- 2.095773131052653
- 2.3174097220102947
- 1.7784754546483357
- 2.815032656987508
- 2.9848123582204185
- 2.0558613952000937
- 1.747850333849589
- 2.2584952290852867
- 2.2049221483866375
- 3.2624984073638914
- 2.7198275407155355
- 1.9672959311803182
- 2.103751056989034
- 2.2644651635487874
- 1.599280646642049
- 2.2238377412160237
- 2.991766087214152
- 1.826680024464925
- 1.6107855717341104
- 3.4410637919108074
- 1.7776918029785156
- 1.963053207397461
- 1.5285855038960774
- 2.136007874806722
- 1.8669449933369955
- 3.03660298983256
- 1.4833511050542196
- 1.9977045408884684
- 2.077196224530538
- 1.4349162562688191
- 1.520233284632365
- 1.4651697556177774
- 3.005016326904297
- 2.849337501525879
- 1.4144047419230144
- 2.0090588315327964
- 1.7318686819076539
- 1.7761416673660277
- 1.3542865022023518
- 1.9724862019220988
- 2.6772391478220623
- 1.7850002654393513
- 1.9382115077972413
- 1.2913539743423461
- 1.4296587657928468
- 1.6961410665512084
- 1.7079983806610108
- 1.6891886774698894
- 1.2673198906580607
- 1.8024124670028687
- 1.273736178080241
- 1.3229380575815837
- 1.836190676689148
- 1.2578244129816691
- 1.8414345296223957
- 1.6876088714599609
- 1.6379048697153726
- 2.791096611022949
- 1.5855870898564657
- 1.6175469732284546
train_accuracy:
- 0.967
- 0.002
- 0.0
- 0.815
- 0.017
- 0.485
- 0.148
- 0.006
- 0.454
- 0.935
- 0.29
- 0.042
- 0.325
- 0.279
- 0.423
- 0.067
- 0.569
- 0.906
- 0.49
- 0.565
- 0.115
- 0.477
- 0.748
- 0.225
- 0.373
- 0.206
- 0.337
- 0.64
- 0.335
- 0.131
- 0.677
- 0.61
- 0.217
- 0.546
- 0.415
- 0.496
- 0.665
- 0.365
- 0.531
- 0.642
- 0.252
- 0.731
- 0.531
- 0.144
- 0.269
- 0.688
- 0.529
- 0.362
- 0.94
- 0.621
- 0.356
- 0.873
- 0.823
- 0.723
- 0.281
- 0.246
- 0.681
- 0.606
- 0.465
- 0.073
- 0.733
- 0.321
- 0.667
- 0.3
- 0.744
- 0.885
- 0.733
- 0.312
- 0.877
- 0.319
- 0.646
- 0.71
- 0.527
- 0.606
- 0.808
- 0.515
- 0.377
- 0.942
- 0.615
- 0.325
- 0.65
- 0.856
- 0.838
- 0.535
- 0.535
- 0.908
- 0.94
- 0.398
- 0.356
- 0.94
- 0.65
- 0.588
- 0.723
- 0.329
- 0.821
- 0.404
- 0.675
- 0.963
- 0.442
- 0.421
train_loss:
- 1.821
- 1.868
- 1.243
- 1.166
- 1.116
- 1.02
- 0.629
- 0.573
- 0.963
- 0.923
- 1.216
- 0.825
- 1.14
- 1.1
- 0.757
- 0.463
- 0.765
- 0.446
- 0.751
- 1.009
- 0.697
- 0.99
- 0.698
- 0.693
- 0.666
- 0.652
- 0.644
- 0.375
- 0.662
- 0.661
- 0.656
- 0.389
- 0.629
- 0.61
- 0.874
- 0.624
- 0.615
- 0.616
- 0.836
- 0.606
- 0.603
- 0.594
- 0.809
- 0.587
- 0.347
- 0.575
- 0.803
- 0.574
- 0.554
- 0.33
- 0.325
- 0.549
- 0.541
- 0.542
- 0.753
- 0.526
- 0.313
- 0.524
- 0.739
- 0.316
- 0.537
- 0.523
- 0.734
- 0.514
- 0.508
- 0.299
- 0.718
- 0.509
- 0.506
- 0.704
- 0.686
- 0.684
- 0.3
- 0.289
- 0.691
- 0.479
- 0.485
- 0.476
- 0.675
- 0.48
- 0.275
- 0.473
- 0.457
- 0.657
- 0.652
- 0.462
- 0.46
- 0.457
- 0.633
- 0.455
- 0.634
- 0.636
- 0.446
- 0.632
- 0.446
- 0.445
- 0.446
- 0.26
- 0.439
- 0.444
unequal: 0
verbose: 1
