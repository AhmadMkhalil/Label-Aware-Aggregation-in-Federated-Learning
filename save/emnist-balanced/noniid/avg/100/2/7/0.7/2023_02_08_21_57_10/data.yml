avg_train_accuracy: 0.879
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03728723404255319
- 0.04468085106382979
- 0.05696808510638298
- 0.1297340425531915
- 0.11425531914893618
- 0.1422340425531915
- 0.2074468085106383
- 0.24148936170212765
- 0.24111702127659573
- 0.2912234042553192
- 0.25601063829787235
- 0.3596808510638298
- 0.3398936170212766
- 0.27904255319148935
- 0.18579787234042552
- 0.3672340425531915
- 0.30877659574468086
- 0.261968085106383
- 0.269468085106383
- 0.3280851063829787
- 0.3116489361702128
- 0.3769148936170213
- 0.3682446808510638
- 0.25824468085106383
- 0.38180851063829785
- 0.3652659574468085
- 0.33856382978723404
- 0.42851063829787234
- 0.44648936170212766
- 0.29531914893617023
- 0.3852659574468085
- 0.3777659574468085
- 0.3227127659574468
- 0.39170212765957446
- 0.3497340425531915
- 0.38824468085106384
- 0.4077659574468085
- 0.48106382978723405
- 0.4675531914893617
- 0.37398936170212765
- 0.4269148936170213
- 0.3972340425531915
- 0.32132978723404254
- 0.38898936170212767
- 0.41569148936170214
- 0.42021276595744683
- 0.44648936170212766
- 0.4067021276595745
- 0.2579787234042553
- 0.4790957446808511
- 0.5069148936170212
- 0.41829787234042554
- 0.5469148936170213
- 0.475531914893617
- 0.3923936170212766
- 0.4093085106382979
- 0.3029787234042553
- 0.4802659574468085
- 0.5278191489361702
- 0.5497872340425531
- 0.45132978723404255
- 0.345531914893617
- 0.49340425531914894
- 0.3325
- 0.32898936170212767
- 0.45867021276595743
- 0.4718085106382979
- 0.35643617021276597
- 0.483031914893617
- 0.5392021276595744
- 0.4322872340425532
- 0.48101063829787233
- 0.4408510638297872
- 0.3346808510638298
- 0.5245744680851064
- 0.2720744680851064
- 0.5543085106382979
- 0.4543617021276596
- 0.46835106382978725
- 0.4652127659574468
- 0.485531914893617
- 0.45867021276595743
- 0.5081382978723404
- 0.4887234042553191
- 0.48845744680851066
- 0.5079787234042553
- 0.48558510638297875
- 0.46925531914893615
- 0.3600531914893617
- 0.5902127659574468
- 0.5636170212765957
- 0.5093617021276595
- 0.5848936170212766
- 0.44420212765957445
- 0.38659574468085106
- 0.5884574468085106
- 0.3948404255319149
- 0.6021276595744681
- 0.45787234042553193
- 0.5173404255319148
test_loss_list:
- 4.016209500630697
- 3.851086378097534
- 4.3091170946757
- 3.4351804701487225
- 3.5206611410776776
- 3.204222806294759
- 3.0111941401163738
- 2.875460271835327
- 2.884975175857544
- 2.646933015187581
- 2.7687021096547446
- 2.442004909515381
- 2.4661257616678873
- 2.667210203806559
- 3.390575065612793
- 2.2905135027567547
- 2.516230758031209
- 2.780660622914632
- 2.8134708468119305
- 2.3870445346832274
- 2.4880679734547932
- 2.2447500324249265
- 2.2921640872955322
- 3.118165636062622
- 2.180819460550944
- 2.274615481694539
- 2.380780359903971
- 2.044550280570984
- 1.9770871384938558
- 2.6174945290883382
- 2.156367367108663
- 2.1896281592051188
- 2.516274108886719
- 2.117890717188517
- 2.368917303085327
- 2.180678455034892
- 2.09356294631958
- 1.7798490699132283
- 1.8302588494618734
- 2.1603128878275553
- 1.9866287819544475
- 2.1303844817479454
- 2.7548803424835206
- 2.139230750401815
- 2.0476094770431517
- 2.013962505658468
- 1.8893681637446085
- 2.0565393082300822
- 4.458950990041097
- 1.780989793141683
- 1.682890954017639
- 2.0876097456614175
- 1.5974868551890056
- 1.7455991427103679
- 2.1697353823979695
- 2.0250512552261353
- 2.9279293155670167
- 1.7412598021825154
- 1.597448353767395
- 1.5265834108988443
- 1.9331037139892577
- 2.782735134760539
- 1.7705475107828776
- 2.9986245028177896
- 2.9809893862406414
- 1.8625753657023112
- 1.840699666341146
- 2.7259770456949868
- 1.7335830020904541
- 1.502648539543152
- 2.029005403518677
- 1.738849630355835
- 1.97275976339976
- 2.9427980264027913
- 1.5943980026245117
- 4.452690881093343
- 1.4412579568227133
- 1.9081597073872885
- 1.8102909660339355
- 1.8697873989741007
- 1.7161131318410237
- 1.8867590188980103
- 1.6883704328536988
- 1.7759053293863933
- 1.7707052357991537
- 1.7069063965479534
- 1.7396787261962892
- 1.7953881565729777
- 2.8616651916503906
- 1.3332765833536784
- 1.4243214988708497
- 1.6446436421076456
- 1.3405826807022094
- 1.976792345046997
- 2.4533169714609784
- 1.3336419455210369
- 2.506620248158773
- 1.2893342781066894
- 1.896357479095459
- 1.609807620048523
train_accuracy:
- 0.0
- 0.0
- 0.0
- 0.358
- 0.004
- 0.179
- 0.167
- 0.263
- 0.529
- 0.244
- 0.219
- 0.296
- 0.502
- 0.548
- 0.498
- 0.638
- 0.275
- 0.548
- 0.677
- 0.281
- 0.058
- 0.623
- 0.467
- 0.831
- 0.698
- 0.24
- 0.565
- 0.073
- 0.471
- 0.198
- 0.525
- 0.479
- 0.215
- 0.252
- 0.577
- 0.271
- 0.652
- 0.494
- 0.385
- 0.571
- 0.594
- 0.583
- 0.546
- 0.329
- 0.906
- 0.29
- 0.829
- 0.312
- 0.833
- 0.127
- 0.746
- 0.335
- 0.527
- 0.388
- 0.833
- 0.556
- 0.854
- 0.383
- 0.527
- 0.546
- 0.442
- 0.833
- 0.79
- 0.583
- 0.694
- 0.746
- 0.875
- 0.892
- 0.794
- 0.481
- 0.727
- 0.842
- 0.333
- 0.142
- 0.669
- 0.796
- 0.575
- 0.713
- 0.767
- 0.808
- 0.846
- 0.877
- 0.879
- 0.85
- 0.906
- 0.902
- 0.631
- 0.715
- 0.89
- 0.654
- 0.54
- 0.35
- 0.852
- 0.856
- 0.704
- 0.735
- 0.469
- 0.633
- 0.567
- 0.879
train_loss:
- 1.691
- 1.82
- 0.797
- 1.622
- 1.074
- 1.014
- 0.957
- 1.254
- 0.881
- 0.846
- 0.815
- 1.099
- 1.065
- 0.75
- 0.455
- 0.729
- 0.719
- 0.432
- 0.424
- 0.687
- 0.683
- 0.681
- 0.676
- 0.394
- 0.662
- 0.657
- 0.646
- 0.902
- 0.883
- 0.618
- 0.613
- 0.609
- 0.596
- 0.597
- 0.591
- 0.594
- 0.589
- 0.822
- 0.806
- 0.573
- 0.571
- 0.572
- 0.337
- 0.559
- 0.553
- 0.557
- 0.547
- 0.545
- 0.106
- 0.56
- 0.752
- 0.545
- 0.749
- 0.745
- 0.524
- 0.518
- 0.314
- 0.519
- 0.722
- 0.718
- 0.511
- 0.301
- 0.504
- 0.295
- 0.287
- 0.501
- 0.505
- 0.3
- 0.493
- 0.688
- 0.491
- 0.488
- 0.486
- 0.285
- 0.481
- 0.09
- 0.703
- 0.49
- 0.473
- 0.474
- 0.478
- 0.464
- 0.467
- 0.459
- 0.463
- 0.465
- 0.453
- 0.454
- 0.268
- 0.643
- 0.634
- 0.455
- 0.627
- 0.442
- 0.258
- 0.63
- 0.264
- 0.622
- 0.433
- 0.433
unequal: 0
verbose: 1
