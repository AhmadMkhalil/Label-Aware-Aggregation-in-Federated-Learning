avg_train_accuracy: 0.887
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.022393617021276596
- 0.051808510638297875
- 0.0648404255319149
- 0.06414893617021276
- 0.09664893617021277
- 0.17351063829787233
- 0.08851063829787234
- 0.15420212765957447
- 0.12484042553191489
- 0.11377659574468085
- 0.26574468085106384
- 0.13047872340425531
- 0.24468085106382978
- 0.21654255319148935
- 0.14904255319148937
- 0.36106382978723406
- 0.2300531914893617
- 0.27452127659574466
- 0.37877659574468087
- 0.36648936170212765
- 0.34941489361702127
- 0.17957446808510638
- 0.27393617021276595
- 0.46595744680851064
- 0.2661702127659574
- 0.1946808510638298
- 0.42159574468085104
- 0.3573404255319149
- 0.4802659574468085
- 0.2718617021276596
- 0.4926595744680851
- 0.4614893617021277
- 0.47143617021276596
- 0.48058510638297874
- 0.225
- 0.3901063829787234
- 0.33441489361702126
- 0.3583510638297872
- 0.30319148936170215
- 0.4902127659574468
- 0.2970212765957447
- 0.5131914893617021
- 0.3278723404255319
- 0.2124468085106383
- 0.5291489361702127
- 0.40430851063829787
- 0.3801595744680851
- 0.4909574468085106
- 0.5388829787234043
- 0.2650531914893617
- 0.5364361702127659
- 0.481968085106383
- 0.5088829787234043
- 0.3781914893617021
- 0.36675531914893617
- 0.5103723404255319
- 0.27430851063829786
- 0.31457446808510636
- 0.3675
- 0.37611702127659574
- 0.38111702127659575
- 0.3562234042553192
- 0.4098404255319149
- 0.20569148936170212
- 0.5539893617021276
- 0.568404255319149
- 0.4143085106382979
- 0.5651063829787234
- 0.5427127659574468
- 0.3545744680851064
- 0.3255851063829787
- 0.4102659574468085
- 0.5398936170212766
- 0.5627127659574468
- 0.41260638297872343
- 0.5587765957446809
- 0.42558510638297875
- 0.2797872340425532
- 0.5901063829787234
- 0.5294148936170213
- 0.3721276595744681
- 0.45085106382978724
- 0.5947340425531915
- 0.5587765957446809
- 0.42851063829787234
- 0.43803191489361704
- 0.5891489361702128
- 0.5614893617021277
- 0.30670212765957444
- 0.5439893617021276
- 0.5790425531914893
- 0.41404255319148936
- 0.5989361702127659
- 0.4600531914893617
- 0.5637765957446809
- 0.5711702127659575
- 0.6139361702127659
- 0.5887234042553191
- 0.5971276595744681
- 0.5768085106382979
test_loss_list:
- 4.007969236373901
- 4.974876899719238
- 3.901983766555786
- 5.18856065750122
- 3.6245553970336912
- 3.3115399074554444
- 3.9970885848999025
- 3.319608065287272
- 3.3266444301605222
- 3.27641313234965
- 2.796167869567871
- 3.3171923478444416
- 2.8680553372701008
- 3.0772939586639403
- 3.3866686916351316
- 2.5642392444610596
- 2.912014799118042
- 2.6370849609375
- 2.43895094871521
- 2.395466076533
- 2.450922835667928
- 3.2452152729034425
- 2.6486539459228515
- 2.370896224975586
- 2.8017950503031415
- 3.6289989948272705
- 2.154637532234192
- 2.4314534219106037
- 1.951915979385376
- 2.616989850997925
- 2.1460563929875693
- 2.1524664258956907
- 1.9800579595565795
- 1.9803042618433635
- 2.8901700592041015
- 2.0850721565882364
- 2.6035747305552164
- 2.252156473795573
- 2.6140249220530194
- 1.8014706214269003
- 2.7495306301116944
- 1.8178675905863444
- 2.466274366378784
- 4.157851142883301
- 1.8344231843948364
- 2.0976362737019856
- 2.141610418955485
- 1.6896466064453124
- 1.662811401685079
- 3.5265192794799805
- 1.667300402323405
- 1.7224040508270264
- 1.6328962516784669
- 2.323825124104818
- 2.4177466678619384
- 1.5960973405838013
- 3.2636139011383056
- 2.49058084487915
- 2.3731024837493897
- 2.244169937769572
- 2.2793614292144775
- 2.5750655047098796
- 2.1249704424540203
- 4.539608249664306
- 1.4468742481867471
- 1.4046445735295614
- 1.9678707615534465
- 1.4586632108688355
- 1.4874204460779825
- 2.4048849646250408
- 2.585190337498983
- 2.2052220058441163
- 1.4799788745244344
- 1.4286434618631998
- 2.1504446029663087
- 1.4064160855611165
- 2.003563389778137
- 3.7192072963714597
- 1.4126329040527343
- 1.5383481216430663
- 2.2368051640192665
- 1.8960658629735312
- 1.3087558190027873
- 1.4080520915985106
- 2.201530542373657
- 1.8885194063186646
- 1.361769469579061
- 1.4151266702016194
- 3.3044664096832275
- 1.4210234530766805
- 1.3240191014607747
- 2.254143853187561
- 1.2810716597239176
- 1.996789132754008
- 1.3598646624883015
- 1.3812769587834677
- 1.2500110530853272
- 1.2907645750045775
- 1.3069178771972656
- 1.3445082585016885
train_accuracy:
- 0.0
- 0.0
- 0.506
- 0.475
- 0.071
- 0.029
- 0.51
- 0.135
- 0.233
- 0.96
- 0.017
- 0.0
- 0.877
- 0.206
- 0.881
- 0.783
- 0.731
- 0.604
- 0.408
- 0.829
- 0.35
- 0.908
- 0.785
- 0.631
- 0.777
- 0.908
- 0.483
- 0.329
- 0.629
- 0.963
- 0.469
- 0.612
- 0.521
- 0.677
- 0.733
- 0.41
- 0.917
- 0.869
- 0.935
- 0.879
- 0.858
- 0.365
- 0.652
- 0.562
- 0.354
- 0.208
- 0.704
- 0.467
- 0.688
- 0.879
- 0.681
- 0.821
- 0.89
- 0.842
- 0.946
- 0.698
- 0.619
- 0.192
- 0.917
- 0.252
- 0.933
- 0.944
- 0.919
- 0.252
- 0.556
- 0.85
- 0.752
- 0.904
- 0.915
- 0.923
- 0.938
- 0.858
- 0.948
- 0.846
- 0.86
- 0.594
- 0.306
- 0.892
- 0.746
- 0.565
- 0.865
- 0.944
- 0.629
- 0.912
- 0.308
- 0.94
- 0.752
- 0.869
- 0.896
- 0.879
- 0.863
- 0.321
- 0.7
- 0.971
- 0.971
- 0.59
- 0.917
- 0.408
- 0.638
- 0.887
train_loss:
- 2.09
- 1.13
- 1.659
- 0.295
- 2.166
- 1.453
- 0.276
- 1.267
- 0.722
- 0.738
- 1.134
- 0.705
- 1.104
- 1.04
- 0.61
- 0.984
- 0.613
- 0.95
- 0.928
- 0.91
- 0.89
- 0.206
- 0.556
- 1.27
- 0.55
- 0.518
- 0.914
- 0.843
- 0.869
- 0.543
- 1.174
- 1.135
- 0.838
- 0.797
- 0.486
- 0.489
- 0.454
- 0.445
- 0.47
- 0.746
- 0.458
- 1.063
- 0.456
- 0.151
- 1.097
- 0.454
- 0.451
- 0.736
- 1.015
- 0.146
- 1.035
- 0.713
- 0.675
- 0.427
- 0.392
- 0.656
- 0.146
- 0.425
- 0.395
- 0.397
- 0.415
- 0.373
- 0.39
- 0.107
- 0.698
- 0.661
- 0.396
- 0.658
- 0.663
- 0.367
- 0.355
- 0.373
- 0.644
- 0.636
- 0.371
- 0.651
- 0.366
- 0.107
- 0.927
- 0.601
- 0.358
- 0.366
- 0.643
- 0.621
- 0.374
- 0.376
- 0.854
- 0.608
- 0.117
- 0.61
- 0.585
- 0.335
- 0.616
- 0.34
- 0.567
- 0.556
- 0.61
- 0.594
- 0.568
- 0.574
unequal: 0
verbose: 1
