avg_train_accuracy: 0.835
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.042606382978723406
- 0.06047872340425532
- 0.07212765957446808
- 0.10888297872340426
- 0.16861702127659575
- 0.25159574468085105
- 0.32361702127659575
- 0.385
- 0.4818085106382979
- 0.5143085106382979
- 0.5007446808510638
- 0.5637234042553192
- 0.5822340425531914
- 0.5732446808510638
- 0.5920744680851063
- 0.6191489361702127
- 0.6103191489361702
- 0.6233510638297872
- 0.6318617021276596
- 0.653563829787234
- 0.6454787234042553
- 0.6524468085106383
- 0.6578191489361702
- 0.6764361702127659
- 0.6822872340425532
- 0.6678723404255319
- 0.6799468085106383
- 0.683031914893617
- 0.6901063829787234
- 0.7033510638297872
- 0.6956914893617021
- 0.7009574468085107
- 0.7141489361702128
- 0.7080851063829787
- 0.7109574468085106
- 0.724095744680851
- 0.716063829787234
- 0.7199468085106383
- 0.7311702127659574
- 0.735
- 0.7263297872340425
- 0.729095744680851
- 0.7404787234042554
- 0.744095744680851
- 0.7339893617021277
- 0.7368617021276596
- 0.7391489361702127
- 0.749095744680851
- 0.7428191489361702
- 0.7505851063829787
- 0.745531914893617
- 0.7527659574468085
- 0.7482978723404256
- 0.7479255319148936
- 0.7547340425531915
- 0.7504787234042554
- 0.7516489361702128
- 0.7515957446808511
- 0.7529255319148936
- 0.7557978723404255
- 0.7593085106382979
- 0.7606382978723404
- 0.7573936170212766
- 0.7562234042553192
- 0.7581914893617021
- 0.7600531914893617
- 0.7604255319148936
- 0.7631382978723404
- 0.7617021276595745
- 0.7660106382978723
- 0.7629255319148937
- 0.765
- 0.7663829787234042
- 0.769468085106383
- 0.7697872340425532
- 0.7649468085106383
- 0.7653191489361703
- 0.7678723404255319
- 0.7660638297872341
- 0.7721808510638298
- 0.765904255319149
- 0.7679255319148937
- 0.7703723404255319
- 0.7691489361702127
- 0.7718617021276596
- 0.7708510638297872
- 0.7731382978723405
- 0.7711702127659574
- 0.7732978723404256
- 0.7705851063829787
- 0.7723404255319148
- 0.7723404255319148
- 0.7731382978723405
- 0.7720212765957447
- 0.7718617021276596
- 0.7758510638297872
- 0.7755319148936171
- 0.7770744680851064
- 0.7782978723404256
- 0.7728723404255319
test_loss_list:
- 3.78696683883667
- 3.7492774295806885
- 3.6632952880859375
- 3.4783496379852297
- 3.204860153198242
- 2.896324939727783
- 2.6019358825683594
- 2.3593780040740966
- 2.185502726236979
- 2.048560832341512
- 1.8924891360600788
- 1.8180117638905844
- 1.7594063711166381
- 1.6350528526306152
- 1.5365042702356975
- 1.5383452049891153
- 1.4552955961227416
- 1.3883890787760416
- 1.3332039705912273
- 1.3642746512095134
- 1.2863246726989745
- 1.2373928769429525
- 1.203066374460856
- 1.2524721717834473
- 1.2523015848795573
- 1.169687287012736
- 1.1109988379478455
- 1.0900179998079935
- 1.067183985710144
- 1.1325104173024496
- 1.0485947887102762
- 1.0247497582435607
- 1.0906644256909688
- 1.009439685344696
- 0.9864937074979147
- 1.0664107020696003
- 0.9718920000394186
- 0.9533781067530314
- 1.0350384521484375
- 1.0482300806045532
- 0.9476295852661133
- 0.9159813110033671
- 1.0016852935155234
- 1.0192237901687622
- 0.9168705558776855
- 0.8908927392959595
- 0.8776193404197693
- 0.9655343500773111
- 0.8707432436943054
- 0.9614839919408162
- 0.8713264234860738
- 0.9523991799354553
- 0.8539933276176452
- 0.839194872379303
- 0.9314223917325338
- 0.8387117489178976
- 0.8265190839767456
- 0.8208883062998453
- 0.8158748586972554
- 0.8173511918385824
- 0.9105571206410726
- 0.9317769010861715
- 0.8271160689989726
- 0.8040412243207296
- 0.7996938308080037
- 0.7919627730051676
- 0.7852956120173137
- 0.7804599769910177
- 0.7754685513178508
- 0.8793243908882141
- 0.7876631967226664
- 0.7750799918174743
- 0.7690467317899068
- 0.8673608787854512
- 0.8863165577252706
- 0.7820441738764445
- 0.7717990565299988
- 0.7625452319780985
- 0.7628769548734029
- 0.853284793694814
- 0.7675154638290406
- 0.7566065009435018
- 0.751164391040802
- 0.7489252758026123
- 0.7439110970497131
- 0.7397734649976094
- 0.8392097783088684
- 0.7467762859662374
- 0.8426497809092204
- 0.7519183643658955
- 0.7401142001152039
- 0.7340595690409343
- 0.830409201780955
- 0.7405820218722026
- 0.7351313813527425
- 0.8250081396102905
- 0.8417409427960714
- 0.8587239734331766
- 0.8675600083669027
- 0.7614930136998495
train_accuracy:
- 0.004
- 0.012
- 0.029
- 0.092
- 0.173
- 0.242
- 0.0
- 0.0
- 0.531
- 0.55
- 0.517
- 0.61
- 0.623
- 0.644
- 0.604
- 0.658
- 0.625
- 0.635
- 0.629
- 0.721
- 0.708
- 0.0
- 0.725
- 0.696
- 0.725
- 0.673
- 0.7
- 0.752
- 0.723
- 0.731
- 0.706
- 0.771
- 0.779
- 0.706
- 0.731
- 0.746
- 0.754
- 0.75
- 0.75
- 0.731
- 0.744
- 0.754
- 0.744
- 0.744
- 0.812
- 0.812
- 0.75
- 0.75
- 0.765
- 0.787
- 0.79
- 0.756
- 0.76
- 0.765
- 0.775
- 0.012
- 0.767
- 0.771
- 0.771
- 0.775
- 0.787
- 0.767
- 0.777
- 0.773
- 0.021
- 0.777
- 0.021
- 0.831
- 0.775
- 0.79
- 0.787
- 0.775
- 0.775
- 0.781
- 0.781
- 0.838
- 0.804
- 0.835
- 0.833
- 0.783
- 0.017
- 0.779
- 0.812
- 0.781
- 0.796
- 0.783
- 0.79
- 0.802
- 0.808
- 0.825
- 0.787
- 0.792
- 0.763
- 0.794
- 0.015
- 0.765
- 0.815
- 0.85
- 0.85
- 0.835
train_loss:
- 3.426
- 3.356
- 3.305
- 3.212
- 3.067
- 2.876
- 2.663
- 2.477
- 2.691
- 2.516
- 2.086
- 2.293
- 2.206
- 1.857
- 1.798
- 2.006
- 1.708
- 1.663
- 1.619
- 1.841
- 1.562
- 1.525
- 1.515
- 1.702
- 1.685
- 1.438
- 1.409
- 1.403
- 1.39
- 1.568
- 1.362
- 1.335
- 1.524
- 1.319
- 1.305
- 1.472
- 1.276
- 1.261
- 1.443
- 1.422
- 1.239
- 1.227
- 1.404
- 1.386
- 1.204
- 1.19
- 1.181
- 1.35
- 1.165
- 1.343
- 1.166
- 1.329
- 1.142
- 1.142
- 1.304
- 1.13
- 1.116
- 1.11
- 1.11
- 1.107
- 1.271
- 1.266
- 1.102
- 1.094
- 1.091
- 1.082
- 1.086
- 1.077
- 1.068
- 1.244
- 1.065
- 1.058
- 1.058
- 1.218
- 1.212
- 1.055
- 1.047
- 1.042
- 1.042
- 1.204
- 1.045
- 1.041
- 1.033
- 1.027
- 1.023
- 1.016
- 1.175
- 1.018
- 1.178
- 1.031
- 1.016
- 1.011
- 1.169
- 1.007
- 1.0
- 1.155
- 1.149
- 1.144
- 1.139
- 1.002
unequal: 0
verbose: 1
