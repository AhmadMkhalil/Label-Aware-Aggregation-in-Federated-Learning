avg_train_accuracy: 0.838
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.026063829787234042
- 0.047021276595744683
- 0.07569148936170213
- 0.16803191489361702
- 0.27287234042553193
- 0.4122872340425532
- 0.4220744680851064
- 0.46585106382978725
- 0.5055851063829787
- 0.5335106382978724
- 0.5551595744680851
- 0.576063829787234
- 0.6109042553191489
- 0.6245744680851064
- 0.6181914893617021
- 0.6329255319148936
- 0.6421808510638298
- 0.6497340425531914
- 0.6615425531914894
- 0.6668085106382978
- 0.6731914893617021
- 0.6797340425531915
- 0.6948936170212766
- 0.6863297872340426
- 0.6927659574468085
- 0.7070744680851064
- 0.710531914893617
- 0.7055851063829788
- 0.7182978723404255
- 0.7218085106382979
- 0.7250531914893616
- 0.7177659574468085
- 0.7189893617021277
- 0.7208510638297873
- 0.7343085106382978
- 0.7366489361702128
- 0.7392553191489362
- 0.7318617021276596
- 0.7360106382978724
- 0.7331914893617021
- 0.7367021276595744
- 0.7386170212765958
- 0.7420744680851064
- 0.749095744680851
- 0.7413829787234043
- 0.7447340425531915
- 0.7472872340425532
- 0.7469148936170212
- 0.7483510638297872
- 0.7566489361702128
- 0.748563829787234
- 0.7510106382978723
- 0.7531382978723404
- 0.7563297872340425
- 0.7600531914893617
- 0.7554787234042554
- 0.7553723404255319
- 0.7589893617021276
- 0.7596276595744681
- 0.765531914893617
- 0.7656914893617022
- 0.7610106382978723
- 0.7661702127659574
- 0.77
- 0.7628191489361702
- 0.7678723404255319
- 0.763563829787234
- 0.7662234042553191
- 0.766595744680851
- 0.7720212765957447
- 0.7667553191489361
- 0.7704255319148936
- 0.7757446808510639
- 0.7693617021276595
- 0.7708510638297872
- 0.7703191489361703
- 0.7764893617021277
- 0.7716489361702128
- 0.7735106382978724
- 0.777127659574468
- 0.7720744680851064
- 0.7782978723404256
- 0.7732978723404256
- 0.7744148936170213
- 0.7732978723404256
- 0.7743085106382979
- 0.7808510638297872
- 0.7740425531914894
- 0.7818617021276596
- 0.7765425531914893
- 0.781436170212766
- 0.7774468085106383
- 0.7781914893617021
- 0.7791489361702127
- 0.7803191489361702
- 0.7822340425531915
- 0.7797340425531915
- 0.7818617021276596
- 0.7840425531914894
- 0.7803723404255319
test_loss_list:
- 3.7862985134124756
- 3.7570164648691815
- 3.66565372467041
- 3.4613075478871664
- 3.039764149983724
- 2.674149662653605
- 2.3593773810068766
- 2.131290461222331
- 1.9520648590723673
- 1.830633397102356
- 1.7232067600886027
- 1.6246146217981974
- 1.6057977406183879
- 1.5575855175654094
- 1.4601376104354857
- 1.3876653130849201
- 1.3329675022761027
- 1.2920684750874838
- 1.2485716692606608
- 1.2164256540934244
- 1.185647276242574
- 1.1571924463907877
- 1.2148772462209065
- 1.1367265097300212
- 1.0876728653907777
- 1.1579457728068034
- 1.1581331459681192
- 1.0602656118075053
- 1.115212339560191
- 1.1228229999542236
- 1.12629593928655
- 1.0218212922414145
- 0.9851742641131083
- 0.959948943456014
- 1.0405008387565613
- 1.0508584292729695
- 1.0550357985496521
- 0.9446985538800557
- 0.917843668460846
- 0.8987785530090332
- 0.8822232047716777
- 0.8703019833564758
- 0.863476501305898
- 0.9633472760518392
- 0.8692947649955749
- 0.8472704362869262
- 0.8386921906471252
- 0.8310030031204224
- 0.8331736675898234
- 0.9251898376146952
- 0.8328858701388041
- 0.8207254020373026
- 0.808310736020406
- 0.8041180197397868
- 0.9010169887542725
- 0.8079762093226115
- 0.7945960267384847
- 0.7865453505516052
- 0.7808231314023336
- 0.8791161163647969
- 0.9038846270243327
- 0.7992473403612773
- 0.88387344678243
- 0.8997416989008585
- 0.7873721663157145
- 0.8762742980321249
- 0.7772233883539835
- 0.75997332016627
- 0.7510218969980875
- 0.8466921083132426
- 0.7536421624819437
- 0.7442225329081218
- 0.8399472427368164
- 0.7466813516616821
- 0.7353378780682882
- 0.7311871019999187
- 0.8269904979070027
- 0.7390069492657979
- 0.7301847600936889
- 0.8281372809410095
- 0.7328436875343323
- 0.8214793340365092
- 0.7270583128929138
- 0.7149468278884887
- 0.7136498014132182
- 0.709887683391571
- 0.8038753708203633
- 0.7183591667811076
- 0.8066129096349081
- 0.7165002497037252
- 0.8047719740867615
- 0.7146269488334656
- 0.7023237562179565
- 0.6966137210528056
- 0.6940348251660665
- 0.7869863986968995
- 0.6972625724474589
- 0.6928812058766683
- 0.7856146478652954
- 0.6970304838816325
train_accuracy:
- 0.006
- 0.048
- 0.212
- 0.188
- 0.269
- 0.496
- 0.425
- 0.552
- 0.485
- 0.581
- 0.627
- 0.0
- 0.642
- 0.648
- 0.0
- 0.654
- 0.642
- 0.694
- 0.673
- 0.646
- 0.677
- 0.702
- 0.704
- 0.708
- 0.746
- 0.748
- 0.731
- 0.731
- 0.725
- 0.733
- 0.783
- 0.781
- 0.0
- 0.0
- 0.785
- 0.756
- 0.806
- 0.76
- 0.79
- 0.748
- 0.771
- 0.765
- 0.76
- 0.769
- 0.763
- 0.767
- 0.763
- 0.773
- 0.008
- 0.823
- 0.765
- 0.804
- 0.76
- 0.819
- 0.827
- 0.808
- 0.821
- 0.783
- 0.004
- 0.825
- 0.815
- 0.775
- 0.775
- 0.819
- 0.808
- 0.806
- 0.771
- 0.833
- 0.777
- 0.808
- 0.819
- 0.846
- 0.842
- 0.779
- 0.812
- 0.796
- 0.817
- 0.831
- 0.806
- 0.794
- 0.808
- 0.823
- 0.002
- 0.806
- 0.806
- 0.796
- 0.812
- 0.85
- 0.8
- 0.0
- 0.85
- 0.812
- 0.8
- 0.829
- 0.808
- 0.825
- 0.0
- 0.846
- 0.846
- 0.838
train_loss:
- 3.405
- 3.833
- 3.335
- 3.692
- 3.005
- 3.172
- 2.504
- 2.328
- 2.199
- 2.082
- 1.989
- 1.92
- 2.14
- 2.044
- 1.728
- 1.684
- 1.633
- 1.603
- 1.575
- 1.54
- 1.513
- 1.482
- 1.683
- 1.446
- 1.417
- 1.607
- 1.589
- 1.376
- 1.539
- 1.518
- 1.511
- 1.304
- 1.28
- 1.262
- 1.455
- 1.435
- 1.417
- 1.239
- 1.217
- 1.212
- 1.192
- 1.191
- 1.184
- 1.362
- 1.175
- 1.155
- 1.153
- 1.146
- 1.142
- 1.311
- 1.142
- 1.128
- 1.114
- 1.106
- 1.275
- 1.104
- 1.106
- 1.095
- 1.091
- 1.257
- 1.232
- 1.081
- 1.232
- 1.227
- 1.064
- 1.221
- 1.051
- 1.056
- 1.046
- 1.205
- 1.047
- 1.035
- 1.189
- 1.033
- 1.033
- 1.03
- 1.186
- 1.023
- 1.029
- 1.172
- 1.013
- 1.162
- 1.012
- 1.006
- 1.001
- 0.999
- 1.153
- 1.0
- 1.143
- 0.998
- 1.139
- 0.991
- 0.972
- 0.979
- 0.985
- 1.122
- 0.983
- 0.976
- 1.12
- 0.976
unequal: 0
verbose: 1
