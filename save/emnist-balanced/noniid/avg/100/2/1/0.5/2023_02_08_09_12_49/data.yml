avg_train_accuracy: 0.779
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04218085106382979
- 0.046595744680851064
- 0.0574468085106383
- 0.06861702127659575
- 0.09510638297872341
- 0.17329787234042554
- 0.2611702127659574
- 0.44813829787234044
- 0.5001595744680851
- 0.48223404255319147
- 0.5521276595744681
- 0.5721808510638298
- 0.5925
- 0.6047872340425532
- 0.6164893617021276
- 0.6247340425531915
- 0.6338829787234043
- 0.6442021276595745
- 0.6534574468085106
- 0.643031914893617
- 0.6517021276595745
- 0.6619148936170213
- 0.6656914893617021
- 0.6805851063829788
- 0.675531914893617
- 0.69
- 0.6934574468085106
- 0.6961702127659575
- 0.6893617021276596
- 0.7032978723404255
- 0.7067553191489362
- 0.7025
- 0.7105851063829787
- 0.7145744680851064
- 0.716063829787234
- 0.7125
- 0.7197872340425532
- 0.7231914893617021
- 0.725
- 0.7261170212765957
- 0.7285106382978723
- 0.731063829787234
- 0.7235106382978723
- 0.7330319148936171
- 0.7357978723404255
- 0.7356914893617021
- 0.7365425531914893
- 0.7313829787234043
- 0.74
- 0.7397872340425532
- 0.7336702127659575
- 0.7403723404255319
- 0.7424468085106383
- 0.7445744680851064
- 0.7419148936170212
- 0.7460638297872341
- 0.7478191489361702
- 0.7476063829787234
- 0.7498936170212765
- 0.7454255319148936
- 0.7487765957446808
- 0.749468085106383
- 0.7537234042553191
- 0.7553191489361702
- 0.7532446808510638
- 0.7547340425531915
- 0.7503723404255319
- 0.7523404255319149
- 0.7571808510638298
- 0.7597872340425532
- 0.7527659574468085
- 0.7588297872340426
- 0.7573404255319149
- 0.7611170212765958
- 0.7598404255319149
- 0.761436170212766
- 0.7613297872340425
- 0.7605851063829787
- 0.7617021276595745
- 0.7618617021276596
- 0.7624468085106383
- 0.760531914893617
- 0.7646276595744681
- 0.7648404255319149
- 0.7655851063829787
- 0.7667021276595745
- 0.7620744680851064
- 0.7654787234042553
- 0.7657446808510638
- 0.7684042553191489
- 0.7665425531914893
- 0.7664893617021277
- 0.767127659574468
- 0.7686170212765957
- 0.7688297872340426
- 0.7690425531914894
- 0.7605851063829787
- 0.7675
- 0.7686170212765957
- 0.7695744680851064
test_loss_list:
- 3.794396648406982
- 3.782393341064453
- 3.7357503954569498
- 3.6454997571309407
- 3.4730388355255126
- 3.1895121129353843
- 2.8374552790323895
- 2.5030543041229247
- 2.2087358951568605
- 2.0377336359024047
- 1.8714209222793579
- 1.7796651236216228
- 1.702492109934489
- 1.6568686882654826
- 1.5903143692016601
- 1.564383915265401
- 1.525368307431539
- 1.4942707808812459
- 1.4678256177902222
- 1.3423272196451823
- 1.2441089296340941
- 1.1996388880411784
- 1.1611872776349386
- 1.2546808687845865
- 1.1479337255160014
- 1.2042046038309733
- 1.219393130938212
- 1.2116685096422832
- 1.0786490933100383
- 1.1553313819567363
- 1.1599100812276204
- 1.0177122894922892
- 1.1125170612335205
- 1.124975599447886
- 1.1235896635055542
- 0.9844556593894959
- 0.9377556109428405
- 1.059498172601064
- 1.0793091797828673
- 1.079779449303945
- 1.084377218882243
- 1.0918091050783794
- 0.915398097038269
- 1.025196181933085
- 1.0434523208936055
- 1.0438390851020813
- 1.0557829594612123
- 0.8820787978172302
- 0.9936065483093262
- 1.008404809633891
- 0.8553118316332499
- 0.8327216299374899
- 0.8220158974329631
- 0.9513177299499511
- 0.8269034997622172
- 0.9494853727022807
- 0.969224042892456
- 0.9764339709281922
- 0.985767305692037
- 0.8185869431495667
- 0.794089461962382
- 0.9238077894846598
- 0.7936930545171101
- 0.774876176516215
- 0.9102898780504862
- 0.9292455824216207
- 0.7888503360748291
- 0.7728700272242228
- 0.8927207565307618
- 0.9076181284586589
- 0.773933626015981
- 0.891863272190094
- 0.7626228666305542
- 0.7501743721961975
- 0.7509534104665121
- 0.744609485467275
- 0.7468797175089518
- 0.8658498287200928
- 0.7514166752497355
- 0.8675974631309509
- 0.8934526888529459
- 0.7513766423861186
- 0.7371562099456788
- 0.7327936482429505
- 0.8587640301386515
- 0.8833708381652832
- 0.7405799293518066
- 0.7290659642219544
- 0.8540311233202617
- 0.8775869758923849
- 0.8817836713790893
- 0.898662691116333
- 0.908636748790741
- 0.9149351612726847
- 0.9183462071418762
- 0.9249495132764181
- 0.7503474124272664
- 0.8568409434954325
- 0.7208189686139425
- 0.7092004672686258
train_accuracy:
- 0.042
- 0.054
- 0.885
- 0.033
- 0.05
- 0.167
- 0.271
- 0.473
- 0.517
- 0.517
- 0.588
- 0.627
- 0.631
- 0.625
- 0.658
- 0.675
- 0.685
- 0.671
- 0.671
- 0.0
- 0.675
- 0.708
- 0.008
- 0.698
- 0.012
- 0.71
- 0.713
- 0.731
- 0.0
- 0.737
- 0.727
- 0.75
- 0.746
- 0.754
- 0.775
- 0.754
- 0.746
- 0.735
- 0.763
- 0.74
- 0.76
- 0.75
- 0.769
- 0.792
- 0.748
- 0.769
- 0.783
- 0.752
- 0.787
- 0.802
- 0.771
- 0.771
- 0.769
- 0.781
- 0.777
- 0.8
- 0.765
- 0.779
- 0.773
- 0.8
- 0.79
- 0.785
- 0.777
- 0.773
- 0.787
- 0.773
- 0.8
- 0.783
- 0.796
- 0.785
- 0.785
- 0.8
- 0.769
- 0.19
- 0.154
- 0.754
- 0.777
- 0.787
- 0.796
- 0.792
- 0.779
- 0.765
- 0.8
- 0.812
- 0.802
- 0.792
- 0.812
- 0.775
- 0.79
- 0.798
- 0.81
- 0.821
- 0.812
- 0.823
- 0.796
- 0.794
- 0.779
- 0.831
- 0.81
- 0.779
train_loss:
- 3.855
- 3.839
- 3.235
- 3.087
- 2.996
- 2.85
- 2.658
- 3.041
- 2.758
- 2.095
- 2.43
- 2.299
- 2.196
- 2.114
- 2.046
- 1.976
- 1.924
- 1.872
- 1.841
- 1.508
- 1.441
- 1.425
- 1.4
- 1.705
- 1.384
- 1.654
- 1.645
- 1.595
- 1.307
- 1.566
- 1.549
- 1.268
- 1.516
- 1.491
- 1.498
- 1.234
- 1.203
- 1.473
- 1.441
- 1.445
- 1.425
- 1.416
- 1.155
- 1.405
- 1.386
- 1.378
- 1.369
- 1.139
- 1.361
- 1.353
- 1.1
- 1.095
- 1.089
- 1.327
- 1.079
- 1.311
- 1.315
- 1.302
- 1.29
- 1.073
- 1.044
- 1.28
- 1.069
- 1.041
- 1.263
- 1.279
- 1.03
- 1.018
- 1.258
- 1.26
- 1.019
- 1.238
- 1.011
- 1.002
- 1.017
- 1.008
- 0.994
- 1.228
- 1.001
- 1.221
- 1.206
- 0.978
- 0.971
- 0.974
- 1.2
- 1.188
- 0.98
- 0.964
- 1.186
- 1.179
- 1.175
- 1.176
- 1.171
- 1.168
- 1.173
- 1.167
- 0.973
- 1.172
- 0.96
- 0.936
unequal: 0
verbose: 1
