avg_train_accuracy: 0.806
avg_train_loss: 0.011
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03196808510638298
- 0.05
- 0.08180851063829787
- 0.15367021276595744
- 0.27132978723404255
- 0.3730851063829787
- 0.4422872340425532
- 0.4742021276595745
- 0.517127659574468
- 0.5382978723404256
- 0.5609574468085107
- 0.5875
- 0.5939893617021277
- 0.6130851063829788
- 0.6145744680851064
- 0.6216489361702128
- 0.6326063829787234
- 0.6475
- 0.042340425531914895
- 0.6343085106382979
- 0.6494148936170213
- 0.6602659574468085
- 0.6737234042553192
- 0.6737765957446809
- 0.6812765957446808
- 0.6861170212765958
- 0.08888297872340425
- 0.05851063829787234
- 0.681063829787234
- 0.6929255319148936
- 0.6927127659574468
- 0.7066489361702127
- 0.7002127659574469
- 0.709095744680851
- 0.7103723404255319
- 0.7137765957446809
- 0.7189893617021277
- 0.7163829787234043
- 0.7175531914893617
- 0.7227659574468085
- 0.7247872340425532
- 0.7245744680851064
- 0.7279255319148936
- 0.7251063829787234
- 0.7345212765957447
- 0.733563829787234
- 0.7369148936170212
- 0.7364893617021276
- 0.7356382978723405
- 0.7417553191489362
- 0.7395212765957446
- 0.7420744680851064
- 0.741968085106383
- 0.7426063829787234
- 0.7472340425531915
- 0.7473404255319149
- 0.7506914893617022
- 0.7545744680851064
- 0.7458510638297873
- 0.20148936170212767
- 0.7472340425531915
- 0.7524468085106383
- 0.7546808510638298
- 0.750531914893617
- 0.7532978723404256
- 0.7568085106382979
- 0.7546276595744681
- 0.7529255319148936
- 0.7601063829787233
- 0.7606382978723404
- 0.2742553191489362
- 0.7592553191489362
- 0.7601063829787233
- 0.758563829787234
- 0.7537765957446808
- 0.7574468085106383
- 0.7620744680851064
- 0.7616489361702128
- 0.7613829787234042
- 0.7606382978723404
- 0.7632446808510638
- 0.7675531914893617
- 0.762340425531915
- 0.7648936170212766
- 0.7631382978723404
- 0.7660106382978723
- 0.7632978723404256
- 0.7675
- 0.7704255319148936
- 0.7692021276595745
- 0.7637765957446808
- 0.7690425531914894
- 0.7697340425531914
- 0.7685106382978724
- 0.7698404255319149
- 0.7661170212765958
- 0.765
- 0.7677127659574469
- 0.7697340425531914
- 0.7698404255319149
test_loss_list:
- 3.7885409577687583
- 3.770470962524414
- 3.7135802682240806
- 3.558644348780314
- 3.231247975031535
- 2.843102591832479
- 2.555511465072632
- 2.3040346622467043
- 2.129653040568034
- 2.0247062985102335
- 1.9456718842188516
- 1.8713748041788738
- 1.786666938463847
- 1.7218849817911783
- 1.6607799164454142
- 1.6249999777475992
- 1.5953214184443156
- 1.558463182449341
- 17.14052703857422
- 1.3677428166071575
- 1.3181291548411052
- 1.327355244954427
- 1.3075597190856934
- 1.2822598552703857
- 1.2787689940134683
- 1.2708188279469808
- 8.10584727605184
- 10.351668192545572
- 1.11784605662028
- 1.1216883850097656
- 1.1335019000371298
- 1.13385901927948
- 1.1319993170102438
- 1.1304605579376221
- 1.1163423450787862
- 1.1177401638031006
- 1.1105474853515624
- 1.1183498962720235
- 1.112930768330892
- 1.105195239384969
- 1.0899266775449117
- 1.103490510781606
- 1.0852057592074076
- 1.0855533369382222
- 1.0906690573692321
- 1.0898316248257955
- 1.0760549712181091
- 1.0994927493731181
- 1.080190540154775
- 1.0946107323964436
- 1.080338310400645
- 1.0682686869303386
- 1.0647211615244547
- 1.0615027944246929
- 1.0629030911127726
- 1.064569697380066
- 1.0719430017471314
- 1.0453171149889628
- 1.0615346932411194
- 5.959849402109782
- 0.8268561045328776
- 0.8656475408871969
- 0.8834705297152201
- 0.9000022172927856
- 0.9003943594296774
- 0.9163887111345926
- 0.932582840124766
- 0.9437865591049195
- 0.9371069264411926
- 0.9312520265579224
- 5.202954928080241
- 0.7801724441846212
- 0.8245104908943176
- 0.8474947738647461
- 0.8601657088597615
- 0.8731525150934855
- 0.8685758678118388
- 0.8836057345072429
- 0.8956436848640442
- 0.8960259373982747
- 0.8978243772188822
- 0.8986215289433798
- 0.9100507140159607
- 0.9058809661865235
- 0.9197585749626159
- 0.9106590684254964
- 0.9304589422543844
- 0.9259447900454203
- 0.9354034233093261
- 0.9304278453191122
- 0.9400248416264851
- 0.9337503870328268
- 0.9241714310646058
- 0.9205100536346436
- 0.9344946114222209
- 0.9297409621874492
- 0.9372558728853861
- 0.9437351703643799
- 0.9444470914204915
- 0.9383535329500834
train_accuracy:
- 0.031
- 0.048
- 0.071
- 0.148
- 0.283
- 0.36
- 0.463
- 0.49
- 0.54
- 0.59
- 0.583
- 0.615
- 0.606
- 0.66
- 0.665
- 0.631
- 0.713
- 0.658
- 0.992
- 0.654
- 0.692
- 0.669
- 0.706
- 0.715
- 0.729
- 0.723
- 0.998
- 0.998
- 0.727
- 0.74
- 0.713
- 0.744
- 0.731
- 0.775
- 0.804
- 0.748
- 0.752
- 0.76
- 0.767
- 0.74
- 0.775
- 0.783
- 0.765
- 0.758
- 0.769
- 0.779
- 0.775
- 0.767
- 0.763
- 0.779
- 0.76
- 0.792
- 0.767
- 0.773
- 0.817
- 0.796
- 0.804
- 0.804
- 0.767
- 1.0
- 0.773
- 0.804
- 0.829
- 0.823
- 0.785
- 0.8
- 0.815
- 0.812
- 0.787
- 0.796
- 1.0
- 0.802
- 0.806
- 0.808
- 0.808
- 0.806
- 0.79
- 0.794
- 0.804
- 0.817
- 0.794
- 0.812
- 0.81
- 0.808
- 0.808
- 0.808
- 0.8
- 0.823
- 0.823
- 0.812
- 0.821
- 0.81
- 0.815
- 0.829
- 0.81
- 0.819
- 0.825
- 0.821
- 0.833
- 0.806
train_loss:
- 3.856
- 3.839
- 3.803
- 3.727
- 3.538
- 3.243
- 3.019
- 2.779
- 2.604
- 2.478
- 2.414
- 2.365
- 2.221
- 2.178
- 2.035
- 2.027
- 1.986
- 1.93
- 0.517
- 2.339
- 1.845
- 1.875
- 1.773
- 1.68
- 1.729
- 1.693
- 0.333
- 0.06
- 1.98
- 1.682
- 1.684
- 1.581
- 1.589
- 1.563
- 1.572
- 1.543
- 1.496
- 1.477
- 1.436
- 1.536
- 1.45
- 1.447
- 1.397
- 1.419
- 1.4
- 1.402
- 1.338
- 1.357
- 1.416
- 1.305
- 1.392
- 1.371
- 1.346
- 1.303
- 1.352
- 1.326
- 1.277
- 1.399
- 1.32
- 0.367
- 1.524
- 1.371
- 1.334
- 1.298
- 1.247
- 1.241
- 1.277
- 1.226
- 1.298
- 1.222
- 0.256
- 1.447
- 1.278
- 1.215
- 1.269
- 1.197
- 1.19
- 1.242
- 1.267
- 1.237
- 1.172
- 1.296
- 1.177
- 1.212
- 1.156
- 1.219
- 1.168
- 1.213
- 1.184
- 1.172
- 1.177
- 1.221
- 1.254
- 1.228
- 1.184
- 1.205
- 1.145
- 1.16
- 1.176
- 1.131
unequal: 0
verbose: 1
