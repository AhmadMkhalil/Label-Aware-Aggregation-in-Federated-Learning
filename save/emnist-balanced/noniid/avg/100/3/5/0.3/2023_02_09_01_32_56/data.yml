avg_train_accuracy: 0.815
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04202127659574468
- 0.10106382978723404
- 0.2448404255319149
- 0.08446808510638298
- 0.16377659574468084
- 0.26904255319148934
- 0.2001063829787234
- 0.34324468085106385
- 0.3323936170212766
- 0.37813829787234043
- 0.3663297872340426
- 0.21154255319148937
- 0.395531914893617
- 0.258563829787234
- 0.4621808510638298
- 0.36920212765957444
- 0.3670212765957447
- 0.2655851063829787
- 0.4525
- 0.30031914893617023
- 0.25893617021276594
- 0.49031914893617023
- 0.43867021276595747
- 0.4577127659574468
- 0.28702127659574467
- 0.29414893617021276
- 0.3420744680851064
- 0.33664893617021274
- 0.5030851063829788
- 0.32851063829787236
- 0.24202127659574468
- 0.1726595744680851
- 0.5038297872340426
- 0.37446808510638296
- 0.5213297872340426
- 0.3784574468085106
- 0.5339893617021276
- 0.43824468085106383
- 0.38180851063829785
- 0.3854255319148936
- 0.5337234042553192
- 0.23319148936170211
- 0.5240425531914894
- 0.49175531914893617
- 0.5330851063829787
- 0.5482446808510638
- 0.48654255319148937
- 0.28675531914893615
- 0.5293085106382979
- 0.5344148936170213
- 0.45351063829787236
- 0.5364893617021277
- 0.5102127659574468
- 0.5361170212765958
- 0.5147340425531914
- 0.538031914893617
- 0.47393617021276596
- 0.49840425531914895
- 0.4773936170212766
- 0.5723404255319149
- 0.5417021276595745
- 0.5906382978723405
- 0.5214893617021277
- 0.5803723404255319
- 0.4027127659574468
- 0.5238297872340425
- 0.530904255319149
- 0.5188829787234043
- 0.2877127659574468
- 0.4638829787234043
- 0.5207446808510638
- 0.3535106382978723
- 0.5854255319148937
- 0.5736702127659574
- 0.5888829787234042
- 0.42281914893617023
- 0.6102127659574468
- 0.5517021276595745
- 0.5756382978723404
- 0.5589893617021277
- 0.5545212765957447
- 0.5970744680851063
- 0.5861702127659575
- 0.5754787234042553
- 0.5995744680851064
- 0.5712765957446808
- 0.5363297872340426
- 0.5531914893617021
- 0.49888297872340426
- 0.5943085106382979
- 0.5901595744680851
- 0.5644148936170212
- 0.605531914893617
- 0.6026595744680852
- 0.5438829787234043
- 0.5762765957446808
- 0.6085106382978723
- 0.6072872340425531
- 0.5453191489361702
- 0.6062234042553192
test_loss_list:
- 4.039325202306111
- 3.668368771870931
- 3.4687654717763263
- 3.832047214508057
- 3.338448905944824
- 3.1368166414896645
- 3.081806624730428
- 2.840901149113973
- 2.797689962387085
- 2.727726198832194
- 2.7742868264516196
- 3.171791172027588
- 2.6589855575561523
- 2.7920856793721516
- 3.1898158677419026
- 2.9312196159362793
- 2.4660807196299235
- 2.548008470535278
- 2.4595197423299155
- 2.641977904637655
- 2.881771329243978
- 2.356316474278768
- 2.5051963647206623
- 2.403102566401164
- 2.8937935543060305
- 2.578561979929606
- 2.3292186864217124
- 2.3302320067087807
- 2.1008242829640706
- 2.652427930831909
- 3.13013264020284
- 4.550725231170654
- 2.7778103001912435
- 2.17349636554718
- 2.096437389055888
- 2.3864816761016847
- 2.1548719453811644
- 1.9836338551839192
- 2.0975812101364135
- 2.145740753809611
- 1.9198972145716349
- 3.8496880849202473
- 2.626467138926188
- 1.801868969599406
- 2.0097831964492796
- 1.8100392357508341
- 1.7560124333699545
- 3.0161908149719237
- 2.48270357131958
- 1.9298890288670858
- 2.077344943682353
- 2.664337911605835
- 1.762507201830546
- 2.5557571506500243
- 1.864397988319397
- 1.48791823387146
- 1.7828155517578126
- 1.6119532553354898
- 1.7405597003300985
- 1.4673544025421144
- 1.5180913639068603
- 1.5809880018234252
- 1.485355526606242
- 1.61945663134257
- 2.188082203865051
- 1.5536850961049398
- 1.5150479110081991
- 1.4837065474192301
- 3.388135951360067
- 1.8256368668874106
- 1.6320329840977987
- 2.586961145401001
- 1.3946554040908814
- 1.6206056006749472
- 1.4601511367162068
- 2.2037815618515015
- 1.3785768826802571
- 2.3055789438883463
- 1.7718928162256877
- 1.4664167563120525
- 1.5607677714029948
- 1.3983425839742025
- 1.6596032667160034
- 1.5802418788274128
- 1.5984876187642416
- 1.409502353668213
- 1.569688982963562
- 1.4804875914255777
- 1.7418811909357708
- 1.4820277372996011
- 1.4277450084686278
- 1.3974999205271403
- 1.434759799639384
- 1.2882581440607708
- 1.3584482987721762
- 1.324007757504781
- 1.4897525564829508
- 1.4108851019541422
- 1.4634373124440512
- 1.4177638800938923
train_accuracy:
- 0.502
- 0.137
- 0.367
- 0.317
- 0.177
- 0.713
- 0.269
- 0.465
- 0.117
- 0.412
- 0.492
- 0.279
- 0.55
- 0.292
- 0.729
- 0.513
- 0.794
- 0.302
- 0.627
- 0.279
- 0.954
- 0.681
- 0.642
- 0.629
- 0.281
- 0.852
- 0.758
- 0.354
- 0.702
- 0.879
- 0.869
- 0.869
- 0.783
- 0.135
- 0.758
- 0.69
- 0.715
- 0.785
- 0.967
- 0.44
- 0.694
- 0.654
- 0.79
- 0.615
- 0.773
- 0.713
- 0.925
- 0.787
- 0.8
- 0.706
- 0.819
- 0.831
- 0.6
- 0.771
- 0.923
- 0.581
- 0.719
- 0.537
- 0.802
- 0.546
- 0.848
- 0.769
- 0.875
- 0.792
- 0.894
- 0.917
- 0.54
- 0.958
- 0.854
- 0.983
- 0.815
- 0.975
- 0.771
- 0.767
- 0.8
- 0.844
- 0.81
- 0.825
- 0.81
- 0.96
- 0.635
- 0.781
- 0.773
- 0.696
- 0.819
- 0.621
- 0.85
- 0.535
- 0.954
- 0.704
- 0.771
- 0.877
- 0.71
- 0.667
- 0.612
- 0.673
- 0.825
- 0.794
- 0.969
- 0.815
train_loss:
- 2.23
- 3.764
- 3.389
- 1.604
- 2.196
- 1.971
- 1.292
- 1.774
- 1.751
- 1.612
- 1.534
- 1.047
- 1.568
- 1.02
- 1.937
- 1.387
- 1.039
- 0.935
- 1.308
- 0.939
- 0.842
- 1.279
- 1.282
- 1.224
- 0.783
- 0.464
- 0.844
- 0.786
- 1.201
- 0.748
- 0.385
- 0.293
- 1.715
- 0.806
- 1.097
- 0.721
- 1.074
- 0.775
- 0.724
- 0.661
- 1.098
- 0.295
- 1.519
- 0.796
- 1.043
- 1.04
- 0.678
- 0.29
- 1.434
- 1.006
- 0.657
- 1.347
- 0.702
- 1.302
- 0.657
- 0.696
- 0.598
- 0.621
- 0.569
- 0.663
- 0.604
- 0.931
- 0.632
- 0.957
- 0.294
- 0.58
- 0.654
- 0.588
- 0.212
- 0.566
- 0.59
- 0.248
- 0.949
- 0.91
- 0.906
- 0.25
- 0.936
- 1.187
- 0.872
- 0.584
- 0.528
- 0.897
- 0.839
- 0.861
- 0.831
- 0.577
- 0.537
- 0.551
- 0.511
- 0.879
- 0.836
- 0.551
- 0.84
- 0.528
- 0.548
- 0.505
- 0.822
- 0.822
- 0.52
- 0.835
unequal: 0
verbose: 1
