avg_train_accuracy: 0.335
avg_train_loss: 0.002
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.3
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03824468085106383
- 0.08702127659574468
- 0.12670212765957448
- 0.08015957446808511
- 0.09590425531914894
- 0.24388297872340425
- 0.13835106382978724
- 0.38218085106382976
- 0.19287234042553192
- 0.11478723404255319
- 0.14797872340425533
- 0.17909574468085107
- 0.19542553191489362
- 0.40095744680851064
- 0.3898936170212766
- 0.24319148936170212
- 0.4354787234042553
- 0.34877659574468084
- 0.29345744680851066
- 0.3028723404255319
- 0.46377659574468083
- 0.4542553191489362
- 0.3477659574468085
- 0.4845744680851064
- 0.39132978723404255
- 0.48675531914893616
- 0.4921808510638298
- 0.3729787234042553
- 0.4944148936170213
- 0.403031914893617
- 0.21462765957446808
- 0.5106914893617022
- 0.5145744680851064
- 0.3950531914893617
- 0.41510638297872343
- 0.5127659574468085
- 0.515904255319149
- 0.5246808510638298
- 0.3554787234042553
- 0.5324468085106383
- 0.5152659574468085
- 0.5303723404255319
- 0.5237765957446808
- 0.46925531914893615
- 0.5292021276595744
- 0.4895212765957447
- 0.555
- 0.4208510638297872
- 0.5435106382978724
- 0.45420212765957446
- 0.5523936170212767
- 0.5543617021276596
- 0.5640957446808511
- 0.5381382978723405
- 0.5360106382978723
- 0.5182978723404256
- 0.5598936170212766
- 0.47808510638297874
- 0.5085106382978724
- 0.5587765957446809
- 0.42638297872340425
- 0.5612765957446808
- 0.5415425531914894
- 0.5646808510638298
- 0.5678723404255319
- 0.44351063829787235
- 0.5446808510638298
- 0.5757978723404256
- 0.5493085106382979
- 0.4648404255319149
- 0.33111702127659576
- 0.5938297872340426
- 0.5740957446808511
- 0.5701595744680851
- 0.569468085106383
- 0.5653191489361702
- 0.553031914893617
- 0.5688297872340425
- 0.5539893617021276
- 0.569468085106383
- 0.3716489361702128
- 0.4913297872340426
- 0.5180851063829788
- 0.3351063829787234
- 0.5192021276595745
- 0.5915957446808511
- 0.47627659574468084
- 0.5958510638297873
- 0.5283510638297872
- 0.5938297872340426
- 0.5535638297872341
- 0.538936170212766
- 0.5582446808510638
- 0.5789893617021277
- 0.5852659574468085
- 0.558404255319149
- 0.5674468085106383
- 0.5817553191489362
- 0.5870212765957447
- 0.40617021276595744
test_loss_list:
- 4.6245439338684085
- 3.6051565170288087
- 3.430364866256714
- 5.7338394355773925
- 3.671356061299642
- 3.0443574873606365
- 4.010831829706828
- 3.067149035135905
- 3.143885771433512
- 4.698135331471761
- 3.5641331545511883
- 3.0120474592844646
- 2.7745175043741863
- 2.4090763314565025
- 2.438948713938395
- 3.0412540213267008
- 2.35776611328125
- 2.3120654582977296
- 2.4928508027394614
- 2.6092703533172608
- 2.775999329884847
- 2.3239681561787924
- 2.2812031904856362
- 2.842175458272298
- 2.188360087076823
- 2.1697765684127805
- 2.283908397356669
- 2.2716958777109784
- 2.1476713959376017
- 2.0502956024805705
- 3.747192274729411
- 2.0028734731674196
- 2.0620245997111004
- 2.2222510369618735
- 2.221113107999166
- 1.9224409707387289
- 2.0900568469365437
- 2.1396621878941855
- 2.3182092094421387
- 1.8855368041992187
- 1.9044533205032348
- 1.8353042316436767
- 2.6639152558644614
- 1.7764181327819824
- 1.7150601975123088
- 1.7611437606811524
- 1.7406359815597534
- 1.9712703053156535
- 1.6908345127105713
- 1.8850882387161254
- 1.667934579849243
- 1.6628513272603354
- 1.7551718521118165
- 1.7074941857655843
- 2.6062505785624186
- 1.6133620389302572
- 1.7935126479466756
- 1.9671342007319133
- 1.6555908838907878
- 1.6590139468510945
- 1.8182791074117024
- 1.561696349779765
- 2.4463959725697837
- 1.753985137939453
- 1.6168109877904255
- 1.8361664660771688
- 2.4190626748402915
- 1.8115218925476073
- 1.5149227237701417
- 1.8131383196512858
- 2.6970736376444497
- 1.3299887164433797
- 1.5987022574742635
- 1.5401204268137614
- 1.6215366967519125
- 1.8043790467580159
- 2.5020037047068278
- 1.7010460837682089
- 2.514990383783976
- 1.8563652181625365
- 2.31211376508077
- 1.7836138168970743
- 1.5548607015609741
- 2.7558730602264405
- 1.62670804977417
- 1.5083975156148275
- 1.7968887503941853
- 1.4805168835322062
- 1.4857242663701375
- 1.3750170389811198
- 1.4767756605148314
- 1.4284035348892212
- 2.233405687014262
- 1.6575121323267619
- 1.7913436841964723
- 2.4719783719380697
- 1.582050665219625
- 1.3839520899454754
- 1.7170893224080404
- 2.2453782494862873
train_accuracy:
- 0.0
- 0.073
- 0.129
- 0.971
- 0.029
- 0.292
- 0.398
- 0.592
- 0.602
- 0.51
- 0.602
- 0.54
- 0.769
- 0.588
- 0.523
- 0.933
- 0.423
- 0.667
- 0.45
- 0.288
- 0.713
- 0.285
- 0.446
- 0.721
- 0.446
- 0.638
- 0.66
- 0.694
- 0.673
- 0.396
- 0.954
- 0.56
- 0.679
- 0.442
- 0.442
- 0.696
- 0.696
- 0.708
- 0.352
- 0.74
- 0.677
- 0.094
- 0.785
- 0.494
- 0.49
- 0.954
- 0.723
- 0.404
- 0.737
- 0.902
- 0.748
- 0.742
- 0.26
- 0.706
- 0.804
- 0.598
- 0.744
- 0.519
- 0.619
- 0.758
- 0.398
- 0.763
- 0.773
- 0.746
- 0.737
- 0.927
- 0.827
- 0.787
- 0.619
- 0.973
- 0.917
- 0.748
- 0.754
- 0.787
- 0.781
- 0.783
- 0.829
- 0.254
- 0.785
- 0.781
- 0.923
- 0.967
- 0.929
- 0.248
- 0.95
- 0.771
- 0.965
- 0.808
- 0.969
- 0.469
- 0.952
- 0.921
- 0.817
- 0.775
- 0.896
- 0.827
- 0.963
- 0.471
- 0.896
- 0.335
train_loss:
- 2.003
- 2.766
- 2.437
- 0.513
- 1.441
- 1.991
- 0.422
- 2.586
- 1.091
- 0.523
- 0.395
- 0.968
- 1.055
- 1.579
- 1.523
- 0.904
- 1.468
- 0.904
- 0.838
- 0.828
- 1.88
- 1.325
- 0.806
- 1.726
- 0.787
- 1.189
- 1.162
- 0.799
- 1.202
- 0.782
- 0.251
- 1.155
- 1.11
- 0.705
- 0.654
- 1.106
- 1.063
- 1.019
- 0.701
- 1.093
- 1.047
- 1.025
- 1.368
- 0.657
- 1.026
- 0.607
- 0.975
- 0.652
- 0.961
- 0.597
- 0.968
- 0.972
- 0.917
- 0.954
- 1.266
- 0.646
- 0.915
- 0.547
- 0.559
- 0.924
- 0.596
- 0.903
- 1.19
- 0.867
- 0.873
- 0.562
- 1.181
- 0.859
- 0.568
- 0.52
- 0.205
- 0.925
- 0.839
- 0.841
- 0.836
- 0.794
- 1.138
- 0.827
- 1.097
- 0.809
- 0.267
- 0.498
- 0.551
- 0.186
- 0.513
- 0.794
- 0.507
- 0.834
- 0.499
- 0.83
- 0.502
- 0.504
- 1.118
- 0.799
- 0.768
- 1.071
- 0.532
- 0.489
- 0.757
- 0.206
unequal: 0
verbose: 1
