avg_train_accuracy: 0.804
avg_train_loss: 0.012
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05696808510638298
- 0.06202127659574468
- 0.05148936170212766
- 0.048297872340425534
- 0.0673404255319149
- 0.06069148936170213
- 0.07569148936170213
- 0.15095744680851064
- 0.2375
- 0.31792553191489364
- 0.35329787234042553
- 0.062446808510638295
- 0.06175531914893617
- 0.05771276595744681
- 0.05739361702127659
- 0.3401595744680851
- 0.061436170212765956
- 0.37377659574468086
- 0.06542553191489361
- 0.39180851063829786
- 0.06430851063829787
- 0.06170212765957447
- 0.41095744680851065
- 0.4224468085106383
- 0.4346808510638298
- 0.08893617021276595
- 0.07781914893617022
- 0.44718085106382977
- 0.4523404255319149
- 0.4589893617021277
- 0.08680851063829788
- 0.10117021276595745
- 0.08037234042553192
- 0.4684042553191489
- 0.135
- 0.4765957446808511
- 0.4769148936170213
- 0.4820744680851064
- 0.11223404255319148
- 0.4926063829787234
- 0.13909574468085106
- 0.5008510638297873
- 0.1803723404255319
- 0.12234042553191489
- 0.5069148936170212
- 0.19127659574468084
- 0.08478723404255319
- 0.5212765957446809
- 0.5145744680851064
- 0.5147340425531914
- 0.1125
- 0.5247340425531914
- 0.5230851063829787
- 0.23861702127659573
- 0.16388297872340427
- 0.5332978723404256
- 0.14601063829787234
- 0.5346808510638298
- 0.1579255319148936
- 0.5422872340425532
- 0.5314893617021277
- 0.5255851063829787
- 0.5272872340425532
- 0.21648936170212765
- 0.16622340425531915
- 0.1296276595744681
- 0.17579787234042554
- 0.15521276595744682
- 0.5477659574468086
- 0.538563829787234
- 0.18420212765957447
- 0.09813829787234042
- 0.5701595744680851
- 0.20813829787234042
- 0.5642553191489361
- 0.5486170212765957
- 0.23154255319148936
- 0.5670744680851064
- 0.13547872340425532
- 0.5649468085106383
- 0.2826595744680851
- 0.5521276595744681
- 0.3295212765957447
- 0.220531914893617
- 0.5627659574468085
- 0.5464361702127659
- 0.25457446808510636
- 0.56
- 0.5543617021276596
- 0.27787234042553194
- 0.2277127659574468
- 0.17382978723404255
- 0.22861702127659575
- 0.5673936170212766
- 0.5575
- 0.2981382978723404
- 0.23702127659574468
- 0.5731382978723404
- 0.5664361702127659
- 0.56
test_loss_list:
- 17.436422805786133
- 17.552660675048827
- 16.81401486714681
- 17.196004994710286
- 3.768291660944621
- 11.813755696614583
- 3.677739601135254
- 3.5296596240997316
- 3.362612314224243
- 3.2916730658213296
- 3.295463132858276
- 12.55131083170573
- 15.82089121500651
- 14.331031684875489
- 14.358279711405435
- 2.9007138919830324
- 12.602007713317871
- 2.8539443429311118
- 8.589146575927735
- 2.7933291371663413
- 9.934832051595052
- 10.120058352152506
- 2.5456942812601726
- 2.640896100997925
- 2.735585028330485
- 8.11096419652303
- 10.590509020487467
- 2.5188123162587486
- 2.6320530732472736
- 2.683766876856486
- 9.3119486618042
- 7.323894074757894
- 8.467071164449056
- 2.2473451137542724
- 6.443785101572672
- 2.2467351897557575
- 2.3848654810587564
- 2.4897662099202473
- 7.98188907623291
- 2.371829973856608
- 6.509037176767985
- 2.196414473851522
- 5.523283411661784
- 6.991650638580322
- 2.0350360997517902
- 5.50554048538208
- 7.312135334014893
- 1.8337982988357544
- 2.0403831020991006
- 2.1278158235549927
- 6.2741021664937335
- 2.09269571463267
- 2.2395293140411376
- 4.896025377909343
- 6.189925117492676
- 1.9346519708633423
- 6.518025118509929
- 1.8930782461166382
- 6.892588036855062
- 1.9370980230967203
- 2.0849481376012164
- 2.2307939291000367
- 2.1924819644292195
- 5.324565919240316
- 5.41303186416626
- 7.369887345631917
- 6.314322751363118
- 7.571075274149577
- 1.8350703620910644
- 2.0384092124303184
- 6.067804635365804
- 6.4373925654093425
- 1.7026526467005412
- 5.867860171000163
- 1.8516933917999268
- 2.010447106361389
- 5.519592450459798
- 1.9977656253178915
- 5.935319334665934
- 1.9135066668192546
- 4.263433430989584
- 1.7962745094299317
- 4.04610803604126
- 5.058701648712158
- 1.6490315039952597
- 1.8310561847686768
- 4.438655427296957
- 1.6916454283396403
- 1.841138119697571
- 4.563373788197835
- 4.924714495340983
- 6.54938367207845
- 5.46588570912679
- 1.6397172625859577
- 1.8191242074966432
- 4.365124553044637
- 5.57185520807902
- 1.7777324040730795
- 1.8660281292597454
- 2.0029768562316894
train_accuracy:
- 0.694
- 0.977
- 0.454
- 0.406
- 0.031
- 0.931
- 0.077
- 0.229
- 0.358
- 0.463
- 0.517
- 0.99
- 0.938
- 0.785
- 0.735
- 0.502
- 0.917
- 0.565
- 0.994
- 0.585
- 0.783
- 0.942
- 0.606
- 0.625
- 0.654
- 0.954
- 0.973
- 0.652
- 0.677
- 0.688
- 0.921
- 0.973
- 0.963
- 0.648
- 0.927
- 0.713
- 0.717
- 0.713
- 0.95
- 0.723
- 0.996
- 0.719
- 0.981
- 0.942
- 0.75
- 0.996
- 0.967
- 0.74
- 0.756
- 0.74
- 0.975
- 0.744
- 0.763
- 0.979
- 1.0
- 0.765
- 0.898
- 0.752
- 0.973
- 0.763
- 0.767
- 0.794
- 0.794
- 0.979
- 1.0
- 0.998
- 0.981
- 0.988
- 0.777
- 0.771
- 0.975
- 0.977
- 0.808
- 0.983
- 0.79
- 0.775
- 0.988
- 0.802
- 0.973
- 0.794
- 0.985
- 0.806
- 0.988
- 0.983
- 0.785
- 0.798
- 1.0
- 0.798
- 0.8
- 0.983
- 1.0
- 1.0
- 0.983
- 0.8
- 0.8
- 1.0
- 0.979
- 0.821
- 0.806
- 0.804
train_loss:
- 1.179
- 1.204
- 1.304
- 1.728
- 4.093
- 0.975
- 3.959
- 3.604
- 3.267
- 2.937
- 2.667
- 0.736
- 0.955
- 1.112
- 1.734
- 3.334
- 0.67
- 2.872
- 0.619
- 2.682
- 0.825
- 0.755
- 2.668
- 2.193
- 2.029
- 0.667
- 0.2
- 2.325
- 1.891
- 1.884
- 0.784
- 0.53
- 0.598
- 2.3
- 0.763
- 2.043
- 1.728
- 1.635
- 0.617
- 1.811
- 0.673
- 1.897
- 0.49
- 0.617
- 1.898
- 0.398
- 0.611
- 1.921
- 1.459
- 1.526
- 0.408
- 1.658
- 1.378
- 0.441
- 0.468
- 1.75
- 0.706
- 1.622
- 0.382
- 1.635
- 1.415
- 1.276
- 1.343
- 0.668
- 0.519
- 0.101
- 0.391
- 0.152
- 1.799
- 1.311
- 0.529
- 0.596
- 1.646
- 0.332
- 1.493
- 1.236
- 0.335
- 1.421
- 0.413
- 1.513
- 0.56
- 1.458
- 0.26
- 0.565
- 1.537
- 1.28
- 0.502
- 1.39
- 1.216
- 0.414
- 0.357
- 0.079
- 0.295
- 1.565
- 1.222
- 0.264
- 0.337
- 1.428
- 1.182
- 1.172
unequal: 0
verbose: 1
