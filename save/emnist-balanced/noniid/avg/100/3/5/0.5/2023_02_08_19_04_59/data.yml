avg_train_accuracy: 0.787
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.05361702127659575
- 0.04101063829787234
- 0.1048936170212766
- 0.10696808510638298
- 0.17074468085106384
- 0.29148936170212764
- 0.2921808510638298
- 0.2765957446808511
- 0.37079787234042555
- 0.3677659574468085
- 0.41882978723404257
- 0.3171276595744681
- 0.41
- 0.3270212765957447
- 0.4406914893617021
- 0.33117021276595743
- 0.45138297872340427
- 0.44707446808510637
- 0.3827659574468085
- 0.4315425531914894
- 0.4043617021276596
- 0.47074468085106386
- 0.4004255319148936
- 0.4562765957446808
- 0.423936170212766
- 0.47888297872340424
- 0.32872340425531915
- 0.5122872340425532
- 0.516595744680851
- 0.5027127659574468
- 0.48601063829787233
- 0.4443617021276596
- 0.5081382978723404
- 0.5183510638297872
- 0.5229787234042553
- 0.4753191489361702
- 0.538563829787234
- 0.5384574468085106
- 0.38042553191489364
- 0.5511702127659575
- 0.5219148936170213
- 0.53
- 0.5219148936170213
- 0.5613829787234043
- 0.5598936170212766
- 0.5668085106382978
- 0.561595744680851
- 0.5743617021276596
- 0.5438297872340425
- 0.5502659574468085
- 0.5478191489361702
- 0.5523936170212767
- 0.5588829787234042
- 0.5657446808510638
- 0.5757978723404256
- 0.5688829787234042
- 0.5865957446808511
- 0.5590425531914893
- 0.5986702127659574
- 0.5995744680851064
- 0.5438829787234043
- 0.6103191489361702
- 0.575
- 0.6059574468085106
- 0.5871808510638298
- 0.5961702127659575
- 0.591063829787234
- 0.5981382978723404
- 0.6188829787234043
- 0.5916489361702127
- 0.5831382978723404
- 0.5536170212765957
- 0.5640425531914893
- 0.6022872340425532
- 0.606968085106383
- 0.6075
- 0.603404255319149
- 0.606063829787234
- 0.6204255319148936
- 0.5717021276595745
- 0.5869148936170213
- 0.5923936170212766
- 0.6219148936170212
- 0.6092553191489362
- 0.6013829787234043
- 0.6215425531914893
- 0.640531914893617
- 0.6236702127659575
- 0.5710106382978724
- 0.6097340425531915
- 0.6019148936170213
- 0.6246276595744681
- 0.6426063829787234
- 0.6363829787234042
- 0.6360638297872341
- 0.6211702127659574
- 0.6370744680851064
- 0.6255851063829787
- 0.5951063829787234
- 0.6281382978723404
test_loss_list:
- 3.8295326137542727
- 3.9123374017079673
- 3.7265757846832277
- 3.564540599187215
- 3.4746225102742514
- 3.1024025217692057
- 2.8774127038319905
- 2.833510227203369
- 2.899099384943644
- 2.6828486092885337
- 2.940783084233602
- 2.533322318394979
- 2.4671423562367756
- 2.65038600285848
- 2.6343730131785077
- 2.474507656097412
- 2.2965867058436076
- 2.1698992586135866
- 2.330429786046346
- 2.152394350369771
- 2.130863080024719
- 2.108029883702596
- 2.229859550793966
- 2.0125596714019776
- 2.03184232711792
- 2.032372258504232
- 2.4610315926869712
- 1.9299347003300984
- 2.0107055282592774
- 1.7265521987279255
- 1.789882861773173
- 1.927300279935201
- 1.6803433020909628
- 2.3330012877782185
- 2.439364144007365
- 1.9304058329264322
- 1.7772934818267823
- 1.7627518669764202
- 2.308511247634888
- 1.7947387393315632
- 2.102910448710124
- 1.651989754041036
- 1.6016319767634073
- 1.684790391921997
- 1.669622802734375
- 1.6889735047022503
- 1.7718583170572917
- 1.7573947938283285
- 1.9936185423533122
- 1.5945120763778686
- 2.115091395378113
- 1.618620761235555
- 1.6592024707794188
- 1.5957834863662719
- 1.4862158346176146
- 1.559656449953715
- 1.4451328452428183
- 1.4340811522801717
- 1.5261009136835735
- 1.5297129885355631
- 1.5293070189158122
- 1.4875089820226033
- 1.3603708744049072
- 1.5794269816080728
- 1.3527546040217082
- 1.331067910194397
- 1.3808209816614787
- 1.2841953754425048
- 1.2511921914418538
- 1.3738368129730225
- 1.3453184620539347
- 2.6104592355092366
- 2.058698461850484
- 1.3205850807825725
- 1.2738822984695435
- 1.4675341367721557
- 1.3886432123184205
- 1.4678499523798625
- 1.373365486462911
- 1.9839912096659342
- 1.395794628461202
- 1.2784142144521078
- 1.3002091073989868
- 1.289834394454956
- 1.3646487887700398
- 1.2810519552230835
- 1.3032768011093139
- 1.1859965483347574
- 1.8120732911427815
- 1.351542542775472
- 1.2802120447158813
- 1.166523299217224
- 1.261565227508545
- 1.3515851656595865
- 1.2161788177490234
- 1.1860720666249593
- 1.1376971332232158
- 1.2666040070851643
- 1.3321699492136638
- 1.2705391502380372
train_accuracy:
- 0.085
- 0.002
- 0.925
- 0.006
- 0.081
- 0.429
- 0.352
- 0.027
- 0.0
- 0.175
- 0.602
- 0.308
- 0.544
- 0.565
- 0.627
- 0.244
- 0.596
- 0.581
- 0.371
- 0.44
- 0.633
- 0.06
- 0.406
- 0.448
- 0.74
- 0.069
- 0.621
- 0.023
- 0.65
- 0.519
- 0.463
- 0.483
- 0.66
- 0.748
- 0.754
- 0.583
- 0.0
- 0.723
- 0.76
- 0.306
- 0.715
- 0.506
- 0.629
- 0.704
- 0.669
- 0.26
- 0.329
- 0.285
- 0.765
- 0.677
- 0.0
- 0.14
- 0.448
- 0.296
- 0.008
- 0.727
- 0.723
- 0.681
- 0.504
- 0.706
- 0.075
- 0.765
- 0.775
- 0.575
- 0.598
- 0.031
- 0.731
- 0.546
- 0.667
- 0.763
- 0.569
- 0.817
- 0.125
- 0.731
- 0.898
- 0.206
- 0.717
- 0.769
- 0.767
- 0.806
- 0.621
- 0.827
- 0.773
- 0.808
- 0.856
- 0.8
- 0.75
- 0.767
- 0.823
- 0.258
- 0.721
- 0.631
- 0.69
- 0.773
- 0.796
- 0.548
- 0.55
- 0.752
- 0.596
- 0.787
train_loss:
- 2.818
- 2.035
- 1.782
- 1.629
- 1.476
- 2.358
- 1.707
- 1.58
- 1.839
- 1.504
- 1.694
- 1.113
- 1.317
- 1.02
- 1.557
- 0.989
- 1.215
- 1.206
- 0.868
- 0.921
- 0.872
- 1.101
- 0.869
- 0.84
- 0.823
- 1.089
- 0.59
- 1.111
- 1.059
- 0.793
- 0.795
- 0.747
- 0.797
- 1.225
- 1.171
- 0.759
- 0.95
- 0.999
- 0.498
- 0.959
- 1.163
- 0.724
- 0.693
- 0.908
- 0.908
- 0.926
- 0.886
- 0.898
- 1.082
- 0.877
- 1.052
- 0.886
- 0.847
- 0.877
- 0.834
- 0.838
- 0.818
- 0.621
- 0.845
- 0.794
- 0.633
- 0.787
- 0.645
- 0.818
- 0.633
- 0.813
- 0.775
- 0.593
- 0.623
- 0.592
- 0.57
- 1.173
- 0.933
- 0.789
- 0.602
- 0.741
- 0.741
- 0.745
- 0.79
- 0.934
- 0.613
- 0.571
- 0.743
- 0.565
- 0.557
- 0.757
- 0.713
- 0.736
- 0.905
- 0.711
- 0.531
- 0.564
- 0.703
- 0.689
- 0.74
- 0.548
- 0.55
- 0.687
- 0.528
- 0.743
unequal: 0
verbose: 1
