avg_train_accuracy: 0.623
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.024574468085106382
- 0.050159574468085104
- 0.10090425531914894
- 0.15819148936170213
- 0.23558510638297872
- 0.2649468085106383
- 0.28840425531914893
- 0.32648936170212767
- 0.3553191489361702
- 0.3993617021276596
- 0.40861702127659577
- 0.41686170212765955
- 0.3606382978723404
- 0.43840425531914895
- 0.4219148936170213
- 0.4554787234042553
- 0.46824468085106385
- 0.4628191489361702
- 0.453031914893617
- 0.4852659574468085
- 0.48696808510638295
- 0.4750531914893617
- 0.5078723404255319
- 0.5075
- 0.49882978723404253
- 0.5180851063829788
- 0.5205851063829787
- 0.5253191489361703
- 0.4826063829787234
- 0.5440957446808511
- 0.5217553191489361
- 0.5481382978723405
- 0.4870212765957447
- 0.5613829787234043
- 0.5594148936170212
- 0.5651595744680851
- 0.5395744680851063
- 0.5312234042553191
- 0.5571808510638298
- 0.5502127659574468
- 0.5551063829787234
- 0.5739893617021277
- 0.5791489361702128
- 0.5375531914893616
- 0.5776595744680851
- 0.5901063829787234
- 0.5882446808510639
- 0.5399468085106383
- 0.5595744680851064
- 0.5803191489361702
- 0.6054255319148936
- 0.5417021276595745
- 0.6201595744680851
- 0.6021276595744681
- 0.5993085106382978
- 0.5954787234042553
- 0.6011702127659575
- 0.5987765957446809
- 0.6020744680851063
- 0.5981914893617021
- 0.6232978723404256
- 0.5763297872340426
- 0.6072872340425531
- 0.6075531914893617
- 0.6293085106382978
- 0.6196276595744681
- 0.5663829787234043
- 0.6160638297872341
- 0.6110106382978724
- 0.6164893617021276
- 0.6155851063829787
- 0.6387765957446808
- 0.6258510638297873
- 0.626436170212766
- 0.6361702127659574
- 0.6190425531914894
- 0.628031914893617
- 0.621436170212766
- 0.6221276595744681
- 0.6346808510638298
- 0.6267553191489361
- 0.6227127659574468
- 0.5808510638297872
- 0.6314893617021277
- 0.6455851063829787
- 0.6460638297872341
- 0.6425531914893617
- 0.6351063829787233
- 0.6553191489361702
- 0.6001595744680851
- 0.6391489361702127
- 0.5802659574468085
- 0.6062234042553192
- 0.6723404255319149
- 0.6652127659574468
- 0.6049468085106383
- 0.6109574468085106
- 0.6604255319148936
- 0.6002127659574468
- 0.6627127659574468
test_loss_list:
- 3.807084312438965
- 3.795942096710205
- 3.5968940099080404
- 3.283560218811035
- 3.1029880396525065
- 2.8782698663075763
- 2.8398322296142577
- 2.649467271169027
- 2.5476980209350586
- 2.6970251178741456
- 2.443153028488159
- 2.4349306710561116
- 2.3825195916493733
- 2.537061958312988
- 2.231092201868693
- 2.213143507639567
- 2.1752985111872354
- 2.068001346588135
- 1.9981039222081503
- 2.0644905598958334
- 1.965927732785543
- 1.8826007890701293
- 1.757503587404887
- 1.8745563268661498
- 1.7647020800908406
- 1.7184250497817992
- 1.7201724592844645
- 1.6487154960632324
- 1.7367628367741903
- 1.7163074445724487
- 1.6671357520421346
- 1.6158373387654623
- 1.7116408093770346
- 1.4714403009414674
- 1.474078377087911
- 1.6266153748830159
- 1.9380214055379232
- 1.8345910088221231
- 1.503791216214498
- 1.599452888170878
- 1.6335166851679483
- 1.4431450780232746
- 1.4349149942398072
- 1.5425748777389527
- 1.5744006236394246
- 1.3648946460088094
- 1.3931029923756917
- 1.5161944802602132
- 1.7484262561798096
- 1.4159987942377725
- 1.3123688729604086
- 1.5321595478057861
- 1.2766599718729654
- 1.3545981423060098
- 1.2988885513941446
- 1.4051721398035686
- 1.411994924545288
- 1.3849636205037434
- 1.328024935722351
- 1.346892107327779
- 1.2343738667170208
- 1.4054532273610434
- 1.318036831219991
- 1.3007467810312907
- 1.2137654542922973
- 1.2566166098912557
- 1.4315537071228028
- 1.2800669082005818
- 1.2744655148188273
- 1.2667118755976359
- 1.2674839973449707
- 1.1685030190149943
- 1.2321255127588908
- 1.2993731753031412
- 1.1722185564041139
- 1.2791660372416178
- 1.216699268023173
- 1.2607990344365438
- 1.2455811405181885
- 1.182061160405477
- 1.258537588119507
- 1.2379043849309286
- 1.650573697090149
- 1.205427204767863
- 1.1405002919832865
- 1.0955769507090252
- 1.126300117969513
- 1.1846426630020142
- 1.086317892074585
- 1.294395956993103
- 1.208945918083191
- 1.375339150428772
- 1.2737258116404215
- 1.0487270776430766
- 1.0826335120201112
- 1.293339958190918
- 1.2538867362340291
- 1.0629811803499858
- 1.4556860303878785
- 1.0621285923322041
train_accuracy:
- 0.025
- 0.05
- 0.104
- 0.217
- 0.046
- 0.296
- 0.337
- 0.404
- 0.121
- 0.565
- 0.55
- 0.025
- 0.383
- 0.629
- 0.406
- 0.646
- 0.635
- 0.015
- 0.556
- 0.66
- 0.675
- 0.1
- 0.648
- 0.683
- 0.004
- 0.592
- 0.198
- 0.608
- 0.367
- 0.131
- 0.054
- 0.425
- 0.444
- 0.244
- 0.181
- 0.217
- 0.283
- 0.735
- 0.521
- 0.642
- 0.137
- 0.633
- 0.635
- 0.481
- 0.735
- 0.565
- 0.638
- 0.658
- 0.806
- 0.69
- 0.36
- 0.242
- 0.104
- 0.288
- 0.562
- 0.748
- 0.765
- 0.317
- 0.727
- 0.754
- 0.279
- 0.669
- 0.467
- 0.787
- 0.665
- 0.744
- 0.302
- 0.263
- 0.325
- 0.746
- 0.252
- 0.496
- 0.256
- 0.798
- 0.69
- 0.779
- 0.485
- 0.765
- 0.221
- 0.621
- 0.76
- 0.752
- 0.796
- 0.667
- 0.662
- 0.698
- 0.404
- 0.723
- 0.696
- 0.502
- 0.767
- 0.825
- 0.49
- 0.715
- 0.638
- 0.527
- 0.752
- 0.646
- 0.092
- 0.623
train_loss:
- 3.159
- 2.223
- 1.928
- 2.118
- 1.874
- 1.454
- 1.338
- 1.247
- 1.17
- 1.63
- 1.301
- 1.301
- 0.834
- 1.45
- 1.007
- 1.186
- 1.146
- 0.926
- 0.906
- 1.085
- 1.05
- 0.852
- 0.827
- 1.017
- 0.818
- 0.811
- 0.799
- 0.79
- 0.602
- 0.955
- 0.766
- 0.754
- 0.578
- 0.738
- 0.716
- 0.879
- 1.074
- 1.033
- 0.71
- 0.867
- 0.875
- 0.706
- 0.692
- 0.525
- 0.854
- 0.675
- 0.669
- 0.509
- 0.979
- 0.828
- 0.656
- 0.506
- 0.654
- 0.781
- 0.655
- 0.788
- 0.781
- 0.777
- 0.775
- 0.766
- 0.616
- 0.474
- 0.767
- 0.605
- 0.617
- 0.753
- 0.473
- 0.748
- 0.749
- 0.722
- 0.737
- 0.606
- 0.744
- 0.722
- 0.579
- 0.718
- 0.725
- 0.702
- 0.715
- 0.567
- 0.7
- 0.713
- 0.825
- 0.596
- 0.57
- 0.577
- 0.566
- 0.695
- 0.562
- 0.428
- 0.701
- 0.435
- 0.419
- 0.57
- 0.558
- 0.418
- 0.418
- 0.542
- 0.823
- 0.547
unequal: 0
verbose: 1
