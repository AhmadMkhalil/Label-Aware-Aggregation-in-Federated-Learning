avg_train_accuracy: 0.775
avg_train_loss: 0.007
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021382978723404257
- 0.02526595744680851
- 0.11478723404255319
- 0.1448936170212766
- 0.16744680851063828
- 0.2475
- 0.30946808510638296
- 0.28180851063829787
- 0.358031914893617
- 0.33106382978723403
- 0.3754787234042553
- 0.3823936170212766
- 0.4103723404255319
- 0.4045744680851064
- 0.44648936170212766
- 0.4436702127659575
- 0.4392553191489362
- 0.4676595744680851
- 0.3772340425531915
- 0.4475
- 0.4721808510638298
- 0.4821808510638298
- 0.49159574468085104
- 0.4902127659574468
- 0.4871808510638298
- 0.4808510638297872
- 0.49638297872340426
- 0.48319148936170214
- 0.5046276595744681
- 0.5318617021276596
- 0.5096276595744681
- 0.5019148936170212
- 0.5246276595744681
- 0.48531914893617023
- 0.4995212765957447
- 0.5380851063829787
- 0.541968085106383
- 0.5312234042553191
- 0.5246808510638298
- 0.5452127659574468
- 0.5543085106382979
- 0.5792021276595745
- 0.5587765957446809
- 0.5621276595744681
- 0.5060106382978723
- 0.5838829787234042
- 0.5844680851063829
- 0.5493617021276596
- 0.5848404255319148
- 0.5765957446808511
- 0.565
- 0.5823936170212766
- 0.5638829787234042
- 0.5738829787234042
- 0.5787765957446809
- 0.5872872340425532
- 0.5468617021276596
- 0.5681382978723404
- 0.5721276595744681
- 0.5911702127659575
- 0.5587234042553192
- 0.5870744680851064
- 0.5746808510638298
- 0.6021276595744681
- 0.5918085106382979
- 0.5997340425531915
- 0.5920212765957447
- 0.6113829787234043
- 0.6078191489361702
- 0.6087765957446809
- 0.6066489361702128
- 0.6043085106382978
- 0.6009042553191489
- 0.6317553191489361
- 0.6095744680851064
- 0.6317021276595745
- 0.5840425531914893
- 0.5997872340425532
- 0.5759042553191489
- 0.6177659574468085
- 0.6372340425531915
- 0.6053723404255319
- 0.619095744680851
- 0.6225531914893617
- 0.585531914893617
- 0.6220744680851064
- 0.6329255319148936
- 0.594095744680851
- 0.6210106382978723
- 0.63
- 0.5928191489361702
- 0.6497872340425532
- 0.6302659574468085
- 0.5881382978723404
- 0.6366489361702128
- 0.6300531914893617
- 0.6282978723404256
- 0.6307446808510638
- 0.6381914893617021
- 0.6195212765957446
test_loss_list:
- 3.8426840782165526
- 3.777549336751302
- 3.5361452356974286
- 3.371609477996826
- 3.104983720779419
- 2.9405207284291586
- 2.9882199637095135
- 2.726948429743449
- 2.8616157690684
- 2.669804277420044
- 2.523351418177287
- 2.362752211888631
- 2.4483593908945718
- 2.403594897588094
- 2.317976525624593
- 2.4882033475240073
- 2.125875800450643
- 2.2629897689819334
- 2.1644186305999757
- 2.2013097604115806
- 2.155631373723348
- 2.1117742506663006
- 2.1201520919799806
- 1.9814563878377278
- 1.8414694261550903
- 1.906264861424764
- 2.315198671023051
- 1.91786589940389
- 1.784507605234782
- 1.6981940682729084
- 1.7425276803970338
- 1.85221586227417
- 1.8630778058369954
- 1.738321491877238
- 1.6499603096644084
- 1.583183584213257
- 1.5828231207529704
- 1.7784580612182617
- 1.7075485181808472
- 1.5140024948120117
- 1.5058459949493408
- 1.469655712445577
- 1.6090490611394246
- 1.6288294013341267
- 1.623782771428426
- 1.448161392211914
- 1.4457438961664835
- 1.5751181332270305
- 1.5343618599573772
- 1.5079285955429078
- 1.4314773511886596
- 1.5877313756942748
- 1.4515433979034424
- 1.4064704020818075
- 1.5062357981999714
- 1.3367445294062297
- 1.48648028532664
- 1.4110543998082479
- 1.465087939898173
- 1.4596568743387859
- 1.7676220846176147
- 1.3520291058222453
- 1.525852599143982
- 1.3306263971328736
- 1.3155767424901326
- 1.452557044029236
- 1.3195851516723633
- 1.2935577551523845
- 1.3717650429407755
- 1.4438780848185222
- 1.282097150484721
- 1.2695833444595337
- 1.3834306907653808
- 1.1820726426442465
- 1.3245352776845296
- 1.1858798996607463
- 1.3681869188944498
- 1.3396416521072387
- 1.4076596784591675
- 1.3063086875279744
- 1.1523682181040447
- 1.3406137943267822
- 1.2476243527730306
- 1.238034312725067
- 1.6178311856587728
- 1.2178322982788086
- 1.1506866081555684
- 1.3290826527277628
- 1.2704428164164225
- 1.2611415179570515
- 1.3389009030659993
- 1.1359476772944133
- 1.2898760509490967
- 1.4617950487136842
- 1.1635902341206867
- 1.2341456651687621
- 1.1895444504419963
- 1.2208452447255453
- 1.1382629299163818
- 1.2421848376592
train_accuracy:
- 0.0
- 0.0
- 0.15
- 0.0
- 0.0
- 0.0
- 0.0
- 0.306
- 0.0
- 0.058
- 0.227
- 0.131
- 0.6
- 0.012
- 0.008
- 0.0
- 0.173
- 0.612
- 0.383
- 0.633
- 0.196
- 0.202
- 0.685
- 0.669
- 0.598
- 0.215
- 0.0
- 0.635
- 0.052
- 0.021
- 0.646
- 0.658
- 0.679
- 0.469
- 0.177
- 0.342
- 0.458
- 0.706
- 0.713
- 0.419
- 0.671
- 0.66
- 0.74
- 0.158
- 0.317
- 0.419
- 0.61
- 0.256
- 0.756
- 0.123
- 0.631
- 0.108
- 0.644
- 0.406
- 0.225
- 0.671
- 0.469
- 0.515
- 0.002
- 0.742
- 0.783
- 0.631
- 0.785
- 0.504
- 0.358
- 0.252
- 0.627
- 0.302
- 0.756
- 0.746
- 0.69
- 0.467
- 0.775
- 0.175
- 0.767
- 0.625
- 0.519
- 0.771
- 0.56
- 0.785
- 0.648
- 0.337
- 0.665
- 0.494
- 0.815
- 0.735
- 0.383
- 0.885
- 0.798
- 0.783
- 0.565
- 0.535
- 0.246
- 0.096
- 0.517
- 0.265
- 0.794
- 0.81
- 0.452
- 0.775
train_loss:
- 2.636
- 2.087
- 2.246
- 2.059
- 1.567
- 1.752
- 1.994
- 1.34
- 1.805
- 1.467
- 1.414
- 1.12
- 1.33
- 1.331
- 1.24
- 1.453
- 1.01
- 1.188
- 0.767
- 1.171
- 1.137
- 1.145
- 1.097
- 1.09
- 0.882
- 0.897
- 1.23
- 1.059
- 0.882
- 0.828
- 0.84
- 1.014
- 0.981
- 0.63
- 0.614
- 0.795
- 0.79
- 0.974
- 0.947
- 0.761
- 0.742
- 0.735
- 0.92
- 0.894
- 0.569
- 0.724
- 0.709
- 0.895
- 0.877
- 0.855
- 0.716
- 0.858
- 0.702
- 0.671
- 0.831
- 0.685
- 0.508
- 0.507
- 0.828
- 0.795
- 0.963
- 0.657
- 0.797
- 0.646
- 0.655
- 0.785
- 0.635
- 0.622
- 0.77
- 0.762
- 0.642
- 0.61
- 0.77
- 0.622
- 0.751
- 0.619
- 0.468
- 0.764
- 0.473
- 0.766
- 0.608
- 0.735
- 0.592
- 0.589
- 0.862
- 0.601
- 0.596
- 0.436
- 0.735
- 0.724
- 0.453
- 0.575
- 0.688
- 0.837
- 0.565
- 0.716
- 0.69
- 0.714
- 0.559
- 0.679
unequal: 0
verbose: 1
