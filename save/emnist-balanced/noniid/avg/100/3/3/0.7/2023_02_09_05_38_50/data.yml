avg_train_accuracy: 0.817
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033829787234042556
- 0.04239361702127659
- 0.07909574468085107
- 0.1748404255319149
- 0.3227659574468085
- 0.34117021276595744
- 0.3070212765957447
- 0.4070744680851064
- 0.41675531914893615
- 0.3752127659574468
- 0.4753191489361702
- 0.4592553191489362
- 0.4601595744680851
- 0.43090425531914894
- 0.49553191489361703
- 0.48154255319148936
- 0.46239361702127657
- 0.533563829787234
- 0.506968085106383
- 0.4728191489361702
- 0.5486170212765957
- 0.5331914893617021
- 0.5042021276595745
- 0.5563829787234043
- 0.5154787234042553
- 0.5677127659574468
- 0.54
- 0.5580851063829787
- 0.554468085106383
- 0.5869148936170213
- 0.5534042553191489
- 0.5820212765957447
- 0.5921808510638298
- 0.5976063829787234
- 0.5947340425531915
- 0.58
- 0.6041489361702128
- 0.6078191489361702
- 0.6022872340425532
- 0.6095212765957447
- 0.6160638297872341
- 0.6022872340425532
- 0.6178191489361702
- 0.6071276595744681
- 0.6222872340425532
- 0.6225531914893617
- 0.629095744680851
- 0.6285106382978723
- 0.6238297872340426
- 0.6333510638297872
- 0.6323404255319149
- 0.6384574468085107
- 0.6368617021276596
- 0.6360106382978723
- 0.6447872340425532
- 0.6493085106382979
- 0.6515425531914893
- 0.6472872340425532
- 0.6475531914893617
- 0.6614361702127659
- 0.65
- 0.6644148936170213
- 0.6601595744680852
- 0.6507978723404255
- 0.6735638297872341
- 0.6570744680851064
- 0.6602127659574468
- 0.6510106382978723
- 0.6740957446808511
- 0.6540425531914894
- 0.680372340425532
- 0.6597340425531915
- 0.6546808510638298
- 0.6861702127659575
- 0.6677659574468086
- 0.6737765957446809
- 0.6506914893617022
- 0.6696276595744681
- 0.6707446808510639
- 0.673936170212766
- 0.6562765957446809
- 0.6714361702127659
- 0.6706382978723404
- 0.673936170212766
- 0.6740957446808511
- 0.6714893617021277
- 0.6754787234042553
- 0.7014361702127659
- 0.663563829787234
- 0.7013297872340426
- 0.658563829787234
- 0.6765425531914894
- 0.7033510638297872
- 0.7059042553191489
- 0.7125
- 0.6829787234042554
- 0.6773936170212767
- 0.6843617021276596
- 0.6876595744680851
- 0.6768617021276596
test_loss_list:
- 3.785510851542155
- 3.7396543852488198
- 3.560736131668091
- 3.2405954233805336
- 2.9200821431477864
- 2.7112299378712974
- 2.626890468597412
- 2.4421487363179524
- 2.3672898133595783
- 2.318608109156291
- 2.3317674954732257
- 2.2014688523610433
- 2.124663265546163
- 2.0923578691482545
- 2.0460229047139484
- 1.989900172551473
- 1.9401171429951987
- 2.146607149442037
- 1.9479803848266601
- 1.8720895751317341
- 2.043148644765218
- 1.8806639607747395
- 1.7589303620656331
- 1.7797133541107177
- 1.6794062185287475
- 1.7191205883026124
- 1.609182564417521
- 1.5504094998041789
- 1.5389138348897298
- 1.8483948802947998
- 1.5472694540023804
- 1.580466726620992
- 1.5722483777999878
- 1.8050038035710652
- 1.5772269264856975
- 1.424486419359843
- 1.5153098233540854
- 1.513599762916565
- 1.4627177286148072
- 1.7006940905253092
- 1.7262012577056884
- 1.3461898024876913
- 1.4489578596750896
- 1.298906151453654
- 1.3870645968119304
- 1.390022455851237
- 1.6632493940989177
- 1.4177639595667522
- 1.368505334854126
- 1.6250828377405802
- 1.393668721516927
- 1.3651637236277263
- 1.616356177330017
- 1.2064986737569172
- 1.1471144445737202
- 1.1318240944544475
- 1.2606193947792053
- 1.2400851726531983
- 1.2351627270380656
- 1.101497467358907
- 1.2300030692418416
- 1.0774404613176982
- 1.1934457715352376
- 1.196928742726644
- 1.055704156557719
- 1.1848689126968384
- 1.1906172800064088
- 1.4017637332280477
- 1.0498950441678365
- 1.423561741511027
- 1.0421489874521892
- 1.1614750528335571
- 1.4117203013102213
- 1.0022326509157817
- 1.1467689998944601
- 1.1165083384513854
- 1.383537942568461
- 1.1877367401123047
- 1.1291752417882284
- 1.1430430221557617
- 1.393670916557312
- 1.1737807965278626
- 1.1194036054611205
- 1.140839920838674
- 1.0978709959983826
- 1.1150225567817689
- 1.0953434944152831
- 0.940375562508901
- 1.3360998312632242
- 0.9415204954147339
- 1.3381667153040568
- 1.0902575079600016
- 0.9259390664100647
- 0.9117845241228739
- 0.8912274511655172
- 1.0367431886990865
- 1.061327359676361
- 1.0469630201657614
- 1.0656957236925761
- 1.0646531915664672
train_accuracy:
- 0.042
- 0.031
- 0.056
- 0.146
- 0.4
- 0.027
- 0.117
- 0.0
- 0.06
- 0.0
- 0.581
- 0.596
- 0.594
- 0.502
- 0.044
- 0.588
- 0.523
- 0.679
- 0.598
- 0.571
- 0.679
- 0.067
- 0.583
- 0.69
- 0.01
- 0.702
- 0.6
- 0.008
- 0.615
- 0.731
- 0.631
- 0.692
- 0.7
- 0.717
- 0.702
- 0.633
- 0.0
- 0.719
- 0.002
- 0.0
- 0.785
- 0.69
- 0.742
- 0.023
- 0.748
- 0.76
- 0.763
- 0.002
- 0.002
- 0.765
- 0.029
- 0.777
- 0.8
- 0.715
- 0.169
- 0.096
- 0.769
- 0.752
- 0.01
- 0.181
- 0.777
- 0.71
- 0.806
- 0.008
- 0.219
- 0.787
- 0.777
- 0.794
- 0.302
- 0.812
- 0.208
- 0.779
- 0.8
- 0.346
- 0.062
- 0.792
- 0.81
- 0.827
- 0.008
- 0.312
- 0.806
- 0.067
- 0.012
- 0.777
- 0.79
- 0.188
- 0.79
- 0.742
- 0.844
- 0.404
- 0.792
- 0.833
- 0.292
- 0.167
- 0.752
- 0.79
- 0.812
- 0.088
- 0.823
- 0.817
train_loss:
- 3.501
- 2.667
- 2.852
- 2.195
- 2.766
- 2.13
- 1.701
- 1.893
- 1.847
- 1.479
- 1.994
- 1.657
- 1.607
- 1.319
- 1.55
- 1.505
- 1.247
- 1.707
- 1.436
- 1.204
- 1.619
- 1.37
- 1.149
- 1.355
- 1.122
- 1.323
- 1.086
- 1.075
- 1.07
- 1.467
- 1.053
- 1.233
- 1.221
- 1.395
- 1.19
- 0.994
- 1.169
- 1.145
- 1.151
- 1.3
- 1.31
- 0.955
- 1.101
- 0.93
- 1.093
- 1.087
- 1.249
- 1.078
- 1.064
- 1.223
- 1.049
- 1.053
- 1.212
- 0.873
- 0.857
- 0.844
- 1.016
- 1.005
- 1.002
- 0.833
- 0.994
- 0.826
- 0.986
- 0.985
- 0.823
- 0.957
- 0.961
- 1.131
- 0.809
- 1.119
- 0.809
- 0.944
- 1.101
- 0.784
- 0.933
- 0.931
- 1.078
- 0.919
- 0.924
- 0.901
- 1.067
- 0.908
- 0.906
- 0.901
- 0.909
- 0.89
- 0.902
- 0.747
- 1.037
- 0.748
- 1.029
- 0.896
- 0.741
- 0.733
- 0.723
- 0.87
- 0.867
- 0.869
- 0.861
- 0.862
unequal: 0
verbose: 1
