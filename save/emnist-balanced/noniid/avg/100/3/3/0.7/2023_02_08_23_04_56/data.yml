avg_train_accuracy: 0.802
avg_train_loss: 0.01
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.03223404255319149
- 0.04654255319148936
- 0.15531914893617021
- 0.22840425531914893
- 0.270531914893617
- 0.3196276595744681
- 0.32148936170212766
- 0.3772340425531915
- 0.4064893617021277
- 0.4198404255319149
- 0.4677659574468085
- 0.47617021276595745
- 0.48627659574468085
- 0.4297340425531915
- 0.5109574468085106
- 0.4520212765957447
- 0.5101595744680851
- 0.5200531914893617
- 0.5318085106382979
- 0.5369148936170213
- 0.5371808510638297
- 0.5497340425531915
- 0.523936170212766
- 0.558936170212766
- 0.54
- 0.5816489361702127
- 0.5723404255319149
- 0.5576063829787234
- 0.5756382978723404
- 0.5816489361702127
- 0.6010106382978724
- 0.6059574468085106
- 0.6053191489361702
- 0.5895744680851064
- 0.593404255319149
- 0.6080851063829787
- 0.6110106382978724
- 0.6162765957446809
- 0.6222872340425532
- 0.6255851063829787
- 0.6104787234042554
- 0.6096808510638297
- 0.6368085106382979
- 0.6146808510638297
- 0.6202659574468085
- 0.630904255319149
- 0.6267021276595744
- 0.6406914893617022
- 0.6323404255319149
- 0.6461702127659574
- 0.6393085106382979
- 0.6368617021276596
- 0.6281914893617021
- 0.6501063829787234
- 0.632127659574468
- 0.6490957446808511
- 0.640904255319149
- 0.6356382978723404
- 0.6592021276595744
- 0.6460106382978723
- 0.6503723404255319
- 0.6701595744680852
- 0.6510106382978723
- 0.6528723404255319
- 0.6539893617021276
- 0.6722872340425532
- 0.6581382978723405
- 0.6678191489361702
- 0.6574468085106383
- 0.6775
- 0.6621808510638297
- 0.6475531914893617
- 0.6468617021276596
- 0.6741489361702128
- 0.6475531914893617
- 0.6608510638297872
- 0.6628191489361702
- 0.6672872340425532
- 0.663563829787234
- 0.6657978723404255
- 0.6938297872340425
- 0.695531914893617
- 0.6780851063829787
- 0.6923936170212766
- 0.6634574468085106
- 0.6782446808510638
- 0.664468085106383
- 0.6636170212765957
- 0.6679255319148936
- 0.6767553191489362
- 0.6962234042553191
- 0.6845212765957447
- 0.6851063829787234
- 0.6987765957446809
- 0.7014893617021276
- 0.681595744680851
- 0.6578191489361702
- 0.7
- 0.6813297872340426
- 0.6604255319148936
test_loss_list:
- 3.773253625233968
- 3.64191104888916
- 3.4176803843180337
- 3.097055921554565
- 2.8686262798309325
- 2.7232302888234456
- 2.6078826173146568
- 2.4857321071624754
- 2.3586324977874757
- 2.314797681172689
- 2.3133693663279216
- 2.295902163187663
- 2.3152462100982665
- 2.078254558245341
- 2.20329469203949
- 1.9695651086171468
- 1.9592468484242758
- 1.8717229064305623
- 1.835328688621521
- 1.8287480767567952
- 1.772775001525879
- 1.7589948479334514
- 1.6739823246002197
- 1.919148850440979
- 1.613237738609314
- 1.844303585688273
- 1.8541940180460612
- 1.5407453934351603
- 1.4732422558466594
- 1.5623618125915528
- 1.5194173765182495
- 1.5333962027231853
- 1.7327909247080484
- 1.5304968563715617
- 1.390230949719747
- 1.3406218528747558
- 1.3169995260238647
- 1.2966346406936646
- 1.2689295291900635
- 1.25779039700826
- 1.6256389315923054
- 1.4040636412302654
- 1.3662955379486084
- 1.3851654434204101
- 1.3936219294865926
- 1.24117303053538
- 1.3564795446395874
- 1.2108315849304199
- 1.3322060839335124
- 1.183338991800944
- 1.2864584334691365
- 1.2942990064620972
- 1.584752786954244
- 1.292362993558248
- 1.5909891096750894
- 1.175002277692159
- 1.4991370582580565
- 1.544078934987386
- 1.1371584431330364
- 1.2551693503061931
- 1.2331840387980144
- 1.0840705060958862
- 1.2201288572947184
- 1.2236646461486815
- 1.1968678458531699
- 1.0574581543604533
- 1.1876852989196778
- 1.1559353494644165
- 1.1729229195912678
- 1.0447376950581868
- 1.152352953751882
- 1.41723841826121
- 1.4665040969848633
- 1.0515280485153198
- 1.4085752407709757
- 1.174807300567627
- 1.1631026458740235
- 1.1413532670338948
- 1.1428327973683674
- 1.13857892036438
- 0.9834193142255148
- 0.9727644673983256
- 1.094259934425354
- 0.9660196765263875
- 1.3342410230636597
- 1.1065159336725872
- 1.3861185534795126
- 1.123241151968638
- 1.1264620884259542
- 1.0891197458902995
- 0.9573900643984476
- 1.0764417465527851
- 1.0833351222674052
- 0.9506964540481567
- 0.9275147120157877
- 1.0542429407437643
- 1.3233110936482748
- 0.9474706800778707
- 1.0632494115829467
- 1.3367074394226075
train_accuracy:
- 0.065
- 0.05
- 0.0
- 0.304
- 0.0
- 0.362
- 0.017
- 0.0
- 0.0
- 0.544
- 0.579
- 0.565
- 0.608
- 0.502
- 0.656
- 0.029
- 0.0
- 0.592
- 0.648
- 0.606
- 0.667
- 0.048
- 0.585
- 0.0
- 0.583
- 0.681
- 0.717
- 0.571
- 0.665
- 0.715
- 0.725
- 0.71
- 0.0
- 0.675
- 0.45
- 0.648
- 0.137
- 0.638
- 0.175
- 0.085
- 0.725
- 0.742
- 0.729
- 0.708
- 0.731
- 0.192
- 0.019
- 0.671
- 0.723
- 0.208
- 0.023
- 0.079
- 0.775
- 0.752
- 0.019
- 0.685
- 0.004
- 0.815
- 0.094
- 0.056
- 0.792
- 0.383
- 0.773
- 0.119
- 0.754
- 0.298
- 0.756
- 0.165
- 0.775
- 0.454
- 0.763
- 0.787
- 0.792
- 0.708
- 0.794
- 0.031
- 0.773
- 0.027
- 0.81
- 0.779
- 0.702
- 0.706
- 0.821
- 0.754
- 0.815
- 0.077
- 0.821
- 0.833
- 0.794
- 0.058
- 0.763
- 0.054
- 0.796
- 0.275
- 0.713
- 0.829
- 0.796
- 0.727
- 0.819
- 0.802
train_loss:
- 2.815
- 2.479
- 3.172
- 2.489
- 2.26
- 2.103
- 1.969
- 1.875
- 1.803
- 1.729
- 1.942
- 1.866
- 1.817
- 1.308
- 1.726
- 1.245
- 1.437
- 1.405
- 1.38
- 1.343
- 1.358
- 1.318
- 1.094
- 1.501
- 1.078
- 1.461
- 1.433
- 1.035
- 1.007
- 1.197
- 1.178
- 1.166
- 1.336
- 1.152
- 0.952
- 0.95
- 0.936
- 0.927
- 0.914
- 0.908
- 1.27
- 1.084
- 1.066
- 1.064
- 1.055
- 0.876
- 1.044
- 0.866
- 1.024
- 0.856
- 1.023
- 1.024
- 1.172
- 1.002
- 1.155
- 0.845
- 1.157
- 1.156
- 0.83
- 0.975
- 0.972
- 0.809
- 0.969
- 0.956
- 0.96
- 0.8
- 0.95
- 0.945
- 0.944
- 0.782
- 0.935
- 1.082
- 1.077
- 0.785
- 1.075
- 0.92
- 0.913
- 0.914
- 0.91
- 0.898
- 0.756
- 0.749
- 0.903
- 0.753
- 1.033
- 0.891
- 1.029
- 0.898
- 0.888
- 0.878
- 0.74
- 0.87
- 0.867
- 0.732
- 0.725
- 0.871
- 1.012
- 0.728
- 0.862
- 0.998
unequal: 0
verbose: 1
