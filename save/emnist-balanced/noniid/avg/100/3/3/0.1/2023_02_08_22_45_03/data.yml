avg_train_accuracy: 0.835
avg_train_loss: 0.011
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.039361702127659576
- 0.05228723404255319
- 0.09547872340425533
- 0.2323936170212766
- 0.32611702127659575
- 0.400531914893617
- 0.45601063829787236
- 0.49042553191489363
- 0.0625
- 0.509468085106383
- 0.5217021276595745
- 0.06095744680851064
- 0.5216489361702128
- 0.5405319148936171
- 0.5500531914893617
- 0.5595744680851064
- 0.568936170212766
- 0.5730851063829787
- 0.06813829787234042
- 0.5889893617021277
- 0.5900531914893618
- 0.5949468085106383
- 0.5967021276595744
- 0.0627127659574468
- 0.595531914893617
- 0.599095744680851
- 0.6025531914893617
- 0.6055851063829787
- 0.6098404255319149
- 0.0647872340425532
- 0.06324468085106383
- 0.6080319148936171
- 0.08707446808510638
- 0.6111702127659574
- 0.6120212765957447
- 0.6184042553191489
- 0.6155851063829787
- 0.6239893617021277
- 0.14324468085106384
- 0.6361702127659574
- 0.06765957446808511
- 0.11569148936170212
- 0.6329787234042553
- 0.6330851063829788
- 0.6287765957446808
- 0.6334042553191489
- 0.6325
- 0.095
- 0.6363829787234042
- 0.6311702127659574
- 0.6347872340425532
- 0.631436170212766
- 0.6376063829787234
- 0.09047872340425532
- 0.6360106382978723
- 0.6375
- 0.6363829787234042
- 0.641595744680851
- 0.12154255319148936
- 0.11388297872340425
- 0.6527127659574468
- 0.6456382978723404
- 0.6411170212765958
- 0.6422872340425532
- 0.15909574468085105
- 0.6463297872340426
- 0.20638297872340425
- 0.17122340425531915
- 0.660372340425532
- 0.6507446808510639
- 0.6491489361702127
- 0.6464893617021277
- 0.6480851063829787
- 0.6451063829787234
- 0.6492553191489362
- 0.6490425531914894
- 0.17888297872340425
- 0.1327127659574468
- 0.6637765957446808
- 0.6518617021276596
- 0.2643617021276596
- 0.668936170212766
- 0.1651063829787234
- 0.6702659574468085
- 0.658563829787234
- 0.6567021276595745
- 0.6537234042553192
- 0.6579255319148937
- 0.6554255319148936
- 0.6572872340425532
- 0.6569148936170213
- 0.6556914893617021
- 0.6543085106382979
- 0.6587765957446808
- 0.6571276595744681
- 0.20893617021276595
- 0.658936170212766
- 0.6575531914893618
- 0.6564893617021277
- 0.6577127659574468
test_loss_list:
- 3.791164544423421
- 3.765980898539225
- 3.6775259526570636
- 3.4471970494588215
- 3.1625361601511637
- 2.9906158701578778
- 2.907951456705729
- 2.854919376373291
- 15.14370273590088
- 2.4662773259480795
- 2.529669090906779
- 13.951959966023763
- 2.3211410427093506
- 2.401023400624593
- 2.433156706492106
- 2.4642131614685057
- 2.54891370455424
- 2.547706890106201
- 9.288029492696126
- 2.2499620008468626
- 2.3637415838241576
- 2.3734518909454345
- 2.463843504587809
- 13.064263979593912
- 2.1428449662526448
- 2.2505571619669595
- 2.2834033521016437
- 2.3680346043904623
- 2.3679965941111245
- 10.012520662943523
- 11.162211151123048
- 1.6849963808059691
- 7.157843106587728
- 1.7961315170923868
- 1.9400083843866984
- 1.9915626382827758
- 2.076673992474874
- 2.1116514825820922
- 6.060178737640381
- 1.7855526574452718
- 9.053226051330567
- 6.443214232126872
- 1.5130725606282551
- 1.6447827482223512
- 1.7166923840840658
- 1.7562638028462727
- 1.8404664119084677
- 6.596290391286214
- 1.6157560952504475
- 1.6947430817286173
- 1.781249917348226
- 1.8155927848815918
- 1.861566801071167
- 7.456035582224528
- 1.6095701217651368
- 1.7294987440109253
- 1.7839878908793132
- 1.8023979155222576
- 6.025219955444336
- 7.103488279978435
- 1.4088819487889608
- 1.5289804808298746
- 1.6291764672597249
- 1.672587701479594
- 6.224212055206299
- 1.5710769319534301
- 5.553260885874431
- 5.275936342875163
- 1.2560613361994426
- 1.3800743452707926
- 1.4667212088902792
- 1.56890691280365
- 1.59530810991923
- 1.625185612042745
- 1.6810467672348022
- 1.6873655303319295
- 5.7296003723144535
- 6.073741467793782
- 1.2580941979090372
- 1.3759158595403036
- 4.385682039260864
- 1.2574733400344849
- 5.2853125
- 1.2154760805765787
- 1.3346861632665
- 1.394324345588684
- 1.4682071352005004
- 1.5464419635136921
- 1.5647198136647542
- 1.6311871258417765
- 1.60841725508372
- 1.6608434057235717
- 1.6948553943634033
- 1.7156794293721518
- 1.7660081720352172
- 5.159721177419026
- 1.470112805366516
- 1.5447099208831787
- 1.6232092873255413
- 1.6736823558807372
train_accuracy:
- 0.046
- 0.058
- 0.125
- 0.29
- 0.398
- 0.5
- 0.558
- 0.64
- 0.99
- 0.604
- 0.66
- 0.921
- 0.658
- 0.673
- 0.665
- 0.717
- 0.71
- 0.702
- 0.985
- 0.706
- 0.723
- 0.758
- 0.76
- 0.981
- 0.737
- 0.74
- 0.756
- 0.767
- 0.783
- 0.985
- 0.969
- 0.721
- 0.988
- 0.765
- 0.804
- 0.756
- 0.783
- 0.781
- 0.99
- 0.775
- 0.969
- 0.99
- 0.767
- 0.763
- 0.777
- 0.781
- 0.792
- 0.996
- 0.781
- 0.785
- 0.767
- 0.808
- 0.794
- 0.981
- 0.8
- 0.787
- 0.79
- 0.787
- 0.998
- 0.985
- 0.79
- 0.79
- 0.806
- 0.79
- 0.985
- 0.817
- 0.983
- 0.992
- 0.796
- 0.833
- 0.8
- 0.81
- 0.804
- 0.81
- 0.815
- 0.808
- 0.985
- 0.994
- 0.806
- 0.831
- 0.99
- 0.823
- 1.0
- 0.823
- 0.829
- 0.8
- 0.819
- 0.804
- 0.829
- 0.817
- 0.815
- 0.829
- 0.825
- 0.812
- 0.833
- 0.985
- 0.81
- 0.81
- 0.81
- 0.835
train_loss:
- 3.836
- 3.794
- 3.717
- 3.499
- 3.113
- 2.736
- 2.537
- 2.34
- 0.738
- 2.688
- 2.15
- 1.063
- 2.506
- 1.986
- 1.922
- 1.841
- 1.78
- 1.75
- 0.574
- 1.988
- 1.662
- 1.635
- 1.599
- 0.62
- 2.004
- 1.558
- 1.535
- 1.47
- 1.496
- 0.456
- 1.284
- 2.125
- 0.307
- 1.726
- 1.454
- 1.434
- 1.405
- 1.419
- 0.606
- 1.596
- 0.605
- 0.468
- 1.759
- 1.339
- 1.363
- 1.358
- 1.33
- 0.481
- 1.493
- 1.305
- 1.23
- 1.284
- 1.282
- 0.498
- 1.521
- 1.211
- 1.163
- 1.304
- 0.434
- 0.398
- 1.587
- 1.28
- 1.213
- 1.218
- 0.338
- 1.387
- 0.23
- 0.617
- 1.51
- 1.27
- 1.261
- 1.157
- 1.143
- 1.203
- 1.117
- 1.198
- 0.348
- 0.522
- 1.497
- 1.238
- 0.424
- 1.295
- 0.31
- 1.397
- 1.151
- 1.17
- 1.139
- 1.081
- 1.135
- 1.051
- 1.134
- 1.102
- 1.107
- 1.112
- 1.072
- 0.45
- 1.295
- 1.163
- 1.11
- 1.069
unequal: 0
verbose: 1
