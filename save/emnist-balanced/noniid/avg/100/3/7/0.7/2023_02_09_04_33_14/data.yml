avg_train_accuracy: 0.725
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04069148936170213
- 0.08361702127659575
- 0.08558510638297873
- 0.1296808510638298
- 0.18659574468085105
- 0.12462765957446809
- 0.2643617021276596
- 0.2570212765957447
- 0.24218085106382978
- 0.2763829787234043
- 0.2796808510638298
- 0.30617021276595746
- 0.3392553191489362
- 0.3325531914893617
- 0.39218085106382977
- 0.25659574468085106
- 0.3903723404255319
- 0.36920212765957444
- 0.39632978723404255
- 0.39664893617021274
- 0.4071808510638298
- 0.40154255319148935
- 0.35579787234042554
- 0.28898936170212763
- 0.43803191489361704
- 0.438563829787234
- 0.42398936170212764
- 0.4025531914893617
- 0.4479255319148936
- 0.4651595744680851
- 0.44377659574468087
- 0.4605851063829787
- 0.3997340425531915
- 0.4679255319148936
- 0.4701595744680851
- 0.4697872340425532
- 0.4752659574468085
- 0.47840425531914893
- 0.4126595744680851
- 0.4951063829787234
- 0.4882446808510638
- 0.48569148936170214
- 0.5082978723404256
- 0.49303191489361703
- 0.4976595744680851
- 0.4668617021276596
- 0.5313297872340426
- 0.4192021276595745
- 0.545904255319149
- 0.5099468085106383
- 0.5263297872340426
- 0.45851063829787236
- 0.546063829787234
- 0.49920212765957445
- 0.5348936170212766
- 0.4675
- 0.46617021276595744
- 0.5251595744680851
- 0.46930851063829787
- 0.5581914893617022
- 0.5410106382978723
- 0.5305319148936171
- 0.5368617021276596
- 0.5311702127659574
- 0.5612765957446808
- 0.5377659574468086
- 0.4405851063829787
- 0.5610106382978723
- 0.5378723404255319
- 0.5422872340425532
- 0.5364361702127659
- 0.5557446808510639
- 0.5436702127659574
- 0.5792021276595745
- 0.5713297872340426
- 0.5753191489361702
- 0.48627659574468085
- 0.5870744680851064
- 0.5822872340425532
- 0.5384042553191489
- 0.5836170212765958
- 0.5731382978723404
- 0.5395744680851063
- 0.5823404255319149
- 0.5877659574468085
- 0.556968085106383
- 0.5976063829787234
- 0.5648936170212766
- 0.5946808510638298
- 0.4262234042553191
- 0.5632978723404255
- 0.5912765957446808
- 0.5864893617021276
- 0.5853723404255319
- 0.6020744680851063
- 0.5217553191489361
- 0.5780851063829787
- 0.5966489361702128
- 0.5305319148936171
- 0.5753191489361702
test_loss_list:
- 4.0968026924133305
- 3.730046720504761
- 3.497428477605184
- 3.3576901308695475
- 3.152511863708496
- 3.306923615137736
- 2.884218292236328
- 2.769675366083781
- 2.827731596628825
- 2.7487886842091878
- 2.729066670735677
- 2.530044666926066
- 2.54068878809611
- 2.455464522043864
- 2.335946289698283
- 2.656822477976481
- 2.364614022572835
- 2.321567808787028
- 2.317914482752482
- 2.352185360590617
- 2.1979193751017254
- 2.151344076792399
- 2.329013776779175
- 2.67260222752889
- 2.0360330136617026
- 2.092992075284322
- 2.04007081190745
- 2.1368712266286214
- 2.0088657697041827
- 1.8652224175135295
- 1.9126028601328533
- 1.8852194945017497
- 2.1795354874928794
- 1.9024031114578248
- 1.9116300137837727
- 1.885351332028707
- 1.8500671974817913
- 1.822949055035909
- 2.0395904350280762
- 1.704401445388794
- 1.7626606845855712
- 1.7548379405339558
- 1.706669438680013
- 1.6866253582636515
- 1.7400059207280476
- 1.8704091691970826
- 1.5963250335057577
- 1.9948914194107055
- 1.4986198774973551
- 1.6841039244333904
- 1.5916099421183267
- 1.8677259890238445
- 1.492281076113383
- 1.6568490028381349
- 1.5780073054631552
- 1.859661405881246
- 1.8531164598464966
- 1.5460672362645467
- 1.8371584177017213
- 1.438135887781779
- 1.5541684039433796
- 1.5219256528218588
- 1.5064364353815713
- 1.5946462837855022
- 1.466038751602173
- 1.500948839187622
- 1.9972642358144124
- 1.431334867477417
- 1.491866536140442
- 1.4676743268966674
- 1.5292234992980958
- 1.4165070279439291
- 1.4709930737813315
- 1.3487418222427368
- 1.3988914521535238
- 1.3684572235743204
- 1.7616247336069744
- 1.3119153340657552
- 1.3568778244654338
- 1.5119119358062745
- 1.3211120907465617
- 1.3525124677022298
- 1.5793484703699747
- 1.3396678558985393
- 1.3484154240290325
- 1.3847332270940145
- 1.2898658688863118
- 1.3863887214660644
- 1.3027223904927572
- 2.2448798322677614
- 1.4046626710891723
- 1.2693119192123412
- 1.344161639213562
- 1.3135482947031656
- 1.258606554667155
- 1.6379966497421266
- 1.3378100792566936
- 1.2851448647181194
- 1.6093392531077066
- 1.3379754956563314
train_accuracy:
- 0.0
- 0.11
- 0.081
- 0.117
- 0.004
- 0.008
- 0.083
- 0.002
- 0.171
- 0.267
- 0.244
- 0.058
- 0.123
- 0.379
- 0.035
- 0.319
- 0.002
- 0.429
- 0.01
- 0.54
- 0.604
- 0.119
- 0.06
- 0.037
- 0.473
- 0.592
- 0.044
- 0.706
- 0.006
- 0.415
- 0.479
- 0.502
- 0.096
- 0.688
- 0.596
- 0.627
- 0.502
- 0.185
- 0.21
- 0.269
- 0.513
- 0.492
- 0.371
- 0.435
- 0.669
- 0.481
- 0.133
- 0.319
- 0.333
- 0.529
- 0.779
- 0.36
- 0.6
- 0.496
- 0.704
- 0.421
- 0.644
- 0.548
- 0.648
- 0.4
- 0.306
- 0.571
- 0.131
- 0.9
- 0.606
- 0.696
- 0.623
- 0.606
- 0.458
- 0.554
- 0.8
- 0.194
- 0.5
- 0.602
- 0.692
- 0.625
- 0.619
- 0.396
- 0.61
- 0.523
- 0.454
- 0.575
- 0.833
- 0.585
- 0.529
- 0.64
- 0.69
- 0.658
- 0.787
- 0.554
- 0.86
- 0.39
- 0.569
- 0.585
- 0.735
- 0.346
- 0.521
- 0.575
- 0.844
- 0.725
train_loss:
- 1.696
- 1.864
- 1.332
- 1.177
- 1.059
- 0.715
- 1.263
- 0.925
- 0.866
- 0.832
- 0.801
- 0.804
- 1.019
- 0.751
- 0.959
- 0.524
- 0.921
- 0.703
- 0.884
- 0.856
- 0.836
- 0.639
- 0.453
- 0.266
- 0.815
- 0.776
- 0.63
- 0.608
- 0.765
- 0.602
- 0.571
- 0.557
- 0.395
- 0.732
- 0.723
- 0.726
- 0.543
- 0.543
- 0.397
- 0.528
- 0.528
- 0.541
- 0.673
- 0.52
- 0.677
- 0.515
- 0.515
- 0.366
- 0.521
- 0.496
- 0.49
- 0.358
- 0.491
- 0.498
- 0.648
- 0.349
- 0.344
- 0.493
- 0.337
- 0.479
- 0.61
- 0.471
- 0.6
- 0.464
- 0.468
- 0.608
- 0.325
- 0.464
- 0.454
- 0.448
- 0.459
- 0.569
- 0.456
- 0.438
- 0.571
- 0.437
- 0.307
- 0.437
- 0.428
- 0.438
- 0.431
- 0.438
- 0.299
- 0.411
- 0.417
- 0.425
- 0.416
- 0.423
- 0.426
- 0.167
- 0.429
- 0.543
- 0.43
- 0.419
- 0.541
- 0.295
- 0.414
- 0.417
- 0.278
- 0.422
unequal: 0
verbose: 1
