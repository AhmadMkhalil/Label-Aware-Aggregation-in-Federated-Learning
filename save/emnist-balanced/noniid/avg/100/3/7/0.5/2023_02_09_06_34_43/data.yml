avg_train_accuracy: 0.681
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06585106382978724
- 0.09180851063829787
- 0.08345744680851064
- 0.10845744680851063
- 0.10787234042553191
- 0.10872340425531915
- 0.16936170212765958
- 0.1423936170212766
- 0.151968085106383
- 0.2743617021276596
- 0.15718085106382979
- 0.326063829787234
- 0.33276595744680854
- 0.33622340425531916
- 0.24638297872340426
- 0.2803191489361702
- 0.38042553191489364
- 0.17718085106382978
- 0.3707446808510638
- 0.29909574468085104
- 0.20138297872340424
- 0.42569148936170215
- 0.40122340425531916
- 0.35117021276595745
- 0.3300531914893617
- 0.26340425531914896
- 0.29356382978723405
- 0.3221276595744681
- 0.2696276595744681
- 0.45872340425531916
- 0.2777659574468085
- 0.4452659574468085
- 0.3337765957446808
- 0.4472340425531915
- 0.363936170212766
- 0.4504255319148936
- 0.4629255319148936
- 0.30372340425531913
- 0.4747872340425532
- 0.29132978723404257
- 0.4167021276595745
- 0.49303191489361703
- 0.4403191489361702
- 0.4798404255319149
- 0.4773936170212766
- 0.48909574468085104
- 0.4970212765957447
- 0.515904255319149
- 0.485531914893617
- 0.3448404255319149
- 0.33276595744680854
- 0.408031914893617
- 0.5137765957446808
- 0.4930851063829787
- 0.5251595744680851
- 0.5262234042553191
- 0.5260638297872341
- 0.38132978723404254
- 0.5056382978723404
- 0.3006382978723404
- 0.40664893617021275
- 0.49622340425531913
- 0.42106382978723406
- 0.41925531914893616
- 0.54
- 0.4957446808510638
- 0.31803191489361704
- 0.5315425531914894
- 0.4536702127659574
- 0.5402127659574468
- 0.5149468085106383
- 0.506968085106383
- 0.3121276595744681
- 0.2802127659574468
- 0.5567553191489362
- 0.5534574468085106
- 0.5251063829787234
- 0.3347340425531915
- 0.5505851063829788
- 0.5676063829787235
- 0.5527659574468086
- 0.41377659574468084
- 0.3476063829787234
- 0.5496276595744681
- 0.5817553191489362
- 0.5563297872340426
- 0.39372340425531915
- 0.5469148936170213
- 0.29106382978723405
- 0.5715425531914894
- 0.4722872340425532
- 0.48601063829787233
- 0.5727659574468085
- 0.43946808510638297
- 0.5183510638297872
- 0.5239893617021276
- 0.38148936170212766
- 0.5791489361702128
- 0.5893085106382979
- 0.5552127659574468
test_loss_list:
- 4.255067246754964
- 3.7474596945444745
- 4.047607873280843
- 3.8625754070281983
- 3.7431823507944744
- 3.4996091683705646
- 3.195504185358683
- 3.3922986443837484
- 3.3494056542714437
- 2.7775240739186606
- 3.9525725078582763
- 2.933920710881551
- 2.5658313910166424
- 2.5434068139394124
- 2.738694241841634
- 2.5875262705485027
- 2.8256945323944094
- 3.4167881043752035
- 2.3316435527801516
- 2.6266913763682047
- 4.24080046971639
- 2.1068796904881797
- 2.1389814472198485
- 2.294440673192342
- 2.3343633015950522
- 2.781557642618815
- 2.6519627380371094
- 2.514931974411011
- 2.9059666442871093
- 1.940016403198242
- 2.7922572040557863
- 1.940509794553121
- 2.3703737163543703
- 2.0310663636525472
- 2.217242368062337
- 2.4352609062194825
- 1.8775209108988444
- 2.735133129755656
- 1.8134046204884846
- 2.7360500621795656
- 1.9665584309895834
- 1.7334059556325276
- 1.9010871696472167
- 1.8064861694971721
- 1.8268056329091389
- 1.7382140445709229
- 1.695018417040507
- 1.7321831130981444
- 1.7423435179392497
- 2.530211404164632
- 2.4103700160980224
- 2.058792068163554
- 1.6969034194946289
- 1.7327775398890177
- 1.631958802541097
- 1.5885956255594889
- 1.5726531839370728
- 2.0832677618662516
- 1.6438373486200968
- 3.692140614191691
- 2.048310720125834
- 1.6435389296213785
- 1.9702271763483683
- 2.0696131420135497
- 1.4808849223454794
- 1.9293316396077473
- 2.730267744064331
- 1.585992382367452
- 1.806474231084188
- 1.5234349409739176
- 1.812360200881958
- 1.8586309067408244
- 3.2640833981831867
- 3.6801523844401043
- 1.4434542353947957
- 1.4532931057612102
- 1.5517776330312094
- 2.96517076810201
- 1.4679242769877117
- 1.4341870546340942
- 1.485384399096171
- 2.078336404164632
- 2.9949275080362954
- 1.4747915045420328
- 1.3586300039291381
- 1.3765898068745932
- 2.2033430528640747
- 1.4748575369517007
- 3.599492435455322
- 1.3555866225560507
- 1.7232068395614624
- 1.6431264066696167
- 1.3475046459833782
- 2.0030649534861245
- 1.733819530804952
- 1.5323300568262737
- 2.658042949040731
- 1.348081005414327
- 1.3116445430119832
- 1.3830689096450806
train_accuracy:
- 0.89
- 0.002
- 0.025
- 0.0
- 0.348
- 0.0
- 0.652
- 0.052
- 0.237
- 0.227
- 0.248
- 0.029
- 0.192
- 0.008
- 0.19
- 0.212
- 0.071
- 0.0
- 0.279
- 0.348
- 0.233
- 0.208
- 0.529
- 0.558
- 0.581
- 0.088
- 0.204
- 0.175
- 0.454
- 0.604
- 0.606
- 0.573
- 0.573
- 0.333
- 0.59
- 0.694
- 0.594
- 0.677
- 0.494
- 0.165
- 0.342
- 0.585
- 0.348
- 0.652
- 0.525
- 0.546
- 0.7
- 0.592
- 0.533
- 0.212
- 0.84
- 0.723
- 0.702
- 0.577
- 0.562
- 0.579
- 0.581
- 0.144
- 0.525
- 0.667
- 0.908
- 0.429
- 0.723
- 0.904
- 0.627
- 0.26
- 0.846
- 0.66
- 0.598
- 0.55
- 0.442
- 0.49
- 0.927
- 0.925
- 0.644
- 0.677
- 0.567
- 0.825
- 0.644
- 0.675
- 0.773
- 0.833
- 0.835
- 0.696
- 0.863
- 0.744
- 0.267
- 0.552
- 0.669
- 0.088
- 0.588
- 0.781
- 0.492
- 0.812
- 0.783
- 0.596
- 0.65
- 0.537
- 0.656
- 0.681
train_loss:
- 1.593
- 1.883
- 1.083
- 1.036
- 0.965
- 0.887
- 1.323
- 0.782
- 0.804
- 1.136
- 0.375
- 1.463
- 1.041
- 0.969
- 0.696
- 0.619
- 1.248
- 0.381
- 0.963
- 0.59
- 0.299
- 0.878
- 0.843
- 0.863
- 0.568
- 0.518
- 0.522
- 0.56
- 0.527
- 0.787
- 0.542
- 0.787
- 0.509
- 0.729
- 0.509
- 0.988
- 0.751
- 0.501
- 0.721
- 0.499
- 0.473
- 0.709
- 0.684
- 0.69
- 0.685
- 0.675
- 0.684
- 0.676
- 0.661
- 0.448
- 0.445
- 0.442
- 0.632
- 0.608
- 0.663
- 0.671
- 0.624
- 0.442
- 0.632
- 0.218
- 0.418
- 0.606
- 0.437
- 0.409
- 0.635
- 0.807
- 0.416
- 0.634
- 0.413
- 0.598
- 0.784
- 0.767
- 0.222
- 0.213
- 0.605
- 0.599
- 0.588
- 0.211
- 0.587
- 0.58
- 0.557
- 0.382
- 0.192
- 0.571
- 0.572
- 0.566
- 0.357
- 0.539
- 0.197
- 0.579
- 0.362
- 0.37
- 0.546
- 0.362
- 0.735
- 0.528
- 0.207
- 0.541
- 0.555
- 0.513
unequal: 0
verbose: 1
