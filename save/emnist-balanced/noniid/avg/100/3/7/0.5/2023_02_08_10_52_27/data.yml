avg_train_accuracy: 0.685
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0400531914893617
- 0.08218085106382979
- 0.07037234042553192
- 0.08984042553191489
- 0.11851063829787234
- 0.11579787234042553
- 0.24611702127659574
- 0.1151063829787234
- 0.16031914893617022
- 0.2522872340425532
- 0.2886170212765957
- 0.19382978723404257
- 0.3470744680851064
- 0.32893617021276594
- 0.2878191489361702
- 0.2784042553191489
- 0.2778191489361702
- 0.24430851063829787
- 0.3180851063829787
- 0.35654255319148936
- 0.3402659574468085
- 0.1778191489361702
- 0.4067021276595745
- 0.3022872340425532
- 0.36648936170212765
- 0.385
- 0.34111702127659577
- 0.2655851063829787
- 0.34388297872340423
- 0.39356382978723403
- 0.4221808510638298
- 0.41856382978723405
- 0.27170212765957447
- 0.4325
- 0.4332446808510638
- 0.3519148936170213
- 0.3353191489361702
- 0.4634042553191489
- 0.4144148936170213
- 0.30627659574468086
- 0.476968085106383
- 0.47367021276595744
- 0.47829787234042553
- 0.46127659574468083
- 0.4870212765957447
- 0.41393617021276596
- 0.4718085106382979
- 0.4059042553191489
- 0.4103723404255319
- 0.48345744680851066
- 0.3879255319148936
- 0.43872340425531914
- 0.49111702127659573
- 0.48654255319148937
- 0.4975531914893617
- 0.4954787234042553
- 0.39813829787234045
- 0.5160106382978723
- 0.35904255319148937
- 0.5209574468085106
- 0.48675531914893616
- 0.5059574468085106
- 0.5062765957446809
- 0.39420212765957446
- 0.5349468085106382
- 0.5089893617021276
- 0.49898936170212765
- 0.33180851063829786
- 0.4117021276595745
- 0.5246276595744681
- 0.49925531914893617
- 0.5529787234042554
- 0.5364361702127659
- 0.46101063829787237
- 0.45861702127659576
- 0.3229787234042553
- 0.5003191489361702
- 0.4596276595744681
- 0.3675531914893617
- 0.44063829787234043
- 0.43579787234042555
- 0.5686170212765957
- 0.46680851063829787
- 0.5862765957446808
- 0.5103723404255319
- 0.44468085106382976
- 0.4977127659574468
- 0.4689893617021277
- 0.5068617021276596
- 0.4377659574468085
- 0.5713829787234043
- 0.5362765957446809
- 0.5793617021276596
- 0.6151063829787234
- 0.5770744680851064
- 0.35452127659574467
- 0.5861702127659575
- 0.5757446808510638
- 0.5162765957446809
- 0.5906914893617021
test_loss_list:
- 3.960852238337199
- 3.7740285873413084
- 3.795376656850179
- 3.758868627548218
- 3.394599402745565
- 3.4725432109832766
- 2.947493988672892
- 3.772264439264933
- 3.200736478169759
- 2.858605006535848
- 2.803435967763265
- 2.9814390818277996
- 2.6185139179229737
- 2.640505495071411
- 2.6390474891662596
- 2.5672224871317546
- 2.558319158554077
- 2.740271043777466
- 2.4732681210835774
- 2.3716597747802735
- 2.4702447128295897
- 3.8788235727945963
- 2.241087859471639
- 2.440617815653483
- 2.3062241649627686
- 2.17474266688029
- 2.304786074956258
- 2.5742505836486815
- 2.2282143147786457
- 2.1357978995641074
- 2.05501101175944
- 2.0532623545328774
- 2.617421522140503
- 1.9896302000681558
- 1.9575717719395955
- 2.2015019130706786
- 2.260371561050415
- 1.881620462735494
- 1.9983787282307943
- 2.4661676597595217
- 1.829277156194051
- 1.8753475093841552
- 1.9458277734120686
- 1.8655478032430013
- 1.8971641842524212
- 2.0788089736302693
- 2.089536422093709
- 2.157067495981852
- 2.062172843615214
- 1.9534703016281127
- 2.0900092347462973
- 1.8794795099894206
- 1.8232226451237996
- 1.743106271425883
- 1.8612975470225017
- 1.715075519879659
- 1.933648117383321
- 1.653873734474182
- 2.176687552134196
- 1.6060577233632405
- 1.76023277759552
- 1.7372850545247396
- 1.9584006452560425
- 2.086463726361593
- 1.5991535472869873
- 1.6371347602208455
- 1.9582487233479817
- 2.4859681193033856
- 1.8824323574701944
- 1.5318619298934937
- 1.6332940069834392
- 1.4713193527857462
- 1.5420156319936116
- 1.746305340131124
- 1.7532461484273274
- 2.7429922262827557
- 1.7639870564142863
- 1.8198656415939332
- 2.352822510401408
- 1.9115341742833456
- 1.8609003973007203
- 1.390203711191813
- 1.7572360150019328
- 1.3601138194402058
- 1.6340612983703613
- 1.9360264412562052
- 1.6058844757080077
- 1.7936615212758382
- 1.6303881518046062
- 1.9203242524464925
- 1.4090273173650105
- 1.8346795320510865
- 1.3427336422602336
- 1.3089728514353434
- 1.4240289465586344
- 2.510717264811198
- 1.3334126583735149
- 1.4409487549463909
- 1.6444229904810588
- 1.341262009938558
train_accuracy:
- 0.0
- 0.044
- 0.373
- 0.0
- 0.785
- 0.027
- 0.144
- 0.069
- 0.05
- 0.108
- 0.008
- 0.529
- 0.098
- 0.092
- 0.556
- 0.221
- 0.325
- 0.2
- 0.071
- 0.467
- 0.26
- 0.596
- 0.581
- 0.429
- 0.442
- 0.517
- 0.65
- 0.106
- 0.265
- 0.098
- 0.54
- 0.598
- 0.438
- 0.465
- 0.61
- 0.273
- 0.206
- 0.029
- 0.419
- 0.05
- 0.642
- 0.631
- 0.64
- 0.088
- 0.635
- 0.333
- 0.025
- 0.656
- 0.094
- 0.635
- 0.281
- 0.644
- 0.617
- 0.675
- 0.631
- 0.644
- 0.81
- 0.4
- 0.604
- 0.521
- 0.344
- 0.5
- 0.8
- 0.365
- 0.054
- 0.721
- 0.056
- 0.571
- 0.777
- 0.308
- 0.442
- 0.298
- 0.329
- 0.698
- 0.531
- 0.719
- 0.119
- 0.229
- 0.565
- 0.737
- 0.767
- 0.552
- 0.756
- 0.806
- 0.062
- 0.885
- 0.727
- 0.865
- 0.844
- 0.273
- 0.688
- 0.827
- 0.177
- 0.723
- 0.717
- 0.794
- 0.729
- 0.383
- 0.494
- 0.685
train_loss:
- 2.246
- 2.007
- 1.714
- 1.495
- 0.994
- 0.872
- 1.219
- 0.475
- 0.809
- 1.126
- 1.034
- 0.797
- 1.03
- 1.078
- 1.003
- 0.706
- 0.964
- 0.736
- 0.629
- 0.917
- 0.903
- 0.384
- 0.879
- 0.659
- 0.908
- 0.877
- 0.562
- 0.589
- 0.508
- 0.537
- 0.864
- 0.836
- 0.567
- 0.536
- 0.805
- 0.539
- 0.528
- 0.826
- 0.51
- 0.537
- 0.802
- 0.75
- 0.724
- 0.498
- 0.734
- 0.503
- 0.95
- 0.717
- 0.505
- 0.691
- 0.518
- 0.504
- 0.68
- 0.682
- 0.646
- 0.705
- 0.436
- 0.672
- 0.473
- 0.655
- 0.621
- 0.605
- 0.81
- 0.401
- 0.674
- 0.623
- 0.777
- 0.27
- 0.42
- 0.658
- 0.42
- 0.593
- 0.595
- 0.416
- 0.415
- 0.178
- 0.833
- 0.46
- 0.217
- 0.363
- 0.355
- 0.587
- 0.41
- 0.594
- 0.408
- 0.443
- 0.377
- 0.395
- 0.43
- 0.388
- 0.54
- 0.699
- 0.523
- 0.567
- 0.55
- 0.19
- 0.608
- 0.513
- 0.37
- 0.552
unequal: 0
verbose: 1
