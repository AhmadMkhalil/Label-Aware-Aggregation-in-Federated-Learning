avg_train_accuracy: 0.929
avg_train_loss: 0.004
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.033829787234042556
- 0.032606382978723404
- 0.13138297872340426
- 0.0848936170212766
- 0.1672872340425532
- 0.20824468085106382
- 0.18654255319148935
- 0.21686170212765957
- 0.1376063829787234
- 0.1751063829787234
- 0.21159574468085107
- 0.28122340425531916
- 0.16579787234042553
- 0.26904255319148934
- 0.26574468085106384
- 0.2577659574468085
- 0.17361702127659576
- 0.32904255319148934
- 0.21585106382978722
- 0.33601063829787237
- 0.400531914893617
- 0.2548404255319149
- 0.2561702127659575
- 0.2800531914893617
- 0.21095744680851064
- 0.2277127659574468
- 0.3049468085106383
- 0.2701595744680851
- 0.29127659574468084
- 0.4051595744680851
- 0.3927127659574468
- 0.2793617021276596
- 0.3021276595744681
- 0.28138297872340423
- 0.4498404255319149
- 0.3401063829787234
- 0.42792553191489363
- 0.3129787234042553
- 0.436436170212766
- 0.4832446808510638
- 0.3404255319148936
- 0.36446808510638296
- 0.35345744680851066
- 0.3253723404255319
- 0.47382978723404257
- 0.39611702127659576
- 0.3579787234042553
- 0.45728723404255317
- 0.425
- 0.37207446808510636
- 0.4625531914893617
- 0.4951063829787234
- 0.34574468085106386
- 0.3783510638297872
- 0.35122340425531917
- 0.4121808510638298
- 0.5002659574468085
- 0.3181914893617021
- 0.47829787234042553
- 0.4520212765957447
- 0.43170212765957444
- 0.5130851063829788
- 0.481968085106383
- 0.38372340425531914
- 0.43372340425531913
- 0.3901063829787234
- 0.5312234042553191
- 0.5157978723404255
- 0.512340425531915
- 0.38680851063829785
- 0.41122340425531917
- 0.5334042553191489
- 0.43867021276595747
- 0.5572872340425532
- 0.42531914893617023
- 0.4082978723404255
- 0.3670212765957447
- 0.5013297872340425
- 0.5188297872340426
- 0.49622340425531913
- 0.5148404255319149
- 0.4656914893617021
- 0.36803191489361703
- 0.4346808510638298
- 0.5190957446808511
- 0.5140957446808511
- 0.3173936170212766
- 0.3293617021276596
- 0.520904255319149
- 0.4001063829787234
- 0.5557446808510639
- 0.5481914893617021
- 0.5389893617021276
- 0.5442553191489362
- 0.5735106382978723
- 0.5721808510638298
- 0.5404787234042553
- 0.4493617021276596
- 0.32835106382978724
- 0.4416489361702128
test_loss_list:
- 3.914995463689168
- 4.2492305946350095
- 3.5846843179066976
- 4.084784116744995
- 3.3847103532155356
- 3.3287892627716062
- 3.369079341888428
- 3.008596331278483
- 3.619466937383016
- 3.477815090815226
- 3.0721978410085042
- 2.698745969136556
- 3.2692635536193846
- 2.721264664332072
- 2.736228354771932
- 2.8446308390299477
- 4.522288379669189
- 2.5642779032389322
- 2.972952381769816
- 2.478712507883708
- 2.668000297546387
- 2.882664670944214
- 2.7233103116353354
- 2.6135216903686525
- 3.4418283812204997
- 3.620584980646769
- 2.4893040307362875
- 2.5922660064697265
- 2.5545482444763183
- 2.1050594488779706
- 2.1536114740371706
- 2.729742555618286
- 2.488933204015096
- 2.797657149632772
- 2.0101505517959595
- 2.322339890797933
- 2.5088561248779295
- 2.6704052289326987
- 2.026013247172038
- 1.880459769566854
- 2.44270738919576
- 2.2615967178344727
- 2.3443055470784504
- 2.477135950724284
- 1.9143149773279826
- 2.208884121576945
- 2.1981782786051434
- 1.8925459480285645
- 2.0797484572728475
- 2.242178761164347
- 1.7635030953089397
- 1.7362952136993408
- 2.2806314754486086
- 2.1072841358184813
- 2.3747460905710858
- 1.9744599215189615
- 1.6212497313817342
- 3.0372403462727866
- 1.9590216859181722
- 1.846317121187846
- 1.9830375385284424
- 1.6897108459472656
- 2.0427821350097655
- 2.2209901014963784
- 1.913212587038676
- 2.062957773208618
- 1.5956880680720011
- 1.6218930864334107
- 1.632772510846456
- 2.0985512288411456
- 2.034821397463481
- 1.5779372517267862
- 1.8979236014684042
- 1.5151979907353719
- 2.001472120285034
- 2.024268846511841
- 2.2409693241119384
- 1.661565620104472
- 1.5658571179707845
- 1.6479016494750978
- 1.562471391359965
- 1.804564650853475
- 2.722095905939738
- 1.9516933711369833
- 1.6690215539932252
- 1.7253867435455321
- 3.1248206424713136
- 3.1751600710550942
- 1.7609941705067953
- 2.055313730239868
- 1.4642569716771443
- 1.5006777318318685
- 1.5472559674580892
- 1.4867735242843627
- 1.3748938194910685
- 1.4344231589635212
- 1.5613434839248657
- 1.8503435929616292
- 3.1878117434183757
- 1.8259742466608684
train_accuracy:
- 0.779
- 0.002
- 0.179
- 0.0
- 0.231
- 0.031
- 0.106
- 0.265
- 0.098
- 0.06
- 0.5
- 0.3
- 0.288
- 0.067
- 0.65
- 0.698
- 0.473
- 0.333
- 0.083
- 0.473
- 0.654
- 0.621
- 0.169
- 0.062
- 0.765
- 0.704
- 0.135
- 0.681
- 0.596
- 0.692
- 0.456
- 0.465
- 0.723
- 0.658
- 0.273
- 0.208
- 0.702
- 0.527
- 0.352
- 0.588
- 0.842
- 0.806
- 0.275
- 0.763
- 0.527
- 0.579
- 0.835
- 0.61
- 0.492
- 0.446
- 0.598
- 0.569
- 0.25
- 0.467
- 0.227
- 0.763
- 0.585
- 0.898
- 0.769
- 0.394
- 0.702
- 0.5
- 0.763
- 0.881
- 0.375
- 0.646
- 0.623
- 0.562
- 0.606
- 0.292
- 0.404
- 0.642
- 0.833
- 0.631
- 0.771
- 0.65
- 0.721
- 0.729
- 0.606
- 0.567
- 0.596
- 0.696
- 0.381
- 0.315
- 0.756
- 0.775
- 0.787
- 0.669
- 0.644
- 0.144
- 0.638
- 0.621
- 0.904
- 0.631
- 0.662
- 0.846
- 0.833
- 0.327
- 0.621
- 0.929
train_loss:
- 2.214
- 1.404
- 2.261
- 1.071
- 1.387
- 1.317
- 1.211
- 1.23
- 0.796
- 0.726
- 0.721
- 1.084
- 0.686
- 0.753
- 0.699
- 0.67
- 0.348
- 0.997
- 0.625
- 0.912
- 1.167
- 0.63
- 0.64
- 0.602
- 0.35
- 0.301
- 0.609
- 0.588
- 0.545
- 0.821
- 0.795
- 0.554
- 0.552
- 0.516
- 0.788
- 0.538
- 1.002
- 0.552
- 0.754
- 0.748
- 0.512
- 0.493
- 0.519
- 0.493
- 0.732
- 0.483
- 0.502
- 0.702
- 0.674
- 0.475
- 0.682
- 0.691
- 0.455
- 0.446
- 0.456
- 0.472
- 0.645
- 0.262
- 0.919
- 0.469
- 0.428
- 0.622
- 0.83
- 0.419
- 0.428
- 0.431
- 0.614
- 0.622
- 0.604
- 0.421
- 0.409
- 0.586
- 0.419
- 0.623
- 0.4
- 0.404
- 0.403
- 0.575
- 0.567
- 0.546
- 0.577
- 0.403
- 0.235
- 0.391
- 0.566
- 0.555
- 0.218
- 0.198
- 0.795
- 0.4
- 0.574
- 0.536
- 0.396
- 0.553
- 0.557
- 0.542
- 0.527
- 0.382
- 0.188
- 0.383
unequal: 0
verbose: 1
