avg_train_accuracy: 0.844
avg_train_loss: 0.011
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.059308510638297875
- 0.051382978723404256
- 0.06430851063829787
- 0.10579787234042554
- 0.18063829787234043
- 0.28308510638297874
- 0.3946808510638298
- 0.4445212765957447
- 0.4921276595744681
- 0.5123936170212766
- 0.5415425531914894
- 0.5642553191489361
- 0.5795212765957447
- 0.5860106382978724
- 0.5947340425531915
- 0.6073936170212766
- 0.6180851063829788
- 0.624468085106383
- 0.6319148936170212
- 0.6447340425531914
- 0.6443085106382979
- 0.6507446808510639
- 0.06319148936170213
- 0.6475531914893617
- 0.6581382978723405
- 0.6596808510638298
- 0.6643085106382979
- 0.6695212765957447
- 0.6779255319148936
- 0.6781914893617021
- 0.6785106382978724
- 0.6882978723404255
- 0.6892021276595744
- 0.6926595744680851
- 0.6950531914893617
- 0.7038829787234042
- 0.7003723404255319
- 0.7031382978723404
- 0.7043085106382979
- 0.7081382978723404
- 0.7120212765957447
- 0.710531914893617
- 0.7144148936170213
- 0.7163829787234043
- 0.7163297872340425
- 0.7154255319148937
- 0.7184574468085106
- 0.7216489361702128
- 0.7205851063829787
- 0.7218617021276595
- 0.7235106382978723
- 0.7270744680851063
- 0.7285106382978723
- 0.7317553191489362
- 0.7298936170212766
- 0.7296276595744681
- 0.7312234042553192
- 0.7346808510638297
- 0.734095744680851
- 0.737659574468085
- 0.7359574468085106
- 0.7353191489361702
- 0.7362765957446809
- 0.7393617021276596
- 0.7388829787234042
- 0.743031914893617
- 0.10595744680851064
- 0.7346808510638297
- 0.7413829787234043
- 0.23680851063829786
- 0.7451595744680851
- 0.7424468085106383
- 0.7450531914893617
- 0.7426595744680851
- 0.7429787234042553
- 0.744095744680851
- 0.7450531914893617
- 0.7471276595744681
- 0.7468085106382979
- 0.7473936170212766
- 0.25643617021276593
- 0.7470744680851064
- 0.7514893617021277
- 0.7492553191489362
- 0.7501595744680851
- 0.7489361702127659
- 0.754468085106383
- 0.7506914893617022
- 0.7510106382978723
- 0.7512234042553192
- 0.7561702127659574
- 0.7531382978723404
- 0.7540425531914894
- 0.7560106382978723
- 0.7552127659574468
- 0.3021276595744681
- 0.7599468085106383
- 0.7532978723404256
- 0.7561170212765957
- 0.7565957446808511
test_loss_list:
- 21.853937530517577
- 3.769122101465861
- 3.7024717330932617
- 3.578080094655355
- 3.375138292312622
- 3.05758194287618
- 2.6907095940907797
- 2.4366785303751626
- 2.264254229863485
- 2.150755515098572
- 2.0464625215530394
- 1.9848448340098064
- 1.922347076733907
- 1.859277645746867
- 1.819076402982076
- 1.785760760307312
- 1.7706649319330852
- 1.7408548641204833
- 1.722766588528951
- 1.68927982489268
- 1.6946054013570149
- 1.6687657419840496
- 11.731991488138835
- 1.318566222190857
- 1.349736696879069
- 1.3742061837514241
- 1.3935583432515461
- 1.383516723314921
- 1.3997711547215779
- 1.3865617005030315
- 1.3993657159805297
- 1.385796399116516
- 1.3994947067896526
- 1.3975179560979207
- 1.3766173315048218
- 1.3919285615285237
- 1.3683649396896362
- 1.3716855796178182
- 1.383230053583781
- 1.380673893292745
- 1.3966151523590087
- 1.3946828778584799
- 1.3660479974746704
- 1.3711720609664917
- 1.388239819208781
- 1.376426075299581
- 1.3520595916112264
- 1.3560596195856731
- 1.36418838818868
- 1.3552206309636434
- 1.3589873298009236
- 1.3371456289291381
- 1.3489841365814208
- 1.3479922691980997
- 1.3485063616434734
- 1.3635356171925863
- 1.3580423307418823
- 1.3716333611806233
- 1.3508765776952107
- 1.3810810708999635
- 1.3759707164764405
- 1.3543117332458496
- 1.3554555225372313
- 1.3603473313649495
- 1.3285973421732584
- 1.3579710547129313
- 7.855042279561361
- 0.9360368061065674
- 1.0055284174283345
- 5.311844774881998
- 0.8684999529520671
- 0.9326985351244609
- 0.9548515359560649
- 0.9769593787193298
- 1.0075562771161397
- 1.0144765639305116
- 1.0343254566192628
- 1.0441415818532307
- 1.0396016867955526
- 1.0610808769861857
- 5.074211133321127
- 0.8441953873634338
- 0.8918957273165385
- 0.9239423576990763
- 0.9386613861719767
- 0.9600276764233907
- 0.9713631757100423
- 0.9826962931950887
- 1.0057080260912576
- 1.0173730365435283
- 1.0031253600120544
- 1.0338389587402343
- 1.0314880712827046
- 1.0481128366788228
- 1.0369411786397298
- 4.541417671839397
- 0.7971207722028096
- 0.8560671949386597
- 0.885495035648346
- 0.9136211641629537
train_accuracy:
- 0.752
- 0.048
- 0.071
- 0.079
- 0.16
- 0.312
- 0.412
- 0.471
- 0.521
- 0.552
- 0.585
- 0.604
- 0.623
- 0.608
- 0.65
- 0.656
- 0.669
- 0.656
- 0.65
- 0.702
- 0.702
- 0.7
- 0.971
- 0.692
- 0.744
- 0.708
- 0.731
- 0.733
- 0.729
- 0.763
- 0.775
- 0.719
- 0.723
- 0.758
- 0.742
- 0.763
- 0.76
- 0.748
- 0.737
- 0.773
- 0.769
- 0.756
- 0.779
- 0.742
- 0.79
- 0.771
- 0.779
- 0.827
- 0.812
- 0.781
- 0.769
- 0.785
- 0.771
- 0.783
- 0.796
- 0.767
- 0.821
- 0.787
- 0.79
- 0.775
- 0.773
- 0.787
- 0.787
- 0.79
- 0.802
- 0.775
- 0.973
- 0.794
- 0.785
- 0.99
- 0.773
- 0.79
- 0.804
- 0.84
- 0.798
- 0.785
- 0.785
- 0.785
- 0.815
- 0.796
- 0.996
- 0.792
- 0.804
- 0.794
- 0.777
- 0.815
- 0.798
- 0.787
- 0.794
- 0.798
- 0.823
- 0.808
- 0.804
- 0.79
- 0.8
- 0.994
- 0.804
- 0.819
- 0.798
- 0.844
train_loss:
- 0.94
- 4.114
- 3.808
- 3.734
- 3.599
- 3.355
- 3.06
- 2.78
- 2.628
- 2.473
- 2.338
- 2.312
- 2.235
- 2.082
- 2.041
- 2.055
- 1.993
- 1.949
- 1.862
- 1.887
- 1.839
- 1.739
- 0.634
- 2.197
- 1.798
- 1.747
- 1.672
- 1.672
- 1.709
- 1.638
- 1.576
- 1.648
- 1.568
- 1.557
- 1.554
- 1.479
- 1.509
- 1.456
- 1.506
- 1.492
- 1.397
- 1.417
- 1.423
- 1.445
- 1.43
- 1.376
- 1.412
- 1.386
- 1.329
- 1.334
- 1.35
- 1.332
- 1.35
- 1.358
- 1.27
- 1.357
- 1.291
- 1.257
- 1.313
- 1.302
- 1.256
- 1.288
- 1.247
- 1.23
- 1.218
- 1.277
- 0.67
- 1.625
- 1.217
- 0.332
- 1.461
- 1.215
- 1.18
- 1.24
- 1.171
- 1.23
- 1.249
- 1.192
- 1.144
- 1.126
- 0.38
- 1.443
- 1.227
- 1.206
- 1.226
- 1.218
- 1.194
- 1.187
- 1.129
- 1.183
- 1.174
- 1.159
- 1.102
- 1.163
- 1.206
- 0.402
- 1.351
- 1.202
- 1.166
- 1.132
unequal: 0
verbose: 1
