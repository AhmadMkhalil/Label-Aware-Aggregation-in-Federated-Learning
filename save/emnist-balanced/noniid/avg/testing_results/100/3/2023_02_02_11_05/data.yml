avg_train_accuracy: 0.923
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04797872340425532
- 0.05611702127659574
- 0.13792553191489362
- 0.16148936170212766
- 0.16148936170212766
- 0.16148936170212766
- 0.16148936170212766
- 0.16148936170212766
- 0.1822872340425532
- 0.18606382978723404
- 0.1876595744680851
- 0.1876595744680851
- 0.1876595744680851
- 0.1876595744680851
- 0.1876595744680851
- 0.1926595744680851
- 0.19643617021276596
- 0.20122340425531915
- 0.20122340425531915
- 0.20122340425531915
- 0.20122340425531915
- 0.20122340425531915
- 0.20930851063829786
- 0.20930851063829786
- 0.2195212765957447
- 0.2245744680851064
- 0.2245744680851064
- 0.2245744680851064
- 0.23090425531914893
- 0.23090425531914893
- 0.23090425531914893
- 0.23090425531914893
- 0.23090425531914893
- 0.23090425531914893
- 0.23090425531914893
- 0.23404255319148937
- 0.23404255319148937
- 0.23404255319148937
- 0.23404255319148937
- 0.23404255319148937
- 0.23404255319148937
- 0.23574468085106384
- 0.23574468085106384
- 0.23574468085106384
- 0.23574468085106384
- 0.23574468085106384
- 0.23574468085106384
- 0.23691489361702128
- 0.23691489361702128
- 0.24723404255319148
- 0.24723404255319148
- 0.24723404255319148
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.25377659574468087
- 0.2713829787234043
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.29808510638297875
- 0.3021276595744681
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
- 0.30909574468085105
test_loss_list:
- 709.2947697639465
- 836.6293296813965
- 933.1080117225647
- 1415.3070306777954
- 1415.3070306777954
- 1415.3070306777954
- 1415.3070306777954
- 1415.3070306777954
- 1468.6675329208374
- 827.4284868240356
- 1468.3142786026
- 1468.3142786026
- 1468.3142786026
- 1468.3142786026
- 1468.3142786026
- 1403.4534645080566
- 832.8489747047424
- 688.8188586235046
- 688.8188586235046
- 688.8188586235046
- 688.8188586235046
- 688.8188586235046
- 586.9496757984161
- 586.9496757984161
- 662.0058310031891
- 670.8373265266418
- 670.8373265266418
- 670.8373265266418
- 604.5693697929382
- 604.5693697929382
- 604.5693697929382
- 604.5693697929382
- 604.5693697929382
- 604.5693697929382
- 604.5693697929382
- 625.0410988330841
- 625.0410988330841
- 625.0410988330841
- 625.0410988330841
- 625.0410988330841
- 625.0410988330841
- 654.2958199977875
- 654.2958199977875
- 654.2958199977875
- 654.2958199977875
- 654.2958199977875
- 654.2958199977875
- 633.9005825519562
- 633.9005825519562
- 613.4018862247467
- 613.4018862247467
- 613.4018862247467
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 613.5854470729828
- 625.5922095775604
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 462.88687896728516
- 466.24696826934814
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
- 438.76865100860596
train_accuracy:
- 0.16
- 0.0
- 0.615
- 0.694
- 0.615
- 0.696
- 0.004
- 0.0
- 0.802
- 0.033
- 0.81
- 0.567
- 0.0
- 0.002
- 0.796
- 0.867
- 0.792
- 0.073
- 0.806
- 0.831
- 0.81
- 0.852
- 0.006
- 0.837
- 0.423
- 0.771
- 0.84
- 0.873
- 0.723
- 0.844
- 0.858
- 0.85
- 0.879
- 0.9
- 0.0
- 0.777
- 0.885
- 0.04
- 0.908
- 0.148
- 0.871
- 0.865
- 0.896
- 0.896
- 0.89
- 0.919
- 0.877
- 0.842
- 0.898
- 0.856
- 0.896
- 0.0
- 0.008
- 0.158
- 0.898
- 0.869
- 0.906
- 0.89
- 0.854
- 0.902
- 0.294
- 0.892
- 0.01
- 0.852
- 0.817
- 0.89
- 0.875
- 0.894
- 0.335
- 0.908
- 0.908
- 0.831
- 0.906
- 0.848
- 0.89
- 0.925
- 0.898
- 0.869
- 0.19
- 0.906
- 0.017
- 0.917
- 0.825
- 0.002
- 0.906
- 0.925
- 0.267
- 0.898
- 0.49
- 0.444
- 0.079
- 0.923
- 0.9
- 0.904
- 0.902
- 0.91
- 0.875
- 0.0
- 0.913
- 0.923
train_loss:
- 2.198
- 1.483
- 1.579
- 1.447
- 1.13
- 1.108
- 1.055
- 1.002
- 1.05
- 0.86
- 0.971
- 0.912
- 0.907
- 0.834
- 0.901
- 0.875
- 0.83
- 0.692
- 0.817
- 0.785
- 0.738
- 0.774
- 0.786
- 0.709
- 0.649
- 0.635
- 0.697
- 0.695
- 0.646
- 0.707
- 0.624
- 0.633
- 0.68
- 0.632
- 0.785
- 0.615
- 0.651
- 0.599
- 0.62
- 0.565
- 0.623
- 0.557
- 0.604
- 0.627
- 0.558
- 0.567
- 0.565
- 0.586
- 0.571
- 0.556
- 0.573
- 0.568
- 0.53
- 0.583
- 0.527
- 0.51
- 0.519
- 0.555
- 0.638
- 0.485
- 0.552
- 0.466
- 0.493
- 0.432
- 0.508
- 0.549
- 0.538
- 0.479
- 0.468
- 0.533
- 0.451
- 0.44
- 0.514
- 0.446
- 0.535
- 0.476
- 0.447
- 0.535
- 0.432
- 0.476
- 0.47
- 0.497
- 0.488
- 0.407
- 0.477
- 0.476
- 0.489
- 0.467
- 0.432
- 0.467
- 0.422
- 0.501
- 0.474
- 0.498
- 0.469
- 0.466
- 0.483
- 0.491
- 0.465
- 0.472
unequal: 0
verbose: 1
