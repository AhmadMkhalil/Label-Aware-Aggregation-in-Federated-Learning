avg_train_accuracy: 0.806
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021329787234042552
- 0.021329787234042552
- 0.02154255319148936
- 0.1554787234042553
- 0.1554787234042553
- 0.1554787234042553
- 0.1554787234042553
- 0.4206382978723404
- 0.4206382978723404
- 0.4206382978723404
- 0.4206382978723404
- 0.4785106382978723
- 0.4785106382978723
- 0.4971808510638298
- 0.5034574468085107
- 0.5145744680851064
- 0.5145744680851064
- 0.520904255319149
- 0.520904255319149
- 0.520904255319149
- 0.520904255319149
- 0.5370744680851064
- 0.5392021276595744
- 0.5392021276595744
- 0.5481382978723405
- 0.5481382978723405
- 0.5481382978723405
- 0.5481382978723405
- 0.5481382978723405
- 0.5596276595744681
- 0.563404255319149
- 0.5654787234042553
- 0.5654787234042553
- 0.5694148936170212
- 0.5694148936170212
- 0.5743617021276596
- 0.5743617021276596
- 0.5777659574468085
- 0.5777659574468085
- 0.5793085106382979
- 0.5793085106382979
- 0.5842021276595745
- 0.5842021276595745
- 0.5842021276595745
- 0.5842021276595745
- 0.5882978723404255
- 0.5882978723404255
- 0.5887234042553191
- 0.5887234042553191
- 0.5887234042553191
- 0.5887234042553191
- 0.5887234042553191
- 0.5887234042553191
- 0.5997872340425532
- 0.5997872340425532
- 0.5997872340425532
- 0.5997872340425532
- 0.5997872340425532
- 0.5997872340425532
- 0.5997872340425532
- 0.601063829787234
- 0.601063829787234
- 0.601063829787234
- 0.601063829787234
- 0.6031382978723404
- 0.6031382978723404
- 0.6031382978723404
- 0.6078191489361702
- 0.6078191489361702
- 0.6078191489361702
- 0.6078191489361702
- 0.6078191489361702
- 0.6097340425531915
- 0.6138297872340426
- 0.6138297872340426
- 0.6138297872340426
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6148404255319149
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
- 0.6168085106382979
test_loss_list:
- 630.48952293396
- 630.48952293396
- 641.8351955413818
- 518.9500987529755
- 518.9500987529755
- 518.9500987529755
- 518.9500987529755
- 464.9424216747284
- 464.9424216747284
- 464.9424216747284
- 464.9424216747284
- 463.05964851379395
- 463.05964851379395
- 483.02620220184326
- 482.42742228507996
- 496.7841954231262
- 496.7841954231262
- 499.000216960907
- 499.000216960907
- 499.000216960907
- 499.000216960907
- 485.34204292297363
- 503.9282257556915
- 503.9282257556915
- 498.09526443481445
- 498.09526443481445
- 498.09526443481445
- 498.09526443481445
- 498.09526443481445
- 488.6526892185211
- 495.7536873817444
- 498.19075322151184
- 498.19075322151184
- 486.5809862613678
- 486.5809862613678
- 484.4603352546692
- 484.4603352546692
- 481.7837312221527
- 481.7837312221527
- 498.2278423309326
- 498.2278423309326
- 504.8825421333313
- 504.8825421333313
- 504.8825421333313
- 504.8825421333313
- 467.0122985839844
- 467.0122985839844
- 459.2772738933563
- 459.2772738933563
- 459.2772738933563
- 459.2772738933563
- 459.2772738933563
- 459.2772738933563
- 372.7960021495819
- 372.7960021495819
- 372.7960021495819
- 372.7960021495819
- 372.7960021495819
- 372.7960021495819
- 372.7960021495819
- 435.5441265106201
- 435.5441265106201
- 435.5441265106201
- 435.5441265106201
- 417.64855575561523
- 417.64855575561523
- 417.64855575561523
- 423.0067367553711
- 423.0067367553711
- 423.0067367553711
- 423.0067367553711
- 423.0067367553711
- 353.3481719493866
- 337.260170340538
- 337.260170340538
- 337.260170340538
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 341.6557848453522
- 374.605606675148
- 374.605606675148
- 374.605606675148
- 374.605606675148
- 374.605606675148
- 374.605606675148
- 374.605606675148
- 374.605606675148
- 374.605606675148
train_accuracy:
- 0.0
- 1.0
- 0.998
- 0.208
- 0.123
- 0.112
- 0.008
- 0.585
- 0.454
- 0.696
- 0.506
- 0.629
- 0.506
- 0.675
- 0.704
- 0.685
- 0.59
- 0.71
- 0.758
- 0.683
- 0.45
- 0.731
- 0.748
- 0.744
- 0.748
- 0.654
- 0.637
- 0.681
- 0.694
- 0.794
- 0.754
- 0.75
- 0.69
- 0.756
- 0.571
- 0.769
- 0.681
- 0.754
- 0.796
- 0.771
- 0.752
- 0.794
- 0.725
- 0.773
- 0.654
- 0.773
- 0.958
- 0.819
- 0.302
- 0.727
- 0.221
- 0.571
- 0.792
- 0.81
- 0.81
- 0.685
- 0.744
- 0.781
- 0.783
- 0.748
- 0.806
- 0.788
- 0.694
- 0.658
- 0.819
- 0.796
- 0.86
- 0.806
- 0.717
- 0.835
- 0.802
- 0.744
- 0.794
- 0.798
- 0.794
- 0.575
- 0.81
- 0.81
- 0.804
- 0.731
- 0.731
- 0.748
- 0.975
- 0.917
- 0.348
- 0.827
- 0.812
- 0.669
- 0.894
- 0.729
- 0.792
- 0.84
- 0.735
- 0.806
- 0.683
- 0.979
- 0.779
- 0.725
- 0.802
- 0.806
train_loss:
- 2.037
- 1.01
- 1.845
- 2.518
- 1.532
- 1.44
- 0.74
- 2.6
- 1.803
- 1.244
- 1.658
- 2.054
- 1.525
- 1.934
- 1.852
- 1.788
- 1.374
- 1.713
- 1.325
- 1.294
- 0.896
- 1.657
- 1.573
- 1.224
- 1.555
- 1.206
- 1.191
- 1.17
- 1.161
- 1.473
- 1.461
- 1.456
- 1.135
- 1.42
- 0.823
- 1.404
- 1.094
- 1.402
- 1.34
- 1.346
- 1.065
- 1.326
- 1.028
- 0.992
- 0.764
- 1.323
- 0.717
- 1.297
- 0.778
- 0.728
- 1.021
- 0.786
- 0.986
- 0.952
- 1.249
- 0.734
- 0.981
- 0.971
- 1.211
- 1.011
- 1.217
- 0.938
- 0.71
- 0.967
- 1.185
- 0.934
- 0.922
- 1.201
- 0.679
- 1.205
- 0.901
- 0.921
- 0.904
- 0.912
- 1.132
- 0.923
- 0.884
- 0.905
- 1.138
- 0.664
- 0.641
- 0.877
- 0.638
- 0.622
- 0.912
- 1.143
- 0.896
- 0.888
- 0.861
- 0.649
- 1.116
- 1.093
- 0.855
- 0.85
- 0.655
- 0.582
- 0.606
- 0.847
- 0.886
- 0.834
unequal: 0
verbose: 1
