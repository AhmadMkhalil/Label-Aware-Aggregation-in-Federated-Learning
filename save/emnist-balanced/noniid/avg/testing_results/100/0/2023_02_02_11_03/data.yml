avg_train_accuracy: 0.84
avg_train_loss: 0.001
avg_type: avg
dataset: emnist-balanced
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 0
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.02127659574468085
- 0.023085106382978723
- 0.023085106382978723
- 0.023510638297872342
- 0.023510638297872342
- 0.023510638297872342
- 0.029946808510638297
- 0.029946808510638297
- 0.029946808510638297
- 0.029946808510638297
- 0.029946808510638297
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.0400531914893617
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05037234042553192
- 0.05303191489361702
- 0.05303191489361702
- 0.05303191489361702
- 0.05303191489361702
- 0.05303191489361702
- 0.05303191489361702
- 0.05303191489361702
- 0.05303191489361702
- 0.05638297872340425
- 0.05638297872340425
- 0.05638297872340425
- 0.05638297872340425
- 0.05638297872340425
- 0.05638297872340425
- 0.05638297872340425
- 0.05638297872340425
- 0.060851063829787236
- 0.060851063829787236
- 0.060851063829787236
- 0.060851063829787236
- 0.060851063829787236
- 0.060851063829787236
- 0.060851063829787236
- 0.060851063829787236
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.06622340425531915
- 0.07952127659574468
test_loss_list:
- 1222.3690462112427
- 1222.3690462112427
- 1222.3690462112427
- 1222.3690462112427
- 1037.5233941078186
- 1037.5233941078186
- 1281.7556467056274
- 1281.7556467056274
- 1281.7556467056274
- 760.5991249084473
- 760.5991249084473
- 760.5991249084473
- 760.5991249084473
- 760.5991249084473
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1014.5097241401672
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 1099.518015384674
- 782.6392574310303
- 782.6392574310303
- 782.6392574310303
- 782.6392574310303
- 782.6392574310303
- 782.6392574310303
- 782.6392574310303
- 782.6392574310303
- 838.0692958831787
- 838.0692958831787
- 838.0692958831787
- 838.0692958831787
- 838.0692958831787
- 838.0692958831787
- 838.0692958831787
- 838.0692958831787
- 817.3364663124084
- 817.3364663124084
- 817.3364663124084
- 817.3364663124084
- 817.3364663124084
- 817.3364663124084
- 817.3364663124084
- 817.3364663124084
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 843.9891705513
- 712.4059600830078
train_accuracy:
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 0.115
- 0.0
- 0.0
- 0.0
- 0.062
- 1.0
- 0.0
- 0.01
- 0.0
- 0.0
- 0.815
- 0.998
- 0.0
- 0.0
- 0.983
- 1.0
- 0.0
- 0.119
- 0.744
- 0.808
- 0.408
- 0.015
- 0.042
- 0.808
- 0.769
- 0.0
- 0.525
- 0.015
- 0.0
- 0.0
- 0.583
- 0.958
- 0.996
- 1.0
- 0.0
- 0.898
- 0.331
- 0.0
- 0.825
- 0.985
- 1.0
- 0.315
- 0.0
- 0.14
- 0.992
- 0.144
- 1.0
- 0.031
- 0.425
- 0.0
- 0.002
- 0.0
- 0.0
- 0.085
- 0.002
- 0.746
- 0.987
- 0.029
- 0.331
- 0.0
- 0.029
- 0.994
- 0.902
- 0.658
- 0.458
- 0.029
- 0.679
- 0.06
- 0.0
- 0.985
- 0.283
- 0.858
- 0.0
- 0.002
- 0.717
- 0.954
- 0.04
- 0.983
- 0.996
- 0.298
- 0.002
- 0.879
- 0.906
- 0.994
- 0.631
- 0.842
- 0.629
- 0.002
- 0.948
- 0.669
- 0.087
- 0.04
- 0.975
- 0.84
train_loss:
- 0.298
- 0.171
- 0.101
- 0.127
- 0.15
- 0.169
- 0.098
- 0.15
- 0.121
- 0.178
- 0.078
- 0.125
- 0.132
- 0.134
- 0.13
- 0.142
- 0.145
- 0.121
- 0.162
- 0.127
- 0.116
- 0.137
- 0.124
- 0.106
- 0.119
- 0.131
- 0.13
- 0.085
- 0.134
- 0.125
- 0.163
- 0.117
- 0.096
- 0.149
- 0.133
- 0.14
- 0.135
- 0.089
- 0.148
- 0.138
- 0.139
- 0.12
- 0.098
- 0.151
- 0.104
- 0.107
- 0.083
- 0.084
- 0.151
- 0.12
- 0.087
- 0.1
- 0.119
- 0.116
- 0.111
- 0.106
- 0.101
- 0.124
- 0.136
- 0.102
- 0.133
- 0.102
- 0.09
- 0.121
- 0.104
- 0.12
- 0.124
- 0.118
- 0.107
- 0.101
- 0.091
- 0.113
- 0.106
- 0.094
- 0.109
- 0.121
- 0.086
- 0.094
- 0.095
- 0.086
- 0.086
- 0.122
- 0.102
- 0.104
- 0.101
- 0.106
- 0.076
- 0.134
- 0.101
- 0.1
- 0.121
- 0.079
- 0.116
- 0.099
- 0.081
- 0.091
- 0.09
- 0.109
- 0.075
- 0.1
unequal: 0
verbose: 1
