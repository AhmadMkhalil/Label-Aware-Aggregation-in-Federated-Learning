avg_train_accuracy: 0.129
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.2
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.049414893617021276
- 0.07287234042553191
- 0.10537234042553191
- 0.10537234042553191
- 0.135
- 0.149468085106383
- 0.21462765957446808
- 0.21462765957446808
- 0.21462765957446808
- 0.21563829787234043
- 0.21563829787234043
- 0.21563829787234043
- 0.26835106382978724
- 0.27627659574468083
- 0.27627659574468083
- 0.27627659574468083
- 0.27627659574468083
- 0.27627659574468083
- 0.2804255319148936
- 0.2804255319148936
- 0.2804255319148936
- 0.2804255319148936
- 0.2804255319148936
- 0.28808510638297874
- 0.28808510638297874
- 0.28808510638297874
- 0.28808510638297874
- 0.29106382978723405
- 0.29154255319148936
- 0.2928723404255319
- 0.2928723404255319
- 0.301436170212766
- 0.321063829787234
- 0.321063829787234
- 0.321063829787234
- 0.321063829787234
- 0.3379255319148936
- 0.3379255319148936
- 0.3379255319148936
- 0.3421808510638298
- 0.3421808510638298
- 0.344468085106383
- 0.3448936170212766
- 0.3448936170212766
- 0.3448936170212766
- 0.3675531914893617
- 0.3675531914893617
- 0.3675531914893617
- 0.3675531914893617
- 0.3675531914893617
test_loss_list:
- 969.5445475578308
- 659.8595123291016
- 724.9557752609253
- 724.9557752609253
- 585.8221204280853
- 685.1219339370728
- 693.820207118988
- 693.820207118988
- 693.820207118988
- 552.3016066551208
- 552.3016066551208
- 552.3016066551208
- 1004.8755326271057
- 1034.2778735160828
- 1034.2778735160828
- 1034.2778735160828
- 1034.2778735160828
- 1034.2778735160828
- 927.8621120452881
- 927.8621120452881
- 927.8621120452881
- 927.8621120452881
- 927.8621120452881
- 773.5751781463623
- 773.5751781463623
- 773.5751781463623
- 773.5751781463623
- 774.5985441207886
- 865.1051797866821
- 940.8375306129456
- 940.8375306129456
- 482.7678933143616
- 468.24364852905273
- 468.24364852905273
- 468.24364852905273
- 468.24364852905273
- 545.5679531097412
- 545.5679531097412
- 545.5679531097412
- 581.2396392822266
- 581.2396392822266
- 626.4010465145111
- 527.8847379684448
- 527.8847379684448
- 527.8847379684448
- 434.66932463645935
- 434.66932463645935
- 434.66932463645935
- 434.66932463645935
- 434.66932463645935
train_accuracy:
- 0.085
- 0.002
- 0.106
- 0.131
- 0.096
- 0.148
- 0.127
- 0.125
- 0.004
- 0.325
- 0.152
- 0.275
- 0.746
- 0.76
- 0.146
- 0.317
- 0.106
- 0.131
- 0.804
- 0.044
- 0.485
- 0.431
- 0.046
- 0.821
- 0.15
- 0.11
- 0.108
- 0.808
- 0.833
- 0.8
- 0.09
- 0.127
- 0.133
- 0.821
- 0.6
- 0.844
- 0.156
- 0.631
- 0.815
- 0.658
- 0.838
- 0.669
- 0.129
- 0.15
- 0.127
- 0.123
- 0.846
- 0.846
- 0.669
- 0.129
train_loss:
- 2.01
- 2.396
- 1.698
- 1.684
- 1.733
- 1.454
- 1.233
- 0.749
- 1.238
- 1.529
- 1.236
- 1.318
- 1.626
- 1.462
- 1.079
- 1.193
- 0.881
- 0.647
- 1.612
- 0.918
- 1.052
- 1.095
- 1.159
- 1.478
- 0.706
- 0.936
- 0.686
- 1.463
- 1.181
- 1.136
- 0.835
- 1.096
- 0.961
- 1.136
- 0.883
- 1.072
- 0.888
- 0.946
- 1.04
- 0.808
- 1.022
- 0.755
- 0.837
- 0.539
- 0.647
- 0.933
- 1.02
- 0.915
- 0.751
- 0.751
unequal: 0
verbose: 1
