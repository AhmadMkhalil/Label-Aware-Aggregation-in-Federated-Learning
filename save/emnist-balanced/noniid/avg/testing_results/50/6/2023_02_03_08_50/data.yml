avg_train_accuracy: 0.823
avg_train_loss: 0.006
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.5
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1023936170212766
- 0.16654255319148936
- 0.20420212765957446
- 0.22925531914893618
- 0.22925531914893618
- 0.2515425531914894
- 0.25872340425531914
- 0.25872340425531914
- 0.3081382978723404
- 0.328031914893617
- 0.328031914893617
- 0.328031914893617
- 0.33345744680851064
- 0.34047872340425533
- 0.34047872340425533
- 0.34047872340425533
- 0.37579787234042555
- 0.37579787234042555
- 0.3904787234042553
- 0.39845744680851064
- 0.39845744680851064
- 0.39845744680851064
- 0.39845744680851064
- 0.39845744680851064
- 0.39845744680851064
- 0.39845744680851064
- 0.39845744680851064
- 0.4093617021276596
- 0.4093617021276596
- 0.4395212765957447
- 0.4395212765957447
- 0.44207446808510636
- 0.44207446808510636
- 0.44207446808510636
- 0.44207446808510636
- 0.44207446808510636
- 0.4580851063829787
- 0.45930851063829786
- 0.45930851063829786
- 0.45930851063829786
- 0.46617021276595744
- 0.46617021276595744
- 0.46617021276595744
- 0.46617021276595744
- 0.47154255319148936
- 0.47154255319148936
- 0.47154255319148936
- 0.47154255319148936
- 0.47154255319148936
- 0.47154255319148936
test_loss_list:
- 621.8294298648834
- 650.0525789260864
- 641.9004034996033
- 616.2446038722992
- 616.2446038722992
- 491.4648103713989
- 448.4745543003082
- 448.4745543003082
- 445.95562958717346
- 462.6920716762543
- 462.6920716762543
- 462.6920716762543
- 433.7160987854004
- 432.59756660461426
- 432.59756660461426
- 432.59756660461426
- 418.9298300743103
- 418.9298300743103
- 409.7118225097656
- 429.51086258888245
- 429.51086258888245
- 429.51086258888245
- 429.51086258888245
- 429.51086258888245
- 429.51086258888245
- 429.51086258888245
- 429.51086258888245
- 381.10305738449097
- 381.10305738449097
- 370.9547657966614
- 370.9547657966614
- 414.04975962638855
- 414.04975962638855
- 414.04975962638855
- 414.04975962638855
- 414.04975962638855
- 387.05134415626526
- 367.5794141292572
- 367.5794141292572
- 367.5794141292572
- 383.93308901786804
- 383.93308901786804
- 383.93308901786804
- 383.93308901786804
- 370.922976732254
- 370.922976732254
- 370.922976732254
- 370.922976732254
- 370.922976732254
- 370.922976732254
train_accuracy:
- 0.0
- 0.0
- 0.55
- 0.567
- 0.423
- 0.012
- 0.054
- 0.029
- 0.058
- 0.046
- 0.694
- 0.01
- 0.06
- 0.015
- 0.031
- 0.573
- 0.04
- 0.021
- 0.048
- 0.033
- 0.767
- 0.025
- 0.76
- 0.04
- 0.04
- 0.035
- 0.812
- 0.033
- 0.008
- 0.592
- 0.823
- 0.652
- 0.088
- 0.844
- 0.585
- 0.033
- 0.108
- 0.612
- 0.842
- 0.065
- 0.09
- 0.84
- 0.085
- 0.8
- 0.067
- 0.844
- 0.113
- 0.023
- 0.733
- 0.823
train_loss:
- 3.061
- 2.19
- 1.758
- 1.499
- 1.296
- 1.159
- 0.926
- 0.861
- 0.88
- 1.013
- 1.109
- 1.127
- 0.925
- 0.858
- 0.732
- 0.855
- 0.84
- 0.988
- 0.806
- 0.78
- 0.938
- 0.899
- 0.987
- 0.859
- 0.804
- 0.845
- 0.982
- 0.636
- 0.872
- 0.602
- 0.847
- 0.667
- 0.687
- 0.905
- 0.669
- 0.695
- 0.681
- 0.554
- 0.854
- 0.701
- 0.666
- 0.8
- 0.747
- 0.614
- 0.524
- 0.94
- 0.658
- 0.717
- 0.604
- 0.614
unequal: 0
verbose: 1
