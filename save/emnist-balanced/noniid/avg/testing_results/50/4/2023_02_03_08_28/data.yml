avg_train_accuracy: 0.812
avg_train_loss: 0.008
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.2
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.053404255319148934
- 0.06356382978723404
- 0.10638297872340426
- 0.10638297872340426
- 0.10638297872340426
- 0.10696808510638298
- 0.10696808510638298
- 0.1428191489361702
- 0.15877659574468084
- 0.1848404255319149
- 0.24265957446808512
- 0.24265957446808512
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.39361702127659576
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.425531914893617
- 0.4498404255319149
- 0.4498404255319149
- 0.4498404255319149
- 0.4598404255319149
- 0.46085106382978724
- 0.4625
- 0.4625
- 0.46872340425531916
- 0.46872340425531916
- 0.46872340425531916
- 0.4743617021276596
- 0.4743617021276596
- 0.4743617021276596
- 0.4743617021276596
- 0.4743617021276596
test_loss_list:
- 1099.0047488212585
- 662.4902067184448
- 1320.290316581726
- 1320.290316581726
- 1320.290316581726
- 569.6819589138031
- 569.6819589138031
- 574.3308892250061
- 539.3708684444427
- 554.2460088729858
- 557.5375447273254
- 557.5375447273254
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 591.8788404464722
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 510.26143860816956
- 519.124917268753
- 519.124917268753
- 519.124917268753
- 514.5734589099884
- 548.2416079044342
- 570.4645586013794
- 570.4645586013794
- 531.1300640106201
- 531.1300640106201
- 531.1300640106201
- 460.61515974998474
- 460.61515974998474
- 460.61515974998474
- 460.61515974998474
- 460.61515974998474
train_accuracy:
- 0.021
- 0.179
- 0.463
- 0.054
- 0.01
- 0.102
- 0.7
- 0.102
- 0.481
- 0.521
- 0.548
- 0.237
- 0.698
- 0.337
- 0.75
- 0.335
- 0.002
- 0.679
- 0.067
- 0.046
- 0.533
- 0.229
- 0.421
- 0.481
- 0.694
- 0.756
- 0.41
- 0.681
- 0.44
- 0.508
- 0.729
- 0.344
- 0.506
- 0.379
- 0.787
- 0.781
- 0.579
- 0.396
- 0.808
- 0.802
- 0.852
- 0.494
- 0.819
- 0.683
- 0.579
- 0.852
- 0.708
- 0.842
- 0.777
- 0.812
train_loss:
- 1.499
- 2.188
- 0.571
- 2.434
- 1.896
- 1.98
- 1.639
- 1.605
- 1.442
- 1.401
- 1.212
- 1.341
- 2.005
- 1.202
- 1.367
- 1.148
- 1.507
- 0.609
- 0.576
- 0.513
- 0.485
- 1.353
- 1.093
- 0.431
- 0.535
- 1.875
- 0.487
- 0.366
- 1.038
- 1.015
- 1.111
- 1.159
- 0.439
- 1.091
- 0.928
- 1.518
- 0.927
- 0.993
- 1.419
- 1.308
- 1.259
- 0.863
- 1.311
- 0.498
- 0.532
- 1.403
- 0.431
- 1.356
- 0.829
- 0.793
unequal: 0
verbose: 1
