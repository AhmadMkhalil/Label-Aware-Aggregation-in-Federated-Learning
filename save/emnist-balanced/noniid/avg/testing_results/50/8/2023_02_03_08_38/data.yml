avg_train_accuracy: 0.86
avg_train_loss: 0.005
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.2
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 8
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.0650531914893617
- 0.09047872340425532
- 0.10664893617021276
- 0.11473404255319149
- 0.11478723404255319
- 0.11478723404255319
- 0.11478723404255319
- 0.15319148936170213
- 0.15319148936170213
- 0.19792553191489362
- 0.19792553191489362
- 0.19792553191489362
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.2074468085106383
- 0.20946808510638298
- 0.20946808510638298
- 0.21941489361702127
- 0.21941489361702127
- 0.21941489361702127
- 0.21941489361702127
- 0.21941489361702127
- 0.21941489361702127
- 0.21941489361702127
- 0.21941489361702127
- 0.2272872340425532
- 0.2272872340425532
- 0.2378191489361702
- 0.2378191489361702
- 0.2378191489361702
- 0.23840425531914894
- 0.23840425531914894
- 0.23840425531914894
- 0.24207446808510638
- 0.24207446808510638
- 0.24207446808510638
- 0.24207446808510638
- 0.24207446808510638
- 0.24207446808510638
- 0.25313829787234043
- 0.25313829787234043
- 0.25313829787234043
- 0.25313829787234043
- 0.25313829787234043
test_loss_list:
- 796.2746934890747
- 884.423348903656
- 1629.0389432907104
- 1804.0646543502808
- 1829.3177881240845
- 1829.3177881240845
- 1829.3177881240845
- 718.3261771202087
- 718.3261771202087
- 799.4293990135193
- 799.4293990135193
- 799.4293990135193
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 747.8004260063171
- 891.318838596344
- 891.318838596344
- 569.8352138996124
- 569.8352138996124
- 569.8352138996124
- 569.8352138996124
- 569.8352138996124
- 569.8352138996124
- 569.8352138996124
- 569.8352138996124
- 542.7231786251068
- 542.7231786251068
- 663.6145679950714
- 663.6145679950714
- 663.6145679950714
- 779.0363039970398
- 779.0363039970398
- 779.0363039970398
- 752.754067659378
- 752.754067659378
- 752.754067659378
- 752.754067659378
- 752.754067659378
- 752.754067659378
- 642.7815594673157
- 642.7815594673157
- 642.7815594673157
- 642.7815594673157
- 642.7815594673157
train_accuracy:
- 0.0
- 0.279
- 0.744
- 0.787
- 0.787
- 0.0
- 0.429
- 0.152
- 0.027
- 0.7
- 0.144
- 0.621
- 0.592
- 0.575
- 0.085
- 0.85
- 0.602
- 0.548
- 0.871
- 0.848
- 0.842
- 0.256
- 0.706
- 0.002
- 0.094
- 0.881
- 0.596
- 0.875
- 0.181
- 0.812
- 0.104
- 0.835
- 0.031
- 0.769
- 0.733
- 0.792
- 0.781
- 0.867
- 0.121
- 0.283
- 0.033
- 0.773
- 0.773
- 0.696
- 0.873
- 0.298
- 0.875
- 0.802
- 0.14
- 0.86
train_loss:
- 2.219
- 1.573
- 1.325
- 1.006
- 0.895
- 2.26
- 1.665
- 1.187
- 1.211
- 0.898
- 1.134
- 1.138
- 0.884
- 1.304
- 1.286
- 0.957
- 1.091
- 1.01
- 0.779
- 0.674
- 0.662
- 0.919
- 0.977
- 1.373
- 1.089
- 0.696
- 0.895
- 0.656
- 0.892
- 0.792
- 1.114
- 1.021
- 0.934
- 0.952
- 0.782
- 0.772
- 0.769
- 0.636
- 0.804
- 0.707
- 0.765
- 0.768
- 0.672
- 0.727
- 0.581
- 0.691
- 0.559
- 0.72
- 0.78
- 0.544
unequal: 0
verbose: 1
