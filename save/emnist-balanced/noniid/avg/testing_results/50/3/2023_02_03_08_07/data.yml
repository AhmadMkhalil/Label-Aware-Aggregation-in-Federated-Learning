avg_train_accuracy: 0.854
avg_train_loss: 0.002
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.2
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02851063829787234
- 0.06021276595744681
- 0.12941489361702127
- 0.12941489361702127
- 0.12941489361702127
- 0.12941489361702127
- 0.335
- 0.3675531914893617
- 0.3675531914893617
- 0.3675531914893617
- 0.3675531914893617
- 0.3675531914893617
- 0.4250531914893617
- 0.4250531914893617
- 0.43670212765957445
- 0.43670212765957445
- 0.43670212765957445
- 0.43670212765957445
- 0.43670212765957445
- 0.45159574468085106
- 0.45159574468085106
- 0.45159574468085106
- 0.45159574468085106
- 0.47558510638297874
- 0.47558510638297874
- 0.47558510638297874
- 0.47558510638297874
- 0.47558510638297874
- 0.4892021276595745
- 0.4892021276595745
- 0.49861702127659574
- 0.49861702127659574
- 0.5090957446808511
- 0.5090957446808511
- 0.5090957446808511
- 0.515
- 0.515
- 0.515
- 0.515
- 0.515
- 0.515
- 0.515
- 0.515
- 0.515
- 0.5261170212765958
- 0.5277659574468085
- 0.5277659574468085
- 0.5277659574468085
- 0.5277659574468085
- 0.5277659574468085
test_loss_list:
- 564.5031769275665
- 961.8472967147827
- 532.5616426467896
- 532.5616426467896
- 532.5616426467896
- 532.5616426467896
- 474.0908296108246
- 480.9170262813568
- 480.9170262813568
- 480.9170262813568
- 480.9170262813568
- 480.9170262813568
- 453.07752752304077
- 453.07752752304077
- 433.49145126342773
- 433.49145126342773
- 433.49145126342773
- 433.49145126342773
- 433.49145126342773
- 402.0150730609894
- 402.0150730609894
- 402.0150730609894
- 402.0150730609894
- 424.173677444458
- 424.173677444458
- 424.173677444458
- 424.173677444458
- 424.173677444458
- 381.82942056655884
- 381.82942056655884
- 399.25621271133423
- 399.25621271133423
- 393.3148443698883
- 393.3148443698883
- 393.3148443698883
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 367.42683470249176
- 329.2529580593109
- 343.93453073501587
- 343.93453073501587
- 343.93453073501587
- 343.93453073501587
- 343.93453073501587
train_accuracy:
- 0.04
- 0.973
- 0.154
- 0.975
- 0.946
- 0.008
- 0.465
- 0.481
- 0.075
- 0.215
- 0.858
- 0.977
- 0.604
- 0.819
- 0.644
- 0.963
- 0.971
- 0.0
- 0.644
- 0.665
- 0.29
- 0.85
- 0.946
- 0.719
- 0.433
- 0.667
- 0.735
- 0.95
- 0.717
- 0.912
- 0.74
- 0.929
- 0.735
- 0.579
- 0.96
- 0.76
- 0.5
- 0.631
- 0.892
- 0.506
- 0.473
- 0.531
- 0.533
- 0.8
- 0.76
- 0.756
- 0.619
- 0.675
- 0.944
- 0.854
train_loss:
- 3.82
- 1.304
- 3.703
- 2.021
- 0.594
- 1.733
- 2.866
- 2.529
- 1.771
- 0.556
- 1.612
- 1.442
- 2.252
- 0.477
- 2.253
- 1.215
- 0.333
- 0.733
- 0.462
- 2.276
- 1.185
- 1.171
- 1.092
- 1.86
- 1.161
- 0.428
- 0.439
- 1.088
- 1.806
- 1.046
- 1.736
- 0.996
- 1.663
- 1.065
- 0.32
- 1.715
- 0.976
- 0.955
- 0.241
- 0.911
- 0.927
- 0.883
- 0.889
- 0.41
- 1.578
- 1.464
- 0.869
- 0.211
- 0.238
- 0.161
unequal: 0
verbose: 1
