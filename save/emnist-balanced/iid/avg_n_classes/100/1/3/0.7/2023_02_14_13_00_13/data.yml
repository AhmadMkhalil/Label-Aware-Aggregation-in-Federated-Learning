avg_train_accuracy: 0.806
avg_train_loss: 0.012
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 100
frac: 0.7
iid: 1
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 256
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.2
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 10
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04127659574468085
- 0.08808510638297873
- 0.16872340425531915
- 0.25627659574468087
- 0.3477659574468085
- 0.4327127659574468
- 0.48148936170212764
- 0.5148936170212766
- 0.5442553191489362
- 0.5614361702127659
- 0.5819148936170213
- 0.594095744680851
- 0.6059042553191489
- 0.6182978723404255
- 0.6281914893617021
- 0.6379787234042553
- 0.6446808510638298
- 0.6529787234042553
- 0.6593617021276595
- 0.6632978723404256
- 0.6727659574468086
- 0.6802127659574468
- 0.6843617021276596
- 0.6884574468085106
- 0.6948404255319149
- 0.6990425531914893
- 0.7081914893617022
- 0.7073936170212766
- 0.7123936170212766
- 0.7124468085106384
- 0.7148404255319148
- 0.7194680851063829
- 0.7221808510638298
- 0.7238829787234042
- 0.7268085106382979
- 0.7337765957446809
- 0.7335106382978723
- 0.7348404255319149
- 0.7342021276595745
- 0.7404255319148936
- 0.7413297872340425
- 0.7421808510638298
- 0.7446808510638298
- 0.7493617021276596
- 0.7490425531914894
- 0.751436170212766
- 0.7518617021276596
- 0.7512765957446809
- 0.7536702127659575
- 0.7543085106382978
- 0.7551063829787235
- 0.7595212765957446
- 0.7562234042553192
- 0.7606382978723404
- 0.7593085106382979
- 0.7619148936170212
- 0.7652127659574468
- 0.7648404255319149
- 0.7651595744680851
- 0.765904255319149
- 0.767127659574468
- 0.7698936170212766
- 0.7709574468085106
- 0.7719148936170213
- 0.7719680851063829
- 0.7731914893617021
- 0.7750531914893617
- 0.7743085106382979
- 0.7761170212765958
- 0.7775531914893618
- 0.7773936170212766
- 0.7786702127659575
- 0.7786702127659575
- 0.7773404255319148
- 0.780904255319149
- 0.7811702127659574
- 0.7802659574468085
- 0.7795744680851063
- 0.7803191489361702
- 0.7818085106382979
- 0.781595744680851
- 0.7832978723404256
- 0.7822340425531915
- 0.7843085106382979
- 0.7833510638297873
- 0.7856382978723404
- 0.7863829787234042
- 0.7863297872340426
- 0.7858510638297872
- 0.7850531914893617
- 0.7871808510638297
- 0.7861702127659574
- 0.7870212765957447
- 0.7871808510638297
- 0.7888297872340425
- 0.7888829787234043
- 0.7907446808510639
- 0.79
- 0.7898936170212766
- 0.7875531914893616
test_loss_list:
- 3.776811869939168
- 3.7177356338500975
- 3.537327772776286
- 3.1711669317881266
- 2.7703879070281983
- 2.463708922068278
- 2.2070251814524333
- 2.0191558186213174
- 1.8828396463394166
- 1.7585419225692749
- 1.664194140434265
- 1.5845598300298056
- 1.5303120994567871
- 1.4533082453409831
- 1.390973513921102
- 1.3495007832845052
- 1.3171042505900066
- 1.2634557676315308
- 1.2367464844385783
- 1.2054900773366293
- 1.1762759606043498
- 1.145013648668925
- 1.1217325552304587
- 1.0966332991917929
- 1.0702234490712483
- 1.0507787108421325
- 1.0297706309954326
- 1.0136001515388489
- 0.996959441502889
- 0.9867931087811788
- 0.9647557997703552
- 0.9553017314275106
- 0.9448266545931499
- 0.9353540762265523
- 0.92327352921168
- 0.90757621606191
- 0.904476854801178
- 0.893939843972524
- 0.8840908471743266
- 0.8761600629488627
- 0.8642860341072083
- 0.8548972868919372
- 0.8515690104166667
- 0.8441172591845194
- 0.83479918162028
- 0.8288322496414184
- 0.8209256664911906
- 0.817803148428599
- 0.8129296151796976
- 0.805133052666982
- 0.8034017618497212
- 0.7968201859792073
- 0.7898218901952108
- 0.7887847193082174
- 0.7843505549430847
- 0.7763223401705424
- 0.7734159143765768
- 0.7681325570742289
- 0.7637629771232605
- 0.7629939691225688
- 0.7588715076446533
- 0.7517639311154684
- 0.7513459293047587
- 0.7457521065076193
- 0.7478799017270407
- 0.7416505988438924
- 0.7370832292238871
- 0.7338959964116415
- 0.7301823472976685
- 0.7305595167477925
- 0.7223520398139953
- 0.7236818099021911
- 0.7221177705128987
- 0.7196830463409424
- 0.7131815266609192
- 0.7122319277127583
- 0.7159545723597208
- 0.7124814422925313
- 0.7097267731030782
- 0.7059626730283102
- 0.7041064818700155
- 0.7008901540438334
- 0.7026950391133626
- 0.6981773757934571
- 0.6984089112281799
- 0.6930079913139343
- 0.6926334794362387
- 0.6893600591023763
- 0.6900607601801554
- 0.6890002910296122
- 0.6841651487350464
- 0.6830404321352641
- 0.6816199453671773
- 0.6795858112970988
- 0.677264031569163
- 0.6769806551933288
- 0.673539686203003
- 0.6745203669865926
- 0.6717010847727458
- 0.6721314247449239
train_accuracy:
- 0.025
- 0.083
- 0.204
- 0.279
- 0.34
- 0.45
- 0.494
- 0.533
- 0.523
- 0.592
- 0.575
- 0.59
- 0.594
- 0.625
- 0.623
- 0.662
- 0.656
- 0.671
- 0.667
- 0.673
- 0.681
- 0.69
- 0.671
- 0.7
- 0.69
- 0.694
- 0.715
- 0.746
- 0.71
- 0.735
- 0.727
- 0.733
- 0.719
- 0.721
- 0.723
- 0.717
- 0.767
- 0.737
- 0.754
- 0.731
- 0.752
- 0.733
- 0.748
- 0.75
- 0.74
- 0.771
- 0.742
- 0.76
- 0.769
- 0.763
- 0.763
- 0.769
- 0.783
- 0.779
- 0.752
- 0.758
- 0.75
- 0.775
- 0.787
- 0.804
- 0.785
- 0.777
- 0.763
- 0.756
- 0.785
- 0.773
- 0.787
- 0.758
- 0.81
- 0.792
- 0.792
- 0.815
- 0.796
- 0.79
- 0.779
- 0.802
- 0.779
- 0.79
- 0.775
- 0.777
- 0.796
- 0.802
- 0.769
- 0.773
- 0.804
- 0.806
- 0.808
- 0.785
- 0.767
- 0.783
- 0.796
- 0.775
- 0.767
- 0.802
- 0.775
- 0.785
- 0.81
- 0.783
- 0.827
- 0.806
train_loss:
- 3.847
- 3.816
- 3.737
- 3.542
- 3.273
- 3.032
- 2.834
- 2.675
- 2.553
- 2.435
- 2.339
- 2.26
- 2.212
- 2.146
- 2.088
- 2.033
- 1.998
- 1.944
- 1.912
- 1.874
- 1.846
- 1.812
- 1.783
- 1.766
- 1.727
- 1.711
- 1.697
- 1.674
- 1.648
- 1.626
- 1.604
- 1.597
- 1.576
- 1.58
- 1.547
- 1.545
- 1.524
- 1.52
- 1.51
- 1.503
- 1.479
- 1.466
- 1.463
- 1.445
- 1.443
- 1.437
- 1.426
- 1.423
- 1.415
- 1.409
- 1.396
- 1.394
- 1.382
- 1.376
- 1.378
- 1.36
- 1.361
- 1.359
- 1.348
- 1.345
- 1.339
- 1.337
- 1.323
- 1.322
- 1.323
- 1.312
- 1.296
- 1.297
- 1.299
- 1.296
- 1.282
- 1.285
- 1.273
- 1.278
- 1.271
- 1.275
- 1.274
- 1.26
- 1.259
- 1.257
- 1.252
- 1.248
- 1.246
- 1.24
- 1.239
- 1.236
- 1.236
- 1.231
- 1.226
- 1.216
- 1.216
- 1.222
- 1.21
- 1.21
- 1.207
- 1.2
- 1.207
- 1.211
- 1.198
- 1.192
unequal: 0
verbose: 1
